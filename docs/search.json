[
  {
    "objectID": "posts/xlsx-online-import/index.html",
    "href": "posts/xlsx-online-import/index.html",
    "title": "xls-online-import",
    "section": "",
    "text": "Importieren Sie eine XLSX-Datei aus dem Internet in R (als Dataframe).\nHier ist ein Pfad: https://github.com/sebastiansauer/Lehre/raw/refs/heads/main/25-SoSe/FAU-2025-09/penguins.xlsx.\n\ndata_url &lt;- \"https://github.com/sebastiansauer/Lehre/raw/refs/heads/main/25-SoSe/FAU-2025-09/penguins.xlsx\"\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/xlsx-online-import/index.html#weg-1",
    "href": "posts/xlsx-online-import/index.html#weg-1",
    "title": "xls-online-import",
    "section": "2.1 Weg 1",
    "text": "2.1 Weg 1\n\nlibrary(rio)\npenguins &lt;- import(data_url)"
  },
  {
    "objectID": "posts/xlsx-online-import/index.html#weg-2",
    "href": "posts/xlsx-online-import/index.html#weg-2",
    "title": "xls-online-import",
    "section": "2.2 Weg 2",
    "text": "2.2 Weg 2\n\ndest_file &lt;- \"penguins.xlsx\"\n\ndownload.file(url = data_url, destfile = dest_file, mode = \"wb\")\n\nlibrary(readxl)\n\nmy_data &lt;- read_excel(dest_file)"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "title": "tidymodels-lasso3",
    "section": "",
    "text": "Schreiben Sie eine prototypische Analyse f√ºr ein Vorhersagemodell mit dem Lasso.\nBerichten Sie, welche Pr√§diktoren nach dem Lasso im Modell verbleiben.\nHinweise:\n\nTunen Sie die Penalisierung.\nVerwenden Sie Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ ."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "title": "tidymodels-lasso3",
    "section": "Standardvorgehen",
    "text": "Standardvorgehen\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variablenbedeutung\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n16.641 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0e+00\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod01_post0\n\n\n0.0e+00\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod02_post0\n\n\n0.0e+00\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod03_post0\n\n\n3.0e-07\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod04_post0\n\n\n5.1e-06\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod05_post0\n\n\n\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellg√ºte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n325.8327320\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8188554\npre0_mod0_post0"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "title": "tidymodels-lasso3",
    "section": "Inspektion der Tuningparameter",
    "text": "Inspektion der Tuningparameter\n\nautoplot(wf1_fit)\n\n\n\n\n\n\n\n\nDie Standard-Wahl der Tuningparameter-Werte war offenbar nicht so ideal, zumindest sieht man kaum Unterschiede zwischen der Modellg√ºte in Abh√§ngigkeit von den Werten der Tuningparameter."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "title": "tidymodels-lasso3",
    "section": "Variablenbedeutung",
    "text": "Variablenbedeutung\n\nlibrary(vip)\n\nvi_preds &lt;- \nwf1_fit_final %&gt;% \n  extract_fit_engine() %&gt;% \n  vi()\n\nvi_preds\n\n\n\n\n\nVariable\nImportance\nSign\n\n\n\n\nspecies_Gentoo\n763.05092\nPOS\n\n\nsex_male\n388.86671\nPOS\n\n\nspecies_Chinstrap\n284.44779\nNEG\n\n\nflipper_length_mm\n268.33432\nPOS\n\n\nbill_length_mm\n128.42872\nPOS\n\n\nbill_depth_mm\n70.61908\nPOS\n\n\nisland_Dream\n63.80234\nNEG\n\n\nyear\n30.65721\nNEG\n\n\nisland_Torgersen\n0.00000\nNEG\n\n\n\n\n\n\n\nvi_preds %&gt;% \n  ggplot(aes(x = Importance, y = reorder(Variable, Importance), fill = Sign)) +\n  geom_col()\n\n\n\n\n\n\n\n\nMan beachte: F√ºr regulierte Modelle sind Zentrierung und Skalierung n√∂tig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nstring\ntemplate"
  },
  {
    "objectID": "posts/anim01/anim01.html",
    "href": "posts/anim01/anim01.html",
    "title": "anim01",
    "section": "",
    "text": "Visualisieren Sie in animierter Form den Zusammenhang von Lebenserwartung und Bruttosozialprodukt im Verlauf der Jahre (Datensatz gapminder); der Kontinent soll in der Visualisierung ber√ºcksichtigt sein.\nHinweise:\n\nNutzen Sie gganimate zur Visualisierung."
  },
  {
    "objectID": "posts/anim01/anim01.html#setup",
    "href": "posts/anim01/anim01.html#setup",
    "title": "anim01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(gganimate)\ndata(gapminder)"
  },
  {
    "objectID": "posts/anim01/anim01.html#statisches-diagramm",
    "href": "posts/anim01/anim01.html#statisches-diagramm",
    "title": "anim01",
    "section": "Statisches Diagramm",
    "text": "Statisches Diagramm\n\np &lt;- gapminder %&gt;% \n  ggplot(aes(x = gdpPercap, y = lifeExp, color = continent, frame = year)) +\n  geom_point()+\n  scale_x_log10()\np"
  },
  {
    "objectID": "posts/anim01/anim01.html#animation",
    "href": "posts/anim01/anim01.html#animation",
    "title": "anim01",
    "section": "Animation",
    "text": "Animation\n\ngapminder$continent &lt;- as.factor(gapminder$continent)\n\np_animated &lt;- ggplot(gapminder,\n            aes(x = gdpPercap, \n                y = lifeExp, \n                color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_discrete() +   # &lt;- force discrete scale\n  labs(title = \"Year: {frame_time}\") +\n  transition_time(year)\n\np_animated\n\nDieser Post orientiert sich an dieser Quelle; dort finden sich auch mehr Beispiele.\n\nCategories:\n\n2023\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "href": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "title": "tidymodels-vorlage3",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse f√ºr ein Vorhersagemodell, das sich als Vorlage f√ºr Analysen dieser Art eignet!\nVerzichten Sie auf Resampling und Tuning.\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie keinen Parameter des Modells\nVerwenden Sie keine Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(easystats)   # NAs z√§hlen\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"regression\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d_train) |&gt; \n  step_unknown(all_nominal_predictors(), new_level = \"NA\") |&gt; \n  step_naomit(all_predictors()) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_zv(all_predictors()) |&gt; \n  step_normalize(all_predictors()) \n\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  last_fit(split = d_split)\ntoc()\n\n0.496 sec elapsed\n\ncollect_metrics(wf1_fit)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n310.3661061\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8627167\npre0_mod0_post0\n\n\n\n\n\n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nyear\nbody_mass_g\nspecies_Chinstrap\nspecies_Gentoo\nisland_Dream\nisland_Torgersen\nsex_male\nsex_NA.\n\n\n\n\n-1.2404291\n-1.5309296\n0.3858343\n-0.7943918\n-1.2921757\n3450\n-0.5026644\n-0.7579203\n1.3366001\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n1.4505356\n1.3186250\n0.3858343\n-0.3653368\n1.1407119\n3675\n1.9816579\n-0.7579203\n1.3366001\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n-0.2115308\n0.4006477\n-1.9691393\n0.7073009\n-1.2921757\n4500\n-0.5026644\n1.3142661\n-0.7452558\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n-0.9930977\n0.3432741\n0.8868925\n-0.2938276\n-0.0757319\n4150\n-0.5026644\n-0.7579203\n-0.7452558\n2.4336824\n1.0336378\n-0.1543093\n\n\n0.5304631\n0.8787609\n-0.5661763\n2.0659752\n-0.0757319\n5800\n-0.5026644\n1.3142661\n-0.7452558\n-0.4093011\n1.0336378\n-0.1543093\n\n\n-0.2807836\n-0.9571938\n0.7866809\n-1.1519377\n1.1407119\n3650\n-0.5026644\n-0.7579203\n1.3366001\n-0.4093011\n1.0336378\n-0.1543093\n\n\n\n\n\n\n\ndescribe_distribution(d_train_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nrownames\n0.000\n1.0000\n1.696693\n-1.7153052\n1.678080\n-0.0140987\n-1.2072129\n257\n0\n\n\nbill_length_mm\n0.000\n1.0000\n1.682958\n-2.2767861\n2.982459\n0.0138271\n-0.7949178\n257\n0\n\n\nbill_depth_mm\n0.000\n1.0000\n1.603386\n-2.0192451\n2.189644\n-0.1101092\n-0.8689102\n257\n0\n\n\nflipper_length_mm\n0.000\n1.0000\n1.644711\n-1.9385386\n2.065975\n0.3185041\n-1.0170679\n257\n0\n\n\nyear\n0.000\n1.0000\n2.432888\n-1.2921757\n1.140712\n-0.1160338\n-1.5114889\n257\n0\n\n\nbody_mass_g\n4200.973\n792.5366\n1212.500000\n2700.0000000\n6300.000000\n0.4897600\n-0.6875459\n257\n0\n\n\nspecies_Chinstrap\n0.000\n1.0000\n0.000000\n-0.5026644\n1.981658\n1.4905934\n0.2235476\n257\n0\n\n\nspecies_Gentoo\n0.000\n1.0000\n2.072186\n-0.7579203\n1.314266\n0.5607093\n-1.6988872\n257\n0\n\n\nisland_Dream\n0.000\n1.0000\n2.081856\n-0.7452558\n1.336600\n0.5959823\n-1.6577672\n257\n0\n\n\nisland_Torgersen\n0.000\n1.0000\n0.000000\n-0.4093011\n2.433682\n2.0402588\n2.1795571\n257\n0\n\n\nsex_male\n0.000\n1.0000\n1.997330\n-0.9636924\n1.033638\n0.0704940\n-2.0107396\n257\n0\n\n\nsex_NA.\n0.000\n1.0000\n0.000000\n-0.1543093\n6.455274\n6.3503836\n38.6279271\n257\n0\n\n\n\n\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/mtcars-regr01/mtcars-regr01.html",
    "href": "posts/mtcars-regr01/mtcars-regr01.html",
    "title": "mtcars-regr01",
    "section": "",
    "text": "Aufgabe\n\ndata(\"mtcars\")\n\nBetrachten Sie folgendes Modell (Datensatz mtcars):\nmpg ~ disp\nAnders gesagt: Wie gut kann man den Spritverbrauch vorhersagen auf Basis des Hubraums eines Autos?\n\nBerechnen Sie die Modellkoeffizienten! Tipp: lm()\nBerechnen Sie im Anschluss die Vorhersagen dieses Modells. Tipp: predict() mit mutate()\nVisualisieren Sie dann das Modell Tipp: ggplot() und geom_smooth() oder mittels einer anderer Methode.\nBerechnen Sie die Residuen: e = echtem Y-Wert und vorhergesagtem Y-Wert. Tipp: mutate().\nBerechnen Sie die Korrelation zwischen Spritverbrauch und Hubraum! Tipp: summarise() mitcor()`.\n\n         \n\n\nL√∂sung\n\n\nVorbereitung\n\nlibrary(tidyverse)\ndata(mtcars)\n\n\n\nAd 1\n\nlm1 &lt;- lm(mpg ~ disp, data = mtcars)\nlm1\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122  \n\n\n\n\nAd 2\nNicht einfach nur predicten:\n\npredict(lm1)\n\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive \n           23.00544            23.00544            25.14862            18.96635 \n  Hornet Sportabout             Valiant          Duster 360           Merc 240D \n           14.76241            20.32645            14.76241            23.55360 \n           Merc 230            Merc 280           Merc 280C          Merc 450SE \n           23.79677            22.69220            22.69220            18.23272 \n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental \n           18.23272            18.23272            10.14632            10.64090 \n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla \n           11.46520            26.35622            26.47987            26.66946 \n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 \n           24.64992            16.49345            17.07046            15.17456 \n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa \n           13.11381            26.34386            24.64168            25.68030 \n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E \n           15.13335            23.62366            17.19410            24.61283 \n\n\nSondern die Predictions als neue Spalte in mtcars anlegen. Viel sauberer!\n\nmtcars2  &lt;- \n  mtcars %&gt;% \n  mutate(preds_lm1 = predict(lm1))\n\n\n\nAd 3\n\nggplot(mtcars2) +\n  aes(y = mpg, x = disp) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAndere Visualisierung:\n\nmtcars2 %&gt;% \n  ggplot(aes(x = disp, y = preds_lm1)) +\n  geom_point(size = 2, alpha = .8, color = \"pink\") +\n  geom_line() +\n  labs(y = \"Vorhergesagte MPG-Werte\",\n       title = \"Vorhersage-Modell lm1\")\n\n\n\n\n\n\n\n\nOder so:\n\nlibrary(easystats)\nestimate_expectation(lm1, by = \"disp\") %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\nAd 4\n\nmtcars2 &lt;- \n  mtcars2 %&gt;% \n  mutate(e = abs(mpg - preds_lm1))  # abs steht f√ºr \"Absolutwert\"\n\nDer ‚ÄúAbsolutwert‚Äù kickt das Vorzeichen weg. Das machen wir, wenn wir meinen, dass das Vorzeichen egal ist.\n\n\nBonus-Aufgabe\nBerechnen Sie den mittleren Fehler √ºber alle e!\n\nmtcars2 %&gt;% \n  summarise(e_avg = mean(e))\n\n\n\n\n\ne_avg\n\n\n\n\n2.605473\n\n\n\n\n\n\n\n\nAd 5\n\nmtcars %&gt;% \n  summarise(cor_mpg_disp = cor(mpg, disp))\n\n\n\n\n\ncor_mpg_disp\n\n\n\n\n-0.8475514\n\n\n\n\n\n\n\nCategories:\n\nlm\nmtcars\ncorrelation\nregression\nstring"
  },
  {
    "objectID": "posts/germeval04/germeval04.html",
    "href": "posts/germeval04/germeval04.html",
    "title": "germeval04",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon."
  },
  {
    "objectID": "posts/germeval04/germeval04.html#finalisieren",
    "href": "posts/germeval04/germeval04.html#finalisieren",
    "title": "germeval04",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nfit1_best &lt;- select_best(wf1_fit)\n\n\nwf1_final &lt;- finalize_workflow(wf1, fit1_best)\nwf1_final_fit &lt;- fit(wf1_final, data = d_train)\n\nVorhersagen:\n\npreds &lt;- predict(wf1_final_fit, germeval_test)"
  },
  {
    "objectID": "posts/germeval04/germeval04.html#test-set-g√ºte",
    "href": "posts/germeval04/germeval04.html#test-set-g√ºte",
    "title": "germeval04",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\naccuracy\nbinary\n0.6395810\n\n\nf_meas\nbinary\n0.2645869"
  },
  {
    "objectID": "posts/germeval04/germeval04.html#fazit",
    "href": "posts/germeval04/germeval04.html#fazit",
    "title": "germeval04",
    "section": "Fazit",
    "text": "Fazit\nEine Reihe der Text-Features passen nicht gut auf nicht-englische Texte.\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nsentiment\nstring"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html",
    "title": "ppv-mtcars1",
    "section": "",
    "text": "Berechnen Sie folgendes Modell (Datensatz mtcars):\nmpg ~ hp\nGeben Sie die Breite eines 50%-ETI an f√ºr eine Beobachtung mit einem z-Wert von 0 im Pr√§diktor!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#setup",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#setup",
    "title": "ppv-mtcars1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  mutate(hp = standardize(hp))"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#modell",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#modell",
    "title": "ppv-mtcars1",
    "section": "Modell",
    "text": "Modell\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, seed = 42, refresh = 0)\n\nModellparameter:\n\ncoef(m1)\n\n(Intercept)          hp \n30.11668130 -0.06820988 \n\n\nModellg√ºte:\n\nr2(m1)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])\n\n\nOder mit z-standardisierten Werten:\n\nm2 &lt;- stan_glm(mpg ~ hp, data = mtcars2, seed = 42, refresh = 0)\ncoef(m2)\n\n(Intercept)          hp \n  20.096771   -4.676665 \n\nr2(m2)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#ppv",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#ppv",
    "title": "ppv-mtcars1",
    "section": "PPV",
    "text": "PPV\n\nm2_ppv &lt;- estimate_prediction(m2, data = tibble(hp = 0), ci = 0.5)\nm2_ppv\n\n\n\n\n\nhp\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n0\n20.08646\n4.077161\n17.47148\n22.67675\n\n\n\n\n\n\nVisualisierung:\n\nplot(estimate_prediction(m2, by = \"hp\"))\n\n\n\n\n\n\n\n\nMan beachte, dass die PPV mit mehr Ungewissheit behaftet ist, als die Post-Verteilung.\n\nplot(estimate_relation(m2))\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nppv\nregression\nnum"
  },
  {
    "objectID": "posts/chatgpt-sentiment-simple/chatgpt-sentiment-simple.html",
    "href": "posts/chatgpt-sentiment-simple/chatgpt-sentiment-simple.html",
    "title": "chatgpt-sentiment-simple",
    "section": "",
    "text": "Aufgabe\nFragen Sie ChatGPT via API zum Sentiment des ersten Texts aus dem Germeval-2018-Datensatz (Train).\n\n\n\n\n\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen.\n\n         \n\n\nL√∂sung\n\nOpenAI hat eine neue API (Stand: 2023-11-23). Der Code der alten API bricht. üíî \\(\\square\\)\n\nModule importieren:\n\nfrom openai import OpenAI\n\nModuleNotFoundError: No module named 'openai'\n\n\nAnmelden bei OpenAI:\n\nclient = OpenAI()\n\nNameError: name 'OpenAI' is not defined\n\n\n\n\n\n\n\n\nNote\n\n\n\nDieses Verfahren setzt voraus, dass in .Renviron die Variable OPENAI_API_KEY hinterlegt ist. \\(\\square\\)\n\n\nTextschnipsel, das zu klassifizieren ist:\n\ntext = \"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"\n\nPrompt definieren:\n\nmy_prompt  = f\"Analysieren Sie das Sentiment des folgenden Texts:\\n{text}\"\n\nAnfrage an die API, in eine Funktion gepackt:\n\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n  model=model,\n  messages=messages,\n  max_tokens=50,\n  temperature=0,\n  )\n  return response.choices[0].message.content\n\nUnd los:\n\nget_completion(my_prompt, client) \n\nNameError: name 'client' is not defined"
  },
  {
    "objectID": "posts/samples-nyc2/index.html",
    "href": "posts/samples-nyc2/index.html",
    "title": "samples-nyc2",
    "section": "",
    "text": "Drei Studierende arbeiten f√ºr die New Yorker Flughafenbeh√∂rde als Werkstudenten. Fragt ihre Chefin eines Tages: ‚ÄúWelcher der drei New Yorker Flugh√§fen hat im Schnitt die h√∂chste Versp√§tung? Zieht mal eine kleine Stichprobe und gebt mir eine gute Antwort.‚Äù\nStudi A √ºberlegt: ‚ÄúHm, ich schaue mir mal die ersten 1000 Fl√ºge des Jahres und diesen Mittelwert nehme ich als Sch√§tzwert f√ºr die Versp√§tung des ganzen Jahres.‚Äù\nStudi B argumentiert so: ‚ÄúHm, ich nehme die ersten 100 Fl√ºge von jedem Monat, rechne davon den Mittelwert aus. Das ist dann mein Sch√§tzwert f√ºr die Versp√§tung des ganzen Jahres, pro Flughafen.‚Äù\nStudi C hingegen ist folgender Meinung: ‚ÄúIch ziehe mal eine Zufallsstichprobe, habe ich in der Statistik-Vorlesung gelernt. N=100 sollte gen√ºgen.‚Äù\nDie Chefin bezieht sich √ºbrigens auf das Jahr 2023.\nAufgabe: Welcher der drei Studis macht die beste Vorhersage? Rechnen Sie nach und begr√ºnden Sie Ihre Meinung!"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#setup",
    "href": "posts/samples-nyc2/index.html#setup",
    "title": "samples-nyc2",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(nycflights23)  # Dataset \"flights\"\ndata(\"flights\")\nlibrary(tidyverse)\n\nWie viele Fl√ºge gab es?\n\nnrow(flights)\n\n[1] 435352\n\n\nViele!\nWelche Variablen gibt es im Datensatz?\n\nglimpse(flights)\n\nRows: 435,352\nColumns: 19\n$ year           &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2‚Ä¶\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ dep_time       &lt;int&gt; 1, 18, 31, 33, 36, 503, 520, 524, 537, 547, 549, 551, 5‚Ä¶\n$ sched_dep_time &lt;int&gt; 2038, 2300, 2344, 2140, 2048, 500, 510, 530, 520, 545, ‚Ä¶\n$ dep_delay      &lt;dbl&gt; 203, 78, 47, 173, 228, 3, 10, -6, 17, 2, -10, -9, -7, -‚Ä¶\n$ arr_time       &lt;int&gt; 328, 228, 500, 238, 223, 808, 948, 645, 926, 845, 905, ‚Ä¶\n$ sched_arr_time &lt;int&gt; 3, 135, 426, 2352, 2252, 815, 949, 710, 818, 852, 901, ‚Ä¶\n$ arr_delay      &lt;dbl&gt; 205, 53, 34, 166, 211, -7, -1, -25, 68, -7, 4, -13, -14‚Ä¶\n$ carrier        &lt;chr&gt; \"UA\", \"DL\", \"B6\", \"B6\", \"UA\", \"AA\", \"B6\", \"AA\", \"UA\", \"‚Ä¶\n$ flight         &lt;int&gt; 628, 393, 371, 1053, 219, 499, 996, 981, 206, 225, 800,‚Ä¶\n$ tailnum        &lt;chr&gt; \"N25201\", \"N830DN\", \"N807JB\", \"N265JB\", \"N17730\", \"N925‚Ä¶\n$ origin         &lt;chr&gt; \"EWR\", \"JFK\", \"JFK\", \"JFK\", \"EWR\", \"EWR\", \"JFK\", \"EWR\",‚Ä¶\n$ dest           &lt;chr&gt; \"SMF\", \"ATL\", \"BQN\", \"CHS\", \"DTW\", \"MIA\", \"BQN\", \"ORD\",‚Ä¶\n$ air_time       &lt;dbl&gt; 367, 108, 190, 108, 80, 154, 192, 119, 258, 157, 164, 1‚Ä¶\n$ distance       &lt;dbl&gt; 2500, 760, 1576, 636, 488, 1085, 1576, 719, 1400, 1065,‚Ä¶\n$ hour           &lt;dbl&gt; 20, 23, 23, 21, 20, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6,‚Ä¶\n$ minute         &lt;dbl&gt; 38, 0, 44, 40, 48, 0, 10, 30, 20, 45, 59, 0, 59, 0, 0, ‚Ä¶\n$ time_hour      &lt;dttm&gt; 2023-01-01 20:00:00, 2023-01-01 23:00:00, 2023-01-01 2‚Ä¶\n\n\nNehmen wir dep_delay als Zielvariable. Die Chefin hat nicht genau gesagt, welche Variable sie meint. Da sieht man es mal wieder: Man muss Annahmen treffen. Ist aber auch sch√∂n, denn man kann selber entscheiden, was einem besser gef√§llt."
  },
  {
    "objectID": "posts/samples-nyc2/index.html#los-gehts",
    "href": "posts/samples-nyc2/index.html#los-gehts",
    "title": "samples-nyc2",
    "section": "2.2 Los geht‚Äôs",
    "text": "2.2 Los geht‚Äôs\n\n2.2.1 Studentin A\n\nestimate_A &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  slice(1:1000) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_A\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n26.1\n\n\nJFK\n19.9\n\n\nLGA\n9.4\n\n\n\n\n\n\n‚ÄúKlares (?) Ergebnis! EWR, also Newark, hat die gr√∂√üte Versp√§tung!‚Äù\n\n\n2.2.2 Student B\n\nestimate_B &lt;-\nflights |&gt; \n  select(dep_delay, origin, month) |&gt; \n  drop_na() |&gt; \n  group_by(month, origin) |&gt; \n  slice(1:100) |&gt; \n  summarise(dep_delay = mean(dep_delay)) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_B\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n8.47\n\n\nJFK\n9.74\n\n\nLGA\n0.76\n\n\n\n\n\n\n‚ÄúKnapp! EWR hat fast so viel Versp√§tung wie JFK.‚Äù\n\n\n2.2.3 Studentin C\n\nset.seed(73)\n\nestimate_C &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_C\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n2.0\n\n\nJFK\n14.3\n\n\nLGA\n8.8\n\n\n\n\n\n\n‚ÄúGlasklares (?) Ergebnis! JFK, also John-F-Kennedy, hat die gr√∂√üte Versp√§tung! Newark ist hingegen superp√ºnktlich!‚Äù"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#moment",
    "href": "posts/samples-nyc2/index.html#moment",
    "title": "samples-nyc2",
    "section": "2.3 Moment",
    "text": "2.3 Moment\nLeider entbrennt hier ein Streit. Vermutlich einige Eifersuchtsmomente hinter den Kulissen, aber wir wissen nichts Genaues.\nStudentin A: ‚ÄúSo ein Quatsch, C, du hast die Zufallszahl auf 73 festgelegt, warum gerade diese Zahl?! Bei einer anderen Zahl k√∂nnte ein ganz andere Stichprobe und damit ein ganz anderes Ergebnis herauskommen!‚Äù\nStudentin C: ‚ÄúIch habe k√ºrzlich gelernt, dass nicht 42, sondern 73 die beste Zahl ist. Also musste ich 73 nehmen!\nStudent B: ‚ÄúAber was k√§me heraus, wenn du 42 als Zufallszahl nehmen w√ºrdest, nur mal theoretisch?‚Äù\nStudentin C: ‚Äú√Ñh‚Ä¶‚Äù\n\nset.seed(42)\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n28.3\n\n\nJFK\n7.5\n\n\nLGA\n9.9\n\n\n\n\n\n\nStudentin C: ‚Äú√Ñh, also‚Ä¶ Das spielt doch gar keine Rolle, was rauskommt, denn bei jeder Zahl kann ja was anderes rauskommen.‚Äù\nA: ‚ÄúDu m√ºsstest also dein Vorgehen √§ndern‚Ä¶ Jede Zahl ausprobieren oder so.‚Äù\nC: ‚ÄúLiebe A, du mit deinen Fl√ºgen vom Jahresbeginn, das ist doch totaler Quatsch, an deiner Stelle w√§re ich lieber still.‚Äù\nA: ‚ÄúAber es kommt was Gutes raus mit meiner Methode!‚Äù\nB: ‚ÄúWoher willst du √ºberhaupt wissen, ob es was Gutes ist?‚Äù\nA: ‚ÄúWirst schon sehen!‚Äù\nC: ‚ÄúPuh, also gut, ich rechne noch mal. Ich zieh einfach ne Menge Stichproben, mit zuf√§lligen Seed-Nummern ‚Ä¶‚Äù\nA: ‚ÄúWhatever!‚Äù\nC: ‚ÄúMoment.., hier kommt Newark, EWR.‚Äù\n\nn_reps &lt;- 100  # Anzahl von Stichproben\nsample_size &lt;- 100  # Umfang jeder Stichprobe\n\newr_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"EWR\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\newr_viele_schaetzwerte\n\n[1] 15\n\n\nB: ‚ÄúWow, C, du bist halt schon die Statistik-Checkerin‚Ä¶‚Äù.\nA: ‚ÄúHey B, h√∂r gef√§lligst auf, dich bei A einzuschmeicheln!‚Äù\nB: ‚ÄúJedenfalls ist das Ergebnis von A ‚Ä¶ anders als unsere!‚Äù\nC: ‚ÄúHier noch mal mein Prinzip f√ºr die anderen Flugh√§fen. JFK:‚Äù\n\njfk_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"JFK\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\njfk_viele_schaetzwerte\n\n[1] 16\n\n\nC: ‚ÄúUnd LaGuardia:‚Äù\n\nlga_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"LGA\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\nlga_viele_schaetzwerte\n\n[1] 11\n\n\nC: ‚ÄúAlso, unterm Strich, LGA rules! LGA hat die geringste Versp√§tung im Schnitt, nach meiner Rechnung.‚Äù\n\nlga_viele_schaetzwerte\n\n[1] 11\n\newr_viele_schaetzwerte\n\n[1] 15\n\njfk_viele_schaetzwerte\n\n[1] 16"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#fazit",
    "href": "posts/samples-nyc2/index.html#fazit",
    "title": "samples-nyc2",
    "section": "2.4 Fazit?",
    "text": "2.4 Fazit?\nA: ‚ÄúOkay, meine Methode war ein bisschen zu einfach. Aber hat auch am wenigsten Arbeit gemacht. Das nennt man wirtschaftlich vorgehen, nur darum geht‚Äôs im Business. Also hab ich trotzdem gewonnen!‚Äù\nB: ‚ÄúNope, mein Vorgehen ist in Wirklichkeit das Beste. Ich hab von jedem Monat 100 Fl√ºge genommen, so hat sich alles super ausgeglichen, Jahreszeiten und so, glaub ich. Und es w√§re nicht so viel Aufwand wie die zich Tausend Stichproben, die C gezogen hat.‚Äù\nC: ‚ÄúKann ja alles sein, aber mein Vorgehen hat am meisten Spa√ü gemacht. √úbrigens B, wir k√∂nnten uns, also unsere beiden Ideen, doch zusammenlegn, kombinieren. Das m√ºsste ein super Ergebnis geben. Wollen wir zwei uns das mal zusammen anschauen, nur wir zwei?‚Äù"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#wahre-versp√§tung",
    "href": "posts/samples-nyc2/index.html#wahre-versp√§tung",
    "title": "samples-nyc2",
    "section": "3.1 Wahre Versp√§tung",
    "text": "3.1 Wahre Versp√§tung\nDie Chefin berechnet die wahre Versp√§tung √ºber alle Fl√ºge 2023 (in YNC) insgesamt (also in der Population der NYC-Fl√ºge von 2023):\n\nwahre_verspaetung &lt;- \n  flights |&gt; \n  select(origin, dep_delay) |&gt; \n  drop_na() |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nwahre_verspaetung\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n15\n\n\nJFK\n16\n\n\nLGA\n11\n\n\n\n\n\n\nChefin: ‚ÄúLaGuardia hat am wenigsten Versp√§tung. JFK am meisten, aber dicht gefolgt von EWR.‚Äù\nChefin: ‚ÄúJetzt schauen wir mal, wer pro Flughafen am genauesten gesch√§tzt hat.‚Äù\n\nmodellgueten &lt;-\n  wahre_verspaetung |&gt; \n  mutate(estimate_A = estimate_A$dep_delay,\n         estimate_B = estimate_B$dep_delay,\n         estimate_C = c(\n           ewr_viele_schaetzwerte,\n           jfk_viele_schaetzwerte,\n           lga_viele_schaetzwerte)\n  ) |&gt; \n  pivot_longer(contains(\"estimate\"), \n               names_to = \"student\", \n               values_to = \"estimate\") |&gt; \n  mutate(error_abs = abs(dep_delay - estimate)) \n\nChefin: ‚ÄúLaGuardia wurde ingesamt am genauesten gesch√§tzt, von allen drei Studenten. Aber Studentin A √ºbersch√§tzt die Versp√§tung massiv bei Newark und bei JFK.‚Äù\nChefin: ‚ÄúHier sind die Details.‚Äù\n\nmodellgueten |&gt; \n  ggplot(aes(y = estimate, x = origin)) +\n # geom_line() +\n  geom_col(data = wahre_verspaetung,\n    aes(x = origin, y = dep_delay)) +\n  geom_col(aes(fill = student),\n    position = \"dodge\",\n    alpha = .8) +\n  labs(caption = \"black bars show true delay\",\n       y = \"estimated delay\",\n       fill = \"students' estimates\")"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#and-the-winner-is",
    "href": "posts/samples-nyc2/index.html#and-the-winner-is",
    "title": "samples-nyc2",
    "section": "3.2 And the winner is ‚Ä¶",
    "text": "3.2 And the winner is ‚Ä¶\nChefin: ‚ÄúAnd the winner is ‚Ä¶‚Äù\n\nmodellgueten |&gt; \n  ggplot(aes(x = student, y = error_abs)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nmodellgueten_summ &lt;-\n  modellgueten |&gt; \n  group_by(student) |&gt; \n  summarise(error_abs = mean(error_abs)) |&gt; \n  arrange(error_abs)\n\nmodellgueten_summ\n\n\n\n\n\nstudent\nerror_abs\n\n\n\n\nestimate_C\n0.22\n\n\nestimate_A\n5.34\n\n\nestimate_B\n7.72\n\n\n\n\n\n\nChefin: ‚ÄúSieht so aus, als h√§tte B knapp gewonnen, vor C. A ist leider weit abgeschlagen.‚Äù\nA: ‚ÄúMensch, B, du bist hier der Datenhecht!‚Äù\nB: ‚ÄúIch glaub‚Äôs ja nicht, ich meine, ich hab‚Äôs immer gewusst!‚Äù\nC: ‚ÄúMoment, mein Vorgehen m√ºsste in der Theorie das Beste sein?!‚Äù"
  }
]