[
  {
    "objectID": "posts/xlsx-online-import/index.html",
    "href": "posts/xlsx-online-import/index.html",
    "title": "xls-online-import",
    "section": "",
    "text": "Importieren Sie eine XLSX-Datei aus dem Internet in R (als Dataframe).\nHier ist ein Pfad: https://github.com/sebastiansauer/Lehre/raw/refs/heads/main/25-SoSe/FAU-2025-09/penguins.xlsx.\n\ndata_url &lt;- \"https://github.com/sebastiansauer/Lehre/raw/refs/heads/main/25-SoSe/FAU-2025-09/penguins.xlsx\"\n\nHinweise:\n\nBeachten Sie die üblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/xlsx-online-import/index.html#weg-1",
    "href": "posts/xlsx-online-import/index.html#weg-1",
    "title": "xls-online-import",
    "section": "2.1 Weg 1",
    "text": "2.1 Weg 1\n\nlibrary(rio)\npenguins &lt;- import(data_url)"
  },
  {
    "objectID": "posts/xlsx-online-import/index.html#weg-2",
    "href": "posts/xlsx-online-import/index.html#weg-2",
    "title": "xls-online-import",
    "section": "2.2 Weg 2",
    "text": "2.2 Weg 2\n\ndest_file &lt;- \"penguins.xlsx\"\n\ndownload.file(url = data_url, destfile = dest_file, mode = \"wb\")\n\nlibrary(readxl)\n\nmy_data &lt;- read_excel(dest_file)"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "title": "tidymodels-lasso3",
    "section": "",
    "text": "Schreiben Sie eine prototypische Analyse für ein Vorhersagemodell mit dem Lasso.\nBerichten Sie, welche Prädiktoren nach dem Lasso im Modell verbleiben.\nHinweise:\n\nTunen Sie die Penalisierung.\nVerwenden Sie Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ ."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "title": "tidymodels-lasso3",
    "section": "Standardvorgehen",
    "text": "Standardvorgehen\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variablenbedeutung\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n16.641 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0e+00\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod01_post0\n\n\n0.0e+00\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod02_post0\n\n\n0.0e+00\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod03_post0\n\n\n3.0e-07\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod04_post0\n\n\n5.1e-06\nrmse\nstandard\n281.0325\n10\n12.02709\npre0_mod05_post0\n\n\n\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n325.8327320\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8188554\npre0_mod0_post0"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "title": "tidymodels-lasso3",
    "section": "Inspektion der Tuningparameter",
    "text": "Inspektion der Tuningparameter\n\nautoplot(wf1_fit)\n\n\n\n\n\n\n\n\nDie Standard-Wahl der Tuningparameter-Werte war offenbar nicht so ideal, zumindest sieht man kaum Unterschiede zwischen der Modellgüte in Abhängigkeit von den Werten der Tuningparameter."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "title": "tidymodels-lasso3",
    "section": "Variablenbedeutung",
    "text": "Variablenbedeutung\n\nlibrary(vip)\n\nvi_preds &lt;- \nwf1_fit_final %&gt;% \n  extract_fit_engine() %&gt;% \n  vi()\n\nvi_preds\n\n\n\n\n\nVariable\nImportance\nSign\n\n\n\n\nspecies_Gentoo\n763.05092\nPOS\n\n\nsex_male\n388.86671\nPOS\n\n\nspecies_Chinstrap\n284.44779\nNEG\n\n\nflipper_length_mm\n268.33432\nPOS\n\n\nbill_length_mm\n128.42872\nPOS\n\n\nbill_depth_mm\n70.61908\nPOS\n\n\nisland_Dream\n63.80234\nNEG\n\n\nyear\n30.65721\nNEG\n\n\nisland_Torgersen\n0.00000\nNEG\n\n\n\n\n\n\n\nvi_preds %&gt;% \n  ggplot(aes(x = Importance, y = reorder(Variable, Importance), fill = Sign)) +\n  geom_col()\n\n\n\n\n\n\n\n\nMan beachte: Für regulierte Modelle sind Zentrierung und Skalierung nötig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nstring\ntemplate"
  },
  {
    "objectID": "posts/anim01/anim01.html",
    "href": "posts/anim01/anim01.html",
    "title": "anim01",
    "section": "",
    "text": "Visualisieren Sie in animierter Form den Zusammenhang von Lebenserwartung und Bruttosozialprodukt im Verlauf der Jahre (Datensatz gapminder); der Kontinent soll in der Visualisierung berücksichtigt sein.\nHinweise:\n\nNutzen Sie gganimate zur Visualisierung."
  },
  {
    "objectID": "posts/anim01/anim01.html#setup",
    "href": "posts/anim01/anim01.html#setup",
    "title": "anim01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(gganimate)\ndata(gapminder)"
  },
  {
    "objectID": "posts/anim01/anim01.html#statisches-diagramm",
    "href": "posts/anim01/anim01.html#statisches-diagramm",
    "title": "anim01",
    "section": "Statisches Diagramm",
    "text": "Statisches Diagramm\n\np &lt;- gapminder %&gt;% \n  ggplot(aes(x = gdpPercap, y = lifeExp, color = continent, frame = year)) +\n  geom_point()+\n  scale_x_log10()\np"
  },
  {
    "objectID": "posts/anim01/anim01.html#animation",
    "href": "posts/anim01/anim01.html#animation",
    "title": "anim01",
    "section": "Animation",
    "text": "Animation\n\ngapminder$continent &lt;- as.factor(gapminder$continent)\n\np_animated &lt;- ggplot(gapminder,\n            aes(x = gdpPercap, \n                y = lifeExp, \n                color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_discrete() +   # &lt;- force discrete scale\n  labs(title = \"Year: {frame_time}\") +\n  transition_time(year)\n\np_animated\n\nDieser Post orientiert sich an dieser Quelle; dort finden sich auch mehr Beispiele.\n\nCategories:\n\n2023\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "href": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "title": "tidymodels-vorlage3",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse für ein Vorhersagemodell, das sich als Vorlage für Analysen dieser Art eignet!\nVerzichten Sie auf Resampling und Tuning.\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie keinen Parameter des Modells\nVerwenden Sie keine Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(easystats)   # NAs zählen\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"regression\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d_train) |&gt; \n  step_unknown(all_nominal_predictors(), new_level = \"NA\") |&gt; \n  step_naomit(all_predictors()) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_zv(all_predictors()) |&gt; \n  step_normalize(all_predictors()) \n\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  last_fit(split = d_split)\ntoc()\n\n0.496 sec elapsed\n\ncollect_metrics(wf1_fit)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n310.3661061\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8627167\npre0_mod0_post0\n\n\n\n\n\n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nyear\nbody_mass_g\nspecies_Chinstrap\nspecies_Gentoo\nisland_Dream\nisland_Torgersen\nsex_male\nsex_NA.\n\n\n\n\n-1.2404291\n-1.5309296\n0.3858343\n-0.7943918\n-1.2921757\n3450\n-0.5026644\n-0.7579203\n1.3366001\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n1.4505356\n1.3186250\n0.3858343\n-0.3653368\n1.1407119\n3675\n1.9816579\n-0.7579203\n1.3366001\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n-0.2115308\n0.4006477\n-1.9691393\n0.7073009\n-1.2921757\n4500\n-0.5026644\n1.3142661\n-0.7452558\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n-0.9930977\n0.3432741\n0.8868925\n-0.2938276\n-0.0757319\n4150\n-0.5026644\n-0.7579203\n-0.7452558\n2.4336824\n1.0336378\n-0.1543093\n\n\n0.5304631\n0.8787609\n-0.5661763\n2.0659752\n-0.0757319\n5800\n-0.5026644\n1.3142661\n-0.7452558\n-0.4093011\n1.0336378\n-0.1543093\n\n\n-0.2807836\n-0.9571938\n0.7866809\n-1.1519377\n1.1407119\n3650\n-0.5026644\n-0.7579203\n1.3366001\n-0.4093011\n1.0336378\n-0.1543093\n\n\n\n\n\n\n\ndescribe_distribution(d_train_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nrownames\n0.000\n1.0000\n1.696693\n-1.7153052\n1.678080\n-0.0140987\n-1.2072129\n257\n0\n\n\nbill_length_mm\n0.000\n1.0000\n1.682958\n-2.2767861\n2.982459\n0.0138271\n-0.7949178\n257\n0\n\n\nbill_depth_mm\n0.000\n1.0000\n1.603386\n-2.0192451\n2.189644\n-0.1101092\n-0.8689102\n257\n0\n\n\nflipper_length_mm\n0.000\n1.0000\n1.644711\n-1.9385386\n2.065975\n0.3185041\n-1.0170679\n257\n0\n\n\nyear\n0.000\n1.0000\n2.432888\n-1.2921757\n1.140712\n-0.1160338\n-1.5114889\n257\n0\n\n\nbody_mass_g\n4200.973\n792.5366\n1212.500000\n2700.0000000\n6300.000000\n0.4897600\n-0.6875459\n257\n0\n\n\nspecies_Chinstrap\n0.000\n1.0000\n0.000000\n-0.5026644\n1.981658\n1.4905934\n0.2235476\n257\n0\n\n\nspecies_Gentoo\n0.000\n1.0000\n2.072186\n-0.7579203\n1.314266\n0.5607093\n-1.6988872\n257\n0\n\n\nisland_Dream\n0.000\n1.0000\n2.081856\n-0.7452558\n1.336600\n0.5959823\n-1.6577672\n257\n0\n\n\nisland_Torgersen\n0.000\n1.0000\n0.000000\n-0.4093011\n2.433682\n2.0402588\n2.1795571\n257\n0\n\n\nsex_male\n0.000\n1.0000\n1.997330\n-0.9636924\n1.033638\n0.0704940\n-2.0107396\n257\n0\n\n\nsex_NA.\n0.000\n1.0000\n0.000000\n-0.1543093\n6.455274\n6.3503836\n38.6279271\n257\n0\n\n\n\n\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/mtcars-regr01/mtcars-regr01.html",
    "href": "posts/mtcars-regr01/mtcars-regr01.html",
    "title": "mtcars-regr01",
    "section": "",
    "text": "Aufgabe\n\ndata(\"mtcars\")\n\nBetrachten Sie folgendes Modell (Datensatz mtcars):\nmpg ~ disp\nAnders gesagt: Wie gut kann man den Spritverbrauch vorhersagen auf Basis des Hubraums eines Autos?\n\nBerechnen Sie die Modellkoeffizienten! Tipp: lm()\nBerechnen Sie im Anschluss die Vorhersagen dieses Modells. Tipp: predict() mit mutate()\nVisualisieren Sie dann das Modell Tipp: ggplot() und geom_smooth() oder mittels einer anderer Methode.\nBerechnen Sie die Residuen: e = echtem Y-Wert und vorhergesagtem Y-Wert. Tipp: mutate().\nBerechnen Sie die Korrelation zwischen Spritverbrauch und Hubraum! Tipp: summarise() mitcor()`.\n\n         \n\n\nLösung\n\n\nVorbereitung\n\nlibrary(tidyverse)\ndata(mtcars)\n\n\n\nAd 1\n\nlm1 &lt;- lm(mpg ~ disp, data = mtcars)\nlm1\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122  \n\n\n\n\nAd 2\nNicht einfach nur predicten:\n\npredict(lm1)\n\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive \n           23.00544            23.00544            25.14862            18.96635 \n  Hornet Sportabout             Valiant          Duster 360           Merc 240D \n           14.76241            20.32645            14.76241            23.55360 \n           Merc 230            Merc 280           Merc 280C          Merc 450SE \n           23.79677            22.69220            22.69220            18.23272 \n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental \n           18.23272            18.23272            10.14632            10.64090 \n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla \n           11.46520            26.35622            26.47987            26.66946 \n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 \n           24.64992            16.49345            17.07046            15.17456 \n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa \n           13.11381            26.34386            24.64168            25.68030 \n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E \n           15.13335            23.62366            17.19410            24.61283 \n\n\nSondern die Predictions als neue Spalte in mtcars anlegen. Viel sauberer!\n\nmtcars2  &lt;- \n  mtcars %&gt;% \n  mutate(preds_lm1 = predict(lm1))\n\n\n\nAd 3\n\nggplot(mtcars2) +\n  aes(y = mpg, x = disp) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAndere Visualisierung:\n\nmtcars2 %&gt;% \n  ggplot(aes(x = disp, y = preds_lm1)) +\n  geom_point(size = 2, alpha = .8, color = \"pink\") +\n  geom_line() +\n  labs(y = \"Vorhergesagte MPG-Werte\",\n       title = \"Vorhersage-Modell lm1\")\n\n\n\n\n\n\n\n\nOder so:\n\nlibrary(easystats)\nestimate_expectation(lm1, by = \"disp\") %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\nAd 4\n\nmtcars2 &lt;- \n  mtcars2 %&gt;% \n  mutate(e = abs(mpg - preds_lm1))  # abs steht für \"Absolutwert\"\n\nDer “Absolutwert” kickt das Vorzeichen weg. Das machen wir, wenn wir meinen, dass das Vorzeichen egal ist.\n\n\nBonus-Aufgabe\nBerechnen Sie den mittleren Fehler über alle e!\n\nmtcars2 %&gt;% \n  summarise(e_avg = mean(e))\n\n\n\n\n\ne_avg\n\n\n\n\n2.605473\n\n\n\n\n\n\n\n\nAd 5\n\nmtcars %&gt;% \n  summarise(cor_mpg_disp = cor(mpg, disp))\n\n\n\n\n\ncor_mpg_disp\n\n\n\n\n-0.8475514\n\n\n\n\n\n\n\nCategories:\n\nlm\nmtcars\ncorrelation\nregression\nstring"
  },
  {
    "objectID": "posts/germeval04/germeval04.html",
    "href": "posts/germeval04/germeval04.html",
    "title": "germeval04",
    "section": "",
    "text": "Erstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch über das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon."
  },
  {
    "objectID": "posts/germeval04/germeval04.html#finalisieren",
    "href": "posts/germeval04/germeval04.html#finalisieren",
    "title": "germeval04",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nfit1_best &lt;- select_best(wf1_fit)\n\n\nwf1_final &lt;- finalize_workflow(wf1, fit1_best)\nwf1_final_fit &lt;- fit(wf1_final, data = d_train)\n\nVorhersagen:\n\npreds &lt;- predict(wf1_final_fit, germeval_test)"
  },
  {
    "objectID": "posts/germeval04/germeval04.html#test-set-güte",
    "href": "posts/germeval04/germeval04.html#test-set-güte",
    "title": "germeval04",
    "section": "Test-Set-Güte",
    "text": "Test-Set-Güte\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\naccuracy\nbinary\n0.6395810\n\n\nf_meas\nbinary\n0.2645869"
  },
  {
    "objectID": "posts/germeval04/germeval04.html#fazit",
    "href": "posts/germeval04/germeval04.html#fazit",
    "title": "germeval04",
    "section": "Fazit",
    "text": "Fazit\nEine Reihe der Text-Features passen nicht gut auf nicht-englische Texte.\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nsentiment\nstring"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html",
    "title": "ppv-mtcars1",
    "section": "",
    "text": "Berechnen Sie folgendes Modell (Datensatz mtcars):\nmpg ~ hp\nGeben Sie die Breite eines 50%-ETI an für eine Beobachtung mit einem z-Wert von 0 im Prädiktor!\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#setup",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#setup",
    "title": "ppv-mtcars1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  mutate(hp = standardize(hp))"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#modell",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#modell",
    "title": "ppv-mtcars1",
    "section": "Modell",
    "text": "Modell\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, seed = 42, refresh = 0)\n\nModellparameter:\n\ncoef(m1)\n\n(Intercept)          hp \n30.11668130 -0.06820988 \n\n\nModellgüte:\n\nr2(m1)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])\n\n\nOder mit z-standardisierten Werten:\n\nm2 &lt;- stan_glm(mpg ~ hp, data = mtcars2, seed = 42, refresh = 0)\ncoef(m2)\n\n(Intercept)          hp \n  20.096771   -4.676665 \n\nr2(m2)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#ppv",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#ppv",
    "title": "ppv-mtcars1",
    "section": "PPV",
    "text": "PPV\n\nm2_ppv &lt;- estimate_prediction(m2, data = tibble(hp = 0), ci = 0.5)\nm2_ppv\n\n\n\n\n\nhp\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n0\n20.08646\n4.077161\n17.47148\n22.67675\n\n\n\n\n\n\nVisualisierung:\n\nplot(estimate_prediction(m2, by = \"hp\"))\n\n\n\n\n\n\n\n\nMan beachte, dass die PPV mit mehr Ungewissheit behaftet ist, als die Post-Verteilung.\n\nplot(estimate_relation(m2))\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nppv\nregression\nnum"
  },
  {
    "objectID": "posts/chatgpt-sentiment-simple/chatgpt-sentiment-simple.html",
    "href": "posts/chatgpt-sentiment-simple/chatgpt-sentiment-simple.html",
    "title": "chatgpt-sentiment-simple",
    "section": "",
    "text": "Aufgabe\nFragen Sie ChatGPT via API zum Sentiment des ersten Texts aus dem Germeval-2018-Datensatz (Train).\n\n\n\n\n\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. 💸 Informieren Sie sich vorab. Um auf die API zugreifen zu können, müssen Sie sich ein Konto angelegt haben und über ein Guthaben verfügen.\n\n         \n\n\nLösung\n\nOpenAI hat eine neue API (Stand: 2023-11-23). Der Code der alten API bricht. 💔 \\(\\square\\)\n\nModule importieren:\n\nfrom openai import OpenAI\n\nModuleNotFoundError: No module named 'openai'\n\n\nAnmelden bei OpenAI:\n\nclient = OpenAI()\n\nNameError: name 'OpenAI' is not defined\n\n\n\n\n\n\n\n\nNote\n\n\n\nDieses Verfahren setzt voraus, dass in .Renviron die Variable OPENAI_API_KEY hinterlegt ist. \\(\\square\\)\n\n\nTextschnipsel, das zu klassifizieren ist:\n\ntext = \"@corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\"\n\nPrompt definieren:\n\nmy_prompt  = f\"Analysieren Sie das Sentiment des folgenden Texts:\\n{text}\"\n\nAnfrage an die API, in eine Funktion gepackt:\n\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n  model=model,\n  messages=messages,\n  max_tokens=50,\n  temperature=0,\n  )\n  return response.choices[0].message.content\n\nUnd los:\n\nget_completion(my_prompt, client) \n\nNameError: name 'client' is not defined"
  },
  {
    "objectID": "posts/samples-nyc2/index.html",
    "href": "posts/samples-nyc2/index.html",
    "title": "samples-nyc2",
    "section": "",
    "text": "Drei Studierende arbeiten für die New Yorker Flughafenbehörde als Werkstudenten. Fragt ihre Chefin eines Tages: “Welcher der drei New Yorker Flughäfen hat im Schnitt die höchste Verspätung? Zieht mal eine kleine Stichprobe und gebt mir eine gute Antwort.”\nStudi A überlegt: “Hm, ich schaue mir mal die ersten 1000 Flüge des Jahres und diesen Mittelwert nehme ich als Schätzwert für die Verspätung des ganzen Jahres.”\nStudi B argumentiert so: “Hm, ich nehme die ersten 100 Flüge von jedem Monat, rechne davon den Mittelwert aus. Das ist dann mein Schätzwert für die Verspätung des ganzen Jahres, pro Flughafen.”\nStudi C hingegen ist folgender Meinung: “Ich ziehe mal eine Zufallsstichprobe, habe ich in der Statistik-Vorlesung gelernt. N=100 sollte genügen.”\nDie Chefin bezieht sich übrigens auf das Jahr 2023.\nAufgabe: Welcher der drei Studis macht die beste Vorhersage? Rechnen Sie nach und begründen Sie Ihre Meinung!"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#setup",
    "href": "posts/samples-nyc2/index.html#setup",
    "title": "samples-nyc2",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(nycflights23)  # Dataset \"flights\"\ndata(\"flights\")\nlibrary(tidyverse)\n\nWie viele Flüge gab es?\n\nnrow(flights)\n\n[1] 435352\n\n\nViele!\nWelche Variablen gibt es im Datensatz?\n\nglimpse(flights)\n\nRows: 435,352\nColumns: 19\n$ year           &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 1, 18, 31, 33, 36, 503, 520, 524, 537, 547, 549, 551, 5…\n$ sched_dep_time &lt;int&gt; 2038, 2300, 2344, 2140, 2048, 500, 510, 530, 520, 545, …\n$ dep_delay      &lt;dbl&gt; 203, 78, 47, 173, 228, 3, 10, -6, 17, 2, -10, -9, -7, -…\n$ arr_time       &lt;int&gt; 328, 228, 500, 238, 223, 808, 948, 645, 926, 845, 905, …\n$ sched_arr_time &lt;int&gt; 3, 135, 426, 2352, 2252, 815, 949, 710, 818, 852, 901, …\n$ arr_delay      &lt;dbl&gt; 205, 53, 34, 166, 211, -7, -1, -25, 68, -7, 4, -13, -14…\n$ carrier        &lt;chr&gt; \"UA\", \"DL\", \"B6\", \"B6\", \"UA\", \"AA\", \"B6\", \"AA\", \"UA\", \"…\n$ flight         &lt;int&gt; 628, 393, 371, 1053, 219, 499, 996, 981, 206, 225, 800,…\n$ tailnum        &lt;chr&gt; \"N25201\", \"N830DN\", \"N807JB\", \"N265JB\", \"N17730\", \"N925…\n$ origin         &lt;chr&gt; \"EWR\", \"JFK\", \"JFK\", \"JFK\", \"EWR\", \"EWR\", \"JFK\", \"EWR\",…\n$ dest           &lt;chr&gt; \"SMF\", \"ATL\", \"BQN\", \"CHS\", \"DTW\", \"MIA\", \"BQN\", \"ORD\",…\n$ air_time       &lt;dbl&gt; 367, 108, 190, 108, 80, 154, 192, 119, 258, 157, 164, 1…\n$ distance       &lt;dbl&gt; 2500, 760, 1576, 636, 488, 1085, 1576, 719, 1400, 1065,…\n$ hour           &lt;dbl&gt; 20, 23, 23, 21, 20, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6,…\n$ minute         &lt;dbl&gt; 38, 0, 44, 40, 48, 0, 10, 30, 20, 45, 59, 0, 59, 0, 0, …\n$ time_hour      &lt;dttm&gt; 2023-01-01 20:00:00, 2023-01-01 23:00:00, 2023-01-01 2…\n\n\nNehmen wir dep_delay als Zielvariable. Die Chefin hat nicht genau gesagt, welche Variable sie meint. Da sieht man es mal wieder: Man muss Annahmen treffen. Ist aber auch schön, denn man kann selber entscheiden, was einem besser gefällt."
  },
  {
    "objectID": "posts/samples-nyc2/index.html#los-gehts",
    "href": "posts/samples-nyc2/index.html#los-gehts",
    "title": "samples-nyc2",
    "section": "2.2 Los geht’s",
    "text": "2.2 Los geht’s\n\n2.2.1 Studentin A\n\nestimate_A &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  slice(1:1000) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_A\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n26.1\n\n\nJFK\n19.9\n\n\nLGA\n9.4\n\n\n\n\n\n\n“Klares (?) Ergebnis! EWR, also Newark, hat die größte Verspätung!”\n\n\n2.2.2 Student B\n\nestimate_B &lt;-\nflights |&gt; \n  select(dep_delay, origin, month) |&gt; \n  drop_na() |&gt; \n  group_by(month, origin) |&gt; \n  slice(1:100) |&gt; \n  summarise(dep_delay = mean(dep_delay)) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_B\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n8.47\n\n\nJFK\n9.74\n\n\nLGA\n0.76\n\n\n\n\n\n\n“Knapp! EWR hat fast so viel Verspätung wie JFK.”\n\n\n2.2.3 Studentin C\n\nset.seed(73)\n\nestimate_C &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_C\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n2.0\n\n\nJFK\n14.3\n\n\nLGA\n8.8\n\n\n\n\n\n\n“Glasklares (?) Ergebnis! JFK, also John-F-Kennedy, hat die größte Verspätung! Newark ist hingegen superpünktlich!”"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#moment",
    "href": "posts/samples-nyc2/index.html#moment",
    "title": "samples-nyc2",
    "section": "2.3 Moment",
    "text": "2.3 Moment\nLeider entbrennt hier ein Streit. Vermutlich einige Eifersuchtsmomente hinter den Kulissen, aber wir wissen nichts Genaues.\nStudentin A: “So ein Quatsch, C, du hast die Zufallszahl auf 73 festgelegt, warum gerade diese Zahl?! Bei einer anderen Zahl könnte ein ganz andere Stichprobe und damit ein ganz anderes Ergebnis herauskommen!”\nStudentin C: “Ich habe kürzlich gelernt, dass nicht 42, sondern 73 die beste Zahl ist. Also musste ich 73 nehmen!\nStudent B: “Aber was käme heraus, wenn du 42 als Zufallszahl nehmen würdest, nur mal theoretisch?”\nStudentin C: “Äh…”\n\nset.seed(42)\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n28.3\n\n\nJFK\n7.5\n\n\nLGA\n9.9\n\n\n\n\n\n\nStudentin C: “Äh, also… Das spielt doch gar keine Rolle, was rauskommt, denn bei jeder Zahl kann ja was anderes rauskommen.”\nA: “Du müsstest also dein Vorgehen ändern… Jede Zahl ausprobieren oder so.”\nC: “Liebe A, du mit deinen Flügen vom Jahresbeginn, das ist doch totaler Quatsch, an deiner Stelle wäre ich lieber still.”\nA: “Aber es kommt was Gutes raus mit meiner Methode!”\nB: “Woher willst du überhaupt wissen, ob es was Gutes ist?”\nA: “Wirst schon sehen!”\nC: “Puh, also gut, ich rechne noch mal. Ich zieh einfach ne Menge Stichproben, mit zufälligen Seed-Nummern …”\nA: “Whatever!”\nC: “Moment.., hier kommt Newark, EWR.”\n\nn_reps &lt;- 100  # Anzahl von Stichproben\nsample_size &lt;- 100  # Umfang jeder Stichprobe\n\newr_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"EWR\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\newr_viele_schaetzwerte\n\n[1] 15\n\n\nB: “Wow, C, du bist halt schon die Statistik-Checkerin…”.\nA: “Hey B, hör gefälligst auf, dich bei A einzuschmeicheln!”\nB: “Jedenfalls ist das Ergebnis von A … anders als unsere!”\nC: “Hier noch mal mein Prinzip für die anderen Flughäfen. JFK:”\n\njfk_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"JFK\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\njfk_viele_schaetzwerte\n\n[1] 16\n\n\nC: “Und LaGuardia:”\n\nlga_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"LGA\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\nlga_viele_schaetzwerte\n\n[1] 11\n\n\nC: “Also, unterm Strich, LGA rules! LGA hat die geringste Verspätung im Schnitt, nach meiner Rechnung.”\n\nlga_viele_schaetzwerte\n\n[1] 11\n\newr_viele_schaetzwerte\n\n[1] 15\n\njfk_viele_schaetzwerte\n\n[1] 16"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#fazit",
    "href": "posts/samples-nyc2/index.html#fazit",
    "title": "samples-nyc2",
    "section": "2.4 Fazit?",
    "text": "2.4 Fazit?\nA: “Okay, meine Methode war ein bisschen zu einfach. Aber hat auch am wenigsten Arbeit gemacht. Das nennt man wirtschaftlich vorgehen, nur darum geht’s im Business. Also hab ich trotzdem gewonnen!”\nB: “Nope, mein Vorgehen ist in Wirklichkeit das Beste. Ich hab von jedem Monat 100 Flüge genommen, so hat sich alles super ausgeglichen, Jahreszeiten und so, glaub ich. Und es wäre nicht so viel Aufwand wie die zich Tausend Stichproben, die C gezogen hat.”\nC: “Kann ja alles sein, aber mein Vorgehen hat am meisten Spaß gemacht. Übrigens B, wir könnten uns, also unsere beiden Ideen, doch zusammenlegn, kombinieren. Das müsste ein super Ergebnis geben. Wollen wir zwei uns das mal zusammen anschauen, nur wir zwei?”"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#wahre-verspätung",
    "href": "posts/samples-nyc2/index.html#wahre-verspätung",
    "title": "samples-nyc2",
    "section": "3.1 Wahre Verspätung",
    "text": "3.1 Wahre Verspätung\nDie Chefin berechnet die wahre Verspätung über alle Flüge 2023 (in YNC) insgesamt (also in der Population der NYC-Flüge von 2023):\n\nwahre_verspaetung &lt;- \n  flights |&gt; \n  select(origin, dep_delay) |&gt; \n  drop_na() |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nwahre_verspaetung\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n15\n\n\nJFK\n16\n\n\nLGA\n11\n\n\n\n\n\n\nChefin: “LaGuardia hat am wenigsten Verspätung. JFK am meisten, aber dicht gefolgt von EWR.”\nChefin: “Jetzt schauen wir mal, wer pro Flughafen am genauesten geschätzt hat.”\n\nmodellgueten &lt;-\n  wahre_verspaetung |&gt; \n  mutate(estimate_A = estimate_A$dep_delay,\n         estimate_B = estimate_B$dep_delay,\n         estimate_C = c(\n           ewr_viele_schaetzwerte,\n           jfk_viele_schaetzwerte,\n           lga_viele_schaetzwerte)\n  ) |&gt; \n  pivot_longer(contains(\"estimate\"), \n               names_to = \"student\", \n               values_to = \"estimate\") |&gt; \n  mutate(error_abs = abs(dep_delay - estimate)) \n\nChefin: “LaGuardia wurde ingesamt am genauesten geschätzt, von allen drei Studenten. Aber Studentin A überschätzt die Verspätung massiv bei Newark und bei JFK.”\nChefin: “Hier sind die Details.”\n\nmodellgueten |&gt; \n  ggplot(aes(y = estimate, x = origin)) +\n # geom_line() +\n  geom_col(data = wahre_verspaetung,\n    aes(x = origin, y = dep_delay)) +\n  geom_col(aes(fill = student),\n    position = \"dodge\",\n    alpha = .8) +\n  labs(caption = \"black bars show true delay\",\n       y = \"estimated delay\",\n       fill = \"students' estimates\")"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#and-the-winner-is",
    "href": "posts/samples-nyc2/index.html#and-the-winner-is",
    "title": "samples-nyc2",
    "section": "3.2 And the winner is …",
    "text": "3.2 And the winner is …\nChefin: “And the winner is …”\n\nmodellgueten |&gt; \n  ggplot(aes(x = student, y = error_abs)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nmodellgueten_summ &lt;-\n  modellgueten |&gt; \n  group_by(student) |&gt; \n  summarise(error_abs = mean(error_abs)) |&gt; \n  arrange(error_abs)\n\nmodellgueten_summ\n\n\n\n\n\nstudent\nerror_abs\n\n\n\n\nestimate_C\n0.22\n\n\nestimate_A\n5.34\n\n\nestimate_B\n7.72\n\n\n\n\n\n\nChefin: “Sieht so aus, als hätte B knapp gewonnen, vor C. A ist leider weit abgeschlagen.”\nA: “Mensch, B, du bist hier der Datenhecht!”\nB: “Ich glaub’s ja nicht, ich meine, ich hab’s immer gewusst!”\nC: “Moment, mein Vorgehen müsste in der Theorie das Beste sein?!”"
  }
]