[
  {
    "objectID": "Hinweise.html",
    "href": "Hinweise.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "Hinweise.html#nicht-ins-boxhorn-jagen-lassen",
    "href": "Hinweise.html#nicht-ins-boxhorn-jagen-lassen",
    "title": "",
    "section": "Nicht ins Boxhorn jagen lassen",
    "text": "Nicht ins Boxhorn jagen lassen\n\n\n\n\n\n\nNote\n\n\n\nDie Webseite Datenwerk stellt eine Reihe von Aufgaben zum Thema Statistik bereit. Zu jeder Aufgabe sind ein oder mehrere Schlagw√∂rter (Tags) zugeordnet. Wenn Sie auf ein Schlagwort klicken, sehen Sie die Liste der Aufgaben mit diesem Schlagwort. Es kann aber sein, dass Sie einige Aufgabe nicht l√∂sen k√∂nnen, da Wissen vorausgesetzt wird, das Sie (noch) nicht haben. Lassen Sie sich davon nicht ins Boxhorn jagen. Ignorieren Sie solche Aufgaben f√ºrs Erste. \\(\\square\\)"
  },
  {
    "objectID": "Hinweise.html#bearbeitungshinweise",
    "href": "Hinweise.html#bearbeitungshinweise",
    "title": "",
    "section": "Bearbeitungshinweise",
    "text": "Bearbeitungshinweise\nBeachten Sie Hinweise aus dem Hinweisbuch, insbesondere:\n\nallgemeine Pr√ºfungshinweise\nf√ºr quantitative Pr√ºfungen"
  },
  {
    "objectID": "Hinweise.html#datenschutz",
    "href": "Hinweise.html#datenschutz",
    "title": "",
    "section": "Datenschutz",
    "text": "Datenschutz\nHier finden Sie die Datenschutzinformationen f√ºr diese Webseite."
  },
  {
    "objectID": "Hinweise.html#impressum",
    "href": "Hinweise.html#impressum",
    "title": "",
    "section": "Impressum",
    "text": "Impressum\nHier finden Sie das Impressum dieser Webseite."
  },
  {
    "objectID": "data-privacy.html",
    "href": "data-privacy.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "data-privacy.html#einleitung",
    "href": "data-privacy.html#einleitung",
    "title": "",
    "section": "Einleitung",
    "text": "Einleitung\nDiese Datenschutzhinweise informieren Sie √ºber die Art, den Umfang und den Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend ‚ÄúDaten‚Äù) im Rahmen der Nutzung dieser Webseite (nachfolgend ‚ÄúWebseite‚Äù), die auf GitHub gehostet wird.\n\nVerantwortliche Person\nProf.¬†Dr.¬†habil. Sebastian Sauer, Residenzstr. 10, 90522 Ansbach, sebastian.sauer@hs-ansbach.de\n\n\nHosting durch GitHub\nUnsere Webseite wird von GitHub Inc., 88 Colin P. Kelly Jr.¬†St, San Francisco, CA 94107, USA (‚ÄúGitHub‚Äù) gehostet. GitHub verarbeitet in unserem Auftrag Daten von Webseitenbesuchern (z.B. IP-Adressen). Dies ist f√ºr den Betrieb der Webseite und die Bereitstellung von Inhalten erforderlich. GitHub ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europ√§ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC&status=Active).\nWeitere Informationen zum Datenschutz bei GitHub finden Sie in der Datenschutzerkl√§rung von GitHub: https://docs.github.com/de/site-policy/privacy-policies/github-general-privacy-statement"
  },
  {
    "objectID": "data-privacy.html#datenerhebung-und--verarbeitung",
    "href": "data-privacy.html#datenerhebung-und--verarbeitung",
    "title": "",
    "section": "Datenerhebung und -verarbeitung",
    "text": "Datenerhebung und -verarbeitung\n\nServer-Log-Dateien\nBei jedem Zugriff auf unsere Webseite erfasst GitHub automatisiert Daten und speichert diese in Server-Log-Dateien. Zu diesen Daten geh√∂ren: IP-Adresse des zugreifenden Ger√§ts Datum und Uhrzeit des Zugriffs Name und URL der abgerufenen Datei Webseite, von der aus der Zugriff erfolgt (Referrer-URL) Verwendeter Browser und ggf. das Betriebssystem des zugreifenden Ger√§ts Name des Access-Providers\nDie Verarbeitung dieser Daten erfolgt, um die Funktionsf√§higkeit der Webseite sicherzustellen, die Nutzung der Webseite zu analysieren und unser Angebot zu verbessern. Rechtsgrundlage f√ºr die Datenverarbeitung ist Art. 6 Abs. 1 lit. f DSGVO (berechtigtes Interesse). Unser berechtigtes Interesse liegt in den oben genannten Zwecken.\n\n\nCookies\nUnsere Webseite verwendet keine Cookies.\n\n\nEinbindung von Drittinhalten\nEs k√∂nnen Inhalte von Drittanbietern wie Videos, Schriftarten oder Karten eingebunden sein. Beim Abruf dieser Inhalte wird Ihre IP-Adresse m√∂glicherweise an den Drittanbieter √ºbertragen. F√ºr weitere Informationen konsultiere bitte die Datenschutzrichtlinien der jeweiligen Anbieter."
  },
  {
    "objectID": "data-privacy.html#ihre-rechte",
    "href": "data-privacy.html#ihre-rechte",
    "title": "",
    "section": "Ihre Rechte",
    "text": "Ihre Rechte\nSie habengegen√ºber uns folgende Rechte hinsichtlich der dich betreffenden personenbezogenen Daten: Recht auf Auskunft (Art. 15 DSGVO) Recht auf Berichtigung (Art. 16 DSGVO) Recht auf L√∂schung (Art. 17 DSGVO) Recht auf Einschr√§nkung der Verarbeitung (Art. 18 DSGVO) Recht auf Daten√ºbertragbarkeit (Art. 20 DSGVO) Recht auf Widerspruch gegen die Verarbeitung (Art. 21 DSGVO)\nSie haben zudem das Recht, sich bei einer Datenschutz-Aufsichtsbeh√∂rde √ºber die Verarbeitung deiner personenbezogenen Daten durch uns zu beschweren."
  },
  {
    "objectID": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "href": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "title": "",
    "section": "Anwendbare Rechtsgrundlagen",
    "text": "Anwendbare Rechtsgrundlagen\nNachstehend geben wir Ihnen eine √úbersicht der rechtlichen Grundlagen der DSGVO, auf deren Basis personenbezogene Daten auf dieser Webseite verarbeitet werden. Bitte beachten Sie, dass neben den Regelungen der DSGVO auch nationale Datenschutzvorgaben in Ihrem oder unserem Land relevant sein k√∂nnen. Sofern in Einzelf√§llen spezifische Rechtsgrundlagen gelten, werden diese in der Datenschutzerkl√§rung gesondert erw√§hnt.\n\nVertragserf√ºllung und vorvertragliche Ma√ünahmen (Art. 6 Abs. 1 S. 1 lit. b) DSGVO)\nDie Verarbeitung personenbezogener Daten ist erforderlich zur Erf√ºllung eines Vertrags, bei dem die betroffene Person Vertragspartei ist, oder zur Durchf√ºhrung vorvertraglicher Ma√ünahmen, die auf Anfrage der betroffenen Person erfolgen.\n\n\nBerechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO)\nDie Datenverarbeitung erfolgt zur Wahrung berechtigter Interessen des Verantwortlichen oder eines Dritten, sofern keine entgegenstehenden Interessen, Grundrechte oder Grundfreiheiten der betroffenen Person, die den Schutz ihrer personenbezogenen Daten erfordern, √ºberwiegen.\n\n\nNationale Datenschutzbestimmungen in Deutschland\nNeben der DSGVO gelten in Deutschland nationale Datenschutzvorgaben, insbesondere das Bundesdatenschutzgesetz (BDSG). Das BDSG beinhaltet spezielle Regelungen zum Recht auf Auskunft, L√∂schung, Widerspruch, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung f√ºr andere Zwecke sowie zur Daten√ºbermittlung und zu automatisierten Einzelentscheidungen einschlie√ülich Profiling. In bestimmten F√§llen k√∂nnen auch Datenschutzgesetze der Bundesl√§nder Anwendung finden.\n\n\nHinweis auf die Geltung von DSGVO und Schweizer DSG\nDiese Datenschutzhinweise ber√ºcksichtigen die Vorgaben sowohl der DSGVO als auch des Schweizer Datenschutzgesetzes (DSG). Zur besseren Verst√§ndlichkeit und zur Vermeidung wiederholter Begriffsdefinitionen werden die Begriffe der DSGVO verwendet. Begriffe wie ‚ÄûVerarbeitung‚Äú, ‚Äûpersonenbezogene Daten‚Äú, ‚Äûberechtigtes Interesse‚Äú und ‚Äûbesondere Kategorien von Daten‚Äú entsprechen inhaltlich den Begriffen ‚ÄûBearbeitung‚Äú, ‚ÄûPersonendaten‚Äú, ‚Äû√ºberwiegendes Interesse‚Äú und ‚Äûbesonders sch√ºtzenswerte Personendaten‚Äú des Schweizer DSG. Die genaue Auslegung und Anwendung erfolgt jedoch gem√§√ü den Vorgaben des Schweizer DSG."
  },
  {
    "objectID": "data-privacy.html#sicherheitsma√ünahmen",
    "href": "data-privacy.html#sicherheitsma√ünahmen",
    "title": "",
    "section": "Sicherheitsma√ünahmen",
    "text": "Sicherheitsma√ünahmen\nWir setzen angemessene technische und organisatorische Ma√ünahmen zum Schutz Ihrer Daten entsprechend den gesetzlichen Anforderungen um. Dabei ber√ºcksichtigen wir den aktuellen Stand der Technik, die Implementierungskosten, Art, Umfang, Umst√§nde und Zweck der Verarbeitung sowie die Wahrscheinlichkeit und Schwere m√∂glicher Risiken f√ºr die Rechte und Freiheiten betroffener Personen.\nZu den Schutzma√ünahmen geh√∂ren insbesondere: Sicherstellung der Vertraulichkeit, Integrit√§t und Verf√ºgbarkeit von Daten durch Kontrolle des Zugriffs auf die Daten und die Infrastruktur, der Eingaben, Weitergaben und Trennungen von Daten. Zudem haben wir Verfahren eingerichtet, um die Rechte betroffener Personen zu gew√§hrleisten, Daten zu l√∂schen und angemessen auf Bedrohungen zu reagieren. Bereits in der Entwicklung und Auswahl von Hard- und Software sowie Verfahren ber√ºcksichtigen wir Datenschutzprinzipien wie Datenschutz durch Technikgestaltung und datenschutzfreundliche Voreinstellungen.\nSicherung von Online-Verbindungen mit TLS-/SSL-Verschl√ºsselung (HTTPS) Um die Daten√ºbertragung √ºber unsere Online-Dienste vor unbefugtem Zugriff zu sch√ºtzen, nutzen wir die TLS-/SSL-Verschl√ºsselungstechnologie. Dies gew√§hrleistet eine sichere Daten√ºbertragung zwischen unserem Server und Ihrem Browser, erkennbar an der HTTPS-Kennung in der URL-Leiste.\n\nInternationale Daten√ºbertragungen\nFalls Datenverarbeitungen in Drittl√§ndern (au√üerhalb der EU und des EWR) stattfinden oder personenbezogene Daten an Dritte im Ausland √ºbermittelt werden, erfolgt dies ausschlie√ülich unter Einhaltung gesetzlicher Anforderungen. Sofern ein Angemessenheitsbeschluss der EU-Kommission f√ºr das betreffende Drittland vorliegt (Art. 45 DSGVO), gilt dieser als Grundlage der √úbertragung. Falls kein Angemessenheitsbeschluss vorliegt, sichern Standardvertragsklauseln (Art. 46 Abs. 2 lit. c) DSGVO), eine ausdr√ºckliche Einwilligung oder gesetzliche Erfordernisse die √úbertragung ab (Art. 49 Abs. 1 DSGVO).\nWeitere Informationen zu den Angemessenheitsbeschl√ºssen der EU-Kommission finden Sie auf dieser Seite. Die USA bieten mit dem sogenannten ‚ÄûData Privacy Framework‚Äú (DPF) eine Regelung zur Sicherstellung eines angemessenen Datenschutzniveaus, das durch die EU-Kommission am 10.07.2023 anerkannt wurde. Die Liste der zertifizierten Unternehmen und weitere Informationen finden Sie auf der Webseite des US-Handelsministeriums unter Data Privacy Framework.\nWir informieren Sie in unseren Datenschutzhinweisen, welche Drittanbieter unter diesem Rahmen zertifiziert sind."
  },
  {
    "objectID": "data-privacy.html#kontakt",
    "href": "data-privacy.html#kontakt",
    "title": "",
    "section": "Kontakt",
    "text": "Kontakt\nF√ºr Anfragen zum Datenschutz k√∂nnen Sie sich an uns wenden:\nProf.¬†Dr.¬†habil. Sebastian Sauer\nResidenzstr. 10, 90522 Ansbach\nsebastian.sauer@hs-ansbach.de"
  },
  {
    "objectID": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "href": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "title": "",
    "section": "√Ñnderung der Datenschutzhinweise",
    "text": "√Ñnderung der Datenschutzhinweise\nWir behalten uns vor, diese Datenschutzhinweise jederzeit anzupassen, um sie an ge√§nderte Rechtslagen oder bei √Ñnderungen des Dienstes sowie der Datenverarbeitung anzupassen.\nStand: 15. November 2024"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ans Werk, Daten!",
    "section": "",
    "text": "Datenwerk ist eine Sammlung von Aufgaben mit Bezug zur Datenanalyse.\nAutor: Sebastian Sauer (soweit nicht anders ausgewiesen)\nDer Quellcode dieser Webseite findet sich hier.\nDie Lizenz ist permissiv, s. Hinweise hier."
  },
  {
    "objectID": "imprint.html",
    "href": "imprint.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "imprint.html#vertreten-durch",
    "href": "imprint.html#vertreten-durch",
    "title": "",
    "section": "Vertreten durch:",
    "text": "Vertreten durch:\nSebastian Sauer"
  },
  {
    "objectID": "imprint.html#kontakt",
    "href": "imprint.html#kontakt",
    "title": "",
    "section": "Kontakt:",
    "text": "Kontakt:\nTelefon: 0981 4877 0, E-Mail: sebastian.sauer@hs-ansbach.de"
  },
  {
    "objectID": "imprint.html#aufsichtsbeh√∂rde",
    "href": "imprint.html#aufsichtsbeh√∂rde",
    "title": "",
    "section": "Aufsichtsbeh√∂rde:",
    "text": "Aufsichtsbeh√∂rde:\nN√ºrnberg"
  },
  {
    "objectID": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "href": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "title": "",
    "section": "Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:",
    "text": "Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach"
  },
  {
    "objectID": "imprint.html#haftungsausschluss",
    "href": "imprint.html#haftungsausschluss",
    "title": "",
    "section": "Haftungsausschluss:",
    "text": "Haftungsausschluss:\n\nHaftung f√ºr Inhalte\nDie Inhalte unserer Seiten wurden mit gr√∂√üter Sorgfalt erstellt. F√ºr die Richtigkeit, Vollst√§ndigkeit und Aktualit√§t der Inhalte k√∂nnen wir jedoch keine Gew√§hr √ºbernehmen. Als Diensteanbieter sind wir gem√§√ü ¬ß 7 Abs.1 DDG f√ºr eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach ¬ß¬ß 8 bis 10 DDG sind wir als Diensteanbieter jedoch nicht verpflichtet, √ºbermittelte oder gespeicherte fremde Informationen zu √ºberwachen oder nach Umst√§nden zu forschen, die auf eine rechtswidrige T√§tigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unber√ºhrt. Eine diesbez√ºgliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung m√∂glich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\n\n\nHaftung f√ºr Links\nUnser Angebot enth√§lt Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb k√∂nnen wir f√ºr diese fremden Inhalte auch keine Gew√§hr √ºbernehmen. F√ºr die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf m√∂gliche Rechtsverst√∂√üe √ºberpr√ºft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n\n\nUrheberrecht\nDie durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielf√§ltigung, Bearbeitung, Verbreitung und jede Art der Verwertung au√üerhalb der Grenzen des Urheberrechtes bed√ºrfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur f√ºr den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n\n\nDatenschutz\nDie Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten m√∂glich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit m√∂glich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdr√ºckliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Daten√ºbertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitsl√ºcken aufweisen kann. Ein l√ºckenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht m√∂glich. Der Nutzung von im Rahmen der Impressumspflicht ver√∂ffentlichten Kontaktdaten durch Dritte zur √úbersendung von nicht ausdr√ºcklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdr√ºcklich widersprochen. Die Betreiber der Seiten behalten sich ausdr√ºcklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, Fachanw√§lte f√ºr Familienrecht"
  },
  {
    "objectID": "posts/filter-na4/filter-na4.html",
    "href": "posts/filter-na4/filter-na4.html",
    "title": "filter-na4",
    "section": "",
    "text": "Liefern Sie einen visuellen √úberblick √ºber fehlende Werte im Datensatz penguins!"
  },
  {
    "objectID": "posts/filter-na4/filter-na4.html#setup",
    "href": "posts/filter-na4/filter-na4.html#setup",
    "title": "filter-na4",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\nnrow(d)\n\n[1] 344"
  },
  {
    "objectID": "posts/filter-na4/filter-na4.html#weg-1",
    "href": "posts/filter-na4/filter-na4.html#weg-1",
    "title": "filter-na4",
    "section": "Weg 1",
    "text": "Weg 1\n\nlibrary(visdat)\nvis_dat(d)"
  },
  {
    "objectID": "posts/filter-na4/filter-na4.html#weg-2",
    "href": "posts/filter-na4/filter-na4.html#weg-2",
    "title": "filter-na4",
    "section": "Weg 2",
    "text": "Weg 2\n\nd_na_only &lt;- \n  d %&gt;% \n  rowwise() %&gt;% \n  mutate(na_n = sum(is.na(cur_data()))) %&gt;% \n  ungroup()\n\nd_na_only %&gt;% \n  ggplot(aes(x = na_n)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nCategories:\n\n2023\neda\nna\nstring"
  },
  {
    "objectID": "posts/Stichprobenziehen1/Stichprobenziehen1.html",
    "href": "posts/Stichprobenziehen1/Stichprobenziehen1.html",
    "title": "Stichprobenziehen1",
    "section": "",
    "text": "Exercise\nIn dieser √úbung untersuchen wir den Effekt der Stichprobengr√∂√üe auf die Genauigkeit der Sch√§tzung. Und zwar auf praktische Art und Weise.\nAls praktisches Beispiel soll uns dabei die K√∂rpergr√∂√üe dienen. Wir erfragen die K√∂rpergr√∂√üe der Studis und betrachten den Mittelwert einer Stichrpobe in Abh√§ngigkeit der Gr√∂√üe der Stichprobe.\n\nGeben Sie anonym Ihre K√∂rpergr√∂√üe hier ein.\nSie k√∂nnen die Daten hier beziehen.\nBerechnen Sie den Mittelwert der K√∂rpergr√∂√üe f√ºr eine zuf√§llige Stichprobe der Gr√∂√üen \\(n=5\\) und \\(n=50\\)\nDann berechnen Sie die den ‚Äúechten‚Äù Mittelwert der Studis; damit ist der Mittelwert aller Werte der Tabelle gemeint.\nDiskutieren Sie die Ergebnisse!\nWird die Sch√§tzung genauer bei gr√∂√üerer Stichprobe?\nWird die Sch√§tzung ‚Äúrobuster‚Äù (weniger schwankend) bei gr√∂√üerer Stichprobe?\n\n         \n\n\nSolution\nIndividuell\n\nCategories:\n\nlm\ninference\nqm2"
  },
  {
    "objectID": "posts/purrr-map04/purrr-map04.html",
    "href": "posts/purrr-map04/purrr-map04.html",
    "title": "purrr-map04",
    "section": "",
    "text": "Exercise\nImportieren Sie das Grundatzprogramm der Partei AfD (in der aktuellsten Version). Tokenisieren Sie nach Seiten. Dann verschachteln Sie die Spalte, in denen der Text der Seite steht, zu einer Listenspalte. Schlie√ülich z√§hlen Sie die Anzahl der W√∂rter pro Seite und berichten g√§ngige deskriptive Statistiken dazu.\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nText aus PDF-Dateien kann man mit dem Paket pdftools einlesen:\n\nlibrary(pdftools)\nd_path &lt;- \"~/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf\"\n\nd &lt;- tibble(text = pdf_text(d_path))\n\nZu Seiten tokenisieren brauchen wir nicht; das Datenmaterial ist bereits nach Seiten organisiert.\nJetzt ‚Äúverschachteln‚Äù (to nest) wir die Spalte mit dem Text:\n\nd2 &lt;-\n  d %&gt;% \n  nest(data = text)\n\nhead(d2)\n\nDann z√§hlen wir die W√∂rter pro Seite:\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(word_count_per_page = map(data, ~ str_count(.x$text, \"\\\\w+\")))\n\nhead(d3)\n\nWie sieht eine Zelle aus data aus?\n\nd3$data[[1]]\n\nWie sieht eine Zelle aus word_count_per_page aus?\n\nd3$data[[1]]\n\nAh! Darin steckt nur eine einzelne Zahl!\n\nd3$data[[1]] %&gt;% str()\n\nDas hei√üt, wir k√∂nnen vereinfachen, entschacheln:\n\nd4 &lt;-\n  d3 %&gt;% \n  unnest(word_count_per_page)\n\nhead(d4)\n\nVisualisierung:\n\nd4 %&gt;% \n  ggplot(aes(x = word_count_per_page)) +\n  geom_histogram()\n\n\nlibrary(easystats)\ndescribe_distribution(d4$word_count_per_page)\n\n\nCategories:\n\nR\nmap\ntidyverse"
  },
  {
    "objectID": "posts/sicherheit/sicherheit.html",
    "href": "posts/sicherheit/sicherheit.html",
    "title": "sicherheit",
    "section": "",
    "text": "Aufgabe\nEin Betreiber eines komplexen technischen Ger√§ts versucht, Sie zu beruhigen: Die Wahrscheinlichkeit eines Ausfalls (Ereignis \\(A\\)) betrage nur 0.001. Allerdings pro Komponente des Ger√§ts. Das Ger√§t besteht aus 10 Komponenten.\nBerechnen Sie die Wahrscheinlichkeit, dass das Ger√§t funktioniert (also nicht ausf√§llt)!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nUnterstellen Sie Unabh√§ngigkeit der einzelnen Ereignisse.\n\n         \n\n\nL√∂sung\nDen Ausfall der Komponente \\(i\\) bezeichnen wir als \\(A_i\\) und entsprechend \\(Pr(A_i) = 0.001\\).\n\\(Pr(\\neg A_i) = 1- Pr(A_i)\\)\n\nPr_Ai &lt;- 0.001\nPr_negAi &lt;- 1 - Pr_Ai\nPr_negAi\n\n[1] 0.999\n\n\nDie Wahrscheinlichkeit, dass keine der Komponenten ausf√§llt, ist dann √ºber den Multiplikationssatzu bestimmen:\n\nPr_negA &lt;- Pr_negAi^10\nPr_negA\n\n[1] 0.9900449\n\n\nDie L√∂sung lautet 0.9900449.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/summarise02/summarise02.html",
    "href": "posts/summarise02/summarise02.html",
    "title": "summarise02",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, ob ein Foto bei der Auktion dabei war (stock_photo).\nFassen Sie die Spalte total_pr zusammen und zwar zum maximalwert - pro Gruppe!\nBerechnen Sie den Mittelwert dieser beiden Zahlen!\n\nGeben Sie diese Zahl als Antwort zur√ºck!\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nZusammenfassen:\n\nmariokart_gruppiert &lt;- group_by(mariokart, stock_photo)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, max_preis = max(total_pr))  # zusammenfassen\nmariokart_klein\n\n\n\n\n\nstock_photo\nmax_preis\n\n\n\n\nno\n326.51\n\n\nyes\n75.00\n\n\n\n\n\n\n\nsummarise(mariokart_klein, max_preis_mw = mean(max_preis))\n\n\n\n\n\nmax_preis_mw\n\n\n\n\n200.755\n\n\n\n\n\n\nmin analog.\nDie L√∂sung lautet: 201\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/tidymodels-vorlage2/tidymodels-vorlage2.html",
    "href": "posts/tidymodels-vorlage2/tidymodels-vorlage2.html",
    "title": "tidymodels-vorlage2",
    "section": "",
    "text": "Aufgabe\nSchreiben Sie eine Vorlage f√ºr eine pr√§diktive Analyse mit Tidymodels!\n\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie mind. einen Parameter des Modells\nVerwenden Sie Kreuzvalidierung\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(&lt;other_package_you_might_need_for_modelling&gt;)  # tidymodels uses existing packages for modelling so you need to make them available\n\n\n# Data:\nd_path &lt;- \"Enter data path here\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  &lt;enter_parsnip_model_name_here&gt;(mode = \"&lt;choose_regression_or_classification&gt;\",\n           cost_complexity = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(&lt;enter_output_variable&gt; ~  ., data = d_train)\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellg√ºte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/penguins-regr02/penguins-regr02.html",
    "href": "posts/penguins-regr02/penguins-regr02.html",
    "title": "penguins-regr02",
    "section": "",
    "text": "library(tidyverse)\n\n\nAufgabe\nBeantworten Sie folgende Forschungsfrage:\nGibt es einen Zusammenhang von Schnabell√§nge und Gewicht (AV) bei Pinguinen?\nHinweise:\n\nNutzen Sie den Datensatz aus dem R-Paket palmerpenguins.\nVerwenden Sie das Rope-Verfahren\n\n         \n\n\nL√∂sung\nWir rufen Stan:\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(penguins)\nm1 &lt;- stan_glm(body_mass_g ~ bill_length_mm, \n               seed = 42,\n               refresh = 0,\n               data = penguins)\n\n\nplot(rope(m1))\n\n\n\n\n\n\n\n\nHier ist also keine klare Aussage zur Frage, ob der Effekt vernachl√§ssigbar klein ist oder gr√∂√üer, m√∂glich.\n\nCategories:\n\nlm\nbayes\nrope\nstring"
  },
  {
    "objectID": "posts/mariokart-mean3/mariokart-mean3.html",
    "href": "posts/mariokart-mean3/mariokart-mean3.html",
    "title": "mariokart-mean3",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie den mittleren Verkaufspreis (total_pr) f√ºr Spiele, die sowohl neu sind als auch √ºber Lenkr√§der (wheels) verf√ºgen.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  filter(cond == \"new\" & wheels &gt; 0) %&gt;% \n  summarise(pr_mean = mean(total_pr))\n\nsolution\n\n\n\n\n\npr_mean\n\n\n\n\n54.28418\n\n\n\n\n\n\nL√∂sung: 54.28.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nnum"
  },
  {
    "objectID": "posts/rethink4e1/rethink4e1.html",
    "href": "posts/rethink4e1/rethink4e1.html",
    "title": "rethink4e1",
    "section": "",
    "text": "Welche der folgenden Zeilen zeigt den Likelihood?\n\n\n\n\\(\\mu \\sim \\mathcal{N}(0, 10)\\)\n\\(\\sigma \\sim \\mathcal{U}(0, 1)\\)\n\\(y_i = \\beta_0 + \\beta_1\\cdot x\\)\n\\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press."
  },
  {
    "objectID": "posts/rethink4e1/rethink4e1.html#answerlist",
    "href": "posts/rethink4e1/rethink4e1.html#answerlist",
    "title": "rethink4e1",
    "section": "",
    "text": "\\(\\mu \\sim \\mathcal{N}(0, 10)\\)\n\\(\\sigma \\sim \\mathcal{U}(0, 1)\\)\n\\(y_i = \\beta_0 + \\beta_1\\cdot x\\)\n\\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press."
  },
  {
    "objectID": "posts/rethink4e1/rethink4e1.html#answerlist-1",
    "href": "posts/rethink4e1/rethink4e1.html#answerlist-1",
    "title": "rethink4e1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Priori-Verteilung.\nFalsch. Priori-Verteilung.\nFalsch. Regressionsformel.\nWahr. Likelihood.\n\nMan k√∂nnte den Likelihood auch so schreiben:\n$L = y_i| , N(, ) $,\nwas noch deutlicher macht, dass die Likelihood die Wahrscheinlichkeit der Daten (y) ausdr√ºckt, gegeben der Modellparameter (\\(\\mu, \\sigma)\\).\n\nCategories:\n\nprobability\nbayes\nschoice"
  },
  {
    "objectID": "posts/twitter02/twitter02.html",
    "href": "posts/twitter02/twitter02.html",
    "title": "twitter02",
    "section": "",
    "text": "Exercise\nLaden Sie die neuesten Tweets an karl_lauterbach herunter - und zwar so viele wie auf einmal m√∂glich.\n         \n\n\nSolution\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\nAus der Hilfe zu search_tweets:\nDescription\nReturns Twitter statuses matching a user provided search query. ONLY RETURNS DATA FROM THE PAST 6-9 DAYS.\nTweets an Karl Lauterbach suchen:\n\nkarl_tweets &lt;- search_tweets(q = \"@karl_lauterbach\", n = 150000, retryonratelimit = TRUE)\n\nWir k√∂nnten n auch auf Inf setzen, aber, da wir auf das Refreshen des Rate Limits warten m√ºssen, k√∂nnte sehr lange dauern. Daher nehmen wir hier nur einen k√ºrzeren Wert.\n\ndim(karl_tweets)\n\n[1] 18000    43\n\nhead(karl_tweets)\n\n# A tibble: 6 √ó 43\n  created_at               id id_str      full_‚Ä¶¬π trunc‚Ä¶¬≤ displ‚Ä¶¬≥ entities     metad‚Ä¶‚Å¥\n  &lt;dttm&gt;                &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;list&gt;       &lt;list&gt; \n1 2022-10-23 13:30:18 1.58e18 1584145185‚Ä¶ \"Bei ‚Å¶@‚Ä¶ FALSE       122 &lt;named list&gt; &lt;df&gt;   \n2 2022-10-22 18:34:37 1.58e18 1583859379‚Ä¶ \"Es is‚Ä¶ FALSE       263 &lt;named list&gt; &lt;df&gt;   \n3 2022-10-22 17:56:39 1.58e18 1583849826‚Ä¶ \"Die S‚Ä¶ FALSE       215 &lt;named list&gt; &lt;df&gt;   \n4 2022-10-24 08:10:35 1.58e18 1584427113‚Ä¶ \"Zu we‚Ä¶ FALSE       219 &lt;named list&gt; &lt;df&gt;   \n5 2022-10-24 08:10:35 1.58e18 1584427113‚Ä¶ \"RT @K‚Ä¶ FALSE       140 &lt;named list&gt; &lt;df&gt;   \n6 2022-10-24 08:10:25 1.58e18 1584427072‚Ä¶ \"RT @U‚Ä¶ FALSE       139 &lt;named list&gt; &lt;df&gt;   \n# ‚Ä¶ with 35 more variables: source &lt;chr&gt;, in_reply_to_status_id &lt;dbl&gt;,\n#   in_reply_to_status_id_str &lt;chr&gt;, in_reply_to_user_id &lt;dbl&gt;,\n#   in_reply_to_user_id_str &lt;chr&gt;, in_reply_to_screen_name &lt;chr&gt;, geo &lt;list&gt;,\n#   coordinates &lt;list&gt;, place &lt;list&gt;, contributors &lt;lgl&gt;, is_quote_status &lt;lgl&gt;,\n#   retweet_count &lt;int&gt;, favorite_count &lt;int&gt;, favorited &lt;lgl&gt;, retweeted &lt;lgl&gt;,\n#   possibly_sensitive &lt;lgl&gt;, lang &lt;chr&gt;, quoted_status_id &lt;dbl&gt;,\n#   quoted_status_id_str &lt;chr&gt;, quoted_status &lt;list&gt;, retweeted_status &lt;list&gt;, ‚Ä¶\n# ‚Ñπ Use `colnames()` to see all variable names\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie Random Forest (Ranger). Tunen Sie mtry und min_n.\n\n\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\n\n\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\n\n\n\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#daten",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#daten",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "",
    "text": "Verwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#av-und-uv",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#av-und-uv",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "",
    "text": "Die AV lautet c1. Die (einzige) UV lautet: text."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#hinweise",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#hinweise",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "",
    "text": "Orientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#setup",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#setup",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Setup",
    "text": "Setup\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\n\nlibrary(tictoc)\nlibrary(tidymodels)\n#library(syuzhet)\nlibrary(beepr)\nlibrary(finetune)  # anova race\nlibrary(lobstr)  # object size\nlibrary(visdat)  # footprint of csv\n#data(\"sentiws\", package = \"pradadata\")\n\nEine Vorlage f√ºr ein Tidymodels-Pipeline findet sich hier."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#learnermodell",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#learnermodell",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Learner/Modell",
    "text": "Learner/Modell\n\nmod &lt;-\n  rand_forest(mode = \"classification\",\n             mtry =  tune(), \n             min_n = tune()\n             )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#gebackenen-datensatz-als-neue-grundlage",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#gebackenen-datensatz-als-neue-grundlage",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Gebackenen Datensatz als neue Grundlage",
    "text": "Gebackenen Datensatz als neue Grundlage\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz. Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind. Die Arbeit des Feature Engineering wurde uns schon abgenommen.\n\nd_train &lt;-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\n\nvis_dat(d_train) +\n  # remove axis labels:\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank() \n        )\n\n\nd_test_baked &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#plain-rezept",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#plain-rezept",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Plain-Rezept",
    "text": "Plain-Rezept\n\nrec &lt;- \n  recipe(c1 ~ ., data = d_train)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#neuer-workflow-mit-plainem-rezept",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#neuer-workflow-mit-plainem-rezept",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Neuer Workflow mit plainem Rezept",
    "text": "Neuer Workflow mit plainem Rezept\n\nwf &lt;-\n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#parallelisierung-√ºber-mehrere-kerne",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#parallelisierung-√ºber-mehrere-kerne",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Parallelisierung √ºber mehrere Kerne",
    "text": "Parallelisierung √ºber mehrere Kerne\n\nlibrary(parallel)\nall_cores &lt;- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl &lt;- makeCluster(3)\nplan(cluster, workers = cl)\n\nAchtung: Viele Kerne brauchen auch viel Speicher."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#tuneresamplefit",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#tuneresamplefit",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Tune/Resample/Fit",
    "text": "Tune/Resample/Fit\n\ntic()\nfit_wordvec_senti_rf &lt;-\n  tune_race_anova(\n    wf,\n    grid = 50,\n    resamples = vfold_cv(d_train, v = 5),\n    control = control_race(verbose_elim = TRUE))\ntoc()\nbeep()\n\nObjekt-Gr√∂√üe:\n\nlobstr::obj_size(fit_wordvec_senti_rf)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#beste-performance",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#beste-performance",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Beste Performance",
    "text": "Beste Performance\n\nautoplot(fit_wordvec_senti_rf)\n\n\nshow_best(fit_wordvec_senti_rf)\n\nbest_params &lt;- select_best(fit_wordvec_senti_rf)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#finalisieren",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#finalisieren",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_params &lt;- select_best(fit_wordvec_senti_rf)\ntic()\nwf_finalized &lt;- finalize_workflow(wf, best_params)\nlastfit_rf &lt;- fit(wf_finalized, data = d_train)\ntoc()"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-rf-tune/germeval-sent-wordvec-rf-tune.html#test-set-g√ºte",
    "title": "germeval03-sent-wordvec-rf-tune",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(lastfit_rf, new_data = d_test_baked)\ntoc()\n\n\nd_test &lt;-\n  d_test_baked |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/wskt-mtcars-5meilen/index.html",
    "href": "posts/wskt-mtcars-5meilen/index.html",
    "title": "wskt-mtcars-5meilen",
    "section": "",
    "text": "Es soll die Wahrscheinlichkeit folgender Hypothese gepr√ºft werden:\n\nEin Auto mit manueller Schaltung hat pro Gallone Sprit mind. 5 Meilen mehr Reichweite als ein Auto mit Automatikschaltung (ceteris paribus).\n\nAufgabe: Geben Sie Sie die Wahrscheinlichkeit der Hypothese an!\nNutzen Sie zur L√∂sung folgende Analyse.\n\n\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\ndata(mtcars)\n\n\n\n\nDie Hypothese kann man wie folgt formalisieren:\n\nDie Wahrscheinlichkeit, dass Manuellschalter eine h√∂here Reichweite haben, ist gr√∂√üer als die Wahrscheinlichkeit, dass Automatikschalter eine h√∂here Reichweite haben:\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; Pr(mpg_M &lt;= mpg_A)\\]\n\nOder anders gesagt: Die Wahrscheinlichkeit, dass Automatikschalter eine h√∂here Reichweite haben (pro Gallone Sprit und im Vergleich zu Automatikschalter) ist gr√∂√üer als 50%.\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; 1/2\\] 3. M√∂chte man noch hinzuf√ºgen, dass sich diese Behauptung auf ein bestimmtes, n√§mlich unser Regressionsmodell bezieht, kann man schreiben:\n\\[Pr(mpg_M &gt; mpg_A \\quad | \\beta_0, \\beta_1, \\sigma)\\]\n\n\n\n\nm &lt;- stan_glm(mpg ~ am,\n              data = mtcars,\n              refresh = 0,\n              seed = 42)\n\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n17.135995\n0.95\n14.85310\n19.50922\n1.0000\n0.9992095\n3739.117\nnormal\n20.09062\n15.06737\n\n\nam\n7.210857\n0.95\n3.72452\n10.69610\n0.9995\n0.9994221\n3754.841\nnormal\n0.00000\n30.19568\n\n\n\n\n\n\n\n\n\n\nm_post &lt;-\n  m |&gt;\n  as_tibble()\n\nprop &lt;- \nm_post |&gt; \n  count(am &gt;= 5) |&gt; \n  mutate(prop = n/sum(n))\n\nprop\n\n\n\n\n\nam &gt;= 5\nn\nprop\n\n\n\n\nFALSE\n431\n0.10775\n\n\nTRUE\n3569\n0.89225\n\n\n\n\n\n\nHinweise:\n\nNutzen Sie die Bayes-Statistik mit Stan.\nBeachten Sie die Standardhinweise des Datenwerks.\nVerwenden Sie den Datensatz mtcars.\n\n         \n\n\n\nLaut unserem Modell betr√§gt die Wahrscheinlichkeit f√ºr obige Hypothese 0.89."
  },
  {
    "objectID": "posts/wskt-mtcars-5meilen/index.html#setup",
    "href": "posts/wskt-mtcars-5meilen/index.html#setup",
    "title": "wskt-mtcars-5meilen",
    "section": "",
    "text": "library(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/wskt-mtcars-5meilen/index.html#modell",
    "href": "posts/wskt-mtcars-5meilen/index.html#modell",
    "title": "wskt-mtcars-5meilen",
    "section": "",
    "text": "Die Hypothese kann man wie folgt formalisieren:\n\nDie Wahrscheinlichkeit, dass Manuellschalter eine h√∂here Reichweite haben, ist gr√∂√üer als die Wahrscheinlichkeit, dass Automatikschalter eine h√∂here Reichweite haben:\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; Pr(mpg_M &lt;= mpg_A)\\]\n\nOder anders gesagt: Die Wahrscheinlichkeit, dass Automatikschalter eine h√∂here Reichweite haben (pro Gallone Sprit und im Vergleich zu Automatikschalter) ist gr√∂√üer als 50%.\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; 1/2\\] 3. M√∂chte man noch hinzuf√ºgen, dass sich diese Behauptung auf ein bestimmtes, n√§mlich unser Regressionsmodell bezieht, kann man schreiben:\n\\[Pr(mpg_M &gt; mpg_A \\quad | \\beta_0, \\beta_1, \\sigma)\\]"
  },
  {
    "objectID": "posts/wskt-mtcars-5meilen/index.html#modell-berechnen",
    "href": "posts/wskt-mtcars-5meilen/index.html#modell-berechnen",
    "title": "wskt-mtcars-5meilen",
    "section": "",
    "text": "m &lt;- stan_glm(mpg ~ am,\n              data = mtcars,\n              refresh = 0,\n              seed = 42)\n\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n17.135995\n0.95\n14.85310\n19.50922\n1.0000\n0.9992095\n3739.117\nnormal\n20.09062\n15.06737\n\n\nam\n7.210857\n0.95\n3.72452\n10.69610\n0.9995\n0.9994221\n3754.841\nnormal\n0.00000\n30.19568"
  },
  {
    "objectID": "posts/wskt-mtcars-5meilen/index.html#post-verteilung-auslesen",
    "href": "posts/wskt-mtcars-5meilen/index.html#post-verteilung-auslesen",
    "title": "wskt-mtcars-5meilen",
    "section": "",
    "text": "m_post &lt;-\n  m |&gt;\n  as_tibble()\n\nprop &lt;- \nm_post |&gt; \n  count(am &gt;= 5) |&gt; \n  mutate(prop = n/sum(n))\n\nprop\n\n\n\n\n\nam &gt;= 5\nn\nprop\n\n\n\n\nFALSE\n431\n0.10775\n\n\nTRUE\n3569\n0.89225\n\n\n\n\n\n\nHinweise:\n\nNutzen Sie die Bayes-Statistik mit Stan.\nBeachten Sie die Standardhinweise des Datenwerks.\nVerwenden Sie den Datensatz mtcars."
  },
  {
    "objectID": "posts/wskt-mtcars-5meilen/index.html#antwort",
    "href": "posts/wskt-mtcars-5meilen/index.html#antwort",
    "title": "wskt-mtcars-5meilen",
    "section": "",
    "text": "Laut unserem Modell betr√§gt die Wahrscheinlichkeit f√ºr obige Hypothese 0.89."
  },
  {
    "objectID": "posts/Klausur-raten/Klausur-raten.html",
    "href": "posts/Klausur-raten/Klausur-raten.html",
    "title": "Klausur-raten",
    "section": "",
    "text": "Aufgabe\nEine Studentin muss (oder will ?) eine Statistik-Klausur schreiben. Die Klausur besteht ausschlie√ülich aus 15 Richtig-Falsch-Aufgaben, Aufgaben also, die mit entweder Ja oder Nein zu beantworten sind (per Ankreuzen). Nach (mehr oder weniger) reiflicher √úberlegung entschlie√üt sie sich, die Klausur nur durch M√ºnzwurf zu beantworten. Also nix lernen, nix wissen, einfach nur raten. Bei jeder Aufgabe.\nDie M√ºnze, die die Studentin benutzt, hat eine Wahrscheinlichkeit f√ºr einen ‚ÄúTreffer‚Äù (richtige Antwort angekreuzt) von \\(p = 0.25\\).\nWie gro√ü ist die Wahrscheinlichkeit f√ºr genau \\(k=7\\) Treffer in der Klausur?\nBeachten Sie die Bearbeitungshinweise.\n         \n\n\nL√∂sung\n\nsol &lt;- dbinom(x = k_treffer,  # Anzahl Treffer\n              size = anz_aufgaben,  # Anzahl Aufgaben in der Klausur\n              prob = p_treffer)  # Wahrscheinlichkeit f√ºr einen Treffer\n\n\n\n\n\n\n\n\n\n\nAntwort: Der gesuchte Werte betr√§gt: 0.04.\n\nAufgaben-ID: Klausur-raten, Toleranzbreite: 0.025\n\nCategories:\n\nprobability\ndyn\nbayes\nnum"
  },
  {
    "objectID": "posts/bayesbox/index.html",
    "href": "posts/bayesbox/index.html",
    "title": "bayesbox",
    "section": "",
    "text": "1 Setup\n\nlibrary(tidyverse)\n\n\n\n2 Aufgabe\nSie f√ºhren ein zweiwertiges (binomiales) Zufallsexperiment \\(n\\)-mal durch, dabei erzielen Sie \\(k\\) Treffer. Die Wiederholungen sind unabh√§ngig voneinander, und die Trefferwahrscheinlichkeit \\(\\pi\\) bleibt konstant.\n(Eine M√ºnze wiederholt werfen w√§re das typische Beispiel f√ºr ein solches Zufallexperiment.)\nGehen Sie von folgenden Parameterwerten aus:\n\nn &lt;- 8\nk &lt;- 5\n\nWelcher Parameterwert \\(\\pi\\) ist am wahrscheinlichsten, wenn Sie keine weiteren Informationen haben?\nSie √ºberpr√ºfen alle 11 Parameterwerte f√ºr \\(\\pi\\) von 0 bis 1 in Schritten von 0.1.\nUm diese Frage zu beantworten, berechnen Sie die Wahrscheinlichkeiten f√ºr alle m√∂glichen Parameterwerte \\(\\pi\\) von 0 bis 1 in Schritten von 0.1 anhand einer Bayesbox. Dabei gehen wir von einer Binomialverteilung aus:\n\\(k \\sim Bin(n, \\pi)\\).\n\n\n\n\nListing¬†1: Parameterwerte (Gitter) f√ºr Trefferwahrscheinlichkeit: 0, 0.1, 0.2, ‚Ä¶, 1\n\n\npis &lt;- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte\npis\n\n\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten gegeben jeweils eines Parameterwerts:\n\nLikelihood &lt;- dbinom(k, size = n, prob = pis)\nLikelihood\n\n [1] 0.00000000 0.00040824 0.00917504 0.04667544 0.12386304 0.21875000\n [7] 0.27869184 0.25412184 0.14680064 0.03306744 0.00000000\n\n\nAuf dieser Basis erstellen wir eine Bayes-Box, um die Posteriori-Wahrscheinlichkeiten f√ºr alle Parameterwerte zu berechnen, s. (list-gitter1?).\n\n\n\n\nListing¬†2: Wir basteln uns eine Bayes-Box\n\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (die Parameterwerte, p): \n    p = pis,\n    # Lege den Priori-Wert fest:\n    Priori  = 1/11) |&gt; \n    mutate(\n      # berechne Likelihood f√ºr jeden Wasseranteil (Parameterwert):\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\n\n\n\nDie Bayes-Box (Table¬†1) zeigt, wie sich die Post-Verteilung berechnet.\nLeider ist die zentrale Spalte, die die Posteriors enth√§lt, ausgeblendet. ü§¨\n\n\n\n\nTable¬†1: Die Bayes-Box\n\n\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\n\n\n\n\n1\n0.0\n0.01\n0.00\n0\n0.01\n\n\n2\n0.1\n0.01\n0.00\n0\n0.01\n\n\n3\n0.2\n0.01\n0.01\n0\n0.01\n\n\n4\n0.3\n0.01\n0.05\n0\n0.01\n\n\n5\n0.4\n0.01\n0.12\n0\n0.01\n\n\n6\n0.5\n0.01\n0.22\n0\n0.01\n\n\n7\n0.6\n0.01\n0.28\n0\n0.01\n\n\n8\n0.7\n0.01\n0.25\n0\n0.01\n\n\n9\n0.8\n0.01\n0.15\n0\n0.01\n\n\n10\n0.9\n0.01\n0.03\n0\n0.01\n\n\n11\n1.0\n0.01\n0.00\n0\n0.01\n\n\n\n\n\n\n\n\nAufgabe: Welcher Parameterwert \\(\\pi\\) ist am wahrscheinlichsten laut der Bayesbox?\n  \n  \n  \n  \n\n\n3 L√∂sung\nDer wahrscheinlichste Parameterwert \\(\\pi\\) ist derjenige, der die h√∂chste Posteriori-Wahrscheinlichkeit hat. Die Posteriori-Wahrscheinlichkeit ist proportional zur unstandardisierten Posteriori-Wahrscheinlichkeit. Das bedeutet, dass der Parameterwert \\(\\pi\\), der die h√∂chste unstandardisierte Posteriori-Wahrscheinlichkeit hat, auch die h√∂chste Posteriori-Wahrscheinlichkeit hat.\n\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n\n1\n0.0\n0.01\n0.00\n0\n0.01\n0.00\n\n\n2\n0.1\n0.01\n0.00\n0\n0.01\n0.00\n\n\n3\n0.2\n0.01\n0.01\n0\n0.01\n0.01\n\n\n4\n0.3\n0.01\n0.05\n0\n0.01\n0.04\n\n\n5\n0.4\n0.01\n0.12\n0\n0.01\n0.11\n\n\n6\n0.5\n0.01\n0.22\n0\n0.01\n0.20\n\n\n7\n0.6\n0.01\n0.28\n0\n0.01\n0.25\n\n\n8\n0.7\n0.01\n0.25\n0\n0.01\n0.23\n\n\n9\n0.8\n0.01\n0.15\n0\n0.01\n0.13\n\n\n10\n0.9\n0.01\n0.03\n0\n0.01\n0.03\n\n\n11\n1.0\n0.01\n0.00\n0\n0.01\n0.00\n\n\n\n\n\nIn diesem Fall ist das der folgende Parameterwert:\n\n\n[1] 0.6"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html",
    "title": "tidymodels-penguins07",
    "section": "",
    "text": "Berechnen Sie ein Entscheidungsbaum-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm.\nBerichten Sie die RMSE!\nHinweise:\n\nTuning Sie \\(Cp\\) mit 20 verschiedenen den Werten.\nL√∂schen Sie alle Zeilen mit fehlenden Werten in den Pr√§diktoren.\nBeachten Sie die √ºblichen Hinweise.\nNat√ºrlich gilt: Ceteris paribus. Halten Sie also die Modelle im √úbrigen vergleichbar bzw. identisch."
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#setup",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#setup",
    "title": "tidymodels-penguins07",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nWir d√ºrfen keine fehlenden Werte in der Y-Variable haben (im Train-Set), sonst meckert Tidymodels:\n\nd2 &lt;- \n  d %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#daten-aufteilen",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#daten-aufteilen",
    "title": "tidymodels-penguins07",
    "section": "Daten aufteilen:",
    "text": "Daten aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#cv-1",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#cv-1",
    "title": "tidymodels-penguins07",
    "section": "CV",
    "text": "CV\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 10)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#workflow",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#workflow",
    "title": "tidymodels-penguins07",
    "section": "Workflow",
    "text": "Workflow\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric_predictors())\n\nmod_tree &lt;- \ndecision_tree(\n  mode = \"regression\",\n  cost_complexity = tune()\n)\n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#fitten",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#fitten",
    "title": "tidymodels-penguins07",
    "section": "Fitten",
    "text": "Fitten\n\ntic()\nwflow_fit &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = 20,\n    metrics = metric_set(rmse)\n    )\ntoc()\n\n14.665 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#modellg√ºte",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#modellg√ºte",
    "title": "tidymodels-penguins07",
    "section": "Modellg√ºte",
    "text": "Modellg√ºte\n\nbestfit1 &lt;- fit_best(x = wflow_fit)\nlastfit1 &lt;- last_fit(bestfit1, d_split)\n\nError in `last_fit()`:\n! `last_fit()` is not well-defined for a fitted workflow.\n\ncollect_metrics(lastfit1)\n\nError: object 'lastfit1' not found\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntrees\nschoice"
  },
  {
    "objectID": "posts/kausal24/kausal24.html",
    "href": "posts/kausal24/kausal24.html",
    "title": "kausal24",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x7.\nAV: x8.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x2, x3 }\n{ x1, x2, x3, x4, x5, x6 }\n{ x1, x3 }\n{ x2 }\n{ x7, x8 }"
  },
  {
    "objectID": "posts/kausal24/kausal24.html#answerlist",
    "href": "posts/kausal24/kausal24.html#answerlist",
    "title": "kausal24",
    "section": "",
    "text": "{ x2, x3 }\n{ x1, x2, x3, x4, x5, x6 }\n{ x1, x3 }\n{ x2 }\n{ x7, x8 }"
  },
  {
    "objectID": "posts/kausal24/kausal24.html#answerlist-1",
    "href": "posts/kausal24/kausal24.html#answerlist-1",
    "title": "kausal24",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/adjustieren2/adjustieren2.html",
    "href": "posts/adjustieren2/adjustieren2.html",
    "title": "adjustieren2",
    "section": "",
    "text": "Betrachten Sie folgendes Modell, das den Zusammenhang des Preises (price) und dem Gewicht (carat) von Diamanten untersucht (Datensatz diamonds).\n\nlibrary(tidyverse)\ndiamonds &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n\nAber zuerst zentrieren wir den metrischen Pr√§diktor carat, um den Achsenabschnitt besser interpretieren zu k√∂nnen.\n\ndiamonds &lt;-\n  diamonds %&gt;% \n  mutate(carat_z = carat - mean(carat, na.rm = TRUE))\n\nDann berechnen wir ein (bayesianisches) Regressionsmodell, wobei wir auf die Standardwerte der Prior zur√ºckgreifen.\n\nlibrary(rstanarm)\nlibrary(easystats)\nlm1 &lt;- stan_glm(price ~ carat_z, data = diamonds,\n                chains = 1,  # nur ein Mal Stichproben ziehen, spart Zeit (auf Kosten der Genauigkeit)\n                refresh = 0)\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n3932.771\n0.95\n3918.390\n3946.382\n1\n1.004343\n298.9047\nnormal\n3932.8\n9973.599\n\n\ncarat_z\n7756.901\n0.95\n7730.718\n7784.369\n1\n1.001497\n1004.2651\nnormal\n0.0\n21040.850\n\n\n\n\n\n\nZur Verdeutlichung ein Diagramm zum Modell:\n\ndiamonds %&gt;% \n  ggplot() +\n  aes(x = carat_z, y = price) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\nWas kostet in Diamant mittlerer Gr√∂√üe laut Modell lm1? Runden Sie auf eine Dezimale. Geben Sie nur eine Zahl ein.\nGeben Sie eine Regressionsformel an, die lm1 erg√§nzt, so dass die Schliffart (cut) des Diamanten kontrolliert (adjustiert) wird. Anders gesagt: Das Modell soll die mittleren Preise f√ºr jede der f√ºnf Schliffarten angeben. Geben Sie nur die Regressionsformel an. Lassen Sie zwischen Termen jeweils ein Leerzeichen Abstand.\n\nHinweis: Es gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\n\ndiamonds %&gt;% \n  distinct(cut)\n\n\n\n\n\ncut\n\n\n\n\nIdeal\n\n\nPremium\n\n\nGood\n\n\nVery Good\n\n\nFair"
  },
  {
    "objectID": "posts/adjustieren2/adjustieren2.html#answerlist",
    "href": "posts/adjustieren2/adjustieren2.html#answerlist",
    "title": "adjustieren2",
    "section": "",
    "text": "Was kostet in Diamant mittlerer Gr√∂√üe laut Modell lm1? Runden Sie auf eine Dezimale. Geben Sie nur eine Zahl ein.\nGeben Sie eine Regressionsformel an, die lm1 erg√§nzt, so dass die Schliffart (cut) des Diamanten kontrolliert (adjustiert) wird. Anders gesagt: Das Modell soll die mittleren Preise f√ºr jede der f√ºnf Schliffarten angeben. Geben Sie nur die Regressionsformel an. Lassen Sie zwischen Termen jeweils ein Leerzeichen Abstand.\n\nHinweis: Es gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\n\ndiamonds %&gt;% \n  distinct(cut)\n\n\n\n\n\ncut\n\n\n\n\nIdeal\n\n\nPremium\n\n\nGood\n\n\nVery Good\n\n\nFair"
  },
  {
    "objectID": "posts/mariokart-sd3/mariokart-sd3.html",
    "href": "posts/mariokart-sd3/mariokart-sd3.html",
    "title": "mariokart-sd3",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die SD des Verkaufspreis (total_pr) f√ºr Spiele, die sowohl neu sind als auch √ºber Lenkr√§der (wheels) verf√ºgen.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- data_read(d_url)\n\n\nsolution &lt;-\nmariokart  %&gt;% \n  filter(cond == \"new\" & wheels &gt; 0) %&gt;% \n  summarise(pr_sd = sd(total_pr))\n\nsolution\n\n\n\n\n\npr_sd\n\n\n\n\n7.339186\n\n\n\n\n\n\nL√∂sung: 7.3.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nvariability\nnum"
  },
  {
    "objectID": "posts/Mediterran-Alk/Mediterran-Alk.html",
    "href": "posts/Mediterran-Alk/Mediterran-Alk.html",
    "title": "Mediterran-Alk",
    "section": "",
    "text": "Exercise\nAlkohol ist ein weit verbreites Genussmittel in vielen Gesellschaften. Insgesamt sind die negativen (kausalen) Konsequenzen f√ºr die Gesundheit unstrittig. So findet man etwa in dieser Studie:\n\nThis meta-analysis found that alcohol most strongly increased the risks for cancers of the oral cavity, pharynx, esophagus, and larynx. Statistically significant increases in risk also existed for cancers of the stomach, colon, rectum, liver, female breast, and ovaries.\n\nAllerdings gibt es auch Stimmen, die Alkohol mit gesundheitlich w√ºnschenswerten Effekten in Verbindung bringen. Dabei wird in einigen F√§llen die ‚Äúmediterrane Ern√§hrung‚Äù als Erk√§rungsnarrativ ins Spiel gebracht. So kann man etwa hier lesen:\n\nAdhering to a Mediterranean diet (‚Ä¶) were associated with a lower risk of all-cause mortality (‚Ä¶).\n\nSolche Befunde wurden von der Breiten- oder Boulevardpresse dankbar aufgenommen, wie man z.B. hier nachlesen kann:\n\nSmall Amounts of Alcohol in Mediterranean Diet Could Boost Brain Health, Claims Study\n\nMan beachte, dass ‚Äúboost your health‚Äù eine kausale Aussage ist, die √ºber einen reinen Zusammenhang hinausgeht. Nach dieser Lesart hei√üt es: Trink etwas Alkohol (A), das macht dich ges√ºnder (G).\nIhre Aufgabe: Zeigen Sie ein alternatives Kausalmodell auf, das erkl√§rt, warum ein Zusammenhang (wie eine Korrelation) zwischen A und G zu beobachten ist, aber ohne dass es einen (kausalen) Effekt zwischen beiden Gr√∂√üen g√§be!\n         \n\n\nSolution\nEine Erkl√§rung lautet - frei erfunden! -, dass die Lebenszufriedenheit (L) jeweils einen (positiven, kausalen) Effekt auf Alkoholkonsum (A) und auf die Gesundheit (G) aus√ºbt.\n\n\n\n\n\n\n\n\n\n√úbrigens: Eine Art von Diagramm, das Kausalbeziehungen zwischen Variablen aufzeigt, ist ein sog. Directed Acyclic Graph, oder kurz ein DAG. Hier ist so ein DAG gezeichnet.\n\nCategories:\n~"
  },
  {
    "objectID": "posts/log-y-regr1/log-y-regr1.html",
    "href": "posts/log-y-regr1/log-y-regr1.html",
    "title": "log-y-regression1",
    "section": "",
    "text": "Exercise\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nIn dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zun√§chst den Datensatz und verschaffen Sie sich einen √úberblick.\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\"\n\nd &lt;- data_read(d_path)\n\nDokumentation und Quellenangaben zum Datensatz finden sich hier.\n\nglimpse(d)\n\nRows: 2,675\nColumns: 11\n$ rownames &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18‚Ä¶\n$ treat    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ age      &lt;int&gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 2‚Ä¶\n$ educ     &lt;int&gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12‚Ä¶\n$ ethn     &lt;chr&gt; \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\"‚Ä¶\n$ married  &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,‚Ä¶\n$ re74     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ re75     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ re78     &lt;dbl&gt; 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 2‚Ä¶\n$ u74      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ u75      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n\n\nModellieren Sie den Effekt der Bildungsdauer auf das Einkommen! Gehen Sie von einem exponenziellen Zusammenhang der beiden Variablen aus. Um welchen Faktor steigt das Einkommen pro Jahr Bildung (laut Modell)?\nHinweise:\n\nVerwenden Sie lm zur Modellierung.\nOperationalisieren Sie das Einkommen mit der Variable re74.\nF√ºgen Sie keine weiteren Variablen dem Modell hinzu.\nGehen Sie von einem kausalen Effekt des Pr√§diktors aus.\n\n         \n\n\nSolution\n\nd2 &lt;-\n  d %&gt;% \n  filter(re74 &gt; 0) %&gt;% \n  mutate(re74_log = log(re74))\n\n\nm &lt;- lm(re74_log ~ educ, data = d2)\n\nHier sind die parameters des Modells.\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(2327)\np\n\n\n\n\n(Intercept)\n8.83\n0.06\n(8.70, 8.95)\n142.91\n&lt; .001\n\n\neduc\n0.07\n4.94e-03\n(0.07, 0.08)\n15.16\n&lt; .001\n\n\n\nF√ºr jedes Jahr Bildung steigt das Einkommen also ca. um den Faktor 1.07.\nEtwas genauer:\n\\(\\hat{\\beta_1} = 0.07\\) bedeutet, dass ein Jahr Bildung zu einen erwarteten Unterschied im Einkommen in H√∂he von 0.07 in Log-Einkommen f√ºhrt. Anders gesagt wird das Einkommen um exp(0.07) erh√∂ht. Dabei gilt \\(e^{0.07} \\approx 1.07\\):\n\nexp(0.07)\n\n[1] 1.072508\n\n\nDie L√∂sung lautet also: ‚ÄúPro Jahr Bildung steigt das Einkommen - laut Modell um den Faktor ca. 1.07‚Äù.\nMan darf dabei nicht vergessen, dass wir wir uns hier auf die Schnelle ein Modell ausgedacht haben. Ob es in Wirklichkeit so ist, wie unser Modell meint, ist eine andere Sache!\n\nCategories:\n\nregression\nlm\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html",
    "href": "posts/regr-tree02/regr-tree02.html",
    "title": "regr-tree02",
    "section": "",
    "text": "library(tidymodels)"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#setup",
    "href": "posts/regr-tree02/regr-tree02.html#setup",
    "title": "regr-tree02",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\n\nF√ºr Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#daten-teilen",
    "href": "posts/regr-tree02/regr-tree02.html#daten-teilen",
    "title": "regr-tree02",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#modelle",
    "href": "posts/regr-tree02/regr-tree02.html#modelle",
    "title": "regr-tree02",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#rezepte",
    "href": "posts/regr-tree02/regr-tree02.html#rezepte",
    "title": "regr-tree02",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec1 &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#resampling",
    "href": "posts/regr-tree02/regr-tree02.html#resampling",
    "title": "regr-tree02",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#workflow",
    "href": "posts/regr-tree02/regr-tree02.html#workflow",
    "title": "regr-tree02",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec1) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#tuningfitting",
    "href": "posts/regr-tree02/regr-tree02.html#tuningfitting",
    "title": "regr-tree02",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\n\nfit1 &lt;-\n  tune_grid(object = wf1,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#bester-kandidat",
    "href": "posts/regr-tree02/regr-tree02.html#bester-kandidat",
    "title": "regr-tree02",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(fit1)\n\n\n\n\n\n\n\n\n\nshow_best(fit1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncost_complexity\ntree_depth\nmin_n\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0e+00\n5\n18\nroc_auc\nbinary\n0.8333333\n2\n0\npre0_mod01_post0\n\n\n0e+00\n13\n23\nroc_auc\nbinary\n0.8333333\n2\n0\npre0_mod02_post0\n\n\n0e+00\n4\n35\nroc_auc\nbinary\n0.8333333\n2\n0\npre0_mod03_post0\n\n\n1e-06\n1\n10\nroc_auc\nbinary\n0.8333333\n2\n0\npre0_mod05_post0\n\n\n1e-05\n11\n40\nroc_auc\nbinary\n0.8333333\n2\n0\npre0_mod06_post0"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#finalisieren",
    "href": "posts/regr-tree02/regr-tree02.html#finalisieren",
    "title": "regr-tree02",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nwf1_finalized &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(fit1))"
  },
  {
    "objectID": "posts/regr-tree02/regr-tree02.html#last-fit",
    "href": "posts/regr-tree02/regr-tree02.html#last-fit",
    "title": "regr-tree02",
    "section": "Last Fit",
    "text": "Last Fit\n\nfinal_fit &lt;- \n  last_fit(object = wf1_finalized, d_split)\n\ncollect_metrics(final_fit)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.7500000\npre0_mod0_post0\n\n\nroc_auc\nbinary\n0.7500000\npre0_mod0_post0\n\n\nbrier_class\nbinary\n0.2509766\npre0_mod0_post0\n\n\n\n\n\n\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nstring"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html",
    "href": "posts/vis-penguins/vis-penguins.html",
    "title": "vis-penguins",
    "section": "",
    "text": "In dieser Fallstudie (YACSDA: Yet another Case Study on Data Analysis) untersuchen wir den Datensatz penguins.\nSie k√∂nnen den Datensatz so beziehen:\n\n#install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(\"penguins\")\nd &lt;- penguins \n\nOder so:\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nEin Codebook finden Sie hier.\nDie Forschungsfrage lautet:\nWas ist der Einfluss der Spezies und der Schnabell√§nge auf das K√∂rpergewicht?\n\nAbh√§ngige Variable (metrisch), y: K√∂rpergewicht\nUnabh√§ngige Variable 1 (nominal), x1: Spezies\nUnabh√§ngige Variable 2 (metrisch), x2: Schnabell√§nge\n\nVisualisieren Sie dazu folgende Aspekte der Forschungsfrage!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#umbenennen",
    "href": "posts/vis-penguins/vis-penguins.html#umbenennen",
    "title": "vis-penguins",
    "section": "Umbenennen",
    "text": "Umbenennen\nF√ºr weniger Tippen nenne ich die Variablen um:\n\nd &lt;-\n  d |&gt; \n  rename(y = body_mass_g, x1 = species, x2 = bill_length_mm)\n\nDas ist aber nicht unbedingt n√∂tig und bringt auch vielleicht keinen Vorteil f√ºr Sie."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "title": "vis-penguins",
    "section": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.",
    "text": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.\nDas R-Paket ggpubr erstellt sch√∂ne Diagramme (basierend auf ggplot) auf einfache Art. Nehmen wir ein Dichtediagramm; die Variable y soll auf der X-Achse stehen:\n\nggdensity(d, x = \"y\")\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable in Anf√ºhrungsstriche gesetzt werden muss: x = \"y\".\nOder ein Histogramm:\n\ngghistogram(d, x = \"y\")\n\n\n\n\n\n\n\n\nAlternativ k√∂nnte man das R-Paket {DataExplorer} verwenden:\n\nd |&gt; \n  select(y) |&gt; \n  plot_density()"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-relevante-kennzahlen-hinzu.",
    "href": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-relevante-kennzahlen-hinzu.",
    "title": "vis-penguins",
    "section": "F√ºgen Sie relevante Kennzahlen hinzu.",
    "text": "F√ºgen Sie relevante Kennzahlen hinzu.\nUm Diagramme mit Statistiken anzureichen, bietet sich das Paket {ggstatsplot} an:\n\ngghistostats(d, x = y)\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable nicht in Anf√ºhrungsstriche gesetzt werden darf: x = y.\nNat√ºrlich k√∂nnte man sich typische deskriptive Statistiken auch anderweitig ausgeben lassen, etwa mit {easystats}:\n\nd |&gt; \n  select(y) |&gt; \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\ny\n4201.754\n801.9545\n1206.25\n2700\n6300\n0.4703293\n-0.7192219\n342\n2"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "title": "vis-penguins",
    "section": "Visualisieren Sie die Verteilung von x1 und x2.",
    "text": "Visualisieren Sie die Verteilung von x1 und x2.\n\nx1\nMit ggpubr:\n\nd_counted &lt;- \n  d |&gt; \n  count(x1) \n\n\nggbarplot(data = d_counted, y = \"n\", x = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMit DataExplorer:\n\nd |&gt; \n  select(x1) |&gt; \n  plot_bar()\n\n\n\n\n\n\n\n\n\n\nx2\n\ngghistostats(d, x = x2)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "title": "vis-penguins",
    "section": "Visualisieren Sie die Verteilung von y bedingt auf x1",
    "text": "Visualisieren Sie die Verteilung von y bedingt auf x1\n\ngghistogram(d, x = \"y\", fill = \"x1\")\n\n\n\n\n\n\n\n\nOder so:\n\ngghistogram(d, x = \"y\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "href": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "title": "vis-penguins",
    "section": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu",
    "text": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu\n\ngrouped_gghistostats(d, x = y, grouping.var = x1)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "title": "vis-penguins",
    "section": "Visualisieren Sie den Zusammenhang von y und x2",
    "text": "Visualisieren Sie den Zusammenhang von y und x2\n\nggscatter(d, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#verbessern-sie-das-letzte-diagramm-so-dass-es-√ºbersichtlicher-wird",
    "href": "posts/vis-penguins/vis-penguins.html#verbessern-sie-das-letzte-diagramm-so-dass-es-√ºbersichtlicher-wird",
    "title": "vis-penguins",
    "section": "Verbessern Sie das letzte Diagramm, so dass es √ºbersichtlicher wird",
    "text": "Verbessern Sie das letzte Diagramm, so dass es √ºbersichtlicher wird\nEs gibt mehrere Wege, das Diagramm √ºbersichtlicher zu machen. Logarithmieren ist ein Weg.\n\nd |&gt; \n  mutate(x2 = log(x2)) |&gt; \n  ggscatter(x = \"x2\", y = \"y\")\n\n\n\n\n\n\n\n\nSynonym k√∂nnten wir schreiben:\n\nd_logged &lt;- \n  d |&gt; \n  mutate(x2 = log(x2))\n  \n\nggscatter(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "href": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "title": "vis-penguins",
    "section": "F√ºgen Sie dem letzten Diagramm relevante Kennzahlen hinzu",
    "text": "F√ºgen Sie dem letzten Diagramm relevante Kennzahlen hinzu\n\nggscatterstats(d_logged, x = x2, y = y)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "href": "posts/vis-penguins/vis-penguins.html#f√ºgen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "title": "vis-penguins",
    "section": "F√ºgen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu",
    "text": "F√ºgen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"reg.line\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "href": "posts/vis-penguins/vis-penguins.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "title": "vis-penguins",
    "section": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade",
    "text": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "href": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "title": "vis-penguins",
    "section": "Gruppieren Sie das letzte Diagramm nach x1",
    "text": "Gruppieren Sie das letzte Diagramm nach x1\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"),\n          facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#dichotomisieren-sie-y-und-z√§hlen-sie-die-h√§ufigkeiten",
    "href": "posts/vis-penguins/vis-penguins.html#dichotomisieren-sie-y-und-z√§hlen-sie-die-h√§ufigkeiten",
    "title": "vis-penguins",
    "section": "Dichotomisieren Sie y und z√§hlen Sie die H√§ufigkeiten",
    "text": "Dichotomisieren Sie y und z√§hlen Sie die H√§ufigkeiten\nNehmen wir einen Mediansplit, um zu dichotomisieren.\n\nd &lt;-\n  d |&gt; \n  mutate(y_dicho = ifelse(y &gt; median(y), \"high\", \"low\"))\n\n\nd |&gt; \n  count(y_dicho) |&gt; \n  ggbarplot(x = \"y_dicho\", y = \"n\")\n\n\n\n\n\n\n\n\nGleich viele! Das sollte nicht verwundern."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "href": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "title": "vis-penguins",
    "section": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1",
    "text": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1\n\nd_count &lt;- \nd |&gt; \n  count(y_dicho, x1) \n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\n\n\n\n\nNA\nAdelie\n152\n\n\nNA\nChinstrap\n68\n\n\nNA\nGentoo\n124\n\n\n\n\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"n\", facet.by = \"x1\", label = TRUE)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-h√§ufigkeiten-statt-absoluter-h√§ufigkeiten-gezeigt-werden",
    "href": "posts/vis-penguins/vis-penguins.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-h√§ufigkeiten-statt-absoluter-h√§ufigkeiten-gezeigt-werden",
    "title": "vis-penguins",
    "section": "Variieren Sie das letzte Diagramm so, dass Anteile (relative H√§ufigkeiten) statt absoluter H√§ufigkeiten gezeigt werden",
    "text": "Variieren Sie das letzte Diagramm so, dass Anteile (relative H√§ufigkeiten) statt absoluter H√§ufigkeiten gezeigt werden\n\nd_count &lt;-\n  d_count |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\nprop\n\n\n\n\nNA\nAdelie\n152\n0.44\n\n\nNA\nChinstrap\n68\n0.20\n\n\nNA\nGentoo\n124\n0.36\n\n\n\n\n\n\nCheck:\n\nd_count |&gt; \n  summarise(sum(prop))\n\n\n\n\n\nsum(prop)\n\n\n\n\n1\n\n\n\n\n\n\nGut! Die Anteile summieren sich zu ca. 1 (100 Prozent).\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMan beachten, dass sich die Anteile auf das ‚ÄúGesamt-N‚Äù beziehen.\n\nCategories:\n\nvis\nyacsda\nggquick\npenguins\nstring"
  },
  {
    "objectID": "posts/mtcars-post/mtcars-post.html",
    "href": "posts/mtcars-post/mtcars-post.html",
    "title": "mtcars-post",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mtcars: Berichten Sie die Breite eines Sch√§tzintervalls (89%, HDI) zum mittleren Spritverbrauch! Nutzen Sie Methoden der Bayes-Statistik.\nHinweise\n         \n\n\nL√∂sung\nSetup:\n\ndata(mtcars)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\nModell berechnen:\n\nm1 &lt;- stan_glm(mpg ~ 1, \n               data = mtcars,\n               seed = 42,\n               refresh = 0)\n\nModellparameter auslesen, wobei wir als CI-Methode ein HDI ausw√§hlen, und als CI-Gr√∂√üe 89%:\n\nparameters(m1, ci = .89, ci_method = \"hdi\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n20.10377\n0.89\n18.26377\n21.63711\n1\n1.000792\n2838.234\nnormal\n20.09062\n15.06737\n\n\n\n\n\n\nIm Standard wird ein 95%-Perzentilintervall berechnet, s. die Dokumentation zur Funktion hier.\nDie L√∂sung lautet also:\n\nsolution &lt;- 21.64 - 18.26\nsolution\n\n[1] 3.38\n\n\n\nCategories:\n\nbayes\npost\nestimation\nexam-22"
  },
  {
    "objectID": "posts/mtcars-simple3/mtcars-simple3.html",
    "href": "posts/mtcars-simple3/mtcars-simple3.html",
    "title": "mtcars-simple3",
    "section": "",
    "text": "We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nWhich of the predictors in the above model has the weakest causal impact on the output variable?\nNotes:\n\nUse can either use frequentist or bayesian modeling.\nUse R for all computations.\nThere are multiple ways to find a solution.\n\n\n\n\ncyl\nhp\ndisp\nAll are equally strong\nnone of the above"
  },
  {
    "objectID": "posts/mtcars-simple3/mtcars-simple3.html#answerlist",
    "href": "posts/mtcars-simple3/mtcars-simple3.html#answerlist",
    "title": "mtcars-simple3",
    "section": "",
    "text": "cyl\nhp\ndisp\nAll are equally strong\nnone of the above"
  },
  {
    "objectID": "posts/mtcars-simple3/mtcars-simple3.html#answerlist-1",
    "href": "posts/mtcars-simple3/mtcars-simple3.html#answerlist-1",
    "title": "mtcars-simple3",
    "section": "Answerlist",
    "text": "Answerlist\n\nwrong\ncorrect\nwrong\nwrong\nwrong\n\n\nCategories:\n\nregression\nen\nbayes\nfrequentist\nqm1\nstats-nutshell"
  },
  {
    "objectID": "posts/PPV1a-mtcars/PPV1a-mtcars.html",
    "href": "posts/PPV1a-mtcars/PPV1a-mtcars.html",
    "title": "PPV1a-mtcars",
    "section": "",
    "text": "Im Folgenden ist der Datensatz mtcars zu analysieren.\nEine M√∂glichkeit, den Datensatz zu beziehen, ist diese Sammlung an Datens√§tzen. Suchen Sie dort nach dem Namen des Datensatzes. Importieren Sie dann die Daten in R.\nHilfe zum Datensatz ist auf dieser Webseite abrufbar.\nBerechnen Sie das folgende lineare Modell:\nAV: mpg.\nUVs: hp, am.\nAufgabe: Was ist der Wert des Punktsch√§tzers f√ºr eine Beobachtung, bei der alle Pr√§diktoren den Wert 0 aufweisen?\nHinweise\nW√§hlen Sie die am besten passende Antwortoption!\n\n\n\n-27\n-17\n-7\n17\n27"
  },
  {
    "objectID": "posts/PPV1a-mtcars/PPV1a-mtcars.html#answerlist",
    "href": "posts/PPV1a-mtcars/PPV1a-mtcars.html#answerlist",
    "title": "PPV1a-mtcars",
    "section": "",
    "text": "-27\n-17\n-7\n17\n27"
  },
  {
    "objectID": "posts/PPV1a-mtcars/PPV1a-mtcars.html#answerlist-1",
    "href": "posts/PPV1a-mtcars/PPV1a-mtcars.html#answerlist-1",
    "title": "PPV1a-mtcars",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/mariokart-mean2/mariokart-mean2.html",
    "href": "posts/mariokart-mean2/mariokart-mean2.html",
    "title": "mariokart-mean2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie den mittleren Verkaufspreis (total_pr) f√ºr neue Spiele.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  filter(cond == \"new\") %&gt;% \n  summarise(pr_mean = mean(total_pr))\n\nsolution\n\n\n\n\n\npr_mean\n\n\n\n\n53.77068\n\n\n\n\n\n\nL√∂sung: 53.77.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nnum"
  },
  {
    "objectID": "posts/twitter03/twitter03.html",
    "href": "posts/twitter03/twitter03.html",
    "title": "twitter03",
    "section": "",
    "text": "Exercise\nLaden Sie die neuesten Tweets an karl_lauterbach herunter, die mindestens 100 Likes oder 100 Retweets haben.\n         \n\n\nSolution\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nDann anmelden:\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\nTweets an Karl Lauterbach suchen:\n\nkarl1 &lt;- search_tweets(\"@karl_lauterbach min_faves:100 OR min_retweets:100\", n = 10)\n\n\nkarl1 %&gt;% \n  select(retweet_count, favorite_count)\n\n# A tibble: 10 √ó 2\n   retweet_count favorite_count\n           &lt;int&gt;          &lt;int&gt;\n 1            56            210\n 2            56            229\n 3            44           1626\n 4            60            225\n 5            30            494\n 6             5            148\n 7            27            435\n 8            12            178\n 9            13            162\n10            46            375\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "href": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "title": "tidymodels-vorlage3",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse f√ºr ein Vorhersagemodell, das sich als Vorlage f√ºr Analysen dieser Art eignet!\nVerzichten Sie auf Resampling und Tuning.\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie keinen Parameter des Modells\nVerwenden Sie keine Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(easystats)   # NAs z√§hlen\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"regression\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d_train) |&gt; \n  step_unknown(all_nominal_predictors(), new_level = \"NA\") |&gt; \n  step_naomit(all_predictors()) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_zv(all_predictors()) |&gt; \n  step_normalize(all_predictors()) \n\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  last_fit(split = d_split)\ntoc()\n\n0.496 sec elapsed\n\ncollect_metrics(wf1_fit)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n310.3661061\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8627167\npre0_mod0_post0\n\n\n\n\n\n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nyear\nbody_mass_g\nspecies_Chinstrap\nspecies_Gentoo\nisland_Dream\nisland_Torgersen\nsex_male\nsex_NA.\n\n\n\n\n-1.2404291\n-1.5309296\n0.3858343\n-0.7943918\n-1.2921757\n3450\n-0.5026644\n-0.7579203\n1.3366001\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n1.4505356\n1.3186250\n0.3858343\n-0.3653368\n1.1407119\n3675\n1.9816579\n-0.7579203\n1.3366001\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n-0.2115308\n0.4006477\n-1.9691393\n0.7073009\n-1.2921757\n4500\n-0.5026644\n1.3142661\n-0.7452558\n-0.4093011\n-0.9636924\n-0.1543093\n\n\n-0.9930977\n0.3432741\n0.8868925\n-0.2938276\n-0.0757319\n4150\n-0.5026644\n-0.7579203\n-0.7452558\n2.4336824\n1.0336378\n-0.1543093\n\n\n0.5304631\n0.8787609\n-0.5661763\n2.0659752\n-0.0757319\n5800\n-0.5026644\n1.3142661\n-0.7452558\n-0.4093011\n1.0336378\n-0.1543093\n\n\n-0.2807836\n-0.9571938\n0.7866809\n-1.1519377\n1.1407119\n3650\n-0.5026644\n-0.7579203\n1.3366001\n-0.4093011\n1.0336378\n-0.1543093\n\n\n\n\n\n\n\ndescribe_distribution(d_train_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nrownames\n0.000\n1.0000\n1.696693\n-1.7153052\n1.678080\n-0.0140987\n-1.2072129\n257\n0\n\n\nbill_length_mm\n0.000\n1.0000\n1.682958\n-2.2767861\n2.982459\n0.0138271\n-0.7949178\n257\n0\n\n\nbill_depth_mm\n0.000\n1.0000\n1.603386\n-2.0192451\n2.189644\n-0.1101092\n-0.8689102\n257\n0\n\n\nflipper_length_mm\n0.000\n1.0000\n1.644711\n-1.9385386\n2.065975\n0.3185041\n-1.0170679\n257\n0\n\n\nyear\n0.000\n1.0000\n2.432888\n-1.2921757\n1.140712\n-0.1160338\n-1.5114889\n257\n0\n\n\nbody_mass_g\n4200.973\n792.5366\n1212.500000\n2700.0000000\n6300.000000\n0.4897600\n-0.6875459\n257\n0\n\n\nspecies_Chinstrap\n0.000\n1.0000\n0.000000\n-0.5026644\n1.981658\n1.4905934\n0.2235476\n257\n0\n\n\nspecies_Gentoo\n0.000\n1.0000\n2.072186\n-0.7579203\n1.314266\n0.5607093\n-1.6988872\n257\n0\n\n\nisland_Dream\n0.000\n1.0000\n2.081856\n-0.7452558\n1.336600\n0.5959823\n-1.6577672\n257\n0\n\n\nisland_Torgersen\n0.000\n1.0000\n0.000000\n-0.4093011\n2.433682\n2.0402588\n2.1795571\n257\n0\n\n\nsex_male\n0.000\n1.0000\n1.997330\n-0.9636924\n1.033638\n0.0704940\n-2.0107396\n257\n0\n\n\nsex_NA.\n0.000\n1.0000\n0.000000\n-0.1543093\n6.455274\n6.3503836\n38.6279271\n257\n0\n\n\n\n\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie XGB.\nPreppen und Backen Sie das Rezept, aber f√ºhren Sie die Pipelien mit dem gebackenen Datensatz und einem ‚ÄúPlain-Rezept‚Äù durch.\n\n\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\n\n\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\n\n\n\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#daten",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#daten",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "",
    "text": "Verwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#av-und-uv",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#av-und-uv",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "",
    "text": "Die AV lautet c1. Die (einzige) UV lautet: text."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#hinweise",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#hinweise",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "",
    "text": "Orientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#setup",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#setup",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Setup",
    "text": "Setup\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\n\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(lobstr)  # object size\nlibrary(visdat)  # Fingerprint/footprint of dataset (CSV)\ndata(\"sentiws\", package = \"pradadata\")\n\nEine Vorlage f√ºr ein Tidymodels-Pipeline findet sich hier."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#learnermodell",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#learnermodell",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Learner/Modell",
    "text": "Learner/Modell\n\nmod &lt;-\n  boost_tree(mode = \"classification\",\n             learn_rate = tune(), \n             tree_depth = tune()\n             )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#rezept-workvektoren",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#rezept-workvektoren",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Rezept Workvektoren",
    "text": "Rezept Workvektoren\nPfad zu den Wordvektoren:\n\npath_wordvec &lt;- \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/part-0.arrow\"\n\n\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_recipe_wordvec_senti.R\")\n\nrec &lt;- def_recipe_wordvec_senti(data_train = d_train,\n                                path_wordvec = path_wordvec)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#prepbake-wordvektoren",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#prepbake-wordvektoren",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Prep/Bake Wordvektoren",
    "text": "Prep/Bake Wordvektoren\n\ntic()\nrec_prepped &lt;- prep(rec)\ntoc()\n\n78.021 sec elapsed\n\nd_rec_baked &lt;- bake(rec_prepped, new_data = NULL)\n\n\nsum(is.na(d_rec_baked))"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#test-set-auch-baken",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#test-set-auch-baken",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Test-Set auch baken",
    "text": "Test-Set auch baken\n\nd_test_baked &lt;- bake(rec_prepped, new_data = germeval_test)\ndim(d_test_baked)\n\n\nwrite_csv(d_test_baked, \"data/germeval/germeval_test_recipe_wordvec_senti.csv\")\n\nSp√§ter kann man es dann analog wieder importieren:\n\nd_test_baked &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#gebackenen-datensatz-als-neue-grundlage",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#gebackenen-datensatz-als-neue-grundlage",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Gebackenen Datensatz als neue Grundlage",
    "text": "Gebackenen Datensatz als neue Grundlage\nDen gepreppten/gebackenen Datensatz speichern wir als Datensatz ab:\n\nwrite_csv(d_rec_baked, \"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\nSp√§ter k√∂nnen wir den Datensatz als ‚Äúneuen, frischen‚Äù Datensatz f√ºr ein ‚ÄúPlain-Rezept‚Äù, also ein ganz einfaches Rezept nutzen. Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind.\n\nd_train_new &lt;-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\n\nvis_dat(d_train_new) +\n  # remove axis labels:\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank() \n        )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#plain-rezept",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#plain-rezept",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Plain-Rezept",
    "text": "Plain-Rezept\n\nrec &lt;- \n  recipe(c1 ~ ., data = d_train_new)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#neuer-workflow-mit-plainem-rezept",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#neuer-workflow-mit-plainem-rezept",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Neuer Workflow mit plainem Rezept",
    "text": "Neuer Workflow mit plainem Rezept\n\nwf &lt;-\n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)\n\nwf"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#parallelisierung-√ºber-mehrere-kerne",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#parallelisierung-√ºber-mehrere-kerne",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Parallelisierung √ºber mehrere Kerne",
    "text": "Parallelisierung √ºber mehrere Kerne\n\nlibrary(parallel)\nall_cores &lt;- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl &lt;- makeCluster(2)\nplan(cluster, workers = cl)\n\nAchtung: Viele Kerne brauchen auch viel Speicher."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#tuneresamplefit",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#tuneresamplefit",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Tune/Resample/Fit",
    "text": "Tune/Resample/Fit\n\ntic()\nfit_wordvec_senti_xgb &lt;-\n  tune_grid(\n    wf,\n    grid = 50,\n    resamples = vfold_cv(d_train_new, v = 5))\ntoc()\nbeep()\n\nObjekt-Gr√∂√üe:\n\nlobstr::obj_size(fit_wordvec_senti_xgb)\n\nAh! Angenehm klein."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#get-best-performance",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#get-best-performance",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Get best performance",
    "text": "Get best performance\n\nautoplot(fit_wordvec_senti_xgb)\n\n\nshow_best(fit_wordvec_senti_xgb)\n\n\nbest_params &lt;- select_best(fit_wordvec_senti_xgb)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#finalisieren",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#finalisieren",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_params &lt;- select_best(fit_wordvec_senti_xgb)\ntic()\nwf_finalized &lt;- finalize_workflow(wf, best_params)\nlastfit_xgb &lt;- fit(wf_finalized, data = d_train_new)\ntoc()"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#test-set-g√ºte",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(lastfit_xgb, new_data = d_test_baked)\ntoc()\n\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#fazit",
    "href": "posts/germeval-sent-wordvec-xgb-plain/germeval-sent-wordvec-xgb-plain.html#fazit",
    "title": "germeval03-sent-wordvec-xgb-plain",
    "section": "Fazit",
    "text": "Fazit\nVerzichtet man auf ein Rezept mit viel Datenvolument (Wordvektoren bl√§hen das Rezept m√§chtig auf), so wird das Fitten schlanker und schneller. Schneller auch deshalb, weil ggf. kein Swapping zwischen Speicher und Festplatte mehr n√∂tig ist."
  },
  {
    "objectID": "posts/filter-na2/filter-na2.html",
    "href": "posts/filter-na2/filter-na2.html",
    "title": "filter-na2",
    "section": "",
    "text": "Filtern Sie alle Zeilen mit fehlende Werte im Datensatz penguins!"
  },
  {
    "objectID": "posts/filter-na2/filter-na2.html#setup",
    "href": "posts/filter-na2/filter-na2.html#setup",
    "title": "filter-na2",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\nnrow(d)\n\n[1] 344"
  },
  {
    "objectID": "posts/filter-na2/filter-na2.html#weg-1",
    "href": "posts/filter-na2/filter-na2.html#weg-1",
    "title": "filter-na2",
    "section": "Weg 1",
    "text": "Weg 1\n\nd %&gt;% \n  filter(!complete.cases(.)) %&gt;% \n  nrow()\n\n[1] 11"
  },
  {
    "objectID": "posts/filter-na2/filter-na2.html#weg-2",
    "href": "posts/filter-na2/filter-na2.html#weg-2",
    "title": "filter-na2",
    "section": "Weg 2",
    "text": "Weg 2\n\nd %&gt;% \n  filter(if_any(everything(), ~ is.na(.))) %&gt;% \n  nrow()\n\n[1] 11\n\n\n\nCategories:\n\n2023\neda\nna\nstring"
  },
  {
    "objectID": "posts/summarise03/summarise03.html",
    "href": "posts/summarise03/summarise03.html",
    "title": "summarise03",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, wie viele Lenkr√§der bei der Auktion dabei waren.\nFassen Sie die Spalte total_pr zusammen und zwar zum Mittelwert - pro Gruppe!\nBerechnen Sie den Mittelwert dieser Zahlen!\n\nGeben Sie diese Zahl als Antwort zur√ºck!\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nZusammenfassen:\n\nmariokart_gruppiert &lt;- group_by(mariokart, wheels)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, pr_mean = mean(total_pr))  # zusammenfassen\nmariokart_klein\n\n\n\n\n\nwheels\npr_mean\n\n\n\n\n0\n41.05973\n\n\n1\n44.16885\n\n\n2\n61.02745\n\n\n3\n69.75000\n\n\n4\n65.02000\n\n\n\n\n\n\n\nsummarise(mariokart_klein, pr_mean = mean(pr_mean))\n\n\n\n\n\npr_mean\n\n\n\n\n56.20521\n\n\n\n\n\n\nmin analog.\nDie L√∂sung lautet: 56\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/adjustieren2_var1/adjustieren2_var1.html",
    "href": "posts/adjustieren2_var1/adjustieren2_var1.html",
    "title": "adjustieren2_var1",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgendes Modell, das den Zusammenhang des Preises (price) und dem Gewicht (carat) von Diamanten untersucht (Datensatz diamonds).\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\ndiamonds &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n\nAber zuerst zentrieren wir den metrischen Pr√§diktor carat, um den Achsenabschnitt besser interpretieren zu k√∂nnen.\n\ndiamonds2 &lt;-\n  diamonds %&gt;% \n  mutate(carat_z = carat - mean(carat, na.rm = TRUE))\n\nDann berechnen wir ein (bayesianisches) Regressionsmodell, wobei wir auf die Standardwerte der Prior zur√ºckgreifen.\n\nlibrary(rstanarm)\nlm1 &lt;- stan_glm(price ~ carat_z, data = diamonds2,\n                refresh = 0)\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n3933.103\n0.95\n3919.932\n3945.329\n1\n1.0007236\n1337.926\nnormal\n3932.8\n9973.599\n\n\ncarat_z\n7756.757\n0.95\n7728.920\n7784.542\n1\n0.9999506\n4482.262\nnormal\n0.0\n21040.850\n\n\n\n\n\n\nZur Verdeutlichung ein Diagramm zum Modell:\n\ndiamonds2 %&gt;% \n  ggplot() +\n  aes(x = carat_z, y = price) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nOder so:\n\nestimate_relation(lm1) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgabe:\nGeben Sie eine Regressionsformel an, die lm1 erg√§nzt, so dass die Schliffart (cut) des Diamanten kontrolliert (adjustiert) wird. Anders gesagt: Das Modell soll die mittleren Preise f√ºr jede der f√ºnf Schliffarten angeben.\nHinweis:\n\nGeben Sie nur die Regressionsformel an.\nLassen Sie zwischen Termen der Regressionsformel jeweils ein Leerzeichen Abstand.\nBeziehen Sie sich auf das Modell bzw. die Angaben oben.\nEs gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\n\n\ndiamonds %&gt;% \n  distinct(cut)\n\n\n\n\n\ncut\n\n\n\n\nIdeal\n\n\nPremium\n\n\nGood\n\n\nVery Good\n\n\nFair\n\n\n\n\n\n\n         \n\n\nL√∂sung\nDie richtige Antwort lautet: price ~ carat_z + cut\nDas Modell k√∂nnten wir so berechnen:\n\nlm2 &lt;- stan_glm(price ~ carat_z + cut, data = diamonds2,\n                refresh = 0)  # verhindert einen Haufen unn√∂tigen Output\nparameters(lm2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n2403.533\n0.95\n2328.352\n2474.815\n1\n1.001242\n1766.022\nnormal\n3932.8\n9973.599\n\n\ncarat_z\n7870.523\n0.95\n7843.157\n7897.570\n1\n1.000339\n4271.289\nnormal\n0.0\n21040.850\n\n\ncutGood\n1122.273\n0.95\n1040.951\n1206.763\n1\n1.000233\n2115.490\nnormal\n0.0\n34685.376\n\n\ncutIdeal\n1802.437\n0.95\n1727.233\n1878.867\n1\n1.000457\n1845.860\nnormal\n0.0\n20362.277\n\n\ncutPremium\n1440.937\n0.95\n1362.846\n1519.823\n1\n1.000445\n1875.457\nnormal\n0.0\n22862.493\n\n\ncutVery Good\n1511.725\n0.95\n1433.968\n1589.377\n1\n1.000600\n1886.521\nnormal\n0.0\n23922.148\n\n\n\n\n\n\nOder auch so, mit der klassischen Regression:\n\nlm(price ~ carat_z + cut, data = diamonds2)\n\n\nCall:\nlm(formula = price ~ carat_z + cut, data = diamonds2)\n\nCoefficients:\n (Intercept)       carat_z       cutGood      cutIdeal    cutPremium  \n        2405          7871          1120          1801          1439  \ncutVery Good  \n        1510  \n\n\nDas f√ºhrt zu √§hnlichen Ergebnissen.\nMan k√∂nnte hier noch einen Interaktionseffekt erg√§nzen.\n\nCategories:\n\nlm\nregression\nbayes\nadjust\nstring"
  },
  {
    "objectID": "posts/summarise04/summarise04.html",
    "href": "posts/summarise04/summarise04.html",
    "title": "summarise04",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, wie viele Lenkr√§der bei der Auktion dabei waren.\nFassen Sie die Spalte total_pr zusammen und zwar zur Standardabweichung (SD) - pro Gruppe!\n\nGeben Sie die erste Kennzahl als Antwort zur√ºck!\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nZusammenfassen:\n\nmariokart_gruppiert &lt;- group_by(mariokart, wheels)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, pr_sd = sd(total_pr))  # zusammenfassen\nmariokart_klein\n\n\n\n\n\nwheels\npr_sd\n\n\n\n\n0\n14.268965\n\n\n1\n4.146452\n\n\n2\n38.344077\n\n\n3\n7.424621\n\n\n4\nNA\n\n\n\n\n\n\nDie L√∂sung lautet: 14.27\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nvariability\nnum"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html",
    "href": "posts/tmdb02/tmdb02.html",
    "title": "tmdb02",
    "section": "",
    "text": "Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme.\nDie Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\n\n\nReichen Sie bei Kaggle eine Submission f√ºr die Fallstudie ein! Berichten Sie den Kaggle-Score\nHinweise:\n\nSie m√ºssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym m√∂glich); alternativ k√∂nnen Sie sich mit einem Google-Konto anmelden.\nBerechnen Sie einen Entscheidungsbaum und einen Random-Forest.\nTunen Sie nach Bedarf; verwenden Sie aber Default-Werte.\nVerwenden Sie Tidymodels."
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#vorbereitung",
    "href": "posts/tmdb02/tmdb02.html#vorbereitung",
    "title": "tmdb02",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(doParallel)  # mehrere CPUs nutzen\nlibrary(finetune)  # Tune Anova\n\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nglimpse(d_train)\nglimpse(d_test)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#rezept",
    "href": "posts/tmdb02/tmdb02.html#rezept",
    "title": "tmdb02",
    "section": "Rezept",
    "text": "Rezept\n\nRezept definieren\n\nrec1 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(popularity, runtime, revenue, budget) %&gt;% \n  update_role(revenue, new_role = \"outcome\") %&gt;% \n  step_mutate(budget = ifelse(budget &lt; 10, 10, budget)) %&gt;% \n  step_log(budget) %&gt;% \n  step_impute_knn(all_predictors())\n\nrec1\n\n\n\nCheck das Rezept\n\nrec1_prepped &lt;-\n  prep(rec1, verbose = TRUE)\n\nrec1_prepped\n\n\nd_train_baked &lt;-\n  rec1_prepped %&gt;% \n  bake(new_data = NULL) \n\nhead(d_train_baked)\n\nDie AV-Spalte sollte leer sein:\n\nbake(rec1_prepped, new_data = head(d_test), all_outcomes())\n\n\nd_train_baked %&gt;% \n  map_df(~ sum(is.na(.)))\n\nKeine fehlenden Werte mehr in den Pr√§diktoren.\nNach fehlenden Werten k√∂nnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train_baked)\n\nSo bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache.\nDas Test-Sample backen wir auch mal:\n\nd_test_baked &lt;-\n  bake(rec1_prepped, new_data = d_test)\n\nd_test_baked %&gt;% \n  head()"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#kreuzvalidierung",
    "href": "posts/tmdb02/tmdb02.html#kreuzvalidierung",
    "title": "tmdb02",
    "section": "Kreuzvalidierung",
    "text": "Kreuzvalidierung\n\ncv_scheme &lt;- vfold_cv(d_train,\n                      v = 5, \n                      repeats = 1)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#modelle",
    "href": "posts/tmdb02/tmdb02.html#modelle",
    "title": "tmdb02",
    "section": "Modelle",
    "text": "Modelle\n\nBaum\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                mode = \"regression\")\n\n\n\nRandom Forest\n\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000,\n              mode = \"regression\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#workflows",
    "href": "posts/tmdb02/tmdb02.html#workflows",
    "title": "tmdb02",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;% \n  add_model(mod_tree) %&gt;% \n  add_recipe(rec1)\n\nwf_rf &lt;-\n  workflow() %&gt;% \n  add_model(mod_rf) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#fitten-und-tunen",
    "href": "posts/tmdb02/tmdb02.html#fitten-und-tunen",
    "title": "tmdb02",
    "section": "Fitten und tunen",
    "text": "Fitten und tunen\nUm Rechenzeit zu sparen, kann man den Parameter grid bei tune_grid() auf einen kleinen Wert setzen. Der Default ist 10. Um gute Vorhersagen zu erzielen, sollte man den Wert tendenziell noch √ºber 10 erh√∂hen.\n\nTree\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\ntree_fit &lt;-\n  wf_tree %&gt;% \n  tune_race_anova(\n    resamples = cv_scheme,\n    #grid = 2\n  )\ntoc()\n\nHilfe zu tune_grid() bekommt man hier.\n\ntree_fit\n\nSteht was in den .notes?\n\ntree_fit[[\".notes\"]][[2]]\n\nNein.\n\ncollect_metrics(tree_fit)\n\n\nshow_best(tree_fit)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#finalisieren",
    "href": "posts/tmdb02/tmdb02.html#finalisieren",
    "title": "tmdb02",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_tree_wf &lt;-\n  wf_tree %&gt;% \n  finalize_workflow(select_best(tree_fit))\n\nbest_tree_wf\n\n\ntree_last_fit &lt;-\n  fit(best_tree_wf, data = d_train)\n\ntree_last_fit"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#vorhersage-test-sample",
    "href": "posts/tmdb02/tmdb02.html#vorhersage-test-sample",
    "title": "tmdb02",
    "section": "Vorhersage Test-Sample",
    "text": "Vorhersage Test-Sample\n\npredict(tree_last_fit, new_data = d_test)\n\n\nRF"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#fitten-und-tunen-1",
    "href": "posts/tmdb02/tmdb02.html#fitten-und-tunen-1",
    "title": "tmdb02",
    "section": "Fitten und Tunen",
    "text": "Fitten und Tunen\nUm Rechenzeit zu sparen, kann man das Objekt, wenn einmal berechnet, abspeichern unter result_obj_path auf der Festplatte und beim n√§chsten Mal importieren, das geht schneller als neu berechnen.\nDas k√∂nnte dann z.B. so aussehen:\n\nif (file.exists(result_obj_path)) {\n  rf_fit &lt;- read_rds(result_obj_path)\n} else {\n  tic()\n  rf_fit &lt;-\n    wf_rf %&gt;% \n    tune_grid(\n      resamples = cv_scheme)\n  toc()\n}\n\nAchtung Ein Ergebnisobjekt von der Festplatte zu laden ist gef√§hrlich. Wenn Sie Ihr Modell ver√§ndern, aber vergessen, das Objekt auf der Festplatte zu aktualisieren, werden Ihre Ergebnisse falsch sein (da auf dem veralteten Objekt beruhend), ohne dass Sie durch eine Fehlermeldung von R gewarnt w√ºrden!\nSo kann man das Ergebnisobjekt auf die Festplatte schreiben:\n\n#write_rds(rf_fit, file = \"objects/tmbd_rf_fit1.rds\")\n\nAber wir berechnen lieber neu:\n\ntic()\nrf_fit &lt;-\n  wf_rf %&gt;% \n  tune_grid(\n    resamples = cv_scheme\n    #grid = 2\n    )\ntoc()\n\n\ncollect_metrics(rf_fit)\n\n\nselect_best(rf_fit)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#finalisieren-1",
    "href": "posts/tmdb02/tmdb02.html#finalisieren-1",
    "title": "tmdb02",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nfinal_wf &lt;-\n  wf_rf %&gt;% \n  finalize_workflow(select_best(rf_fit))\n\n\nfinal_fit &lt;-\n  fit(final_wf, data = d_train)\n\n\nfinal_preds &lt;- \n  final_fit %&gt;% \n  predict(new_data = d_test) %&gt;% \n  bind_cols(d_test)\n\n\nsubmission &lt;-\n  final_preds %&gt;% \n  select(id, revenue = .pred)\n\nAbspeichern und einreichen:\n\nwrite_csv(submission, file = \"submission.csv\")"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#kaggle-score",
    "href": "posts/tmdb02/tmdb02.html#kaggle-score",
    "title": "tmdb02",
    "section": "Kaggle Score",
    "text": "Kaggle Score\nDiese Submission erzielte einen Score von 2.7664 (RMSLE).\n\nsol &lt;- 2.7664\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\ntrees\nnum"
  },
  {
    "objectID": "posts/purrr-map05/purrr-map05.html",
    "href": "posts/purrr-map05/purrr-map05.html",
    "title": "purrr-map05",
    "section": "",
    "text": "library(tidyverse)\n\n\nExercise\nErstellen Sie eine Tabelle mit mit folgenden Spalten:\n\nID-Spalte: \\(1,2,..., 10\\)\nEine Spalte, in der jede Zelle eine Tabelle mit einem Vektor \\(x\\), einer standardnormalverteilten Zufallszahlen (n=1000), enth√§lt\n\nBerechnen Sie den Mittelwert von jedem \\(x\\)! Diese Ergebnisse sollen als weitere Spalte der Tabelle hinzugef√ºgt werden.\n         \n\n\nSolution\n\nd &lt;- tibble(\n  id = 1:10) %&gt;% \n  mutate(x = map(id, ~ rnorm(n = 1e3))\n) \n\nstr(d)\n\ntibble [10 √ó 2] (S3: tbl_df/tbl/data.frame)\n $ id: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ x :List of 10\n  ..$ : num [1:1000] 1.13 0.0391 -1.111 0.9633 1.8529 ...\n  ..$ : num [1:1000] 0.286 -0.202 0.512 -0.818 2.291 ...\n  ..$ : num [1:1000] -0.00874 -1.73109 -0.80031 0.08323 0.58919 ...\n  ..$ : num [1:1000] -0.7134 0.327 0.7852 -0.7954 -0.0336 ...\n  ..$ : num [1:1000] 0.1108 -1.444 -0.0823 -0.6374 -0.3509 ...\n  ..$ : num [1:1000] 1.793 -0.735 0.407 -0.309 -1.184 ...\n  ..$ : num [1:1000] 0.145 -2.144 -0.114 -1.099 1.179 ...\n  ..$ : num [1:1000] -0.0448 -1.8064 0.6906 -0.3094 1.146 ...\n  ..$ : num [1:1000] 0.5583 -1.6305 0.0383 -0.2991 0.9314 ...\n  ..$ : num [1:1000] -0.23 1.695 0.234 -0.411 1.496 ...\n\n\nSo kann man sich die Mittelwerte ausgeben lassen:\n\nd$x %&gt;% \n  map(mean)\n\n[[1]]\n[1] 0.003790061\n\n[[2]]\n[1] -0.02829832\n\n[[3]]\n[1] 0.0140533\n\n[[4]]\n[1] -0.02764058\n\n[[5]]\n[1] 0.01011673\n\n[[6]]\n[1] -0.01683266\n\n[[7]]\n[1] 0.009744692\n\n[[8]]\n[1] -0.008774502\n\n[[9]]\n[1] -0.02438361\n\n[[10]]\n[1] 0.007858768\n\n\nJetzt f√ºgen wir den letzten Schritt als Spalte hinzu:\n\nd2 &lt;-\n  d %&gt;% \n  mutate(x_mean = map_dbl(x, ~ mean(.x))) \n\nhead(d2)\n\n\n\n\n\n\n\n\n\n\nid\nx\nx_mean\n\n\n\n\n1\n1.129967218, 0.039082892, -1.110991626, 0.963305222, 1.852870661, 1.510573329, -0.528400433, 1.220485244, 0.318030059, -0.816448130, 1.025637380, 0.915494970, -0.450388473, -1.305825405, -0.786611772, -1.316948555, -0.461831683, 0.540257800, 1.393654064, 1.171380379, -0.892157806, -0.024515178, 0.136435431, 1.098061769, -2.197377401, 1.300823740, 0.670045146, -0.426523692, -0.854517941, 1.099605371, 1.504040110, 0.847705794, 0.510170385, -0.328402111, 0.592919535, -0.608226040, -0.627629610, 0.305000678, 2.026647427, 1.057585943, -0.125291620, -0.557331326, -1.250103237, -1.438773706, -0.847581772, 0.038457469, 1.859989746, -2.846900660, 0.699182408, 1.358251956, 0.241036754, 0.201835365, 1.045979791, -0.029048537, 1.105006595, 0.102657526, 1.365572948, -0.139392789, 0.366220545, -0.648249390, -0.260941781, -0.031464865, 0.203537095, 0.892117218, -0.133749011, 0.494395844, 1.152557971, 2.295697720, -0.152736386, 1.895861211, 1.785232176, -1.200307338, 1.696002950, 0.065712076, 1.126016136, 0.249685654, 0.166369840, 0.749613507, -0.653662831, 0.454460938, 0.179472330, 0.548301461, 0.777678065, 0.104919580, -2.124976061, 0.298960473, -0.143763184, -0.511598346, 0.319750225, -0.021363371, 0.704876792, -0.647839981, -0.258415332, -1.518134860, 0.728855482, -0.092621260, 0.908858348, -0.009648747, -1.324239993, -0.651122005, -0.916851495, -0.854200195, -0.334544127, -0.022515115, -0.445657020, 0.602186026, 2.258159826, 0.383361510, 0.394630295, -0.355604862, -0.757102309, 0.197263333, 0.814895336, -0.800532822, -1.269143880, 1.812920024, -0.752624588, -0.098348785, -0.482570679, 0.224027748, 0.140633273, -0.470958145, 0.145149874, -0.102401632, -1.286361002, -0.049713491, 2.646737350, 0.474319974, -0.064973494, 0.231694995, 0.358649218, 0.903135146, -0.786853583, 1.113797615, -0.486163793, 1.381860897, 0.456276600, -0.237615111, 0.615750310, 0.458893717, -1.235879902, 0.113891396, -1.507756905, 1.058283661, -0.812731219, 0.152592025, -1.344434832, 1.176973206, 0.538809173, -1.556706604, 0.236570938, -0.870731446, -2.314587677, -0.314112610, 0.462815878, 0.023560067, 0.487588235, -1.365092473, 0.456941334, 0.063067389, 0.132878276, 1.493064819, 1.783940578, 1.468083364, -0.165996052, -0.001145478, -1.012548490, 1.143666487, -0.471309210, -0.371584919, 1.349553368, 1.066876169, 0.932575947, -0.881931169, 0.901025164, 0.972495367, -0.669096040, -0.881019778, -0.315833916, 0.319078271, -0.892115196, 0.926236226, -0.390766018, 0.785628908, 0.229082894, -0.051466014, 0.571593349, 0.643600311, 0.218532459, 0.754151979, -1.235138799, -1.191502629, -0.592713810, 0.254176198, 0.778980189, -0.008015603, -0.220179450, -1.030406254, 0.293301387, -1.906965172, 1.284756273, 0.203484253, -0.486511320, -0.590883951, -0.040179589, -1.282374318, -0.572306644, -0.999848401, -0.968162493, 0.378743653, 0.096420009, -2.219888869, -0.626330790, 0.564604389, -0.313753914, 3.116766725, -0.720571724, -1.759463652, -1.406390627, 0.915304714, -0.034101478, 0.347312573, -0.459503393, 0.113068732, -0.005834427, 0.471463280, -1.793254335, -1.139576366, 1.530660862, 1.071655964, -1.112517232, 0.265747446, -2.048228986, -0.413635751, -0.802559214, 0.043349202, -0.684345870, 0.117879476, -0.717077069, 0.370982275, -0.343640691, 0.616093384, 1.653051517, -2.098092668, -0.033690771, 0.075771304, -0.174876899, -0.733146051, -0.914061364, 0.072876010, -1.018325329, -0.922929187, -0.268274964, 1.639059264, -0.160097189, -0.594861712, 0.730054876, 0.189185886, 1.499068724, 0.664479838, -1.225450550, -1.037737800, 3.216506830, 0.353593122, -1.064682522, 0.275001955, 1.285968356, -0.012353992, -0.532326461, 0.282273492, 0.028574045, 1.384436459, 0.496008126, -0.085141356, 2.670116606, 0.395562506, 1.626417625, 1.528433382, -0.838625906, 0.155983725, -1.210554412, 1.354553420, -0.620935909, 0.277840728, -0.717794555, -0.109762211, -1.881558039, -1.034518882, 0.631286266, 1.859987911, -0.678825864, 1.151095888, -0.005303699, -0.104549078, -0.318006356, 1.231966371, 0.263620417, 0.566762117, 1.075351201, 0.156135790, -1.291197912, 0.275794294, 0.520759328, 0.462667374, -1.018249190, 0.852810523, 1.164210923, -1.918292756, 1.113904969, 0.176476422, 0.403117260, -0.823213535, 0.348650715, 0.437658443, -0.964428584, -1.431218397, -0.616430129, -1.551349115, -1.780677709, 1.556005561, -0.230286124, -1.253028749, -0.397620452, -0.676268612, 0.463167517, -0.948164651, -0.621994281, 2.496845717, -0.162251585, -0.561733210, -0.235508368, 0.300783373, 0.608940192, -0.651050760, 0.661605874, 0.207635789, 0.548966621, 0.392897080, -0.253141294, -0.270680123, 1.968225874, 1.955617263, -0.015320112, 0.910878724, 0.678909501, -0.660430052, -0.893767004, -0.875305949, -0.372627401, -0.693063025, -1.057465069, -0.453663580, 0.732340194, -0.581993479, -1.691984073, 2.213767668, 0.120690930, 1.882392411, -0.201023714, 1.423959368, -1.079583106, 1.423459522, -0.831278411, 2.443603110, -0.414781778, -3.160644904, -0.976867510, 0.253497520, 0.826291500, 1.714739474, -0.354763284, 0.475499238, 0.841677699, -1.347083549, -0.165843118, 0.190399343, -0.525638044, -0.973549660, 0.412252423, 1.563918033, -0.029765329, -1.110231170, -0.641232844, -0.771855397, -1.398508298, 0.728458342, 1.405720668, -1.029635294, 0.044471358, 2.197789473, 0.089617411, 1.132705241, -1.296284023, -0.338818190, 1.399031547, -0.779972794, -1.316512211, -0.549584525, 0.598508290, -1.973338235, 0.855598966, 0.552004035, -0.519126454, -1.090520843, -1.318281070, 0.654281728, -0.969244299, 0.946920915, -0.816157316, 1.066280520, -0.981943251, -1.452123735, -0.493853256, 0.798283006, -0.921433040, 1.039313336, -0.480486341, -0.121938688, 1.149422313, 0.213706624, -0.016586289, -0.192714026, -0.320802167, 0.466027183, -0.424492144, -0.871168791, 0.083375221, -1.146960700, 0.745015787, 0.842776775, 0.326677649, 2.365342645, -0.880466854, 0.169053528, 0.038457439, -0.396240777, 0.783016038, -0.203227089, -0.245422772, -1.275996231, 0.289004045, -1.213843628, -2.100738773, -1.376663714, -0.692549069, 0.025480644, -0.765406509, 0.115587137, -0.450898888, -0.401309625, -2.669569506, -1.164928197, 1.508213361, 1.944699612, 0.646943631, 1.053770857, 1.796278445, -0.048861183, 0.356601813, 0.138716686, 0.780266311, 0.235423161, -0.139100020, -0.899393907, -1.934618297, -0.405649907, -0.523387952, -0.218113561, -0.955197112, 2.709536228, 0.701315986, 0.873182437, -0.993990547, -0.994832487, 1.146159020, 0.109945700, 1.669637503, 0.986571944, -2.375728234, 1.029035130, -1.172946971, 0.708807673, 1.320631088, 1.960183366, 1.298937122, 0.975738118, 0.050416369, 0.292675332, 2.539013525, -1.117995792, 0.172843101, 0.337660722, -0.405452045, 1.202401800, -0.368547580, 1.404642514, -0.487371860, 1.681126971, -1.091448164, -1.596981846, -1.497650172, 0.455056120, 0.792667073, -0.730220610, 1.822368746, 0.434871882, 1.178763767, -0.589339218, 0.409759910, 0.646364494, -1.167524471, -1.098737286, -0.467541913, 0.529736011, 1.286759847, -2.168839771, 1.174667269, 0.584273618, -1.527337271, -0.402731878, 1.239244756, -0.193439276, -0.613648494, -0.318685983, -0.770860387, 1.313233769, -0.092077418, -1.407488110, 1.312626791, 0.502718375, 1.585570442, -1.113076502, -1.973689731, -0.597920595, 0.151107905, 2.077067462, 0.264413552, 0.248859194, -0.897412550, -1.449397853, -1.142929407, -1.968359640, 0.901427771, -1.033674168, 0.863153893, -0.285098556, -0.343730292, -0.845323356, -1.138880169, 0.369672289, 0.148136945, -1.740570243, 0.669351525, -0.241596138, 0.973735756, 0.015320285, 1.336746002, 0.969256399, -0.650779630, 1.084838030, -0.832118265, -0.289304578, -1.061392626, -0.395760344, -1.497772319, -0.112968278, 0.953678413, 0.351708734, 0.784024251, 2.174232779, -0.586742406, 0.414903346, -1.242525285, -1.145275666, 0.110992524, 1.609956317, -0.089387108, -1.637980137, 0.481040543, 0.176681913, -2.291326829, -0.100550892, 0.677973088, -1.428880333, -1.459732112, 1.425705750, -0.907141180, 0.711008949, -1.467245026, -1.427831743, 0.147947047, -1.281417623, -1.591997569, -1.827158905, 1.683107986, 0.811686189, -0.110821091, 1.211853775, -0.876880390, -0.369211558, 0.022121771, -1.610269956, 0.272686665, -0.433647933, -0.737257856, -0.034155450, -0.869582930, -1.117740904, 1.335175400, 0.294808106, 1.241398876, -1.090658105, -1.214719514, 0.661056609, 0.330433236, 0.581589807, -0.211605369, 0.236172726, -1.022019395, 0.836146137, -1.692206712, -1.924532297, -0.423327102, 1.074914348, 0.321520549, 2.219034238, -0.910261010, -0.784235788, 1.452718051, -0.635274997, 0.045097560, 1.001025019, -1.700287564, -0.471429513, 2.795029765, -0.221030461, -0.515794753, -0.608826464, 0.808313557, 1.095402367, 0.381564509, -0.119830422, 0.553787491, 0.437483485, -0.739584291, 0.473515983, -0.707131491, -0.180509278, -0.257555899, 0.440442418, 0.321004199, 0.699103623, -1.198366007, 0.283714652, 1.603066840, 0.090143066, -0.407805714, -1.071282548, 0.753981024, 0.602499058, -1.331621417, 3.139663949, 1.407084551, 1.488593502, -2.134105759, 1.369173597, -0.473202807, 0.418862156, 0.176698080, -0.063796367, 0.242670314, 1.699890711, -1.006141780, -0.563497777, -0.161991020, -0.383299241, 0.225688916, 0.550192611, 1.165341678, -0.130062572, 0.158019092, 0.971597164, 0.092210912, 0.310577354, 0.539612063, 1.179415372, 0.030830222, -1.634271726, -1.942323835, 0.017304331, 1.968500017, -0.037745472, -1.031414841, 1.170749225, 1.840629554, -0.927175689, 0.277862753, 0.129602773, -0.273999743, -1.506294772, -2.222435134, -1.470093357, 0.056151100, -1.056113767, -0.766217371, 1.029420868, 0.868117951, -0.548252036, 1.620960955, 1.722380772, 0.885203234, -2.445738181, -0.990713919, 0.136066259, 0.116297217, -0.293246050, 0.971484047, 1.720417742, -0.674682282, 0.367943352, 0.636845249, 1.295825058, 0.639833929, -0.722309354, 0.238946697, 0.003518656, 0.215765478, 0.819692975, -0.564833236, -0.761415142, -0.237909732, -1.911660080, -0.431903417, 0.149371806, 0.798518087, 1.596950173, 0.384646030, -0.122690466, -0.977275874, 2.147091062, 0.732016206, -1.444233601, 0.503533569, 1.606140077, 0.523581728, -2.067882804, 0.267201467, -0.466840808, -0.954397657, 0.869472598, 0.282870426, -1.038178297, 0.504300138, 0.186300158, 0.303947860, 0.985802923, 0.313011870, 0.540532926, 2.497365291, 0.984298385, -1.062844685, -0.464506730, -1.483266516, 0.197583503, -2.026736071, -0.169392498, 0.549724186, 0.572940546, 0.403158611, -1.901919380, -0.497408783, 0.617646292, 0.779202910, -1.343605070, -0.040339903, 0.917569332, 0.571237416, -1.271930852, 2.032347541, -1.101986721, 0.401626349, -0.374636244, -1.385437023, -0.943960372, -0.054018420, 0.017533228, 0.600716620, -0.348086600, -1.658654688, 1.685267660, 0.864736338, -0.025791136, 3.115899787, 0.144436448, -0.611601005, -0.157208262, -1.900978819, -0.210606506, 0.731370825, -1.577751263, -1.045338832, 0.084390573, -0.552996307, 0.274337417, -0.608135010, 0.369004970, 0.601689292, -0.292676305, 1.013159521, 1.156905297, 0.107826084, -3.178526172, -1.305099602, 1.159651866, -2.550122949, -2.210798298, 1.153334608, 0.492542319, 0.115512202, 0.242114430, -0.766794710, 0.165139932, 1.109427202, -0.447667633, 0.229986560, -0.068247058, -0.317518707, -0.206758572, -0.700991367, -0.480865492, 1.288034476, -0.343648842, -0.305577822, 0.939122154, 0.446328518, 0.292465078, -0.278864451, 0.915966803, -0.308774415, 0.912573957, -1.796507229, -0.287465786, -0.606460423, -0.361654318, -0.599922432, -0.138336037, 0.316617100, 0.388502844, 0.042186959, 0.493227540, -0.844674085, -0.183160890, -0.849635341, 0.355152641, -0.569306739, -1.191446355, 1.143738462, 0.374711767, -1.996757132, -1.122049961, 0.302059205, 0.426663935, 0.232066789, -0.690175851, -0.491658382, 2.138545443, 0.586609408, 0.269033730, -0.988684850, 1.016692546, -1.055018811, -0.675778019, -1.344386495, 0.866128122, 0.428917100, -0.550445293, 2.065223305, -0.351130535, 0.986848924, -0.788238178, 0.101651243, -0.730858194, -0.614357276, -0.184055835, 0.111329256, 0.227778275, 0.386432806, -1.356971876, -1.183639613, -0.061195714, 0.959025606, 1.283758712, -1.585692891, 0.555128280, -0.688819996, -0.695117389, 1.380061022, 1.119313728, 0.455308986, -0.602495449, -1.141234321, 0.270741668, 2.505181519, -0.695418727, 0.188865459, 0.792765943, -0.422228589, 1.175012792, -0.200884084, -0.488023804, -0.702256152, -1.653978605, 0.716271841, -1.496694688, 0.667089562, 0.087416613, -1.031227409, -0.224599758, 0.456909370, 0.445676247, -1.489377145, 0.417173038, -0.659649948, 0.327252885, 1.243374817, -1.384235040, -1.925215190, 0.762245635, -0.548549818, -1.036209825, -1.022327751, 0.201935287, -0.923743870, 0.942982583, -1.862222891, 0.706510043, -2.202028656, 0.899361730, 0.229044004, -0.757391753, 1.275577837, 0.196059811, -1.078983328, 0.107879528, 0.486619266, -0.687160382, -0.004199881, 0.911850173, -1.923384392, -0.727296704, 0.881606769, 0.662122608, 1.199083205, 0.206317514, 0.917102460, -0.930699735, 2.089422704, 0.426887931, -0.016483436, -0.329186741, -0.072229732, -0.970904312, 1.039050307, -0.443121880, -1.098394759, 0.660034465, 1.299359927, -0.214015593, 1.273735819, -0.367281522, 0.134161858, -0.644885518, -0.213422132, 1.706046702, 1.422636024, 2.157043686, 0.751063490, 0.503327948, -2.401498977, -0.520806366, -2.007402634, -1.399624292, -0.429758368, -1.234532490, -0.511883070, 0.510132814, 1.020402662, -0.469933953, 0.139314624, 0.619379988, 1.623908993, 0.676823762, 0.960487519, -1.184205868, 1.563776211, -0.340610905, -0.876782326, -0.285797342, -0.737242068, -0.930340369\n0.0037901\n\n\n2\n0.285876475, -0.202259878, 0.512416048, -0.818121505, 2.290945880, -0.494822111, 0.684053196, 0.835974137, -0.047935720, -0.326603649, -0.714118074, 0.118547423, 0.088356175, 1.745567070, -1.073236169, -0.622895961, -0.009245922, -0.561584538, -2.301729800, -0.511703258, -0.145948620, 1.107737144, 0.160008358, -0.770723150, 1.217913058, -0.203589376, 0.177375466, 0.080027295, -0.588135730, -0.674989351, -1.007563399, 0.246548218, -0.020368280, -1.518412689, 0.365398990, 0.090682464, 0.736714749, 0.022937487, -0.660786574, -0.942946526, -0.256848996, -0.716803079, -0.460561330, 1.106954580, 0.182536168, 0.191617177, -1.228924114, 0.254679917, -1.560924262, -0.969173547, -0.897894345, -0.906254204, -0.808784201, 0.263649556, 0.207438925, -0.953578968, 0.843252727, 1.482461464, 0.044580195, 0.188456380, -1.260054891, -1.879441888, -0.244142269, -0.546156384, -0.646286469, 0.309884011, 0.145016336, -0.566298214, -0.857786260, -2.250854054, -0.896731676, 0.052125949, -0.143235443, -0.110985933, -0.750108766, -1.527208082, 0.572862158, 2.135930066, -0.038766238, -0.312575587, -0.693908359, 0.869314310, -0.427970967, -0.910155283, 1.223076131, 0.478806550, -2.818036971, 1.854472760, -0.723847258, 0.477901518, 0.629137136, 0.626523398, -0.315329176, 1.732471896, 1.782671089, -0.877112663, -0.059011043, 1.896890807, -0.644218925, 1.497302238, -1.439158587, 0.380117304, 0.065125684, 1.048284651, -0.634997200, 0.899918635, 1.644290244, 0.692657012, -0.869354753, -0.230828689, -1.545867370, -0.132883655, -0.778028867, 0.529372670, -0.019685525, -0.730706702, -0.476366009, 1.874626039, -0.968429880, -0.324281413, -0.120509795, -1.330491842, 0.318089585, -1.617197443, -0.617911375, -1.224890172, -0.651003543, 0.712377947, 1.481676790, 1.486466522, -0.928896361, 0.644729101, -0.917837277, 0.609200614, -0.420962872, 1.298572481, 0.264611353, 0.227575798, 0.342958829, 1.571313567, 1.253770469, 0.641575116, 0.365025753, -0.262247302, 0.990768167, 0.822885523, -0.395449175, 0.368006197, -1.072245857, 0.673825921, 0.074644544, 0.595753014, 1.316899269, -0.302954285, -1.456265040, 0.353459353, -0.794269402, 1.492923530, -0.146043869, -0.186943464, 0.067483373, -0.480476577, 0.653582261, -0.392477552, -0.128914851, -0.235784866, -2.713022053, 0.895220956, 0.174489521, -0.048293382, -0.487689850, 2.690010488, 0.130437634, 1.055406537, 0.196201574, -1.057468643, 1.048853048, -0.713808112, 0.435137431, 0.721369952, 0.639506257, -0.221069463, 0.788678172, 0.965076842, -0.949496159, -0.785273326, -0.704509396, -1.247886169, -0.538858757, -0.014683065, 0.248980772, -0.426389527, 0.812335776, -1.360310368, -0.663631291, 2.103998038, 1.009223578, 0.048578113, 0.175783548, -0.031304667, -1.367278109, -0.431422231, 0.460215230, -1.394815393, 1.498836435, -0.878191118, -0.515170107, 0.330107371, 0.178417362, -1.511631137, -0.760805907, -0.258797492, 0.685543251, 0.366535046, -0.013177324, 0.756033848, -1.275194015, 0.285573844, 2.322952734, 0.197935153, -0.974050152, 1.186537214, -1.391426848, -1.581679784, 1.216642316, -0.948056403, 0.058962717, 0.049168798, -0.656163792, 0.607214391, -0.778723387, 0.482168156, 0.542399648, 0.513492791, -0.119934372, -0.038147714, -1.493357400, -0.361164956, -0.647104051, -0.315571748, -0.523828436, 0.672533262, 0.363286475, 0.690948013, 0.396912660, -0.774657607, 1.855059695, 0.109279032, -0.571657671, -1.173346520, -0.424836250, -0.263017574, -0.035611353, 1.265269445, 0.061110142, 0.627821147, 0.526395380, -0.742823141, -0.018559401, -0.897924605, -0.033616937, 2.200886890, 0.631621067, 1.992513749, -1.597726003, -0.877479360, -1.034750843, -0.083775501, -0.665745138, -0.956880457, -0.854862031, 0.630769491, -1.602797241, 1.334295503, -0.573996594, -2.159424063, 0.041308796, -1.817692504, -0.668215878, 0.501086874, -0.755950901, 1.246820580, -1.130738799, 2.256066160, -0.149668917, 0.506345904, 0.417390455, -0.114742217, -0.077500515, 0.679391949, -0.686131884, -0.544684641, -1.064420087, 0.617769878, 1.449330916, 0.280394352, -0.912076315, -0.137957951, -1.351934088, -0.838916347, 1.284454238, -0.549332629, -1.793507793, 0.286813087, -0.221231800, 1.093650726, 0.918298681, -1.262334187, 1.832030774, 0.920232524, 0.585227673, 0.704516296, -1.119164381, -0.103834318, -0.355361433, -0.230137941, 0.199935367, -0.128840822, -0.420765034, -0.152371163, 1.590759753, 2.153686083, -2.209745522, -0.649438819, -0.049462851, 0.717762688, -1.240644040, -0.033286336, -0.306657577, -0.102933319, 0.142619761, -0.826149555, -0.516178539, -0.729561008, -1.691068245, 0.186368642, 0.541230478, 1.019152994, 0.396055062, -1.281797548, 1.429292004, -1.091571404, -1.430624290, 2.085062244, 0.525875571, 0.489839381, -1.669241829, -1.546011390, 1.143721643, -1.529290486, 1.237307622, -0.960197080, 0.578690423, -0.374144041, -1.491662746, -1.116351327, 1.822843860, -1.294999138, 0.917027287, 0.664855860, -0.422859915, 0.108945067, -0.059799113, 0.364488640, -0.096437164, 0.741185390, -0.781719374, 0.404908338, -1.955669711, -1.108953550, 0.755765525, 0.329775659, 0.447374512, -0.092534123, 0.608369127, 0.339049930, 1.296071496, -0.667151921, 0.305979388, 0.257664597, -1.391915770, 0.685403522, 0.006963806, 1.020435408, 0.285562377, 1.055850395, -2.718118699, -0.662139862, 0.021508881, -0.494489181, -0.511644496, 0.001523051, -2.166735097, 0.218306225, -0.185414213, -0.927252802, -2.953482824, -0.344721003, -0.505888202, 0.207137866, -0.099066355, 0.503398239, 0.852288796, -0.109699948, -0.407514905, -1.335701798, -0.955919742, -0.841233106, 0.547735897, -0.328180749, -1.287608814, 0.773374324, 1.637476583, 1.197208580, 0.691683546, -0.404349247, 0.620499687, 0.538841631, 0.528182121, -1.034798682, 1.898118751, -2.235399234, 0.819642004, 0.175975372, -1.242246939, 0.800352076, 0.678576559, 0.753006542, -1.171217305, 0.637894953, 0.425953084, -0.360516503, -0.830334205, -0.295483679, -1.191072733, 1.053141362, -1.681442622, -0.788648910, -0.394240602, -0.762641831, 0.842099670, -1.537766920, 0.014542336, 0.651585973, 0.906950617, 0.735377637, -0.735692535, -1.588427336, -0.102736937, 0.783306982, -0.742381023, -0.485627791, 1.237612559, 0.817314730, -0.898858775, 1.572405419, -1.453701213, -0.877857002, 0.641437081, 1.488425824, 0.626810250, 0.561539488, 1.098877406, 0.523150985, 0.725112936, 1.863547911, -0.172490474, -0.186244810, 0.811653558, -0.272146009, -1.002290093, 1.842211662, -0.893344775, 0.235967504, -0.958511979, 1.858590648, 0.618023680, -2.350684631, -0.936326025, -0.137343200, 1.076194757, 0.656869739, -0.974782988, 0.621585599, -1.311139614, 0.475934804, -2.150064471, -2.647181930, -0.447867648, -0.099534594, -0.724586941, -0.478308021, -0.241761115, 0.362294438, 1.375431170, 0.777130707, 0.566318817, -1.776307095, 1.317910274, 1.569551895, -1.774313123, -1.307823936, -1.719756776, -0.668927031, 0.586530412, 0.280156460, -0.484295440, -0.083567271, -0.781162991, -0.160709309, 0.746930114, -0.844380555, -0.111196086, 1.500912502, 0.411604087, -0.249270170, 0.403612309, 0.454325473, 0.747303083, -1.570628041, 0.677082459, -0.495752305, -1.200728284, 0.523703971, 0.046336616, 0.752580654, -0.581252942, -0.044195476, 2.263126323, -1.542297013, 0.389268049, 0.129156052, -1.937915452, 0.487202958, -1.391070201, 0.154548338, 0.384665775, -0.920652929, -0.765149324, -0.330147883, -0.902967224, 1.064882915, 0.652276790, -0.656020507, 0.383590262, -0.729518238, 0.530888708, -1.371518304, 0.191339461, -0.495679917, -0.640457017, 0.861929217, 0.053230338, 2.706730437, 0.767257998, -0.002019814, 0.090330165, 0.342732432, 0.161009408, 1.523650465, 1.126538170, -0.071045329, 0.161841839, -0.876015032, 1.914247207, 0.027868129, -2.011256490, 1.076746586, -1.057826090, -1.067719225, -1.382805632, -0.413211328, 0.715290587, 0.498411889, -1.262740819, -0.221167352, -1.074698574, -0.692937196, 0.838567281, -0.463443539, -0.552183150, 1.766033985, -1.271325838, -0.242844195, -0.317132654, -0.222384451, 0.316791553, -0.994756508, -0.822748432, -1.413125275, -0.231977442, 0.361197169, 0.188909405, 0.079000228, 0.718012637, 0.304270181, -2.152103054, 0.912520643, 1.413188356, 2.083811451, 0.188696667, -1.319129554, 0.815199820, -1.356801123, -0.336278943, 0.394281201, -1.291201869, -0.209404484, -0.707910915, 0.093305200, 0.030479631, -0.619339187, 0.660987131, -1.551733475, 1.184913556, -0.341819094, 0.155994949, -2.814978758, 1.372051582, 1.094656456, 0.512559909, -0.093970577, 0.920300761, -1.101184657, -0.189299732, 1.639965457, -0.153790686, -0.226809594, 0.776803512, 1.626360291, 0.983588488, -1.278070181, -1.733813749, -2.849682297, 0.751288583, -0.886615364, 0.388953753, -1.401543047, -1.153268713, 0.756350198, 1.145510882, -0.865434670, -2.192508964, -0.518129109, 0.512214638, -0.536925806, -0.656963777, 2.108273178, -0.034912999, 0.444728713, 0.674155081, -1.175809194, -0.241845535, 2.491044428, 0.839727039, 2.052335471, 0.739382364, -0.332765237, -1.004466485, 0.955437207, -0.153366788, -0.383162431, 0.751605252, 1.069829973, -0.688771502, -0.753328151, -1.828325896, 1.182772496, 1.010468174, 0.456588072, -1.131200995, -0.319487599, -2.735411004, 1.407569971, -0.545620008, -1.031169028, 1.136418305, 2.508785895, 1.138994523, 0.249893635, 1.044736686, -0.580399862, 2.202491045, 2.405953920, 1.021650220, 0.085672925, -0.538711805, -1.127912180, 0.730338050, 0.814975490, -0.565752334, 0.530541624, -0.848387706, -1.297493680, -0.935769852, 1.121995568, 0.341892678, -0.388579066, -0.916198582, 0.645812395, 0.665704280, 2.054968706, 1.405461460, 0.530326486, 0.327679224, 0.473815278, -0.310943080, 0.976336012, -0.966957130, 0.077213237, 1.408219059, -0.578286376, -1.428136158, 1.226784090, 0.089508712, 0.033100492, 0.587804550, -1.145816715, -0.248149033, 2.006329834, -0.126254660, -0.197302695, 0.802954430, -0.356246236, 0.699962401, 1.373199875, 0.985764803, 2.201173150, 1.756473135, -0.772449824, 1.630591392, 0.935606805, 0.113084812, -1.993780088, -0.369825748, -0.575663325, -0.162603743, -0.028244597, -2.027923521, 0.861415619, -0.537669384, -1.101751634, 1.241627777, 0.542168848, 2.331742431, 0.369763404, 0.886061978, -0.942667424, 0.682254660, -0.037393447, -0.407365346, 1.616048869, -1.127872599, 0.101274306, -0.906565691, -1.029127792, -1.283158495, -1.063589614, -0.630419106, -0.056197259, 0.195876854, -0.746351330, 0.833045584, 0.223917694, 0.349601857, 1.274433417, 1.762560451, -2.066924030, -0.675484659, 0.111714604, -1.886243540, -0.113984285, -0.463007876, -1.142300331, -0.508876349, -1.089122811, 0.887917533, -0.243334361, 0.368842979, 1.208214005, -0.009853612, -0.754842764, 0.154704375, -1.276766586, -0.193171932, -0.724556593, 0.166851474, 1.456355766, 0.243008022, -0.275405309, -0.174901299, -1.026580762, -0.126379305, -0.642302287, 0.406716100, 0.155739202, -0.878200828, 0.414690754, -0.205010133, 0.533848638, 0.097774785, 1.459899789, -1.153192969, -0.216943633, 0.177777311, 2.136704083, -0.735788310, -3.359915647, 0.773248790, 0.417863670, 1.022511226, -1.381475409, 0.246654055, 1.126925082, 0.663471012, -0.860459956, 1.718249344, -0.494285338, 1.070913094, 0.789514746, 0.219152727, -0.434969988, -0.335180659, 1.057423272, -0.331258562, 0.647669636, -0.534919884, 0.092392519, -1.387194599, 1.519344642, 0.811702226, 0.774140419, -0.703787071, -0.050308282, 0.505904201, 1.367651250, 1.343235005, 1.215545885, 0.383197927, -1.439852082, 0.494909060, -0.871689025, -1.429522897, -1.488822653, 1.230428904, -0.905490182, 0.066301715, -1.434882291, 0.019218056, -0.474563528, 0.389486240, 0.735016067, -0.071200987, 0.465031478, 1.251348528, -0.525354709, 0.243126407, -1.087468441, -0.397081435, 2.328991940, 0.228896930, 0.602948104, 0.104250268, 0.433066568, 0.065273891, -0.418774038, -0.015346699, 0.551235849, -0.520306050, 0.051174356, 0.425994472, 0.873081040, -1.967326747, -1.017757514, 1.117439175, 0.539616528, 0.088346097, 0.425727796, 1.667975836, 0.598419893, -0.354266306, 0.755712053, 0.823791824, 0.529028154, -1.702481320, -1.570320794, 1.107150762, -0.833857409, 0.032006065, -1.185191705, -0.463462275, 0.837120834, 0.107562202, 0.484385948, -0.323617900, -0.222799789, 0.096746736, 1.019348537, -0.283388813, 0.160281313, 0.034468467, 0.143059764, 0.410040495, -0.716795342, -0.594003142, 1.785402277, -1.331863016, -0.257993230, 0.699193007, 1.003561387, 1.358994047, -1.282757131, -1.147521660, -1.128954704, 0.670276891, 0.409648529, -0.005722589, 0.624588922, 0.433630258, -0.299303537, -1.440484963, -0.019972890, -1.091114677, 0.415029480, -1.056074827, 0.193304745, 0.057263493, -1.383679802, 0.345442309, -0.013227596, -0.173299277, 0.636780679, -0.331426709, -0.821068359, -0.787915880, -1.288715695, -0.233198674, -0.829136957, 1.377052756, 0.139311925, -2.792351344, 1.141409688, 0.578572844, -0.068128269, -0.319124757, -0.640722091, -0.234070126, 0.496901619, -1.135930408, -0.159827733, 0.289744068, 0.744949344, -0.982717749, 1.171191094, -0.350665973, 0.715480085, -0.091348385, -0.369201823, 0.930224197, -1.050827962, -0.420814972, 0.881724573, 0.020619961, 1.195930241, -0.789800236, 0.496419316, 0.852210793, -0.426626133, 1.152600798, 0.532027899, -1.177274594, 0.544815367, -0.523608168, -1.779364374, -0.171362559, -0.846851358, -1.893451525, -0.789199500, 1.595305293, 1.021749249, -2.163936849, 0.712648161, -0.532048993, -0.042338410, -0.545258012, 0.080251633, 1.059791363, -2.037192075, 2.360977297, -0.548277412, -1.892667840, 0.930744806, 0.615691575, -0.542178169, -0.886529725, -0.497588091, 0.491650161, -0.795888134, -1.653922138, 2.049305762\n-0.0282983\n\n\n3\n-0.008738179, -1.731089607, -0.800307573, 0.083230525, 0.589193733, 1.279732496, 0.673674587, 0.202668294, 0.502339569, 0.244678677, -1.383997327, 1.680757120, 0.903803911, -0.078987523, 1.141537203, -0.573870262, 0.286760324, 1.080644549, -0.480111451, -0.097690551, 1.734365825, 0.098260553, 0.016242804, -0.599256563, 0.102693885, -0.326842368, -1.143485749, -0.600251885, -0.946557747, -0.867519445, -1.065987677, -0.087067937, 1.653882488, 1.517346882, 0.896086154, -1.146785784, -1.631992499, 1.152531847, -0.477394769, 0.323136052, 0.537180021, -0.599594081, 0.507024322, 0.397804898, 0.170363858, -0.511149947, -0.010105545, -0.915725698, -0.667079388, 0.176987075, 2.263504626, 0.698946195, 0.301687702, -0.486464330, -0.899176894, 0.477051361, 0.771564680, 0.231903489, -0.432100541, -0.975644213, -0.486046906, 0.477318118, 0.789357941, -0.028715604, -2.860664147, 0.079844893, -1.469150651, -0.603509437, 0.613308071, 1.438072749, 0.716198960, 2.024533820, 0.772022148, 0.310066900, -0.925560590, 0.358824998, -1.121375297, 0.103007785, -3.697751884, -0.568085512, 1.099778041, 1.860794810, 0.807009544, -0.707107116, 1.609766710, -0.478621083, -0.448248547, 0.046897787, -1.037930510, -0.024993786, -2.610045020, -0.310858904, -0.900763689, 1.588411746, 0.839151272, 0.415512178, 1.285888536, -2.238559558, -1.461889695, 0.755031584, -0.450188705, 0.984993636, -0.659773553, -0.885698705, -0.183119540, -1.499706587, -0.549438284, -0.153642627, 2.376245341, 0.091082536, 0.435803486, 2.730594847, -0.076183204, -0.887912351, -0.052994282, 2.078178751, 0.573313363, 0.841147931, -0.329115929, 1.226275159, 0.038549922, 0.365754976, -0.058877345, -0.892811952, 0.904197694, 1.027454087, 0.023560154, -0.495534065, 1.036870310, -0.235982982, 0.891885256, 0.326418777, 2.816991884, -0.671339024, -1.331283115, 0.489113729, -0.361946505, -0.793665668, -0.236462118, -0.403803483, -0.063145045, 0.112953201, 0.284833194, -1.415758184, -0.426141925, 0.169361980, 0.207983632, 0.060535663, -0.821291852, 1.548847338, -0.253886065, 1.008677036, -1.945603390, -2.408961837, -0.586342098, 1.094049224, -1.124449027, 0.965764185, 0.119499096, -0.727906348, -0.575624058, -0.542845800, -2.036208266, 0.535166613, -0.859159366, -0.905627021, 0.602740991, -2.121126789, 0.794553514, -2.103262625, -1.097515001, 0.003808987, 0.342159266, 0.088677188, -2.374542927, -1.065956786, 1.715418864, -0.191746300, 0.154412052, -0.239302523, 0.027131792, 0.523454695, 0.796526583, -1.657524412, 0.448634691, -1.542579685, -1.183193008, -2.122997167, 0.397676745, 0.154007448, 1.186419268, 0.076548465, 0.056406584, 1.330921709, 1.540798571, -1.467824104, 0.195711450, -0.054420017, 1.166574056, -1.188344739, 0.424218575, -0.508614877, 0.144934226, -1.311339585, -1.385510901, -0.095730687, -1.656198325, 1.033687021, 0.859524615, 1.289597305, 0.756777473, -0.798693814, -1.198611099, -0.614499219, -1.222580579, -0.922134293, 0.978438192, 0.626176490, -0.161939408, -0.671285248, -0.493538115, 0.226641545, -0.899114939, -2.204390176, -0.102736943, -0.331325933, 0.002787162, -0.407514111, 1.610711321, 2.236545568, -0.335270121, 0.678659711, -0.288222303, -1.333078943, 0.232671108, -1.070792539, 1.002556427, -1.161288491, 1.280520159, 1.875321945, 0.547164010, 1.525111148, -1.117412308, 0.823413397, 2.438158544, -1.004818245, 2.554529855, -0.902707333, -1.521758310, 1.594776544, 0.574258870, -1.142581303, 1.166190499, 1.582596827, 0.310470623, 0.076832499, -0.095987612, 0.728080456, 0.884627214, 1.441892188, 1.378048981, -0.223051349, -0.221785402, 0.512346458, -0.966958563, 0.247041817, -1.187736487, 0.990502095, -0.502344245, -1.383996331, 0.343775260, 0.138149460, -1.549530510, -0.209550485, 0.746585610, 1.460900591, -0.950976512, 1.032218627, 2.091630524, 0.598007697, -0.328600254, -0.293932240, -0.822092733, 0.340223970, 1.114234850, 0.490856607, 1.120074722, 0.026269828, 0.096180777, 2.231526269, 1.376057399, 0.507093708, -0.206194334, 0.496648172, 0.704628452, -0.080878680, -0.753100289, -2.065075870, 0.179833912, 1.220376441, 0.693104947, -0.072916538, 0.237999888, 0.462485689, -1.009409057, 1.231669281, 0.475626964, 1.351945452, 0.382320124, 0.221649522, -0.062548868, -2.197679404, -2.647229380, 1.112018342, -1.010171154, -0.917965520, -1.103226211, 1.131881004, -0.095371679, -0.007214550, 0.531064718, 0.451046194, -0.629637864, -0.901763605, 2.262064727, 0.561145997, -2.073518365, 1.550190902, 0.200908215, -0.434051627, 0.058343177, -0.738937238, 0.736993449, -0.019069855, 0.147433788, 1.069053129, -0.695344955, -1.306024632, 1.040134404, 3.310327005, -0.505342102, -0.404125969, -0.643780616, -1.200062712, -1.151531446, -0.287703174, 0.345282026, 1.094834778, 0.324693580, 0.263146315, 0.008185711, -0.289373524, 0.280121095, -1.239883559, -0.237320176, -1.031319588, 0.965086483, 0.647165835, -0.593104416, 0.704353782, 0.399025857, 0.426952279, 0.056425533, -0.072448503, -0.861217022, 0.045220031, -1.061431735, -0.112312297, -2.079990661, -0.035756872, -0.301654522, 0.737622083, 0.069074102, -0.759888395, 0.651925689, -0.979139938, -0.430807314, -0.129745327, 0.350650330, 0.002018607, 1.067624896, 0.943097863, -1.244000381, 0.028498127, -1.564076501, 0.027849667, 2.215388683, -0.436651548, 1.344039646, -2.090369172, 0.286318545, -1.882029549, 0.576800067, 1.336577790, 0.069095625, 0.877834171, -0.906711179, 2.169048834, -0.965482726, -0.350199761, -1.903298969, -0.290200807, -1.929769685, 1.084044432, 0.313222938, -0.619853570, 0.992022109, 0.745005395, 0.602317915, 0.781893929, -0.163446296, 0.331582263, 0.701862574, 0.326889239, -1.126736543, 0.674521763, 2.470635585, -0.157626472, -1.049332559, -0.525993363, 0.642184692, -0.063775303, 0.348991652, 0.261741416, -0.314802462, 0.298681772, -0.143219479, 0.219582865, 0.023127731, -1.204748395, -1.375631844, 0.869791735, 1.362931511, 1.026785240, 0.136360371, 1.180363850, -0.153404638, -0.895487669, 0.809928201, -0.372352816, -1.305095372, -0.431018310, -0.901419662, -2.464045894, -0.004797200, 0.270501102, -1.535587418, 0.372298009, 0.047021586, -0.299555567, -0.076010730, 0.621015412, -0.460696255, 1.623660819, 1.546317472, 0.289302803, 0.924048029, -0.206429096, 0.290377820, 1.023797584, -1.430087736, -1.093206758, -1.653103953, 1.489802873, 0.010376003, -1.466677547, -0.149311839, 0.055359271, 0.225589108, -0.076375548, -1.375195834, -0.914798963, -0.166396582, -0.049005981, -0.376721351, 1.041427842, 1.312892092, -0.383813356, -1.548027435, -1.022492977, -1.397241017, -0.277164894, 1.417490885, 0.237493735, -2.153946099, -0.770450819, 1.083359208, -0.458357742, -1.609471741, 0.832038537, -1.004097349, 0.316891725, -0.518042205, 0.109462150, -2.139227291, -0.991166055, -0.140439043, 1.927560947, 1.471350176, 0.812448336, -0.911618051, 0.941911639, -0.184531798, 0.982120894, 0.490278505, 1.246589261, -0.407935056, 0.099741191, 1.781070994, -0.989140879, 0.454249999, 0.240243287, -0.125406890, -1.169108649, -0.891319822, -0.708563300, -1.391544890, 1.290937414, 0.150284440, 0.502679500, 0.097362368, -0.439952874, -1.816065902, 1.342694209, 1.370778960, -0.040103600, 0.910070805, 0.528051532, 0.026034319, -1.451520852, -1.257713726, 1.730856648, 0.350464302, 0.005240072, -1.033343354, -0.217148940, -1.332264561, 2.257003140, 1.177377434, -0.899259580, -1.805300747, 0.563434647, 0.459630838, 0.914807180, -0.719913604, 0.675807504, 0.858278346, 0.430617661, -1.325233950, 0.382317588, 0.689038498, 0.452277641, -2.871323405, -0.429250466, -0.271028678, 0.057913552, -0.686272173, -0.094119759, -1.126835963, 0.534069191, -0.433701845, 0.712532373, -2.474155004, 0.065118830, -1.245492122, 0.053474967, -0.327923526, -0.424137778, 0.094834190, -0.925813040, -0.301017349, 0.917602103, 1.415713307, -1.200771404, -0.842497906, -1.520475204, -0.065633868, -0.261775606, 0.817608184, -1.527942799, 1.067270053, 0.805552848, -0.467926144, -1.034195682, 1.558147259, -0.017363222, -0.842851009, -0.539759290, 0.379524729, 1.528801532, -2.485313317, -0.791470619, 0.305210264, 0.088128011, -0.384765763, -1.518032261, -0.501312587, 0.153739109, -0.100534285, 0.852418553, -0.312906240, 0.223553754, 1.272582972, -0.015513483, -0.171350374, -1.180996680, 2.072376268, -0.685216292, 0.536298787, -0.573512759, -0.072705105, -0.609059208, 0.063276975, 0.281298784, 1.115393068, 3.006929309, 0.637622473, 2.145161439, 0.632840399, -0.486689179, -1.204703136, 0.996637481, -0.622245555, 0.563289220, 0.031229169, -0.525329000, 0.490514727, -1.062923612, 0.854026480, 0.338507149, -0.181407238, 1.166036207, 0.755825680, 1.927331853, 0.678182587, 2.040147948, 1.051566004, -0.499480118, 1.153716813, 1.136940965, 0.163578320, -0.980492112, -0.930636052, -0.438024247, 0.707209623, -0.850608252, 1.392070004, 1.197381707, 0.707758931, -1.709626609, 0.620726917, -0.840636107, -0.575381314, 0.917915936, -0.314564748, -0.911021677, 0.353460005, -2.009276714, 0.413652513, 0.011206169, 0.775490847, 2.444637416, 0.060827667, 1.716561128, -0.110957959, 1.339262978, 1.392942243, -0.118314063, 0.072675812, 0.847769827, -0.500655582, -1.631268196, -1.035702070, -0.209315966, 0.247248613, 1.099586846, 0.711149113, 2.028484741, 0.948135146, -0.498569478, 0.718717544, 0.536279162, -0.172267315, 0.183726579, -1.075591694, 0.775590673, -1.921794466, 1.207664155, -1.308423647, 0.416549370, 0.098125920, 0.020198589, 0.354205187, 0.496259910, -0.262627918, -0.085925537, 1.905145567, 0.857586468, -0.259148094, -1.826313166, -1.257523650, -1.003184163, 0.072242897, -1.169708664, 0.813677693, 0.264749063, -1.214665349, -1.012187800, -1.246427496, -0.745487312, 2.047743838, -0.592134197, 1.859893020, -0.516992675, 0.158430909, 2.242947384, -0.645865580, -0.528186813, 2.375639150, -0.221535975, 0.071995115, -1.162335372, -0.565537576, 0.624877900, -1.837033888, 0.840936323, 1.476076121, -0.902764223, -0.801463298, -1.582321110, 1.322368230, -0.663007703, -0.898994125, -1.483587378, 0.817826659, -0.998929788, -0.486901362, -0.424226937, -0.211106195, 1.279476146, 0.167914152, -0.624178754, 0.768332494, 1.497415382, -0.345915573, 0.494941388, 1.024726746, 0.568908902, -1.305436827, -0.482185797, -0.007248805, 0.459200540, 0.652530314, 1.632610852, -1.244437456, -0.102139996, -0.352320586, 1.527539128, 0.059200835, 0.800030292, 0.880485124, -0.414010463, -1.473288203, -1.022759651, -0.289775390, -1.062219598, -0.569767680, 1.855992250, 0.359021857, -1.702093932, 1.921048865, -0.702366858, 0.918432737, -0.062067241, 0.570279831, 0.795041020, 0.710051256, 1.929112428, -0.036205708, 1.748905458, -0.779810075, -0.911265304, -1.515725719, -0.332376054, -2.385951495, 1.303934513, -0.418366878, -1.318281621, 0.530244671, 0.085605533, 0.183879000, -0.406496201, -1.095418857, 0.801708815, 1.339701539, 1.804202684, 0.564162537, -1.218249092, 0.035690504, -0.268553734, -1.013469015, 0.540928337, 1.636077815, 3.130601676, 1.142889526, -0.465766896, -0.967653930, 0.814706438, 0.098286350, 2.855764427, -0.308316704, -0.935993941, -1.476028270, -1.396945033, 0.939401609, 1.425907752, -0.156225759, -2.183156601, 1.826139656, 0.106455687, -1.841030198, 0.898148034, -1.229950285, 1.179082750, -1.753429163, 0.442987302, -1.785823624, -0.282180524, 1.046154034, 2.398362105, 0.602724596, -0.431581021, -1.027935920, 0.714076734, -0.043251209, 1.322817269, 0.701568809, -0.317075375, -1.214682939, 1.436373469, -0.409272275, -1.125744061, 0.671813709, 0.643701656, -0.429353623, -2.027526564, -0.271349635, -0.639735473, -0.542367526, -0.472898955, 0.126311651, 0.273528274, -0.591015521, -1.107959276, -1.694366927, -1.843294739, 0.562362817, 0.240734022, 0.562008591, 0.319224979, 0.451811350, 0.712834471, 1.364312648, -0.602697324, 0.934370921, -1.054689426, -2.074739365, -0.354313531, -1.622464929, -0.715083118, 0.171840829, 0.609386881, 0.175884179, 0.355251105, -1.922964412, 0.524782659, 0.199776136, 0.311020246, -0.814993410, -0.241507225, 1.039354211, -1.356141092, -1.737946687, 0.268636654, 0.764061439, 0.256561440, -0.067197418, 0.544310373, 0.820531380, 0.327115150, 0.343186565, 0.770891688, -0.681579504, -0.462391690, -1.214100516, -0.079435976, 0.201549585, 0.298204838, -0.210077304, -0.291530665, 1.663979597, -0.486403482, -0.820254790, 0.336629451, 0.124651377, 1.049259386, 1.964077392, -0.007929999, -0.435878843, 1.462073822, -0.509881746, -0.894223273, -0.302397777, 0.672842604, -1.636688684, -2.580629154, 1.453164469, -0.633720929, -0.110182205, 0.281605202, -0.598019147, -0.306349339, 2.244805786, 0.522244549, -0.118400474, -0.495277839, -0.020090863, -1.507384055, 1.312744353, -0.982620217, 0.241499766, -0.605062341, -1.340673345, 0.603021828, 1.367010076, -1.128834735, 0.634654226, 0.344534329, 0.592239956, 1.112643973, 1.191776292, -1.096383083, -0.196719432, -0.685832049, -2.447671658, -0.353320203, -0.854262166, -1.618977285, -1.302341752, 1.031501395, 1.155369541, 0.496244493, -0.003344900, 1.420027166, -1.933483987, -0.013586987, -0.052874582, -0.265002899, -0.098595451, -1.578492501, -0.248273602, 1.652532640, 0.011079306, 1.048657604, -0.786745604, 1.113064378, -0.044199926, -0.492673383, -1.100745619, -1.166420522, 0.676985216, 0.913858562, 0.484009926, -0.273993962, -1.048575487, 0.785266767, -0.289463423, 0.184769044, 0.154805859, 0.011516957, 0.423427362, 1.859818695, 2.098671607, -0.306319194, 1.384153991, -0.919158519, -1.201894436, 0.640543761, 1.805738921, 0.324656441, 2.124769118, -1.056050916, 0.812329744, 1.651623288, 0.452677461, 1.130882695, 0.445545075, 0.738406021, 1.133077794, -0.941342881\n0.0140533\n\n\n4\n-0.713427649, 0.327011944, 0.785237396, -0.795413291, -0.033571738, -1.236616159, 0.108050722, -1.279797735, -1.265526395, -1.824989875, 0.885706304, 0.405068345, 0.179671532, -0.517893011, -1.255636654, -2.390852794, -0.991637006, 1.048680989, -0.919736328, 0.744062588, 0.928337059, -1.593145630, 0.110196278, 0.495122044, 0.533927948, 0.553805875, -1.805799844, -1.377906794, -0.682524619, -1.101904595, -0.954035270, 1.364088376, 0.085035373, -0.143475863, -0.795201884, 1.641012236, 0.446804569, -0.892098784, -0.042058545, 0.683115061, -0.648998451, -0.314063380, 0.308667380, 0.294167403, -1.883819413, 0.273666271, -0.934336960, -0.562312629, 0.600277779, 1.018308108, 0.960212901, 0.927506877, -1.899639728, 0.794295029, -0.584617343, 1.371273248, -0.079919754, 0.714304442, -1.294091860, -0.241447107, 0.564629589, 2.216761768, 0.707513844, -0.823585743, 1.424439690, -1.471536228, 0.306297826, -0.831509047, -2.044193591, -0.218044457, -1.392069870, -1.348200700, -0.333116472, -0.273424690, -0.281018005, -0.610937043, -0.400204273, -1.263206864, -0.196125148, -1.553624191, -0.524800259, -1.285833926, -1.310004093, 0.854077897, 0.513668623, 0.209693487, -0.838134089, -1.075026036, 2.017074740, -0.376243734, -0.199440021, 0.158657027, 0.257244527, 0.317428300, -1.592999906, -0.077460693, -0.727385911, -0.364990261, 1.126260154, 0.847341667, 0.337105046, 0.100800943, 0.188547560, 0.824949682, 0.658856095, -1.124910796, -1.079788711, 0.209588553, -1.548597646, -0.205326728, 0.031169737, 1.920354672, 0.264268264, 0.953249583, -1.419321715, -1.358017185, 0.725933952, -0.437048709, 1.444614991, 0.952989257, 0.866096844, 1.478942909, 0.770309174, -0.361970029, 0.520437704, -0.099742115, 1.170480130, -1.491323644, 0.232442641, 0.298554403, 1.104238729, -1.405638689, -0.078561380, 1.194931959, -0.676090349, -0.374959704, 0.663446796, -0.390259466, 0.232308738, 0.442751175, 0.464758963, 0.880067606, -0.103502987, 0.675733644, -1.893418740, -1.123799432, -1.394260652, -1.478399491, 1.831013208, -0.161502976, 0.289208855, 0.387868896, -0.579345720, 0.638834030, 0.578020515, 0.176585956, 1.313248048, -0.619822868, -0.608711618, 0.532150849, -0.644852426, 0.172526353, -1.173519337, -1.416472945, -1.946941334, -1.797953672, 1.260328173, -0.486091587, 1.535410421, 1.771653371, -0.503465731, 2.100189960, -1.304941844, 0.994735348, 0.953550246, 0.463187336, 0.121909426, 0.599779189, 0.956733308, -0.360561267, -0.815841338, -0.829510915, -0.524569623, 1.272850870, 0.482367457, 1.104194319, 2.661847405, 0.192362452, -0.691675505, -0.682231191, 0.048240299, 1.566596178, -0.543170111, 0.182889115, -0.859022678, 0.019974666, -0.406558304, 1.538651757, 0.469951699, 0.751499892, -0.287273423, 0.081619061, -0.310189743, 0.651662179, 0.943606508, 0.079152755, 0.562786074, 0.743275857, -0.027122707, 0.887955713, 1.833280561, -0.592272115, 0.300003731, -0.530809784, 1.138911786, 0.569218487, -0.112221993, -1.633764638, -0.644541766, 0.014325247, 1.426241006, -1.173222467, 1.112232698, -0.162750059, -0.494195625, -0.370150940, -0.289196578, -0.421278262, 0.945803295, -1.315619229, -1.969623898, 1.370548278, 0.289706706, -0.258200084, 1.749114234, -0.073816919, 3.288542090, 0.832330754, -0.165304204, -1.679478468, 0.387714358, 0.055554894, -0.233651097, -0.510666064, -1.455270258, 3.107342859, 0.472830424, 1.433788522, 0.996716486, 0.635109397, -0.616564699, -0.463629524, 0.009516440, -0.421202566, -1.680887729, -0.328117788, -0.280981409, 0.569754957, 1.114350912, 1.373812878, -0.042174200, 0.746155531, -0.727021042, 0.442690808, -0.414142267, -0.381033215, -0.513513874, -0.534564552, -0.904490597, -1.287804735, -1.107269032, -0.485687699, -0.187281910, 0.251080082, -0.040373549, 2.786243288, -0.680158563, 1.344111147, -1.577209446, 0.378729029, 0.431080053, 0.828866718, 0.095095364, -0.293133916, -2.571826546, -0.220629813, -1.858539353, 0.370740474, -1.231748207, -1.540252836, 0.397745834, -0.653889469, 0.949790317, 1.214037264, 0.843830233, 0.444878809, 0.244373857, -0.224122063, -0.682125050, -0.557827943, -0.680081473, 1.282218498, -0.143240547, -0.633009159, -0.874307613, 1.250746091, 0.198238479, -0.022607462, 0.331022898, -0.865247820, -0.218178783, 0.445341063, -0.132731965, -1.228647757, 1.018055026, -0.379044531, -0.552687480, -0.624059497, 1.221997982, 1.026475207, 0.705046640, -0.146251074, -0.636277295, -0.772726930, -1.160090839, 0.153546102, 0.156911464, 0.248460600, 0.353385395, 0.517200658, 0.731813417, -0.153343081, 0.176250088, -1.909905511, -0.574783977, -0.515702863, 0.303250911, -0.034429748, -0.862138858, 0.907230192, 0.129606543, 1.180404060, 0.852855517, -0.931473504, -1.025091199, 0.451323420, -0.108055776, 1.557840570, 1.295878486, 1.073275497, -0.085044237, 0.027025929, 0.758263427, -0.703932399, -1.224886832, -0.910137127, -0.188255501, -0.499837722, -0.728102528, 0.120449921, -0.581690322, 1.948028993, -0.757591053, 0.518391947, -0.512214413, -0.238157097, 1.046543414, 1.120228707, -1.248822610, -0.823774331, 0.475832252, 0.142577455, -1.952432812, -0.957627439, -0.260977044, -2.095643443, 0.724093519, 1.813986241, 0.513330960, -0.416892608, 0.950377613, -0.265848286, 0.173145556, 0.679364601, 0.896954963, -0.367389177, -1.332913584, 0.573154159, -1.274085004, -0.743142861, 0.337437336, -0.140724136, 0.347409680, 0.070993482, -1.859182107, -0.049501851, 0.307044157, -1.682268710, -1.314120788, -1.469318681, -0.071942118, 0.094106920, -0.593004918, 0.157843773, 0.491694497, -1.490177869, 1.416808564, 1.252933744, 0.442213689, 0.468253931, -1.101702163, -0.372179794, 0.324750137, 0.495638638, 0.191208047, -0.356099810, -1.781671192, -0.513482600, -0.875523598, -1.051143345, 0.049785582, 0.957816708, -0.094737828, 0.220871699, 1.078076915, 0.012329701, 1.355955976, 0.575359658, -1.662377421, -0.102599094, 0.110741293, -0.052771504, 0.842796643, 2.040019995, -0.512456310, -0.838900835, 0.177505496, -0.261367634, -0.829952187, -0.458356716, -0.067708008, -0.327857665, 0.219963251, -0.002223389, -1.491604320, 1.930000505, 0.201218651, -1.782239068, 1.117224889, 0.011259715, 0.915677150, -1.285706777, 1.378662754, 0.856680520, 0.214403918, -0.032758429, 0.637406971, -1.590454007, -0.033356507, 0.528846953, 0.513441753, 0.709704387, -0.049748440, 1.593169414, 1.598708786, 0.319539084, 1.053521926, -0.591498637, -1.810212309, -0.345761264, 0.411851364, 1.121455693, -1.847149122, -0.363937279, -0.911797276, -0.141016577, 0.142444948, 0.318410657, -0.081860616, 1.563371726, -0.424969604, 1.624536838, 1.001697753, -0.599788105, -0.032910958, -0.536074206, -0.679055531, 0.014761258, 0.749407148, -0.571499614, -0.295692739, 0.194678268, 1.450767346, 1.982648699, 0.427412257, 1.074814380, -1.216308112, 1.736529983, -0.754311907, -0.983959615, 1.357691759, -0.500210745, 1.478802915, -1.846263829, 0.271232259, 2.022588091, 0.084218575, 0.234694233, 0.063188653, -0.989596380, -0.026115166, 0.758417754, -1.248876426, -1.049920146, 1.457435760, -0.806057012, -1.274583812, -0.275448289, 1.110964157, -0.411636376, -0.104714229, -0.857376015, -0.088398344, -0.657986725, 0.676869142, -0.879700204, -0.165960470, 0.938614398, 1.472178069, -0.923887681, 0.144150654, 0.779359787, 0.707302899, 0.950020271, -0.987436757, 1.033961039, -0.883538570, -0.395191829, 1.456778280, -0.299298667, -1.317218103, -0.921517023, -0.438004496, 0.662419458, -0.608603637, -0.217299921, 0.666121212, -0.404767582, -1.459923136, -2.169782359, -1.432396023, -2.107934052, -0.083532240, 0.081931766, -1.575142995, 0.270235045, -1.278032670, -0.642417333, 0.706660960, 0.195763632, -1.071182144, -0.556385065, -1.187888508, 1.667432653, -2.212780101, 0.112524833, 0.083054702, -1.374862268, -1.443729682, -0.300703211, 0.246562379, -1.263229306, 0.100483103, 0.137091097, 0.656011287, -0.308767184, -0.320383334, 0.480861682, 0.523300711, -1.062233765, 0.326422455, -0.912809122, 0.137619433, 0.120964638, -0.475737396, 0.228532850, -0.109312221, -0.944545663, -1.269635460, 0.406028996, -1.169877708, -0.996278713, -0.632922871, -0.780584664, 0.017094348, 1.231213280, -1.278817392, 1.956747567, 0.568559229, -1.721351706, 2.130329061, 1.390610601, -0.131521634, -1.718367793, 0.159810864, -2.308426452, 0.087968286, 0.223471566, -0.242688343, -0.884100790, -0.744986671, -2.055779108, 0.410222726, 0.532557888, -0.791301737, 1.449511196, 0.501432885, 0.075141028, 1.338451820, -0.663887835, 0.814111594, 0.436632907, -1.045812111, 0.798388735, 2.089213062, 0.435987541, 0.374289724, -1.090476964, 1.756481524, 1.173073842, -0.762341164, 0.537903913, 1.006410891, -0.086958838, 1.081591702, -0.081808197, 0.341708035, 1.375470193, -1.516695048, -0.758849954, -0.361163747, -0.530175061, -0.894026117, -1.151075042, -0.309718372, -0.565075304, 0.573301405, -0.229684379, 0.189718339, -0.356052767, 1.757934153, 1.521365983, -0.108228866, -1.453344735, -0.229275448, 0.295157801, 0.498290318, -1.364735287, -1.980888680, -1.364674384, -0.796810112, 0.560319384, -0.719836697, 0.674583119, -0.540813303, 0.389596526, -1.031839285, 0.734651378, -1.368348708, -0.514943975, 1.690371568, 2.056103907, -0.036572012, 0.526748509, -1.910497619, 0.491880294, -1.139773085, -1.020560551, -0.698118813, 0.124183332, -1.083337715, -0.703261420, 1.793625349, 0.641292210, -1.249188105, 0.294231407, -0.603898625, 0.734685886, 0.474249883, -2.448570434, -2.636210113, 0.153288034, -1.050873081, 0.176182559, 0.584645361, 0.481242732, -0.264649319, 0.231433286, 0.054155261, 0.659679196, 0.753013831, -0.141275824, -0.765206556, -0.816581458, 1.163272255, 0.558091529, -0.264943002, -0.087736737, -1.927008653, -0.389615510, 0.503113663, 0.539476995, -0.981032891, 1.008119234, 0.419291831, 0.129065989, -0.021471291, -0.437179564, 0.938823288, 0.374035823, -0.457742410, 0.532294936, -0.353864422, 0.285021310, 0.634118905, 0.023241656, -0.279771453, 0.559100223, -0.136355798, -0.679504328, -0.644640984, 0.949078458, -0.675301203, -0.097869712, -0.579702962, 1.181605299, 0.555865271, -0.267305895, 1.307325592, -0.516566695, -1.948779974, -0.102184666, 0.274803244, 0.850314990, 2.973801359, 0.678878155, 0.160820054, 1.469842775, -2.073882049, 0.001776201, -0.340242153, -0.543158024, -0.411201430, -0.921808532, -1.309180006, 0.217953506, 0.979927164, -0.397277911, -1.430023807, -1.143901949, 1.058917733, 1.386452470, 1.834871429, -0.813352471, 1.113618104, 0.127546112, -0.107629079, 0.146226844, 1.070613603, -0.414175020, 0.170566040, -1.473376021, -0.369259984, -1.002574076, -0.063330564, -0.884226293, -0.457072389, 0.734335617, 0.773028440, 0.101621841, -1.281753698, 0.107626403, -1.424102237, -0.770892605, -0.226512606, 0.058285616, 0.343149010, -0.629296716, 1.000232444, -0.968024566, 0.895155074, 0.465431665, -1.348185478, 1.562586006, 0.565948157, 0.088085765, -0.001021268, -0.456157111, 0.224666193, 0.881121908, -0.798440520, -0.587162258, 0.658064578, -1.169518775, -0.564724450, -0.346577759, 0.683240334, -1.076365623, -0.498385780, 1.377515441, 2.298100050, -0.264200333, 0.319381412, -1.527290581, -0.581497125, -0.535609757, 1.142808553, -2.781048820, 0.375985561, -1.942764437, -2.405743511, -1.652961749, -1.637113131, -1.242546024, -0.761604715, 1.112290192, -0.467890010, 0.146332878, 1.798896964, 0.815028076, -0.428597795, 0.227020663, 0.307829747, 0.521854086, 2.487340830, 1.313850155, -0.638781822, -0.130263452, 1.555170527, 0.494123499, 0.583294053, 0.810882383, -1.590638153, 1.527286547, -0.554771078, 0.344649408, 0.138172492, 0.048850618, 0.968580724, 1.547084812, 0.309730543, 2.288283779, -1.309155477, 1.010928630, -2.303216809, 0.200979026, -0.612933983, 0.201598382, -0.053657962, 0.146328939, 1.508912683, 0.957990424, -0.373475098, 0.726449607, 0.289919330, 0.063589768, 0.115151150, -0.324488496, 1.829899001, -2.308228305, 0.991624927, -0.611875864, 1.148120366, 0.321133140, 1.119622405, -0.365394389, -1.012696710, 0.868451522, 1.579948219, 1.359972885, -0.158567491, 0.482366907, -0.309909278, -0.022065475, -2.739437662, 0.067731546, -0.307385505, 1.076258227, -0.732479045, -0.229788809, 1.494405972, -2.226468597, -1.025574677, 0.529890436, 0.640963127, 0.009242953, -1.452143558, -0.514103838, 1.687853703, -1.734177207, -0.999579468, -0.162594348, 0.226698676, -0.487457004, 0.480558916, -1.666525640, -1.951195126, -1.554633523, -1.189303732, 0.901913090, 0.232542821, -0.176433840, -1.713279354, 2.299381312, 1.246415244, -0.303738583, -1.409716165, 1.531123798, -1.098296288, 0.921063534, 0.912326703, -2.256550902, -0.590068237, 2.028083587, 1.369990754, 0.425422766, 0.632749953, 0.777277819, 1.040310849, 0.384232543, 0.259022891, -0.246026638, -1.771938737, 1.530520818, -1.971448093, -0.882570888, -0.295162843, 0.376450346, 4.015695120, 0.775756422, -0.711011116, -0.670247453, -0.035354829, -0.229101617, -0.508604038, -0.037632817, -0.311700439, -0.152657560, 0.940012466, 1.138293802, 0.389200478, -0.459410238, 0.790713476, -0.198769708, 0.851791764, -1.148302190, -1.513172670, 0.496830268, 0.378929900, 0.223185441, 0.410234811, 0.357735699, -0.975186540, -0.694294183, 1.101945459, 2.411447076, 1.360967356, -1.476246175, -0.701554637, 0.190592300, 1.521381498, -1.418789481, 0.521968247, 0.691528264, 0.464972053, 0.484334933, 0.277903988, 0.014503996, 0.107396661, 0.075576599, 1.651132091, -0.315520767, 0.079753491, -0.701426175, 0.054717844, 0.965313022, 0.497598812, 0.626633425, -0.713751588, 0.508996068, -0.818435138, 0.261775253, -0.248830487, -1.665663061, 1.082778733, 0.164019484, -0.533175032, 1.085855756, -1.225645666, -0.242593388\n-0.0276406\n\n\n5\n0.1108419935, -1.4439815736, -0.0822593839, -0.6373849477, -0.3508634981, 3.0016619559, -1.2932163866, -0.1287034366, -0.2264336248, 0.7221056425, 1.0876634397, 0.4488831983, -1.4068513356, 0.4762098195, 0.2124125512, -1.6610902048, -1.6593913031, -1.2569109459, -0.6849242281, 0.5587560799, 0.7535169337, -1.0168006761, -0.3408905366, -0.6167194580, 0.9306923778, -0.2289756307, 0.6738576895, 0.0506152505, -0.2597385301, -0.6305482860, -1.5164953706, -0.0288645807, -0.6153330512, -0.5351325576, -2.1710923374, -1.8953806026, 0.6323731189, 0.0392283080, 0.5614786836, -0.1907252574, -0.0932687922, -0.3327053387, 0.2324152922, 0.0903914050, 0.3195013884, 1.0252842589, -0.2684306832, -1.0161721256, 1.0707993886, 1.7394941742, -1.0722886882, 0.1402592696, 1.8477273021, -1.1355527165, -0.7778544187, 0.3019072842, 1.1141172551, -0.2483917552, 1.3978047389, -1.1329438373, 0.9077741803, -0.1952867494, -0.0010562959, -0.7981120360, 2.3198056447, -0.3812620562, -0.4149550828, 0.5069495177, -0.1315738832, 0.8381334776, -1.7171240530, -1.5471378860, -1.4473730017, -1.0404368562, -1.2264249662, -0.1816427237, 1.1873589000, 0.1240877228, -0.5752369693, 0.7442620190, 0.8855154995, -0.3840680586, 0.7648515999, 2.5724343400, -0.5771722874, -0.6389499340, -0.7205208119, -2.0187950903, 1.5291628112, 0.5180824717, 0.6052182989, 2.2645280827, 0.9195024857, 0.5702984452, 1.3002856431, 1.2870937829, 1.8387542680, 0.1089917357, -0.6289964120, -1.8780882010, -0.2220724454, -0.6396053193, 1.5827903418, 0.1709202996, 0.1253233421, -0.0430933061, 0.2835837530, -0.3207267747, -0.0203170192, 0.1212051868, 1.1624917250, 0.6948991284, -0.6347955371, 2.5136989910, 0.4755964181, 0.1519263904, -0.6401836328, 1.3919648066, -0.2589559671, -2.5366441354, -0.6050963625, 0.7016406153, 0.4096711227, 0.9110895302, 0.7187891212, -0.5440578419, 0.2621604032, 0.5285840454, -0.1478964704, 0.1290910467, -2.4488701291, -0.3981521462, 1.4671835352, 0.8364091590, 1.6021105884, 1.9774932086, -1.5566410229, -2.3428148442, -0.2955667708, -0.6344880415, 1.6828502378, 1.1167739984, 0.0207440563, 1.5319452398, 0.3251390340, -0.0220459606, -0.0568762700, 1.3003554040, -0.7506749291, -1.0674333257, -0.4506726934, 0.8778694398, -0.5947873510, 0.0107867318, 1.1423357243, 0.3498458697, 1.8381339417, 0.3330039712, -0.5286941749, -0.3170400889, 0.5035262355, -0.8296835745, -0.7750926700, -0.6183744237, 0.0047833831, -0.7231608513, 1.5814223980, -0.3670822013, -0.5167320139, -0.0416536766, -0.1855655774, -1.9844517180, -0.3651669135, -1.8299774987, 0.7446682629, 0.8569898868, 0.3654850710, 1.0618878715, 0.4352910223, 0.8916468474, 1.2050631085, -1.2835091994, -0.0314408140, 1.1020198855, 0.6427120906, 0.6853833283, -0.8582235835, -1.6854143174, 0.7794617736, 0.8306453921, 0.0745565381, -1.2863042258, -0.0837252638, 0.8554511180, 1.0409897896, 0.0625128199, 2.3065762249, 1.4772335188, 0.4261625467, -0.9402224848, 0.5981915624, 1.3401016462, -1.7109305750, -0.3304830826, 1.0594519671, -0.5179583871, -0.3178815249, -0.4966564985, 0.6034760946, 0.4257338517, 1.2015515515, -1.3737902020, 0.6066206916, -0.3091002865, -1.2071598308, -1.5721390826, 0.4273421132, -1.3068052196, -0.3332487160, 1.3189585335, -0.3002279101, -1.7746166283, 0.4396002604, -0.7975809088, -0.6130360056, 0.3271814867, -0.5342003800, 0.3923870972, 0.7574025522, -0.3427042137, 0.9647152883, 0.3776802077, -0.3785226189, -0.5575471381, 1.6392153323, 0.2564793096, -0.2231900816, -1.1786699294, -1.4152625753, -0.1527267234, -0.7248454972, 0.1807984099, 0.6205405607, 0.4480576514, 1.2719067196, -0.0749578474, -0.5347752327, 0.4548612164, 1.2120003075, 0.9181526313, 0.4054339150, -1.0767798365, -1.8276414428, 0.5443748381, 1.0520400448, 0.4529082916, -0.4952598250, -0.7074137675, -0.2899605433, -1.2892148724, 0.4023175992, -0.1019996679, -0.1680377404, 0.7821437586, 0.6903424723, 0.0234377262, -0.6100526902, -0.7944238387, -0.3468587078, 0.3208899694, 0.4495165423, -0.6553621975, 0.7049844114, -0.1044933892, -0.2763243060, 0.1552991071, -1.1245244882, 0.5640623001, 0.2194674283, -1.2306220860, -1.3324093313, -0.0954707155, 0.1823673483, -0.3171108995, -0.4952826252, 0.7022632772, 0.7136397458, -1.6016379434, 1.5562423860, 1.5685495042, -0.2359697560, 1.2644125132, -1.3070273416, 0.7371784973, -0.1581602574, -0.2521713255, -0.2671952146, -1.4628438914, 0.0779780471, 0.8640586932, 0.1055223276, 2.3675278220, -0.3780462392, 0.0450212535, -0.9343876770, -0.7914157897, 0.9369745448, 0.5272834870, -0.1522867624, -0.7148214776, -0.8546428982, -0.9528239664, 1.2839927043, -1.4074988820, -0.3247927765, -0.0618854745, -1.2647463502, 0.1280195695, 1.0567574061, 0.8112323507, 2.2877844338, 1.1276199885, -0.8432085921, 1.4613108928, -0.0095722757, -0.3847390997, 2.6971619952, -0.7737684062, 0.0017057614, -1.2122675092, 0.4690242085, 1.3735311279, -0.6870759123, -0.7051305469, 1.1010387922, -0.5352573004, 0.1063013689, -0.2055718903, 0.5637667749, 0.0957386916, 0.3890329613, -1.5077476469, 0.2778421111, -1.6217478170, -0.3891324164, 0.2191923757, 2.0502177089, -0.1381068017, 0.4533290920, -0.1980682713, -0.4291764548, 1.0908965346, -1.4269684580, 0.9688695928, 1.1564807820, -0.5452871033, 0.2360209049, -0.8658174059, 0.4138591951, -0.2648662228, 1.8356822031, -2.1118087718, -1.5172394042, 0.1917345516, -1.2866071849, -0.2130688705, 0.0507961242, 1.3923564898, 2.4144277029, 0.4547865868, 0.4001703805, -1.4646688635, 1.3103920361, 0.1544426873, 1.8727321648, 0.0336529880, -0.5509064243, 1.7440172578, 1.9039731236, -1.7526514779, 0.6172026634, -0.0136343816, 0.7102457106, -0.2962229748, -1.9237587420, -0.7753073037, -1.1884800392, -0.9109266000, 1.0199793390, 0.1338100451, 0.1287786397, -1.2780633249, 1.4096732374, 0.3242055377, -0.1557647478, 1.5932959823, 2.6352947397, -0.9742287715, -1.0189531740, 0.3098325361, -0.7325486850, 1.2344586960, -1.3219325838, -1.2067290708, 0.1159585641, 0.3867444835, -0.1475370914, 0.1231836590, -1.0286960931, 0.0405573260, 1.8483616747, 0.3532901834, 0.0104956613, -0.3380206781, -0.5783092682, 0.5779280064, -0.1421380762, -0.8650121392, -0.4518810963, 0.3106488531, 0.5894720027, -0.4799577715, -0.5804574324, 0.8096025718, -0.9119532948, 0.0985381315, 1.3305393646, 0.9518316328, -0.7937106905, -0.4669497624, 0.4155645983, 0.5462861386, 1.1521614249, -1.1053977814, -0.3996020184, 1.6859134529, 0.1335693794, -2.0173087010, -2.7062626101, -1.6919575230, -0.7016016364, -1.1211434704, 0.7345879668, -0.0348254916, -1.0237247259, -0.2034181901, -0.1045040713, -0.0848192367, 0.2322157667, -1.0656910800, 0.5397485731, -0.2618692406, -0.3467125042, -0.0607353820, -0.4118395080, 1.5560155649, 1.6012009800, 1.4882603305, 2.1446298405, 0.0602130322, -1.9746854286, 1.4023305780, -0.4128781199, 0.4338199610, 2.3622120724, -1.3431603625, -1.5933007446, -0.2593498752, -2.2139004126, -1.1684633683, 1.4593949614, -0.1105342020, 0.7304043065, 1.6259843026, 0.0531502437, 0.2510173365, -0.1241221710, 0.6188944219, -1.1514217207, -1.1565989721, 0.7954014523, 1.5060472207, -1.5066800040, -1.3622605746, 0.1799073759, -0.0004602177, -0.1035092992, 1.9640367747, 0.8157615594, 0.9141970454, 1.9789561441, -2.0541951907, -0.3103509463, -1.0588022941, 1.3749106848, -0.2477943087, 0.8477682892, 0.0618581572, -0.1942560369, 1.3195880725, -2.1700537791, 0.4469450877, -0.6665484519, -1.3334921971, -1.8884189646, 1.5284716465, 0.1084464632, 1.3710829422, 1.7999222328, 0.4188619822, 0.3500838973, 0.6999025228, -1.9749357497, -0.3376866338, -0.1958657009, -0.6831628518, -0.9849506575, -1.1990812076, -0.5586557836, -0.0028766892, -0.1808894473, 0.4423017354, -1.9289942495, 0.2056122876, 0.3254502814, -2.9924620137, -1.2008126593, -0.3667270895, 0.6343571838, -0.3660375042, -0.2415091199, -0.0162854720, 0.2752755216, -0.1487834510, -0.3760581327, -0.4137552311, -0.9077541342, 0.5587343995, -0.5893629979, -0.5539756097, -0.5257141626, -1.9840131763, 0.9936555470, -0.1567050829, 1.3726311507, -0.4778714721, 1.0142999725, 1.1729941812, 1.3255240622, -0.4652610493, -0.2809449749, -1.4091724563, -0.8915608099, 0.2024279224, -0.0557491546, -2.0724963555, -0.1202622526, -0.0225101522, 2.3682291855, 0.4655967093, -1.0200130840, -0.2181170733, -0.5496375926, 1.5564558777, 0.0949437503, -0.3140530853, -0.5130200140, 0.6124530913, 1.0905793019, -1.3467623253, -0.2772667786, -0.7126151068, -1.9703954877, -1.0475672302, 1.2084692022, 1.8278663192, -1.8054532688, 1.0523873216, 1.5805291448, -0.4001170080, -0.8345858347, -0.5454414252, 0.6916213815, 1.1865220998, -0.6419869403, 1.9318454446, 0.8919479802, 1.4615613596, 0.2125707875, 0.1856800941, -1.2450108162, -2.0447614110, 0.2131251124, -0.7257818490, -0.0006143089, 0.4825783831, 1.6694056625, 2.4201754852, 0.7785399697, -0.6573062339, -0.7670972153, 0.6024505395, 1.3715894193, 0.0156990833, -1.8251172826, -1.5477400539, -0.0205458689, 0.5074900557, -0.4757835899, 1.7069648468, -1.1550984243, 0.5695994308, 1.3176262248, -0.3680306315, -0.3728401539, 0.2705289205, 1.8083110519, 0.2949974636, -0.2828213856, -0.2734994509, -0.1310349789, -1.9923130909, 0.1669175020, -0.8992225217, 0.0197138227, 0.9827633346, -0.2128013936, 0.1028906823, -0.5379267318, -0.2371426728, 1.4157720330, 0.8997985465, 0.2610262785, 2.4939388709, 0.2434108004, -0.0933388918, 1.3108350046, 0.8409435989, -0.3862955620, -1.1664962350, 0.4717417072, -0.7630873185, -0.4018835330, -0.3590689397, 0.4133978686, -0.0957373703, -1.1474997701, 0.4756266455, -0.6193886008, -0.2781632285, -1.5021973125, 1.2951244056, 0.6057171698, 0.6172578141, 0.6229138041, -0.5257964836, 0.3758280930, -0.4834612166, -0.9228694509, -0.8671339686, -0.5888413650, -0.5527800569, 2.0522765296, -0.1666917432, 1.3058173860, 0.5132773547, -0.9335699253, -0.2843517931, 0.2524589100, -0.0759222609, -0.6627251500, -1.1337363472, -0.5582937970, -0.7617144921, -0.0092526007, 0.6103129464, -1.3249891601, 0.0643695849, -0.4060151127, 0.1464589930, -0.9286891757, 0.2506341265, -0.8837558093, 0.9627892073, 0.2326009329, -0.7380685257, -0.4616386097, 2.0384575629, 0.7987859785, 0.0612994450, -0.3530535839, -0.5309793978, 0.7646339473, -0.3230921663, 1.4268604945, -0.5681791604, 0.4434423367, -0.2131721586, -0.2621100623, 0.5988805543, 0.3088089322, -0.4302148829, -1.5938221413, -0.9555470256, -0.0069557901, -1.9428413266, -1.2844804803, 0.4548687573, 1.2222921578, -1.4451762250, -1.0154458060, -2.4053890523, 1.4738626722, 0.4626695755, 0.2955072024, 1.6363790172, -0.0408313384, 0.6048036949, -1.6157700251, 0.7401797609, 0.1216143203, -1.3744802212, 2.0341038213, 0.2140287577, 0.4523580547, -0.0691780074, -0.6257620984, -0.5274345403, -1.2460876600, 0.6433721387, -1.7710669164, 1.0071761659, 0.0321350736, -1.2601982234, -1.4655656435, -0.8181809765, 0.6738811193, 0.9439382182, 0.0308443553, -0.2274145911, -0.4311874621, -0.1770479507, -0.2717300217, 0.2345761063, -0.7816690694, 0.5058085596, 0.4221258102, -0.6357523269, 1.3651954537, -1.5986530634, 0.0199692413, 0.9542365487, 0.8608438957, -1.0331462250, -0.6950822217, 0.4212569960, -0.6174772064, -1.1331021566, 1.1409953671, -0.0275710362, 1.1806156228, -0.4808058503, -1.0262264543, 0.7205734834, -0.6674681012, -0.7386365318, -0.1668646431, -0.0197297858, 0.0587799767, 0.1934269132, 0.3625303182, 0.2557286740, 0.1225608383, 0.5660311401, -0.3488448550, 0.3330009712, -0.0939938410, -0.7698725658, -1.3683491426, -1.4464380373, 0.3179260987, -0.2567162956, -0.2651539955, -0.4905595034, -0.8274587216, 0.0534954630, -2.4414984188, 1.3965266892, -1.2568338838, 1.7944262636, 1.4383515712, -0.6252921886, -0.7843512957, -0.2082198417, -0.1222909171, -1.2956314030, 0.1099556120, -0.6636072351, 1.1893453294, -1.6195380905, 0.2030195293, 1.3909856674, -1.7784217336, -1.2639888206, -0.3351935946, -0.9160754418, 0.0569406226, -0.1909256874, -1.0813980495, -0.1167614820, 2.4489776387, 0.8949711758, -0.7049449537, -0.1581863769, 0.4704855361, 0.3050967277, -0.6612132355, -0.2947729566, 0.7511345201, 0.3908027980, 0.1063436767, 0.5781365809, -0.7328357828, -0.6917085161, -0.4945186991, -0.3023469262, 0.4138631827, 0.4231570446, 0.7985470706, -0.7531739769, -0.5732089111, 0.3530993582, 0.8655841938, 0.6667721144, -1.3643079254, -0.1783130132, -0.7418566341, -0.3903136259, -0.7623696390, -0.9630892230, -0.0928547084, 0.3338715206, -0.5055638228, 0.7571030375, -2.0794907723, -1.5799561255, 1.0374091002, 1.4096463763, -1.6092265999, -1.1739991291, -1.6197091181, 0.3961568745, 0.9511094689, 0.2628015052, 1.7730015818, 0.6365424518, -0.7337647615, -0.5199194845, -1.3111175595, -0.6188310272, 0.9347129197, 1.4988705233, -0.4042536756, 0.7218673296, -0.7645885760, 1.2648138629, -0.1814649681, -0.3729263767, 0.4694623990, -0.2144930110, -0.3714312938, 0.5960179820, 1.0374408326, -1.9550125956, 1.5977618218, 0.4209271056, 0.2285662845, -0.5002681930, -0.3428793836, -0.7433453005, 1.2815938308, -1.3188344535, -0.3009231124, 0.9449815792, 0.3854157623, 1.6187761852, 0.2403736266, 0.2814402802, 0.7221974611, -2.3694050525, 0.8436235121, 0.2367008278, -2.0412581008, 0.6580892909, 0.7402485476, 0.1144613228, 0.9337276471, 1.7399512466, 1.1700420190, -0.3447625478, -0.5912173208, 0.9734186690, 1.8089480240, 0.7834644940, 0.6079714584, 1.1476729655, 0.0638583958, 0.5609017954, 1.0639521624, 0.6131233540, 0.1322679066, 1.3701747824, 1.7774986390, -0.7672138917, 1.0079667592, -1.3545386496, -0.0186818844, -0.2595285909, -0.9143528903, 0.7714894982, 0.1395959090, 0.0726524707, 0.7071262375, 0.3906439447, 0.5595306856, -0.3775261759, -0.1187765501, -0.7979722495, -0.8395287050, 0.8425756046, 1.7685713710, -1.0065360249, 0.5794972074, 1.2314391598, -0.8655407005, 0.3049770475, 2.0474429178, -1.2928733684, -0.0881542378, 0.1944198673, 0.1689117966, -0.6076113229, -0.3326665840, 0.2203057652, -0.2288455128, 0.1392847659, -1.6288082665, -0.3732683721, -0.1397198423, -0.5749551831, -0.2171183832, 0.1641895786, -0.8654016554, 0.7286335464, 1.7035893621, 2.0160915966, -0.2342836421, -0.4171515315, -0.6687532083, 0.1835762982, -0.0659986226, 0.4723331365, 1.0322099431, 0.2355142158, -0.0961822521, 1.7916940611, 0.1373343916, 0.4153555363, -1.8458922784, -0.0137471576, -1.1108388187, 1.5256728206, 2.7153052871, 0.8266358326, 0.6133657643, -0.0604279386, -0.5339655408, -0.2770486883, 3.4368946121, 0.3011729137, 1.2001524023, 0.2357677421, -1.1427302472, -0.6105504713, 0.1323911545, 0.4066511874, -0.9289611128, 0.0631364702, -0.0393368979, -0.3423747555, -0.7118989016, -0.0335323006, 0.7687255404, -0.6937225214, 0.6082265110, -0.5568268119, -0.5111239435, 0.7231807600, -0.9038238961, 0.0904979588\n0.0101167\n\n\n6\n1.7929632770, -0.7352684659, 0.4073985804, -0.3086796620, -1.1839738377, -1.4197291629, -0.7169555496, 0.1203513409, 2.5149309385, 2.4692912153, -1.1481953059, -0.1553506551, 0.3071285188, 0.4955145856, -0.2151395120, -1.1208275672, -0.1809047934, -0.8229707849, 0.0802755907, 0.2730936799, 1.0684339121, 0.0240289609, -0.1347733252, 0.6263034620, -0.7385485723, 1.1010781257, -0.3630504409, -1.0521643955, 0.8673717482, -1.0578212230, -2.3216585160, -0.4262263146, -1.4093502180, -0.4588788913, -0.1094954724, 0.7109277407, 1.1836273484, 0.5939686540, -0.2879842070, -0.4085386305, 0.2710898033, 1.0774354841, -1.8458079795, 0.0943240268, -2.1313695246, -0.3530223193, -0.6021901819, -0.4726222950, -1.1868572228, 2.7126666318, 0.5875703432, -1.0357174740, 0.4055427029, -0.1593572599, -2.4701887397, -0.1002124290, 1.2980904344, 0.0647980605, 0.2493509297, -0.1994271523, 0.4162729008, -0.2516880157, 0.4715033994, 0.0676158071, -1.4770522677, -0.4665713078, 0.5532605870, 0.3439251716, -0.9264702359, -1.4051644516, -0.3236743635, -0.1299791828, 0.4510486792, -1.1552305370, 0.3558257995, -0.2617020387, -0.2176998758, 1.1385475193, 0.0799027382, -0.5048187643, 0.0954962617, -0.4802069676, 0.4163354624, -1.6360220765, -0.3088456748, 2.3216278140, 0.3606884231, -0.0260079418, -0.9476822048, 0.6871647235, -0.6736623723, 1.0476191937, -1.6969277102, 0.4387337545, 2.3464102730, 0.1959207574, -0.4048067180, 1.0691424154, -0.3228722290, -0.1797038149, 0.7689042768, 1.4508969055, -0.4318995505, 0.2915148912, -0.5808177045, -1.5185069524, -0.0598225772, -0.5622042523, 2.2004727181, -0.0163288674, 1.4641290514, -1.6631827256, -0.0325900814, 0.8449261565, -0.1224132881, -0.8296934626, 0.5121898398, -0.3160908791, -0.7072938872, -0.5255864409, -0.2512625285, 1.4443812553, -1.8105998203, -0.4246714213, -0.2103760138, -0.0578940824, -0.5522716533, 1.6372356965, -0.1971963351, 1.0355501521, 0.7155331559, 0.9406800392, 1.1136225750, 1.1659762446, 0.4034833393, 0.4884161467, -1.8703798243, -0.3797871136, -0.0602522794, 2.3676552738, 0.2327360098, 0.3016789088, -0.4436589892, -2.1696766931, 0.7743094054, 0.8294548259, -0.4464023256, -0.7416370822, -2.2819470942, 1.8562303664, -1.2362240315, -0.5511607462, 0.8705152693, 0.7562485203, -0.7002023282, 0.4510382503, -0.0509898923, 0.5633557130, -0.8866725763, -0.1747668279, 2.0331235819, -0.6995113353, -1.2507761462, -0.1680578408, 1.0449859511, 0.1960585003, 1.2868572825, -1.2293201356, 1.2255730618, 0.4187474891, 0.4543546251, -1.4189051268, 0.9425978814, 1.7771031180, -1.1536321748, 0.7415511508, -0.6454531785, -0.2243508009, 1.1321832362, 0.9478826936, 1.9696974652, -0.0535971205, -0.8911262125, 1.1586005431, -1.1380359696, 0.7243724668, -1.2341230850, 0.3209835001, -1.0875785216, -0.5323219520, -0.5930078945, 1.6692317514, -0.1051484851, 0.3929022901, -0.4808131628, 0.6054673745, -0.0303438045, 0.0644358714, -0.3546776021, -0.3817811315, 0.0642438284, -0.0163473466, 0.6857396574, 0.1853029153, -0.3138192707, -0.9771649322, 0.8267077141, -0.8218851962, -0.0503348636, 1.8582519538, -0.6248003258, 0.9765742385, -0.2477062374, -0.9576130673, 0.5274947042, 0.1548037727, -0.1621978302, 0.0956744172, -2.0171528357, -0.2765919607, -1.0956860788, 0.5737076110, 0.1274375500, 0.1593889720, -0.0399472567, -0.2515798219, 1.2783532912, -0.1575637473, 0.7434516911, -0.3178421394, -0.9020291122, -1.0308910075, -0.3519246041, 1.5017262079, 0.1371522828, -0.5788650312, -0.2603738754, -1.2294849229, -1.2775762213, 0.8352349749, 0.1667807661, 0.2117503349, 0.3540307605, 0.0080785853, 0.4403911842, -0.3449237431, 0.9223221200, -0.6138106428, -0.9596966475, -0.6535532067, -1.7556531965, 0.0452107439, -2.1299511858, 0.2790673912, 2.0246451950, 1.3895088918, 1.2396437874, 0.2132829788, 1.2107159014, 1.3677616346, 0.2374695987, 0.1268505415, 0.6871357823, -0.6313881833, 0.3016339737, 1.3305031394, 0.6541109279, -0.4225107830, -0.4820916257, -0.8403966487, -0.2565534920, 0.0910543560, -0.5803926346, 0.4585508151, 1.1501386663, -0.1330504319, -1.1031411842, 0.5189624104, -0.7067243746, -0.6779941713, -0.7181151312, -0.0002872247, -0.0378358616, 0.2163323500, -0.2358325773, -1.3057754066, 0.3564009272, -2.0245828927, -0.2990767274, -0.0456112421, 0.2701879949, 0.6227092997, -1.2631683478, -1.8268524450, 2.7961854489, 0.4775512473, -1.8739689674, -2.0296924953, -1.3182039240, -0.5614562084, -0.4840413989, -0.2717576840, -0.7728342018, 1.9707045996, -1.5761646615, 0.3803203576, 0.5572864003, 0.8528762992, -0.7447104162, 0.1335609724, -1.9578896484, -0.3679585370, -0.5231497889, -1.0003251884, 0.0676227509, 0.3738148233, -0.7055995495, -0.4906226207, 0.8430772004, -1.5037435312, 1.3152721703, 0.2829937002, -0.7968821552, -0.3826730478, 0.6248804528, 0.7973933721, 1.1043294113, 1.6183877237, 1.1449289221, 0.4385174961, -0.0325810577, 0.1776283900, 0.0055520170, -1.4011723290, 0.3538178875, 0.4454725567, -1.3695807792, -0.4658526635, 0.7318711496, -0.3002161104, 0.3031446490, -2.5451909126, -0.2560123709, -0.7259014441, 2.3596764355, 1.5161596589, -0.4828037191, -0.0927788279, -0.1707636508, -0.1026581426, -0.4570425978, 1.2219587371, 2.5964018326, 0.4297144621, 0.8958013510, -0.0816895681, 0.3006717786, -0.6064579121, 1.5754802089, 1.8003894334, 1.2293290567, -0.0878251554, 1.0169849911, -2.2994067745, -0.2183680398, 1.4158778954, 1.6728656968, -0.5957561123, 0.5630711554, -1.7590921941, 0.7350310026, 0.1016849326, 0.2664758042, 0.3264117395, 0.8399298578, 0.7795204537, -0.4212957913, -0.7484718858, -1.2356702945, -0.9129405861, -1.2379586294, -0.9035555524, 0.8739762255, -0.2492817476, -0.6183622837, -0.0974445825, -1.0684556824, 0.9604539520, -0.1228070046, 1.5104787919, -1.2378029468, 2.1532347065, 0.7701934874, -0.2526433035, 0.8363351964, 1.2101055164, -0.5321508564, 0.1359324885, 0.5209174926, 0.4977462583, -0.6679721547, -0.4611746567, -0.4593061723, 0.2797929944, 0.6257417808, 1.4040066915, 0.4183853109, 0.9793582773, -0.8345577998, -0.0967694739, 0.1252573921, -0.2235003656, 2.7413025959, 0.5930345499, 0.2374345529, 0.5332420952, -0.6372176654, 0.2853399717, -1.4883240479, -0.2442226219, -1.0459897168, 0.5481403288, -0.0097178044, 2.0542166763, 0.5169890837, -0.8381066780, -0.0704556445, -1.9100246153, 0.2767022260, 1.2463021702, 1.9754403117, -1.2963366481, -0.4801658667, -0.1566439650, -0.4245850818, -0.9424745819, -0.3862489595, -0.1061648322, 0.1097810736, -0.3351726828, -1.9843788232, 1.6445135928, -0.2031567880, -0.5826830168, 0.1189901450, -0.9266563146, -0.1485211290, -0.6293769924, 0.3220956964, 0.9813800672, 0.1197057951, -1.4750150723, -0.9728585589, -1.2019335085, 0.3479631106, 1.2455221269, -0.3526216494, 1.3203607062, 1.1172812571, -1.6154530929, 1.2705304462, -1.2394257015, 0.9761868198, -1.1428695098, 0.4449098945, 0.5147853062, 0.2249320755, -0.7830609471, -0.2491066483, -1.7287597759, 0.0225324327, 1.3293341920, -0.7989634239, -1.0791269585, -0.7387157940, -0.1146258117, -0.9751132845, 0.0747759017, -1.3317483731, 0.3722882459, 1.5191511003, -0.9498703536, -0.4563881780, -0.6341833037, 2.1287373597, -0.9757670526, 0.0714019628, 0.5012889431, 2.1517635806, 0.3982388350, 0.2850022161, 0.7565230140, 1.5891810136, 1.2053199597, 0.9487632098, 0.6461415308, -0.9612068811, -0.6111983512, -0.8057581930, -2.2046321314, -0.1399848357, 1.1266223858, -1.2594926736, -0.4051924743, -0.7864227995, -0.0076392877, -1.2148865789, 0.0224146555, 0.3162899511, -0.7914808400, 0.9229611994, -0.8135240632, -0.8117200885, 0.4568334792, -0.3806423420, 0.5511202819, -0.2783127743, 1.0204399313, -1.1514821047, 0.7022908571, 0.0691098672, 0.3022300232, -1.0928488343, 1.5214550672, 0.5818621708, -0.5168615329, -1.3025574693, 1.3178292808, 0.3327174380, -1.0889328072, -0.7300780307, -0.7990240707, 0.1549466715, 0.7302019645, -0.9597759458, 1.4478382169, 0.6898823629, -0.4396606080, -0.8038030708, 0.8986606254, 1.4663799571, 0.4213099343, 1.0721915187, 0.0004270931, -1.8190060371, 0.9334040270, 0.6933457646, -0.9428803601, 1.5076887436, -1.0725358588, 0.3109695959, 0.6899589678, 0.4663364772, -1.2051674010, -0.8492449788, -0.8435402988, 0.2284364440, -0.4517366603, -0.1457986453, -0.8031141674, 1.9962589999, 0.9734472848, -1.7317208930, -0.2691687878, 1.7000762686, 0.9555035835, -0.6364228743, 0.5643430946, -0.3581462093, -0.4735592964, -0.1109767021, -0.7140245815, -1.1933989254, 1.3921219875, 0.1149336097, -0.9018754333, -0.4855101448, 0.1816603041, 0.0086196595, 0.1834025505, -2.9500764921, 0.8379839938, -0.1602575560, 0.2949079634, -1.2909311514, -1.0132604729, -0.2337856604, -0.5831928053, -1.8842571156, 0.0109578823, -1.2868838382, 0.7996299981, -0.7268257429, 1.1116232941, 0.5137587147, -0.0075185239, -1.1741442910, -1.0906749253, -1.1155707983, -0.3522219230, 0.3207591969, -1.0707626161, 0.0494070954, -0.7488658302, 0.9258771112, -0.4411833024, 1.4030242940, 1.7460849298, -0.9056847811, -3.1129201699, 0.0901076308, -0.3587376422, -0.8223680711, 0.3010386604, 0.5355436206, -1.6133009142, 0.0558011071, 0.5790166848, -1.7465442739, -0.9057910473, 0.5305155467, -2.6496090630, 1.5390646894, -1.0863986113, -1.5706771018, -2.0286487213, 0.2629739428, 2.1623874292, -0.2978498288, -0.2966696053, 0.4014788260, 0.1729803217, 0.2769837200, 1.4912276240, 1.3324490826, 1.0289211764, 1.5999464021, -1.0219275552, 0.8975337417, -0.2655790691, 1.5318114397, 1.0100245394, 0.4095373178, 1.5413297211, -0.3442066039, 0.1161455841, -0.8261079852, 0.4762477494, -0.4501155231, -0.5983399948, -1.1634510571, -0.7927315180, -0.7395624227, -1.4669508385, 0.0308158995, 1.7200221481, 1.0007276049, 0.4292327003, 0.6875987801, -1.0411680335, -0.4449264175, -0.3780266778, -0.2792342143, -1.0270984177, 1.2676084071, -0.5407293118, 1.1410835550, -0.3554195187, 1.1906525480, -0.7048658963, 2.0544178432, -0.7923599435, -0.0318257944, -0.5820648131, -0.3630288643, -0.3666679604, -0.3142407464, -1.1212414915, -0.9707628115, 0.3327088860, 0.1223212603, -0.7745332526, 0.3057860070, 0.2399186609, 1.2659730729, -3.0211244484, 1.4096829066, -1.4990310037, 0.0985467827, 1.3763716369, -1.8016132746, 0.4573467214, -0.0572949278, 0.6811224225, -0.6884818523, 1.1579837262, -1.1404994431, -0.9541128644, 0.4849594651, -0.0683172856, -1.5092523956, 0.4255836358, -1.4782236491, 0.8551550480, 0.0600944965, -0.7723545984, -2.0102572284, 0.6304477713, -0.8868559626, 0.1048685716, 0.8810145885, 1.5113201493, 1.3480537963, -1.5093996547, 0.2351888727, 0.2865227494, 0.7473929640, -0.8590022549, -1.8719194121, 0.7025039356, 0.2102076638, 0.1196859997, 0.6843870322, -0.5596707268, -1.6263910432, -0.5596626563, 0.3869025548, -2.5372069797, -0.4141435141, 0.9069737041, -0.0734516978, 1.1075640710, 1.2013049739, -0.4940917696, 0.4916785443, -0.4558939111, -1.4810431423, -0.1364382892, 1.1508443162, 0.1049952773, -1.4742599331, -0.3280047616, 1.0614730454, 0.5739907049, 0.7686440207, -1.1357116930, -0.2640378355, 1.9017258478, 1.2548629055, -1.0486415297, -0.0899452299, 2.2403065549, 2.0211399215, -0.7365834165, -0.9326942547, -0.4899628684, 0.7342433964, -0.8435308837, 0.4333955533, 0.4661009411, -0.5840341720, 0.4640134677, 0.7934135351, -0.9498785377, 0.9688180276, -0.0007812686, 0.5563958237, 2.1066469178, 0.7397812600, -0.4149482543, -0.7448184493, 0.7753333256, 1.2645138591, -2.0332809771, -0.4170762400, 0.7338481835, -2.6917140206, -0.2060145320, 0.1907956346, 0.0885374035, -0.3519388309, 0.4064374008, -1.0304612917, 1.2422921987, -1.2399664716, 1.0069234200, -0.0501179368, -0.6126452644, 0.7849907690, 0.8987959528, -1.7603686589, -3.2605412617, -1.5065749054, 0.8991648460, -0.0609459441, 0.1624854374, 1.3120776096, 0.7578458149, 0.2800084559, 0.3179200280, 0.1485101727, -1.9772087459, 2.4873951976, 2.4049807030, -2.2652358415, 0.7008296778, -0.3470177286, -0.6913907363, 0.2994783625, 0.3567813088, 1.0821109171, -0.5377192839, 1.2572424422, 1.0637266727, 0.5430932680, 0.6300689740, 0.2774210026, -0.3525394454, -1.7114882987, -0.7431538384, 1.9459830328, -0.0565561613, -0.8421066851, -1.4189260396, 0.0205164012, -0.9143551805, 0.6158809114, -1.1948293265, 2.5054313537, -2.2034089527, -0.5972224009, -0.5635298975, 0.4917533697, 0.3577445824, 1.1222350944, 0.0498121845, -0.0776976176, -0.8242519143, 1.3424404529, 1.7677613646, 0.2856412184, 1.1880471874, -0.2555152309, 0.0432459748, 0.5858776258, 0.8541196235, -0.1483626567, -0.8582603022, 0.4521597023, 0.5616072633, -0.5534978124, 0.4992941622, -1.3965325878, -0.2249879461, -0.1439427244, 1.1944110368, 0.1032605645, 1.2897845237, -0.1927637275, -0.3646659364, -0.3290444016, 0.4598530363, 0.4713102624, -0.8503854296, 0.5877261275, -1.3348268137, -0.5745489857, -0.8492801091, 0.3782766627, 0.0575127637, 0.9896599933, 1.2284962465, -1.0535364680, 0.0314501607, 1.3908865414, -0.4961156517, 0.2807000687, 0.8038558496, -0.4090929442, 0.7114917915, -0.6147616847, -0.9758830216, -0.6741629686, -0.8011700808, 0.6142650190, -1.3008709252, 2.0147303763, -0.0135171610, 0.1522860540, 0.2237270979, 0.2005145757, -0.1812940116, 1.6278010592, -0.6049790480, 2.6133311691, -0.3259300503, -1.9668808827, 0.5499415966, -0.2308224071, 0.1039313709, -0.5310240326, 0.8568955896, -0.1905456136, -2.0763866665, 1.2615312494, -0.3837361942, 1.3819689280, 0.3804709661, -0.5066989862, -0.9810965430, -1.5574971704, -1.1503714805, -0.0591567586, 0.9379219642, 0.2331476223, 0.2881763807, 0.4249390819, 0.2407511943, 0.4555896106, 0.0464325003, 1.1728324671, 0.4234568822, 0.2620704447, 0.9357423735, -0.4269697882, -1.4656417488, -0.0913619986, -0.2274104495, 1.8313209412, 1.4380859477, 1.5565561068, 0.0897773175, -0.9652230933, 0.6008331547, -1.1768830112, -0.0541478058, -0.8943743469, 0.2809096676, 2.5418853999, -0.7091287471, 0.9746142753, -0.2416512668, -0.3891504686, 0.2154966349, -0.1499963763, 1.2053817255, -0.6423394388, -0.8153154861, 0.9248480344, -0.4162581805, 1.1139414420, -0.5400639384, -0.4521743092, 0.1592396942, -0.5650406793, -1.0685284953, 0.1581286729, -2.2651013948, -1.9558300647, 1.5736307678, -0.6553156595, 0.9436219504, 0.4268356618, -1.6936523517, 0.7608796573, -0.6336220768, 1.1989561881, 0.0877135049, 1.6649619793, 2.1776915742, -0.8237554548, 0.8819519350, 0.4400725850, -1.4498728213, -2.2792667491, 2.0156774326, -0.5684052897, -1.2065357322, -0.7376811935, -0.6320111897, -0.2752095186, 0.2352656994, -0.6856856300, 0.6991831723, -0.4790781605, -1.1460782117, -0.2168787128, -0.2482822340, -0.1046266138, 0.9572764202, -0.7969823651, -0.9012621124, -1.0167740219, -0.3685693156, 0.6015070788, -1.0668683945, 0.0497361766, -0.8825730381, -1.0111428532, -0.7590071042\n-0.0168327\n\n\n\n\n\n\nHier h√§tten wir auch schreiben k√∂nnen:\n\nd %&gt;% \n  mutate(x_mean = map(x, mean)) %&gt;% \n  unnest(x_mean) %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nid\nx\nx_mean\n\n\n\n\n1\n1.129967218, 0.039082892, -1.110991626, 0.963305222, 1.852870661, 1.510573329, -0.528400433, 1.220485244, 0.318030059, -0.816448130, 1.025637380, 0.915494970, -0.450388473, -1.305825405, -0.786611772, -1.316948555, -0.461831683, 0.540257800, 1.393654064, 1.171380379, -0.892157806, -0.024515178, 0.136435431, 1.098061769, -2.197377401, 1.300823740, 0.670045146, -0.426523692, -0.854517941, 1.099605371, 1.504040110, 0.847705794, 0.510170385, -0.328402111, 0.592919535, -0.608226040, -0.627629610, 0.305000678, 2.026647427, 1.057585943, -0.125291620, -0.557331326, -1.250103237, -1.438773706, -0.847581772, 0.038457469, 1.859989746, -2.846900660, 0.699182408, 1.358251956, 0.241036754, 0.201835365, 1.045979791, -0.029048537, 1.105006595, 0.102657526, 1.365572948, -0.139392789, 0.366220545, -0.648249390, -0.260941781, -0.031464865, 0.203537095, 0.892117218, -0.133749011, 0.494395844, 1.152557971, 2.295697720, -0.152736386, 1.895861211, 1.785232176, -1.200307338, 1.696002950, 0.065712076, 1.126016136, 0.249685654, 0.166369840, 0.749613507, -0.653662831, 0.454460938, 0.179472330, 0.548301461, 0.777678065, 0.104919580, -2.124976061, 0.298960473, -0.143763184, -0.511598346, 0.319750225, -0.021363371, 0.704876792, -0.647839981, -0.258415332, -1.518134860, 0.728855482, -0.092621260, 0.908858348, -0.009648747, -1.324239993, -0.651122005, -0.916851495, -0.854200195, -0.334544127, -0.022515115, -0.445657020, 0.602186026, 2.258159826, 0.383361510, 0.394630295, -0.355604862, -0.757102309, 0.197263333, 0.814895336, -0.800532822, -1.269143880, 1.812920024, -0.752624588, -0.098348785, -0.482570679, 0.224027748, 0.140633273, -0.470958145, 0.145149874, -0.102401632, -1.286361002, -0.049713491, 2.646737350, 0.474319974, -0.064973494, 0.231694995, 0.358649218, 0.903135146, -0.786853583, 1.113797615, -0.486163793, 1.381860897, 0.456276600, -0.237615111, 0.615750310, 0.458893717, -1.235879902, 0.113891396, -1.507756905, 1.058283661, -0.812731219, 0.152592025, -1.344434832, 1.176973206, 0.538809173, -1.556706604, 0.236570938, -0.870731446, -2.314587677, -0.314112610, 0.462815878, 0.023560067, 0.487588235, -1.365092473, 0.456941334, 0.063067389, 0.132878276, 1.493064819, 1.783940578, 1.468083364, -0.165996052, -0.001145478, -1.012548490, 1.143666487, -0.471309210, -0.371584919, 1.349553368, 1.066876169, 0.932575947, -0.881931169, 0.901025164, 0.972495367, -0.669096040, -0.881019778, -0.315833916, 0.319078271, -0.892115196, 0.926236226, -0.390766018, 0.785628908, 0.229082894, -0.051466014, 0.571593349, 0.643600311, 0.218532459, 0.754151979, -1.235138799, -1.191502629, -0.592713810, 0.254176198, 0.778980189, -0.008015603, -0.220179450, -1.030406254, 0.293301387, -1.906965172, 1.284756273, 0.203484253, -0.486511320, -0.590883951, -0.040179589, -1.282374318, -0.572306644, -0.999848401, -0.968162493, 0.378743653, 0.096420009, -2.219888869, -0.626330790, 0.564604389, -0.313753914, 3.116766725, -0.720571724, -1.759463652, -1.406390627, 0.915304714, -0.034101478, 0.347312573, -0.459503393, 0.113068732, -0.005834427, 0.471463280, -1.793254335, -1.139576366, 1.530660862, 1.071655964, -1.112517232, 0.265747446, -2.048228986, -0.413635751, -0.802559214, 0.043349202, -0.684345870, 0.117879476, -0.717077069, 0.370982275, -0.343640691, 0.616093384, 1.653051517, -2.098092668, -0.033690771, 0.075771304, -0.174876899, -0.733146051, -0.914061364, 0.072876010, -1.018325329, -0.922929187, -0.268274964, 1.639059264, -0.160097189, -0.594861712, 0.730054876, 0.189185886, 1.499068724, 0.664479838, -1.225450550, -1.037737800, 3.216506830, 0.353593122, -1.064682522, 0.275001955, 1.285968356, -0.012353992, -0.532326461, 0.282273492, 0.028574045, 1.384436459, 0.496008126, -0.085141356, 2.670116606, 0.395562506, 1.626417625, 1.528433382, -0.838625906, 0.155983725, -1.210554412, 1.354553420, -0.620935909, 0.277840728, -0.717794555, -0.109762211, -1.881558039, -1.034518882, 0.631286266, 1.859987911, -0.678825864, 1.151095888, -0.005303699, -0.104549078, -0.318006356, 1.231966371, 0.263620417, 0.566762117, 1.075351201, 0.156135790, -1.291197912, 0.275794294, 0.520759328, 0.462667374, -1.018249190, 0.852810523, 1.164210923, -1.918292756, 1.113904969, 0.176476422, 0.403117260, -0.823213535, 0.348650715, 0.437658443, -0.964428584, -1.431218397, -0.616430129, -1.551349115, -1.780677709, 1.556005561, -0.230286124, -1.253028749, -0.397620452, -0.676268612, 0.463167517, -0.948164651, -0.621994281, 2.496845717, -0.162251585, -0.561733210, -0.235508368, 0.300783373, 0.608940192, -0.651050760, 0.661605874, 0.207635789, 0.548966621, 0.392897080, -0.253141294, -0.270680123, 1.968225874, 1.955617263, -0.015320112, 0.910878724, 0.678909501, -0.660430052, -0.893767004, -0.875305949, -0.372627401, -0.693063025, -1.057465069, -0.453663580, 0.732340194, -0.581993479, -1.691984073, 2.213767668, 0.120690930, 1.882392411, -0.201023714, 1.423959368, -1.079583106, 1.423459522, -0.831278411, 2.443603110, -0.414781778, -3.160644904, -0.976867510, 0.253497520, 0.826291500, 1.714739474, -0.354763284, 0.475499238, 0.841677699, -1.347083549, -0.165843118, 0.190399343, -0.525638044, -0.973549660, 0.412252423, 1.563918033, -0.029765329, -1.110231170, -0.641232844, -0.771855397, -1.398508298, 0.728458342, 1.405720668, -1.029635294, 0.044471358, 2.197789473, 0.089617411, 1.132705241, -1.296284023, -0.338818190, 1.399031547, -0.779972794, -1.316512211, -0.549584525, 0.598508290, -1.973338235, 0.855598966, 0.552004035, -0.519126454, -1.090520843, -1.318281070, 0.654281728, -0.969244299, 0.946920915, -0.816157316, 1.066280520, -0.981943251, -1.452123735, -0.493853256, 0.798283006, -0.921433040, 1.039313336, -0.480486341, -0.121938688, 1.149422313, 0.213706624, -0.016586289, -0.192714026, -0.320802167, 0.466027183, -0.424492144, -0.871168791, 0.083375221, -1.146960700, 0.745015787, 0.842776775, 0.326677649, 2.365342645, -0.880466854, 0.169053528, 0.038457439, -0.396240777, 0.783016038, -0.203227089, -0.245422772, -1.275996231, 0.289004045, -1.213843628, -2.100738773, -1.376663714, -0.692549069, 0.025480644, -0.765406509, 0.115587137, -0.450898888, -0.401309625, -2.669569506, -1.164928197, 1.508213361, 1.944699612, 0.646943631, 1.053770857, 1.796278445, -0.048861183, 0.356601813, 0.138716686, 0.780266311, 0.235423161, -0.139100020, -0.899393907, -1.934618297, -0.405649907, -0.523387952, -0.218113561, -0.955197112, 2.709536228, 0.701315986, 0.873182437, -0.993990547, -0.994832487, 1.146159020, 0.109945700, 1.669637503, 0.986571944, -2.375728234, 1.029035130, -1.172946971, 0.708807673, 1.320631088, 1.960183366, 1.298937122, 0.975738118, 0.050416369, 0.292675332, 2.539013525, -1.117995792, 0.172843101, 0.337660722, -0.405452045, 1.202401800, -0.368547580, 1.404642514, -0.487371860, 1.681126971, -1.091448164, -1.596981846, -1.497650172, 0.455056120, 0.792667073, -0.730220610, 1.822368746, 0.434871882, 1.178763767, -0.589339218, 0.409759910, 0.646364494, -1.167524471, -1.098737286, -0.467541913, 0.529736011, 1.286759847, -2.168839771, 1.174667269, 0.584273618, -1.527337271, -0.402731878, 1.239244756, -0.193439276, -0.613648494, -0.318685983, -0.770860387, 1.313233769, -0.092077418, -1.407488110, 1.312626791, 0.502718375, 1.585570442, -1.113076502, -1.973689731, -0.597920595, 0.151107905, 2.077067462, 0.264413552, 0.248859194, -0.897412550, -1.449397853, -1.142929407, -1.968359640, 0.901427771, -1.033674168, 0.863153893, -0.285098556, -0.343730292, -0.845323356, -1.138880169, 0.369672289, 0.148136945, -1.740570243, 0.669351525, -0.241596138, 0.973735756, 0.015320285, 1.336746002, 0.969256399, -0.650779630, 1.084838030, -0.832118265, -0.289304578, -1.061392626, -0.395760344, -1.497772319, -0.112968278, 0.953678413, 0.351708734, 0.784024251, 2.174232779, -0.586742406, 0.414903346, -1.242525285, -1.145275666, 0.110992524, 1.609956317, -0.089387108, -1.637980137, 0.481040543, 0.176681913, -2.291326829, -0.100550892, 0.677973088, -1.428880333, -1.459732112, 1.425705750, -0.907141180, 0.711008949, -1.467245026, -1.427831743, 0.147947047, -1.281417623, -1.591997569, -1.827158905, 1.683107986, 0.811686189, -0.110821091, 1.211853775, -0.876880390, -0.369211558, 0.022121771, -1.610269956, 0.272686665, -0.433647933, -0.737257856, -0.034155450, -0.869582930, -1.117740904, 1.335175400, 0.294808106, 1.241398876, -1.090658105, -1.214719514, 0.661056609, 0.330433236, 0.581589807, -0.211605369, 0.236172726, -1.022019395, 0.836146137, -1.692206712, -1.924532297, -0.423327102, 1.074914348, 0.321520549, 2.219034238, -0.910261010, -0.784235788, 1.452718051, -0.635274997, 0.045097560, 1.001025019, -1.700287564, -0.471429513, 2.795029765, -0.221030461, -0.515794753, -0.608826464, 0.808313557, 1.095402367, 0.381564509, -0.119830422, 0.553787491, 0.437483485, -0.739584291, 0.473515983, -0.707131491, -0.180509278, -0.257555899, 0.440442418, 0.321004199, 0.699103623, -1.198366007, 0.283714652, 1.603066840, 0.090143066, -0.407805714, -1.071282548, 0.753981024, 0.602499058, -1.331621417, 3.139663949, 1.407084551, 1.488593502, -2.134105759, 1.369173597, -0.473202807, 0.418862156, 0.176698080, -0.063796367, 0.242670314, 1.699890711, -1.006141780, -0.563497777, -0.161991020, -0.383299241, 0.225688916, 0.550192611, 1.165341678, -0.130062572, 0.158019092, 0.971597164, 0.092210912, 0.310577354, 0.539612063, 1.179415372, 0.030830222, -1.634271726, -1.942323835, 0.017304331, 1.968500017, -0.037745472, -1.031414841, 1.170749225, 1.840629554, -0.927175689, 0.277862753, 0.129602773, -0.273999743, -1.506294772, -2.222435134, -1.470093357, 0.056151100, -1.056113767, -0.766217371, 1.029420868, 0.868117951, -0.548252036, 1.620960955, 1.722380772, 0.885203234, -2.445738181, -0.990713919, 0.136066259, 0.116297217, -0.293246050, 0.971484047, 1.720417742, -0.674682282, 0.367943352, 0.636845249, 1.295825058, 0.639833929, -0.722309354, 0.238946697, 0.003518656, 0.215765478, 0.819692975, -0.564833236, -0.761415142, -0.237909732, -1.911660080, -0.431903417, 0.149371806, 0.798518087, 1.596950173, 0.384646030, -0.122690466, -0.977275874, 2.147091062, 0.732016206, -1.444233601, 0.503533569, 1.606140077, 0.523581728, -2.067882804, 0.267201467, -0.466840808, -0.954397657, 0.869472598, 0.282870426, -1.038178297, 0.504300138, 0.186300158, 0.303947860, 0.985802923, 0.313011870, 0.540532926, 2.497365291, 0.984298385, -1.062844685, -0.464506730, -1.483266516, 0.197583503, -2.026736071, -0.169392498, 0.549724186, 0.572940546, 0.403158611, -1.901919380, -0.497408783, 0.617646292, 0.779202910, -1.343605070, -0.040339903, 0.917569332, 0.571237416, -1.271930852, 2.032347541, -1.101986721, 0.401626349, -0.374636244, -1.385437023, -0.943960372, -0.054018420, 0.017533228, 0.600716620, -0.348086600, -1.658654688, 1.685267660, 0.864736338, -0.025791136, 3.115899787, 0.144436448, -0.611601005, -0.157208262, -1.900978819, -0.210606506, 0.731370825, -1.577751263, -1.045338832, 0.084390573, -0.552996307, 0.274337417, -0.608135010, 0.369004970, 0.601689292, -0.292676305, 1.013159521, 1.156905297, 0.107826084, -3.178526172, -1.305099602, 1.159651866, -2.550122949, -2.210798298, 1.153334608, 0.492542319, 0.115512202, 0.242114430, -0.766794710, 0.165139932, 1.109427202, -0.447667633, 0.229986560, -0.068247058, -0.317518707, -0.206758572, -0.700991367, -0.480865492, 1.288034476, -0.343648842, -0.305577822, 0.939122154, 0.446328518, 0.292465078, -0.278864451, 0.915966803, -0.308774415, 0.912573957, -1.796507229, -0.287465786, -0.606460423, -0.361654318, -0.599922432, -0.138336037, 0.316617100, 0.388502844, 0.042186959, 0.493227540, -0.844674085, -0.183160890, -0.849635341, 0.355152641, -0.569306739, -1.191446355, 1.143738462, 0.374711767, -1.996757132, -1.122049961, 0.302059205, 0.426663935, 0.232066789, -0.690175851, -0.491658382, 2.138545443, 0.586609408, 0.269033730, -0.988684850, 1.016692546, -1.055018811, -0.675778019, -1.344386495, 0.866128122, 0.428917100, -0.550445293, 2.065223305, -0.351130535, 0.986848924, -0.788238178, 0.101651243, -0.730858194, -0.614357276, -0.184055835, 0.111329256, 0.227778275, 0.386432806, -1.356971876, -1.183639613, -0.061195714, 0.959025606, 1.283758712, -1.585692891, 0.555128280, -0.688819996, -0.695117389, 1.380061022, 1.119313728, 0.455308986, -0.602495449, -1.141234321, 0.270741668, 2.505181519, -0.695418727, 0.188865459, 0.792765943, -0.422228589, 1.175012792, -0.200884084, -0.488023804, -0.702256152, -1.653978605, 0.716271841, -1.496694688, 0.667089562, 0.087416613, -1.031227409, -0.224599758, 0.456909370, 0.445676247, -1.489377145, 0.417173038, -0.659649948, 0.327252885, 1.243374817, -1.384235040, -1.925215190, 0.762245635, -0.548549818, -1.036209825, -1.022327751, 0.201935287, -0.923743870, 0.942982583, -1.862222891, 0.706510043, -2.202028656, 0.899361730, 0.229044004, -0.757391753, 1.275577837, 0.196059811, -1.078983328, 0.107879528, 0.486619266, -0.687160382, -0.004199881, 0.911850173, -1.923384392, -0.727296704, 0.881606769, 0.662122608, 1.199083205, 0.206317514, 0.917102460, -0.930699735, 2.089422704, 0.426887931, -0.016483436, -0.329186741, -0.072229732, -0.970904312, 1.039050307, -0.443121880, -1.098394759, 0.660034465, 1.299359927, -0.214015593, 1.273735819, -0.367281522, 0.134161858, -0.644885518, -0.213422132, 1.706046702, 1.422636024, 2.157043686, 0.751063490, 0.503327948, -2.401498977, -0.520806366, -2.007402634, -1.399624292, -0.429758368, -1.234532490, -0.511883070, 0.510132814, 1.020402662, -0.469933953, 0.139314624, 0.619379988, 1.623908993, 0.676823762, 0.960487519, -1.184205868, 1.563776211, -0.340610905, -0.876782326, -0.285797342, -0.737242068, -0.930340369\n0.0037901\n\n\n2\n0.285876475, -0.202259878, 0.512416048, -0.818121505, 2.290945880, -0.494822111, 0.684053196, 0.835974137, -0.047935720, -0.326603649, -0.714118074, 0.118547423, 0.088356175, 1.745567070, -1.073236169, -0.622895961, -0.009245922, -0.561584538, -2.301729800, -0.511703258, -0.145948620, 1.107737144, 0.160008358, -0.770723150, 1.217913058, -0.203589376, 0.177375466, 0.080027295, -0.588135730, -0.674989351, -1.007563399, 0.246548218, -0.020368280, -1.518412689, 0.365398990, 0.090682464, 0.736714749, 0.022937487, -0.660786574, -0.942946526, -0.256848996, -0.716803079, -0.460561330, 1.106954580, 0.182536168, 0.191617177, -1.228924114, 0.254679917, -1.560924262, -0.969173547, -0.897894345, -0.906254204, -0.808784201, 0.263649556, 0.207438925, -0.953578968, 0.843252727, 1.482461464, 0.044580195, 0.188456380, -1.260054891, -1.879441888, -0.244142269, -0.546156384, -0.646286469, 0.309884011, 0.145016336, -0.566298214, -0.857786260, -2.250854054, -0.896731676, 0.052125949, -0.143235443, -0.110985933, -0.750108766, -1.527208082, 0.572862158, 2.135930066, -0.038766238, -0.312575587, -0.693908359, 0.869314310, -0.427970967, -0.910155283, 1.223076131, 0.478806550, -2.818036971, 1.854472760, -0.723847258, 0.477901518, 0.629137136, 0.626523398, -0.315329176, 1.732471896, 1.782671089, -0.877112663, -0.059011043, 1.896890807, -0.644218925, 1.497302238, -1.439158587, 0.380117304, 0.065125684, 1.048284651, -0.634997200, 0.899918635, 1.644290244, 0.692657012, -0.869354753, -0.230828689, -1.545867370, -0.132883655, -0.778028867, 0.529372670, -0.019685525, -0.730706702, -0.476366009, 1.874626039, -0.968429880, -0.324281413, -0.120509795, -1.330491842, 0.318089585, -1.617197443, -0.617911375, -1.224890172, -0.651003543, 0.712377947, 1.481676790, 1.486466522, -0.928896361, 0.644729101, -0.917837277, 0.609200614, -0.420962872, 1.298572481, 0.264611353, 0.227575798, 0.342958829, 1.571313567, 1.253770469, 0.641575116, 0.365025753, -0.262247302, 0.990768167, 0.822885523, -0.395449175, 0.368006197, -1.072245857, 0.673825921, 0.074644544, 0.595753014, 1.316899269, -0.302954285, -1.456265040, 0.353459353, -0.794269402, 1.492923530, -0.146043869, -0.186943464, 0.067483373, -0.480476577, 0.653582261, -0.392477552, -0.128914851, -0.235784866, -2.713022053, 0.895220956, 0.174489521, -0.048293382, -0.487689850, 2.690010488, 0.130437634, 1.055406537, 0.196201574, -1.057468643, 1.048853048, -0.713808112, 0.435137431, 0.721369952, 0.639506257, -0.221069463, 0.788678172, 0.965076842, -0.949496159, -0.785273326, -0.704509396, -1.247886169, -0.538858757, -0.014683065, 0.248980772, -0.426389527, 0.812335776, -1.360310368, -0.663631291, 2.103998038, 1.009223578, 0.048578113, 0.175783548, -0.031304667, -1.367278109, -0.431422231, 0.460215230, -1.394815393, 1.498836435, -0.878191118, -0.515170107, 0.330107371, 0.178417362, -1.511631137, -0.760805907, -0.258797492, 0.685543251, 0.366535046, -0.013177324, 0.756033848, -1.275194015, 0.285573844, 2.322952734, 0.197935153, -0.974050152, 1.186537214, -1.391426848, -1.581679784, 1.216642316, -0.948056403, 0.058962717, 0.049168798, -0.656163792, 0.607214391, -0.778723387, 0.482168156, 0.542399648, 0.513492791, -0.119934372, -0.038147714, -1.493357400, -0.361164956, -0.647104051, -0.315571748, -0.523828436, 0.672533262, 0.363286475, 0.690948013, 0.396912660, -0.774657607, 1.855059695, 0.109279032, -0.571657671, -1.173346520, -0.424836250, -0.263017574, -0.035611353, 1.265269445, 0.061110142, 0.627821147, 0.526395380, -0.742823141, -0.018559401, -0.897924605, -0.033616937, 2.200886890, 0.631621067, 1.992513749, -1.597726003, -0.877479360, -1.034750843, -0.083775501, -0.665745138, -0.956880457, -0.854862031, 0.630769491, -1.602797241, 1.334295503, -0.573996594, -2.159424063, 0.041308796, -1.817692504, -0.668215878, 0.501086874, -0.755950901, 1.246820580, -1.130738799, 2.256066160, -0.149668917, 0.506345904, 0.417390455, -0.114742217, -0.077500515, 0.679391949, -0.686131884, -0.544684641, -1.064420087, 0.617769878, 1.449330916, 0.280394352, -0.912076315, -0.137957951, -1.351934088, -0.838916347, 1.284454238, -0.549332629, -1.793507793, 0.286813087, -0.221231800, 1.093650726, 0.918298681, -1.262334187, 1.832030774, 0.920232524, 0.585227673, 0.704516296, -1.119164381, -0.103834318, -0.355361433, -0.230137941, 0.199935367, -0.128840822, -0.420765034, -0.152371163, 1.590759753, 2.153686083, -2.209745522, -0.649438819, -0.049462851, 0.717762688, -1.240644040, -0.033286336, -0.306657577, -0.102933319, 0.142619761, -0.826149555, -0.516178539, -0.729561008, -1.691068245, 0.186368642, 0.541230478, 1.019152994, 0.396055062, -1.281797548, 1.429292004, -1.091571404, -1.430624290, 2.085062244, 0.525875571, 0.489839381, -1.669241829, -1.546011390, 1.143721643, -1.529290486, 1.237307622, -0.960197080, 0.578690423, -0.374144041, -1.491662746, -1.116351327, 1.822843860, -1.294999138, 0.917027287, 0.664855860, -0.422859915, 0.108945067, -0.059799113, 0.364488640, -0.096437164, 0.741185390, -0.781719374, 0.404908338, -1.955669711, -1.108953550, 0.755765525, 0.329775659, 0.447374512, -0.092534123, 0.608369127, 0.339049930, 1.296071496, -0.667151921, 0.305979388, 0.257664597, -1.391915770, 0.685403522, 0.006963806, 1.020435408, 0.285562377, 1.055850395, -2.718118699, -0.662139862, 0.021508881, -0.494489181, -0.511644496, 0.001523051, -2.166735097, 0.218306225, -0.185414213, -0.927252802, -2.953482824, -0.344721003, -0.505888202, 0.207137866, -0.099066355, 0.503398239, 0.852288796, -0.109699948, -0.407514905, -1.335701798, -0.955919742, -0.841233106, 0.547735897, -0.328180749, -1.287608814, 0.773374324, 1.637476583, 1.197208580, 0.691683546, -0.404349247, 0.620499687, 0.538841631, 0.528182121, -1.034798682, 1.898118751, -2.235399234, 0.819642004, 0.175975372, -1.242246939, 0.800352076, 0.678576559, 0.753006542, -1.171217305, 0.637894953, 0.425953084, -0.360516503, -0.830334205, -0.295483679, -1.191072733, 1.053141362, -1.681442622, -0.788648910, -0.394240602, -0.762641831, 0.842099670, -1.537766920, 0.014542336, 0.651585973, 0.906950617, 0.735377637, -0.735692535, -1.588427336, -0.102736937, 0.783306982, -0.742381023, -0.485627791, 1.237612559, 0.817314730, -0.898858775, 1.572405419, -1.453701213, -0.877857002, 0.641437081, 1.488425824, 0.626810250, 0.561539488, 1.098877406, 0.523150985, 0.725112936, 1.863547911, -0.172490474, -0.186244810, 0.811653558, -0.272146009, -1.002290093, 1.842211662, -0.893344775, 0.235967504, -0.958511979, 1.858590648, 0.618023680, -2.350684631, -0.936326025, -0.137343200, 1.076194757, 0.656869739, -0.974782988, 0.621585599, -1.311139614, 0.475934804, -2.150064471, -2.647181930, -0.447867648, -0.099534594, -0.724586941, -0.478308021, -0.241761115, 0.362294438, 1.375431170, 0.777130707, 0.566318817, -1.776307095, 1.317910274, 1.569551895, -1.774313123, -1.307823936, -1.719756776, -0.668927031, 0.586530412, 0.280156460, -0.484295440, -0.083567271, -0.781162991, -0.160709309, 0.746930114, -0.844380555, -0.111196086, 1.500912502, 0.411604087, -0.249270170, 0.403612309, 0.454325473, 0.747303083, -1.570628041, 0.677082459, -0.495752305, -1.200728284, 0.523703971, 0.046336616, 0.752580654, -0.581252942, -0.044195476, 2.263126323, -1.542297013, 0.389268049, 0.129156052, -1.937915452, 0.487202958, -1.391070201, 0.154548338, 0.384665775, -0.920652929, -0.765149324, -0.330147883, -0.902967224, 1.064882915, 0.652276790, -0.656020507, 0.383590262, -0.729518238, 0.530888708, -1.371518304, 0.191339461, -0.495679917, -0.640457017, 0.861929217, 0.053230338, 2.706730437, 0.767257998, -0.002019814, 0.090330165, 0.342732432, 0.161009408, 1.523650465, 1.126538170, -0.071045329, 0.161841839, -0.876015032, 1.914247207, 0.027868129, -2.011256490, 1.076746586, -1.057826090, -1.067719225, -1.382805632, -0.413211328, 0.715290587, 0.498411889, -1.262740819, -0.221167352, -1.074698574, -0.692937196, 0.838567281, -0.463443539, -0.552183150, 1.766033985, -1.271325838, -0.242844195, -0.317132654, -0.222384451, 0.316791553, -0.994756508, -0.822748432, -1.413125275, -0.231977442, 0.361197169, 0.188909405, 0.079000228, 0.718012637, 0.304270181, -2.152103054, 0.912520643, 1.413188356, 2.083811451, 0.188696667, -1.319129554, 0.815199820, -1.356801123, -0.336278943, 0.394281201, -1.291201869, -0.209404484, -0.707910915, 0.093305200, 0.030479631, -0.619339187, 0.660987131, -1.551733475, 1.184913556, -0.341819094, 0.155994949, -2.814978758, 1.372051582, 1.094656456, 0.512559909, -0.093970577, 0.920300761, -1.101184657, -0.189299732, 1.639965457, -0.153790686, -0.226809594, 0.776803512, 1.626360291, 0.983588488, -1.278070181, -1.733813749, -2.849682297, 0.751288583, -0.886615364, 0.388953753, -1.401543047, -1.153268713, 0.756350198, 1.145510882, -0.865434670, -2.192508964, -0.518129109, 0.512214638, -0.536925806, -0.656963777, 2.108273178, -0.034912999, 0.444728713, 0.674155081, -1.175809194, -0.241845535, 2.491044428, 0.839727039, 2.052335471, 0.739382364, -0.332765237, -1.004466485, 0.955437207, -0.153366788, -0.383162431, 0.751605252, 1.069829973, -0.688771502, -0.753328151, -1.828325896, 1.182772496, 1.010468174, 0.456588072, -1.131200995, -0.319487599, -2.735411004, 1.407569971, -0.545620008, -1.031169028, 1.136418305, 2.508785895, 1.138994523, 0.249893635, 1.044736686, -0.580399862, 2.202491045, 2.405953920, 1.021650220, 0.085672925, -0.538711805, -1.127912180, 0.730338050, 0.814975490, -0.565752334, 0.530541624, -0.848387706, -1.297493680, -0.935769852, 1.121995568, 0.341892678, -0.388579066, -0.916198582, 0.645812395, 0.665704280, 2.054968706, 1.405461460, 0.530326486, 0.327679224, 0.473815278, -0.310943080, 0.976336012, -0.966957130, 0.077213237, 1.408219059, -0.578286376, -1.428136158, 1.226784090, 0.089508712, 0.033100492, 0.587804550, -1.145816715, -0.248149033, 2.006329834, -0.126254660, -0.197302695, 0.802954430, -0.356246236, 0.699962401, 1.373199875, 0.985764803, 2.201173150, 1.756473135, -0.772449824, 1.630591392, 0.935606805, 0.113084812, -1.993780088, -0.369825748, -0.575663325, -0.162603743, -0.028244597, -2.027923521, 0.861415619, -0.537669384, -1.101751634, 1.241627777, 0.542168848, 2.331742431, 0.369763404, 0.886061978, -0.942667424, 0.682254660, -0.037393447, -0.407365346, 1.616048869, -1.127872599, 0.101274306, -0.906565691, -1.029127792, -1.283158495, -1.063589614, -0.630419106, -0.056197259, 0.195876854, -0.746351330, 0.833045584, 0.223917694, 0.349601857, 1.274433417, 1.762560451, -2.066924030, -0.675484659, 0.111714604, -1.886243540, -0.113984285, -0.463007876, -1.142300331, -0.508876349, -1.089122811, 0.887917533, -0.243334361, 0.368842979, 1.208214005, -0.009853612, -0.754842764, 0.154704375, -1.276766586, -0.193171932, -0.724556593, 0.166851474, 1.456355766, 0.243008022, -0.275405309, -0.174901299, -1.026580762, -0.126379305, -0.642302287, 0.406716100, 0.155739202, -0.878200828, 0.414690754, -0.205010133, 0.533848638, 0.097774785, 1.459899789, -1.153192969, -0.216943633, 0.177777311, 2.136704083, -0.735788310, -3.359915647, 0.773248790, 0.417863670, 1.022511226, -1.381475409, 0.246654055, 1.126925082, 0.663471012, -0.860459956, 1.718249344, -0.494285338, 1.070913094, 0.789514746, 0.219152727, -0.434969988, -0.335180659, 1.057423272, -0.331258562, 0.647669636, -0.534919884, 0.092392519, -1.387194599, 1.519344642, 0.811702226, 0.774140419, -0.703787071, -0.050308282, 0.505904201, 1.367651250, 1.343235005, 1.215545885, 0.383197927, -1.439852082, 0.494909060, -0.871689025, -1.429522897, -1.488822653, 1.230428904, -0.905490182, 0.066301715, -1.434882291, 0.019218056, -0.474563528, 0.389486240, 0.735016067, -0.071200987, 0.465031478, 1.251348528, -0.525354709, 0.243126407, -1.087468441, -0.397081435, 2.328991940, 0.228896930, 0.602948104, 0.104250268, 0.433066568, 0.065273891, -0.418774038, -0.015346699, 0.551235849, -0.520306050, 0.051174356, 0.425994472, 0.873081040, -1.967326747, -1.017757514, 1.117439175, 0.539616528, 0.088346097, 0.425727796, 1.667975836, 0.598419893, -0.354266306, 0.755712053, 0.823791824, 0.529028154, -1.702481320, -1.570320794, 1.107150762, -0.833857409, 0.032006065, -1.185191705, -0.463462275, 0.837120834, 0.107562202, 0.484385948, -0.323617900, -0.222799789, 0.096746736, 1.019348537, -0.283388813, 0.160281313, 0.034468467, 0.143059764, 0.410040495, -0.716795342, -0.594003142, 1.785402277, -1.331863016, -0.257993230, 0.699193007, 1.003561387, 1.358994047, -1.282757131, -1.147521660, -1.128954704, 0.670276891, 0.409648529, -0.005722589, 0.624588922, 0.433630258, -0.299303537, -1.440484963, -0.019972890, -1.091114677, 0.415029480, -1.056074827, 0.193304745, 0.057263493, -1.383679802, 0.345442309, -0.013227596, -0.173299277, 0.636780679, -0.331426709, -0.821068359, -0.787915880, -1.288715695, -0.233198674, -0.829136957, 1.377052756, 0.139311925, -2.792351344, 1.141409688, 0.578572844, -0.068128269, -0.319124757, -0.640722091, -0.234070126, 0.496901619, -1.135930408, -0.159827733, 0.289744068, 0.744949344, -0.982717749, 1.171191094, -0.350665973, 0.715480085, -0.091348385, -0.369201823, 0.930224197, -1.050827962, -0.420814972, 0.881724573, 0.020619961, 1.195930241, -0.789800236, 0.496419316, 0.852210793, -0.426626133, 1.152600798, 0.532027899, -1.177274594, 0.544815367, -0.523608168, -1.779364374, -0.171362559, -0.846851358, -1.893451525, -0.789199500, 1.595305293, 1.021749249, -2.163936849, 0.712648161, -0.532048993, -0.042338410, -0.545258012, 0.080251633, 1.059791363, -2.037192075, 2.360977297, -0.548277412, -1.892667840, 0.930744806, 0.615691575, -0.542178169, -0.886529725, -0.497588091, 0.491650161, -0.795888134, -1.653922138, 2.049305762\n-0.0282983\n\n\n3\n-0.008738179, -1.731089607, -0.800307573, 0.083230525, 0.589193733, 1.279732496, 0.673674587, 0.202668294, 0.502339569, 0.244678677, -1.383997327, 1.680757120, 0.903803911, -0.078987523, 1.141537203, -0.573870262, 0.286760324, 1.080644549, -0.480111451, -0.097690551, 1.734365825, 0.098260553, 0.016242804, -0.599256563, 0.102693885, -0.326842368, -1.143485749, -0.600251885, -0.946557747, -0.867519445, -1.065987677, -0.087067937, 1.653882488, 1.517346882, 0.896086154, -1.146785784, -1.631992499, 1.152531847, -0.477394769, 0.323136052, 0.537180021, -0.599594081, 0.507024322, 0.397804898, 0.170363858, -0.511149947, -0.010105545, -0.915725698, -0.667079388, 0.176987075, 2.263504626, 0.698946195, 0.301687702, -0.486464330, -0.899176894, 0.477051361, 0.771564680, 0.231903489, -0.432100541, -0.975644213, -0.486046906, 0.477318118, 0.789357941, -0.028715604, -2.860664147, 0.079844893, -1.469150651, -0.603509437, 0.613308071, 1.438072749, 0.716198960, 2.024533820, 0.772022148, 0.310066900, -0.925560590, 0.358824998, -1.121375297, 0.103007785, -3.697751884, -0.568085512, 1.099778041, 1.860794810, 0.807009544, -0.707107116, 1.609766710, -0.478621083, -0.448248547, 0.046897787, -1.037930510, -0.024993786, -2.610045020, -0.310858904, -0.900763689, 1.588411746, 0.839151272, 0.415512178, 1.285888536, -2.238559558, -1.461889695, 0.755031584, -0.450188705, 0.984993636, -0.659773553, -0.885698705, -0.183119540, -1.499706587, -0.549438284, -0.153642627, 2.376245341, 0.091082536, 0.435803486, 2.730594847, -0.076183204, -0.887912351, -0.052994282, 2.078178751, 0.573313363, 0.841147931, -0.329115929, 1.226275159, 0.038549922, 0.365754976, -0.058877345, -0.892811952, 0.904197694, 1.027454087, 0.023560154, -0.495534065, 1.036870310, -0.235982982, 0.891885256, 0.326418777, 2.816991884, -0.671339024, -1.331283115, 0.489113729, -0.361946505, -0.793665668, -0.236462118, -0.403803483, -0.063145045, 0.112953201, 0.284833194, -1.415758184, -0.426141925, 0.169361980, 0.207983632, 0.060535663, -0.821291852, 1.548847338, -0.253886065, 1.008677036, -1.945603390, -2.408961837, -0.586342098, 1.094049224, -1.124449027, 0.965764185, 0.119499096, -0.727906348, -0.575624058, -0.542845800, -2.036208266, 0.535166613, -0.859159366, -0.905627021, 0.602740991, -2.121126789, 0.794553514, -2.103262625, -1.097515001, 0.003808987, 0.342159266, 0.088677188, -2.374542927, -1.065956786, 1.715418864, -0.191746300, 0.154412052, -0.239302523, 0.027131792, 0.523454695, 0.796526583, -1.657524412, 0.448634691, -1.542579685, -1.183193008, -2.122997167, 0.397676745, 0.154007448, 1.186419268, 0.076548465, 0.056406584, 1.330921709, 1.540798571, -1.467824104, 0.195711450, -0.054420017, 1.166574056, -1.188344739, 0.424218575, -0.508614877, 0.144934226, -1.311339585, -1.385510901, -0.095730687, -1.656198325, 1.033687021, 0.859524615, 1.289597305, 0.756777473, -0.798693814, -1.198611099, -0.614499219, -1.222580579, -0.922134293, 0.978438192, 0.626176490, -0.161939408, -0.671285248, -0.493538115, 0.226641545, -0.899114939, -2.204390176, -0.102736943, -0.331325933, 0.002787162, -0.407514111, 1.610711321, 2.236545568, -0.335270121, 0.678659711, -0.288222303, -1.333078943, 0.232671108, -1.070792539, 1.002556427, -1.161288491, 1.280520159, 1.875321945, 0.547164010, 1.525111148, -1.117412308, 0.823413397, 2.438158544, -1.004818245, 2.554529855, -0.902707333, -1.521758310, 1.594776544, 0.574258870, -1.142581303, 1.166190499, 1.582596827, 0.310470623, 0.076832499, -0.095987612, 0.728080456, 0.884627214, 1.441892188, 1.378048981, -0.223051349, -0.221785402, 0.512346458, -0.966958563, 0.247041817, -1.187736487, 0.990502095, -0.502344245, -1.383996331, 0.343775260, 0.138149460, -1.549530510, -0.209550485, 0.746585610, 1.460900591, -0.950976512, 1.032218627, 2.091630524, 0.598007697, -0.328600254, -0.293932240, -0.822092733, 0.340223970, 1.114234850, 0.490856607, 1.120074722, 0.026269828, 0.096180777, 2.231526269, 1.376057399, 0.507093708, -0.206194334, 0.496648172, 0.704628452, -0.080878680, -0.753100289, -2.065075870, 0.179833912, 1.220376441, 0.693104947, -0.072916538, 0.237999888, 0.462485689, -1.009409057, 1.231669281, 0.475626964, 1.351945452, 0.382320124, 0.221649522, -0.062548868, -2.197679404, -2.647229380, 1.112018342, -1.010171154, -0.917965520, -1.103226211, 1.131881004, -0.095371679, -0.007214550, 0.531064718, 0.451046194, -0.629637864, -0.901763605, 2.262064727, 0.561145997, -2.073518365, 1.550190902, 0.200908215, -0.434051627, 0.058343177, -0.738937238, 0.736993449, -0.019069855, 0.147433788, 1.069053129, -0.695344955, -1.306024632, 1.040134404, 3.310327005, -0.505342102, -0.404125969, -0.643780616, -1.200062712, -1.151531446, -0.287703174, 0.345282026, 1.094834778, 0.324693580, 0.263146315, 0.008185711, -0.289373524, 0.280121095, -1.239883559, -0.237320176, -1.031319588, 0.965086483, 0.647165835, -0.593104416, 0.704353782, 0.399025857, 0.426952279, 0.056425533, -0.072448503, -0.861217022, 0.045220031, -1.061431735, -0.112312297, -2.079990661, -0.035756872, -0.301654522, 0.737622083, 0.069074102, -0.759888395, 0.651925689, -0.979139938, -0.430807314, -0.129745327, 0.350650330, 0.002018607, 1.067624896, 0.943097863, -1.244000381, 0.028498127, -1.564076501, 0.027849667, 2.215388683, -0.436651548, 1.344039646, -2.090369172, 0.286318545, -1.882029549, 0.576800067, 1.336577790, 0.069095625, 0.877834171, -0.906711179, 2.169048834, -0.965482726, -0.350199761, -1.903298969, -0.290200807, -1.929769685, 1.084044432, 0.313222938, -0.619853570, 0.992022109, 0.745005395, 0.602317915, 0.781893929, -0.163446296, 0.331582263, 0.701862574, 0.326889239, -1.126736543, 0.674521763, 2.470635585, -0.157626472, -1.049332559, -0.525993363, 0.642184692, -0.063775303, 0.348991652, 0.261741416, -0.314802462, 0.298681772, -0.143219479, 0.219582865, 0.023127731, -1.204748395, -1.375631844, 0.869791735, 1.362931511, 1.026785240, 0.136360371, 1.180363850, -0.153404638, -0.895487669, 0.809928201, -0.372352816, -1.305095372, -0.431018310, -0.901419662, -2.464045894, -0.004797200, 0.270501102, -1.535587418, 0.372298009, 0.047021586, -0.299555567, -0.076010730, 0.621015412, -0.460696255, 1.623660819, 1.546317472, 0.289302803, 0.924048029, -0.206429096, 0.290377820, 1.023797584, -1.430087736, -1.093206758, -1.653103953, 1.489802873, 0.010376003, -1.466677547, -0.149311839, 0.055359271, 0.225589108, -0.076375548, -1.375195834, -0.914798963, -0.166396582, -0.049005981, -0.376721351, 1.041427842, 1.312892092, -0.383813356, -1.548027435, -1.022492977, -1.397241017, -0.277164894, 1.417490885, 0.237493735, -2.153946099, -0.770450819, 1.083359208, -0.458357742, -1.609471741, 0.832038537, -1.004097349, 0.316891725, -0.518042205, 0.109462150, -2.139227291, -0.991166055, -0.140439043, 1.927560947, 1.471350176, 0.812448336, -0.911618051, 0.941911639, -0.184531798, 0.982120894, 0.490278505, 1.246589261, -0.407935056, 0.099741191, 1.781070994, -0.989140879, 0.454249999, 0.240243287, -0.125406890, -1.169108649, -0.891319822, -0.708563300, -1.391544890, 1.290937414, 0.150284440, 0.502679500, 0.097362368, -0.439952874, -1.816065902, 1.342694209, 1.370778960, -0.040103600, 0.910070805, 0.528051532, 0.026034319, -1.451520852, -1.257713726, 1.730856648, 0.350464302, 0.005240072, -1.033343354, -0.217148940, -1.332264561, 2.257003140, 1.177377434, -0.899259580, -1.805300747, 0.563434647, 0.459630838, 0.914807180, -0.719913604, 0.675807504, 0.858278346, 0.430617661, -1.325233950, 0.382317588, 0.689038498, 0.452277641, -2.871323405, -0.429250466, -0.271028678, 0.057913552, -0.686272173, -0.094119759, -1.126835963, 0.534069191, -0.433701845, 0.712532373, -2.474155004, 0.065118830, -1.245492122, 0.053474967, -0.327923526, -0.424137778, 0.094834190, -0.925813040, -0.301017349, 0.917602103, 1.415713307, -1.200771404, -0.842497906, -1.520475204, -0.065633868, -0.261775606, 0.817608184, -1.527942799, 1.067270053, 0.805552848, -0.467926144, -1.034195682, 1.558147259, -0.017363222, -0.842851009, -0.539759290, 0.379524729, 1.528801532, -2.485313317, -0.791470619, 0.305210264, 0.088128011, -0.384765763, -1.518032261, -0.501312587, 0.153739109, -0.100534285, 0.852418553, -0.312906240, 0.223553754, 1.272582972, -0.015513483, -0.171350374, -1.180996680, 2.072376268, -0.685216292, 0.536298787, -0.573512759, -0.072705105, -0.609059208, 0.063276975, 0.281298784, 1.115393068, 3.006929309, 0.637622473, 2.145161439, 0.632840399, -0.486689179, -1.204703136, 0.996637481, -0.622245555, 0.563289220, 0.031229169, -0.525329000, 0.490514727, -1.062923612, 0.854026480, 0.338507149, -0.181407238, 1.166036207, 0.755825680, 1.927331853, 0.678182587, 2.040147948, 1.051566004, -0.499480118, 1.153716813, 1.136940965, 0.163578320, -0.980492112, -0.930636052, -0.438024247, 0.707209623, -0.850608252, 1.392070004, 1.197381707, 0.707758931, -1.709626609, 0.620726917, -0.840636107, -0.575381314, 0.917915936, -0.314564748, -0.911021677, 0.353460005, -2.009276714, 0.413652513, 0.011206169, 0.775490847, 2.444637416, 0.060827667, 1.716561128, -0.110957959, 1.339262978, 1.392942243, -0.118314063, 0.072675812, 0.847769827, -0.500655582, -1.631268196, -1.035702070, -0.209315966, 0.247248613, 1.099586846, 0.711149113, 2.028484741, 0.948135146, -0.498569478, 0.718717544, 0.536279162, -0.172267315, 0.183726579, -1.075591694, 0.775590673, -1.921794466, 1.207664155, -1.308423647, 0.416549370, 0.098125920, 0.020198589, 0.354205187, 0.496259910, -0.262627918, -0.085925537, 1.905145567, 0.857586468, -0.259148094, -1.826313166, -1.257523650, -1.003184163, 0.072242897, -1.169708664, 0.813677693, 0.264749063, -1.214665349, -1.012187800, -1.246427496, -0.745487312, 2.047743838, -0.592134197, 1.859893020, -0.516992675, 0.158430909, 2.242947384, -0.645865580, -0.528186813, 2.375639150, -0.221535975, 0.071995115, -1.162335372, -0.565537576, 0.624877900, -1.837033888, 0.840936323, 1.476076121, -0.902764223, -0.801463298, -1.582321110, 1.322368230, -0.663007703, -0.898994125, -1.483587378, 0.817826659, -0.998929788, -0.486901362, -0.424226937, -0.211106195, 1.279476146, 0.167914152, -0.624178754, 0.768332494, 1.497415382, -0.345915573, 0.494941388, 1.024726746, 0.568908902, -1.305436827, -0.482185797, -0.007248805, 0.459200540, 0.652530314, 1.632610852, -1.244437456, -0.102139996, -0.352320586, 1.527539128, 0.059200835, 0.800030292, 0.880485124, -0.414010463, -1.473288203, -1.022759651, -0.289775390, -1.062219598, -0.569767680, 1.855992250, 0.359021857, -1.702093932, 1.921048865, -0.702366858, 0.918432737, -0.062067241, 0.570279831, 0.795041020, 0.710051256, 1.929112428, -0.036205708, 1.748905458, -0.779810075, -0.911265304, -1.515725719, -0.332376054, -2.385951495, 1.303934513, -0.418366878, -1.318281621, 0.530244671, 0.085605533, 0.183879000, -0.406496201, -1.095418857, 0.801708815, 1.339701539, 1.804202684, 0.564162537, -1.218249092, 0.035690504, -0.268553734, -1.013469015, 0.540928337, 1.636077815, 3.130601676, 1.142889526, -0.465766896, -0.967653930, 0.814706438, 0.098286350, 2.855764427, -0.308316704, -0.935993941, -1.476028270, -1.396945033, 0.939401609, 1.425907752, -0.156225759, -2.183156601, 1.826139656, 0.106455687, -1.841030198, 0.898148034, -1.229950285, 1.179082750, -1.753429163, 0.442987302, -1.785823624, -0.282180524, 1.046154034, 2.398362105, 0.602724596, -0.431581021, -1.027935920, 0.714076734, -0.043251209, 1.322817269, 0.701568809, -0.317075375, -1.214682939, 1.436373469, -0.409272275, -1.125744061, 0.671813709, 0.643701656, -0.429353623, -2.027526564, -0.271349635, -0.639735473, -0.542367526, -0.472898955, 0.126311651, 0.273528274, -0.591015521, -1.107959276, -1.694366927, -1.843294739, 0.562362817, 0.240734022, 0.562008591, 0.319224979, 0.451811350, 0.712834471, 1.364312648, -0.602697324, 0.934370921, -1.054689426, -2.074739365, -0.354313531, -1.622464929, -0.715083118, 0.171840829, 0.609386881, 0.175884179, 0.355251105, -1.922964412, 0.524782659, 0.199776136, 0.311020246, -0.814993410, -0.241507225, 1.039354211, -1.356141092, -1.737946687, 0.268636654, 0.764061439, 0.256561440, -0.067197418, 0.544310373, 0.820531380, 0.327115150, 0.343186565, 0.770891688, -0.681579504, -0.462391690, -1.214100516, -0.079435976, 0.201549585, 0.298204838, -0.210077304, -0.291530665, 1.663979597, -0.486403482, -0.820254790, 0.336629451, 0.124651377, 1.049259386, 1.964077392, -0.007929999, -0.435878843, 1.462073822, -0.509881746, -0.894223273, -0.302397777, 0.672842604, -1.636688684, -2.580629154, 1.453164469, -0.633720929, -0.110182205, 0.281605202, -0.598019147, -0.306349339, 2.244805786, 0.522244549, -0.118400474, -0.495277839, -0.020090863, -1.507384055, 1.312744353, -0.982620217, 0.241499766, -0.605062341, -1.340673345, 0.603021828, 1.367010076, -1.128834735, 0.634654226, 0.344534329, 0.592239956, 1.112643973, 1.191776292, -1.096383083, -0.196719432, -0.685832049, -2.447671658, -0.353320203, -0.854262166, -1.618977285, -1.302341752, 1.031501395, 1.155369541, 0.496244493, -0.003344900, 1.420027166, -1.933483987, -0.013586987, -0.052874582, -0.265002899, -0.098595451, -1.578492501, -0.248273602, 1.652532640, 0.011079306, 1.048657604, -0.786745604, 1.113064378, -0.044199926, -0.492673383, -1.100745619, -1.166420522, 0.676985216, 0.913858562, 0.484009926, -0.273993962, -1.048575487, 0.785266767, -0.289463423, 0.184769044, 0.154805859, 0.011516957, 0.423427362, 1.859818695, 2.098671607, -0.306319194, 1.384153991, -0.919158519, -1.201894436, 0.640543761, 1.805738921, 0.324656441, 2.124769118, -1.056050916, 0.812329744, 1.651623288, 0.452677461, 1.130882695, 0.445545075, 0.738406021, 1.133077794, -0.941342881\n0.0140533\n\n\n4\n-0.713427649, 0.327011944, 0.785237396, -0.795413291, -0.033571738, -1.236616159, 0.108050722, -1.279797735, -1.265526395, -1.824989875, 0.885706304, 0.405068345, 0.179671532, -0.517893011, -1.255636654, -2.390852794, -0.991637006, 1.048680989, -0.919736328, 0.744062588, 0.928337059, -1.593145630, 0.110196278, 0.495122044, 0.533927948, 0.553805875, -1.805799844, -1.377906794, -0.682524619, -1.101904595, -0.954035270, 1.364088376, 0.085035373, -0.143475863, -0.795201884, 1.641012236, 0.446804569, -0.892098784, -0.042058545, 0.683115061, -0.648998451, -0.314063380, 0.308667380, 0.294167403, -1.883819413, 0.273666271, -0.934336960, -0.562312629, 0.600277779, 1.018308108, 0.960212901, 0.927506877, -1.899639728, 0.794295029, -0.584617343, 1.371273248, -0.079919754, 0.714304442, -1.294091860, -0.241447107, 0.564629589, 2.216761768, 0.707513844, -0.823585743, 1.424439690, -1.471536228, 0.306297826, -0.831509047, -2.044193591, -0.218044457, -1.392069870, -1.348200700, -0.333116472, -0.273424690, -0.281018005, -0.610937043, -0.400204273, -1.263206864, -0.196125148, -1.553624191, -0.524800259, -1.285833926, -1.310004093, 0.854077897, 0.513668623, 0.209693487, -0.838134089, -1.075026036, 2.017074740, -0.376243734, -0.199440021, 0.158657027, 0.257244527, 0.317428300, -1.592999906, -0.077460693, -0.727385911, -0.364990261, 1.126260154, 0.847341667, 0.337105046, 0.100800943, 0.188547560, 0.824949682, 0.658856095, -1.124910796, -1.079788711, 0.209588553, -1.548597646, -0.205326728, 0.031169737, 1.920354672, 0.264268264, 0.953249583, -1.419321715, -1.358017185, 0.725933952, -0.437048709, 1.444614991, 0.952989257, 0.866096844, 1.478942909, 0.770309174, -0.361970029, 0.520437704, -0.099742115, 1.170480130, -1.491323644, 0.232442641, 0.298554403, 1.104238729, -1.405638689, -0.078561380, 1.194931959, -0.676090349, -0.374959704, 0.663446796, -0.390259466, 0.232308738, 0.442751175, 0.464758963, 0.880067606, -0.103502987, 0.675733644, -1.893418740, -1.123799432, -1.394260652, -1.478399491, 1.831013208, -0.161502976, 0.289208855, 0.387868896, -0.579345720, 0.638834030, 0.578020515, 0.176585956, 1.313248048, -0.619822868, -0.608711618, 0.532150849, -0.644852426, 0.172526353, -1.173519337, -1.416472945, -1.946941334, -1.797953672, 1.260328173, -0.486091587, 1.535410421, 1.771653371, -0.503465731, 2.100189960, -1.304941844, 0.994735348, 0.953550246, 0.463187336, 0.121909426, 0.599779189, 0.956733308, -0.360561267, -0.815841338, -0.829510915, -0.524569623, 1.272850870, 0.482367457, 1.104194319, 2.661847405, 0.192362452, -0.691675505, -0.682231191, 0.048240299, 1.566596178, -0.543170111, 0.182889115, -0.859022678, 0.019974666, -0.406558304, 1.538651757, 0.469951699, 0.751499892, -0.287273423, 0.081619061, -0.310189743, 0.651662179, 0.943606508, 0.079152755, 0.562786074, 0.743275857, -0.027122707, 0.887955713, 1.833280561, -0.592272115, 0.300003731, -0.530809784, 1.138911786, 0.569218487, -0.112221993, -1.633764638, -0.644541766, 0.014325247, 1.426241006, -1.173222467, 1.112232698, -0.162750059, -0.494195625, -0.370150940, -0.289196578, -0.421278262, 0.945803295, -1.315619229, -1.969623898, 1.370548278, 0.289706706, -0.258200084, 1.749114234, -0.073816919, 3.288542090, 0.832330754, -0.165304204, -1.679478468, 0.387714358, 0.055554894, -0.233651097, -0.510666064, -1.455270258, 3.107342859, 0.472830424, 1.433788522, 0.996716486, 0.635109397, -0.616564699, -0.463629524, 0.009516440, -0.421202566, -1.680887729, -0.328117788, -0.280981409, 0.569754957, 1.114350912, 1.373812878, -0.042174200, 0.746155531, -0.727021042, 0.442690808, -0.414142267, -0.381033215, -0.513513874, -0.534564552, -0.904490597, -1.287804735, -1.107269032, -0.485687699, -0.187281910, 0.251080082, -0.040373549, 2.786243288, -0.680158563, 1.344111147, -1.577209446, 0.378729029, 0.431080053, 0.828866718, 0.095095364, -0.293133916, -2.571826546, -0.220629813, -1.858539353, 0.370740474, -1.231748207, -1.540252836, 0.397745834, -0.653889469, 0.949790317, 1.214037264, 0.843830233, 0.444878809, 0.244373857, -0.224122063, -0.682125050, -0.557827943, -0.680081473, 1.282218498, -0.143240547, -0.633009159, -0.874307613, 1.250746091, 0.198238479, -0.022607462, 0.331022898, -0.865247820, -0.218178783, 0.445341063, -0.132731965, -1.228647757, 1.018055026, -0.379044531, -0.552687480, -0.624059497, 1.221997982, 1.026475207, 0.705046640, -0.146251074, -0.636277295, -0.772726930, -1.160090839, 0.153546102, 0.156911464, 0.248460600, 0.353385395, 0.517200658, 0.731813417, -0.153343081, 0.176250088, -1.909905511, -0.574783977, -0.515702863, 0.303250911, -0.034429748, -0.862138858, 0.907230192, 0.129606543, 1.180404060, 0.852855517, -0.931473504, -1.025091199, 0.451323420, -0.108055776, 1.557840570, 1.295878486, 1.073275497, -0.085044237, 0.027025929, 0.758263427, -0.703932399, -1.224886832, -0.910137127, -0.188255501, -0.499837722, -0.728102528, 0.120449921, -0.581690322, 1.948028993, -0.757591053, 0.518391947, -0.512214413, -0.238157097, 1.046543414, 1.120228707, -1.248822610, -0.823774331, 0.475832252, 0.142577455, -1.952432812, -0.957627439, -0.260977044, -2.095643443, 0.724093519, 1.813986241, 0.513330960, -0.416892608, 0.950377613, -0.265848286, 0.173145556, 0.679364601, 0.896954963, -0.367389177, -1.332913584, 0.573154159, -1.274085004, -0.743142861, 0.337437336, -0.140724136, 0.347409680, 0.070993482, -1.859182107, -0.049501851, 0.307044157, -1.682268710, -1.314120788, -1.469318681, -0.071942118, 0.094106920, -0.593004918, 0.157843773, 0.491694497, -1.490177869, 1.416808564, 1.252933744, 0.442213689, 0.468253931, -1.101702163, -0.372179794, 0.324750137, 0.495638638, 0.191208047, -0.356099810, -1.781671192, -0.513482600, -0.875523598, -1.051143345, 0.049785582, 0.957816708, -0.094737828, 0.220871699, 1.078076915, 0.012329701, 1.355955976, 0.575359658, -1.662377421, -0.102599094, 0.110741293, -0.052771504, 0.842796643, 2.040019995, -0.512456310, -0.838900835, 0.177505496, -0.261367634, -0.829952187, -0.458356716, -0.067708008, -0.327857665, 0.219963251, -0.002223389, -1.491604320, 1.930000505, 0.201218651, -1.782239068, 1.117224889, 0.011259715, 0.915677150, -1.285706777, 1.378662754, 0.856680520, 0.214403918, -0.032758429, 0.637406971, -1.590454007, -0.033356507, 0.528846953, 0.513441753, 0.709704387, -0.049748440, 1.593169414, 1.598708786, 0.319539084, 1.053521926, -0.591498637, -1.810212309, -0.345761264, 0.411851364, 1.121455693, -1.847149122, -0.363937279, -0.911797276, -0.141016577, 0.142444948, 0.318410657, -0.081860616, 1.563371726, -0.424969604, 1.624536838, 1.001697753, -0.599788105, -0.032910958, -0.536074206, -0.679055531, 0.014761258, 0.749407148, -0.571499614, -0.295692739, 0.194678268, 1.450767346, 1.982648699, 0.427412257, 1.074814380, -1.216308112, 1.736529983, -0.754311907, -0.983959615, 1.357691759, -0.500210745, 1.478802915, -1.846263829, 0.271232259, 2.022588091, 0.084218575, 0.234694233, 0.063188653, -0.989596380, -0.026115166, 0.758417754, -1.248876426, -1.049920146, 1.457435760, -0.806057012, -1.274583812, -0.275448289, 1.110964157, -0.411636376, -0.104714229, -0.857376015, -0.088398344, -0.657986725, 0.676869142, -0.879700204, -0.165960470, 0.938614398, 1.472178069, -0.923887681, 0.144150654, 0.779359787, 0.707302899, 0.950020271, -0.987436757, 1.033961039, -0.883538570, -0.395191829, 1.456778280, -0.299298667, -1.317218103, -0.921517023, -0.438004496, 0.662419458, -0.608603637, -0.217299921, 0.666121212, -0.404767582, -1.459923136, -2.169782359, -1.432396023, -2.107934052, -0.083532240, 0.081931766, -1.575142995, 0.270235045, -1.278032670, -0.642417333, 0.706660960, 0.195763632, -1.071182144, -0.556385065, -1.187888508, 1.667432653, -2.212780101, 0.112524833, 0.083054702, -1.374862268, -1.443729682, -0.300703211, 0.246562379, -1.263229306, 0.100483103, 0.137091097, 0.656011287, -0.308767184, -0.320383334, 0.480861682, 0.523300711, -1.062233765, 0.326422455, -0.912809122, 0.137619433, 0.120964638, -0.475737396, 0.228532850, -0.109312221, -0.944545663, -1.269635460, 0.406028996, -1.169877708, -0.996278713, -0.632922871, -0.780584664, 0.017094348, 1.231213280, -1.278817392, 1.956747567, 0.568559229, -1.721351706, 2.130329061, 1.390610601, -0.131521634, -1.718367793, 0.159810864, -2.308426452, 0.087968286, 0.223471566, -0.242688343, -0.884100790, -0.744986671, -2.055779108, 0.410222726, 0.532557888, -0.791301737, 1.449511196, 0.501432885, 0.075141028, 1.338451820, -0.663887835, 0.814111594, 0.436632907, -1.045812111, 0.798388735, 2.089213062, 0.435987541, 0.374289724, -1.090476964, 1.756481524, 1.173073842, -0.762341164, 0.537903913, 1.006410891, -0.086958838, 1.081591702, -0.081808197, 0.341708035, 1.375470193, -1.516695048, -0.758849954, -0.361163747, -0.530175061, -0.894026117, -1.151075042, -0.309718372, -0.565075304, 0.573301405, -0.229684379, 0.189718339, -0.356052767, 1.757934153, 1.521365983, -0.108228866, -1.453344735, -0.229275448, 0.295157801, 0.498290318, -1.364735287, -1.980888680, -1.364674384, -0.796810112, 0.560319384, -0.719836697, 0.674583119, -0.540813303, 0.389596526, -1.031839285, 0.734651378, -1.368348708, -0.514943975, 1.690371568, 2.056103907, -0.036572012, 0.526748509, -1.910497619, 0.491880294, -1.139773085, -1.020560551, -0.698118813, 0.124183332, -1.083337715, -0.703261420, 1.793625349, 0.641292210, -1.249188105, 0.294231407, -0.603898625, 0.734685886, 0.474249883, -2.448570434, -2.636210113, 0.153288034, -1.050873081, 0.176182559, 0.584645361, 0.481242732, -0.264649319, 0.231433286, 0.054155261, 0.659679196, 0.753013831, -0.141275824, -0.765206556, -0.816581458, 1.163272255, 0.558091529, -0.264943002, -0.087736737, -1.927008653, -0.389615510, 0.503113663, 0.539476995, -0.981032891, 1.008119234, 0.419291831, 0.129065989, -0.021471291, -0.437179564, 0.938823288, 0.374035823, -0.457742410, 0.532294936, -0.353864422, 0.285021310, 0.634118905, 0.023241656, -0.279771453, 0.559100223, -0.136355798, -0.679504328, -0.644640984, 0.949078458, -0.675301203, -0.097869712, -0.579702962, 1.181605299, 0.555865271, -0.267305895, 1.307325592, -0.516566695, -1.948779974, -0.102184666, 0.274803244, 0.850314990, 2.973801359, 0.678878155, 0.160820054, 1.469842775, -2.073882049, 0.001776201, -0.340242153, -0.543158024, -0.411201430, -0.921808532, -1.309180006, 0.217953506, 0.979927164, -0.397277911, -1.430023807, -1.143901949, 1.058917733, 1.386452470, 1.834871429, -0.813352471, 1.113618104, 0.127546112, -0.107629079, 0.146226844, 1.070613603, -0.414175020, 0.170566040, -1.473376021, -0.369259984, -1.002574076, -0.063330564, -0.884226293, -0.457072389, 0.734335617, 0.773028440, 0.101621841, -1.281753698, 0.107626403, -1.424102237, -0.770892605, -0.226512606, 0.058285616, 0.343149010, -0.629296716, 1.000232444, -0.968024566, 0.895155074, 0.465431665, -1.348185478, 1.562586006, 0.565948157, 0.088085765, -0.001021268, -0.456157111, 0.224666193, 0.881121908, -0.798440520, -0.587162258, 0.658064578, -1.169518775, -0.564724450, -0.346577759, 0.683240334, -1.076365623, -0.498385780, 1.377515441, 2.298100050, -0.264200333, 0.319381412, -1.527290581, -0.581497125, -0.535609757, 1.142808553, -2.781048820, 0.375985561, -1.942764437, -2.405743511, -1.652961749, -1.637113131, -1.242546024, -0.761604715, 1.112290192, -0.467890010, 0.146332878, 1.798896964, 0.815028076, -0.428597795, 0.227020663, 0.307829747, 0.521854086, 2.487340830, 1.313850155, -0.638781822, -0.130263452, 1.555170527, 0.494123499, 0.583294053, 0.810882383, -1.590638153, 1.527286547, -0.554771078, 0.344649408, 0.138172492, 0.048850618, 0.968580724, 1.547084812, 0.309730543, 2.288283779, -1.309155477, 1.010928630, -2.303216809, 0.200979026, -0.612933983, 0.201598382, -0.053657962, 0.146328939, 1.508912683, 0.957990424, -0.373475098, 0.726449607, 0.289919330, 0.063589768, 0.115151150, -0.324488496, 1.829899001, -2.308228305, 0.991624927, -0.611875864, 1.148120366, 0.321133140, 1.119622405, -0.365394389, -1.012696710, 0.868451522, 1.579948219, 1.359972885, -0.158567491, 0.482366907, -0.309909278, -0.022065475, -2.739437662, 0.067731546, -0.307385505, 1.076258227, -0.732479045, -0.229788809, 1.494405972, -2.226468597, -1.025574677, 0.529890436, 0.640963127, 0.009242953, -1.452143558, -0.514103838, 1.687853703, -1.734177207, -0.999579468, -0.162594348, 0.226698676, -0.487457004, 0.480558916, -1.666525640, -1.951195126, -1.554633523, -1.189303732, 0.901913090, 0.232542821, -0.176433840, -1.713279354, 2.299381312, 1.246415244, -0.303738583, -1.409716165, 1.531123798, -1.098296288, 0.921063534, 0.912326703, -2.256550902, -0.590068237, 2.028083587, 1.369990754, 0.425422766, 0.632749953, 0.777277819, 1.040310849, 0.384232543, 0.259022891, -0.246026638, -1.771938737, 1.530520818, -1.971448093, -0.882570888, -0.295162843, 0.376450346, 4.015695120, 0.775756422, -0.711011116, -0.670247453, -0.035354829, -0.229101617, -0.508604038, -0.037632817, -0.311700439, -0.152657560, 0.940012466, 1.138293802, 0.389200478, -0.459410238, 0.790713476, -0.198769708, 0.851791764, -1.148302190, -1.513172670, 0.496830268, 0.378929900, 0.223185441, 0.410234811, 0.357735699, -0.975186540, -0.694294183, 1.101945459, 2.411447076, 1.360967356, -1.476246175, -0.701554637, 0.190592300, 1.521381498, -1.418789481, 0.521968247, 0.691528264, 0.464972053, 0.484334933, 0.277903988, 0.014503996, 0.107396661, 0.075576599, 1.651132091, -0.315520767, 0.079753491, -0.701426175, 0.054717844, 0.965313022, 0.497598812, 0.626633425, -0.713751588, 0.508996068, -0.818435138, 0.261775253, -0.248830487, -1.665663061, 1.082778733, 0.164019484, -0.533175032, 1.085855756, -1.225645666, -0.242593388\n-0.0276406\n\n\n5\n0.1108419935, -1.4439815736, -0.0822593839, -0.6373849477, -0.3508634981, 3.0016619559, -1.2932163866, -0.1287034366, -0.2264336248, 0.7221056425, 1.0876634397, 0.4488831983, -1.4068513356, 0.4762098195, 0.2124125512, -1.6610902048, -1.6593913031, -1.2569109459, -0.6849242281, 0.5587560799, 0.7535169337, -1.0168006761, -0.3408905366, -0.6167194580, 0.9306923778, -0.2289756307, 0.6738576895, 0.0506152505, -0.2597385301, -0.6305482860, -1.5164953706, -0.0288645807, -0.6153330512, -0.5351325576, -2.1710923374, -1.8953806026, 0.6323731189, 0.0392283080, 0.5614786836, -0.1907252574, -0.0932687922, -0.3327053387, 0.2324152922, 0.0903914050, 0.3195013884, 1.0252842589, -0.2684306832, -1.0161721256, 1.0707993886, 1.7394941742, -1.0722886882, 0.1402592696, 1.8477273021, -1.1355527165, -0.7778544187, 0.3019072842, 1.1141172551, -0.2483917552, 1.3978047389, -1.1329438373, 0.9077741803, -0.1952867494, -0.0010562959, -0.7981120360, 2.3198056447, -0.3812620562, -0.4149550828, 0.5069495177, -0.1315738832, 0.8381334776, -1.7171240530, -1.5471378860, -1.4473730017, -1.0404368562, -1.2264249662, -0.1816427237, 1.1873589000, 0.1240877228, -0.5752369693, 0.7442620190, 0.8855154995, -0.3840680586, 0.7648515999, 2.5724343400, -0.5771722874, -0.6389499340, -0.7205208119, -2.0187950903, 1.5291628112, 0.5180824717, 0.6052182989, 2.2645280827, 0.9195024857, 0.5702984452, 1.3002856431, 1.2870937829, 1.8387542680, 0.1089917357, -0.6289964120, -1.8780882010, -0.2220724454, -0.6396053193, 1.5827903418, 0.1709202996, 0.1253233421, -0.0430933061, 0.2835837530, -0.3207267747, -0.0203170192, 0.1212051868, 1.1624917250, 0.6948991284, -0.6347955371, 2.5136989910, 0.4755964181, 0.1519263904, -0.6401836328, 1.3919648066, -0.2589559671, -2.5366441354, -0.6050963625, 0.7016406153, 0.4096711227, 0.9110895302, 0.7187891212, -0.5440578419, 0.2621604032, 0.5285840454, -0.1478964704, 0.1290910467, -2.4488701291, -0.3981521462, 1.4671835352, 0.8364091590, 1.6021105884, 1.9774932086, -1.5566410229, -2.3428148442, -0.2955667708, -0.6344880415, 1.6828502378, 1.1167739984, 0.0207440563, 1.5319452398, 0.3251390340, -0.0220459606, -0.0568762700, 1.3003554040, -0.7506749291, -1.0674333257, -0.4506726934, 0.8778694398, -0.5947873510, 0.0107867318, 1.1423357243, 0.3498458697, 1.8381339417, 0.3330039712, -0.5286941749, -0.3170400889, 0.5035262355, -0.8296835745, -0.7750926700, -0.6183744237, 0.0047833831, -0.7231608513, 1.5814223980, -0.3670822013, -0.5167320139, -0.0416536766, -0.1855655774, -1.9844517180, -0.3651669135, -1.8299774987, 0.7446682629, 0.8569898868, 0.3654850710, 1.0618878715, 0.4352910223, 0.8916468474, 1.2050631085, -1.2835091994, -0.0314408140, 1.1020198855, 0.6427120906, 0.6853833283, -0.8582235835, -1.6854143174, 0.7794617736, 0.8306453921, 0.0745565381, -1.2863042258, -0.0837252638, 0.8554511180, 1.0409897896, 0.0625128199, 2.3065762249, 1.4772335188, 0.4261625467, -0.9402224848, 0.5981915624, 1.3401016462, -1.7109305750, -0.3304830826, 1.0594519671, -0.5179583871, -0.3178815249, -0.4966564985, 0.6034760946, 0.4257338517, 1.2015515515, -1.3737902020, 0.6066206916, -0.3091002865, -1.2071598308, -1.5721390826, 0.4273421132, -1.3068052196, -0.3332487160, 1.3189585335, -0.3002279101, -1.7746166283, 0.4396002604, -0.7975809088, -0.6130360056, 0.3271814867, -0.5342003800, 0.3923870972, 0.7574025522, -0.3427042137, 0.9647152883, 0.3776802077, -0.3785226189, -0.5575471381, 1.6392153323, 0.2564793096, -0.2231900816, -1.1786699294, -1.4152625753, -0.1527267234, -0.7248454972, 0.1807984099, 0.6205405607, 0.4480576514, 1.2719067196, -0.0749578474, -0.5347752327, 0.4548612164, 1.2120003075, 0.9181526313, 0.4054339150, -1.0767798365, -1.8276414428, 0.5443748381, 1.0520400448, 0.4529082916, -0.4952598250, -0.7074137675, -0.2899605433, -1.2892148724, 0.4023175992, -0.1019996679, -0.1680377404, 0.7821437586, 0.6903424723, 0.0234377262, -0.6100526902, -0.7944238387, -0.3468587078, 0.3208899694, 0.4495165423, -0.6553621975, 0.7049844114, -0.1044933892, -0.2763243060, 0.1552991071, -1.1245244882, 0.5640623001, 0.2194674283, -1.2306220860, -1.3324093313, -0.0954707155, 0.1823673483, -0.3171108995, -0.4952826252, 0.7022632772, 0.7136397458, -1.6016379434, 1.5562423860, 1.5685495042, -0.2359697560, 1.2644125132, -1.3070273416, 0.7371784973, -0.1581602574, -0.2521713255, -0.2671952146, -1.4628438914, 0.0779780471, 0.8640586932, 0.1055223276, 2.3675278220, -0.3780462392, 0.0450212535, -0.9343876770, -0.7914157897, 0.9369745448, 0.5272834870, -0.1522867624, -0.7148214776, -0.8546428982, -0.9528239664, 1.2839927043, -1.4074988820, -0.3247927765, -0.0618854745, -1.2647463502, 0.1280195695, 1.0567574061, 0.8112323507, 2.2877844338, 1.1276199885, -0.8432085921, 1.4613108928, -0.0095722757, -0.3847390997, 2.6971619952, -0.7737684062, 0.0017057614, -1.2122675092, 0.4690242085, 1.3735311279, -0.6870759123, -0.7051305469, 1.1010387922, -0.5352573004, 0.1063013689, -0.2055718903, 0.5637667749, 0.0957386916, 0.3890329613, -1.5077476469, 0.2778421111, -1.6217478170, -0.3891324164, 0.2191923757, 2.0502177089, -0.1381068017, 0.4533290920, -0.1980682713, -0.4291764548, 1.0908965346, -1.4269684580, 0.9688695928, 1.1564807820, -0.5452871033, 0.2360209049, -0.8658174059, 0.4138591951, -0.2648662228, 1.8356822031, -2.1118087718, -1.5172394042, 0.1917345516, -1.2866071849, -0.2130688705, 0.0507961242, 1.3923564898, 2.4144277029, 0.4547865868, 0.4001703805, -1.4646688635, 1.3103920361, 0.1544426873, 1.8727321648, 0.0336529880, -0.5509064243, 1.7440172578, 1.9039731236, -1.7526514779, 0.6172026634, -0.0136343816, 0.7102457106, -0.2962229748, -1.9237587420, -0.7753073037, -1.1884800392, -0.9109266000, 1.0199793390, 0.1338100451, 0.1287786397, -1.2780633249, 1.4096732374, 0.3242055377, -0.1557647478, 1.5932959823, 2.6352947397, -0.9742287715, -1.0189531740, 0.3098325361, -0.7325486850, 1.2344586960, -1.3219325838, -1.2067290708, 0.1159585641, 0.3867444835, -0.1475370914, 0.1231836590, -1.0286960931, 0.0405573260, 1.8483616747, 0.3532901834, 0.0104956613, -0.3380206781, -0.5783092682, 0.5779280064, -0.1421380762, -0.8650121392, -0.4518810963, 0.3106488531, 0.5894720027, -0.4799577715, -0.5804574324, 0.8096025718, -0.9119532948, 0.0985381315, 1.3305393646, 0.9518316328, -0.7937106905, -0.4669497624, 0.4155645983, 0.5462861386, 1.1521614249, -1.1053977814, -0.3996020184, 1.6859134529, 0.1335693794, -2.0173087010, -2.7062626101, -1.6919575230, -0.7016016364, -1.1211434704, 0.7345879668, -0.0348254916, -1.0237247259, -0.2034181901, -0.1045040713, -0.0848192367, 0.2322157667, -1.0656910800, 0.5397485731, -0.2618692406, -0.3467125042, -0.0607353820, -0.4118395080, 1.5560155649, 1.6012009800, 1.4882603305, 2.1446298405, 0.0602130322, -1.9746854286, 1.4023305780, -0.4128781199, 0.4338199610, 2.3622120724, -1.3431603625, -1.5933007446, -0.2593498752, -2.2139004126, -1.1684633683, 1.4593949614, -0.1105342020, 0.7304043065, 1.6259843026, 0.0531502437, 0.2510173365, -0.1241221710, 0.6188944219, -1.1514217207, -1.1565989721, 0.7954014523, 1.5060472207, -1.5066800040, -1.3622605746, 0.1799073759, -0.0004602177, -0.1035092992, 1.9640367747, 0.8157615594, 0.9141970454, 1.9789561441, -2.0541951907, -0.3103509463, -1.0588022941, 1.3749106848, -0.2477943087, 0.8477682892, 0.0618581572, -0.1942560369, 1.3195880725, -2.1700537791, 0.4469450877, -0.6665484519, -1.3334921971, -1.8884189646, 1.5284716465, 0.1084464632, 1.3710829422, 1.7999222328, 0.4188619822, 0.3500838973, 0.6999025228, -1.9749357497, -0.3376866338, -0.1958657009, -0.6831628518, -0.9849506575, -1.1990812076, -0.5586557836, -0.0028766892, -0.1808894473, 0.4423017354, -1.9289942495, 0.2056122876, 0.3254502814, -2.9924620137, -1.2008126593, -0.3667270895, 0.6343571838, -0.3660375042, -0.2415091199, -0.0162854720, 0.2752755216, -0.1487834510, -0.3760581327, -0.4137552311, -0.9077541342, 0.5587343995, -0.5893629979, -0.5539756097, -0.5257141626, -1.9840131763, 0.9936555470, -0.1567050829, 1.3726311507, -0.4778714721, 1.0142999725, 1.1729941812, 1.3255240622, -0.4652610493, -0.2809449749, -1.4091724563, -0.8915608099, 0.2024279224, -0.0557491546, -2.0724963555, -0.1202622526, -0.0225101522, 2.3682291855, 0.4655967093, -1.0200130840, -0.2181170733, -0.5496375926, 1.5564558777, 0.0949437503, -0.3140530853, -0.5130200140, 0.6124530913, 1.0905793019, -1.3467623253, -0.2772667786, -0.7126151068, -1.9703954877, -1.0475672302, 1.2084692022, 1.8278663192, -1.8054532688, 1.0523873216, 1.5805291448, -0.4001170080, -0.8345858347, -0.5454414252, 0.6916213815, 1.1865220998, -0.6419869403, 1.9318454446, 0.8919479802, 1.4615613596, 0.2125707875, 0.1856800941, -1.2450108162, -2.0447614110, 0.2131251124, -0.7257818490, -0.0006143089, 0.4825783831, 1.6694056625, 2.4201754852, 0.7785399697, -0.6573062339, -0.7670972153, 0.6024505395, 1.3715894193, 0.0156990833, -1.8251172826, -1.5477400539, -0.0205458689, 0.5074900557, -0.4757835899, 1.7069648468, -1.1550984243, 0.5695994308, 1.3176262248, -0.3680306315, -0.3728401539, 0.2705289205, 1.8083110519, 0.2949974636, -0.2828213856, -0.2734994509, -0.1310349789, -1.9923130909, 0.1669175020, -0.8992225217, 0.0197138227, 0.9827633346, -0.2128013936, 0.1028906823, -0.5379267318, -0.2371426728, 1.4157720330, 0.8997985465, 0.2610262785, 2.4939388709, 0.2434108004, -0.0933388918, 1.3108350046, 0.8409435989, -0.3862955620, -1.1664962350, 0.4717417072, -0.7630873185, -0.4018835330, -0.3590689397, 0.4133978686, -0.0957373703, -1.1474997701, 0.4756266455, -0.6193886008, -0.2781632285, -1.5021973125, 1.2951244056, 0.6057171698, 0.6172578141, 0.6229138041, -0.5257964836, 0.3758280930, -0.4834612166, -0.9228694509, -0.8671339686, -0.5888413650, -0.5527800569, 2.0522765296, -0.1666917432, 1.3058173860, 0.5132773547, -0.9335699253, -0.2843517931, 0.2524589100, -0.0759222609, -0.6627251500, -1.1337363472, -0.5582937970, -0.7617144921, -0.0092526007, 0.6103129464, -1.3249891601, 0.0643695849, -0.4060151127, 0.1464589930, -0.9286891757, 0.2506341265, -0.8837558093, 0.9627892073, 0.2326009329, -0.7380685257, -0.4616386097, 2.0384575629, 0.7987859785, 0.0612994450, -0.3530535839, -0.5309793978, 0.7646339473, -0.3230921663, 1.4268604945, -0.5681791604, 0.4434423367, -0.2131721586, -0.2621100623, 0.5988805543, 0.3088089322, -0.4302148829, -1.5938221413, -0.9555470256, -0.0069557901, -1.9428413266, -1.2844804803, 0.4548687573, 1.2222921578, -1.4451762250, -1.0154458060, -2.4053890523, 1.4738626722, 0.4626695755, 0.2955072024, 1.6363790172, -0.0408313384, 0.6048036949, -1.6157700251, 0.7401797609, 0.1216143203, -1.3744802212, 2.0341038213, 0.2140287577, 0.4523580547, -0.0691780074, -0.6257620984, -0.5274345403, -1.2460876600, 0.6433721387, -1.7710669164, 1.0071761659, 0.0321350736, -1.2601982234, -1.4655656435, -0.8181809765, 0.6738811193, 0.9439382182, 0.0308443553, -0.2274145911, -0.4311874621, -0.1770479507, -0.2717300217, 0.2345761063, -0.7816690694, 0.5058085596, 0.4221258102, -0.6357523269, 1.3651954537, -1.5986530634, 0.0199692413, 0.9542365487, 0.8608438957, -1.0331462250, -0.6950822217, 0.4212569960, -0.6174772064, -1.1331021566, 1.1409953671, -0.0275710362, 1.1806156228, -0.4808058503, -1.0262264543, 0.7205734834, -0.6674681012, -0.7386365318, -0.1668646431, -0.0197297858, 0.0587799767, 0.1934269132, 0.3625303182, 0.2557286740, 0.1225608383, 0.5660311401, -0.3488448550, 0.3330009712, -0.0939938410, -0.7698725658, -1.3683491426, -1.4464380373, 0.3179260987, -0.2567162956, -0.2651539955, -0.4905595034, -0.8274587216, 0.0534954630, -2.4414984188, 1.3965266892, -1.2568338838, 1.7944262636, 1.4383515712, -0.6252921886, -0.7843512957, -0.2082198417, -0.1222909171, -1.2956314030, 0.1099556120, -0.6636072351, 1.1893453294, -1.6195380905, 0.2030195293, 1.3909856674, -1.7784217336, -1.2639888206, -0.3351935946, -0.9160754418, 0.0569406226, -0.1909256874, -1.0813980495, -0.1167614820, 2.4489776387, 0.8949711758, -0.7049449537, -0.1581863769, 0.4704855361, 0.3050967277, -0.6612132355, -0.2947729566, 0.7511345201, 0.3908027980, 0.1063436767, 0.5781365809, -0.7328357828, -0.6917085161, -0.4945186991, -0.3023469262, 0.4138631827, 0.4231570446, 0.7985470706, -0.7531739769, -0.5732089111, 0.3530993582, 0.8655841938, 0.6667721144, -1.3643079254, -0.1783130132, -0.7418566341, -0.3903136259, -0.7623696390, -0.9630892230, -0.0928547084, 0.3338715206, -0.5055638228, 0.7571030375, -2.0794907723, -1.5799561255, 1.0374091002, 1.4096463763, -1.6092265999, -1.1739991291, -1.6197091181, 0.3961568745, 0.9511094689, 0.2628015052, 1.7730015818, 0.6365424518, -0.7337647615, -0.5199194845, -1.3111175595, -0.6188310272, 0.9347129197, 1.4988705233, -0.4042536756, 0.7218673296, -0.7645885760, 1.2648138629, -0.1814649681, -0.3729263767, 0.4694623990, -0.2144930110, -0.3714312938, 0.5960179820, 1.0374408326, -1.9550125956, 1.5977618218, 0.4209271056, 0.2285662845, -0.5002681930, -0.3428793836, -0.7433453005, 1.2815938308, -1.3188344535, -0.3009231124, 0.9449815792, 0.3854157623, 1.6187761852, 0.2403736266, 0.2814402802, 0.7221974611, -2.3694050525, 0.8436235121, 0.2367008278, -2.0412581008, 0.6580892909, 0.7402485476, 0.1144613228, 0.9337276471, 1.7399512466, 1.1700420190, -0.3447625478, -0.5912173208, 0.9734186690, 1.8089480240, 0.7834644940, 0.6079714584, 1.1476729655, 0.0638583958, 0.5609017954, 1.0639521624, 0.6131233540, 0.1322679066, 1.3701747824, 1.7774986390, -0.7672138917, 1.0079667592, -1.3545386496, -0.0186818844, -0.2595285909, -0.9143528903, 0.7714894982, 0.1395959090, 0.0726524707, 0.7071262375, 0.3906439447, 0.5595306856, -0.3775261759, -0.1187765501, -0.7979722495, -0.8395287050, 0.8425756046, 1.7685713710, -1.0065360249, 0.5794972074, 1.2314391598, -0.8655407005, 0.3049770475, 2.0474429178, -1.2928733684, -0.0881542378, 0.1944198673, 0.1689117966, -0.6076113229, -0.3326665840, 0.2203057652, -0.2288455128, 0.1392847659, -1.6288082665, -0.3732683721, -0.1397198423, -0.5749551831, -0.2171183832, 0.1641895786, -0.8654016554, 0.7286335464, 1.7035893621, 2.0160915966, -0.2342836421, -0.4171515315, -0.6687532083, 0.1835762982, -0.0659986226, 0.4723331365, 1.0322099431, 0.2355142158, -0.0961822521, 1.7916940611, 0.1373343916, 0.4153555363, -1.8458922784, -0.0137471576, -1.1108388187, 1.5256728206, 2.7153052871, 0.8266358326, 0.6133657643, -0.0604279386, -0.5339655408, -0.2770486883, 3.4368946121, 0.3011729137, 1.2001524023, 0.2357677421, -1.1427302472, -0.6105504713, 0.1323911545, 0.4066511874, -0.9289611128, 0.0631364702, -0.0393368979, -0.3423747555, -0.7118989016, -0.0335323006, 0.7687255404, -0.6937225214, 0.6082265110, -0.5568268119, -0.5111239435, 0.7231807600, -0.9038238961, 0.0904979588\n0.0101167\n\n\n6\n1.7929632770, -0.7352684659, 0.4073985804, -0.3086796620, -1.1839738377, -1.4197291629, -0.7169555496, 0.1203513409, 2.5149309385, 2.4692912153, -1.1481953059, -0.1553506551, 0.3071285188, 0.4955145856, -0.2151395120, -1.1208275672, -0.1809047934, -0.8229707849, 0.0802755907, 0.2730936799, 1.0684339121, 0.0240289609, -0.1347733252, 0.6263034620, -0.7385485723, 1.1010781257, -0.3630504409, -1.0521643955, 0.8673717482, -1.0578212230, -2.3216585160, -0.4262263146, -1.4093502180, -0.4588788913, -0.1094954724, 0.7109277407, 1.1836273484, 0.5939686540, -0.2879842070, -0.4085386305, 0.2710898033, 1.0774354841, -1.8458079795, 0.0943240268, -2.1313695246, -0.3530223193, -0.6021901819, -0.4726222950, -1.1868572228, 2.7126666318, 0.5875703432, -1.0357174740, 0.4055427029, -0.1593572599, -2.4701887397, -0.1002124290, 1.2980904344, 0.0647980605, 0.2493509297, -0.1994271523, 0.4162729008, -0.2516880157, 0.4715033994, 0.0676158071, -1.4770522677, -0.4665713078, 0.5532605870, 0.3439251716, -0.9264702359, -1.4051644516, -0.3236743635, -0.1299791828, 0.4510486792, -1.1552305370, 0.3558257995, -0.2617020387, -0.2176998758, 1.1385475193, 0.0799027382, -0.5048187643, 0.0954962617, -0.4802069676, 0.4163354624, -1.6360220765, -0.3088456748, 2.3216278140, 0.3606884231, -0.0260079418, -0.9476822048, 0.6871647235, -0.6736623723, 1.0476191937, -1.6969277102, 0.4387337545, 2.3464102730, 0.1959207574, -0.4048067180, 1.0691424154, -0.3228722290, -0.1797038149, 0.7689042768, 1.4508969055, -0.4318995505, 0.2915148912, -0.5808177045, -1.5185069524, -0.0598225772, -0.5622042523, 2.2004727181, -0.0163288674, 1.4641290514, -1.6631827256, -0.0325900814, 0.8449261565, -0.1224132881, -0.8296934626, 0.5121898398, -0.3160908791, -0.7072938872, -0.5255864409, -0.2512625285, 1.4443812553, -1.8105998203, -0.4246714213, -0.2103760138, -0.0578940824, -0.5522716533, 1.6372356965, -0.1971963351, 1.0355501521, 0.7155331559, 0.9406800392, 1.1136225750, 1.1659762446, 0.4034833393, 0.4884161467, -1.8703798243, -0.3797871136, -0.0602522794, 2.3676552738, 0.2327360098, 0.3016789088, -0.4436589892, -2.1696766931, 0.7743094054, 0.8294548259, -0.4464023256, -0.7416370822, -2.2819470942, 1.8562303664, -1.2362240315, -0.5511607462, 0.8705152693, 0.7562485203, -0.7002023282, 0.4510382503, -0.0509898923, 0.5633557130, -0.8866725763, -0.1747668279, 2.0331235819, -0.6995113353, -1.2507761462, -0.1680578408, 1.0449859511, 0.1960585003, 1.2868572825, -1.2293201356, 1.2255730618, 0.4187474891, 0.4543546251, -1.4189051268, 0.9425978814, 1.7771031180, -1.1536321748, 0.7415511508, -0.6454531785, -0.2243508009, 1.1321832362, 0.9478826936, 1.9696974652, -0.0535971205, -0.8911262125, 1.1586005431, -1.1380359696, 0.7243724668, -1.2341230850, 0.3209835001, -1.0875785216, -0.5323219520, -0.5930078945, 1.6692317514, -0.1051484851, 0.3929022901, -0.4808131628, 0.6054673745, -0.0303438045, 0.0644358714, -0.3546776021, -0.3817811315, 0.0642438284, -0.0163473466, 0.6857396574, 0.1853029153, -0.3138192707, -0.9771649322, 0.8267077141, -0.8218851962, -0.0503348636, 1.8582519538, -0.6248003258, 0.9765742385, -0.2477062374, -0.9576130673, 0.5274947042, 0.1548037727, -0.1621978302, 0.0956744172, -2.0171528357, -0.2765919607, -1.0956860788, 0.5737076110, 0.1274375500, 0.1593889720, -0.0399472567, -0.2515798219, 1.2783532912, -0.1575637473, 0.7434516911, -0.3178421394, -0.9020291122, -1.0308910075, -0.3519246041, 1.5017262079, 0.1371522828, -0.5788650312, -0.2603738754, -1.2294849229, -1.2775762213, 0.8352349749, 0.1667807661, 0.2117503349, 0.3540307605, 0.0080785853, 0.4403911842, -0.3449237431, 0.9223221200, -0.6138106428, -0.9596966475, -0.6535532067, -1.7556531965, 0.0452107439, -2.1299511858, 0.2790673912, 2.0246451950, 1.3895088918, 1.2396437874, 0.2132829788, 1.2107159014, 1.3677616346, 0.2374695987, 0.1268505415, 0.6871357823, -0.6313881833, 0.3016339737, 1.3305031394, 0.6541109279, -0.4225107830, -0.4820916257, -0.8403966487, -0.2565534920, 0.0910543560, -0.5803926346, 0.4585508151, 1.1501386663, -0.1330504319, -1.1031411842, 0.5189624104, -0.7067243746, -0.6779941713, -0.7181151312, -0.0002872247, -0.0378358616, 0.2163323500, -0.2358325773, -1.3057754066, 0.3564009272, -2.0245828927, -0.2990767274, -0.0456112421, 0.2701879949, 0.6227092997, -1.2631683478, -1.8268524450, 2.7961854489, 0.4775512473, -1.8739689674, -2.0296924953, -1.3182039240, -0.5614562084, -0.4840413989, -0.2717576840, -0.7728342018, 1.9707045996, -1.5761646615, 0.3803203576, 0.5572864003, 0.8528762992, -0.7447104162, 0.1335609724, -1.9578896484, -0.3679585370, -0.5231497889, -1.0003251884, 0.0676227509, 0.3738148233, -0.7055995495, -0.4906226207, 0.8430772004, -1.5037435312, 1.3152721703, 0.2829937002, -0.7968821552, -0.3826730478, 0.6248804528, 0.7973933721, 1.1043294113, 1.6183877237, 1.1449289221, 0.4385174961, -0.0325810577, 0.1776283900, 0.0055520170, -1.4011723290, 0.3538178875, 0.4454725567, -1.3695807792, -0.4658526635, 0.7318711496, -0.3002161104, 0.3031446490, -2.5451909126, -0.2560123709, -0.7259014441, 2.3596764355, 1.5161596589, -0.4828037191, -0.0927788279, -0.1707636508, -0.1026581426, -0.4570425978, 1.2219587371, 2.5964018326, 0.4297144621, 0.8958013510, -0.0816895681, 0.3006717786, -0.6064579121, 1.5754802089, 1.8003894334, 1.2293290567, -0.0878251554, 1.0169849911, -2.2994067745, -0.2183680398, 1.4158778954, 1.6728656968, -0.5957561123, 0.5630711554, -1.7590921941, 0.7350310026, 0.1016849326, 0.2664758042, 0.3264117395, 0.8399298578, 0.7795204537, -0.4212957913, -0.7484718858, -1.2356702945, -0.9129405861, -1.2379586294, -0.9035555524, 0.8739762255, -0.2492817476, -0.6183622837, -0.0974445825, -1.0684556824, 0.9604539520, -0.1228070046, 1.5104787919, -1.2378029468, 2.1532347065, 0.7701934874, -0.2526433035, 0.8363351964, 1.2101055164, -0.5321508564, 0.1359324885, 0.5209174926, 0.4977462583, -0.6679721547, -0.4611746567, -0.4593061723, 0.2797929944, 0.6257417808, 1.4040066915, 0.4183853109, 0.9793582773, -0.8345577998, -0.0967694739, 0.1252573921, -0.2235003656, 2.7413025959, 0.5930345499, 0.2374345529, 0.5332420952, -0.6372176654, 0.2853399717, -1.4883240479, -0.2442226219, -1.0459897168, 0.5481403288, -0.0097178044, 2.0542166763, 0.5169890837, -0.8381066780, -0.0704556445, -1.9100246153, 0.2767022260, 1.2463021702, 1.9754403117, -1.2963366481, -0.4801658667, -0.1566439650, -0.4245850818, -0.9424745819, -0.3862489595, -0.1061648322, 0.1097810736, -0.3351726828, -1.9843788232, 1.6445135928, -0.2031567880, -0.5826830168, 0.1189901450, -0.9266563146, -0.1485211290, -0.6293769924, 0.3220956964, 0.9813800672, 0.1197057951, -1.4750150723, -0.9728585589, -1.2019335085, 0.3479631106, 1.2455221269, -0.3526216494, 1.3203607062, 1.1172812571, -1.6154530929, 1.2705304462, -1.2394257015, 0.9761868198, -1.1428695098, 0.4449098945, 0.5147853062, 0.2249320755, -0.7830609471, -0.2491066483, -1.7287597759, 0.0225324327, 1.3293341920, -0.7989634239, -1.0791269585, -0.7387157940, -0.1146258117, -0.9751132845, 0.0747759017, -1.3317483731, 0.3722882459, 1.5191511003, -0.9498703536, -0.4563881780, -0.6341833037, 2.1287373597, -0.9757670526, 0.0714019628, 0.5012889431, 2.1517635806, 0.3982388350, 0.2850022161, 0.7565230140, 1.5891810136, 1.2053199597, 0.9487632098, 0.6461415308, -0.9612068811, -0.6111983512, -0.8057581930, -2.2046321314, -0.1399848357, 1.1266223858, -1.2594926736, -0.4051924743, -0.7864227995, -0.0076392877, -1.2148865789, 0.0224146555, 0.3162899511, -0.7914808400, 0.9229611994, -0.8135240632, -0.8117200885, 0.4568334792, -0.3806423420, 0.5511202819, -0.2783127743, 1.0204399313, -1.1514821047, 0.7022908571, 0.0691098672, 0.3022300232, -1.0928488343, 1.5214550672, 0.5818621708, -0.5168615329, -1.3025574693, 1.3178292808, 0.3327174380, -1.0889328072, -0.7300780307, -0.7990240707, 0.1549466715, 0.7302019645, -0.9597759458, 1.4478382169, 0.6898823629, -0.4396606080, -0.8038030708, 0.8986606254, 1.4663799571, 0.4213099343, 1.0721915187, 0.0004270931, -1.8190060371, 0.9334040270, 0.6933457646, -0.9428803601, 1.5076887436, -1.0725358588, 0.3109695959, 0.6899589678, 0.4663364772, -1.2051674010, -0.8492449788, -0.8435402988, 0.2284364440, -0.4517366603, -0.1457986453, -0.8031141674, 1.9962589999, 0.9734472848, -1.7317208930, -0.2691687878, 1.7000762686, 0.9555035835, -0.6364228743, 0.5643430946, -0.3581462093, -0.4735592964, -0.1109767021, -0.7140245815, -1.1933989254, 1.3921219875, 0.1149336097, -0.9018754333, -0.4855101448, 0.1816603041, 0.0086196595, 0.1834025505, -2.9500764921, 0.8379839938, -0.1602575560, 0.2949079634, -1.2909311514, -1.0132604729, -0.2337856604, -0.5831928053, -1.8842571156, 0.0109578823, -1.2868838382, 0.7996299981, -0.7268257429, 1.1116232941, 0.5137587147, -0.0075185239, -1.1741442910, -1.0906749253, -1.1155707983, -0.3522219230, 0.3207591969, -1.0707626161, 0.0494070954, -0.7488658302, 0.9258771112, -0.4411833024, 1.4030242940, 1.7460849298, -0.9056847811, -3.1129201699, 0.0901076308, -0.3587376422, -0.8223680711, 0.3010386604, 0.5355436206, -1.6133009142, 0.0558011071, 0.5790166848, -1.7465442739, -0.9057910473, 0.5305155467, -2.6496090630, 1.5390646894, -1.0863986113, -1.5706771018, -2.0286487213, 0.2629739428, 2.1623874292, -0.2978498288, -0.2966696053, 0.4014788260, 0.1729803217, 0.2769837200, 1.4912276240, 1.3324490826, 1.0289211764, 1.5999464021, -1.0219275552, 0.8975337417, -0.2655790691, 1.5318114397, 1.0100245394, 0.4095373178, 1.5413297211, -0.3442066039, 0.1161455841, -0.8261079852, 0.4762477494, -0.4501155231, -0.5983399948, -1.1634510571, -0.7927315180, -0.7395624227, -1.4669508385, 0.0308158995, 1.7200221481, 1.0007276049, 0.4292327003, 0.6875987801, -1.0411680335, -0.4449264175, -0.3780266778, -0.2792342143, -1.0270984177, 1.2676084071, -0.5407293118, 1.1410835550, -0.3554195187, 1.1906525480, -0.7048658963, 2.0544178432, -0.7923599435, -0.0318257944, -0.5820648131, -0.3630288643, -0.3666679604, -0.3142407464, -1.1212414915, -0.9707628115, 0.3327088860, 0.1223212603, -0.7745332526, 0.3057860070, 0.2399186609, 1.2659730729, -3.0211244484, 1.4096829066, -1.4990310037, 0.0985467827, 1.3763716369, -1.8016132746, 0.4573467214, -0.0572949278, 0.6811224225, -0.6884818523, 1.1579837262, -1.1404994431, -0.9541128644, 0.4849594651, -0.0683172856, -1.5092523956, 0.4255836358, -1.4782236491, 0.8551550480, 0.0600944965, -0.7723545984, -2.0102572284, 0.6304477713, -0.8868559626, 0.1048685716, 0.8810145885, 1.5113201493, 1.3480537963, -1.5093996547, 0.2351888727, 0.2865227494, 0.7473929640, -0.8590022549, -1.8719194121, 0.7025039356, 0.2102076638, 0.1196859997, 0.6843870322, -0.5596707268, -1.6263910432, -0.5596626563, 0.3869025548, -2.5372069797, -0.4141435141, 0.9069737041, -0.0734516978, 1.1075640710, 1.2013049739, -0.4940917696, 0.4916785443, -0.4558939111, -1.4810431423, -0.1364382892, 1.1508443162, 0.1049952773, -1.4742599331, -0.3280047616, 1.0614730454, 0.5739907049, 0.7686440207, -1.1357116930, -0.2640378355, 1.9017258478, 1.2548629055, -1.0486415297, -0.0899452299, 2.2403065549, 2.0211399215, -0.7365834165, -0.9326942547, -0.4899628684, 0.7342433964, -0.8435308837, 0.4333955533, 0.4661009411, -0.5840341720, 0.4640134677, 0.7934135351, -0.9498785377, 0.9688180276, -0.0007812686, 0.5563958237, 2.1066469178, 0.7397812600, -0.4149482543, -0.7448184493, 0.7753333256, 1.2645138591, -2.0332809771, -0.4170762400, 0.7338481835, -2.6917140206, -0.2060145320, 0.1907956346, 0.0885374035, -0.3519388309, 0.4064374008, -1.0304612917, 1.2422921987, -1.2399664716, 1.0069234200, -0.0501179368, -0.6126452644, 0.7849907690, 0.8987959528, -1.7603686589, -3.2605412617, -1.5065749054, 0.8991648460, -0.0609459441, 0.1624854374, 1.3120776096, 0.7578458149, 0.2800084559, 0.3179200280, 0.1485101727, -1.9772087459, 2.4873951976, 2.4049807030, -2.2652358415, 0.7008296778, -0.3470177286, -0.6913907363, 0.2994783625, 0.3567813088, 1.0821109171, -0.5377192839, 1.2572424422, 1.0637266727, 0.5430932680, 0.6300689740, 0.2774210026, -0.3525394454, -1.7114882987, -0.7431538384, 1.9459830328, -0.0565561613, -0.8421066851, -1.4189260396, 0.0205164012, -0.9143551805, 0.6158809114, -1.1948293265, 2.5054313537, -2.2034089527, -0.5972224009, -0.5635298975, 0.4917533697, 0.3577445824, 1.1222350944, 0.0498121845, -0.0776976176, -0.8242519143, 1.3424404529, 1.7677613646, 0.2856412184, 1.1880471874, -0.2555152309, 0.0432459748, 0.5858776258, 0.8541196235, -0.1483626567, -0.8582603022, 0.4521597023, 0.5616072633, -0.5534978124, 0.4992941622, -1.3965325878, -0.2249879461, -0.1439427244, 1.1944110368, 0.1032605645, 1.2897845237, -0.1927637275, -0.3646659364, -0.3290444016, 0.4598530363, 0.4713102624, -0.8503854296, 0.5877261275, -1.3348268137, -0.5745489857, -0.8492801091, 0.3782766627, 0.0575127637, 0.9896599933, 1.2284962465, -1.0535364680, 0.0314501607, 1.3908865414, -0.4961156517, 0.2807000687, 0.8038558496, -0.4090929442, 0.7114917915, -0.6147616847, -0.9758830216, -0.6741629686, -0.8011700808, 0.6142650190, -1.3008709252, 2.0147303763, -0.0135171610, 0.1522860540, 0.2237270979, 0.2005145757, -0.1812940116, 1.6278010592, -0.6049790480, 2.6133311691, -0.3259300503, -1.9668808827, 0.5499415966, -0.2308224071, 0.1039313709, -0.5310240326, 0.8568955896, -0.1905456136, -2.0763866665, 1.2615312494, -0.3837361942, 1.3819689280, 0.3804709661, -0.5066989862, -0.9810965430, -1.5574971704, -1.1503714805, -0.0591567586, 0.9379219642, 0.2331476223, 0.2881763807, 0.4249390819, 0.2407511943, 0.4555896106, 0.0464325003, 1.1728324671, 0.4234568822, 0.2620704447, 0.9357423735, -0.4269697882, -1.4656417488, -0.0913619986, -0.2274104495, 1.8313209412, 1.4380859477, 1.5565561068, 0.0897773175, -0.9652230933, 0.6008331547, -1.1768830112, -0.0541478058, -0.8943743469, 0.2809096676, 2.5418853999, -0.7091287471, 0.9746142753, -0.2416512668, -0.3891504686, 0.2154966349, -0.1499963763, 1.2053817255, -0.6423394388, -0.8153154861, 0.9248480344, -0.4162581805, 1.1139414420, -0.5400639384, -0.4521743092, 0.1592396942, -0.5650406793, -1.0685284953, 0.1581286729, -2.2651013948, -1.9558300647, 1.5736307678, -0.6553156595, 0.9436219504, 0.4268356618, -1.6936523517, 0.7608796573, -0.6336220768, 1.1989561881, 0.0877135049, 1.6649619793, 2.1776915742, -0.8237554548, 0.8819519350, 0.4400725850, -1.4498728213, -2.2792667491, 2.0156774326, -0.5684052897, -1.2065357322, -0.7376811935, -0.6320111897, -0.2752095186, 0.2352656994, -0.6856856300, 0.6991831723, -0.4790781605, -1.1460782117, -0.2168787128, -0.2482822340, -0.1046266138, 0.9572764202, -0.7969823651, -0.9012621124, -1.0167740219, -0.3685693156, 0.6015070788, -1.0668683945, 0.0497361766, -0.8825730381, -1.0111428532, -0.7590071042\n-0.0168327\n\n\n\n\n\n\n\nCategories:\n\nprogramming\nloop"
  },
  {
    "objectID": "posts/globus1/index.html",
    "href": "posts/globus1/index.html",
    "title": "globus1",
    "section": "",
    "text": "1 Aufgabe\nWir werfen einen Globus \\(n=9\\) Mal und erzielen \\(W=6\\) mal das Ereignis ‚ÄúWasser‚Äù.\nWas ist die Wahrscheinlichkeit, dass wir bei \\(n=9\\) W√ºrfen \\(W=6\\) mal das Ereignis ‚ÄúWasser‚Äù erzielen, wenn wir von einer Wasseranteil, d.h. Wahrscheinlichkeit von \\(\\pi=.7\\) ausgehen?\n  \n  \n  \n  \n\n\n2 L√∂sung\nHier sind die gegebenen Werte:\n\nW &lt;- 6\nn &lt;- 9\npi &lt;- .7\n\nWir suchen also diese Gr√∂√üe:\n\\[Pr(W=6 | \\pi=0.7, n=9) = ?\\]\nWir k√∂nnen R die Arbeit machen lassen:\n\n\n\n\nListing¬†1: Binomialverteilung mit R\n\n\nloesung &lt;- dbinom(x = W, size = n, prob = pi)\nloesung\n\n\n\n\n[1] 0.2668279\n\n\nOder den Taschenrechner nutzen:\n\nloesung &lt;- choose(n,W) * pi^W * (1-pi)^(n-W)\nloesung\n\n[1] 0.2668279\n\n\nDie Harten unter uns rechnen es per Hand aus.\nDaf√ºr kann man zun√§chst die Anzahl der Pfade mit dem Binomialkoeffizienten berechnen:\n\nanzahl_pfade &lt;- factorial(n) / (factorial(W) * factorial(n-W))\nanzahl_pfade\n\n[1] 84\n\n\nfactorial(W) liefert die Fakult√§t von \\(W\\) zur√ºck.\nDann berechnet man die Wahrscheinlichkeit eines einzelnen Pfades:\n\npfad_wskt &lt;-  pi^W * (1-pi)^(n-W)\npfad_wskt\n\n[1] 0.003176523\n\n\nMultipliziert man die beiden vorherigen Zwischenergebnisse, so erh√§lt man die L√∂sung:\n\nloesung &lt;-  anzahl_pfade * pfad_wskt\nloesung\n\n[1] 0.2668279"
  },
  {
    "objectID": "posts/mtcars-simple2/mtcars-simple2.html",
    "href": "posts/mtcars-simple2/mtcars-simple2.html",
    "title": "mtcars-simple2",
    "section": "",
    "text": "Exercise\nWe will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nCompute the explained variance (point estimate) for the above model!\nNotes:\n\nUse can either use frequentist or bayesian modeling.\nUse R for all computations.\nThere are multiple ways to find a solution.\n\n         \n\n\nSolution\nCompute Model:\n\nlm1_freq &lt;- lm(mpg ~ hp + cyl + disp, data = mtcars)\n\nlibrary(rstanarm)\nlm1_bayes &lt;- stan_glm(mpg ~ hp + cyl + disp, data = mtcars, refresh = 0)\n\nGet R2:\n\nlibrary(easystats)\n\n\nr2(lm1_freq)\n\n# R2 for Linear Regression\n       R2: 0.768\n  adj. R2: 0.743\n\n\n\nr2(lm1_bayes)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.746 (95% CI [0.610, 0.856])\n\n\nThe coefficient is estimated as about 0.77.\n\nCategories:\n\nregression\nen\nbayes\nfrequentist\nqm1\nstats-nutshell"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html",
    "href": "posts/regr-tree03/regr-tree03.html",
    "title": "regr-tree03",
    "section": "",
    "text": "library(tidymodels)"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#setup",
    "href": "posts/regr-tree03/regr-tree03.html#setup",
    "title": "regr-tree03",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\n\nF√ºr Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#daten-teilen",
    "href": "posts/regr-tree03/regr-tree03.html#daten-teilen",
    "title": "regr-tree03",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#modelle",
    "href": "posts/regr-tree03/regr-tree03.html#modelle",
    "title": "regr-tree03",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#rezepte",
    "href": "posts/regr-tree03/regr-tree03.html#rezepte",
    "title": "regr-tree03",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec1 &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#resampling",
    "href": "posts/regr-tree03/regr-tree03.html#resampling",
    "title": "regr-tree03",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#workflow",
    "href": "posts/regr-tree03/regr-tree03.html#workflow",
    "title": "regr-tree03",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec1) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#tuningfitting",
    "href": "posts/regr-tree03/regr-tree03.html#tuningfitting",
    "title": "regr-tree03",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\ntune_grid\n\n\n\n\n\ncost_complexity\ntree_depth\nmin_n\n\n\n\n\n0.0000000\n1\n2\n\n\n0.0000000\n1\n2\n\n\n0.0000032\n1\n2\n\n\n0.0005623\n1\n2\n\n\n0.1000000\n1\n2\n\n\n0.0000000\n4\n2\n\n\n0.0000000\n4\n2\n\n\n0.0000032\n4\n2\n\n\n0.0005623\n4\n2\n\n\n0.1000000\n4\n2\n\n\n0.0000000\n8\n2\n\n\n0.0000000\n8\n2\n\n\n0.0000032\n8\n2\n\n\n0.0005623\n8\n2\n\n\n0.1000000\n8\n2\n\n\n0.0000000\n11\n2\n\n\n0.0000000\n11\n2\n\n\n0.0000032\n11\n2\n\n\n0.0005623\n11\n2\n\n\n0.1000000\n11\n2\n\n\n0.0000000\n15\n2\n\n\n0.0000000\n15\n2\n\n\n0.0000032\n15\n2\n\n\n0.0005623\n15\n2\n\n\n0.1000000\n15\n2\n\n\n0.0000000\n1\n11\n\n\n0.0000000\n1\n11\n\n\n0.0000032\n1\n11\n\n\n0.0005623\n1\n11\n\n\n0.1000000\n1\n11\n\n\n0.0000000\n4\n11\n\n\n0.0000000\n4\n11\n\n\n0.0000032\n4\n11\n\n\n0.0005623\n4\n11\n\n\n0.1000000\n4\n11\n\n\n0.0000000\n8\n11\n\n\n0.0000000\n8\n11\n\n\n0.0000032\n8\n11\n\n\n0.0005623\n8\n11\n\n\n0.1000000\n8\n11\n\n\n0.0000000\n11\n11\n\n\n0.0000000\n11\n11\n\n\n0.0000032\n11\n11\n\n\n0.0005623\n11\n11\n\n\n0.1000000\n11\n11\n\n\n0.0000000\n15\n11\n\n\n0.0000000\n15\n11\n\n\n0.0000032\n15\n11\n\n\n0.0005623\n15\n11\n\n\n0.1000000\n15\n11\n\n\n0.0000000\n1\n21\n\n\n0.0000000\n1\n21\n\n\n0.0000032\n1\n21\n\n\n0.0005623\n1\n21\n\n\n0.1000000\n1\n21\n\n\n0.0000000\n4\n21\n\n\n0.0000000\n4\n21\n\n\n0.0000032\n4\n21\n\n\n0.0005623\n4\n21\n\n\n0.1000000\n4\n21\n\n\n0.0000000\n8\n21\n\n\n0.0000000\n8\n21\n\n\n0.0000032\n8\n21\n\n\n0.0005623\n8\n21\n\n\n0.1000000\n8\n21\n\n\n0.0000000\n11\n21\n\n\n0.0000000\n11\n21\n\n\n0.0000032\n11\n21\n\n\n0.0005623\n11\n21\n\n\n0.1000000\n11\n21\n\n\n0.0000000\n15\n21\n\n\n0.0000000\n15\n21\n\n\n0.0000032\n15\n21\n\n\n0.0005623\n15\n21\n\n\n0.1000000\n15\n21\n\n\n0.0000000\n1\n30\n\n\n0.0000000\n1\n30\n\n\n0.0000032\n1\n30\n\n\n0.0005623\n1\n30\n\n\n0.1000000\n1\n30\n\n\n0.0000000\n4\n30\n\n\n0.0000000\n4\n30\n\n\n0.0000032\n4\n30\n\n\n0.0005623\n4\n30\n\n\n0.1000000\n4\n30\n\n\n0.0000000\n8\n30\n\n\n0.0000000\n8\n30\n\n\n0.0000032\n8\n30\n\n\n0.0005623\n8\n30\n\n\n0.1000000\n8\n30\n\n\n0.0000000\n11\n30\n\n\n0.0000000\n11\n30\n\n\n0.0000032\n11\n30\n\n\n0.0005623\n11\n30\n\n\n0.1000000\n11\n30\n\n\n0.0000000\n15\n30\n\n\n0.0000000\n15\n30\n\n\n0.0000032\n15\n30\n\n\n0.0005623\n15\n30\n\n\n0.1000000\n15\n30\n\n\n0.0000000\n1\n40\n\n\n0.0000000\n1\n40\n\n\n0.0000032\n1\n40\n\n\n0.0005623\n1\n40\n\n\n0.1000000\n1\n40\n\n\n0.0000000\n4\n40\n\n\n0.0000000\n4\n40\n\n\n0.0000032\n4\n40\n\n\n0.0005623\n4\n40\n\n\n0.1000000\n4\n40\n\n\n0.0000000\n8\n40\n\n\n0.0000000\n8\n40\n\n\n0.0000032\n8\n40\n\n\n0.0005623\n8\n40\n\n\n0.1000000\n8\n40\n\n\n0.0000000\n11\n40\n\n\n0.0000000\n11\n40\n\n\n0.0000032\n11\n40\n\n\n0.0005623\n11\n40\n\n\n0.1000000\n11\n40\n\n\n0.0000000\n15\n40\n\n\n0.0000000\n15\n40\n\n\n0.0000032\n15\n40\n\n\n0.0005623\n15\n40\n\n\n0.1000000\n15\n40\n\n\n\n\n\n\n\ntic()\nfit1 &lt;-\n  tune_grid(object = wf1,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\n24.798 sec elapsed"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#bester-kandidat",
    "href": "posts/regr-tree03/regr-tree03.html#bester-kandidat",
    "title": "regr-tree03",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(fit1)\n\n\n\n\n\n\n\n\n\nshow_best(fit1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncost_complexity\ntree_depth\nmin_n\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0\n1\n11\nroc_auc\nbinary\n0.8055556\n2\n0.0277778\npre0_mod002_post0\n\n\n0\n1\n21\nroc_auc\nbinary\n0.8055556\n2\n0.0277778\npre0_mod003_post0\n\n\n0\n1\n30\nroc_auc\nbinary\n0.8055556\n2\n0.0277778\npre0_mod004_post0\n\n\n0\n1\n40\nroc_auc\nbinary\n0.8055556\n2\n0.0277778\npre0_mod005_post0\n\n\n0\n4\n11\nroc_auc\nbinary\n0.8055556\n2\n0.0277778\npre0_mod007_post0"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#finalisieren",
    "href": "posts/regr-tree03/regr-tree03.html#finalisieren",
    "title": "regr-tree03",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nwf1_finalized &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(fit1))"
  },
  {
    "objectID": "posts/regr-tree03/regr-tree03.html#last-fit",
    "href": "posts/regr-tree03/regr-tree03.html#last-fit",
    "title": "regr-tree03",
    "section": "Last Fit",
    "text": "Last Fit\n\nfinal_fit &lt;- \n  last_fit(object = wf1_finalized, d_split)\n\ncollect_metrics(final_fit)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.8750000\npre0_mod0_post0\n\n\nroc_auc\nbinary\n0.8750000\npre0_mod0_post0\n\n\nbrier_class\nbinary\n0.1157407\npre0_mod0_post0\n\n\n\n\n\n\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nstring"
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html",
    "href": "posts/mariokart_desk-inf-mod/index.html",
    "title": "mariokart_desk-inf-mod",
    "section": "",
    "text": "Untersuchen Sie den Datensatz mariokart. Beantworten Sie dabei die folgende Forschungsfrage:\n\nErzielen Spiele mit Photo (stock_photo) einen h√∂heren Verkaufspreis (total_pr) im Vergleich zu Spielen ohne Photo?\n\n\nPr√ºfen Sie auf fehlende Werte und Extremwerte und f√ºhren Sie ggf. entsprechende Schritte aus, um etwaige Probleme in diesem Zusammenhang zu l√∂sen.\nBerechnen Sie relevante deskriptive Statistiken.\nVisualisieren Sie die die Daten sinnvoll.\nBerechnen und interpretieren Sie ein passendes Modell. e.Berechnen und interpretieren Sie Ma√üe der Inferenzstatistik (Bayes oder Frequentistisch).\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html#vorbereitung",
    "href": "posts/mariokart_desk-inf-mod/index.html#vorbereitung",
    "title": "mariokart_desk-inf-mod",
    "section": "2.1 Vorbereitung",
    "text": "2.1 Vorbereitung\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)\nlibrary(visdat)\nlibrary(rstanarm)\n\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")"
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html#vorverarbeitung",
    "href": "posts/mariokart_desk-inf-mod/index.html#vorverarbeitung",
    "title": "mariokart_desk-inf-mod",
    "section": "2.2 Vorverarbeitung",
    "text": "2.2 Vorverarbeitung\n\n2.2.1 Extremwerte\n\ngghistogram(mariokart, x = \"total_pr\")\n\n\n\n\n\n\n\n\nJa, besser wir entfernen die Extremwerte:\n\nmariokart_no_extreme &lt;- \n  mariokart |&gt; \n  filter(total_pr &lt; 100)\n\n\n\n2.2.2 Fehlende Werte\nFehlende Werte visualisieren:\n\nvis_dat(mariokart_no_extreme)\n\n\n\n\n\n\n\n\nFehlende Werte z√§hlen:\n\ncolSums(is.na(mariokart_no_extreme))\n\n   rownames          id    duration      n_bids        cond    start_pr \n          0           0           0           0           0           0 \n    ship_pr    total_pr     ship_sp seller_rate stock_photo      wheels \n          0           0           0           0           0           0 \n      title \n          0 \n\n\nOder so, mit dplyr:\n\nmariokart_no_extreme |&gt; \n  summarise(across(everything(), ~ sum(is.na(.x))))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\ntitle\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0"
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html#deskriptive-statistik",
    "href": "posts/mariokart_desk-inf-mod/index.html#deskriptive-statistik",
    "title": "mariokart_desk-inf-mod",
    "section": "2.3 Deskriptive Statistik",
    "text": "2.3 Deskriptive Statistik\n\n2.3.1 Metrische Variablen\n√úberblick\n\ndescribe_distribution(mariokart_no_extreme) |&gt; \n  format_table(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nrownames\n72.42\n41.48\n72.00\n1.00\n143.00\n-0.02\n-1.20\n141.00\n0\n\n\nid\n2.25e+11\n8.78e+10\n1.60e+11\n1.10e+11\n4.00e+11\n0.23\n-1.24\n141.00\n0\n\n\nduration\n3.75\n2.59\n6.00\n1.00\n10.00\n0.35\n-1.31\n141.00\n0\n\n\nn_bids\n13.38\n5.76\n7.50\n1.00\n29.00\n-0.07\n-0.03\n141.00\n0\n\n\nstart_pr\n8.85\n15.16\n9.01\n0.01\n69.95\n2.35\n5.40\n141.00\n0\n\n\nship_pr\n2.98\n2.62\n4.00\n0.00\n11.45\n0.95\n1.32\n141.00\n0\n\n\ntotal_pr\n47.43\n9.11\n12.99\n28.98\n75.00\n0.41\n-1.75e-03\n141.00\n0\n\n\nseller_rate\n16122.82\n52174.55\n4748.50\n0.00\n2.70e+05\n4.06\n16.12\n141.00\n0\n\n\nwheels\n1.15\n0.84\n2.00\n0.00\n4.00\n0.14\n-0.45\n141.00\n0\n\n\n\n\n\n\nVisualisierung:\n\ndescribe_distribution(mariokart_no_extreme) |&gt; plot()\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 Nominale Variablen\n√úberblick:\n\ndata_tabulate(mariokart_no_extreme, \n              select = c(\"cond\", \"ship_sp\", \"stock_photo\")) |&gt; \n  print_md() |&gt; \n  format_table(digits = 2)\n\n\n\n\n\n\n\n\nx\n\n\n\n\nTable: Frequency Table\n\n\n\n\n\n|Variable | Value| N|Raw % | Valid %| Cumulative %|\n\n\n|:‚Äî‚Äî‚Äî‚Äì|‚Äî‚Äî‚Äî-:|‚Äî:|:‚Äî‚Äì|‚Äî‚Äî-:|‚Äî‚Äî‚Äî‚Äî:|\n\n\n|cond | new| 59|41.84 | 41.84| 41.84|\n\n\n| | used| 82|58.16 | 58.16| 100.00|\n\n\n| | (NA)| 0| 0.00 | (NA)| (NA)|\n\n\n| | | | | | |\n\n\n|ship_sp | firstClass| 22|15.60 | 15.60| 15.60|\n\n\n| | media| 14| 9.93 | 9.93| 25.53|\n\n\n| | other| 3| 2.13 | 2.13| 27.66|\n\n\n| | parcel| 14| 9.93 | 9.93| 37.59|\n\n\n| | priority| 23|16.31 | 16.31| 53.90|\n\n\n| | standard| 33|23.40 | 23.40| 77.30|\n\n\n| | ups3Day| 1| 0.71 | 0.71| 78.01|\n\n\n| | upsGround| 31|21.99 | 21.99| 100.00|\n\n\n| | (NA)| 0| 0.00 | (NA)| (NA)|\n\n\n| | | | | | |\n\n\n|stock_photo | no| 36|25.53 | 25.53| 25.53|\n\n\n| | yes| 105|74.47 | 74.47| 100.00|\n\n\n| | (NA)| 0| 0.00 | (NA)| (NA)|\n\n\n| | | | | | |\n\n\n\n\n\n\nVisualisierung:\n\ndata_tabulate(mariokart_no_extreme, \n              select = c(\"cond\", \"ship_sp\", \"stock_photo\")) |&gt; \n  plot()\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Alternative\n\nskimr::skim(mariokart_no_extreme)\n\n\nData summary\n\n\nName\nmariokart_no_extreme\n\n\nNumber of rows\n141\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n9\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncond\n0\n1\n3\n4\n0\n2\n0\n\n\nship_sp\n0\n1\n5\n10\n0\n8\n0\n\n\nstock_photo\n0\n1\n2\n3\n0\n2\n0\n\n\ntitle\n0\n1\n0\n59\n1\n79\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n7.242000e+01\n4.148000e+01\n1.000000e+00\n3.700000e+01\n7.300000e+01\n1.080000e+02\n1.430000e+02\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nid\n0\n1\n2.249920e+11\n8.784150e+10\n1.104395e+11\n1.403507e+11\n2.303822e+11\n3.003523e+11\n4.000775e+11\n‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ\n\n\nduration\n0\n1\n3.750000e+00\n2.590000e+00\n1.000000e+00\n1.000000e+00\n3.000000e+00\n7.000000e+00\n1.000000e+01\n‚ñá‚ñÖ‚ñÇ‚ñÜ‚ñÅ\n\n\nn_bids\n0\n1\n1.338000e+01\n5.760000e+00\n1.000000e+00\n1.000000e+01\n1.400000e+01\n1.700000e+01\n2.900000e+01\n‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñÅ\n\n\nstart_pr\n0\n1\n8.850000e+00\n1.516000e+01\n1.000000e-02\n9.900000e-01\n1.000000e+00\n1.000000e+01\n6.995000e+01\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nship_pr\n0\n1\n2.980000e+00\n2.620000e+00\n0.000000e+00\n0.000000e+00\n2.990000e+00\n4.000000e+00\n1.145000e+01\n‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÅ\n\n\ntotal_pr\n0\n1\n4.743000e+01\n9.110000e+00\n2.898000e+01\n4.100000e+01\n4.603000e+01\n5.399000e+01\n7.500000e+01\n‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÅ\n\n\nseller_rate\n0\n1\n1.612282e+04\n5.217455e+04\n0.000000e+00\n1.160000e+02\n8.200000e+02\n4.858000e+03\n2.701440e+05\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nwheels\n0\n1\n1.150000e+00\n8.400000e-01\n0.000000e+00\n0.000000e+00\n1.000000e+00\n2.000000e+00\n4.000000e+00\n‚ñÜ‚ñá‚ñá‚ñÅ‚ñÅ"
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html#visualisierung",
    "href": "posts/mariokart_desk-inf-mod/index.html#visualisierung",
    "title": "mariokart_desk-inf-mod",
    "section": "2.4 Visualisierung",
    "text": "2.4 Visualisierung\n\nggboxplot(data = mariokart_no_extreme,\n          x = \"stock_photo\",\n          y = \"total_pr\",\n          add = \"mean_se\",\n          add.params = list(color = okabeito_colors()[1]))"
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html#modellierung",
    "href": "posts/mariokart_desk-inf-mod/index.html#modellierung",
    "title": "mariokart_desk-inf-mod",
    "section": "2.5 Modellierung",
    "text": "2.5 Modellierung\n\n2.5.1 Kausalmodell\nWir nehmen folgendes Kausalmodell an.\n\n\n\n\n\ngraph LR\n  photo --&gt; price\n  u --&gt; price\n\n\n\n\n\n\nUnter der Annahme dieses Kausalmodells k√∂nnen wir die Modellkoeffizienten als valide betrachten.\n\n\n2.5.2 Modell - Frequentistisch\nModell berechnen und Parameter pr√ºfen:\n\nlm1 &lt;- lm(total_pr ~ stock_photo, data = mariokart_no_extreme)\nparameters(lm1) |&gt; \n  format_table(digits = 2)\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(139)\np\n\n\n\n\n(Intercept)\n44.33\n1.49\n[41.37, 47.28]\n29.68\n&lt; .001\n\n\nstock photo [yes]\n4.17\n1.73\n[ 0.75, 7.59]\n2.41\n0.017\n\n\n\n\n\n\nVisualisierung:\n\nparameters(lm1) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n2.5.3 Modell - Bayesianisch\nModell berechnen und Parameter pr√ºfen:\n\nlm1_bayes &lt;- stan_glm(total_pr ~ stock_photo, \n                      data = mariokart_no_extreme,\n                      refresh = 0)\nparameters(lm1_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n44.357345\n0.95\n41.4536558\n47.380282\n1.00000\n0.9994405\n3895.248\nnormal\n47.43191\n22.78413\n\n\nstock_photoyes\n4.141773\n0.95\n0.6167945\n7.738697\n0.99075\n1.0001186\n3964.198\nnormal\n0.00000\n52.06671\n\n\n\n\n\n\nVisualisierung:\n\nparameters(lm1_bayes) |&gt; plot()"
  },
  {
    "objectID": "posts/mariokart_desk-inf-mod/index.html#inferenzstatistik",
    "href": "posts/mariokart_desk-inf-mod/index.html#inferenzstatistik",
    "title": "mariokart_desk-inf-mod",
    "section": "2.6 Inferenzstatistik",
    "text": "2.6 Inferenzstatistik\n\n2.6.1 Nullhypothese\nWie man sieht, ist die Null nicht im Konfidenzintervall enthalten. Daher k√∂nnen wir die Nullhypothese ausschlie√üen.\n\n\n2.6.2 ROPE\nWir k√∂nnen eine ROPE-Nullhypothese nicht komplett ausschlie√üen, aber fast.\n\nrope(lm1_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-0.9113651\n0.9113651\n0.0000000\nfixed\nconditional\n\n\nstock_photoyes\n0.95\n-0.9113651\n0.9113651\n0.0105263\nfixed\nconditional\n\n\n\n\n\n\nVisualisierung:\n\nrope(lm1_bayes) |&gt; plot()"
  },
  {
    "objectID": "posts/haeufigkeit01/haeufigkeit01.html",
    "href": "posts/haeufigkeit01/haeufigkeit01.html",
    "title": "haeufigkeit01",
    "section": "",
    "text": "Aufgabe\nWerten Sie die H√§ufigkeiten (der Stufen) folgender Variablen aus wie unten beschrieben.\nDatensatz: mtcars.\nVariablen:\n\nam\ncyl\nvs\n\n\nErstellen Sie f√ºr jede der genannten Variablen eine univariate H√§ufigkeitsanalyse (also nur eine Variable).\nErstellen Sie dann f√ºr die ersten beiden genannten Variablen eine gemeinsame H√§ufigkeitsanalyse (bivariat).\nErstellen Sie dann f√ºr alle genannten Variablen eine gemeinsame H√§ufigkeitsanalyse.\nWie viele Gruppen (also H√§ufigkeitswerte) ergeben sich (theoretisch) in der letzten Auswertung?\n\n         \n\n\nL√∂sung\n\nlibrary(\"tidyverse\")\ndata(\"mtcars\")\n\n\nunivariate H√§ufigkeitsanalyse\n\n\nmtcars %&gt;% \n  group_by(am) %&gt;% \n  summarise(zeilen_n = n())\n\n\n\n\n\nam\nzeilen_n\n\n\n\n\n0\n19\n\n\n1\n13\n\n\n\n\n\n\nDer Befehle n() gibt die Anzahl der Zeilen (Reihen) zur√ºck. Da in einem Dataframe alle Zeilen gleich lang sind, brauchen wir keine Spalte anzugeben.\nAlternativ k√∂nnte man auch schreiben:\n\nmtcars %&gt;% \n  count(am)\n\n\n\n\n\nam\nn\n\n\n\n\n0\n19\n\n\n1\n13\n\n\n\n\n\n\nDas ist haargenau der gleiche Effekt wie die vorherige Syntax.\n√úblich ist auch, eine Kontingenztabelle so darzustellen:\n\ngemeinsame H√§ufigkeitsanalyse (bivariat)\n\n\nmtcars %&gt;% \n  count(am, cyl)\n\n\n\n\n\nam\ncyl\nn\n\n\n\n\n0\n4\n3\n\n\n0\n6\n4\n\n\n0\n8\n12\n\n\n1\n4\n8\n\n\n1\n6\n3\n\n\n1\n8\n2\n\n\n\n\n\n\n\ntable(mtcars$am, mtcars$cyl)\n\n   \n     4  6  8\n  0  3  4 12\n  1  8  3  2\n\n\nWir sehen, dass wir \\(2\\cdot3=6\\) Gruppen haben, in denen sich die \\(n=32\\) Beobachtungen aufteilen.\n\nH√§ufigkeitsanalyse mit 3 Variablen\n\n\nmtcars %&gt;% \n  count(am, cyl, vs)\n\n\n\n\n\nam\ncyl\nvs\nn\n\n\n\n\n0\n4\n1\n3\n\n\n0\n6\n1\n4\n\n\n0\n8\n0\n12\n\n\n1\n4\n0\n1\n\n\n1\n4\n1\n7\n\n\n1\n6\n0\n3\n\n\n1\n8\n0\n2\n\n\n\n\n\n\nDas sind drei Variablen mit \\(2 \\cdot 3 \\cdot 2 = 12\\) Gruppen.\nDa einige der 12 Gruppen in den Daten nicht vorkommen, sind sie in der Ausz√§hlung der H√§ufigkeiten nicht aufgenommen; in den Daten gibt es nur 7 der 12 Gruppen.\n\nCategories:\n\ndatawrangling\neda\ncount\nstring"
  },
  {
    "objectID": "posts/knn-ames01/knn-ames01.html",
    "href": "posts/knn-ames01/knn-ames01.html",
    "title": "knn-ames01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein knn-Modell f√ºr den Datensatz ames!\nNutzen Sie diese Modellformel: Sale_Price ~ Lot_Area + Fireplaces + Longitude + Latitude.\nBerichten Sie die Modellg√ºte.\nHinweise:\n\nTunen Sie \\(k\\) mit den Werten 1 bis 10.\nTeilen Sie in Train- und Test-Sample auf.\nVerwenden Sie Defaults der Funktionen, wo nicht anders angegeben.\nz-Transformieren Sie die Pr√§diktoren.\nVerwenden Sie den RSME als Kennzahl der Modellg√ºte.\n\n         \n\n\nL√∂sung\n\nlibrary(tidymodels)\ndata(ames)\n\nDaten aufteilen:\n\nd_split &lt;- initial_split(ames)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nModell definieren:\n\nmod1 &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune())  # k-Wert zum Tunen taggen\n\nRezept definieren:\n\nrec1 &lt;-\n  recipe(Sale_Price ~ Lot_Area + Fireplaces + Longitude + Latitude, data = d_split) %&gt;% \n  step_normalize(all_predictors())\n\nWorkflow definieren:\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\nResampling definieren:\n\ncv1 &lt;- vfold_cv(d_train)\n\nTuning definieren:\n\nk_grid &lt;-\n  tibble(neighbors = 1:10)\n\nFitting:\n\nfit1 &lt;-\n  tune_grid(wf1,\n            resamples = vfold_cv(d_train),\n            metrics = metric_set(rmse),  # nur RMSE als Modellg√ºte, Default ist RMSE und R2\n            grid = k_grid,\n            control = control_grid(save_workflow = TRUE)  # nur n√∂tig f√ºr \"fit_best\", s.u.\n            )\n\nMetriken im Train-Sample (genauer: im Assessment-Sample):\n\nshow_best(fit1)\n\n(Komplettes) Train-Sample mit bestem Tuning-Kandidat fitten:\n\ntune1_best &lt;- fit_best(fit1)\n\nIm Test-Sample predicten:\n\nfit_test &lt;- last_fit(tune1_best, d_split)\n\nMetriken einsammeln:\n\ncollect_metrics(fit_test)\n\nDamit haben wir die L√∂sung.\n\nCategories:\n\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/Priorwahl2/Priorwahl2.html",
    "href": "posts/Priorwahl2/Priorwahl2.html",
    "title": "Priorwahl2",
    "section": "",
    "text": "Betrachten wir den biologisch fundierten Zusammenhang von Gewicht (UV) und K√∂rpergr√∂√üe (AV).\nWelche der folgenden Priori-Verteilungen passt am besten f√ºr \\(\\beta\\)?\nGehen Sie von z-standardisierten Variablen aus.\n\n\n\n\\(N(0,1)\\)\n\\(N(0,100)\\)\n\\(N(1,0)\\)\n\\(N(0,0)\\)\n\\(N(-1,1)\\)"
  },
  {
    "objectID": "posts/Priorwahl2/Priorwahl2.html#answerlist",
    "href": "posts/Priorwahl2/Priorwahl2.html#answerlist",
    "title": "Priorwahl2",
    "section": "",
    "text": "\\(N(0,1)\\)\n\\(N(0,100)\\)\n\\(N(1,0)\\)\n\\(N(0,0)\\)\n\\(N(-1,1)\\)"
  },
  {
    "objectID": "posts/Priorwahl2/Priorwahl2.html#answerlist-1",
    "href": "posts/Priorwahl2/Priorwahl2.html#answerlist-1",
    "title": "Priorwahl2",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr. Plausibler Prior. Bei z-standardisierten Werten sind die Koeffizienten meist kleiner 1. Noch sinnvoller w√§re vermutlich, wenn \\(\\mu &gt; 0\\) und nicht \\(\\mu=0\\).\nFalsch. Zu weit.\nFalsch. Keine Streuung.\nFalsch. Keine Streuung.\nFalsch. Negativer Mittelwert ist nicht sehr plausibel.\n\n\nCategories:\n\nregression\nbayes\ndistribution"
  },
  {
    "objectID": "posts/Skalenniveau1b/Skalenniveau1b.html",
    "href": "posts/Skalenniveau1b/Skalenniveau1b.html",
    "title": "Skalenniveau1b",
    "section": "",
    "text": "Variable\n\n\n\n\nHaarfarbe\n\n\nTemperatur in Fahrenheit\n\n\nGeschlecht\n\n\nIQ\n\n\n\n\n\n\n\nGeben Sie f√ºr jede der folgenden vier Variable an, ob sie √ºber ein metrisches Skalenniveau verf√ºgt!"
  },
  {
    "objectID": "posts/Skalenniveau1b/Skalenniveau1b.html#answerlist",
    "href": "posts/Skalenniveau1b/Skalenniveau1b.html#answerlist",
    "title": "Skalenniveau1b",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nRichtig\n\n\nCategories:\n\ndyn\nvariable-levels\nvariable-levels\nmchoice"
  },
  {
    "objectID": "posts/mariokart-sd2/mariokart-sd2.html",
    "href": "posts/mariokart-sd2/mariokart-sd2.html",
    "title": "mariokart-sd2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die SD des Verkaufspreis (total_pr)!\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- data_read(d_url)\n\n\nmariokart %&gt;% \n  summarise(pr_sd = sd(total_pr))\n\n\n\n\n\npr_sd\n\n\n\n\n25.68856\n\n\n\n\n\n\nL√∂sung: 25.7.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nvariability\nnum"
  },
  {
    "objectID": "posts/kausal25/kausal25.html",
    "href": "posts/kausal25/kausal25.html",
    "title": "kausal25",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber 6 Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äú/‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ }\n{ x3, x4 }\n{ x5, x6 }\n{ x1, x4 }\n{ x1 }"
  },
  {
    "objectID": "posts/kausal25/kausal25.html#answerlist",
    "href": "posts/kausal25/kausal25.html#answerlist",
    "title": "kausal25",
    "section": "",
    "text": "{ }\n{ x3, x4 }\n{ x5, x6 }\n{ x1, x4 }\n{ x1 }"
  },
  {
    "objectID": "posts/kausal25/kausal25.html#answerlist-1",
    "href": "posts/kausal25/kausal25.html#answerlist-1",
    "title": "kausal25",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/indifferenz-p.html",
    "href": "posts/indifferenz-p.html",
    "title": "indifferenz-p",
    "section": "",
    "text": "1 Aufgabe\nIch halte eine M√ºnze in einer meinen beiden H√§nde.\nWie gro√ü ist die Wahrscheinlichkeit, dass die M√ºnze in meiner rechten Hand ist?\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nEs kommt drauf an, welches Hintergrundwissen man ansetzt.\nF√ºr Sie gilt \\(p=1/2\\).\nF√ºr mich gilt \\(p=1\\); ich wei√ü, dass die M√ºnze in meiner rechten Hand ist.\nMan sieht: Wahrscheinlichkeit ist keine Beschreibung der Natur, sondern des Wissens einer bestimmten Person."
  },
  {
    "objectID": "posts/rethink3m3/rethink3m3.html",
    "href": "posts/rethink3m3/rethink3m3.html",
    "title": "rethink3m3",
    "section": "",
    "text": "Exercise\nNehmen wir an, wir haben 8 (Wasser-)‚ÄúTreffer‚Äù (\\(W=8\\)) bei 15 W√ºrfen (\\(N=15\\)) erhalten (wieder im Globusversuch).\n\nF√ºhren Sie einen Posteriori-Pr√§diktiv-Check durch: Erstellen Sie also eine Posteriori-Pr√§diktiv-Verteilung (PPV). Mit anderen Worten: Erstellen Sie die Stichprobenverteilung, gemittelt √ºber die Posteriori-Wahrscheinlichkeiten des Wasseranteils \\(p\\)!\nVisualisieren Sie die PPV!\nWas ist die Wahrscheinlichkeit laut PPV 8 von 15 Treffer zu erzielen (also 8 Wasser in 15 W√ºrfen)?\n\nHinweise:\n\nBerechnen Sie eine Bayes-Box (Gittermethode).\nVerwenden Sie 1000 Gitterwerte.\nGehen Sie von einem gleichverteilten Prior aus.\nFixieren Sie die Zufallszahlen mit dem Startwert 42, d.h. set.seed(42).\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\n\n\n\nErstellen wir zuerst wieder die Posteriori-Verteilung f√ºr den Globusversuch.\n\np_grid &lt;- seq( from=0 , to=1 , length.out = 1000)  # 1000 Gitterwerte\n\nprior &lt;- rep(1, 1000 )  # Priori-Gewichte\n\nlikelihood &lt;- dbinom(8 , size= 15, prob=p_grid ) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nDann ziehen wir unsere Stichproben daraus:\n\n# um die Zufallszahlen festzulegen, damit alle die gleichen Zufallswerte bekommen: \nset.seed(42) \n\n# Stichproben ziehen aus der Posteriori-Verteilung\nsamples &lt;- \n  tibble(\n    p = sample(p_grid , prob=posterior, size=1e4, replace=TRUE))\n\n\nPPV &lt;- \n  samples %&gt;% \n  mutate( anzahl_wasser = rbinom(1e4, size = 15, prob = p))\n\nDurch prob = p gewichten wir die Wahrscheinlichkeit an den Werten der Posteriori-Verteilung.\nSo sehen die ersten paar Zeilen von PPV aus:\n\n\n\n\n\n\n\n\np\nanzahl_wasser\n\n\n\n\n0.4304304\n4\n\n\n0.5575576\n11\n\n\n0.6516517\n4\n\n\n0.6156156\n9\n\n\n0.6716717\n6\n\n\n\n\n\n\n\n\n\n\n\nPPV %&gt;% \n  ggplot() +\n  aes(x = anzahl_wasser) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nPPV %&gt;% \n  count(anzahl_wasser == 8)\n\n\n\n\n\nanzahl_wasser == 8\nn\n\n\n\n\nFALSE\n8536\n\n\nTRUE\n1464\n\n\n\n\n\n\nAlternativer R-Code aus dieser Quelle:\n\nw &lt;- rbinom(1e4, size = 15, prob = samples$p)\nmean(w == 8)\n\n[1] 0.1504\n\n\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/chatgpt-sentiment-loop/chatgpt-sentiment-loop.html",
    "href": "posts/chatgpt-sentiment-loop/chatgpt-sentiment-loop.html",
    "title": "chatgpt-sentiment-loop",
    "section": "",
    "text": "Aufgabe\nFragen Sie ChatGPT via API zum Sentiment der ersten zwei Texte aus dem Germeval-2018-Datensatz (Train).\n\n\n\n\n\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen.\n\n         \n\n\nL√∂sung\n\nOpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî \\(\\square\\)\n\nDie richtige venv nutzen:\n\nlibrary(reticulate)\n#virtualenv_create(\"chatgpt\")\nuse_virtualenv(\"chatgpt\")\n\nCheck zu Python:\n\nreticulate::py_config()\n\nGgf. noch Module installieren:\n\n#reticulate::py_install(\"pandas\")\n\nModule importieren:\n\nfrom openai import OpenAI\nimport pandas as pd\nimport time \nimport tiktoken  # Token z√§hlen\n\nVersionen der importierten Module:\n\npd.__version__\n\n\n```{zsh}\npip list | grep openai\n```\n\nWir brauchen &gt;= 1.35.\nDaten importieren:\n\ncsv_file_path_train = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv'\n\ngermeval_train = pd.read_csv(csv_file_path_train)\n\nDie ersten paar Texte herausziehen:\n\nn_tweets = 2\ntweets_first_few = germeval_train[\"text\"].head(n_tweets).tolist()\ntweets_first_few\n\nPrompt definieren:\n\nprompt_stem  = \"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes zu erkennen. Bitte antworten Sie nur mit einem Wort, entweder 'positiv', 'neutral' oder 'negativ'. Dieses Wort soll die Insgesamt-Einsch√§tzung des Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folt der Text, dessen Sentiment Sie einsch√§tzen sollen: \\n\"\n\nMit ‚ÄúList Comprehension‚Äù k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:\n\nprompts = [prompt_stem + tweet for tweet in tweets_first_few]\nprompts[0]\n\nCheck: Wie viele Elemente hat die Liste prompts?\n\nlen(prompts)\n\nCheck: Wie viele Tokens hat jeder String (jeder Prompt)?\nWir definieren eine Helper-Funktion:\n\ndef count_tokens(string: str, encoding_name: str) -&gt; int:\n    encoding = tiktoken.get_encoding(encoding_name)\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\nUnd z√§hlen:\n\nencoding_name = \"cl100k_base\"\n\nnum_tokens_list = [count_tokens(prompt, encoding_name) for prompt in prompts]\n\nfor i, num_tokens in enumerate(num_tokens_list):\n    print(f\"The number of tokens in Prompt {[i]} is {num_tokens}.\")\n\nMehr Infos zum Encoding bei ChatGPT finden sich hier.\nLaut OpenAI kostet 1k Token f√ºr das Modell gpt-3.5-turbo-1106 $0.001.\nAnmelden bei OpenAI:\n\nclient = OpenAI()\n\n\n\n\n\n\n\nNote\n\n\n\nDieses Anmeldeverfahren setzt voraus, dass in .Renviron die Variable OPENAI_API_KEY hinterlegt ist. \\(\\square\\)\n\n\nAnfrage an die API, in eine Funktion gepackt:\n\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n    model=model,\n    messages=messages,\n    max_tokens=50,\n    temperature=0,\n  )\n  return response.choices[0].message.content\n\nUnd jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:\n\nresults = []\n\n\nstart_time = time.time()\n\nfor prompt in prompts:\n  result = get_completion(prompt, client) \n  results.append(result)\n\nend_time = time.time()\nend_time - start_time\n\nVoil√†:\n\nprint(results)"
  },
  {
    "objectID": "posts/movies-vis1/movies-vis1.html",
    "href": "posts/movies-vis1/movies-vis1.html",
    "title": "movies-vis1",
    "section": "",
    "text": "Aufgabe\nImportieren Sie bitte f√ºr diese Aufgabe den Datensatz movies (aus dem R-Paket ggplot2movies). Ein Data-Dictionary findet sich hier.\nErstellen Sie folgende Visualisierung:\n\nStreudiagramme mit rating als Y-Variable, und alle √ºbrigen metrischen Variablen als X-Variable.\nLassen Sie aber folgende Variablen au√üen vor: etwaige ID-Variablen, die Variablen, die die Perzentile der Bewertungen angeben (rX, mit X von 1 bis 10)\nBer√ºcksichtigen Sie nur Actionfilme ab 2000\nVerzichten Sie auf Filme mit einer unterdurchschnittlichen Zahl an Bewertungen (votes; gemessen an allen Filmen, gerundet zur n√§chsten ganzen Zahl)\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(DataExplorer)\n\nDaten importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\"\nd &lt;- read.csv(d_path)\n\nDurchschnittliche Zahl an Bewertungen:\n\nd %&gt;% \n  summarise(votes_mean = mean(votes))\n\n\n\n\n\nvotes_mean\n\n\n\n\n632.1304\n\n\n\n\n\n\nDie durchschnittliche Zahl an Bewertungen betr√§gt also 632.\n\nd %&gt;% \n  select(length, budget, rating, year, votes, Action) %&gt;% \n  filter(year &gt;= 2000) %&gt;% \n  filter(Action == 1) %&gt;% \n  filter(votes &gt;= 632) %&gt;% \n  select(-Action) %&gt;% \n  plot_scatterplot(by = \"rating\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nvis\neda\nstring"
  },
  {
    "objectID": "posts/ReThink3m4/ReThink3m4.html",
    "href": "posts/ReThink3m4/ReThink3m4.html",
    "title": "ReThink3m4",
    "section": "",
    "text": "Aufgabe\nNehmen wir an, wir haben 8 (Wasser-)‚ÄúTreffer‚Äù (\\(W=8\\)) bei 15 W√ºrfen (\\(N=15\\)) erhalten (wieder im Globusversuch).\nBerechnen Sie auf Basis dieser Posteriori-Verteilung (8 Treffer bei 15 W√ºrfen) die Wahrscheinlichkeit f√ºr 6 Wasser bei 9 W√ºrfen (\\(W=6, N=9\\)).\nHinweise:\n\nBerechnen Sie eine Bayes-Box (Gittermethode).\nVerwenden Sie 1000 Gitterwerte.\nFixieren Sie die Zufallszahlen mit dem Startwert 42, d.h. set.seed(42).\nGehen Sie von einem gleichverteilten Prior aus.\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nL√∂sung\nErstellen wir zuerst wieder die Posteriori-Verteilung f√ºr den Globusversuch.\n\np_grid &lt;- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior &lt;- rep( 1 , 1000 )  # Priori-Gewichte\n\nset.seed(42)\nlikelihood &lt;- dbinom( 6 , size=9 , prob=p_grid ) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nDann ziehen wir unsere Stichproben daraus:\n\n# um die Zufallszahlen festzulegen, damit alle die gleichen Zufallswerte bekommen: \nset.seed(42) \n\n# Stichproben ziehen aus der Posteriori-Verteilung\nsamples &lt;- \n  tibble(\n    p = sample( p_grid , prob=posterior, size=1e4, replace=TRUE)) \n\nJetzt erstellen wir die PPV f√ºr einen anderen Versuch, n√§mlich mit 9 Z√ºgen:\n\nPPV &lt;-\n  samples %&gt;% \n  mutate(anzahl_wasser2 = rbinom(1e4, size = 9, prob = p))\n\nSchlie√ülich z√§hlen wir, wie oft 6 Treffer beobachtet werden:\n\nPPV %&gt;% \n  count(anzahl_wasser2 == 6) \n\n# A tibble: 2 √ó 2\n  `anzahl_wasser2 == 6`     n\n  &lt;lgl&gt;                 &lt;int&gt;\n1 FALSE                  7972\n2 TRUE                   2028\n\n\nQuelle\n\nCategories:\n\nbayes\nppv\nprobability\nstring"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie XGB.\nPreppen und Backen Sie das Rezept, aber f√ºhren Sie die Pipelien mit dem gebackenen Datensatz und einem ‚ÄúPlain-Rezept‚Äù durch.\n\n\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\n\n\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\n\n\n\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#daten",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#daten",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "",
    "text": "Verwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#av-und-uv",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#av-und-uv",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "",
    "text": "Die AV lautet c1. Die (einzige) UV lautet: text."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#hinweise",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#hinweise",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "",
    "text": "Orientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#setup",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#setup",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Setup",
    "text": "Setup\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\n\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(lobstr)  # object size\nlibrary(visdat)  # Fingerprint/footprint of dataset (CSV)\ndata(\"sentiws\", package = \"pradadata\")\n\nEine Vorlage f√ºr ein Tidymodels-Pipeline findet sich hier."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#learnermodell-rf",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#learnermodell-rf",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Learner/Modell: RF",
    "text": "Learner/Modell: RF\n\nmod &lt;-\n  rand_forest(mode = \"classification\",\n           mtry = tune(), \n           min_n = tune()\n  )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#gebackenen-datensatz-als-neue-grundlage",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#gebackenen-datensatz-als-neue-grundlage",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Gebackenen Datensatz als neue Grundlage",
    "text": "Gebackenen Datensatz als neue Grundlage\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz. Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind. Die Arbeit des Feature Engineering wurde uns schon abgenommen.\n\nd_train &lt;-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\n\nvis_dat(d_train) +\n  # remove axis labels:\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank() \n        )\n\n\nd_test_baked &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#plain-rezept",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#plain-rezept",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Plain-Rezept",
    "text": "Plain-Rezept\n\nrec &lt;- \n  recipe(c1 ~ ., data = d_train)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#neuer-workflow-mit-plainem-rezept",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#neuer-workflow-mit-plainem-rezept",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Neuer Workflow mit plainem Rezept",
    "text": "Neuer Workflow mit plainem Rezept\n\nwf &lt;-\n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#parallelisierung-√ºber-mehrere-kerne",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#parallelisierung-√ºber-mehrere-kerne",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Parallelisierung √ºber mehrere Kerne",
    "text": "Parallelisierung √ºber mehrere Kerne\n\nlibrary(parallel)\nall_cores &lt;- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl &lt;- makeCluster(3)\nplan(cluster, workers = cl)\n\nAchtung: Viele Kerne brauchen auch viel Speicher."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#tuneresamplefit",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#tuneresamplefit",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Tune/Resample/Fit",
    "text": "Tune/Resample/Fit\n\ntic()\nfit_wordvec_senti_rf &lt;-\n  tune_grid(\n    wf,\n    grid = 10,\n    resamples = vfold_cv(d_train, v = 5))\ntoc()\nbeep()\n\nModerate Gr√∂√üe:\n\nobj_size(fit_wordvec_senti_rf)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#get-best-performance",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#get-best-performance",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Get best performance",
    "text": "Get best performance\n\nautoplot(fit_wordvec_senti_rf)\n\n\nshow_best(fit_wordvec_senti_rf)\n\n\nbest_params &lt;- select_best(fit_wordvec_senti_rf)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#finalisieren",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#finalisieren",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_params &lt;- select_best(fit_wordvec_senti_rf)\ntic()\nwf_finalized &lt;- finalize_workflow(wf, best_params)\nlastfit_rf &lt;- fit(wf_finalized, data = d_train)\ntoc()"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#test-set-g√ºte",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(lastfit_rf, new_data = d_test_baked)\ntoc()\n\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#fazit",
    "href": "posts/germeval-sent-wordvec-rf-plain/germeval-sent-wordvec-rf-plain.html#fazit",
    "title": "germeval03-sent-wordvec-rf-plain",
    "section": "Fazit",
    "text": "Fazit\nVerzichtet man auf ein Rezept mit viel Datenvolumen (Wordvektoren bl√§hen das Rezept m√§chtig auf), so wird das Fitten schlanker und schneller. Schneller auch deshalb, weil ggf. kein Swapping zwischen Speicher und Festplatte mehr n√∂tig ist."
  },
  {
    "objectID": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html",
    "href": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html",
    "title": "wozu-balkendiagramm",
    "section": "",
    "text": "Zu welchem Zweck ist ein Balkendiagramm am besten geeignet?\n\n\n\nUm Mittelwerte zwischen zwei oder mehr Gruppen darzustellen.\nUm H√§ufigkeiten darzustellen.\nUm metrische Verteilungen darzustellen.\nUm metrische Zusammenh√§nge darzustellen."
  },
  {
    "objectID": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist",
    "href": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist",
    "title": "wozu-balkendiagramm",
    "section": "",
    "text": "Um Mittelwerte zwischen zwei oder mehr Gruppen darzustellen.\nUm H√§ufigkeiten darzustellen.\nUm metrische Verteilungen darzustellen.\nUm metrische Zusammenh√§nge darzustellen."
  },
  {
    "objectID": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist-1",
    "href": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist-1",
    "title": "wozu-balkendiagramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/genial/index.html",
    "href": "posts/genial/index.html",
    "title": "genial",
    "section": "",
    "text": "Aufgabe\nWissenschaft! Vielleicht das wichtigste Projekt der Menschheit, deht es doch um die Losl√∂ung von ‚ÄúDu musst das glauben, weil ich das sage‚Äù hinzu ‚ÄúIch glaube das, weil ich es verstehe‚Äù.\nSei 1% aller Studien der Wissenschaft ‚Äúgenial‚Äù. Ein Gutachter pr√ºft eine wissenschaftliche Studie und erkennt 90% der genialen Studien als solche. Nach der Pr√ºfung der Studie ist der Gutachter √ºberzeugt, dass die Studie genial ist.\nAufgabe: Berechnen Sie die Wahrscheinlichkeit, dass die Studie wirklich genial ist.\n         \n\n\nL√∂sung\nGegeben ist:\n\nPr_g &lt;- 0.01  # Anteil genialer Studien/ Wskt einer *g*enialen Studie\nPr_t_geg_g &lt;- 0.9  # Wskt, dass eine Studie als genial getestet wird gegeben, dass sie genial ist\n\nHier kann man Bayes Theorem anwenden:\n\\(Pr(g|t) = \\frac{Pr(g) \\cdot Pr(t|g) }{Pr(t)}\\).\nBerechnen wir zuerst den Z√§hler von Bayes‚Äô Theorem:\n\nzaehler_bayes &lt;- Pr_g * Pr_t_geg_g\nzaehler_bayes\n\n[1] 0.009\n\n\nDann den Nenner:\n\nnenner_bayes &lt;- (zaehler_bayes + (1-Pr_g) * (1-Pr_t_geg_g))\nnenner_bayes\n\n[1] 0.108\n\n\nDann berechnen wir den Wert des Bruchs, indem wir den Z√§hler durch den Nenner teilen:\n\nsol &lt;- zaehler_bayes / nenner_bayes\nsol\n\n[1] 0.08333333\n\n\nDie L√∂sung betr√§gt also: 0.08.\nHier ist ein Baumdiagramm zur Visualisierung:\n\n\n\n\n\n\n\n\n\n\n\nMan kann die Aufgabe auch mit dem Baumdiagramm l√∂sen:\nEs erhalten 108=99+9 Studien ein positives Testergebnis: ‚Äúgeniale Studie!‚Äù Davon sind 9 tats√§chlich genial. Das ist ist ein Anteil von \\(\\frac{9}{108} = 0.0833\\).\nAlso: \\(Pr(g|t) = \\frac{9}{108} = 0.0833\\).\nAlternativ kann man auch mit der Bayesbox arbeiten:\n\n\n\n\n\n\n\n\n\n\n\nHypothese\nPrior\nLikelihood\nPost_unstand\nEvidenz\nPost\n\n\n\n\ngenial\n.01\n.9\n.009\n.108\n.083\n\n\nnichtgenial\n.99\n.1\n.099\n.108\n.092\n\n\n\nK: Krebs\nDie Likelihood f√ºr die Hypothese \\(g\\) (die Hypothese, dass die Studie genail) ist definiert als \\(Pr(D|H)=.9\\). Hier entspricht der positive Genialit√§tstest den Daten.\nDie unstandardisierte Post-Wahrscheinlichkeit entspricht dem Produkt aus Likelihood und Prior: \\(Pr(D|H) \\cdot Pr(H)=.009\\) bzw. \\(.099\\).\nDie Evidenz ist die Summe der Posterior-Wahrscheinlichkeiten multipliziert mit den jeweiligen Priors: \\(Pr(D)=.108\\).\nDie Post-Wahrscheinlichkeit ist die durch die Evidenz dividierte unstandardisierte Post-Wahrscheinlichkeit: \\(Pr(H|D)=.083\\) bzw. \\(.092\\).\n\nCategories:\n\nbayes\nprobability\nnum"
  },
  {
    "objectID": "posts/tidymodels-ames-01/tidymodels-ames-01.html",
    "href": "posts/tidymodels-ames-01/tidymodels-ames-01.html",
    "title": "tidymodels-ames-01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im Train-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price))\n\nDatensatz aufteilen:\n\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nModell fitten:\n\nfit1 &lt;-\n  m1 %&gt;% \n  fit(Sale_Price ~ Gr_Liv_Area, data = ames)\n\n\nfit1 %&gt;% pluck(\"fit\") \n\nModellg√ºte im Train-Sample:\n\nfit1_performance &lt;-\n  fit1 %&gt;% \n  extract_fit_engine()  # identisch zu pluck(\"fit\")\n\nModellg√ºte:\n\nfit1_performance %&gt;% summary()\n\nR-Quadrat via easystats:\n\nlibrary(easystats)\nfit1_performance %&gt;% r2()  # rmse()\n\n\ntidy(fit1_performance)  # √§hnlich zu parameters()\n\n\nsol &lt;- 0.484\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/prob-elementarereignis/index.html",
    "href": "posts/prob-elementarereignis/index.html",
    "title": "prob-elementarereignis",
    "section": "",
    "text": "1 Aufgabe\nWas beschreibt ein Elementarereignis \\(\\omega\\) in der Wahrscheinlichkeitsrechnung?\n\nDie Menge aller m√∂glichen Ergebnisse.\nEine Menge, die zwei oder mehr Ergebnisse enth√§lt.\nDas Ereignis, das immer eintritt.\nEin einzelnes, nicht weiter zerlegbares Ergebnis eines Zufallsexperiments.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nEin einzelnes, nicht weiter zerlegbares Ergebnis eines Zufallsexperiments."
  },
  {
    "objectID": "posts/Likelihood-identifizieren/Likelihood-identifizieren.html",
    "href": "posts/Likelihood-identifizieren/Likelihood-identifizieren.html",
    "title": "Likelihood-identifizieren",
    "section": "",
    "text": "Welche Zeile der folgenden Modellspezifikation zeigt den Likelihood?\n\\[\n\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\beta_0 + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\n\\]\nAufgabe: W√§hlen Sie die richtige Zeile aus der folgenden Liste aus.\n\n\n\n1\n2\n3\n4\n5"
  },
  {
    "objectID": "posts/Likelihood-identifizieren/Likelihood-identifizieren.html#answerlist",
    "href": "posts/Likelihood-identifizieren/Likelihood-identifizieren.html#answerlist",
    "title": "Likelihood-identifizieren",
    "section": "",
    "text": "1\n2\n3\n4\n5"
  },
  {
    "objectID": "posts/Likelihood-identifizieren/Likelihood-identifizieren.html#answerlist-1",
    "href": "posts/Likelihood-identifizieren/Likelihood-identifizieren.html#answerlist-1",
    "title": "Likelihood-identifizieren",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch. Lineares Modell.\nFalsch. Prior Achsenabschnitt.\nFalsch. Prior Regressiongewicht.\nFalsch. Prior Streuung der AV.\n\n\nCategories:\n\nregression\nbayes\nlikelihood"
  },
  {
    "objectID": "posts/nasa02/nasa02.html",
    "href": "posts/nasa02/nasa02.html",
    "title": "nasa02",
    "section": "",
    "text": "Aufgabe\nViele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read_csv(data_path, skip = 1)\n\nOder von der eigenen Festplatte, wenn schon heruntergeladen:\n\nd &lt;- read_csv(\"/Users/sebastiansaueruser/datasets/nasa02.csv\")\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgaben\n\nBerechnen Sie die die Korrelation der Temperatur von Januar und Februar\nBerechnen Sie die die Korrelation der Temperatur von Januar und Februar pro Dekade\n\nHinweise:\n\nSie m√ºssen zuerst die Dekade als neue Spalte berechnen.\n\n         \n\n\nL√∂sung\nDekade berechnen:\n\nd &lt;-\n  d %&gt;% \n  mutate(decade = round(Year/10))\n\nKorrelation:\n\nd %&gt;% \n  summarise(temp_cor = cor(Jan, Feb))\n\n\n\n\n\ntemp_cor\n\n\n\n\n0.9415313\n\n\n\n\n\n\nKorrelation pro Dekade:\n\nd_summarized &lt;- \n  d %&gt;% \n  group_by(decade) %&gt;% \n  summarise(temp_cor = cor(Jan, Feb))\n\n\n\n\n\n\n\n\n\ndecade\ntemp_cor\n\n\n\n\n188\n0.88\n\n\n189\n0.79\n\n\n190\n0.53\n\n\n191\n0.84\n\n\n192\n0.82\n\n\n193\n0.72\n\n\n194\n0.50\n\n\n195\n0.78\n\n\n196\n0.54\n\n\n197\n0.79\n\n\n198\n0.80\n\n\n199\n0.52\n\n\n200\n0.58\n\n\n201\n0.66\n\n\n202\n0.93\n\n\n\n\n\n\n\nZum Visualisieren gibt es viele M√∂glichkeiten. Wer kein Experte sein will, dem reicht es, eine M√∂glichkeit zu kennen.\nHier ist eine Visualisierung mit Hilfe des R-Pakets ggplot2:\n\nd_summarized %&gt;% \n  ggplot(aes(x = decade, y = temp_cor)) +\n  geom_point(color = \"darkblue\") +\n  geom_line(alpha = .7) +\n  scale_y_continuous(limits = c(0,1))\n\n\n\n\n\n\n\n\nAlternativ k√∂nnen Sie zum Visualisieren der Daten z.B. das Paket ggpubr nutzen:\n\nlibrary(ggpubr)\nggscatter(d_summarized, x = \"decade\", y = \"temp_cor\", add = \"reg.line\")\n\n\n\n\n\n\n\n\nOder mit dem R-Paket DataExplorer:\n\nlibrary(DataExplorer)\nd_summarized |&gt; \n  plot_scatterplot(by = \"temp_cor\")\n\n\n\n\n\n\n\n\nDie Korrelation der Temperaturen und damit die √Ñhnlichkeit der Muster hat im Laufe der Dekaden immer mal wieder geschwankt.\nFalls Sie Teile der R-Syntax nicht kennen: Machen Sie sich nichts daraus. üòÑ\n\nCategories:\n\ndata\neda\nlagema√üe\nstring"
  },
  {
    "objectID": "posts/min-corr1/min-corr1.html",
    "href": "posts/min-corr1/min-corr1.html",
    "title": "min-corr1",
    "section": "",
    "text": "Aufgabe\nWelches Diagramm zeigt den schw√§chsten (absoluten) linearen Zusammenhang (Korrelation)?\nGeben Sie die Nummer ein, die in der Kopfzeile jedes Teildiagramms angezeigt wird.\n         \n\n\nL√∂sung\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nnum"
  },
  {
    "objectID": "posts/nasa05/nasa05.html",
    "href": "posts/nasa05/nasa05.html",
    "title": "nasa05",
    "section": "",
    "text": "Viele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nZum Animieren verwenden wir diese Pakete:\n\nlibrary(gganimate)\nlibrary(plotly)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read_csv(data_path, skip = 1)\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgabe\n\nVisualisieren Sie Temperatur pro Jahr und Dekade; animieren Sie Ihre Diagramme mittels plotly.\n\nHinweise:\n\nSie m√ºssen zuerst die Dekade als neue Spalte berechnen."
  },
  {
    "objectID": "posts/nasa05/nasa05.html#daten-aufbereiten",
    "href": "posts/nasa05/nasa05.html#daten-aufbereiten",
    "title": "nasa05",
    "section": "Daten aufbereiten",
    "text": "Daten aufbereiten\nCharacter in Zahlen umwandeln:\n\nd2 &lt;-\n  d %&gt;% \n  select(Year:Dec) %&gt;% \n  mutate(across(Apr:Dec, as.numeric))\n\n\nd3 &lt;- \n  d2 %&gt;% \n  pivot_longer(-Year, values_to = \"temp\", names_to = \"month\")\n\n\nmonths &lt;-\n  tibble(\n    month = d3$month[1:12],\n    month_num = 1:12\n  )\n\n\nd3 &lt;- \n  d3 %&gt;% \n  full_join(months)"
  },
  {
    "objectID": "posts/nasa05/nasa05.html#daten-zusammenfassen",
    "href": "posts/nasa05/nasa05.html#daten-zusammenfassen",
    "title": "nasa05",
    "section": "Daten zusammenfassen",
    "text": "Daten zusammenfassen"
  },
  {
    "objectID": "posts/nasa05/nasa05.html#animation-mit-plotly",
    "href": "posts/nasa05/nasa05.html#animation-mit-plotly",
    "title": "nasa05",
    "section": "Animation mit plotly",
    "text": "Animation mit plotly\n\nd3 %&gt;% \nplot_ly(\n  x = ~Year,\n  y = ~temp,\n  #color = ~month,\n  frame = ~Year,\n  hoverinfo = \"text\",\n  text = ~Year,\n  type = \"scatter\",\n  mode = \"markers\"\n)\n\n\n\n\n\n\nd3 %&gt;% \nplot_ly(\n  x = ~Year,\n  y = ~temp,\n  color = ~month_num,\n  frame = ~Year,\n  hoverinfo = \"text\",\n  text = ~Year,\n  type = \"scatter\",\n  mode = \"markers\"\n)"
  },
  {
    "objectID": "posts/nasa05/nasa05.html#fazit",
    "href": "posts/nasa05/nasa05.html#fazit",
    "title": "nasa05",
    "section": "Fazit",
    "text": "Fazit\nFalls Sie Teile der R-Syntax nicht kennen: Machen Sie sich nichts daraus. Be happy üòÑ\n\nCategories:\n\ndata\neda\nlagema√üe\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/rethink3e1-7/rethink3e1-7.html",
    "href": "posts/rethink3e1-7/rethink3e1-7.html",
    "title": "rethink3e1-7",
    "section": "",
    "text": "Exercise\nErstellen Sie die Posteriori-Verteilung f√ºr den Globusversuch. Nutzen Sie daf√ºr diese Syntax:\n\np_grid &lt;- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior &lt;- rep( 1 , 1000 )  # Priori-Gewichte\n\nlikelihood &lt;- dbinom( 6 , size=9 , prob=p_grid ) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\n# um die Zufallszahlen festzulegen, damit wir alle die gleichen Zahlen bekommen zum Schnluss: \nset.seed(42) \n\n# Stichproben ziehen aus der Posteriori-Verteilung\nsamples &lt;- \n  tibble(\n    p = sample( p_grid , prob=posterior, size=1e4, replace=TRUE)) \n\n\nWie viel Wahrscheinlichkeitsmasse liegt unter \\(p=0.2\\)?\nWie viel Wahrscheinlichkeitsmasse liegt √ºber \\(p=0.8\\)?\nWelcher Anteil der Posteriori-Verteilung liegt zwischen \\(p=0.2\\) und \\(p=0.8\\)?\nUnter welchem Wasseranteil \\(p\\) liegen 10% der Posteriori-Verteilung?\n√úber welchem Wasseranteil \\(p\\) liegen 10% der Posteriori-Verteilung?\nWelches schm√§lstes Intervall von \\(p\\) enth√§lt 66% der Posteriori-Wahrscheinlichkeit?\nWelcher Wertebereich (synonym: Welches Intervall) von \\(p\\) enth√§lt 66% der Posteriori-Wahrscheinlichkeit (hier wird Posteriori-Wahrscheinlichkeit synonym gebraucht zu Posteriori-Verteilung)? Wie nennt man diese Arten von Intervall?\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nSolution\nHier ist eine Visualisierung der Posteriori-Verteilung:\n\nggdensity(samples, x = \"p\")   # aus \"ggpubr\"\n\n\n\n\n\n\n\n\nEs finden sich auch L√∂sungsvorschl√§ge online, z.B. hier\n\nWie viel Wahrscheinlichkeitsmasse liegt unter \\(p=0.2\\)?\n\n\nsamples %&gt;% \n  count(p &lt; 0.2)\n\n\n\n\n\np &lt; 0.2\nn\n\n\n\n\nFALSE\n9993\n\n\nTRUE\n7\n\n\n\n\n\n\nFast nix!\n\nWie viel Wahrscheinlichkeitsmasse liegt √ºber \\(p=0.8\\)?\n\n\nsamples %&gt;% \n  count(p &gt; 0.8)\n\n\n\n\n\np &gt; 0.8\nn\n\n\n\n\nFALSE\n8842\n\n\nTRUE\n1158\n\n\n\n\n\n\nNaja, so gut 10%!\n\nWelcher Anteil der Posteriori-Verteilung liegt zwischen \\(p=0.2\\) und \\(p=0.8\\)?\n\n\nsamples %&gt;% \n  count(p &gt; 0.2 & p &lt; 0.8) \n\n\n\n\n\np &gt; 0.2 & p &lt; 0.8\nn\n\n\n\n\nFALSE\n1165\n\n\nTRUE\n8835\n\n\n\n\n\n\nKnapp 90%!\n\nUnter welchem Wasseranteil \\(p\\) liegen 20% der Posteriori-Verteilung?\n\nEine M√∂glichkeit: Wir sortieren \\(p\\) der Gr√∂√üe nach (aufsteigend), filtern dann so, dass wir nur die ersten 20% der Zeilen behalten und schauen dann, was der gr√∂√üte Wert ist.\n\nsamples %&gt;% \n  arrange(p) %&gt;% \n  slice_head(prop = 0.2) %&gt;% \n  summarise(quantil_20 = max(p))\n\n\n\n\n\nquantil_20\n\n\n\n\n0.5165165\n\n\n\n\n\n\nAndererseits: Das, was wir gerade gemacht haben, nennt man auch ein Quantil berechnen, s. auch hier. Daf√ºr gibt‚Äôs fertige Funktionen in R, wie quantile():\n\nsamples %&gt;% \n  summarise(q_20 = quantile(p, 0.2))\n\n\n\n\n\nq_20\n\n\n\n\n0.5165165\n\n\n\n\n\n\n\n√úber welchem Wasseranteil \\(p\\) liegen 10% der Posteriori-Verteilung?\n\n\nsamples %&gt;% \n  summarise(quantile(p, 0.9))\n\n\n\n\n\nquantile(p, 0.9)\n\n\n\n\n0.8098098\n\n\n\n\n\n\nMit 90% Wahrscheinlichkeit ist der Wasseranteil h√∂chstens bei 81%.\n\nWelches schm√§lstes Intervall von \\(p\\) enth√§lt 66% der Posteriori-Wahrscheinlichkeit?\n\n\nlibrary(easystats)\nhdi(samples, ci = 0.66)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np\n0.66\n0.5155155\n0.7857858\n\n\n\n\n\n\n\nWelcher Wertebereich von \\(p\\) enth√§lt 66% der Posteriori-Wahrscheinlichkeit (hier wird Posteriori-Wahrscheinlichkeit syonyom gebraucht zu Posteriori-Verteilung)?\n\nWir nutzen hier die Equal-Tail-Intervall (oder Perzentilintervall genannt), da die Aufgabe keine genauen Angaben macht.\n\neti(samples, ci = 0.66)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np\n0.66\n0.5005005\n0.7747748\n\n\n\n\n\n\nEin ‚Äúmittleres‚Äù 2/3-Intervall l√§sst 1/3 der Wahrscheinlichkeitsmasse au√üen vor, und zwar gleichm√§√üig in zwei H√§lften links und rechts, also jeweils 1/6 (17%). So ein Intervall hei√üt Perzentilintervall. Daher synonym:\n\nsamples %&gt;% \n  summarise(PI_66 = quantile(p, prob = c(0.17, .84)))\n\n\n\n\n\nPI_66\n\n\n\n\n0.5005005\n\n\n0.7787788\n\n\n\n\n\n\n\nCategories:\n\nbayes\nprobability\npost"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html",
    "href": "posts/vis-gapminder/vis-gapminder.html",
    "title": "vis-gapminder",
    "section": "",
    "text": "In dieser Fallstudie (YACSDA: Yet another Case Study on Data Analysis) untersuchen wir den Datensatz gapminder.\nSie k√∂nnen den Datensatz so beziehen:\n\n#install.packages(\"gapminder\")\nlibrary(gapminder)\ndata(\"gapminder\")\nd &lt;- gapminder \n\nOder so:\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/gapminder/gapminder.csv\")\n\nEin Codebook finden Sie hier.\nDie Forschungsfrage lautet:\nWas ist der Einfluss des Kontinents und des Bruttosozialprodukts auf die Lebenswartung?\n\nAbh√§ngige Variable (metrisch), y: Lebenserwartung\nUnabh√§ngige Variable 1 (nominal), x1: Kontinent\nUnabh√§ngige Variable 2 (metrisch), x2: Bruttosozialprodukt\n\nVisualisieren Sie dazu folgende Aspekte der Forschungsfrage!"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#umbenennen",
    "href": "posts/vis-gapminder/vis-gapminder.html#umbenennen",
    "title": "vis-gapminder",
    "section": "Umbenennen",
    "text": "Umbenennen\nZur einfacheren Verarbeitung nenne ich die Variablen um:\n\nd &lt;-\n  d |&gt; \n  rename(y = lifeExp, x1 = continent, x2 = gdpPercap)"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.",
    "text": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.\nDas R-Paket ggpubr erstellt sch√∂ne Diagramme (basierend auf ggplot) auf einfache Art. Nehmen wir ein Dichtediagramm; die Variable y soll auf der X-Achse stehen:\n\nggdensity(d, x = \"y\")\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable in Anf√ºhrungsstriche gesetzt werden muss: x = \"y\".\nOder ein Histogramm:\n\ngghistogram(d, x = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "href": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "title": "vis-gapminder",
    "section": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.",
    "text": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.\nUm Diagramme mit Statistiken anzureichen, bietet sich das Paket ggstatsplot an:\n\ngghistostats(d, x = y)\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable nicht in Anf√ºhrungsstriche gesetzt werden darf: x = y."
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie die Verteilung von x1 und x2.",
    "text": "Visualisieren Sie die Verteilung von x1 und x2.\n\nx1\n\nd_counted &lt;- \n  d |&gt; \n  count(x1) \n\n\nggbarplot(data = d_counted, y = \"n\", x = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\n\n\nx2\n\ngghistostats(d, x = x2)"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie die Verteilung von y bedingt auf x1",
    "text": "Visualisieren Sie die Verteilung von y bedingt auf x1\n\ngghistogram(d, x = \"y\", fill = \"x1\")\n\n\n\n\n\n\n\n\nOder so:\n\ngghistogram(d, x = \"y\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "href": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "title": "vis-gapminder",
    "section": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu",
    "text": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu\n\ngrouped_gghistostats(d, x = y, grouping.var = x1)"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie den Zusammenhang von y und x2",
    "text": "Visualisieren Sie den Zusammenhang von y und x2\n\nggscatter(d, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#verbessern-sie-das-letzte-diagramm-so-dass-es-√ºbersichtlicher-wird",
    "href": "posts/vis-gapminder/vis-gapminder.html#verbessern-sie-das-letzte-diagramm-so-dass-es-√ºbersichtlicher-wird",
    "title": "vis-gapminder",
    "section": "Verbessern Sie das letzte Diagramm, so dass es √ºbersichtlicher wird",
    "text": "Verbessern Sie das letzte Diagramm, so dass es √ºbersichtlicher wird\nEs gibt mehrere Wege, das Diagramm √ºbersichtlicher zu machen. Logarithmieren ist ein Weg.\n\nd |&gt; \n  mutate(x2 = log(x2)) |&gt; \n  ggscatter(x = \"x2\", y = \"y\")\n\n\n\n\n\n\n\n\nSynonym k√∂nnten wir schreiben:\n\nd_logged &lt;- \n  d |&gt; \n  mutate(x2 = log(x2))\n  \n\nggscatter(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "href": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "title": "vis-gapminder",
    "section": "F√ºgen Sie dem letzten Diagramm relevante Kennzahlen hinzu",
    "text": "F√ºgen Sie dem letzten Diagramm relevante Kennzahlen hinzu\n\nggscatterstats(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "href": "posts/vis-gapminder/vis-gapminder.html#f√ºgen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "title": "vis-gapminder",
    "section": "F√ºgen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu",
    "text": "F√ºgen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"reg.line\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "href": "posts/vis-gapminder/vis-gapminder.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "title": "vis-gapminder",
    "section": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade",
    "text": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "href": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "title": "vis-gapminder",
    "section": "Gruppieren Sie das letzte Diagramm nach x1",
    "text": "Gruppieren Sie das letzte Diagramm nach x1\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"),\n          facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#dichotomisieren-sie-y-und-z√§hlen-sie-die-h√§ufigkeiten",
    "href": "posts/vis-gapminder/vis-gapminder.html#dichotomisieren-sie-y-und-z√§hlen-sie-die-h√§ufigkeiten",
    "title": "vis-gapminder",
    "section": "Dichotomisieren Sie y und z√§hlen Sie die H√§ufigkeiten",
    "text": "Dichotomisieren Sie y und z√§hlen Sie die H√§ufigkeiten\nNehmen wir einen Mediansplit, um zu dichotomisieren.\n\nd &lt;-\n  d |&gt; \n  mutate(y_dicho = ifelse(y &gt; median(y), \"high\", \"low\"))\n\n\nd |&gt; \n  count(y_dicho) |&gt; \n  ggbarplot(x = \"y_dicho\", y = \"n\")\n\n\n\n\n\n\n\n\nGleich viele! Das sollte nicht verwundern."
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "href": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "title": "vis-gapminder",
    "section": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1",
    "text": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1\n\nd_count &lt;- \nd |&gt; \n  count(y_dicho, x1) \n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\n\n\n\n\nhigh\nAfrica\n64\n\n\nhigh\nAmericas\n211\n\n\nhigh\nAsia\n207\n\n\nhigh\nEurope\n346\n\n\nhigh\nOceania\n24\n\n\nlow\nAfrica\n560\n\n\nlow\nAmericas\n89\n\n\nlow\nAsia\n189\n\n\nlow\nEurope\n14\n\n\n\n\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"n\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-h√§ufigkeiten-statt-absoluter-h√§ufigkeiten-gezeigt-werden",
    "href": "posts/vis-gapminder/vis-gapminder.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-h√§ufigkeiten-statt-absoluter-h√§ufigkeiten-gezeigt-werden",
    "title": "vis-gapminder",
    "section": "Variieren Sie das letzte Diagramm so, dass Anteile (relative H√§ufigkeiten) statt absoluter H√§ufigkeiten gezeigt werden",
    "text": "Variieren Sie das letzte Diagramm so, dass Anteile (relative H√§ufigkeiten) statt absoluter H√§ufigkeiten gezeigt werden\n\nd_count &lt;-\n  d_count |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\nprop\n\n\n\n\nhigh\nAfrica\n64\n0.04\n\n\nhigh\nAmericas\n211\n0.12\n\n\nhigh\nAsia\n207\n0.12\n\n\nhigh\nEurope\n346\n0.20\n\n\nhigh\nOceania\n24\n0.01\n\n\nlow\nAfrica\n560\n0.33\n\n\nlow\nAmericas\n89\n0.05\n\n\nlow\nAsia\n189\n0.11\n\n\nlow\nEurope\n14\n0.01\n\n\n\n\n\n\nCheck:\n\nd_count |&gt; \n  summarise(sum(prop))\n\n\n\n\n\nsum(prop)\n\n\n\n\n0.99\n\n\n\n\n\n\nGut! Die Anteile summieren sich zu ca. 1 (100 Prozent).\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMan beachten, dass sich die Anteile auf das ‚ÄúGesamt-N‚Äù beziehen.\nVielleicht m√∂chten wir die Anteile lieber pro Stufe von x1 beziehen. Dazu gruppieren wir nach (und pro Stufe von) x1.\n\nd_count &lt;-\n  d_count |&gt; \n  group_by(x1) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\nprop\n\n\n\n\nhigh\nAfrica\n64\n0.10\n\n\nhigh\nAmericas\n211\n0.70\n\n\nhigh\nAsia\n207\n0.52\n\n\nhigh\nEurope\n346\n0.96\n\n\nhigh\nOceania\n24\n1.00\n\n\nlow\nAfrica\n560\n0.90\n\n\nlow\nAmericas\n89\n0.30\n\n\nlow\nAsia\n189\n0.48\n\n\nlow\nEurope\n14\n0.04\n\n\n\n\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\n\nCategories:\n\nvis\nyacsda\nggquick\ngapminder\nstring"
  },
  {
    "objectID": "posts/samples-nyc/index.html",
    "href": "posts/samples-nyc/index.html",
    "title": "samples-nyc",
    "section": "",
    "text": "Drei Studierende arbeiten f√ºr die New Yorker Flughafenbeh√∂rde als Werkstudenten. Fragt ihre Chefin eines Tages: ‚ÄúWelcher der drei New Yorker Flugh√§fen hat im Schnitt die h√∂chste Versp√§tung?‚Äù\nStudi A √ºberlegt: ‚ÄúIch schaue mir mal die Versp√§tung vom 1. Januar an, das geht am schnellsten, den Wert nehme ich dann als Sch√§tzwert f√ºr die Versp√§tung des ganzen Jahres.‚Äù\nStudi B argumentiert so: ‚ÄúHm, ich schaue mir mal die ersten 1000 Fl√ºge des Jahres und diesen Mittelwert nehme ich als Sch√§tzwert f√ºr die Versp√§tung des ganzen Jahres.‚Äù\nStudi C hingegen ist folgender Meinung: ‚ÄúIch ziehe mal eine Zufallsstichprobe, habe ich in der Statistik-Vorlesung gelernt. N=100 sollte gen√ºgen.‚Äù\nDie Chefin bezieht sich √ºbrigens auf das Jahr 2023.\nAufgabe: Welcher der drei Studis macht die beste Vorhersage? Rechnen Sie nach und begr√ºnden Sie Ihre Meinung!"
  },
  {
    "objectID": "posts/samples-nyc/index.html#setup",
    "href": "posts/samples-nyc/index.html#setup",
    "title": "samples-nyc",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(nycflights23)\ndata(\"flights\")\nlibrary(tidyverse)\n\nWie viele Fl√ºge gab es?\n\nnrow(flights)\n\n[1] 435352\n\n\nViele!\nWelche Variablens gibt es im Datensatz?\n\nglimpse(flights)\n\nRows: 435,352\nColumns: 19\n$ year           &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2‚Ä¶\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ dep_time       &lt;int&gt; 1, 18, 31, 33, 36, 503, 520, 524, 537, 547, 549, 551, 5‚Ä¶\n$ sched_dep_time &lt;int&gt; 2038, 2300, 2344, 2140, 2048, 500, 510, 530, 520, 545, ‚Ä¶\n$ dep_delay      &lt;dbl&gt; 203, 78, 47, 173, 228, 3, 10, -6, 17, 2, -10, -9, -7, -‚Ä¶\n$ arr_time       &lt;int&gt; 328, 228, 500, 238, 223, 808, 948, 645, 926, 845, 905, ‚Ä¶\n$ sched_arr_time &lt;int&gt; 3, 135, 426, 2352, 2252, 815, 949, 710, 818, 852, 901, ‚Ä¶\n$ arr_delay      &lt;dbl&gt; 205, 53, 34, 166, 211, -7, -1, -25, 68, -7, 4, -13, -14‚Ä¶\n$ carrier        &lt;chr&gt; \"UA\", \"DL\", \"B6\", \"B6\", \"UA\", \"AA\", \"B6\", \"AA\", \"UA\", \"‚Ä¶\n$ flight         &lt;int&gt; 628, 393, 371, 1053, 219, 499, 996, 981, 206, 225, 800,‚Ä¶\n$ tailnum        &lt;chr&gt; \"N25201\", \"N830DN\", \"N807JB\", \"N265JB\", \"N17730\", \"N925‚Ä¶\n$ origin         &lt;chr&gt; \"EWR\", \"JFK\", \"JFK\", \"JFK\", \"EWR\", \"EWR\", \"JFK\", \"EWR\",‚Ä¶\n$ dest           &lt;chr&gt; \"SMF\", \"ATL\", \"BQN\", \"CHS\", \"DTW\", \"MIA\", \"BQN\", \"ORD\",‚Ä¶\n$ air_time       &lt;dbl&gt; 367, 108, 190, 108, 80, 154, 192, 119, 258, 157, 164, 1‚Ä¶\n$ distance       &lt;dbl&gt; 2500, 760, 1576, 636, 488, 1085, 1576, 719, 1400, 1065,‚Ä¶\n$ hour           &lt;dbl&gt; 20, 23, 23, 21, 20, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6,‚Ä¶\n$ minute         &lt;dbl&gt; 38, 0, 44, 40, 48, 0, 10, 30, 20, 45, 59, 0, 59, 0, 0, ‚Ä¶\n$ time_hour      &lt;dttm&gt; 2023-01-01 20:00:00, 2023-01-01 23:00:00, 2023-01-01 2‚Ä¶\n\n\nNehmen wir dep_delay als Zielvariable. Die Chefin hat nicht genau gesagt, welche Variable sie meint. Da sieht man es mal wieder: Man muss Annahmen treffen. Ist aber auch sch√∂n, denn man kann selber entscheiden, was einem besser gef√§llt."
  },
  {
    "objectID": "posts/samples-nyc/index.html#los-gehts",
    "href": "posts/samples-nyc/index.html#los-gehts",
    "title": "samples-nyc",
    "section": "2.2 Los geht‚Äôs",
    "text": "2.2 Los geht‚Äôs"
  },
  {
    "objectID": "posts/samples-nyc/index.html#studentin-a",
    "href": "posts/samples-nyc/index.html#studentin-a",
    "title": "samples-nyc",
    "section": "2.3 Studentin A",
    "text": "2.3 Studentin A\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n# A tibble: 3 √ó 2\n  origin dep_delay\n  &lt;chr&gt;      &lt;dbl&gt;\n1 EWR        23.7 \n2 JFK        18.8 \n3 LGA         9.07\n\n\n‚ÄúKlares (?) Ergebnis! EWR, also Newark, hat die gr√∂√üte Versp√§tung!‚Äù\n\n2.3.1 Student B\n\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  slice(1:1000) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n# A tibble: 3 √ó 2\n  origin dep_delay\n  &lt;chr&gt;      &lt;dbl&gt;\n1 EWR        26.1 \n2 JFK        19.9 \n3 LGA         9.41\n\n\n‚ÄúGlasklares (?) Ergebnis! EWR, also Newark, hat die gr√∂√üte Versp√§tung!‚Äù\n\n\n2.3.2 Studentin C\n\nset.seed(73)\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n# A tibble: 3 √ó 2\n  origin dep_delay\n  &lt;chr&gt;      &lt;dbl&gt;\n1 EWR         2.04\n2 JFK        14.3 \n3 LGA         8.85\n\n\n‚ÄúGlasklares (?) Ergebnis! JFK, also John-F-Kennedy, hat die gr√∂√üte Versp√§tung! Newark ist hingegen superp√ºnktlich!‚Äù"
  },
  {
    "objectID": "posts/samples-nyc/index.html#moment",
    "href": "posts/samples-nyc/index.html#moment",
    "title": "samples-nyc",
    "section": "2.4 Moment",
    "text": "2.4 Moment\nLeider entbrennt hier ein Streit. Vermutlich einige Eifersuchtsmomente hinter den Kulissen, aber wir wissen nichts Genaues.\nStudentin A: ‚ÄúSo ein Quatsch, C, du hast die Zufallszahl auf 73 festgelegt, warum gerade diese Zahl?! Bei einer anderen Zahl k√∂nnte ein ganz andere Stichprobe und damit ein ganz anderes Ergebnis herauskommen!‚Äù\nStudentin C: ‚ÄúIch habe k√ºrzlich gelernt, dass nicht 42, sondern 73 die beste Zahl ist. Also musste ich 73 nehmen!\nStudent B: ‚ÄúAber was k√§me heraus, wenn du 42 als Zufallszahl nehmen w√ºrdest, nur mal theoretisch?‚Äù\nStudentin C: ‚Äú√Ñh‚Ä¶‚Äù\n\nset.seed(42)\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n# A tibble: 3 √ó 2\n  origin dep_delay\n  &lt;chr&gt;      &lt;dbl&gt;\n1 EWR        28.3 \n2 JFK         7.52\n3 LGA         9.94\n\n\nStudentin C: ‚Äú√Ñh, also‚Ä¶ Das spielt doch gar keine Rolle, was rauskommt, denn bei jeder Zahl kann ja was anderes rauskommen.‚Äù\nA: ‚ÄúDu m√ºsstest also dein Vorgehen √§ndern‚Ä¶ Jede Zahl ausprobieren oder so.‚Äù\nC: ‚ÄúLiebe A, du mit deinem 1. Januar, das ist doch totaler Quatsch, an deiner Stelle w√§re ich lieber still.‚Äù\nA: ‚ÄúAber es kommt was Gutes raus mit meiner Methode!‚Äù\nB: ‚ÄúWoher willst du √ºberhaupt wissen, ob es was Gutes ist?‚Äù\nA: ‚ÄúWirst schon sehen!‚Äù\nC: ‚ÄúPuh, also gut, ich rechne noch mal. Ich zieh einfach ne Menge Stichproben, mit zuf√§lligen Seed-Nummern ‚Ä¶‚Äù\nA: ‚ÄúWhatever!‚Äù\nC: ‚ÄúMoment.., hier kommt Newark, EWR.‚Äù\n\nn_reps &lt;- 100  # Anzahl von Stichproben\nsample_size &lt;- 100  # Umfang jeder Stichprobe\n\newr_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"EWR\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\newr_viele_schaetzwerte\n\n[1] 15.035\n\n\nB: ‚ÄúWow, C, du bist halt schon die Statistik-Checkerin‚Ä¶‚Äù.\nA: ‚ÄúHey B, h√∂r gef√§lligst mit diesen Schmeicheleien auf!‚Äù\nB: ‚ÄúJedenfalls ist das Ergebnis ‚Ä¶ anders als unsere!‚Äù\nC: ‚ÄúHier noch mal f√ºr die anderen Flugh√§fen. JFK:‚Äù\n\njfk_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"JFK\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\njfk_viele_schaetzwerte\n\n[1] 16.1487\n\n\nC: ‚ÄúUnd LaGuardia:‚Äù\n\nlga_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"LGA\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\nlga_viele_schaetzwerte\n\n[1] 10.7901\n\n\nC: ‚ÄúAlso, unterm Strich, LGA rules! LGA hat die geringste Versp√§tung im Schnitt, nach meiner Rechnung.‚Äù\n\nlga_viele_schaetzwerte\n\n[1] 10.7901\n\newr_viele_schaetzwerte\n\n[1] 15.035\n\njfk_viele_schaetzwerte\n\n[1] 16.1487"
  },
  {
    "objectID": "posts/samples-nyc/index.html#fazit",
    "href": "posts/samples-nyc/index.html#fazit",
    "title": "samples-nyc",
    "section": "2.5 Fazit?",
    "text": "2.5 Fazit?\nA: ‚ÄúOkay, meine Methode war ein bisschen zu einfach. Aber hat auch am wenigsten Arbeit gemacht. Das nennt man wirtschaftlich vorgehen, nur darum geht‚Äôs im Business. Also hab ich trotzdem gewonnen!‚Äù\nB: ‚ÄúNope, mein Vorgehen ist in Wirklichkeit das Beste. Zumindest wenn ich von jedem Monat 100 Fl√ºge genommen h√§tte, dann h√§tte sich sicher alles super ausgeglichen, Jahreszeiten und so. Und es w√§re nicht so viel Aufwand wie die zich Tausend Stichproben, die C gezogen hat.‚Äù\nC: ‚ÄúKann ja alles sein, aber mein Vorgehen hat am meisten Spa√ü gemacht. √úbrigens B, deine neue Idee m√ºsste man mal untersuchen. Wollen wir zwei uns das mal zusammen anschauen, nur wir zwei?‚Äù"
  },
  {
    "objectID": "posts/Regr-Bayes-interpret02a/Regr-Bayes-interpret02a.html",
    "href": "posts/Regr-Bayes-interpret02a/Regr-Bayes-interpret02a.html",
    "title": "Regr-Bayes-interpret02a",
    "section": "",
    "text": "Exercise\nBetrachten Sie das Modell zu folgender Regressionsformel und interpretieren Sie die Ausgabe des folgenden Regressionsmodells. Geben Sie f√ºr jeden Regressionskoeffizienten an, wie sein Wert zu verstehen ist! Interpretieren Sie auch den Interaktionseffekt.\nRegressionsformel:\nmpg ~ hp_z + am + hp_z:am\nHinweise:\n\nDas Suffix _z steht f√ºr z-standardisierte Variablen.\n\nSetup:\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Stan, komm her\nlibrary(easystats)  # Komfort\n\ndata(mtcars)\n\nZuerst standardisieren wir die Daten:\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nmtcars2  %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.090625\n6.0269481\n7.525000\n10.4000000\n33.900000\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl\n6.187500\n1.7859216\n4.000000\n4.0000000\n8.000000\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp\n230.721875\n123.9386938\n221.525000\n71.1000000\n472.000000\n0.4202331\n-1.0675234\n32\n0\n\n\nhp\n146.687500\n68.5628685\n84.500000\n52.0000000\n335.000000\n0.7994067\n0.2752116\n32\n0\n\n\ndrat\n3.596563\n0.5346787\n0.840000\n2.7600000\n4.930000\n0.2927802\n-0.4504325\n32\n0\n\n\nwt\n3.217250\n0.9784574\n1.186250\n1.5130000\n5.424000\n0.4659161\n0.4165947\n32\n0\n\n\nqsec\n17.848750\n1.7869432\n2.022500\n14.5000000\n22.900000\n0.4063466\n0.8649307\n32\n0\n\n\nvs\n0.437500\n0.5040161\n1.000000\n0.0000000\n1.000000\n0.2645418\n-2.0632731\n32\n0\n\n\nam\n0.406250\n0.4989909\n1.000000\n0.0000000\n1.000000\n0.4008089\n-1.9665503\n32\n0\n\n\ngear\n3.687500\n0.7378041\n1.000000\n3.0000000\n5.000000\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb\n2.812500\n1.6152000\n2.000000\n1.0000000\n8.000000\n1.1570911\n2.0200593\n32\n0\n\n\nmpg_z\n0.000000\n1.0000000\n1.248559\n-1.6078826\n2.291272\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl_z\n0.000000\n1.0000000\n2.239740\n-1.2248578\n1.014882\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp_z\n0.000000\n1.0000000\n1.787376\n-1.2879099\n1.946754\n0.4202331\n-1.0675234\n32\n0\n\n\nhp_z\n0.000000\n1.0000000\n1.232446\n-1.3810318\n2.746567\n0.7994067\n0.2752116\n32\n0\n\n\ndrat_z\n0.000000\n1.0000000\n1.571037\n-1.5646078\n2.493904\n0.2927802\n-0.4504325\n32\n0\n\n\nwt_z\n0.000000\n1.0000000\n1.212368\n-1.7417722\n2.255336\n0.4659161\n0.4165947\n32\n0\n\n\nqsec_z\n0.000000\n1.0000000\n1.131821\n-1.8740103\n2.826755\n0.4063466\n0.8649307\n32\n0\n\n\nvs_z\n0.000000\n1.0000000\n1.984063\n-0.8680278\n1.116036\n0.2645418\n-2.0632731\n32\n0\n\n\nam_z\n0.000000\n1.0000000\n2.004045\n-0.8141431\n1.189901\n0.4008089\n-1.9665503\n32\n0\n\n\ngear_z\n0.000000\n1.0000000\n1.355373\n-0.9318192\n1.778928\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb_z\n0.000000\n1.0000000\n1.238237\n-1.1221521\n3.211677\n1.1570911\n2.0200593\n32\n0\n\n\n\n\n\n\n\nm1 &lt;- \n  stan_glm(mpg ~ hp_z + am + hp_z:am, \n           seed = 42,\n           refresh = 0,\n           data = mtcars2)\n\ncoef(m1)\n\n(Intercept)        hp_z          am     hp_z:am \n17.95232456 -4.07311028  5.26504242  0.06037871 \n\n\n         \n\n\nSolution\n\nIntercept: Ein Auto mit 0 PS und Automatikantrieb (am=0, s. Hilfe zum Datensatz: help(mtcars)) kann laut Modell mit einer Gallone Sprit ca. 17.95 Meilen fahren.\nhp: Pro zus√§tzlichem PS kann ein Auto mit Automatikantrieb pro Gallone Sprit ca. -4.07 Meilen weniger weit fahren.\nam: Ein Auto mit 0 PS und Schaltgetriebe (am=1) kommt pro Gallone Sprit ca. 5.27 Meilen weiter als ein Auto mit Automatikantrieb.\nhp:am: Der Interaktionseffekt ist praktisch Null (17.95): Der Zusammenhang von PS-Zahl und Spritverbrauch unterscheidet sich nicht (wesentlich) zwischen Autos mit bzw. ohne Automatikantrieb.\n\n\nCategories:\n\nbayes\nregression\npaper"
  },
  {
    "objectID": "posts/bsp-binomial/bsp-binomial.html",
    "href": "posts/bsp-binomial/bsp-binomial.html",
    "title": "Bsp-Binomial",
    "section": "",
    "text": "Aufgabe\nDie Binomialverteilung wird in Lehrb√ºchern h√§ufig mit M√ºnzw√ºrfen motiviert. Im Buch Statistical Rethinking muss etwa ein Globus herhalten (also ein Zufallsexperiment mit den Ergebnissen Wasser und Land unter dem Zeigefinger). Dahinter steht als theoretisches Konzept die Binomialverteilung.\nDie Beispiele sind ja gut und sch√∂n. Aber was hat das mit der Praxis zu tun? Gute Frage. Nennen Sie Beispiele aus Berufsfeldern der Sozialwissenschaften, f√ºr die die Binomialverteilung relevant ist.\nSie m√ºssen nichts rechnen, nur Beispiele nennen.\n         \n\n\nL√∂sung\nZur Erinnerung: Die Inferenzstatistik macht Aussagen bzgl. einer Population, nicht einer Stichprobe. Solche Aussagen sind ungewiss, also mit einer Unsicherheit behaftet, da wir nicht die ganze Population kennen. Aber die Daten der Stichprobe werden als Grundlage der Sch√§tzung herangezogen.\n\nAuswahl geeigneter Kandidatis in einem Assessment-Verfahren. Man hat \\(n=40\\) Bewerbis, und die Wahrscheinlichkeit geeigneter Kandidatis liege bei \\(p=10%\\). Welche Spannweite an geeigneten Bewerbis kann man erwarten?\nSocial Influencing. Sie posten 100 Videoclips; davon werden 9 viral. Welche Spannweite plausibler Werte f√ºr eine Erfolgsquote kann man zugrunde legen?\nApp-Wartung. Sie pr√ºfen eine Anzahl (\\(n=42\\)) alter Apps, aus einer fr√ºheren Kampagne. Sie finden, dass \\(k=19\\) noch funktionieren. Welche Quote an ‚Äútechnisch veraltet‚Äù muss man in der Population erwarten, und in welchem Bereich k√∂nnte sich diese Quote bewegen?\nSchulungsprogramm. Sie entwickeln ein Schulungsprogramm, das im gro√üen Stil in einer Firma eingesetzt werden soll; mehrere Tausend Personen sollen das Programm durchlaufen. In einer Pilotstudie mit \\(n=90\\) Personen erreichen \\(k=42\\) nicht das Lernziel. Welche Parameterwerte f√ºr \\(p\\) (Lernziel erreicht) sind plausibel?\n\n\nCategories:\n\nprobability\nbinomial\nexample\nstring"
  },
  {
    "objectID": "posts/gini-plot/gini-plot.html",
    "href": "posts/gini-plot/gini-plot.html",
    "title": "gini-plot",
    "section": "",
    "text": "Aufgabe\nVisualisieren Sie die Gini-Funktion!\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\n\ngranularity &lt;- .1\nx1 = seq(from = 0, to = 1, by = granularity)\nx2 = seq(from = 1, to = 0, by = -granularity)\n#x2 &lt;- 1 - x1\n  \nd &lt;- expand_grid(x1, x2)\n\nGini-Loss:\n\ngini_loss &lt;- function(x1, x2) {1 - (x1^2 + x2^2)}\n\nFunktion berechnen:\n\nd2 &lt;-\n  d %&gt;% \n  rowwise() %&gt;% \n  mutate(y = gini_loss(x1, x2))\n\n\n# d2 &lt;-\n#   outer(x1, x3, FUN = gini_loss) %&gt;% \n#   as_tibble() %&gt;% \n#   pivot_longer(cols = everything())\n\n\n# d &lt;-\n#   d %&gt;% \n#   mutate(\n#     x3 = 1 - x1,\n#     y = 1 - (x1^2 + x3^2))\n\n\nd2 %&gt;% \n  ggplot(aes(x1, x2, fill = y)) +\n  geom_tile() +\n  scale_x_continuous(limits = c(-2, 2)) +\n  scale_y_continuous(limits = c(-2, 2))\n\n\n\n\n\n\n\n\nSo sieht der Funktionsgraph in Geogebra aus.\n\nCategories:\n\n2023\nvis\nstatlearning\ntree\nstring"
  },
  {
    "objectID": "posts/count-emoji-emo/count-emoji-emo.html",
    "href": "posts/count-emoji-emo/count-emoji-emo.html",
    "title": "count-emoji-emo",
    "section": "",
    "text": "Aufgabe\nGegeben eines (mehrelementigen) Strings, my_string, und eines Lexicons, my_lexicon, z√§hlen Sie, wie h√§ufig sich ein Emoji in einem Element des Strings wiederfindet.\n\nmy_string &lt;-\n  c(\"Heute ist ein sch√∂ner Tag üòÑüòÑ\", \"Was geht in dieser Woche?\", \"Super üôÇ\")\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie die Funktion emo::ji.\n\n         \n\n\nL√∂sung\n\nlibrary(emo)\nlibrary(purrr)\n\n\nmap_int(my_string, ji_count)\n\n[1] 2 0 1\n\n\n\nCategories:\n\ntextmining\nnlp\nemoji\nstring"
  },
  {
    "objectID": "posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html",
    "href": "posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html",
    "title": "diamonds-nullhyp-mws",
    "section": "",
    "text": "Betrachten Sie folgende Ausgabe eines Bayesmodells, das mit rstanarm ‚Äúgefittet‚Äù wurde:\nParameter    |  Median |              95% CI |     pd |  Rhat |     ESS |                       Prior\n-----------------------------------------------------------------------------------------------------\n(Intercept)  | 4354.87 | [ 4169.07, 4547.04] |   100% | 1.001 | 1217.00 | Normal (3932.80 +- 9973.60)\ncutGood      | -426.02 | [ -648.68, -208.69] |   100% | 1.001 | 1425.00 |   Normal (0.00 +- 34685.38)\ncutIdeal     | -896.54 | [-1099.03, -704.16] |   100% | 1.001 | 1239.00 |   Normal (0.00 +- 20362.28)\ncutPremium   |  231.20 | [   26.53,  435.01] | 98.75% | 1.001 | 1292.00 |   Normal (0.00 +- 22862.49)\ncutVery Good | -371.85 | [ -575.61, -174.49] |   100% | 1.001 | 1237.00 |   Normal (0.00 +- 23922.15)\nWelche Aussage passt (am besten)?\nHinweise:\n\nMit ‚ÄúNullhypothese‚Äù ist im Folgenden dieser Ausdruck gemeint: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\).\nGehen Sie davon aus, dass die Posteriori-Verteilungen der Regressionskoeffizienten normalverteilt sind.\nBeziehen Sie sich bei den Antworten auf die oben dargestellten Daten.\n\n\n\n\nDie Nullhypothese ist (sicher) falsch.\nDie Nullhypothese ist (sicher) wahr.\nMan kann schlie√üen, dass beim Parameter von cutGood der Wert Null au√üerhalb des 95%-PI der Posteriori-Verteilung liegt.\nMan kann schlie√üen, dass alle Parameter positiv sind."
  },
  {
    "objectID": "posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html#answerlist",
    "href": "posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html#answerlist",
    "title": "diamonds-nullhyp-mws",
    "section": "",
    "text": "Die Nullhypothese ist (sicher) falsch.\nDie Nullhypothese ist (sicher) wahr.\nMan kann schlie√üen, dass beim Parameter von cutGood der Wert Null au√üerhalb des 95%-PI der Posteriori-Verteilung liegt.\nMan kann schlie√üen, dass alle Parameter positiv sind."
  },
  {
    "objectID": "posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html#answerlist-1",
    "href": "posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html#answerlist-1",
    "title": "diamonds-nullhyp-mws",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Streng genommen k√∂nnen wir nicht ganz sicher sein, ob eine Hypothese auf Basis eines Modells richtig oder falsch ist.\nFalsch. Streng genommen k√∂nnen wir nicht ganz sicher sein, ob eine Hypothese auf Basis eines Modells richtig oder falsch ist.\nRichtig. Mittelwert plus/minus 2 SD-Einheiten gibt bei einer Normalverteilung das 95%-ETI an.\nFalsch. cutGood hat z.B. negative Werte in seinem 95%-ETI der Postverteilung.\n\n\nCategories:\n\nbayes\nregression\nnull"
  },
  {
    "objectID": "posts/wrangle4/wrangle4.html",
    "href": "posts/wrangle4/wrangle4.html",
    "title": "wrangle4",
    "section": "",
    "text": "Welche Variante der folgenden Syntax-Beispiele ist richtig (formal korrekt)?\n\n\n\nfilter(flights, month = 1, day = 1)\nfilter(flights, day == 1)\nfilter(month == 1, day == 1)\nfilter(month = 1, day == 1)\nfilter(flights, month == 1, day == 1)"
  },
  {
    "objectID": "posts/wrangle4/wrangle4.html#answerlist",
    "href": "posts/wrangle4/wrangle4.html#answerlist",
    "title": "wrangle4",
    "section": "",
    "text": "filter(flights, month = 1, day = 1)\nfilter(flights, day == 1)\nfilter(month == 1, day == 1)\nfilter(month = 1, day == 1)\nfilter(flights, month == 1, day == 1)"
  },
  {
    "objectID": "posts/wrangle4/wrangle4.html#answerlist-1",
    "href": "posts/wrangle4/wrangle4.html#answerlist-1",
    "title": "wrangle4",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\neda\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/mtcars-post2a/index.html",
    "href": "posts/mtcars-post2a/index.html",
    "title": "mtcars-post2a",
    "section": "",
    "text": "Im Datensatz mtcars: Wie gro√ü ist der Effekt der UV vs auf die AV mpg? Geben Sie die Breite des 95% PI an (im Bezug zur gesuchten Gr√∂√üe).\nHinweise\nDazu wird folgendes Modell berechnet.\nSetup:\n\ndata(mtcars)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats) \n\nModell berechnen:\n\nm1 &lt;- stan_glm(mpg ~ vs, data = mtcars,\n               seed = 42,\n               refresh = 0)\n\n95%-PI:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n16.63\n(14.47, 18.88)\n100%\n1.000\n3894.00\nNormal (20.09 +- 15.07)\n\n\nvs\n7.91\n(4.60, 11.26)\n100%\n1.000\n3797.00\nNormal (0.00 +- 29.89)\n\n\n\n\n\nVisualisierung der Posterior-Verteilung (95% CI):\n\n\n\n\n\n\n\n\n\nAufgabe W√§hlen Sie die am besten passende Option.\n\n\n\n0.7\n2.7\n4.7\n6.7\n8.7"
  },
  {
    "objectID": "posts/mtcars-post2a/index.html#answerlist",
    "href": "posts/mtcars-post2a/index.html#answerlist",
    "title": "mtcars-post2a",
    "section": "",
    "text": "0.7\n2.7\n4.7\n6.7\n8.7"
  },
  {
    "objectID": "posts/mtcars-post2a/index.html#answerlist-1",
    "href": "posts/mtcars-post2a/index.html#answerlist-1",
    "title": "mtcars-post2a",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\nbayes\nregression\npost\nexam-22"
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html",
    "href": "posts/lm-mario1/lm-mario1.html",
    "title": "lm-mario1",
    "section": "",
    "text": "Sagen Sie den Verkaufspreis vorher f√ºr ein Spiel mit 2 Lenkr√§dern!\nHinweise:\n\nEntfernen Sie Spiele mit einem Verkaufspreis von √ºber 100 Euro aus dem Datensatz."
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html#setup",
    "href": "posts/lm-mario1/lm-mario1.html#setup",
    "title": "lm-mario1",
    "section": "Setup",
    "text": "Setup\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nlibrary(tidyverse)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html#bild-der-daten",
    "href": "posts/lm-mario1/lm-mario1.html#bild-der-daten",
    "title": "lm-mario1",
    "section": "Bild der Daten",
    "text": "Bild der Daten\n\nlibrary(ggpubr)  # einmalig vorab installieren, nicht vergessen\n\nggscatter(mariokart, x = \"wheels\", y = \"total_pr\")  # aus ggpubr\n\n\n\n\n\n\n\n\nOder mit DataExplorer visualisieren:\n\nlibrary(DataExplorer)\n\nplot_scatterplot(mariokart, by = \"total_pr\")  # \"by\" ist Y-Achse"
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html#extremwerte-entfernen",
    "href": "posts/lm-mario1/lm-mario1.html#extremwerte-entfernen",
    "title": "lm-mario1",
    "section": "Extremwerte entfernen",
    "text": "Extremwerte entfernen\n\nmariokart2 &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)  # alle Spiele teuerer als 100‚Ç¨ entfernen\n\nggscatter(mariokart2, x = \"wheels\", y = \"total_pr\")"
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html#regressionsgerade-eintragen-in-das-diagramm",
    "href": "posts/lm-mario1/lm-mario1.html#regressionsgerade-eintragen-in-das-diagramm",
    "title": "lm-mario1",
    "section": "Regressionsgerade eintragen in das Diagramm",
    "text": "Regressionsgerade eintragen in das Diagramm\n\nggscatter(mariokart2, \n          x = \"wheels\", \n          y = \"total_pr\",\n          add = \"reg.line\")  # Dieser Schalter malt die Regr.gerade in das Diagramm"
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html#regressionsgerade-berechnen",
    "href": "posts/lm-mario1/lm-mario1.html#regressionsgerade-berechnen",
    "title": "lm-mario1",
    "section": "Regressionsgerade berechnen",
    "text": "Regressionsgerade berechnen\n\nlm_mariokart &lt;- lm(total_pr ~ wheels, data = mariokart2)\nlm_mariokart\n\n\nCall:\nlm(formula = total_pr ~ wheels, data = mariokart2)\n\nCoefficients:\n(Intercept)       wheels  \n     37.502        8.643  \n\n\n‚Äúlm‚Äù wie llineares Modell, also eine Gerade."
  },
  {
    "objectID": "posts/lm-mario1/lm-mario1.html#vorhersagen",
    "href": "posts/lm-mario1/lm-mario1.html#vorhersagen",
    "title": "lm-mario1",
    "section": "Vorhersagen",
    "text": "Vorhersagen\nVorhersagen funktionieren mit dem Befehl predict.\n\nneues_spiel &lt;-\n  data.frame(\n    wheels = 2\n  )\n\nneues_spiel\n\n\n\n\n\nwheels\n\n\n\n\n2\n\n\n\n\n\n\n\npredict(lm_mariokart, neues_spiel)  # predicte mir den Verkaufspreis\n\n       1 \n54.78743 \n\n\n\nCategories:\n\nR\nlm\npredict\nnum"
  },
  {
    "objectID": "posts/penguins-relationen2/index.html",
    "href": "posts/penguins-relationen2/index.html",
    "title": "penguins-relationen2",
    "section": "",
    "text": "In dieser Aufgabe betrachten wir die Relationen einiger Ereignisse im Zusammenhang mit dem Datensatz penguins.\nSie k√∂nnen den Datensatz z.B. so importieren:\n\nlibrary(palmerpenguins) # Lade das Paket zuerst\ndata(penguins) # Jetzt wird der Datensatz geladen\n\nSei das Ereignis A das Tier ist von der Spezies ‚ÄúAdelie‚Äù. Sei das Ereignis B das Tier hat eine Schnabell√§nge (bill_length_mm) gr√∂√üer als der Median aller Pinguine (des Datensatzes, nur g√ºltige Messungen). Sei AB ein Pinguin, der sowohl A als auch B erf√ºllt.\nBerechnen Sie folgende Wahrscheinlichkeiten, wobei wir den jeweiligen Anteil der Tiere als Wahrscheinlichkeit interpretieren.\n\n\n\n\n\\(Pr(A \\cup B)\\)\n\\(Pr(A \\cap B)\\)\n\\(Pr(\\neg B)\\)\n\\(Pr(\\neg A)\\)\n\\(Pr(A \\setminus AB)\\)\n\\(Pr(B \\setminus AB)\\)\n\nHinweis: Die Berechnungen sollen nur Pinguine ber√ºcksichtigen, f√ºr die die Schnabell√§nge (bill_length_mm) bekannt ist, um konsistente Wahrscheinlichkeiten zu gew√§hrleisten."
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#hintergrund",
    "href": "posts/penguins-relationen2/index.html#hintergrund",
    "title": "penguins-relationen2",
    "section": "",
    "text": "In dieser Aufgabe betrachten wir die Relationen einiger Ereignisse im Zusammenhang mit dem Datensatz penguins.\nSie k√∂nnen den Datensatz z.B. so importieren:\n\nlibrary(palmerpenguins) # Lade das Paket zuerst\ndata(penguins) # Jetzt wird der Datensatz geladen\n\nSei das Ereignis A das Tier ist von der Spezies ‚ÄúAdelie‚Äù. Sei das Ereignis B das Tier hat eine Schnabell√§nge (bill_length_mm) gr√∂√üer als der Median aller Pinguine (des Datensatzes, nur g√ºltige Messungen). Sei AB ein Pinguin, der sowohl A als auch B erf√ºllt.\nBerechnen Sie folgende Wahrscheinlichkeiten, wobei wir den jeweiligen Anteil der Tiere als Wahrscheinlichkeit interpretieren."
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#teilaufgaben",
    "href": "posts/penguins-relationen2/index.html#teilaufgaben",
    "title": "penguins-relationen2",
    "section": "",
    "text": "\\(Pr(A \\cup B)\\)\n\\(Pr(A \\cap B)\\)\n\\(Pr(\\neg B)\\)\n\\(Pr(\\neg A)\\)\n\\(Pr(A \\setminus AB)\\)\n\\(Pr(B \\setminus AB)\\)\n\nHinweis: Die Berechnungen sollen nur Pinguine ber√ºcksichtigen, f√ºr die die Schnabell√§nge (bill_length_mm) bekannt ist, um konsistente Wahrscheinlichkeiten zu gew√§hrleisten."
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#a.-pra-u-b",
    "href": "posts/penguins-relationen2/index.html#a.-pra-u-b",
    "title": "penguins-relationen2",
    "section": "2.1 A. Pr(A U B)",
    "text": "2.1 A. Pr(A U B)\nA ODER B: Spezies ist ‚ÄúAdelie‚Äù ODER Schnabell√§nge ist gr√∂√üer als der Median.\n\nanzahl_a_oder_b &lt;- penguins_clean |&gt;\n    filter(species == \"Adelie\" | bill_length_mm &gt; bill_length_md) |&gt;\n    nrow()\n\nPr_a_oder_b &lt;- anzahl_a_oder_b / N_clean\nPr_a_oder_b\n\n[1] 0.9327485"
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#b.-pra-n-b",
    "href": "posts/penguins-relationen2/index.html#b.-pra-n-b",
    "title": "penguins-relationen2",
    "section": "2.2 B. $Pr(A n B)",
    "text": "2.2 B. $Pr(A n B)\nA UND B: Spezies ist ‚ÄúAdelie‚Äù UND Schnabell√§nge ist gr√∂√üer als der Median.\n\nanzahl_a_und_b &lt;- penguins_clean |&gt;\n    filter(species == \"Adelie\" & bill_length_mm &gt; bill_length_md) |&gt;\n    nrow()\n\nPr_a_und_b &lt;- anzahl_a_und_b / N_clean\nPr_a_und_b\n\n[1] 0.00877193"
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#c.-prneg-b",
    "href": "posts/penguins-relationen2/index.html#c.-prneg-b",
    "title": "penguins-relationen2",
    "section": "2.3 C. \\(Pr(\\neg B)\\)",
    "text": "2.3 C. \\(Pr(\\neg B)\\)\nNICHT B: Schnabell√§nge ist kleiner oder gleich dem Median.\n\nanzahl_nicht_b &lt;- penguins_clean |&gt;\n    filter(bill_length_mm &lt;= bill_length_md) |&gt;\n    nrow()\n\nPr_nicht_b &lt;- anzahl_nicht_b / N_clean\nPr_nicht_b\n\n[1] 0.5"
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#d.-prneg-a",
    "href": "posts/penguins-relationen2/index.html#d.-prneg-a",
    "title": "penguins-relationen2",
    "section": "2.4 D. \\(Pr(\\neg A)\\)",
    "text": "2.4 D. \\(Pr(\\neg A)\\)\nNICHT A: Das Tier ist nicht von der Spezies ‚ÄúAdelie‚Äù.\n\nanzahl_nicht_a &lt;- penguins_clean |&gt;\n    filter(species != \"Adelie\") |&gt;\n    nrow()\n\nPr_nicht_a &lt;- anzahl_nicht_a / N_clean\nPr_nicht_a\n\n[1] 0.5584795"
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#e.-pra-setminus-ab",
    "href": "posts/penguins-relationen2/index.html#e.-pra-setminus-ab",
    "title": "penguins-relationen2",
    "section": "2.5 E. \\(Pr(A \\setminus AB)\\)",
    "text": "2.5 E. \\(Pr(A \\setminus AB)\\)\nA ohne AB: Die Menge der ‚ÄúAdelie‚Äù Pinguine, die NICHT auch B erf√ºllen. Dies entspricht \\(A \\cap \\neg B\\).\n\nanzahl_a_minus_ab &lt;- penguins_clean |&gt;\n    filter(species == \"Adelie\" & bill_length_mm &lt;= bill_length_md) |&gt;\n    nrow()\n\nPr_a_minus_ab &lt;- anzahl_a_minus_ab / N_clean\nPr_a_minus_ab\n\n[1] 0.4327485"
  },
  {
    "objectID": "posts/penguins-relationen2/index.html#f.-prb-setminus-ab",
    "href": "posts/penguins-relationen2/index.html#f.-prb-setminus-ab",
    "title": "penguins-relationen2",
    "section": "2.6 F. \\(Pr(B \\setminus AB)\\)",
    "text": "2.6 F. \\(Pr(B \\setminus AB)\\)\nB ohne AB: Die Menge der Pinguine mit langer Schnabell√§nge (B), die NICHT auch A erf√ºllen. Dies entspricht \\(B \\cap \\neg A\\).\n\nanzahl_b_minus_ab &lt;- penguins_clean |&gt;\n    filter(bill_length_mm &gt; bill_length_md & species != \"Adelie\") |&gt;\n    nrow()\n\nPr_b_minus_ab &lt;- anzahl_b_minus_ab / N_clean\nPr_b_minus_ab\n\n[1] 0.4912281"
  },
  {
    "objectID": "posts/simu-unif2/index.html",
    "href": "posts/simu-unif2/index.html",
    "title": "simu-unif2",
    "section": "",
    "text": "1 Aufgabe\nSie warten an einer Bushaltestelle auf einen Bus. Der Bus f√§hrt alle 10 Minuten ab. Allerdings wissen Sie nicht, wann der Bus das letzte Mal abgefahren ist.\nAufgabe: Wie hoch ist die Wahrscheinlichkeit, dass Sie l√§nger als 5 Minuten warten m√ºssen?\n  \n  \n  \n  \n\n\n2 L√∂sung\n50% der Zeit m√ºssen Sie l√§nger als 5 Minuten warten."
  },
  {
    "objectID": "posts/durch3-durch5/durch3-durch5.html",
    "href": "posts/durch3-durch5/durch3-durch5.html",
    "title": "durch3-durch5",
    "section": "",
    "text": "Aufgabe\nGegeben sei ein Vektor x:\n\nx &lt;- 1:50\n\nSchreiben Sie R-Code, der ‚Äúdurch3‚Äù ausgibt, wenn x durch 3 teilbar ist und (auch) ‚Äúdurch5‚Äù ausgibt, wenn x durch5 teilbar ist.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\n\nd &lt;-\n  tibble(\n    x = 1:50,\n    txt = \"\"\n  ) %&gt;% \n  mutate(txt = case_when(\n    (x %% 3) == 0 ~ str_c(txt, \"_durch_3\"),\n    TRUE ~ txt)\n  ) %&gt;% \n  mutate(txt = case_when(\n    (x %% 5) == 0 ~ str_c(txt, \"_durch_5\"),\n    TRUE ~ txt\n  ))\n\nSo sieht die Tabelle aus:\n\nd\n\n\n\n\n\nx\ntxt\n\n\n\n\n1\n\n\n\n2\n\n\n\n3\n_durch_3\n\n\n4\n\n\n\n5\n_durch_5\n\n\n6\n_durch_3\n\n\n7\n\n\n\n8\n\n\n\n9\n_durch_3\n\n\n10\n_durch_5\n\n\n11\n\n\n\n12\n_durch_3\n\n\n13\n\n\n\n14\n\n\n\n15\n_durch_3_durch_5\n\n\n16\n\n\n\n17\n\n\n\n18\n_durch_3\n\n\n19\n\n\n\n20\n_durch_5\n\n\n21\n_durch_3\n\n\n22\n\n\n\n23\n\n\n\n24\n_durch_3\n\n\n25\n_durch_5\n\n\n26\n\n\n\n27\n_durch_3\n\n\n28\n\n\n\n29\n\n\n\n30\n_durch_3_durch_5\n\n\n31\n\n\n\n32\n\n\n\n33\n_durch_3\n\n\n34\n\n\n\n35\n_durch_5\n\n\n36\n_durch_3\n\n\n37\n\n\n\n38\n\n\n\n39\n_durch_3\n\n\n40\n_durch_5\n\n\n41\n\n\n\n42\n_durch_3\n\n\n43\n\n\n\n44\n\n\n\n45\n_durch_3_durch_5\n\n\n46\n\n\n\n47\n\n\n\n48\n_durch_3\n\n\n49\n\n\n\n50\n_durch_5\n\n\n\n\n\n\nSo kann man sich dann den Text ausgeben lassen:\n\nd$txt\n\n [1] \"\"                 \"\"                 \"_durch_3\"         \"\"                \n [5] \"_durch_5\"         \"_durch_3\"         \"\"                 \"\"                \n [9] \"_durch_3\"         \"_durch_5\"         \"\"                 \"_durch_3\"        \n[13] \"\"                 \"\"                 \"_durch_3_durch_5\" \"\"                \n[17] \"\"                 \"_durch_3\"         \"\"                 \"_durch_5\"        \n[21] \"_durch_3\"         \"\"                 \"\"                 \"_durch_3\"        \n[25] \"_durch_5\"         \"\"                 \"_durch_3\"         \"\"                \n[29] \"\"                 \"_durch_3_durch_5\" \"\"                 \"\"                \n[33] \"_durch_3\"         \"\"                 \"_durch_5\"         \"_durch_3\"        \n[37] \"\"                 \"\"                 \"_durch_3\"         \"_durch_5\"        \n[41] \"\"                 \"_durch_3\"         \"\"                 \"\"                \n[45] \"_durch_3_durch_5\" \"\"                 \"\"                 \"_durch_3\"        \n[49] \"\"                 \"_durch_5\"        \n\n\nOder so:\n\nd$txt %&gt;% discard(\\(x) x == \"\")\n\n [1] \"_durch_3\"         \"_durch_5\"         \"_durch_3\"         \"_durch_3\"        \n [5] \"_durch_5\"         \"_durch_3\"         \"_durch_3_durch_5\" \"_durch_3\"        \n [9] \"_durch_5\"         \"_durch_3\"         \"_durch_3\"         \"_durch_5\"        \n[13] \"_durch_3\"         \"_durch_3_durch_5\" \"_durch_3\"         \"_durch_5\"        \n[17] \"_durch_3\"         \"_durch_3\"         \"_durch_5\"         \"_durch_3\"        \n[21] \"_durch_3_durch_5\" \"_durch_3\"         \"_durch_5\"        \n\n\n\nCategories:\n\nr\nchallenge\nstring"
  },
  {
    "objectID": "posts/boxplot_with_points/index.html",
    "href": "posts/boxplot_with_points/index.html",
    "title": "boxplot_with_points",
    "section": "",
    "text": "Visualisieren Sie die das K√∂rpergewicht von Pinguinen (palmerpenguins) in Abh√§ngigkeit vom Geschlecht der Tiere. Entfernen Sie vorab etwaige fehlende Werte.\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/boxplot_with_points/index.html#daten-improtieren",
    "href": "posts/boxplot_with_points/index.html#daten-improtieren",
    "title": "boxplot_with_points",
    "section": "2.1 Daten improtieren",
    "text": "2.1 Daten improtieren\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")"
  },
  {
    "objectID": "posts/boxplot_with_points/index.html#fehlende-werte-entfernen",
    "href": "posts/boxplot_with_points/index.html#fehlende-werte-entfernen",
    "title": "boxplot_with_points",
    "section": "2.2 Fehlende Werte entfernen",
    "text": "2.2 Fehlende Werte entfernen\n\npenguins_filtered &lt;-\n  penguins |&gt; \n  filter(sex == \"male\" | sex == \"female\")"
  },
  {
    "objectID": "posts/boxplot_with_points/index.html#visualisieren",
    "href": "posts/boxplot_with_points/index.html#visualisieren",
    "title": "boxplot_with_points",
    "section": "2.3 Visualisieren",
    "text": "2.3 Visualisieren\n\nggboxplot(penguins_filtered, \n          x = \"sex\",\n          y = \"body_mass_g\") + geom_jitter(width = 0.1,\n                                           alpha = .6)"
  },
  {
    "objectID": "posts/boxplot_with_points/index.html#bonus-mittelwert-hinzuf√ºgen",
    "href": "posts/boxplot_with_points/index.html#bonus-mittelwert-hinzuf√ºgen",
    "title": "boxplot_with_points",
    "section": "2.4 Bonus: Mittelwert hinzuf√ºgen:",
    "text": "2.4 Bonus: Mittelwert hinzuf√ºgen:\n\nggboxplot(penguins_filtered, \n          x = \"sex\",\n          y = \"body_mass_g\") + \n  geom_jitter(width=0.1, alpha = .6) +\n  stat_summary(geom = \"point\", fun = mean, color = \"red\", size = 3)"
  },
  {
    "objectID": "posts/wskt-quiz01/wskt-quiz01.html",
    "href": "posts/wskt-quiz01/wskt-quiz01.html",
    "title": "wskt-quiz01",
    "section": "",
    "text": "Sind die Ereignisse \\(A\\) und \\(B\\) unabh√§ngig, so gilt \\(Pr(A|B) = P(A)\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz01/wskt-quiz01.html#answerlist",
    "href": "posts/wskt-quiz01/wskt-quiz01.html#answerlist",
    "title": "wskt-quiz01",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz01/wskt-quiz01.html#answerlist-1",
    "href": "posts/wskt-quiz01/wskt-quiz01.html#answerlist-1",
    "title": "wskt-quiz01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Nein, die Aussage ist nicht falsch, sie ist wahr.\nWahr. Ja, die Aussage ist wahr.\n\n\nCategories:\n\nquiz\nprobability\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/mtcars-easystats/index.html",
    "href": "posts/mtcars-easystats/index.html",
    "title": "mtcars-easystats",
    "section": "",
    "text": "1 Exercise\nProvide an overview of descriptive statistics on the mtcars dataset using the R package easystats.\n         \n\n\n2 Solution\nStarting R packages:\n\nlibrary(easystats) \nlibrary(tidyverse)  # comfort\n\nProviding the dataset mtcars:\n\ndata(mtcars)\n\nHere are some descriptive statistics for the metric variables of the dataset:\n\ndescribe_distribution(mtcars) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.09\n6.03\n7.53\n(10.40, 33.90)\n0.67\n-0.02\n32\n0\n\n\ncyl\n6.19\n1.79\n4.00\n(4.00, 8.00)\n-0.19\n-1.76\n32\n0\n\n\ndisp\n230.72\n123.94\n221.53\n(71.10, 472.00)\n0.42\n-1.07\n32\n0\n\n\nhp\n146.69\n68.56\n84.50\n(52.00, 335.00)\n0.80\n0.28\n32\n0\n\n\ndrat\n3.60\n0.53\n0.84\n(2.76, 4.93)\n0.29\n-0.45\n32\n0\n\n\nwt\n3.22\n0.98\n1.19\n(1.51, 5.42)\n0.47\n0.42\n32\n0\n\n\nqsec\n17.85\n1.79\n2.02\n(14.50, 22.90)\n0.41\n0.86\n32\n0\n\n\nvs\n0.44\n0.50\n1.00\n(0.00, 1.00)\n0.26\n-2.06\n32\n0\n\n\nam\n0.41\n0.50\n1.00\n(0.00, 1.00)\n0.40\n-1.97\n32\n0\n\n\ngear\n3.69\n0.74\n1.00\n(3.00, 5.00)\n0.58\n-0.90\n32\n0\n\n\ncarb\n2.81\n1.62\n2.00\n(1.00, 8.00)\n1.16\n2.02\n32\n0\n\n\n\n\n\nWhat about statistics for the non-metric (nominal) variables (columns)? Let‚Äôs restrict the analysis to the columns vs, am, and gear.\n\ndata_tabulate(mtcars, select = c(\"vs\", \"am\", \"gear\"))\n\n\n\n\nFrequency Table\n\n\nVariable\nValue\nN\nRaw %\nValid %\nCumulative %\n\n\n\n\nvs\n0\n18\n56.25\n56.25\n56.25\n\n\n\n1\n14\n43.75\n43.75\n100.00\n\n\n\n(NA)\n0\n0.00\n(NA)\n(NA)\n\n\n\n\n\n\n\n\n\n\nam\n0\n19\n59.38\n59.38\n59.38\n\n\n\n1\n13\n40.62\n40.62\n100.00\n\n\n\n(NA)\n0\n0.00\n(NA)\n(NA)\n\n\n\n\n\n\n\n\n\n\ngear\n3\n15\n46.88\n46.88\n46.88\n\n\n\n4\n12\n37.50\n37.50\n84.38\n\n\n\n5\n5\n15.62\n15.62\n100.00\n\n\n\n(NA)\n0\n0.00\n(NA)\n(NA)"
  },
  {
    "objectID": "posts/wskt-quiz06/wskt-quiz06.html",
    "href": "posts/wskt-quiz06/wskt-quiz06.html",
    "title": "wskt-quiz06",
    "section": "",
    "text": "Jemand geht zum Krebstest. Der Test habe eine Sicherheit von 95%. Die Grundrate des Krebs liege bei 0.001. Leider zeigt der Test einen positiven Befund, also Krebs.\nGilt: \\(Pr(K|T) = .95\\)?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz06/wskt-quiz06.html#answerlist",
    "href": "posts/wskt-quiz06/wskt-quiz06.html#answerlist",
    "title": "wskt-quiz06",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz06/wskt-quiz06.html#answerlist-1",
    "href": "posts/wskt-quiz06/wskt-quiz06.html#answerlist-1",
    "title": "wskt-quiz06",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html",
    "href": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html",
    "title": "Verteilungen-Quiz-13",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nBei rechtsschiefen Verteilungen gilt \\(\\bar{x} \\gt Md\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist",
    "href": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist",
    "title": "Verteilungen-Quiz-13",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist-1",
    "title": "Verteilungen-Quiz-13",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html",
    "href": "posts/wfsets1/wfsets1.html",
    "title": "wfsets1",
    "section": "",
    "text": "Berechnen Sie die Vorhersageg√ºte (RMSE) f√ºr folgende Lernalgorithmen mittesl tidymodels:\n\nlineares Modell\n\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nNutzen Sie minimale Vorverarbeitung im Rahmen zweier Rezepte.\nNutzen Sie ein Workflowset."
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#setup",
    "href": "posts/wfsets1/wfsets1.html#setup",
    "title": "wfsets1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung\ndata(penguins, package = \"palmerpenguins\")"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#daten",
    "href": "posts/wfsets1/wfsets1.html#daten",
    "title": "wfsets1",
    "section": "Daten",
    "text": "Daten\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()\n\n\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#modelle",
    "href": "posts/wfsets1/wfsets1.html#modelle",
    "title": "wfsets1",
    "section": "Modelle",
    "text": "Modelle\nLineares Modell:\n\nmod_lin &lt;- linear_reg()\n\nmod_knn &lt;- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#rezepte",
    "href": "posts/wfsets1/wfsets1.html#rezepte",
    "title": "wfsets1",
    "section": "Rezepte",
    "text": "Rezepte\n\nrec_basic &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n         step_normalize(all_predictors())\n\n\nrec_plain &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#resampling",
    "href": "posts/wfsets1/wfsets1.html#resampling",
    "title": "wfsets1",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpls &lt;- vfold_cv(d_train, v = 5)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#workflow-set",
    "href": "posts/wfsets1/wfsets1.html#workflow-set",
    "title": "wfsets1",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic,\n                   rec_plain = rec_plain),\n    models = list(mod_lm = mod_lin)\n  )"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#fitten",
    "href": "posts/wfsets1/wfsets1.html#fitten",
    "title": "wfsets1",
    "section": "Fitten",
    "text": "Fitten\n\ntic()\nwf_fit &lt;-\n  wf_set %&gt;% \n  workflow_map(resamples = rsmpls)\ntoc()\nwf_fit\n\nCheck:\n\nwf_fit %&gt;% pluck(\"result\")"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#bester-kandidat",
    "href": "posts/wfsets1/wfsets1.html#bester-kandidat",
    "title": "wfsets1",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(wf_fit)\n\n\n\n\n\n\n\n\n\nautoplot(wf_fit, select_best = TRUE)\n\n\n\n\n\n\n\n\n\ncollect_metrics(wf_fit)\n\n\nrank_results(wf_fit, rank_metric = \"rmse\") %&gt;% \n  filter(.metric == \"rmse\")"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#last-fit",
    "href": "posts/wfsets1/wfsets1.html#last-fit",
    "title": "wfsets1",
    "section": "Last Fit",
    "text": "Last Fit\n\nbest_wf &lt;-\n  wf_fit %&gt;% \n  extract_workflow(\"rec_simple_mod_lm\")\n\nFinalisieren m√ºssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\nfit_final &lt;-\n  best_wf %&gt;% \n  last_fit(d_split)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#modellg√ºte-im-test-set",
    "href": "posts/wfsets1/wfsets1.html#modellg√ºte-im-test-set",
    "title": "wfsets1",
    "section": "Modellg√ºte im Test-Set",
    "text": "Modellg√ºte im Test-Set\n\ncollect_metrics(fit_final)"
  },
  {
    "objectID": "posts/Regression6/Regression6.html",
    "href": "posts/Regression6/Regression6.html",
    "title": "Regression6",
    "section": "",
    "text": "Gegeben sei ein Datensatz mit folgenden Pr√§diktoren, wobei Studierende die Beobachtungseinheit darstellen:\n\nX_1: Quereinsteiger (0: nein, 1: ja)\nX_2: Letzte Mathenote (z-Wert)\nX_3: Motivation-Testwert (z-Wert)\nX_4: Interaktion von X1 und X2\n\nDie vorherzusagende Variable (Y; Kriterium) ist Gehalt nach Studienabschluss.\nFolgende Modellparameter einer Regression (Least Squares, mit lm()) seien gegeben:\n\nbeta_0: 70\nbeta_1: 10\nbeta_2: 9\nbeta_3: 15\nbeta_4: 11\n\nWelche der Aussagen ist korrekt?\n\n\n\nF√ºr einen bestimmten (festen) Wert von X_2= Letzte Mathenote (z-Wert) und X_3= Motivation-Testwert (z-Wert) gilt, dass das erwartete Gehalt im Mittel h√∂her ist bei X_1=1 im Vergleich zu X_1=0, laut dem Modell.\nF√ºr einen bestimmten (festen) Wert von X_2= Letzte Mathenote (z-Wert) und X_3= Motivation-Testwert (z-Wert) gilt, dass das erwartete Gehalt im Mittel h√∂her ist bei X_1=0 im Vergleich zu X_1=1, laut dem Modell.\nDer mittlere erwartete Gehaltsunterschied Y zweier Personen a und b, wobei bei Person a gilt X_1=0 und bei Person b gilt X_1=1, betr√§gt stets 70, laut dem Modell.\nDer mittlere erwartete Gehaltsunterschied Y zweier Personen a und b, wobei bei Person a gilt X_2=0 und bei Person b gilt X_2=1, betr√§gt stets 70, laut dem Modell.\nDer mittlere erwartete Gehaltsunterschied von Menschen ist eine Wirkung von genau drei Ursachen: Quereinsteiger (0: nein, 1: ja), Letzte Mathenote (z-Wert), Motivation-Testwert (z-Wert), laut dem Modell."
  },
  {
    "objectID": "posts/Regression6/Regression6.html#answerlist",
    "href": "posts/Regression6/Regression6.html#answerlist",
    "title": "Regression6",
    "section": "",
    "text": "F√ºr einen bestimmten (festen) Wert von X_2= Letzte Mathenote (z-Wert) und X_3= Motivation-Testwert (z-Wert) gilt, dass das erwartete Gehalt im Mittel h√∂her ist bei X_1=1 im Vergleich zu X_1=0, laut dem Modell.\nF√ºr einen bestimmten (festen) Wert von X_2= Letzte Mathenote (z-Wert) und X_3= Motivation-Testwert (z-Wert) gilt, dass das erwartete Gehalt im Mittel h√∂her ist bei X_1=0 im Vergleich zu X_1=1, laut dem Modell.\nDer mittlere erwartete Gehaltsunterschied Y zweier Personen a und b, wobei bei Person a gilt X_1=0 und bei Person b gilt X_1=1, betr√§gt stets 70, laut dem Modell.\nDer mittlere erwartete Gehaltsunterschied Y zweier Personen a und b, wobei bei Person a gilt X_2=0 und bei Person b gilt X_2=1, betr√§gt stets 70, laut dem Modell.\nDer mittlere erwartete Gehaltsunterschied von Menschen ist eine Wirkung von genau drei Ursachen: Quereinsteiger (0: nein, 1: ja), Letzte Mathenote (z-Wert), Motivation-Testwert (z-Wert), laut dem Modell."
  },
  {
    "objectID": "posts/Regression6/Regression6.html#answerlist-1",
    "href": "posts/Regression6/Regression6.html#answerlist-1",
    "title": "Regression6",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr. X_1 ist positiv. Daher hat Gruppe X_1=1 h√∂here erwartete Werte als \\(X_1=0\\).\nFalsch. Diese Option sagt das Gegenteil wie die fast gleich lautende (aber richtige) Antwortoption.\nFalsch. Der Unterschied in der AV ist von mehreren UV abh√§ngig. Bei Kenntnis des Wertes nur einer UV kann nicht sicher auf den erwarteten Wert der AV geschlossen werden.\nFalsch. Der Unterschied in der AV ist von mehreren UV abh√§ngig. Bei Kenntnis des Wertes nur einer UV kann nicht sicher auf den erwarteten Wert der AV geschlossen werden.\nFalsch. Ein Regressionsmodell ist nicht automatisch ein Kausalmodell.\n\n\nCategories:\n\ndyn\nregression\nexam-22\nschoice"
  },
  {
    "objectID": "posts/nasa04/nasa04.html",
    "href": "posts/nasa04/nasa04.html",
    "title": "nasa04",
    "section": "",
    "text": "Viele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nZum Animieren verwenden wir diese Pakete:\n\nlibrary(gganimate)\nlibrary(plotly)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read_csv(data_path, skip = 1)\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgaben\n\nVisualisieren Sie Temperatur pro Jahr und Dekade.\nBONUSAUFGABE: Animieren Sie Ihre Diagramme mittels gganimate.\n\nHinweise:\n\nSie m√ºssen zuerst die Dekade als neue Spalte berechnen."
  },
  {
    "objectID": "posts/nasa04/nasa04.html#daten-aufbereiten",
    "href": "posts/nasa04/nasa04.html#daten-aufbereiten",
    "title": "nasa04",
    "section": "Daten aufbereiten",
    "text": "Daten aufbereiten\nDekade berechnen:\n\nd &lt;-\n  d %&gt;% \n  mutate(decade = round(Year/10))\n\nDie Temperaturdaten der Monate April bis Dezember sind als Textdaten (character) formatiert. Aber wir brauchen Zahlen zum Rechne. Daher m√ºssen wir noch in Zahlen umwandeln:\n\nd2 &lt;-\n  d %&gt;% \n  select(Year:Dec) %&gt;% \n  mutate(across(Apr:Dec, as.numeric))\n\nIns lange Format umwandeln:\n\nd3 &lt;- \n  d2 %&gt;% \n  pivot_longer(-Year, \n               values_to = \"temp\", \n               names_to = \"month\")\n\nDie Monate sind wie folgt bezeichnet in den Daten:\n\nmonth_vec &lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\",\n               \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\",\n               \"Nov\", \"Dec\")\n\n\nmonths &lt;-\n  tibble(\n    month = month_vec,\n    month_num = 1:12\n  )\n\nUnd dann die Monatsnummer (1-12) zu den Daten (d3) hinzuf√ºgen. Das geht komfortabel mit einem Join:\n\nd4 &lt;- \n  d3 %&gt;% \n  full_join(months)"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#daten-zusammenfassen",
    "href": "posts/nasa04/nasa04.html#daten-zusammenfassen",
    "title": "nasa04",
    "section": "Daten zusammenfassen",
    "text": "Daten zusammenfassen\nStatistiken pro Dekade f√ºr Januar:\n\nd_summarized &lt;- \n  d %&gt;% \n  group_by(decade) %&gt;% \n  summarise(temp_mean = mean(Jan),\n            temp_sd = sd(Jan))\n\nd_summarized"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#statisches-diagramm",
    "href": "posts/nasa04/nasa04.html#statisches-diagramm",
    "title": "nasa04",
    "section": "Statisches Diagramm",
    "text": "Statisches Diagramm\nZur Veranschaulichung visualisieren wir die Ergebnisse:\n\nd_summarized %&gt;% \n  pivot_longer(-decade) %&gt;% \n  ggplot(aes(x = decade, y = value)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ name)\n\n\n\n\n\n\n\n\nAlternativ k√∂nnen Sie zum Visualisieren der Daten z.B. das Paket ggpubr nutzen:\n\nlibrary(ggpubr)\nggscatter(d_summarized, x = \"decade\", y = \"temp_mean\", add = \"reg.line\")"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#animiertes-diagramm-pro-dekade",
    "href": "posts/nasa04/nasa04.html#animiertes-diagramm-pro-dekade",
    "title": "nasa04",
    "section": "Animiertes Diagramm pro Dekade",
    "text": "Animiertes Diagramm pro Dekade\nMit Punken:\n\np1 &lt;- \n  d_summarized %&gt;% \n  ggplot(aes(x = decade, y = temp_mean)) +\n  geom_point(aes(group = seq_along(decade))) \n\np1 + transition_reveal(decade) \n\nMit Linie:\n\np2 &lt;- ggplot(d_summarized,\n            aes(x = decade, temp_mean)) +\n  geom_line()\np2 + transition_reveal(decade)"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#animiertes-diagramm-pro-jahr",
    "href": "posts/nasa04/nasa04.html#animiertes-diagramm-pro-jahr",
    "title": "nasa04",
    "section": "Animiertes Diagramm pro Jahr",
    "text": "Animiertes Diagramm pro Jahr\n\nd3 %&gt;% \n  ggplot(aes(x = Year, y = temp)) +\n  geom_line() + \n  transition_reveal(Year)"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#statisches-diagramm-f√ºr-alle-monate",
    "href": "posts/nasa04/nasa04.html#statisches-diagramm-f√ºr-alle-monate",
    "title": "nasa04",
    "section": "Statisches Diagramm f√ºr alle Monate",
    "text": "Statisches Diagramm f√ºr alle Monate\n\np3 &lt;- d3 %&gt;% \n  ggplot(aes(x = Year, y = temp, color = month, group = month)) +\n  geom_line()"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#animiertes-diagramm-f√ºr-alle-monate",
    "href": "posts/nasa04/nasa04.html#animiertes-diagramm-f√ºr-alle-monate",
    "title": "nasa04",
    "section": "Animiertes Diagramm f√ºr alle Monate",
    "text": "Animiertes Diagramm f√ºr alle Monate\n\np3 + transition_reveal(Year)"
  },
  {
    "objectID": "posts/nasa04/nasa04.html#fazit",
    "href": "posts/nasa04/nasa04.html#fazit",
    "title": "nasa04",
    "section": "Fazit",
    "text": "Fazit\nFalls Sie Teile der R-Syntax nicht kennen: Machen Sie sich nichts daraus. Be happy üòÑ\n\nCategories:\n\ndata\neda\nlagema√üe\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/rf-finalize2/rf-finalize2.html",
    "href": "posts/rf-finalize2/rf-finalize2.html",
    "title": "rf-finalize2",
    "section": "",
    "text": "Aufgabe\n\nBerechnen Sie ein pr√§diktives Modell (Random Forest) mit dieser Modellgleichung:\nbody_mass_g ~ . (Datensatz: palmerpenguins::penguins).\nZeigen Sie, welche Werte f√ºr mtry im Default von Tidymodels gesetzt werden!\nHinweise: - Tunen Sie mtry - Verwenden Sie Kreuzvalidierung - Verwenden Sie Standardwerte, wo nicht anders angegeben. - Fixieren Sie Zufallszahlen auf den Startwert 42.\n         \n\n\nL√∂sung\nZuererst der Standardablauf:\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# rm NA in the dependent variable:\nd &lt;- d %&gt;% \n  drop_na(body_mass_g)\n\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_rf &lt;-\n  rand_forest(mode = \"regression\",\n           mtry = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_rf) %&gt;% \n  add_recipe(rec_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n26.129 sec elapsed\n\n\nDann schauen wir uns das Ergebnisobjekt vom Tuning an.\n\nwf1_fit %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  arrange(mtry)\n\n\n\n\n\nmtry\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n1\nrmse\nstandard\n311.1338\n10\n13.561765\npre0_mod1_post0\n\n\n2\nrmse\nstandard\n282.0886\n10\n11.401888\npre0_mod2_post0\n\n\n3\nrmse\nstandard\n280.8153\n10\n11.206073\npre0_mod3_post0\n\n\n4\nrmse\nstandard\n284.6346\n10\n10.374466\npre0_mod4_post0\n\n\n5\nrmse\nstandard\n284.6638\n10\n10.446736\npre0_mod5_post0\n\n\n6\nrmse\nstandard\n283.1617\n10\n9.830670\npre0_mod6_post0\n\n\n7\nrmse\nstandard\n283.2110\n10\n9.983912\npre0_mod7_post0\n\n\n8\nrmse\nstandard\n283.1983\n10\n10.600386\npre0_mod8_post0\n\n\n\n\n\n\nIn der Hilfe ist zu lesen:\n\nIf no tuning grid is provided, a semi-random grid (via dials::grid_latin_hypercube()) is created with 10 candidate parameter combinations.\n\nAus irgendwelchen Gr√ºnden wurden hier nur 10 Kandidatenwerte berechnet.\nWeiter steht dort:\n\nIn some cases, the tuning parameter values depend on the dimensions of the data. For example, mtry in random forest models depends on the number of predictors. In this case, the default tuning parameter object requires an upper range. dials::finalize() can be used to derive the data-dependent parameters. Otherwise, a parameter set can be created (via dials::parameters()) and the dials update() function can be used to change the values. This updated parameter set can be passed to the function via the param_info argument.\n\nAchtung: step_impute_knn scheint Probleme zu haben, wenn es Charakter-Variablen gibt.\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/regression1/regression1.html",
    "href": "posts/regression1/regression1.html",
    "title": "regression1",
    "section": "",
    "text": "Die folgende Frage bezieht sich auf dieses Ergebnis einer Regressionsanalyse:\n\n\n\nCall:\nlm(formula = log(y) ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.97394 -0.81203 -0.04712  0.76554  2.89696 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.0977     0.1617   0.604    0.549    \nx            -0.9517     0.1631  -5.833 6.39e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.084 on 43 degrees of freedom\nMultiple R-squared:  0.4418,    Adjusted R-squared:  0.4288 \nF-statistic: 34.03 on 1 and 43 DF,  p-value: 6.389e-07\n\n\nZusammengefasst sind die Koeffizienten (beta0 und beta1) also:\n\ncoef(m)\n\n(Intercept)           x \n 0.09769633 -0.95169074 \n\n\nWelche der folgenden Aussagen ist korrekt?\n\n\n\nDer Mittelwert der abh√§ngigen Variaben y sinkt mit zunehmenden x.\nWenn x um 1 Einheit steigt, dann kann eine Ver√§nderung um etwa 10.26 Prozent in y erwartet werden.\nWenn x=0, dann ist ein Mittelwert von y in H√∂he von etwa -0.85 zu erwarten.\nWenn x=1, dann ist ein Mittelwert von y in H√∂he von ca. 0.1 zu erwarten.\nWenn x=2, dann ist ein Mittelwert von y in H√∂he von ca. -0.85 zu erwarten."
  },
  {
    "objectID": "posts/regression1/regression1.html#answerlist",
    "href": "posts/regression1/regression1.html#answerlist",
    "title": "regression1",
    "section": "",
    "text": "Der Mittelwert der abh√§ngigen Variaben y sinkt mit zunehmenden x.\nWenn x um 1 Einheit steigt, dann kann eine Ver√§nderung um etwa 10.26 Prozent in y erwartet werden.\nWenn x=0, dann ist ein Mittelwert von y in H√∂he von etwa -0.85 zu erwarten.\nWenn x=1, dann ist ein Mittelwert von y in H√∂he von ca. 0.1 zu erwarten.\nWenn x=2, dann ist ein Mittelwert von y in H√∂he von ca. -0.85 zu erwarten."
  },
  {
    "objectID": "posts/regression1/regression1.html#answerlist-1",
    "href": "posts/regression1/regression1.html#answerlist-1",
    "title": "regression1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nregression\ndyn\nlm\nschoice"
  },
  {
    "objectID": "posts/rope4/rope4.html",
    "href": "posts/rope4/rope4.html",
    "title": "rope4",
    "section": "",
    "text": "Einer der (bisher) gr√∂√üten Studien der Untersuchung psychologischer Konsequenzen (oder Korrelate) der Covid-Zeit ist die Studie COVIDiStress.\nIm Folgenden sollen Sie folgende Forschungsfrage untersuchen:\nForschungsfrage:\nIst der Unterschied zwischen M√§nnern und Frauen (Dem_gender) im Hinblick zum Zusammenhang von Stress (PSS10_avg, AV) und Neurotizismus (neu, UV) vernachl√§ssigbar klein?\nDen Datensatz k√∂nnen Sie so herunterladen (Achtung, gro√ü):\n\nosf_d_path &lt;- \"https://osf.io/cjxua/?action=download\"\n\nd &lt;- read_csv(osf_d_path)\n\nHinweise:\n\nSie ben√∂tigen einen Computer, um diese Aufgabe zu l√∂sen.\nVerwenden Sie die statistischen Methoden, die im Unterricht behandelt wurden.\nVerwenden Sie Ans√§tze aus der Bayes-Statistik zur L√∂sung dieser Aufgabe.\nBei der Variable f√ºr Geschlecht k√∂nnen Sie sich auf F√§lle begrenzen, die M√§nner und Frauen umfassen.\nWandeln Sie die die Variable f√ºr Geschlecht in eine bin√§re Variable - also Werte mit 0 und 1 - um.\nAlle Daten (und weitere Informationen) zum Projekt sind hier abgelegt.\nEine Beschreibung der Variablen der Studie finden Sie hier.\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\nAntwortoptionen:\n\n\n\nJa\nNein\nDie Daten sind nicht konkludent; es ist keine Entscheidung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Entscheidung m√∂glich."
  },
  {
    "objectID": "posts/rope4/rope4.html#answerlist",
    "href": "posts/rope4/rope4.html#answerlist",
    "title": "rope4",
    "section": "",
    "text": "Ja\nNein\nDie Daten sind nicht konkludent; es ist keine Entscheidung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Entscheidung m√∂glich."
  },
  {
    "objectID": "posts/rope4/rope4.html#answerlist-1",
    "href": "posts/rope4/rope4.html#answerlist-1",
    "title": "rope4",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nrope\nbayes"
  },
  {
    "objectID": "posts/krebs1/krebs1.html",
    "href": "posts/krebs1/krebs1.html",
    "title": "Krebs1",
    "section": "",
    "text": "Aufgabe\nEin Krebstest (\\(T\\)) habe die Wahrscheinlichkeit von 0.9, einen vorhandenen Krebs (\\(K\\)) zu erkennen. Diese Wahrscheinlichkeit bezeichnen wir als \\(Pr(T+|K+)\\). Der Test erkennt also die meisten Krebsf√§lle, und ein paar werden (leider) √ºbersehen.\nManchmal macht der Test auch den umgekehrten Fehler: Bei einem gesunden Mensch wird f√§lschlich Krebs diagnostiziert, \\(Pr(T+|K-)\\). Diese Wahrscheinlichkeit liegt bei dem Test bei 0.1, zum Gl√ºck also relativ gering.\nDie Grundrate dieser Krebsart belaufe sich in der Population auf 0.01, \\(Pr(K+)\\).\nAufgabe: Berechnen Sie die Wahrscheinlichkeit, dass ein Patient tats√§chlich Krebs hat, wenn (gegeben dass) der Test positiv ist, also Krebs diagnostiziert hat!\n         \n\n\nL√∂sung\n\nPr_Tpos_geg_Kpos &lt;- .9  # Wskt f√ºr Test positiv geg. Krebs ist positiv (tats√§chlich Krebs)\nPr_Tpos_geg_Kneg &lt;- .1\nPr_Kpos &lt;- .01\n\nHier kann man Bayes Theorem anwenden:\n\\(Pr(K|T) = \\frac{Pr(K) \\cdot Pr(T|K) }{Pr(T)}\\).\n\nzaehler_bayes &lt;- Pr_Kpos * Pr_Tpos_geg_Kpos\nzaehler_bayes\n\n[1] 0.009\n\nPr_T &lt;- (zaehler_bayes + (1-Pr_Kpos) * Pr_Tpos_geg_Kneg)\nPr_T\n\n[1] 0.108\n\nsol &lt;- Pr_Kpos_geg_Tpos &lt;- zaehler_bayes / Pr_T \nsol &lt;- round(sol, 2)\nsol\n\n[1] 0.08\n\n\nDie L√∂sung betr√§gt also: 0.08.\nHier ist ein Baumdiagramm zur Visualisierung:\n\n\n\n\n\nflowchart LR\n  S[1000 Personen] --&gt; K[Krebs: 10]\n  S --&gt; NK[Nicht-Krebs: 990]\n  K --&gt; T[Test positiv: 9]\n  K --&gt; NT[Nicht Test positiv: 1]\n  NK --&gt; TNK[Test positiv: 99]\n  NK --&gt; NTNK[Nicht Test positiv: 891]\n\n\n\n\n\n\nMan kann die Aufgabe auch mit dem Baumdiagramm l√∂sen:\nEs erhalten 108=99+9 Personen ein positives Testergebnis. Davon haben 9 tats√§chlich Krebs. Also: \\(Pr(K+|T+) = \\frac{9}{108} = 0.0833\\).\nAlternativ kann man auch mit der Bayesbox arbeiten:\n\n\n\n\n\n\n\n\n\n\n\nHypothese\nPrior\nLikelihood\nPost_unstand\nEvidenz\nPost\n\n\n\n\nK\n.01\n.9\n.009\n.108\n.083\n\n\nNK\n.99\n.1\n.099\n.108\n.092\n\n\n\nK: Krebs NK: Nicht-Krebs\nDie Likelihood f√ºr die Hypothese \\(K\\) (die Hypothese, dass Krebs vorliegt) ist definiert als \\(Pr(D|H)=.9\\). Hier entspricht der positive Krebstest den Daten. Die Likelihood f√ºr die Hypothese \\(NK\\) (die Hypothese, dass kein Krebs vorliegt) ist definiert als \\(Pr(D|\\neg H)=.9\\). Hier entspricht der negative Krebstest den Daten.\nDie unstandardisierte Post-Wahrscheinlichkeit entspricht dem Produkt aus Likelihood und Prior: \\(Pr(D|H) \\cdot Pr(H)=.009\\) bzw. \\(.099\\).\nDie Evidenz ist die Summe der Posterior-Wahrscheinlichkeiten multipliziert mit den jeweiligen Priors: \\(Pr(D)=.108\\).\nDie Post-Wahrscheinlichkeit ist die durch die Evidenz dividierte unstandardisierte Post-Wahrscheinlichkeit: \\(Pr(H|D)=.083\\) bzw. \\(.092\\).\n\nCategories:\n\nbayes\nprobability\nnum"
  },
  {
    "objectID": "posts/nasa03/nasa03.html",
    "href": "posts/nasa03/nasa03.html",
    "title": "nasa03",
    "section": "",
    "text": "Aufgabe\nViele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read_csv(data_path, skip = 1)\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgaben\n\nErstellen Sie f√ºr jeden Januar eine Variable (temp_is_above), die ausgibt, ob die Temperatur √ºber oder unter dem Durchschnitt liegt (d.h. eine negative oder positive Abweichung ist). Nutzen Sie als Auspr√§gungen die Werte ‚Äúyes‚Äù und ‚Äúno‚Äù.\nErstellen Sie dann eine Variable, die das Jahrhundert angibt (19. JH. vs.¬†20 JH).\nZ√§hlen Sie dann wie oft temp_is_above ‚Äúyes‚Äù aufweist pro Jahrhundert (‚Äúerh√∂hter Temperatur‚Äù).\nBONUSAUFGABE: Berechnen Sie das Odds Ratio (Chancenverh√§ltnis) von erh√∂hter Temperatur (vs.¬†nicht erh√∂hter Temperatur) zwischen dem 19. und dem 20. Jahrhundert.\n\nHinweise:\nF√ºr ‚ÄúWenn-Dann-Abfragen‚Äù eignet sich folgender R-Befehl (als ‚ÄúPseudocode‚Äù dargestellt):\n\nd %&gt;% \n  mutate(neue_spalte = case_when(\n    erste_bedingung_bzw_wenn_teil ~ dann_teil1,\n    zweite_bedingung_bzw_zweiter_wenn_teil ~ dann_teil2\n  ))\n\nEs finden sich online viele Hilfsangebote zu case_when, falls Sie weitere Informationen ben√∂tigen.\nUnter Odds Ratio versteht man den Quotienten zweier Quotienten. Das h√∂rt sich zu theoretisch an? Betrachten wir ein Beispiel. Sagen wir, mit Impfung sei das Risiko f√ºr eine bestimmte Erkrankung 1:1000; ohne Impfung aber 1:100.\nAlso: Hundert-zu-eins steht gegen tausend-zu-eins. Das ist ein Faktor von zehn bzw. von ein Zehntel, jenachdem wie rum man den Bruch (Quotient) betrachtet.\n\\[\\frac{\\frac{1}{100}}{\\frac{1}{1000}} = \\frac{1}{10}\\]\n         \n\n\nL√∂sung\ntemp_is_above erstellen:\n\nd &lt;-\n  d %&gt;% \n  mutate(temp_is_above = case_when(\n    Jan &gt; 0 ~ \"yes\",\n    Jan &lt;= 0 ~ \"no\"\n  ))\n\nJahrhundert berechnen:\n\nd &lt;-\n  d %&gt;% \n  mutate(century = case_when(\n    Year &lt; 1900 ~ \"19th\",\n    Year &gt;= 1900 ~ \"20th\"\n  ))\n\nErh√∂hte Werte der Januar-Temperatur pro Jahrhundert berechnen:\n\nd_summarized &lt;- \nd %&gt;% \n  group_by(century) %&gt;% \n  count(temp_is_above)\n\nd_summarized\n\n\n\n\n\ncentury\ntemp_is_above\nn\n\n\n\n\n19th\nno\n19\n\n\n19th\nyes\n1\n\n\n20th\nno\n56\n\n\n20th\nyes\n70\n\n\n\n\n\n\nDer Befehl count() z√§hlt aus, wie h√§ufig die Auspr√§gungen der angegebenen Variablen X sind, m.a.W. er gibt die Verteilung von X wieder.\nEs macht vermutlich Sinn, noch die Anteile (relative H√§ufigkeiten) zu den absoluten H√§ufigkeiten zu erg√§nzen:\n\nd_summarized %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n\n\ncentury\ntemp_is_above\nn\nprop\n\n\n\n\n19th\nno\n19\n0.9500000\n\n\n19th\nyes\n1\n0.0500000\n\n\n20th\nno\n56\n0.4444444\n\n\n20th\nyes\n70\n0.5555556\n\n\n\n\n\n\nOdds Ratio berechnen:\nWir bezeichnen mit c19 (f√ºr ‚ÄúChance 1‚Äù) das Verh√§ltnis von erh√∂hter Temperatur zu nicht erh√∂hter Temperatur im 19. Jahrhundert.\n\nc19 &lt;- 1 / 19\n\nMit c20 bezeichnen wir die analoge Chance f√ºr das 20. Jahrhundert:\n\nc20 &lt;- 56 / 67\n\nDas Verh√§ltnis der beiden Chancen gibt das Chancenverh√§ltnis (Odds Ratio, OR):\n\nc19 / c20\n\n[1] 0.06296992\n\n\nGenauso gut kann man das OR von c20 zu c19 ausrechnen, der Effekt bleibt identisch:\n\nc20 / c19\n\n[1] 15.8806\n\n\nIn beiden F√§llen ist es ein Faktor von knapp 16.\n\nCategories:\n\ndata\neda\nassociation\nstring"
  },
  {
    "objectID": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html",
    "href": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html",
    "title": "stan_glm_prioriwerte",
    "section": "",
    "text": "Berechnet man eine Posteriori-Verteilung mit stan_glm(), so kann man entweder die schwach informativen Prioriwerte der Standardeinstellung verwenden, oder selber Prioriwerte definieren.\nBetrachten Sie dazu dieses Modell:\nstan_glm(price ~ cut, data = diamonds, \n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(10, 10, 10, 10)),\n                   prior_intercept = normal(3000, 500))\nBeziehen Sie sich auf den Datensatz diamonds.\nHinweise:\n\nGehen Sie davon aus, dass die Post-Verteilung von Intercept und Gruppeneffekte normalverteilt sind.\n\nWelche Aussage dazu passt (am besten)?\n\n\n\nEs wird f√ºr (genau) einen Parameter eine Priori-Verteilung definiert.\nF√ºr das Regressionsgewicht \\(\\beta_1\\) sind negative Werte apriori plausibel.\nMit prior = normal() werden Gruppenmittelwerte definiert.\nAlle Parameter des Modells sind normalverteilt."
  },
  {
    "objectID": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist",
    "href": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist",
    "title": "stan_glm_prioriwerte",
    "section": "",
    "text": "Es wird f√ºr (genau) einen Parameter eine Priori-Verteilung definiert.\nF√ºr das Regressionsgewicht \\(\\beta_1\\) sind negative Werte apriori plausibel.\nMit prior = normal() werden Gruppenmittelwerte definiert.\nAlle Parameter des Modells sind normalverteilt."
  },
  {
    "objectID": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist-1",
    "href": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist-1",
    "title": "stan_glm_prioriwerte",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Es gibt mehrere Parameter im Modell (Achsenabschnitt, 4 Pr√§diktoren, sigma)\nWahr. F√ºr cutGood sind negative Werte plausibel.\nFalsch. prior = normal() werden Regressionskoeffizienten in ihren Prioris definiert.\nFalsch. sigma ist in Stans Voreinstellung exponentialverteilt.\n\n\nCategories:\n\nbayes\nregression"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html",
    "title": "germeval-textfeatures01",
    "section": "",
    "text": "Extrahieren Sie g√§ngige Textfeatures - mit Hilfe des gleichnamigen R-Pakets - als Teil des Feature Engineering im Rahmen eines Tidymodels-Klassifikationsmodells.\nModellieren Sie dann mit einem einfachen linearen Modell die abh√§ngige Variable.\nVerwenden Sie diesen Datensatz:\n\n# Analyse-Daten:\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n# Sentiment-Daten\ndata(\"sentiws\", package = \"pradadata\")\n\nDie AV ist c1.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#setup",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#setup",
    "title": "germeval-textfeatures01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(beepr)\nlibrary(textrecipes)"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#daten",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#daten",
    "title": "germeval-textfeatures01",
    "section": "Daten",
    "text": "Daten\nc2 brauchen wir hier nicht:\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(-c2) |&gt; \n  as_tibble()"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#rezept",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#rezept",
    "title": "germeval-textfeatures01",
    "section": "Rezept",
    "text": "Rezept\nRezept definieren:\n\nrec &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  update_role(text, new_role = \"ignore\") |&gt; \n  step_textfeature(text)  # isst `text` auf\n\nstep_mutate erg√§nzt f√ºr die erzeugte (mutierte) Variable automatisch eine Rolle im Rezept, nimmt sie also als Pr√§diktor auf.\nMal schauen:\n\nrec\n\n\ntidy(rec)\n\nPreppen und backen:\n\ntic()\nrec_prepped &lt;- prep(rec)\ntoc()\nbeep()\n\n\nrec_prepped\n\n\nrec_baked &lt;- bake(rec_prepped, new_data = NULL)\nhead(rec_baked)\n\nFolgende Spalten/Features hat step_textfeatures extrahiert:\n\nnames(rec_baked)"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#model",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#model",
    "title": "germeval-textfeatures01",
    "section": "Model",
    "text": "Model\n\nmod &lt;-\n  logistic_reg()"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#workflow",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#workflow",
    "title": "germeval-textfeatures01",
    "section": "Workflow",
    "text": "Workflow\n\nwf &lt;- workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#fit",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#fit",
    "title": "germeval-textfeatures01",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;-\n  fit(wf,\n      data = d_train)\ntoc()\n\n\nfit1"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#test-set-g√ºte",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#test-set-g√ºte",
    "title": "germeval-textfeatures01",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmetrics(d_test,\n        truth = c1,\n        estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval-textfeatures01/germeval-textfeatures01.html#baseline",
    "href": "posts/germeval-textfeatures01/germeval-textfeatures01.html#baseline",
    "title": "germeval-textfeatures01",
    "section": "Baseline",
    "text": "Baseline\nEin einfaches Referenzmodell ist, einfach die h√§ufigste Kategorie vorherzusagen:\n\nd_train |&gt; \n  count(c1)\n\n\nCategories:\n\ntidymodels\ntextmining\nprediction\nsentimentanalysis\ngermeval\nstring"
  },
  {
    "objectID": "posts/wskt-quiz12/wskt-quiz12.html",
    "href": "posts/wskt-quiz12/wskt-quiz12.html",
    "title": "wskt-quiz12",
    "section": "",
    "text": "Behauptung: Der Likelihood \\(L\\) gibt die Wahrscheinlichkeit einer Hypothese an, gegeben der Daten.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz12/wskt-quiz12.html#answerlist",
    "href": "posts/wskt-quiz12/wskt-quiz12.html#answerlist",
    "title": "wskt-quiz12",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz12/wskt-quiz12.html#answerlist-1",
    "href": "posts/wskt-quiz12/wskt-quiz12.html#answerlist-1",
    "title": "wskt-quiz12",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/bestehen_ohne_lernen/index.html",
    "href": "posts/bestehen_ohne_lernen/index.html",
    "title": "bestehen_ohne_lernen",
    "section": "",
    "text": "1 Aufgabe\nSie bereiten sich gerade auf die Klausur bei Prof.¬†S√º√ü vor. Das hei√üt: Sie √ºberlegen, ob Sie sich auf die Klausur vorbereiten sollten. Vielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr gro√ü? Aber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen k√∂nnen, s. Table¬†1. In der Tabelle sind die Daten von 100 Studis ausgewiesen. Ein Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die ‚ÄúLerner‚Äù. Ein anderer Teil hat nicht gelernt, \\(NL\\) bzw. \\(\\neg L\\). Ein Teil hat bestanden, \\(B\\), ein Teil nicht \\(NB\\) oder \\(\\neg B\\).\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: \\(Pr(B |\\neg L)\\).\n\n\n\n\nTable¬†1: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n\n\n.\nL\nNL\nSumme\n\n\n\n\nB\n80\n1\n81\n\n\nNB\n5\n14\n19\n\n\nSumme\n85\n15\n100\n\n\n\n\n\n\n\n\nWarum kann man NICHT einfach rechnen:\n\\[Pr(B |\\neg L) = Pr(B) \\cdot Pr(\\neg L)\\]\nAusgerechnet:\n\nPr_B_geg_nichtL &lt;- 81/100 * 15/100\nPr_B_geg_nichtL\n\n[1] 0.1215\n\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nDer Multiplikationssatz der Wahrscheinlichkeitsrechnung darf nur angewendet werden, wenn die Ereignisse unabh√§ngig sind. In diesem Fall sind die Ereignisse \\(B\\) und \\(\\neg L\\) aber abh√§ngig, da \\(Pr(B|\\neg L) \\ne Pr(B) \\ne Pr(B| L)\\).\n\nPr_B_geg_nichtL &lt;- 1/15\nPr_B &lt;- 81/100\nPr_B_geg_L &lt;- 80/85"
  },
  {
    "objectID": "posts/posterior_interval/posterior_interval.html",
    "href": "posts/posterior_interval/posterior_interval.html",
    "title": "posterior_interval",
    "section": "",
    "text": "Welches Ergebnis hat der R-Befehl posterior_interval() (R-Paket rstanarm)?\nW√§hlen Sie die (am besten) passende Antwort aus.\nHinweis:\n\nSoweit nicht anders benannt, ist immer die Voreinstellung der betreffenden Funktion gemeint.\n\n\n\n\nEr liefert einen Vorhersagewert aus der Posteriori-Verteilung.\nEr liefert ein Vorhersageintervall aus der Posteriori-Verteilung.\nEr liefert ein 90%-Vorhersageintervall aus der Posteriori-Verteilung.\nEr liefert ein 95%-Vorhersageintervall aus der Posteriori-Verteilung.\nEr liefert ein HDI-Vorhersageinterval aus der Posteriori-Verteilung."
  },
  {
    "objectID": "posts/posterior_interval/posterior_interval.html#answerlist",
    "href": "posts/posterior_interval/posterior_interval.html#answerlist",
    "title": "posterior_interval",
    "section": "",
    "text": "Er liefert einen Vorhersagewert aus der Posteriori-Verteilung.\nEr liefert ein Vorhersageintervall aus der Posteriori-Verteilung.\nEr liefert ein 90%-Vorhersageintervall aus der Posteriori-Verteilung.\nEr liefert ein 95%-Vorhersageintervall aus der Posteriori-Verteilung.\nEr liefert ein HDI-Vorhersageinterval aus der Posteriori-Verteilung."
  },
  {
    "objectID": "posts/posterior_interval/posterior_interval.html#answerlist-1",
    "href": "posts/posterior_interval/posterior_interval.html#answerlist-1",
    "title": "posterior_interval",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nbayes\nregression\npost"
  },
  {
    "objectID": "posts/rowmeans-groupby-summarise/index.html",
    "href": "posts/rowmeans-groupby-summarise/index.html",
    "title": "rowmeans-groupby-summarise",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)\n\n\n\n\n\nlibrary(rio)\nextra_path &lt;- \"https://github.com/sebastiansauer/statistik1/raw/main/data/extra.xls\"\nextra &lt;- import(extra_path)\n\n\n\n\nWie gro√ü ist der Unterschied in der Extraversion zwischen Frauen und M√§nnern? Berechnen Sie dazu den Mittelwert f√ºr Extraversion pro Geschlechtsgruppe.\n\n\n\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/rowmeans-groupby-summarise/index.html#setup",
    "href": "posts/rowmeans-groupby-summarise/index.html#setup",
    "title": "rowmeans-groupby-summarise",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/rowmeans-groupby-summarise/index.html#daten",
    "href": "posts/rowmeans-groupby-summarise/index.html#daten",
    "title": "rowmeans-groupby-summarise",
    "section": "",
    "text": "library(rio)\nextra_path &lt;- \"https://github.com/sebastiansauer/statistik1/raw/main/data/extra.xls\"\nextra &lt;- import(extra_path)"
  },
  {
    "objectID": "posts/rowmeans-groupby-summarise/index.html#forschungsfrage",
    "href": "posts/rowmeans-groupby-summarise/index.html#forschungsfrage",
    "title": "rowmeans-groupby-summarise",
    "section": "",
    "text": "Wie gro√ü ist der Unterschied in der Extraversion zwischen Frauen und M√§nnern? Berechnen Sie dazu den Mittelwert f√ºr Extraversion pro Geschlechtsgruppe."
  },
  {
    "objectID": "posts/rowmeans-groupby-summarise/index.html#hinweise",
    "href": "posts/rowmeans-groupby-summarise/index.html#hinweise",
    "title": "rowmeans-groupby-summarise",
    "section": "",
    "text": "Beachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/germeval06/germeval06.html",
    "href": "posts/germeval06/germeval06.html",
    "title": "germeval06",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Glove6b Word-Vektoren f√ºr das Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels."
  },
  {
    "objectID": "posts/germeval06/germeval06.html#textvektoren-importieren",
    "href": "posts/germeval06/germeval06.html#textvektoren-importieren",
    "title": "germeval06",
    "section": "Textvektoren importieren",
    "text": "Textvektoren importieren\n\nlibrary(textdata)\n\nglove_embedding &lt;- embedding_glove6b(\n  dir = \"/Users/sebastiansaueruser/datasets\",\n  return_path = TRUE,\n  manual_download = TRUE\n)\n\nhead(glove_embedding)\n\n\n# model:\nmod1 &lt;-\n  logistic_reg()\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train, v = 5)\n\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  step_tokenize(text) %&gt;%\n  step_stopwords(text, keep = FALSE) %&gt;%\n  step_word_embeddings(text,\n                       embeddings = glove_embedding,\n                       aggregation = \"mean\") |&gt; \n  step_normalize(all_numeric_predictors()) \n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval06/germeval06.html#tuning",
    "href": "posts/germeval06/germeval06.html#tuning",
    "title": "germeval06",
    "section": "Tuning",
    "text": "Tuning\n\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit_resamples(\n    resamples = rsmpl,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE))\ntoc()\nbeep()\n\n\nwf1_fit |&gt; collect_metrics()\n\nBester Fold:\n\nshow_best(wf1_fit)"
  },
  {
    "objectID": "posts/germeval06/germeval06.html#fit",
    "href": "posts/germeval06/germeval06.html#fit",
    "title": "germeval06",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;- \n  wf1 |&gt; \n  fit(data = d_train)\ntoc()"
  },
  {
    "objectID": "posts/germeval06/germeval06.html#test-set-g√ºte",
    "href": "posts/germeval06/germeval06.html#test-set-g√ºte",
    "title": "germeval06",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval06/germeval06.html#fazit",
    "href": "posts/germeval06/germeval06.html#fazit",
    "title": "germeval06",
    "section": "Fazit",
    "text": "Fazit\nglove6b ist f√ºr die englische Sprache vorgekocht. Das macht wenig Sinn f√ºr einen deutschsprachigen Corpus.\n\nCategories:\n\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nwordvec\nstring"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html",
    "href": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html",
    "title": "Verteilungen-Quiz-09",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\ge \\bar{x} + \\sigma) \\approx 0.16\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html#answerlist",
    "href": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html#answerlist",
    "title": "Verteilungen-Quiz-09",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Kausal/Kausal.html",
    "href": "posts/Kausal/Kausal.html",
    "title": "Kausal",
    "section": "",
    "text": "Die kausale Abh√§ngigkeit zwischen drei Variablen A, B, C sieht wie folgt aus:\n\nA h√§ngt ab von B.\nC h√§ngt ab von A.\nC h√§ngt ab von B.\n\nHinweise:\n\nAbh√§ngigkeit ist kausal zu verstehen.\n\nAufgabe: Wie lautet die R-Formel, um den totalen kausalen Effekt von B auf C zu bestimmen?\n\n\n\nC ~ A\nC ~ B\nC ~ A + B\nB ~ C\nB ~ C + A\nB ~ A\nDer totale kausale Effekt kann nicht bestimmt werden."
  },
  {
    "objectID": "posts/Kausal/Kausal.html#answerlist",
    "href": "posts/Kausal/Kausal.html#answerlist",
    "title": "Kausal",
    "section": "",
    "text": "C ~ A\nC ~ B\nC ~ A + B\nB ~ C\nB ~ C + A\nB ~ A\nDer totale kausale Effekt kann nicht bestimmt werden."
  },
  {
    "objectID": "posts/Kausal/Kausal.html#answerlist-1",
    "href": "posts/Kausal/Kausal.html#answerlist-1",
    "title": "Kausal",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch"
  },
  {
    "objectID": "posts/Typ-Fehler-R-04/Typ-Fehler-R-04.html",
    "href": "posts/Typ-Fehler-R-04/Typ-Fehler-R-04.html",
    "title": "Typ-Fehler-R-04",
    "section": "",
    "text": "Aufgabe\nGegeben sei diese Syntax, die einen Fehlermeldung ausgibt:\n\nmean(c(1,2,3,4), na.rm = TRUE)\n\n[1] 2.5\n\n\nGeben Sie die korrekte Syntax ein, die nicht zu einer Fehlermeldung f√ºhrt!\nBitte verwenden Sie keine Leerzeichen bei Ihrer Eingabe.\n         \n\n\nL√∂sung\n\nmean(c(1,2,3,4), na.rm = TRUE)\n\n[1] 2.5\n\n\n\nsol &lt;- \"mean(c(1,2,3,4),na.rm=TRUE)\"\n\nDie Antwort lautet: mean(c(1,2,3,4),na.rm=TRUE).\n\nCategories:\n\nR\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/iq08/iq08.html",
    "href": "posts/iq08/iq08.html",
    "title": "iq08",
    "section": "",
    "text": "Aufgabe\nAn einer Elite-Hochschule wird man nur zugelassen, wenn man sowohl sch√∂n als auch schlau ist.\n‚ÄúSch√∂n‚Äù sei definiert als eine SD-Einheit √ºber dem mittleren Aussehen, unter der Annahme, dass Aussehen normalverteilt ist.\n‚ÄúSchlau‚Äù sei definiert als eine SD-Einheit √ºber dem mittleren Wert, unter der Annahme, dass die Variable normalverteilt ist.\nWie hoch ist die Wahrscheinlichkeit, an dieser Elite-Uni zugelassen zu werden?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender Verteilung f√ºr Sch√∂nheit und f√ºr Schlauheit aus: \\(X \\sim N(0,1)\\)\nIntelligenz und Sch√∂nheit sollen als unabh√§ngig angenommen werden.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^4\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nDie Wahrscheinlichkeit f√ºr ‚Äúsch√∂n‚Äù, \\(S1\\) ist gleich der Wahrscheinlichkeit f√ºr ‚ÄúSchlau‚Äù, \\(S2\\).\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\n\nd &lt;- tibble(\n  id = 1:10^4,\n  schoenheit = rnorm(n = 10^4, mean = 0, sd = 1),\n  schlauheit = rnorm(n = 10^4, mean = 0, sd = 1))\n\nDa es nur um Anteile (bzw. Wahrscheinlichkeiten) der Population geht, k√∂nnen wir mit z-Werten arbeiten.\nZur Erinnerung: Ein z-Wert von 1 bedeutet, dass der Messwert eine SD-Einheit gr√∂√üer ist als der Mittelwert der Verteilung.\nDann filtern wir wie in der Angabe gefragt:\n\nd2 &lt;-\n  d %&gt;% \n  count(schoenheit &gt; 1, schlauheit &gt; 1) %&gt;%  # Das Komma wird als logisches UND interpretiert\n  mutate(prop = n / sum(n))\n\nd2\n\n\n\n\n\nschoenheit &gt; 1\nschlauheit &gt; 1\nn\nprop\n\n\n\n\nFALSE\nFALSE\n7082\n0.7082\n\n\nFALSE\nTRUE\n1364\n0.1364\n\n\nTRUE\nFALSE\n1314\n0.1314\n\n\nTRUE\nTRUE\n240\n0.0240\n\n\n\n\n\n\nWieder nehmen wir den Anteil her und bezeichnen ihn als Wahrscheinlichkeit. Das ist eine sch√∂ne Sache dieser Simulationsmethoden: Es vereinfacht die Angelegenheit, denn mit H√§ufigkeiten l√§sst sich einfacher hantieren als mit Wahrscheinlichkeiten. Und die Anteile erf√ºllen die Kolmogorov-Axiome, wir k√∂nnen also beruhigt rechnen. Falls Sie also vor Sorge um die Reinheit der Mathematik nicht schlafen konnten, kann ich Sie insofern beruhigen :-)\nNat√ºrlich k√∂nnte man die Frage auch analytisch l√∂sen (mit dem Multiplikationssatz f√ºr unabh√§ngige Ereignisse).\nDie Wahrscheinlichkeit f√ºr einen Wert \\(x &gt;= 115, X \\sim N(100,15)\\) betr√§gt:\n\npr_1sd_ueber_mw &lt;- 1- pnorm(115, 100, 15)\npr_1sd_ueber_mw\n\n[1] 0.1586553\n\n\nDannn:\n\npr_1sd_ueber_mw * pr_1sd_ueber_mw\n\n[1] 0.02517149\n\n\nAntwort: Die L√∂sung lautet also 0.024.\nInteressant ist es vielleicht, die Gesamtpopulation zu visualisieren:\n\nd %&gt;% \n  mutate(ist_schoen = if_else(schoenheit &gt; 1, TRUE, FALSE),\n         ist_schlau = if_else(schlauheit &gt; 1, TRUE, FALSE),\n         ist_schoen_schlau = if_else(ist_schoen & ist_schlau, TRUE, FALSE)) %&gt;% \n  ggplot() +\n  aes(x = schoenheit, y = schlauheit, color = ist_schoen_schlau, alpha = .1) +\n  geom_point()\n\n\n\n\n\n\n\n\nW√§re die Aufnahmeregel, dass es reichte, entweder sch√∂n oder schlau (beides ist auch ok) zu sein, w√§re der Anteil an zugelassenen Personen gr√∂√üer:\n\nd3 &lt;-\n  d %&gt;% \n  count(schoenheit &gt; 1 | schlauheit &gt; 1) %&gt;%  # der horizontale Balken steht f√ºr das logische ODER.\n  mutate(prop = n / sum(n))\n\nd3\n\n\n\n\n\nschoenheit &gt; 1 | schlauheit &gt; 1\nn\nprop\n\n\n\n\nFALSE\n7082\n0.7082\n\n\nTRUE\n2918\n0.2918\n\n\n\n\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/import-xls/import-xls.html",
    "href": "posts/import-xls/import-xls.html",
    "title": "import-xls",
    "section": "",
    "text": "Question\nImportieren Sie in R die Excel-Datei extra.xls.\nDie Daten liegen online z.B. hier: https://github.com/sebastiansauer/statistik1/raw/main/data/extra.xls\nEs handelt sich um die Daten einer Umfrage zu den Korrelaten von Extraversion.\nEin Daten-Dictionary finden Sie hier.\nMehr Hinweise zu der zugrundeliegenden Studie finden Sie hier: https://osf.io/4kgzh.\n\n\nSolution\nEs gibt verschiedene Wege, Excel-Daten in R zu importieren. Hier ist ein Weg, mit Hilfe des Pakets {rio}:\n\nlibrary(rio)\nextra_path &lt;- \"https://github.com/sebastiansauer/statistik1/raw/main/data/extra.xls\"\nextra &lt;- import(extra_path)\n\nTest:\n\nlibrary(tidyverse)\nglimpse(extra)\n\nRows: 40\nColumns: 25\n$ X        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18‚Ä¶\n$ i1       &lt;chr&gt; \"3/3/2016 15:33:23\", \"3/3/2016 15:33:28\", \"3/3/2016 15:34:43\"‚Ä¶\n$ i2       &lt;chr&gt; NA, \"FBR\", \"CZP\", NA, \"ism\", \"Asm\", \"TPF\", \"Oam\", \"AEM\", NA, ‚Ä¶\n$ i3       &lt;dbl&gt; 3, 3, 4, 4, 4, 4, 3, 2, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 4, 4, 4‚Ä¶\n$ i4       &lt;dbl&gt; 3, 3, 3, 3, 4, 3, 3, 2, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4‚Ä¶\n$ i5       &lt;dbl&gt; 2, 3, 3, 3, 2, 3, 1, 3, 1, 2, 1, 1, 1, 3, 2, 4, 1, 2, 3, 3, 2‚Ä¶\n$ i6       &lt;dbl&gt; 2, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3, 3, 4, 3, 4, 4, 2, 3, 3, NA, ‚Ä¶\n$ i7       &lt;dbl&gt; 2, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 2, 4, 4, 4, 3, 2, 3, 3, 4, 3‚Ä¶\n$ i8       &lt;dbl&gt; 3, 3, 4, 4, 3, 3, 4, 2, 3, 3, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3‚Ä¶\n$ i9       &lt;dbl&gt; 3, 2, 3, 3, 3, 4, 3, 1, 3, 3, 3, 2, 3, 3, 2, 4, 2, 4, 3, 3, 2‚Ä¶\n$ i10      &lt;dbl&gt; 2, 2, 3, 4, 3, 3, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 2‚Ä¶\n$ i11      &lt;dbl&gt; 3, 3, 3, 4, 3, 4, 4, 1, 3, 4, 3, 4, 3, 4, 3, 3, 2, 3, 4, 3, 3‚Ä¶\n$ i12      &lt;dbl&gt; 1, 2, 2, 4, 2, 3, 2, 2, 2, 1, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 1‚Ä¶\n$ i13      &lt;dbl&gt; 250, 294, 600, 500, 300, 350, 608, NA, 500, 521, 280, 250, 12‚Ä¶\n$ i14      &lt;dbl&gt; 1, 2, 0, 0, 0, 10, 2, 6, 10, 12, 12, 12, 20, 1, 3, 25, 0, 40,‚Ä¶\n$ i15      &lt;dbl&gt; 24, 28, 24, 20, 20, 23, 24, 24, 21, 25, 23, 22, 23, 21, 22, 2‚Ä¶\n$ i16      &lt;chr&gt; \"Frau\", \"Frau\", \"Frau\", \"Frau\", \"Frau\", \"Frau\", \"Frau\", \"Mann‚Ä¶\n$ i17      &lt;dbl&gt; 1, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 2, 4, 3, 3, 4, 2, 3, 3, 3, 2‚Ä¶\n$ i18      &lt;dbl&gt; NA, 27, NA, 7, 30, 15, 10, 15, 10, 10, 10, 10, 15, 1, 5, 1, 1‚Ä¶\n$ i19      &lt;chr&gt; \"nein\", \"ja\", \"nein\", \"nein\", \"nein\", \"nein\", \"nein\", \"nein\",‚Ä¶\n$ i20      &lt;dbl&gt; 6, 1, 30, 4, 5, 20, 30, 6, 5, 12, 30, 12, 22, 5, 15, 40, 48, ‚Ä¶\n$ i21      &lt;chr&gt; \"im Schnitt 1 Mal pro Quartal (oder weniger)\", \"im Schnitt me‚Ä¶\n$ i22      &lt;chr&gt; \"keine Antwort\", \"passt insgesamt nicht\", \"passt insgesamt\", ‚Ä¶\n$ i23      &lt;dbl&gt; 6, 4, 3, 3, 3, 3, 5, 4, 6, 5, 4, 6, 2, 3, 5, 2, 8, 6, 2, 4, 5‚Ä¶\n$ extra_mw &lt;dbl&gt; 2.400000, 2.800000, 3.300000, 3.500000, 3.200000, 3.400000, 3‚Ä¶"
  },
  {
    "objectID": "posts/flights-delay-simplified/index.html",
    "href": "posts/flights-delay-simplified/index.html",
    "title": "flights-delay-simplified",
    "section": "",
    "text": "Wir untersuchen die Forschungsfrage Was sind Pr√§diktoren von Flugversp√§tungen. Wir nutzen dep_delay als AV (Zielvariable), also als die Variable, die wir vorhersagen wollen.\nDazu verwenden wir lineare Modelle als Modellierungsmethoden."
  },
  {
    "objectID": "posts/flights-delay-simplified/index.html#pakete-laden",
    "href": "posts/flights-delay-simplified/index.html#pakete-laden",
    "title": "flights-delay-simplified",
    "section": "3.1 Pakete laden",
    "text": "3.1 Pakete laden\nWirklich wichtig sind nur tidymodels und tidyverse. Die restlichen Pakete werden nur am Rande ben√∂tigt. Man sollte auch nur die Pakete laden, die man f√ºr die Analyse ben√∂tigt.\n\nlibrary(\"tidymodels\")  # Train- und Test-Sample aufteilen\nlibrary(\"tidyverse\")  # data wrangling\nlibrary(\"conflicted\")  # Name clashes finden\nlibrary(\"easystats\")  # stats made easy\nlibrary(\"DataExplorer\")  # Data Vis"
  },
  {
    "objectID": "posts/flights-delay-simplified/index.html#daten-laden-flights-2023",
    "href": "posts/flights-delay-simplified/index.html#daten-laden-flights-2023",
    "title": "flights-delay-simplified",
    "section": "3.2 Daten laden: Flights 2023",
    "text": "3.2 Daten laden: Flights 2023\nAus Gr√ºnden der Daten√∂konomie nutzen wir eine kleinere Version des Datensatz flights. Wir nutzen nicht mehr die Daten aus dem 2013, sondern die neueren Daten aus dem Jahr 2023.\n\nlibrary(nycflights23)\ndata(flights)\n\nset.seed(42)  # Reproduzierbarkeit\nflights &lt;- \n  flights |&gt; \n  sample_n(size = 3e4)  # \"3e4\" hei√üt \"3 Mal 10 hoch 4\"\n\nAchtung: flights ist recht gro√ü; die Regressionsmodelle k√∂nnen leicht ein paar Hundert Megabyte gro√ü werden. Das bringt u.U. auch einen modernen Computer irgendwann ins Straucheln. Daher verringern wir aus Gr√ºnden der Einfachheit den Datensatz mit einem Zufallssample. Man beachte, dass die Pr√§zision der Ergebnisse h√∂her ist, wenn man nicht mit einem Zufallssample, sondern dem gesamten Datensatz arbeitet."
  },
  {
    "objectID": "posts/flights-delay-simplified/index.html#footnotes",
    "href": "posts/flights-delay-simplified/index.html#footnotes",
    "title": "flights-delay-simplified",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHintergrund ist, dass diese Fallstudie eine vereinfachte und verk√ºrzte Version einer √§hnlichen Fallstudie ist.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/penguins-stan-04a/index.html",
    "href": "posts/penguins-stan-04a/index.html",
    "title": "penguins-stan-04a",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nAufgabe:\nWie gro√ü ist die Wahrscheinlichkeit, dass der Effekt vorhanden ist (also gr√∂√üer als Null ist), die ‚ÄúEffektwahrscheinlichkeit‚Äù? Geben Sie die Wahrscheinlichkeit an.\nHinweise:\n\nNutzen Sie den Datensatz zu den Palmer Penguins.\nVerwenden Sie Methoden der Bayes-Statistik und die Software Stan.\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nWeitere Hinweise\n\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n359.9393\n0.95\n-210.59190\n927.8249\n0.89575\n1.000485\n4117.553\nnormal\n4201.754\n2004.8863\n\n\nbill_length_mm\n87.4472\n0.95\n74.55696\n100.2532\n1.00000\n1.000491\n4123.761\nnormal\n0.000\n367.2233\n\n\n\n\n\n\nETI:\n\neti(m1) |&gt; plot()\n\n\n\n\n\n\n\n\n         \n\n\nL√∂sung\nMan sieht im Diagramm direkt, dass 100% des Sch√§tzbereichs rechts von der Null ist. Daher ist die Effektwahrscheinlichkeit 100%.\nAlternativ bekommt man die Statistik auch mit parameters(), wie in der Tabelle oben in der Spalte pd ersichtlich.\nMit pd() kann man sich die Effektwahrscheinlichkeit (‚Äúprobability of direction‚Äù) ausgeben lassen:\n\npd(m1)\n\n\n\n\n\nParameter\npd\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.89575\nfixed\nconditional\n\n\nbill_length_mm\n1.00000\nfixed\nconditional\n\n\n\n\n\n\nMehr Informationen zu dieser Statistik findet sich hier oder hier.\nDie L√∂sung lautet also 1.\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html",
    "href": "posts/r-quiz/r-quiz.html",
    "title": "r-quiz",
    "section": "",
    "text": "ExerciseSolution\n\n\nDefine in R the variable age and assign the value 42.\n\n\n\nage &lt;- 42\n\nNote that spaces here are not mandatory, but useful."
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#define-a-variable",
    "href": "posts/r-quiz/r-quiz.html#define-a-variable",
    "title": "r-quiz",
    "section": "",
    "text": "ExerciseSolution\n\n\nDefine in R the variable age and assign the value 42.\n\n\n\nage &lt;- 42\n\nNote that spaces here are not mandatory, but useful."
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#define-a-variable-as-a-string",
    "href": "posts/r-quiz/r-quiz.html#define-a-variable-as-a-string",
    "title": "r-quiz",
    "section": "2 Define a variable as a string",
    "text": "2 Define a variable as a string\n\nExerciseSolution\n\n\nDefine in R the variable name and assign the value me.\n\n\n\nname &lt;- \"me\""
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#define-a-variable-by-another-variable",
    "href": "posts/r-quiz/r-quiz.html#define-a-variable-by-another-variable",
    "title": "r-quiz",
    "section": "3 Define a variable by another variable",
    "text": "3 Define a variable by another variable\n\nExerciseSolution\n\n\nDefine in R the variable name and assign the variable age.\n\n\n\nname &lt;- age"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#call-a-function",
    "href": "posts/r-quiz/r-quiz.html#call-a-function",
    "title": "r-quiz",
    "section": "4 Call a function",
    "text": "4 Call a function\n\nExerciseSolution\n\n\nAsk R what today‚Äôs date() is, that is, call a function.\n\n\n\ndate()\n\n[1] \"Fri Sep 19 16:51:59 2025\""
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#define-a-vector",
    "href": "posts/r-quiz/r-quiz.html#define-a-vector",
    "title": "r-quiz",
    "section": "5 Define a vector",
    "text": "5 Define a vector\n\nExerciseSolution\n\n\nDefine in R a vector x with the values 1,2,3 .\n\n\n\nx &lt;- c(1, 2, 3)"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#sum-up-vector",
    "href": "posts/r-quiz/r-quiz.html#sum-up-vector",
    "title": "r-quiz",
    "section": "6 Sum up vector",
    "text": "6 Sum up vector\n\nExerciseSolution\n\n\nDefine in R a vector x with the values 1,2,3 . Then sum up its values.\n\n\n\nx &lt;- c(1, 2, 3)\nsum(x)\n\n[1] 6"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#vector-wise-computation",
    "href": "posts/r-quiz/r-quiz.html#vector-wise-computation",
    "title": "r-quiz",
    "section": "7 Vector wise computation",
    "text": "7 Vector wise computation\n\nExerciseSolution\n\n\nSquare each value in the vector x.\n\n\n\nx^2\n\n[1] 1 4 9"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#vector-wise-computation-2",
    "href": "posts/r-quiz/r-quiz.html#vector-wise-computation-2",
    "title": "r-quiz",
    "section": "8 Vector wise computation 2",
    "text": "8 Vector wise computation 2\n\nExerciseSolution\n\n\nSquare each value in the vector x and sum up the values.\n\n\n\nsum(x^2)\n\n[1] 14"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#compute-the-variance",
    "href": "posts/r-quiz/r-quiz.html#compute-the-variance",
    "title": "r-quiz",
    "section": "9 Compute the variance",
    "text": "9 Compute the variance\n\nExerciseSolution\n\n\nCompute the variance of x using basic arithmetic.\n\n\n\n x &lt;- c(1, 2, 3)\n\nsum((x - mean(x))^2) / (length(x)-1)\n\n[1] 1\n\n # compare: \nvar(x) \n\n[1] 1"
  },
  {
    "objectID": "posts/r-quiz/r-quiz.html#work-with-na",
    "href": "posts/r-quiz/r-quiz.html#work-with-na",
    "title": "r-quiz",
    "section": "10 Work with NA",
    "text": "10 Work with NA\n\nExerciseSolution\n\n\nDefine the vector y with the values 1,2,NA. Compute the mean. Explain the results.\n\n\n\ny &lt;- c(1, 2, NA)\nmean(y)\n\n[1] NA\n\n\nNA (not available, ie., missing data) is contagious in R: If there‚Äôs a missing element, R will assume that something has gone wrong and will raise a red flag, i.e, give you a NA back."
  },
  {
    "objectID": "posts/germeval07/germeval07.html",
    "href": "posts/germeval07/germeval07.html",
    "title": "germeval07",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie deutsche Word-Vektoren f√ºr das Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie Wikipedia2Vec als Grundlage f√ºr die Wordembeddings in deutscher Sprache. Laden Sie die Daten herunter (Achtung: ca. 2.8 GB)."
  },
  {
    "objectID": "posts/germeval07/germeval07.html#deutsche-textvektoren-importieren",
    "href": "posts/germeval07/germeval07.html#deutsche-textvektoren-importieren",
    "title": "germeval07",
    "section": "Deutsche Textvektoren importieren",
    "text": "Deutsche Textvektoren importieren\n\nwiki_de_embeds_path &lt;- \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/dewiki_20180420_100d.txt\"\n\ntic()\nwiki_de_embeds &lt;- arrow::read_feather(file = \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/part-0.arrow\")\ntoc()\n\nnames(wiki_de_embeds)[1] &lt;- \"word\"\n\nwiki &lt;- as_tibble(wiki_de_embeds)\n\nDie Arrow-Datei ist viel schneller zu importieren als die Text-Datei.\n\ntic()\nwiki_de_embeds &lt;-\n  data.table::fread(file = wiki_de_embeds_path,\n                    sep = \" \",\n                    header = FALSE,\n                    showProgress = FALSE)  # progressbar\ntoc()\n\nAls Parquet-Datei speichern (effizienter):\n\ntic()\narrow::write_dataset(wiki_de_embeds, path = \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec\",\n                     format = \"arrow\")\ntoc()"
  },
  {
    "objectID": "posts/germeval07/germeval07.html#workflow",
    "href": "posts/germeval07/germeval07.html#workflow",
    "title": "germeval07",
    "section": "Workflow",
    "text": "Workflow\n\n# model:\nmod1 &lt;-\n  logistic_reg()\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  step_tokenize(text) %&gt;%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") |&gt; \n\n  step_word_embeddings(text,\n                       embeddings = wiki,\n                       aggregation = \"mean\") |&gt; \n  step_normalize(all_numeric_predictors()) \n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval07/germeval07.html#preppenbaken",
    "href": "posts/germeval07/germeval07.html#preppenbaken",
    "title": "germeval07",
    "section": "Preppen/Baken",
    "text": "Preppen/Baken\n\ntic()\nrec1_prepped &lt;- prep(rec1)\ntoc()\n\n\nd_train_baked &lt;-\n  bake(rec1_prepped, new_data = NULL)\n\nhead(d_train_baked)"
  },
  {
    "objectID": "posts/germeval07/germeval07.html#tuninigfitting",
    "href": "posts/germeval07/germeval07.html#tuninigfitting",
    "title": "germeval07",
    "section": "Tuninig/Fitting",
    "text": "Tuninig/Fitting\n\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit(data = d_train)\ntoc()\nbeep()\n\nAus Zeitgr√ºnden verzichten wir hier auf Tuning."
  },
  {
    "objectID": "posts/germeval07/germeval07.html#test-set-g√ºte",
    "href": "posts/germeval07/germeval07.html#test-set-g√ºte",
    "title": "germeval07",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(wf1_fit, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval07/germeval07.html#fazit",
    "href": "posts/germeval07/germeval07.html#fazit",
    "title": "germeval07",
    "section": "Fazit",
    "text": "Fazit\nwikipedia2vec ist f√ºr die deutsche Sprache vorgekocht. Das macht Sinn f√ºr einen deutschsprachigen Corpus.\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nstring"
  },
  {
    "objectID": "posts/stan_glm01a/index.html",
    "href": "posts/stan_glm01a/index.html",
    "title": "stan_glm01a",
    "section": "",
    "text": "Exercise\nGegeben dem folgenden Modell, geben Sie die verwendeten Prioris in statistischer Notation an.\n\nlibrary(rstanarm)\n\n\nmodel &lt;-\n  stan_glm(h ~ 1,\n           prior_intercept = normal(0,1),\n           prior_aux = exponential(0.1),\n           daten = meine_Daten\n  )\n\n         \n\n\nSolution\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(0, 1)\\)\nPrior f√ºr \\(\\sigma\\): \\(\\sigma \\sim \\text{Exponential}(0.1)\\)"
  },
  {
    "objectID": "posts/Var-vs-Stufe/Var-vs-Stufe.html",
    "href": "posts/Var-vs-Stufe/Var-vs-Stufe.html",
    "title": "Var-vs-Stufe",
    "section": "",
    "text": "F√ºr ein Forschungsprojekt hat ein Forschungsteam die Frage getestet, ob Personen, die einen animierten Graphen zu Auswirkungen von Stress gesehen haben danach eine h√∂here Motivation haben ihr Stresspensum anzugehen, als Personen, die einen statischen Graph gesehen haben. Dazu wurde jeweils in einem Fragebogen die Ver√§nderungsbereitschaft auf das Stressniveau angepasst abgefragt, dann den jeweiligen Graphen gezeigt und danach dieselben Fragen wie davor nochmals gestellt.\nZur Auswertung wurde nun zu jeder der Fragen zur Ver√§nderungsbereitschaft die Mittelwerte der Vor-sehen-des-Graphen-Gruppe von der Nach-sehen-des-Graphen-Gruppe abgezogen und diese Werte dann verglichen von dem animierten und dem statischen Graphen. Dabei konnte der gew√ºnschten Effekt deutlich erkannt werden, hypothesenkonform.\nNun kommt dem Forschungsteam folgender Zweifel auf:\nOder w√§re die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nJa, es w√§re richtig gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nNein, es w√§re falsch gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nBeide Sichtweisen sind m√∂glich (entweder jeweils als einzelne Variable oder als ingesamt eine einzelne Variable)\nAuf Basis des dargestellten Forschungsdesigns ist diese Frage nicht zu beantworten"
  },
  {
    "objectID": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist",
    "href": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist",
    "title": "Var-vs-Stufe",
    "section": "",
    "text": "Ja, es w√§re richtig gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nNein, es w√§re falsch gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nBeide Sichtweisen sind m√∂glich (entweder jeweils als einzelne Variable oder als ingesamt eine einzelne Variable)\nAuf Basis des dargestellten Forschungsdesigns ist diese Frage nicht zu beantworten"
  },
  {
    "objectID": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist-1",
    "href": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist-1",
    "title": "Var-vs-Stufe",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nfopro\nresearchdesign\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html",
    "href": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html",
    "title": "Verteilungen-Quiz-08",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\ge 115) \\approx 0.16\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist",
    "href": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist",
    "title": "Verteilungen-Quiz-08",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist-1",
    "title": "Verteilungen-Quiz-08",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Kennwert-robust2/Kennwert-robust2.html",
    "href": "posts/Kennwert-robust2/Kennwert-robust2.html",
    "title": "Kennwert-robust2",
    "section": "",
    "text": "Welcher der folgenden Kennwerte ist robust (im statistischen Sinn)?\n\n\n\nVarianz\nSchiefe\nSumme\nInterquartilsabstand\nKorrelation\nRegressionsgewicht"
  },
  {
    "objectID": "posts/Kennwert-robust2/Kennwert-robust2.html#answerlist",
    "href": "posts/Kennwert-robust2/Kennwert-robust2.html#answerlist",
    "title": "Kennwert-robust2",
    "section": "",
    "text": "Varianz\nSchiefe\nSumme\nInterquartilsabstand\nKorrelation\nRegressionsgewicht"
  },
  {
    "objectID": "posts/Kennwert-robust2/Kennwert-robust2.html#answerlist-1",
    "href": "posts/Kennwert-robust2/Kennwert-robust2.html#answerlist-1",
    "title": "Kennwert-robust2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\neda\nstreuungsma√ü\nvariability\nschoice"
  },
  {
    "objectID": "posts/Schiefe1/Schiefe1.html",
    "href": "posts/Schiefe1/Schiefe1.html",
    "title": "Schiefe1",
    "section": "",
    "text": "Welche der Abbildungen zeigt am deutlichsten eine bimodale Verteilung?\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/Schiefe1/Schiefe1.html#answerlist",
    "href": "posts/Schiefe1/Schiefe1.html#answerlist",
    "title": "Schiefe1",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/Schiefe1/Schiefe1.html#answerlist-1",
    "href": "posts/Schiefe1/Schiefe1.html#answerlist-1",
    "title": "Schiefe1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/eti-hdi/index.html",
    "href": "posts/eti-hdi/index.html",
    "title": "eti-hdi",
    "section": "",
    "text": "Eine Personalberatung pr√ºft Kandidatinnen f√ºr eine F√ºhrungsposition.\nEs wurden 10 Kandidatinnen gepr√ºft. Davon haben 10 die Pr√ºfung bestanden.\n\nn_success &lt;- 10\nn_trials  &lt;- 10\n\n\n\n\nlibrary(prada)  # f√ºr bayesbox\nlibrary(tidyverse)\nlibrary(knitr)  # sch√∂ne HTML-Tabellen\nlibrary(ggpubr)\nlibrary(easystats)  # f√ºr hdi, eti\n\nEs werden alle Parameterwerte von 0 bis 1 untersucht, mit einer Aufl√∂sung von 1%-Schritten:\n\np_grid &lt;- \n  seq(from = 0, to = 1, length.out = 101) |&gt; \n  # auf zwei Dezimalen runden\n  round(2)\n\np_grid\n\n  [1] 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14\n [16] 0.15 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29\n [31] 0.30 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.40 0.41 0.42 0.43 0.44\n [46] 0.45 0.46 0.47 0.48 0.49 0.50 0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59\n [61] 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74\n [76] 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89\n [91] 0.90 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99 1.00\n\n\nHier sind die Likelihoods, also die Wahrscheinlichkeiten der Daten gegeben jeweils eines Parameterwerts (einer Hypothese):\n\nL &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\nL\n\n  [1] 0.000000e+00 1.000000e-20 1.024000e-17 5.904900e-16 1.048576e-14\n  [6] 9.765625e-14 6.046618e-13 2.824752e-12 1.073742e-11 3.486784e-11\n [11] 1.000000e-10 2.593742e-10 6.191736e-10 1.378585e-09 2.892547e-09\n [16] 5.766504e-09 1.099512e-08 2.015994e-08 3.570467e-08 6.131066e-08\n [21] 1.024000e-07 1.667988e-07 2.655992e-07 4.142651e-07 6.340338e-07\n [26] 9.536743e-07 1.411671e-06 2.058911e-06 2.961968e-06 4.207072e-06\n [31] 5.904900e-06 8.196283e-06 1.125900e-05 1.531579e-05 2.064378e-05\n [36] 2.758547e-05 3.656158e-05 4.808584e-05 6.278212e-05 8.140406e-05\n [41] 1.048576e-04 1.342266e-04 1.708020e-04 2.161148e-04 2.719736e-04\n [46] 3.405063e-04 4.242075e-04 5.259913e-04 6.492506e-04 7.979227e-04\n [51] 9.765625e-04 1.190424e-03 1.445551e-03 1.748875e-03 2.108325e-03\n [56] 2.532952e-03 3.033055e-03 3.620333e-03 4.308042e-03 5.111168e-03\n [61] 6.046618e-03 7.133429e-03 8.392994e-03 9.849303e-03 1.152922e-02\n [66] 1.346274e-02 1.568337e-02 1.822838e-02 2.113923e-02 2.446194e-02\n [71] 2.824752e-02 3.255244e-02 3.743906e-02 4.297626e-02 4.923990e-02\n [76] 5.631351e-02 6.428889e-02 7.326680e-02 8.335776e-02 9.468276e-02\n [81] 1.073742e-01 1.215767e-01 1.374480e-01 1.551604e-01 1.749012e-01\n [86] 1.968744e-01 2.213016e-01 2.484234e-01 2.785010e-01 3.118172e-01\n [91] 3.486784e-01 3.894161e-01 4.343885e-01 4.839823e-01 5.386151e-01\n [96] 5.987369e-01 6.648326e-01 7.374241e-01 8.170728e-01 9.043821e-01\n[101] 1.000000e+00\n\n\nUnd hier ist die Bayesbox:\n\nbb &lt;- bayesbox(hyps = p_grid, priors = 1, liks = L)  # aus \"prada\"\n\nbb |&gt;   \n  kable(digits = 2)\n\n\n\n\nhyps\npriors\nliks\npost_unstand\npost_std\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.01\n1\n0.00\n0.00\n0.00\n\n\n0.02\n1\n0.00\n0.00\n0.00\n\n\n0.03\n1\n0.00\n0.00\n0.00\n\n\n0.04\n1\n0.00\n0.00\n0.00\n\n\n0.05\n1\n0.00\n0.00\n0.00\n\n\n0.06\n1\n0.00\n0.00\n0.00\n\n\n0.07\n1\n0.00\n0.00\n0.00\n\n\n0.08\n1\n0.00\n0.00\n0.00\n\n\n0.09\n1\n0.00\n0.00\n0.00\n\n\n0.10\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.12\n1\n0.00\n0.00\n0.00\n\n\n0.13\n1\n0.00\n0.00\n0.00\n\n\n0.14\n1\n0.00\n0.00\n0.00\n\n\n0.15\n1\n0.00\n0.00\n0.00\n\n\n0.16\n1\n0.00\n0.00\n0.00\n\n\n0.17\n1\n0.00\n0.00\n0.00\n\n\n0.18\n1\n0.00\n0.00\n0.00\n\n\n0.19\n1\n0.00\n0.00\n0.00\n\n\n0.20\n1\n0.00\n0.00\n0.00\n\n\n0.21\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.00\n\n\n0.23\n1\n0.00\n0.00\n0.00\n\n\n0.24\n1\n0.00\n0.00\n0.00\n\n\n0.25\n1\n0.00\n0.00\n0.00\n\n\n0.26\n1\n0.00\n0.00\n0.00\n\n\n0.27\n1\n0.00\n0.00\n0.00\n\n\n0.28\n1\n0.00\n0.00\n0.00\n\n\n0.29\n1\n0.00\n0.00\n0.00\n\n\n0.30\n1\n0.00\n0.00\n0.00\n\n\n0.31\n1\n0.00\n0.00\n0.00\n\n\n0.32\n1\n0.00\n0.00\n0.00\n\n\n0.33\n1\n0.00\n0.00\n0.00\n\n\n0.34\n1\n0.00\n0.00\n0.00\n\n\n0.35\n1\n0.00\n0.00\n0.00\n\n\n0.36\n1\n0.00\n0.00\n0.00\n\n\n0.37\n1\n0.00\n0.00\n0.00\n\n\n0.38\n1\n0.00\n0.00\n0.00\n\n\n0.39\n1\n0.00\n0.00\n0.00\n\n\n0.40\n1\n0.00\n0.00\n0.00\n\n\n0.41\n1\n0.00\n0.00\n0.00\n\n\n0.42\n1\n0.00\n0.00\n0.00\n\n\n0.43\n1\n0.00\n0.00\n0.00\n\n\n0.44\n1\n0.00\n0.00\n0.00\n\n\n0.45\n1\n0.00\n0.00\n0.00\n\n\n0.46\n1\n0.00\n0.00\n0.00\n\n\n0.47\n1\n0.00\n0.00\n0.00\n\n\n0.48\n1\n0.00\n0.00\n0.00\n\n\n0.49\n1\n0.00\n0.00\n0.00\n\n\n0.50\n1\n0.00\n0.00\n0.00\n\n\n0.51\n1\n0.00\n0.00\n0.00\n\n\n0.52\n1\n0.00\n0.00\n0.00\n\n\n0.53\n1\n0.00\n0.00\n0.00\n\n\n0.54\n1\n0.00\n0.00\n0.00\n\n\n0.55\n1\n0.00\n0.00\n0.00\n\n\n0.56\n1\n0.00\n0.00\n0.00\n\n\n0.57\n1\n0.00\n0.00\n0.00\n\n\n0.58\n1\n0.00\n0.00\n0.00\n\n\n0.59\n1\n0.01\n0.01\n0.00\n\n\n0.60\n1\n0.01\n0.01\n0.00\n\n\n0.61\n1\n0.01\n0.01\n0.00\n\n\n0.62\n1\n0.01\n0.01\n0.00\n\n\n0.63\n1\n0.01\n0.01\n0.00\n\n\n0.64\n1\n0.01\n0.01\n0.00\n\n\n0.65\n1\n0.01\n0.01\n0.00\n\n\n0.66\n1\n0.02\n0.02\n0.00\n\n\n0.67\n1\n0.02\n0.02\n0.00\n\n\n0.68\n1\n0.02\n0.02\n0.00\n\n\n0.69\n1\n0.02\n0.02\n0.00\n\n\n0.70\n1\n0.03\n0.03\n0.00\n\n\n0.71\n1\n0.03\n0.03\n0.00\n\n\n0.72\n1\n0.04\n0.04\n0.00\n\n\n0.73\n1\n0.04\n0.04\n0.00\n\n\n0.74\n1\n0.05\n0.05\n0.01\n\n\n0.75\n1\n0.06\n0.06\n0.01\n\n\n0.76\n1\n0.06\n0.06\n0.01\n\n\n0.77\n1\n0.07\n0.07\n0.01\n\n\n0.78\n1\n0.08\n0.08\n0.01\n\n\n0.79\n1\n0.09\n0.09\n0.01\n\n\n0.80\n1\n0.11\n0.11\n0.01\n\n\n0.81\n1\n0.12\n0.12\n0.01\n\n\n0.82\n1\n0.14\n0.14\n0.01\n\n\n0.83\n1\n0.16\n0.16\n0.02\n\n\n0.84\n1\n0.17\n0.17\n0.02\n\n\n0.85\n1\n0.20\n0.20\n0.02\n\n\n0.86\n1\n0.22\n0.22\n0.02\n\n\n0.87\n1\n0.25\n0.25\n0.03\n\n\n0.88\n1\n0.28\n0.28\n0.03\n\n\n0.89\n1\n0.31\n0.31\n0.03\n\n\n0.90\n1\n0.35\n0.35\n0.04\n\n\n0.91\n1\n0.39\n0.39\n0.04\n\n\n0.92\n1\n0.43\n0.43\n0.05\n\n\n0.93\n1\n0.48\n0.48\n0.05\n\n\n0.94\n1\n0.54\n0.54\n0.06\n\n\n0.95\n1\n0.60\n0.60\n0.06\n\n\n0.96\n1\n0.66\n0.66\n0.07\n\n\n0.97\n1\n0.74\n0.74\n0.08\n\n\n0.98\n1\n0.82\n0.82\n0.09\n\n\n0.99\n1\n0.90\n0.90\n0.09\n\n\n1.00\n1\n1.00\n1.00\n0.10\n\n\n\n\n\nUnd hier ist die Post-Verteilung:\n\nggline(bb, x = \"hyps\", y = \"post_std\") \n\n\n\n\n\n\n\n\nDaraus ziehen wir Stichproben:\n\npost_samples &lt;-\n  bb |&gt; \n  slice_sample(n = 10000,\n               weight_by = post_std,\n               replace = TRUE)\n\nUnd hier ist die Post-Verteilung auf Basis der Stichproben visualisiert:\n\npost_samples |&gt; \n  count(hyps) |&gt; \n  ggbarplot(x = \"hyps\", y = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn diesem Fall ist die Posterior-Verteilung schief (rechtssteil), wie man im Diagramm sieht.\nAufgabe W√ºrden in diesem Fall eine ETI- bzw. ein HDI zum gleichen Ergebnis kommen? Welches von beiden Intervallen w√ºrden Sie vorziehen? Begr√ºnden Sie.\nTipp: Nutzen Sie das Diagramm der Post-Verteilung zur L√∂sung der Aufgabe."
  },
  {
    "objectID": "posts/eti-hdi/index.html#setup",
    "href": "posts/eti-hdi/index.html#setup",
    "title": "eti-hdi",
    "section": "",
    "text": "library(prada)  # f√ºr bayesbox\nlibrary(tidyverse)\nlibrary(knitr)  # sch√∂ne HTML-Tabellen\nlibrary(ggpubr)\nlibrary(easystats)  # f√ºr hdi, eti\n\nEs werden alle Parameterwerte von 0 bis 1 untersucht, mit einer Aufl√∂sung von 1%-Schritten:\n\np_grid &lt;- \n  seq(from = 0, to = 1, length.out = 101) |&gt; \n  # auf zwei Dezimalen runden\n  round(2)\n\np_grid\n\n  [1] 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14\n [16] 0.15 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29\n [31] 0.30 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.40 0.41 0.42 0.43 0.44\n [46] 0.45 0.46 0.47 0.48 0.49 0.50 0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59\n [61] 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74\n [76] 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89\n [91] 0.90 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99 1.00\n\n\nHier sind die Likelihoods, also die Wahrscheinlichkeiten der Daten gegeben jeweils eines Parameterwerts (einer Hypothese):\n\nL &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\nL\n\n  [1] 0.000000e+00 1.000000e-20 1.024000e-17 5.904900e-16 1.048576e-14\n  [6] 9.765625e-14 6.046618e-13 2.824752e-12 1.073742e-11 3.486784e-11\n [11] 1.000000e-10 2.593742e-10 6.191736e-10 1.378585e-09 2.892547e-09\n [16] 5.766504e-09 1.099512e-08 2.015994e-08 3.570467e-08 6.131066e-08\n [21] 1.024000e-07 1.667988e-07 2.655992e-07 4.142651e-07 6.340338e-07\n [26] 9.536743e-07 1.411671e-06 2.058911e-06 2.961968e-06 4.207072e-06\n [31] 5.904900e-06 8.196283e-06 1.125900e-05 1.531579e-05 2.064378e-05\n [36] 2.758547e-05 3.656158e-05 4.808584e-05 6.278212e-05 8.140406e-05\n [41] 1.048576e-04 1.342266e-04 1.708020e-04 2.161148e-04 2.719736e-04\n [46] 3.405063e-04 4.242075e-04 5.259913e-04 6.492506e-04 7.979227e-04\n [51] 9.765625e-04 1.190424e-03 1.445551e-03 1.748875e-03 2.108325e-03\n [56] 2.532952e-03 3.033055e-03 3.620333e-03 4.308042e-03 5.111168e-03\n [61] 6.046618e-03 7.133429e-03 8.392994e-03 9.849303e-03 1.152922e-02\n [66] 1.346274e-02 1.568337e-02 1.822838e-02 2.113923e-02 2.446194e-02\n [71] 2.824752e-02 3.255244e-02 3.743906e-02 4.297626e-02 4.923990e-02\n [76] 5.631351e-02 6.428889e-02 7.326680e-02 8.335776e-02 9.468276e-02\n [81] 1.073742e-01 1.215767e-01 1.374480e-01 1.551604e-01 1.749012e-01\n [86] 1.968744e-01 2.213016e-01 2.484234e-01 2.785010e-01 3.118172e-01\n [91] 3.486784e-01 3.894161e-01 4.343885e-01 4.839823e-01 5.386151e-01\n [96] 5.987369e-01 6.648326e-01 7.374241e-01 8.170728e-01 9.043821e-01\n[101] 1.000000e+00\n\n\nUnd hier ist die Bayesbox:\n\nbb &lt;- bayesbox(hyps = p_grid, priors = 1, liks = L)  # aus \"prada\"\n\nbb |&gt;   \n  kable(digits = 2)\n\n\n\n\nhyps\npriors\nliks\npost_unstand\npost_std\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.01\n1\n0.00\n0.00\n0.00\n\n\n0.02\n1\n0.00\n0.00\n0.00\n\n\n0.03\n1\n0.00\n0.00\n0.00\n\n\n0.04\n1\n0.00\n0.00\n0.00\n\n\n0.05\n1\n0.00\n0.00\n0.00\n\n\n0.06\n1\n0.00\n0.00\n0.00\n\n\n0.07\n1\n0.00\n0.00\n0.00\n\n\n0.08\n1\n0.00\n0.00\n0.00\n\n\n0.09\n1\n0.00\n0.00\n0.00\n\n\n0.10\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.12\n1\n0.00\n0.00\n0.00\n\n\n0.13\n1\n0.00\n0.00\n0.00\n\n\n0.14\n1\n0.00\n0.00\n0.00\n\n\n0.15\n1\n0.00\n0.00\n0.00\n\n\n0.16\n1\n0.00\n0.00\n0.00\n\n\n0.17\n1\n0.00\n0.00\n0.00\n\n\n0.18\n1\n0.00\n0.00\n0.00\n\n\n0.19\n1\n0.00\n0.00\n0.00\n\n\n0.20\n1\n0.00\n0.00\n0.00\n\n\n0.21\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.00\n\n\n0.23\n1\n0.00\n0.00\n0.00\n\n\n0.24\n1\n0.00\n0.00\n0.00\n\n\n0.25\n1\n0.00\n0.00\n0.00\n\n\n0.26\n1\n0.00\n0.00\n0.00\n\n\n0.27\n1\n0.00\n0.00\n0.00\n\n\n0.28\n1\n0.00\n0.00\n0.00\n\n\n0.29\n1\n0.00\n0.00\n0.00\n\n\n0.30\n1\n0.00\n0.00\n0.00\n\n\n0.31\n1\n0.00\n0.00\n0.00\n\n\n0.32\n1\n0.00\n0.00\n0.00\n\n\n0.33\n1\n0.00\n0.00\n0.00\n\n\n0.34\n1\n0.00\n0.00\n0.00\n\n\n0.35\n1\n0.00\n0.00\n0.00\n\n\n0.36\n1\n0.00\n0.00\n0.00\n\n\n0.37\n1\n0.00\n0.00\n0.00\n\n\n0.38\n1\n0.00\n0.00\n0.00\n\n\n0.39\n1\n0.00\n0.00\n0.00\n\n\n0.40\n1\n0.00\n0.00\n0.00\n\n\n0.41\n1\n0.00\n0.00\n0.00\n\n\n0.42\n1\n0.00\n0.00\n0.00\n\n\n0.43\n1\n0.00\n0.00\n0.00\n\n\n0.44\n1\n0.00\n0.00\n0.00\n\n\n0.45\n1\n0.00\n0.00\n0.00\n\n\n0.46\n1\n0.00\n0.00\n0.00\n\n\n0.47\n1\n0.00\n0.00\n0.00\n\n\n0.48\n1\n0.00\n0.00\n0.00\n\n\n0.49\n1\n0.00\n0.00\n0.00\n\n\n0.50\n1\n0.00\n0.00\n0.00\n\n\n0.51\n1\n0.00\n0.00\n0.00\n\n\n0.52\n1\n0.00\n0.00\n0.00\n\n\n0.53\n1\n0.00\n0.00\n0.00\n\n\n0.54\n1\n0.00\n0.00\n0.00\n\n\n0.55\n1\n0.00\n0.00\n0.00\n\n\n0.56\n1\n0.00\n0.00\n0.00\n\n\n0.57\n1\n0.00\n0.00\n0.00\n\n\n0.58\n1\n0.00\n0.00\n0.00\n\n\n0.59\n1\n0.01\n0.01\n0.00\n\n\n0.60\n1\n0.01\n0.01\n0.00\n\n\n0.61\n1\n0.01\n0.01\n0.00\n\n\n0.62\n1\n0.01\n0.01\n0.00\n\n\n0.63\n1\n0.01\n0.01\n0.00\n\n\n0.64\n1\n0.01\n0.01\n0.00\n\n\n0.65\n1\n0.01\n0.01\n0.00\n\n\n0.66\n1\n0.02\n0.02\n0.00\n\n\n0.67\n1\n0.02\n0.02\n0.00\n\n\n0.68\n1\n0.02\n0.02\n0.00\n\n\n0.69\n1\n0.02\n0.02\n0.00\n\n\n0.70\n1\n0.03\n0.03\n0.00\n\n\n0.71\n1\n0.03\n0.03\n0.00\n\n\n0.72\n1\n0.04\n0.04\n0.00\n\n\n0.73\n1\n0.04\n0.04\n0.00\n\n\n0.74\n1\n0.05\n0.05\n0.01\n\n\n0.75\n1\n0.06\n0.06\n0.01\n\n\n0.76\n1\n0.06\n0.06\n0.01\n\n\n0.77\n1\n0.07\n0.07\n0.01\n\n\n0.78\n1\n0.08\n0.08\n0.01\n\n\n0.79\n1\n0.09\n0.09\n0.01\n\n\n0.80\n1\n0.11\n0.11\n0.01\n\n\n0.81\n1\n0.12\n0.12\n0.01\n\n\n0.82\n1\n0.14\n0.14\n0.01\n\n\n0.83\n1\n0.16\n0.16\n0.02\n\n\n0.84\n1\n0.17\n0.17\n0.02\n\n\n0.85\n1\n0.20\n0.20\n0.02\n\n\n0.86\n1\n0.22\n0.22\n0.02\n\n\n0.87\n1\n0.25\n0.25\n0.03\n\n\n0.88\n1\n0.28\n0.28\n0.03\n\n\n0.89\n1\n0.31\n0.31\n0.03\n\n\n0.90\n1\n0.35\n0.35\n0.04\n\n\n0.91\n1\n0.39\n0.39\n0.04\n\n\n0.92\n1\n0.43\n0.43\n0.05\n\n\n0.93\n1\n0.48\n0.48\n0.05\n\n\n0.94\n1\n0.54\n0.54\n0.06\n\n\n0.95\n1\n0.60\n0.60\n0.06\n\n\n0.96\n1\n0.66\n0.66\n0.07\n\n\n0.97\n1\n0.74\n0.74\n0.08\n\n\n0.98\n1\n0.82\n0.82\n0.09\n\n\n0.99\n1\n0.90\n0.90\n0.09\n\n\n1.00\n1\n1.00\n1.00\n0.10\n\n\n\n\n\nUnd hier ist die Post-Verteilung:\n\nggline(bb, x = \"hyps\", y = \"post_std\") \n\n\n\n\n\n\n\n\nDaraus ziehen wir Stichproben:\n\npost_samples &lt;-\n  bb |&gt; \n  slice_sample(n = 10000,\n               weight_by = post_std,\n               replace = TRUE)\n\nUnd hier ist die Post-Verteilung auf Basis der Stichproben visualisiert:\n\npost_samples |&gt; \n  count(hyps) |&gt; \n  ggbarplot(x = \"hyps\", y = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn diesem Fall ist die Posterior-Verteilung schief (rechtssteil), wie man im Diagramm sieht.\nAufgabe W√ºrden in diesem Fall eine ETI- bzw. ein HDI zum gleichen Ergebnis kommen? Welches von beiden Intervallen w√ºrden Sie vorziehen? Begr√ºnden Sie.\nTipp: Nutzen Sie das Diagramm der Post-Verteilung zur L√∂sung der Aufgabe."
  },
  {
    "objectID": "posts/Cluster01/Cluster01.html",
    "href": "posts/Cluster01/Cluster01.html",
    "title": "Cluster01",
    "section": "",
    "text": "Aufgabe\nGegeben seien zwei Punkte im 3D-Raum:\n\\[P_1(0,0,0)\\] \\[P_2(3,4,12)\\]\nBerechnen Sie den euklidischen Abstand der beiden Punkte (bzw. den Abstand von \\(P_2\\) vom Ursprung)!\n         \n\n\nL√∂sung\nDer Abstand ist so definiert:\n\\[d = \\sqrt{a^2 + b^2 + c+2}\\]\n\nergebnis &lt;- sqrt(3^2 + 4^2 + 12^2)\nergebnis\n\n[1] 13\n\n\n\nCategories:\nnum"
  },
  {
    "objectID": "posts/wskt-schluckspecht2a/index.html",
    "href": "posts/wskt-schluckspecht2a/index.html",
    "title": "Wskt-Schluckspecht2a",
    "section": "",
    "text": "Gepr√ºft werden soll folgende Hypothese:\n\nAutos mit wenig PS sind sparsamer als Autos mit viel PS.\n\nDaf√ºr ist folgende Analyse gegeben.\n\n\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(mtcars)\n\n\n\n\nDie Variable mpg (Miles per Gallone) misst die Spritsparsamkeit.\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{mpg}_{PS=1} &lt; \\text{mpg}_{PS=0},\\]\n‚ÄúDie mittlere Spritsparsamkeit von Autos mit viel PS ist kleiner als die von Autos mit viel PS‚Äù.\nDabei meint \\(PS=0\\) die Autos mit wenig PS (und \\(PS=1\\) die Autos mit viel PS).\nMan beachte, dass man i.d.R. Hypothesen zum Mittelwert formulieren m√∂chte, nicht allgemein f√ºr alle Autos.\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!\n\n\n\n\nWir definieren PS als eine bin√§re Variable, die angibt, ob ein Auto mehr oder weniger PS hat als der Median der PS-Werte:\n\nmtcars &lt;-\n  mtcars |&gt; \n  mutate(PS_high = case_when(\n    hp &gt; median(hp) ~ TRUE,\n    hp &lt;= median(hp) ~ FALSE\n  )) |&gt; \n  mutate(PS_high = as.factor(PS_high))\n\n\n\n\n\nm &lt;- stan_glm(mpg ~ PS_high,  # Regressionsformel\n              data = mtcars,  # Datensatz\n              refresh = 0,  # Nicht so viel Detail-Ausgabe\n              seed = 42)  # Reproduzierbarkeit\n\nHier sind die Modellparameter:\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n24.219612\n0.95\n22.07170\n26.170915\n1\n1.0007744\n3505.490\nnormal\n20.09062\n15.06737\n\n\nPS_highTRUE\n-8.802191\n0.95\n-11.61645\n-5.804179\n1\n0.9995466\n3526.436\nnormal\n0.00000\n29.71825\n\n\n\n\n\n\nDer Effekt von PS ist negativ, was bedeutet, dass Autos der Gruppe PS=1 einen um ca. 9 Meilen geringeren MPG-Wert haben als Autos der Gruppe PS=0. Das bedeutet, dass Autos mit wenig PS sparsamer sind (als Autos mit viel PS).\nUmgekehrt: Autos mit viel PS einen h√∂heren Spritverbrauch haben als Autos mit wenig PS.\nMan beachte, dass in der Zeile PS_highTRUE der Effekt von PS=1 steht, also der Effekt von Autos mit viel PS. Der Effekt besteht im Unterschied zum Mittelwert der Autos mit wenig PS, der in der Zeile des Achsenabschnitts (Intercept) dargestellt ist.\n\n\n\nHier ist das HDI (95%) zum Effekt von PS:\n\nhdi(m) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgabe\n\nSprechen die Ergebnisse daf√ºr, dass Autos mit wenig PS einen geringen Spritverbrauch haben als Autos mit wenig PS? Begr√ºnden Sie.\nWie hoch ist die Wahrscheinlichkeit, dass die Hypothese wahr ist (laut unserem Modell)?\nWas ist Ihr Punktsch√§tzer f√ºr den Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS?\nMit einer Wahrscheinlichkeit von 95% liegt der Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS zwischen welchen Werten (laut unserem Modell)?\nGeben Sie die Skalenniveaus der Variablen in der Regressionsformel an."
  },
  {
    "objectID": "posts/wskt-schluckspecht2a/index.html#setup",
    "href": "posts/wskt-schluckspecht2a/index.html#setup",
    "title": "Wskt-Schluckspecht2a",
    "section": "",
    "text": "library(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/wskt-schluckspecht2a/index.html#modell-und-hypothese",
    "href": "posts/wskt-schluckspecht2a/index.html#modell-und-hypothese",
    "title": "Wskt-Schluckspecht2a",
    "section": "",
    "text": "Die Variable mpg (Miles per Gallone) misst die Spritsparsamkeit.\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{mpg}_{PS=1} &lt; \\text{mpg}_{PS=0},\\]\n‚ÄúDie mittlere Spritsparsamkeit von Autos mit viel PS ist kleiner als die von Autos mit viel PS‚Äù.\nDabei meint \\(PS=0\\) die Autos mit wenig PS (und \\(PS=1\\) die Autos mit viel PS).\nMan beachte, dass man i.d.R. Hypothesen zum Mittelwert formulieren m√∂chte, nicht allgemein f√ºr alle Autos.\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!"
  },
  {
    "objectID": "posts/wskt-schluckspecht2a/index.html#vorverarbeitung",
    "href": "posts/wskt-schluckspecht2a/index.html#vorverarbeitung",
    "title": "Wskt-Schluckspecht2a",
    "section": "",
    "text": "Wir definieren PS als eine bin√§re Variable, die angibt, ob ein Auto mehr oder weniger PS hat als der Median der PS-Werte:\n\nmtcars &lt;-\n  mtcars |&gt; \n  mutate(PS_high = case_when(\n    hp &gt; median(hp) ~ TRUE,\n    hp &lt;= median(hp) ~ FALSE\n  )) |&gt; \n  mutate(PS_high = as.factor(PS_high))"
  },
  {
    "objectID": "posts/wskt-schluckspecht2a/index.html#modell-berechnen",
    "href": "posts/wskt-schluckspecht2a/index.html#modell-berechnen",
    "title": "Wskt-Schluckspecht2a",
    "section": "",
    "text": "m &lt;- stan_glm(mpg ~ PS_high,  # Regressionsformel\n              data = mtcars,  # Datensatz\n              refresh = 0,  # Nicht so viel Detail-Ausgabe\n              seed = 42)  # Reproduzierbarkeit\n\nHier sind die Modellparameter:\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n24.219612\n0.95\n22.07170\n26.170915\n1\n1.0007744\n3505.490\nnormal\n20.09062\n15.06737\n\n\nPS_highTRUE\n-8.802191\n0.95\n-11.61645\n-5.804179\n1\n0.9995466\n3526.436\nnormal\n0.00000\n29.71825\n\n\n\n\n\n\nDer Effekt von PS ist negativ, was bedeutet, dass Autos der Gruppe PS=1 einen um ca. 9 Meilen geringeren MPG-Wert haben als Autos der Gruppe PS=0. Das bedeutet, dass Autos mit wenig PS sparsamer sind (als Autos mit viel PS).\nUmgekehrt: Autos mit viel PS einen h√∂heren Spritverbrauch haben als Autos mit wenig PS.\nMan beachte, dass in der Zeile PS_highTRUE der Effekt von PS=1 steht, also der Effekt von Autos mit viel PS. Der Effekt besteht im Unterschied zum Mittelwert der Autos mit wenig PS, der in der Zeile des Achsenabschnitts (Intercept) dargestellt ist."
  },
  {
    "objectID": "posts/wskt-schluckspecht2a/index.html#post-verteilung-auslesen",
    "href": "posts/wskt-schluckspecht2a/index.html#post-verteilung-auslesen",
    "title": "Wskt-Schluckspecht2a",
    "section": "",
    "text": "Hier ist das HDI (95%) zum Effekt von PS:\n\nhdi(m) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgabe\n\nSprechen die Ergebnisse daf√ºr, dass Autos mit wenig PS einen geringen Spritverbrauch haben als Autos mit wenig PS? Begr√ºnden Sie.\nWie hoch ist die Wahrscheinlichkeit, dass die Hypothese wahr ist (laut unserem Modell)?\nWas ist Ihr Punktsch√§tzer f√ºr den Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS?\nMit einer Wahrscheinlichkeit von 95% liegt der Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS zwischen welchen Werten (laut unserem Modell)?\nGeben Sie die Skalenniveaus der Variablen in der Regressionsformel an."
  },
  {
    "objectID": "posts/gem-wskt1/gem-wskt1.html",
    "href": "posts/gem-wskt1/gem-wskt1.html",
    "title": "Gem-Wskt1",
    "section": "",
    "text": "Exercise\nProf.¬†S√º√ü untersucht eine seiner Lieblingsfragen: Wie viel bringt das Lernen auf eine Klausur? Dabei konzentriert er sich auf das Fach Statistik (es gef√§llt ihm gut). In einer aktuellen Untersuchung hat er \\(n=90\\) Studierende untersucht (s. Tabelle und Diagramm) und jeweils erfasst, ob die Person die Klausur bestanden (\\(B\\)) hat oder durchgefallen (\\(\\neg B\\)) ist. Im Hinblick auf das Lernen, \\(L\\) (wie viel die Person gelernt hat) hat er zwei Gruppen unterschieden: Die ‚ÄúViel-Lerner‚Äù (VL) und die ‚ÄúWenig-Lerner‚Äù (WL).\nAufgabe: Berechnen Sie die folgende: gemeinsame Wahrscheinlichkeit: p(Durchfallen UND Weniglerner).\nBeispiel: Wenn Sie ausrechnen, dass die Wahrscheinlichkeit bei 42 Prozentpunkten liegt, so geben Sie ein: 0,42 bzw. 0.42 (das Dezimalzeichen ist abh√§ngig von Ihren Spracheinstellungen).\n\nGeben Sie nur eine Zahl ein (ohne Prozentzeichen o.√Ñ.), z.B. 0,42.\nAndere Angaben k√∂nnen u.U. nicht gewertet werden.\nRunden Sie auf zwei Dezimalstellen.\nAchten Sie darauf, das korrekte Dezimaltrennzeichen einzugeben; auf Ger√§ten mit deutscher Spracheinstellung ist dies oft ein Komma.\n\nDas folgende Diagramm zeigt die H√§ufigkeiten pro Gruppe:\n\n\n\n\n\n\n\n\n\nHier ist die Kontingenztabelle mit den H√§ufigkeiten pro Gruppe:\nprobs_sample %&gt;% \n  select(Lerntyp, Klausurergebnis, n) %&gt;% \n  pivot_wider(names_from = Klausurergebnis, \n              values_from = n) %&gt;% \n  gt() \n\n\n\n\n\n\nLerntyp\nBestehen\nDurchfallen\n\n\n\n\nViellerner\n43\n20\n\n\nWeniglerner\n16\n11\n\n\n\n\n\n         \n\n\nSolution\nDie gemeinsame Wahrscheinlichkeit betr√§gt 0.12.\n\n\n\n\n\n\n\n\nLerntyp\nKlausurergebnis\nn\nn_group\nprop_conditional_group\njoint_prob\n\n\n\n\nWeniglerner\nDurchfallen\n11\n27\n0.41\n0.12\n\n\n\n\n\n\n\nDie gemeinsame Wahrscheinlichkeit berechnet sich hier als der Quotient der Zellenh√§ufigkeit und der Gesamth√§ufigkeit.\n\nCategories:\n\nprobability"
  },
  {
    "objectID": "posts/fattails01/fattails01.html",
    "href": "posts/fattails01/fattails01.html",
    "title": "fattails01",
    "section": "",
    "text": "Exercise\nIn seinem Buch ‚ÄúStatistical Consequences of Fat Tails‚Äù schreibt der Autor, Nassim Taleb (S. 53):\n\nIn the summer of 1998, the hedge fund called ‚ÄúLong Term Capital Management‚Äù (LTCM) proved to have a very short life; it went bust from some deviations in the markets ‚Äìthose ‚Äúof an unexpected nature‚Äù. The loss was a yuuuge deal because two of the partners received the Swedish Riksbank Prize, marketed as the ‚ÄúNobel‚Äù in economics. (‚Ä¶) At least two of the partners made the statement that it was a ‚Äú10 sigma‚Äù event (10 standard deviations), hence they should be absolved of all accusations of incompetence (I was Ô¨Årst hand witness of two such statements).\n\nWir testen in diesem Zusammenhang zwei Hypothesen: \\(H_N\\), dass der Finanzmarkt normalverteilt ist und \\(H_F\\), dass die Variable fat tailed ist, also nicht normalverteilt, sondern einer Verteilung entspringt, in der ‚ÄúExtremereignisse‚Äù √ºblicher sind als in einer Normalverteilung.\nUm die Fat-Tails-Verteilung mit \\(n=100\\) zu simulieren, nutzen wir hier folgende Funktion:\n\nfat_tail_data &lt;- rt(n = 100, df = 2)\nfat_tail_data\n\n  [1]  1.07191553  0.72657936 -2.80806303 -0.85734696 -1.04171088 -0.28511071\n  [7] -2.75731766  3.40892560 -0.04349465  0.47287150  0.45974792 -1.46049304\n [13] -3.74368779  2.04522523 -0.66975671  4.07853948 -1.17612519  0.38781548\n [19] -0.33177745  1.65383190 -1.26904428  0.27299761  0.73593247  4.61849952\n [25] -1.44744698  0.50048936  0.43025422  0.82865545 -0.29585177  1.45277039\n [31] -0.19685570  2.03453595 -2.80819124 -1.23728166  1.68274260  0.07762617\n [37]  1.93997804  1.42263539  0.29633265 -1.59313972  1.92145539  1.34359698\n [43] -1.06202057  1.06301775 -1.18618803 -0.84320470  0.30827389  0.30204104\n [49]  0.23887092 -0.24805784  0.73815822  0.95554468  0.25865658  0.43817601\n [55] -1.19220151  2.63504876  2.43347344 -0.55008682  0.45452923 -0.68099639\n [61] -1.16186463 -1.07633371 -2.51757583  0.26391561  2.89981158 -0.51761706\n [67]  0.35357062  1.47791202  0.66371887  0.02602585  0.64872915  0.06521705\n [73] -0.82166280 -1.35420194 -0.46883260 -3.74712138 -0.36786794 -1.32467679\n [79]  0.52858969 -4.23238733 -0.36714337  1.91162691  0.65455221 -2.27650824\n [85] -1.62695648 -0.01502936 -1.63442072 -0.39442218  0.02307418 -0.43621203\n [91]  5.01808414  2.40812328  0.94164588  1.61395555  1.23642268  1.41891769\n [97] -1.24735187 -7.22070070  1.36514248 -0.05180149\n\n\nDabei bedeutet df = 2, dass die Verteilung sehr randlastig (fat tailed) sein soll (genauer gesagt eine t-Verteilung mit zwei Freiheitsgraden). Details zu dieser R-Funktion sollen uns hier nicht interessieren. Nur f√ºr diejenigen, die neugierig sind: r steht f√ºr random, also eine Zufallszahl. Diese soll aus der sog. t-Verteilung mit df=2 stammen. Das ist, einfach gesagt, eine ‚Äúplattgedr√ºckte‚Äù Normalverteilung, also eine Verteilung mit mehr Verteilung in den R√§ndern als die Normalverteilung.\nBerechnen wir die Wahrscheinlichkeit, dass die Daten einer Normalverteilung entspringen (und nicht der Fat-Tail-Verteilung).\nDie Wahrscheinlichkeit eines 10-Sigma-Events ist √ºbrigens ‚Ä¶ klein. Taleb berichtet sie mit \\(1.31 \\cdot 10^{-23}\\):\n\nL_norm &lt;- 1.31e-23\n\nDas ist eine Zahl mit 23 Nullen hinter dem Komma und vor der Eins: 0.0000000000000000000000131.\nF√ºr die t-Verteilung ist der entsprechende Wert:\n\nL_fat &lt;- 1 - pt(q = 10, df = 2)\nL_fat\n\n[1] 0.004926229\n\n\nAuch hier soll der Befehl pt nicht interessieren. Nur f√ºr die Neugierigen: p steht f√ºr probability, t f√ºr die t-Verteilung. Der Befehl gibt uns also die Wahrscheintlichkeit, \\(p\\), f√ºr ein bestimmten Quartil, \\(q\\), aus einer t-Verteilung mit 2 Freiheitsgraden.\nWie hoch ist die Post-Wahrscheinlichkeit, dass die Variable normalverteilt ist?\nHinweise:\n\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nApriori sollen uns beide Hypothesen gleich plausibel sein.\n\n\n\nAnswerlist\n\nkleiner als 50%\nkleiner als 5%\nkleiner als 0.5%\nkleiner als 0.05%\nkleiner als 0.005%\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nErstellen wir erstmal den ersten Teil einer Bayes-Box:\n\nd &lt;-\n  tibble(H = c(\"Normalverteilt\", \"Randlastig verteilt\"),\n         Prior = c(1,1))\n\nd\n\n# A tibble: 2 √ó 2\n  H                   Prior\n  &lt;chr&gt;               &lt;dbl&gt;\n1 Normalverteilt          1\n2 Randlastig verteilt     1\n\n\nDann f√ºgen wir den Likelihood jeder Hypothese dazu:\n\nd &lt;-\n  d %&gt;% \n  mutate(L = c(L_norm, L_fat))\n\nd\n\n# A tibble: 2 √ó 3\n  H                   Prior        L\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 Normalverteilt          1 1.31e-23\n2 Randlastig verteilt     1 4.93e- 3\n\n\nDann berechnen wir die Post-Wahrscheinlichkeit:\n\nd &lt;-\n  d %&gt;% \n  mutate(Post_unstand = Prior * L,\n         Post = Post_unstand / sum(Post_unstand))\nd\n\n# A tibble: 2 √ó 5\n  H                   Prior        L Post_unstand     Post\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Normalverteilt          1 1.31e-23     1.31e-23 2.66e-21\n2 Randlastig verteilt     1 4.93e- 3     4.93e- 3 1   e+ 0\n\n\nDie Wahrscheinlichkeit, dass die Variable normalverteilt ist, ist seeeeehr klein, ca. \\(10^{-21}\\).\nDas ist kleiner als kleiner als 0.005%.\n\n\nAnswerlist\n\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nCategories:\n\nprobability\nsimulation\nfat-tails\nnormal-distribution\nfat-tails"
  },
  {
    "objectID": "posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html",
    "href": "posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html",
    "title": "punktschaetzer-reicht-nicht",
    "section": "",
    "text": "Exercise\nZwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktsch√§tzer).\nm1:\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30063 -0.06220 -0.00919  0.05770  0.30505 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.013623   0.009748   1.398    0.165    \nx           1.009461   0.009082 111.148   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09742 on 98 degrees of freedom\nMultiple R-squared:  0.9921,    Adjusted R-squared:  0.992 \nF-statistic: 1.235e+04 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nm2:\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7686 -0.6615  0.1293  0.6313  2.0539 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.06464    0.09747   0.663    0.509    \nx            1.03671    0.10405   9.964   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9747 on 98 degrees of freedom\nMultiple R-squared:  0.5032,    Adjusted R-squared:  0.4982 \nF-statistic: 99.28 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nDie Modelle unterscheiden sich aber in ihrer Ungewissheit bez√ºglich \\(\\beta\\), wie in der Spalte Std. Error ausgedr√ºckt.\nWelches der beiden Modelle ist zu bevorzugen? Begr√ºnden Sie.\n         \n\n\nSolution\nModell m1 hat eine kleinere Ungewissheit im Hinblick auf die Modellkoeffizienten \\(\\beta_0, \\beta_1\\) und ist daher gegen√ºber m2 zu bevorzugen.\n\nCategories:\n\nregression\nen\nbayes\nfrequentist\nqm1\nstats-nutshell\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/Wertpruefen/Wertpruefen.html",
    "href": "posts/Wertpruefen/Wertpruefen.html",
    "title": "Wertpruefen",
    "section": "",
    "text": "Aufgabe\nGeben Sie die R-Syntax ein, um zu pr√ºfen, dass die Variable loesung den Wert 42 hat.\nHinweis: Geben Sie Ihre L√∂sung ohne Leerzeichen an, da sonst eine richtige L√∂sung nicht erkannt werden kann.\n         \n\n\nL√∂sung\nloesung==42\n\nCategories:\n\nR\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/wskt-quiz14/wskt-quiz14.html",
    "href": "posts/wskt-quiz14/wskt-quiz14.html",
    "title": "wskt-quiz14",
    "section": "",
    "text": "Behauptung:\n\\(Pr(AB) = Pr(A|B) \\cdot Pr(B)\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz14/wskt-quiz14.html#answerlist",
    "href": "posts/wskt-quiz14/wskt-quiz14.html#answerlist",
    "title": "wskt-quiz14",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz14/wskt-quiz14.html#answerlist-1",
    "href": "posts/wskt-quiz14/wskt-quiz14.html#answerlist-1",
    "title": "wskt-quiz14",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/na-per-col/na-per-col.html",
    "href": "posts/na-per-col/na-per-col.html",
    "title": "na-per-col",
    "section": "",
    "text": "Z√§hlen Sie die Anzahl der fehlenden Werte pro Spalte im Datensatz penguins.\nZeigen Sie einen pr√§gnanten Weg.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\ndata(\"penguins\", package = \"palmerpenguins\")  # ggf. das Paket vorab installieren"
  },
  {
    "objectID": "posts/na-per-col/na-per-col.html#weg-1",
    "href": "posts/na-per-col/na-per-col.html#weg-1",
    "title": "na-per-col",
    "section": "Weg 1",
    "text": "Weg 1\n\npenguins |&gt; \n  purrr::map_int(~ sum(is.na(.)))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0"
  },
  {
    "objectID": "posts/na-per-col/na-per-col.html#weg-2",
    "href": "posts/na-per-col/na-per-col.html#weg-2",
    "title": "na-per-col",
    "section": "Weg 2",
    "text": "Weg 2\n\ncolSums(is.na(penguins))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0"
  },
  {
    "objectID": "posts/na-per-col/na-per-col.html#weg-3",
    "href": "posts/na-per-col/na-per-col.html#weg-3",
    "title": "na-per-col",
    "section": "Weg 3",
    "text": "Weg 3\n\ndescribe_distribution(penguins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nbill_length_mm\n43.92193\n5.4595837\n9.300\n32.1\n59.6\n0.0531181\n-0.8760270\n342\n2\n\n\nbill_depth_mm\n17.15117\n1.9747932\n3.125\n13.1\n21.5\n-0.1434646\n-0.9068661\n342\n2\n\n\nflipper_length_mm\n200.91520\n14.0617137\n23.250\n172.0\n231.0\n0.3456818\n-0.9842729\n342\n2\n\n\nbody_mass_g\n4201.75439\n801.9545357\n1206.250\n2700.0\n6300.0\n0.4703293\n-0.7192219\n342\n2\n\n\nyear\n2008.02907\n0.8183559\n2.000\n2007.0\n2009.0\n-0.0537278\n-1.5049366\n344\n0\n\n\n\n\n\n\nAllerdings ber√ºcksichtigt describe_distribution nur metrische Spalten."
  },
  {
    "objectID": "posts/na-per-col/na-per-col.html#weg-4",
    "href": "posts/na-per-col/na-per-col.html#weg-4",
    "title": "na-per-col",
    "section": "Weg 4",
    "text": "Weg 4\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2"
  },
  {
    "objectID": "posts/na-per-col/na-per-col.html#weg-5",
    "href": "posts/na-per-col/na-per-col.html#weg-5",
    "title": "na-per-col",
    "section": "Weg 5",
    "text": "Weg 5\n\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n‚ñÉ‚ñá‚ñá‚ñÜ‚ñÅ\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n‚ñÖ‚ñÖ‚ñá‚ñá‚ñÇ\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n‚ñÇ‚ñá‚ñÉ‚ñÖ‚ñÇ\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÇ\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\n\n\n\n\nCategories:\n\nR\nwrangling\nna\nstring"
  },
  {
    "objectID": "posts/parameter-genau/index.html",
    "href": "posts/parameter-genau/index.html",
    "title": "parameter-genau",
    "section": "",
    "text": "1 Aufgabe\nWelcher der folgenden Parameterwerte zeigt die genaueste Sch√§tzung an?\n\n\\(\\beta_1: [2;10]\\)\n\\(\\beta_1: [10; 20]\\)\n\\(\\beta_1: [0,2; 1,0]\\)\n\\(\\beta_1: [200; 1000]\\)\n\\(\\beta_1:  [-1000; 1000]\\)\n\nHinweise:\n\nDie beiden Zahlen in den eckigen Klammern geben die untere bzw. die obere Grenze eines Konfidenzintervalls (Sch√§tzbereichs) an.\nEs gilt die Ceteris-Paribus-Bedingung.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\njkl√∂jkjkl√∂√∂k"
  },
  {
    "objectID": "posts/norms-sd/index.html",
    "href": "posts/norms-sd/index.html",
    "title": "norm-sd",
    "section": "",
    "text": "1 Aufgabe\nJemand stellt folgende Behauptung auf:\n\nDie Durchschnittsjahrestemperatur in Deutschlang liegt bei so 10 bis 12 Grad.\n\nGehen Sie von folgenden Annahmen aus:\n\nDie Temperaturverteilung ist normalverteilt.\nDer Sprecher meint mit ‚Äúso 10 bis 12 Grad‚Äù ein 95%-Konfidenzintervall.\n\nAufgabe Wie gro√ü ist die Streuung?\n  \n  \n  \n  \n\n\n2 L√∂sung\nDie Streuung ist die Standardabweichung der Normalverteilung. Der Mittelwert liegt in der Mitte des Intervalls, also bei 11 Grad. Der Bereich MW¬±2SD enth√§lt 95% der Werte. Daher betr√§gt die SD 1/2 Grad."
  },
  {
    "objectID": "posts/iq07/iq07.html",
    "href": "posts/iq07/iq07.html",
    "title": "iq07",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nIn einer Population gebe es zwei Subgruppen, f√ºr die gilt:\n\\(IQ_1 \\sim N(85, 15)\\) \\(IQ_2 \\sim N(115, 15)\\)\nWie gro√ü ist die Wahrscheinlichkeit, dass eine zuf√§llig gezogene Person einen IQ-Wert von mind. 115 Punkten hat?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\)\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^3\\) Stichproben pro Subpopulation.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten)\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten; Subpopulation 1:\n\nset.seed(42)\n\nd1 &lt;- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 85, sd = 15))\n\nSubpopulation 2:\n\nset.seed(42)\n\nd2 &lt;- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 115, sd = 15))\n\nDann kombinieren wir die Daten zu einer Tabelle:\n\nd &lt;-\n  d1 %&gt;% \n  bind_rows(d2)\n\nDann filtern wir wie in der Angabe gefragt:\n\nsolution_d &lt;-\n  d %&gt;% \n  count(iq &gt; 115) %&gt;% \n  mutate(prop = n / sum(n))\n\nsolution_d\n\n\n\n\n\niq &gt; 115\nn\nprop\n\n\n\n\nFALSE\n1494\n0.747\n\n\nTRUE\n506\n0.253\n\n\n\n\n\n\nDie L√∂sung lautet also 0.253.\nWenn Sie die Zufallszahlen mit set.seed fixiert haben, sollten Sie den exakt gleichen Wert gefunden haben.\nInteressant ist es vielleicht, die Gesamtpopulation zu visualisieren:\n\nggplot(d) +\n  aes(x = iq) +\n  geom_density()\n\n\n\n\n\n\n\n\nIm Vergleich dazu eine Normalverteilung mit MW=100 und SD=15:\n\n\n\n\n\n\n\n\n\nWir sehen, dass unsere Population √ºber eine (deutlich) h√∂here Streuung verf√ºgt:\n\nd %&gt;% \n  summarise(sd(iq))\n\n\n\n\n\nsd(iq)\n\n\n\n\n21.23995\n\n\n\n\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html",
    "title": "wfsets_penguins01",
    "section": "",
    "text": "Berechnen Sie die Vorhersageg√ºte (RMSE) f√ºr folgende Lernalgorithmen:\n\nlineares Modell\nknn (neighbors: tune)\n\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nNutzen Sie minimale Vorverarbeitung."
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#setup",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#setup",
    "title": "wfsets_penguins01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(penguins, package = \"palmerpenguins\")"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#daten",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#daten",
    "title": "wfsets_penguins01",
    "section": "Daten",
    "text": "Daten\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()\n\n\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#modelle",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#modelle",
    "title": "wfsets_penguins01",
    "section": "Modelle",
    "text": "Modelle\nLineares Modell:\n\nmod_lin &lt;- linear_reg()\n\nmod_knn &lt;- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#rezepte",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#rezepte",
    "title": "wfsets_penguins01",
    "section": "Rezepte",
    "text": "Rezepte\n\nrec_basic &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n         step_normalize(all_predictors())"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#resampling",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#resampling",
    "title": "wfsets_penguins01",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpls &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#workflow-set",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#workflow-set",
    "title": "wfsets_penguins01",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic),\n    models = list(mod_lm = mod_lin,\n                  mod_nn = mod_knn)\n  )"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#fitten",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#fitten",
    "title": "wfsets_penguins01",
    "section": "Fitten",
    "text": "Fitten\n\nwf_fit &lt;-\n  wf_set %&gt;% \n  workflow_map(resamples = rsmpls)\n\nCheck:\n\nwf_fit %&gt;% pluck(\"result\")"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#bester-kandidat",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#bester-kandidat",
    "title": "wfsets_penguins01",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(wf_fit)\n\n\n\n\n\n\n\n\n\nautoplot(wf_fit, select_best = TRUE)\n\n\n\n\n\n\n\n\n\nrank_results(wf_fit, rank_metric = \"rmse\") %&gt;% \n  filter(.metric == \"rmse\")\n\nAm besten war das lineare Modell, aber schauen wir uns auch mal das knn-Modell an, v.a. um zu wissen, wie man den besten Tuningparameter-Wert sieht:\n\nextract_workflow_set_result(wf_fit, \"rec_simple_mod_nn\") %&gt;% \n  select_best()"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#last-fit",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#last-fit",
    "title": "wfsets_penguins01",
    "section": "Last Fit",
    "text": "Last Fit\n\nbest_wf &lt;-\n  wf_fit %&gt;% \n  extract_workflow(\"rec_simple_mod_lm\")\n\nFinalisieren m√ºssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\nfit_final &lt;-\n  best_wf %&gt;% \n  last_fit(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#modellg√ºte-im-test-set",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#modellg√ºte-im-test-set",
    "title": "wfsets_penguins01",
    "section": "Modellg√ºte im Test-Set",
    "text": "Modellg√ºte im Test-Set\n\ncollect_metrics(fit_final)\n\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/kaefer1/kaefer1.html",
    "href": "posts/kaefer1/kaefer1.html",
    "title": "kaefer1",
    "section": "",
    "text": "Weltsensation?! Der Insektenforscher Prof.¬†M√ºgge ist der Meinung, eine bislang unbekannte K√§ferart entdeckt zu haben. Nach nur 18 Monaten Feldforschung im brasilianischen Regenwald gelang ihm dieser Durchbruch. Wenn es denn nun wirklich eine neue Art ist. Gerade untersucht er ein Exemplar unter dem Mikroskop. Hm, was ist das f√ºr ein Tier? üêõ üî¨\nDrei Arten kommen in Frage, \\(A_1, A_2, A_3\\).\nDabei ist die Art \\(A_1\\) sehr verbreitet und schon l√§ngst bekannt, \\(A_2\\) ist die neue Art, Exemplare dieser Art sind selten und \\(A_3\\) ist auch bekannt und eher h√§ufig anzutreffen. Allerdings spricht das Aussehen am ehesten f√ºr \\(A_2\\), der seltenen Art.\nüëâ Aufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass Prof.¬†M√ºgge wirklich einen gro√üen Fang gemacht hat und einen unbekannten K√§fer entdeckt hat?\nHier sind die genauen Vorkommensh√§ufigkeiten:\n\nPr_A1 &lt;- .6\nPr_A2 &lt;- .1\nPr_A3 &lt;- .4\n\nUnd hier die genauen Wahrscheinlichkeiten, wie typisch das beobachtete Objekt f√ºr einen Vertreter der jeweiligen Art ist:\n\nL_A1 &lt;- .5\nL_A2 &lt;- .9\nL_A3 &lt;- .4\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/kaefer1/kaefer1.html#setup",
    "href": "posts/kaefer1/kaefer1.html#setup",
    "title": "kaefer1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(prada)  # f√ºr Funktion `bayesbox`\n\n\nbb &lt;- bayesbox(hyps = c(\"A\", \"B\", \"C\"),\n               priors = c(Pr_A1, Pr_A2, Pr_A3),\n               liks = c(L_A1, L_A2, L_A3))\n\nbb\n\n\n\n\n\nhyps\npriors\nliks\npost_unstand\npost_std\n\n\n\n\nA\n0.6\n0.5\n0.30\n0.55\n\n\nB\n0.1\n0.9\n0.09\n0.16\n\n\nC\n0.4\n0.4\n0.16\n0.29\n\n\n\n\n\n\n\nsol &lt;- .164\n\nDie Wahrscheinlichkeit, dass der K√§fer zur Art ‚ÄúB‚Äù geh√∂rt, ist relativ klein: 16%.\n\nCategories:\n\nR\nbayes\nbayesbox\nnum"
  },
  {
    "objectID": "posts/nichtlineare-regr1/nichtlineare-regr1.html",
    "href": "posts/nichtlineare-regr1/nichtlineare-regr1.html",
    "title": "nichtlineare-regr1",
    "section": "",
    "text": "Aufgabe\nWir suchen ein Modell, das einen nichtlinearen Zusammenhang von PS-Zahl und Spritverbrauch darstellt (Datensatz mtcars).\nGeben Sie daf√ºr ein m√∂gliches Modell an! Nutzen Sie den R-Befehl lm.\n         \n\n\nL√∂sung\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(mpg_log = log(mpg)) \n\nlm1 &lt;- lm(mpg_log ~ hp, data = mtcars)\nsummary(lm1)\n\n\nCall:\nlm(formula = mpg_log ~ hp, data = mtcars)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.41577 -0.06583 -0.01737  0.09827  0.39621 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.4604669  0.0785838  44.035  &lt; 2e-16 ***\nhp          -0.0034287  0.0004867  -7.045 7.85e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1858 on 30 degrees of freedom\nMultiple R-squared:  0.6233,    Adjusted R-squared:  0.6107 \nF-statistic: 49.63 on 1 and 30 DF,  p-value: 7.853e-08\n\n\nVisualisieren wir die Vorhersagen des Modells:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(pred = predict(lm1))\n\n\nmtcars %&gt;% \n  ggplot() +\n  aes(x = hp) +\n  geom_line(aes( y = pred), color = \"blue\") +\n  geom_point(aes(y = mpg_log)) +\n  labs(y = \"log(mpg)\",\n       title = \"Vorhersage von log-mpg in einem Log-Y-Modell\")\n\n\n\n\n\n\n\n\nOder so visualisieren:\n\nlibrary(easystats)\nestimate_expectation(lm1) %&gt;% plot()\n\n\n\n\n\n\n\n\nM√∂chte man auf der Y-Achse mpg und nicht log(mpg) anzeigen, muss man den Logarithmus wieder ‚Äúaufl√∂sen‚Äù, das erreicht man mit der Umkehrfunktion des Logarithmus, das Exponentieren (man ‚Äúdelogarithmiert‚Äù):\n\\[\\begin{aligned}\nlog(y) &= x \\qquad | \\text{Y in Log-Form}\\\\\n    exp(log(y)) &= exp(x)  \\qquad | \\text{Jetzt exponenzieren wir beide Seiten}\\\\\n    y = exp(x)\n\\end{aligned}\\]\nDabei gilt \\(exp(x) = e^x\\), mit \\(e\\) als Eulersche Zahl (2.71‚Ä¶).\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(pred_delog = exp(pred))  # delogarithmieren\n\n\nmtcars %&gt;% \n  ggplot() +\n  aes(x = hp) +\n  geom_line(aes( y = pred_delog), color = \"blue\") +\n  geom_point(aes(y = mpg_log)) +\n  labs(y = \"mpg\",\n       title = \"Vorhersage von mpg in einem Log-Y-Modell\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nlm\nvis\nqm2\nregression\nstring"
  },
  {
    "objectID": "posts/Regr-Bayes-interpret02/Regr-Bayes-interpret02.html",
    "href": "posts/Regr-Bayes-interpret02/Regr-Bayes-interpret02.html",
    "title": "Regr-Bayes-interpret02",
    "section": "",
    "text": "Exercise\nBerechnen Sie das Modell zu folgender Regressionsformel und interpretieren Sie die Ausgabe des folgenden Regressionsmodells. Geben Sie f√ºr jeden Regressionskoeffizienten an, wie sein Wert zu verstehen ist! Interpretieren Sie auch den Interaktionseffekt.\nRegressionsformel:\nmpg ~ hp_z + am + hp_z:am\nHinweise:\n\nFixieren Sie die Zufallszahlen.\nVerwenden Sie Stan zur Berechnung.\nRunden Sie auf 2 Dezimalstellen.\nDas Suffix _z steht f√ºr z-standardisierte Variablen.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Stan, komm her\nlibrary(easystats)  # Komfort\n\ndata(mtcars)\n\nZuerst standardisieren wir die Daten:\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nmtcars2  %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.090625\n6.0269481\n7.525000\n10.4000000\n33.900000\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl\n6.187500\n1.7859216\n4.000000\n4.0000000\n8.000000\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp\n230.721875\n123.9386938\n221.525000\n71.1000000\n472.000000\n0.4202331\n-1.0675234\n32\n0\n\n\nhp\n146.687500\n68.5628685\n84.500000\n52.0000000\n335.000000\n0.7994067\n0.2752116\n32\n0\n\n\ndrat\n3.596563\n0.5346787\n0.840000\n2.7600000\n4.930000\n0.2927802\n-0.4504325\n32\n0\n\n\nwt\n3.217250\n0.9784574\n1.186250\n1.5130000\n5.424000\n0.4659161\n0.4165947\n32\n0\n\n\nqsec\n17.848750\n1.7869432\n2.022500\n14.5000000\n22.900000\n0.4063466\n0.8649307\n32\n0\n\n\nvs\n0.437500\n0.5040161\n1.000000\n0.0000000\n1.000000\n0.2645418\n-2.0632731\n32\n0\n\n\nam\n0.406250\n0.4989909\n1.000000\n0.0000000\n1.000000\n0.4008089\n-1.9665503\n32\n0\n\n\ngear\n3.687500\n0.7378041\n1.000000\n3.0000000\n5.000000\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb\n2.812500\n1.6152000\n2.000000\n1.0000000\n8.000000\n1.1570911\n2.0200593\n32\n0\n\n\nmpg_z\n0.000000\n1.0000000\n1.248559\n-1.6078826\n2.291272\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl_z\n0.000000\n1.0000000\n2.239740\n-1.2248578\n1.014882\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp_z\n0.000000\n1.0000000\n1.787376\n-1.2879099\n1.946754\n0.4202331\n-1.0675234\n32\n0\n\n\nhp_z\n0.000000\n1.0000000\n1.232446\n-1.3810318\n2.746567\n0.7994067\n0.2752116\n32\n0\n\n\ndrat_z\n0.000000\n1.0000000\n1.571037\n-1.5646078\n2.493904\n0.2927802\n-0.4504325\n32\n0\n\n\nwt_z\n0.000000\n1.0000000\n1.212368\n-1.7417722\n2.255336\n0.4659161\n0.4165947\n32\n0\n\n\nqsec_z\n0.000000\n1.0000000\n1.131821\n-1.8740103\n2.826755\n0.4063466\n0.8649307\n32\n0\n\n\nvs_z\n0.000000\n1.0000000\n1.984063\n-0.8680278\n1.116036\n0.2645418\n-2.0632731\n32\n0\n\n\nam_z\n0.000000\n1.0000000\n2.004045\n-0.8141431\n1.189901\n0.4008089\n-1.9665503\n32\n0\n\n\ngear_z\n0.000000\n1.0000000\n1.355373\n-0.9318192\n1.778928\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb_z\n0.000000\n1.0000000\n1.238237\n-1.1221521\n3.211677\n1.1570911\n2.0200593\n32\n0\n\n\n\n\n\n\n\nm1 &lt;- \n  stan_glm(mpg ~ hp_z + am + hp_z:am, \n           seed = 42,\n           refresh = 0,\n           data = mtcars2)\n\ncoef(m1)\n\n(Intercept)        hp_z          am     hp_z:am \n17.95232456 -4.07311028  5.26504242  0.06037871 \n\n\n\nIntercept: Ein Auto mit 0 PS und Automatikantrieb (am=0, s. Hilfe zum Datensatz: help(mtcars)) kann laut Modell mit einer Gallone Sprit ca. 17.95 Meilen fahren.\nhp: Pro zus√§tzlichem PS kann ein Auto mit Automatikantrieb pro Gallone Sprit ca. -4.07 Meilen weniger weit fahren.\nam: Ein Auto mit 0 PS und Schaltgetriebe (am=1) kommt pro Gallone Sprit ca. 5.27 Meilen weiter als ein Auto mit Automatikantrieb.\nhp:am: Der Interaktionseffekt ist praktisch Null (17.95): Der Zusammenhang von PS-Zahl und Spritverbrauch unterscheidet sich nicht (wesentlich) zwischen Autos mit bzw. ohne Automatikantrieb.\n\n\nCategories:\n\nbayes\nregression"
  },
  {
    "objectID": "posts/kausal07/kausal07.html",
    "href": "posts/kausal07/kausal07.html",
    "title": "kausal07",
    "section": "",
    "text": "Eine Forscherin untersucht den Zusammenhang von Rauchen smo (smoking, UV, exposure) und Herzstillstand ca (cardiac arrest, AV, outcome). Sie hegt die Hypothese, dass Rauchen einen Einfluss auf den Cholesterolspiegel cho (cholestorol) hat, was wiederum Herzstillstand ausl√∂sen k√∂nnte.\n\n\n\n\n\n\n\n\n\nHier sehen Sie die Definition des DAGs:\n\n\ndag {\nca [outcome]\ncho\nsmo [exposure]\nunh\nwei\ncho -&gt; ca\nsmo -&gt; cho\nunh -&gt; smo\nunh -&gt; wei\nwei -&gt; cho\n}\n\n\nDie Forscherin √ºberlegt, Cholestorol zu kontrollieren. Ist diese Idee sinnvoll?\n\n\n\nNein, da die Assoziation zwischen UV und AV unterbrochen wird.\nJa, so wird der kausale Effekt identifiziert.\nJa, nur so wird der kausale Effekt identifiziert.\nEs schadet nicht, aber es ist auch nicht n√∂tig.\nNein, da eine Kollision erzeugt wird."
  },
  {
    "objectID": "posts/kausal07/kausal07.html#answerlist",
    "href": "posts/kausal07/kausal07.html#answerlist",
    "title": "kausal07",
    "section": "",
    "text": "Nein, da die Assoziation zwischen UV und AV unterbrochen wird.\nJa, so wird der kausale Effekt identifiziert.\nJa, nur so wird der kausale Effekt identifiziert.\nEs schadet nicht, aber es ist auch nicht n√∂tig.\nNein, da eine Kollision erzeugt wird."
  },
  {
    "objectID": "posts/kausal07/kausal07.html#answerlist-1",
    "href": "posts/kausal07/kausal07.html#answerlist-1",
    "title": "kausal07",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/max-corr2/max-corr2.html",
    "href": "posts/max-corr2/max-corr2.html",
    "title": "max-corr2",
    "section": "",
    "text": "Aufgabe\nWelches Diagramm zeigt den st√§rksten (absoluten) linearen negativen Zusammenhang (Korrelation)?\nGeben Sie die Nummer ein, die in der Kopfzeile jedes Teildiagramms angezeigt wird.\n         \n\n\nL√∂sung\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nnum"
  },
  {
    "objectID": "posts/anim02/anim02.html",
    "href": "posts/anim02/anim02.html",
    "title": "anim02",
    "section": "",
    "text": "Visualisieren Sie in animierter Form den Zusammenhang von Lebenserwartung und Bruttosozialprodukt im Verlauf der Jahre (Datensatz gapminder); der Kontinent soll in der Visualisierung ber√ºcksichtigt sein.\nHinweise:\n\nNutzen Sie plotly zur Visualisierung."
  },
  {
    "objectID": "posts/anim02/anim02.html#setup",
    "href": "posts/anim02/anim02.html#setup",
    "title": "anim02",
    "section": "Setup",
    "text": "Setup\n\nlibrary(gapminder)\nlibrary(ggplot2)\nlibrary(plotly)\ndata(gapminder)"
  },
  {
    "objectID": "posts/anim02/anim02.html#statisches-diagramm",
    "href": "posts/anim02/anim02.html#statisches-diagramm",
    "title": "anim02",
    "section": "Statisches Diagramm",
    "text": "Statisches Diagramm\n\np &lt;- gapminder %&gt;% \n  ggplot(aes(x = gdpPercap, y = lifeExp, color = continent, frame = year)) +\n  geom_point()+\n  scale_x_log10()\np"
  },
  {
    "objectID": "posts/anim02/anim02.html#animiertes-und-interaktives-diagramm",
    "href": "posts/anim02/anim02.html#animiertes-und-interaktives-diagramm",
    "title": "anim02",
    "section": "Animiertes (und interaktives) Diagramm",
    "text": "Animiertes (und interaktives) Diagramm\n\nggplotly(p)\n\n\n\n\n\nDieser Post orientiert sich an dieser Quelle; dort finden sich auch mehr Beispiele.\n\nCategories:\n\n2023\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/Test-MSE1/Test-MSE1.html",
    "href": "posts/Test-MSE1/Test-MSE1.html",
    "title": "Test-MSE1",
    "section": "",
    "text": "Angenommen, Sie arbeiten als Analyst mit folgender Aufgabe:\nEs liegt ein Datensatz mit 600 Besch√§ftigten (als Beobachtungseinheit) vor. F√ºr jede Person sind folgende Informationen bekannt: Dauer der Betriebszugeh√∂rigkeit, Alter, Ausbildung und Ergebnis der letzten Leistungsbeurteilung. Ziel ist es, die H√∂he des zu erwartenden Gehalts vorherzusagen.\nWelche Aussage ist richtig?\n\n\n\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erkl√§rung (inference). \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine un√ºberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Test-MSE1/Test-MSE1.html#answerlist",
    "href": "posts/Test-MSE1/Test-MSE1.html#answerlist",
    "title": "Test-MSE1",
    "section": "",
    "text": "Es handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erkl√§rung (inference). \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine un√ºberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Test-MSE1/Test-MSE1.html#answerlist-1",
    "href": "posts/Test-MSE1/Test-MSE1.html#answerlist-1",
    "title": "Test-MSE1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/desk-vs-wskt/index.html",
    "href": "posts/desk-vs-wskt/index.html",
    "title": "desk-vs-wskt",
    "section": "",
    "text": "1 Aufgabe\nVervollst√§ndigen Sie die Tabelle!\n\n\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDesktiptive.Statistik\n\n\n\n\n?\nMerkmal\n\n\n?\nrelative H√§ufigkeit, Anteil\n\n\n?\neinfache relative H√§ufigkeitsverteilung\n\n\n?\nkumulierte relative H√§ufigkeitsverteilung\n\n\n?\nMittelwert\n\n\n?\nVarianz\n\n\n\n\n\n\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nS. Skript :-)\n\n\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDesktiptive.Statistik\n\n\n\n\nZufallsvariable\nMerkmal\n\n\nWahrscheinlichkeit\nrelative H√§ufigkeit, Anteil\n\n\nWahrscheinlichkeitsfunktion\neinfache relative H√§ufigkeitsverteilung\n\n\nVerteilungsfunktion\nkumulierte relative H√§ufigkeitsverteilung\n\n\nErwartungswert\nMittelwert\n\n\nVarianz\nVarianz"
  },
  {
    "objectID": "posts/voll-normal/index.html",
    "href": "posts/voll-normal/index.html",
    "title": "voll-normal",
    "section": "",
    "text": "Exercise\nNehmen wir an, \\(k=10\\) voneinander unabh√§ngige Eigenschaften \\(E_1, E_2, \\ldots, E_{10}\\) bestimmen, ob eine Person als ‚Äúnormal‚Äù angesehen wird. Jede dieser Eigenschaften kann entweder mit ‚Äúnormal‚Äù (n) oder aber ‚Äúnichtnormal‚Äù (nn) ausgepr√§gt sein, wobei wir nicht genau vorhersagen k√∂nnen, wie diese Eigenschaften bei einer Person bestellt sein werden.\nAls Zufallsexperiment ausgedr√ºckt: \\(\\Omega_E := \\{n, nn\\}\\) mit den zwei Ergebnissen \\(n\\) und \\(nn\\).\nMit der Wahrscheinlichkeit \\(Pr_{E_i} = 0.9\\) treffe das Ereignis \\(N_i := E_i = \\{n\\}\\) (f√ºr alle \\(i = 1, \\ldots, k\\)) zu.\nNehmen wir weiter an, als ‚Äúvoll normal‚Äù (\\(VN\\)) wird eine Person genau dann angesehen, wenn sie in allen \\(k\\) Eigenschaften ‚Äúnormal‚Äù ausgepr√§gt ist, das Ereignis \\(N\\) also f√ºr alle \\(k\\) Eigenschaften auftritt.\n\nNennen Sie Beispiele f√ºr m√∂gliche Eigenschaften \\(E\\)!\nWie gro√ü ist die Wahrscheinlichkeit - unter den hier geschilderten Annahmen -, dass eine Person ‚Äúvoll normal‚Äù ist?\nDiskutieren Sie die Plausibilit√§t der Annahmen!\n\n         \n\n\nSolution\n\nIntelligenz, Aussehen, Gesundheit, Herkunft, Hautfarbe, sexuelle Identit√§t oder Neigung, ‚Ä¶\nF√ºr unabh√§ngige Ereignisse ist die Wahrscheinlichkeit, dass sie alle eintreten, gleich dem Produkt ihrer Einzelwahrscheinlichkeiten:\n\n\\(VN = Pr(E_i)^{10} = 0.9^{10} \\approx 0.3486784\\)\nDie Wahrscheinlichkeit, dass \\(VN\\) nicht eintritt (Nicht-Voll-Normal, NVN), ist dann die Gegenwahrscheinlichkeit: \\(NVN = 1- VN\\).\n\nMehrere der Annahmen sind diskutabel. So k√∂nnten die Eigenschaften nicht unabh√§ngig sein, dann w√§re der hier gezeigte Rechenweg nicht anwendbar. Die Wahrscheinlichkeit f√ºr ‚Äúnormal‚Äù k√∂nnte h√∂her oder niedriger sein, wobei 90% nicht ganz unplausibel ist. Schlie√ülich unterliegt das Ereignis \\(E_N\\) mit den Ergebnissen \\(n\\) bzw. \\(nn\\) sozialpsychologischen bzw. soziologischen Einfl√ºssen und kann variieren.\n\n\n\nVariante\n\nCategories:\n\nprobability\nmeta"
  },
  {
    "objectID": "posts/tidymodels3/tidymodels3.html",
    "href": "posts/tidymodels3/tidymodels3.html",
    "title": "tidymodels3",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nR√ºcktransformieren Sie die Log-Werte in ‚ÄúRoh-Dollar‚Äù.\n         \n\n\nL√∂sung\nMultiplikatives Modell:\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\nModell definieren:\nModell fitten:\n\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nCoefficients:\n(Intercept)  Gr_Liv_Area  \n  4.8552133    0.0002437  \n\n\nModellg√ºte im Train-Sample:\nModellg√ºte im Train-Sample:\n\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.02587 -0.06577  0.01342  0.07202  0.39231 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.855e+00  7.355e-03  660.12   &lt;2e-16 ***\nGr_Liv_Area 2.437e-04  4.648e-06   52.43   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1271 on 2928 degrees of freedom\nMultiple R-squared:  0.4842,    Adjusted R-squared:  0.484 \nF-statistic:  2749 on 1 and 2928 DF,  p-value: &lt; 2.2e-16\n\n\nR-Quadrat via easystats:\n\n\n# R2 for Linear Regression\n       R2: 0.484\n  adj. R2: 0.484\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n4.8552133\n0.0073550\n660.12345\n0\n\n\nGr_Liv_Area\n0.0002437\n0.0000046\n52.42983\n0\n\n\n\n\n\n\nVorhersagen im Test-Sample:\n\n\n\n\n\n\n.pred\n\n\n\n\n5.073540\n\n\n5.179049\n\n\n5.307462\n\n\n5.112527\n\n\n5.180998\n\n\n5.095714\n\n\n\n\n\n\npreds ist ein Tibble, also m√ºssen wir noch die Spalte .pred. herausziehen, z.B. mit pluck(preds, \".pred\"):\n\n\n\n\n\n\nSale_Price\nGr_Liv_Area\npreds\n.pred\n\n\n\n\n5.021189\n896\n5.073540\n5.073540\n\n\n5.235528\n1329\n5.179049\n5.179049\n\n\n5.595972\n1856\n5.307462\n5.307462\n\n\n5.152288\n1056\n5.112527\n5.112527\n\n\n5.264818\n1337\n5.180998\n5.180998\n\n\n4.982271\n987\n5.095714\n5.095714\n\n\n\n\n\n\nOder mit unnest:\n\n\n\n\n\n\nSale_Price\nGr_Liv_Area\n.pred\n\n\n\n\n5.021189\n896\n5.073540\n\n\n5.235528\n1329\n5.179049\n\n\n5.595972\n1856\n5.307462\n\n\n5.152288\n1056\n5.112527\n\n\n5.264818\n1337\n5.180998\n\n\n4.982271\n987\n5.095714\n\n\n\n\n\n\nOder wir binden einfach die Spalte an den Tibble:\n\n\n\n\n\n\nSale_Price\nGr_Liv_Area\n.pred\n\n\n\n\n5.021189\n896\n5.073540\n\n\n5.235528\n1329\n5.179049\n\n\n5.595972\n1856\n5.307462\n\n\n5.152288\n1056\n5.112527\n\n\n5.264818\n1337\n5.180998\n\n\n4.982271\n987\n5.095714\n\n\n\n\n\n\nModellg√ºte im Test-Sample:\n\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrsq\nstandard\n0.5167906\n\n\n\n\n\n\nZur Interpretation von Log10-Werten\n\n\n[1] 5e+05\n\n\n[1] 0\n\n\nR√ºcktransformation (ohne Bias-Korrektur):\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nlm\nnum"
  },
  {
    "objectID": "posts/abh-ereignisse/abh-ereignisse.html",
    "href": "posts/abh-ereignisse/abh-ereignisse.html",
    "title": "abh-ereignisse",
    "section": "",
    "text": "Aufgabe\n\n\n\n\n\n\n\n\n\nLesen Sie folgende Wahrscheinlichkeiten aus dem Diagramm ab:\n\n\\(Pr(A)\\)\n\\(Pr(B)\\)\n\\(Pr(AB)\\)\n\\(Pr(BA)\\)\n\\(Pr(B|A)\\)\n\\(√úr(A|B)\\)\n\nHinweise:\n\nDas Ereignis ‚ÄúB tritt ein‚Äù ist mit ‚ÄúB+‚Äù im Diagramm eingezeichnet (entsprechend f√ºr A). Analog ist das Ereignis ‚ÄúB tritt nicht ein‚Äù mit ‚ÄúB-‚Äù eingezeichnet (entsprechend f√ºr A).\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\n\\(Pr(A) = 1/2 + 1/8 = 5/8\\)\n\\(Pr(B) = 1/2\\)\n\\(Pr(AB) = 1/2 \\cdot 3/4 = 3/8\\)\n\\(Pr(BA) = Pr(AB) = 3/8\\)\n\\(Pr(B|A) = 3/5\\)\n\\(√úr(A|B) = 3/4\\)\n\n\nCategories:\n\nR\nprobability\nstring"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html",
    "title": "vorhersageintervall1",
    "section": "",
    "text": "Vorhersagen, etwa in einem Regressionsmodell, sind mit mehreren Arten von Unsicherheit konfrontiert.\nBerechnen Sie dazu ein Regressionsmodell, Datensatz mtcars, mit hp als Pr√§diktor (UV) und mpg als AV (Kriterium)!\nDann sagen Sie bitte den Wert der AV f√ºr eine Beobachtungseinheit mit mittlerer Auspr√§gung im Pr√§ktor vorher:\nEinmal nur unter Ber√ºcksichtigung der Unsicherheit innerhalb des Modells (‚ÄúKonfidenzintervall‚Äù); einmal unter Ber√ºcksichtigung der Unsicherheit innerhalb des Modells sowie die Unsicherheit durch die Koffizienten (‚ÄúVohersageintervall‚Äù).\nHinweise:\n\npredict() ist eine Funktion, die Sie zur Vorhersage von Regressionsmodellen verwenden k√∂nnen.\nVerwenden Sie lm() zur Berechnung eines Regressionsmodells.\nDas Argument type von predict() erlaubt Ihnen die Wahl der Art der Vorhersage, betrachten Sie Hilfe der Funktion z.B. hier.\n\nBei welchem Intervall ist die Ungewissheit in der Vorhersage gr√∂√üer?\n\n\n\nKonfidenzintervall\nVohersageintervall\nGleich gro√ü\nKommt auf weitere Faktoren an, keine pauschale Antwort m√∂glich"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist",
    "title": "vorhersageintervall1",
    "section": "",
    "text": "Konfidenzintervall\nVohersageintervall\nGleich gro√ü\nKommt auf weitere Faktoren an, keine pauschale Antwort m√∂glich"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist-1",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist-1",
    "title": "vorhersageintervall1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nlm\ninference\nqm2"
  },
  {
    "objectID": "posts/variation02/variation02.html",
    "href": "posts/variation02/variation02.html",
    "title": "variability02",
    "section": "",
    "text": "In welchem Datensatz (x1-x4) gibt es am meisten Variation?\nDatensatz A:\n\n\n\n\n\n\n\n\n\nDatensatz B:\n\n\n\n\n\n\n\n\n\nDatensatz C:\n\n\n\n\n\n\n\n\n\nDatensatz D:\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/variation02/variation02.html#answerlist",
    "href": "posts/variation02/variation02.html#answerlist",
    "title": "variability02",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/variation02/variation02.html#answerlist-1",
    "href": "posts/variation02/variation02.html#answerlist-1",
    "title": "variability02",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvariablity\nbasics\nschoice"
  },
  {
    "objectID": "posts/ungewiss-arten-regr/ungewiss-arten-regr.html",
    "href": "posts/ungewiss-arten-regr/ungewiss-arten-regr.html",
    "title": "ungewiss-arten-regression",
    "section": "",
    "text": "Exercise\nEine statistische Analyse, wie eine Regression, ist mit mehreren Arten an Ungewissheit konfrontiert. Zum einen gibt es die Ungewissheit in den Modellparametern. F√ºr die Regression y = beta0 + beta1x + error bedeutet das: ‚ÄúLiegt die Regressionsgerade in ‚ÄòWahrheit‚Äô (in der Population) genauso wie in der Stichprobe, sind Achsenabschnitt und Steigung in der Stichprobe also identisch zur Population?‚Äù. Zum anderen die Ungewissheit innerhalb des Modells. Auch wenn wir den wahren Wert von beta0 und von beta1 kennen w√ºrden, w√§ren (in aller Regel) die Vorhersagen trotzdem nicht perfekt. Auch wenn wir etwa w√ºssten, wieviel Klausurpunkte ‚Äúin Wahrheit‚Äù pro Stunde Lernen herausspringen (und wenn wir den wahren Achsenabschnitt kennen w√ºrden), so w√ºrde das Modell trotzdem keine perfekten Vorhersagen zum Klausurerfolg liefern: Vermutlich fehlen dem Modell wichtige Informationen etwa zur Motivation der Studentis.\nVor diesem Hintergrund, betrachten Sie folgendes statistisches Modell, das mit den Methoden der Bayes-Statistik berechnet wurde. Dazu wurde die Funktion stan_glm() verwendet, die √§hnlich zu lm() ein lineare Modell berechnet.\nSie brauchen das Modell nicht zu berechnen. Bei dieser Aufgabe geht es nur um die Interpretation.\nEin wichtiger Unterschied von stan_glm() zu lm() ist, dass Ungewissheiten bei stan_glm() zu den Parametersch√§tzungen berichtet werden, bei lm nicht (bzw. weniger).\n\ndata(mtcars) \nlibrary(rstanarm) \nlibrary(easystats)\nlm1 &lt;- stan_glm(mpg ~ hp, data = mtcars,\n                refresh = 0)  # um nicht zu viel R-Ausgabe zu erhalten\n\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n30.137673\n0.95\n26.7418072\n33.5602799\n1\n1.0002779\n3266.827\nnormal\n20.09062\n15.0673701\n\n\nhp\n-0.068335\n0.95\n-0.0891176\n-0.0469947\n1\n0.9998604\n3466.058\nnormal\n0.00000\n0.2197599\n\n\n\n\n\n\nF√ºr den Pr√§diktor hp ist das Regressionsgewicht (Punktsch√§tzer) angegeben unter der Spalte Median. Dieser Wert entspricht der Punktsch√§tzung in der Population und ist identisch zum Regressionsgewicht (‚Äúb‚Äù) der Stichprobe.\nDie Spalte 95% CI gibt das 95%-Konfidenzintervall (CI wie confidence interval) zur Sch√§tzung der Ungewissheit der Koeffizienten (der entsprechenden Zeile) wieder.\nAufgaben\n\nWie breit ist das Intervall, in dem mit 95% Gewissheit der Achsenabschnitt liegt (laut diesem Model)?\nWie breit ist das Intervall, in dem mit 95% Gewissheit das Regressionsgewicht liegt (laut diesem Model)?\n\nHinweise:\n\nRunden Sie auf zwei Dezimalstellen.\nIgnorieren Sie die Spalte zu ROPE, pd, Prior und Rhat! Goldene Regel der Statistik: Wenn du eine Information nicht brauchst, dann ignoriere sie erstmal ;-)\nGehen Sie von einer Normalverteilung aus.\n\n         \n\n\nSolution\n\n6.82\n0.04\n\n\nCategories:\n\nqm2\ninference\nlm"
  },
  {
    "objectID": "posts/penguins-regr02b/index.html",
    "href": "posts/penguins-regr02b/index.html",
    "title": "penguins-regr02b",
    "section": "",
    "text": "library(tidyverse)\n\n\nAufgabe\nBeantworten Sie folgende Forschungsfrage:\nGibt es einen substanziellen Zusammenhang von Flossenl√§nge (Flipper, mm, UV) und Gewicht (g, AV) bei Pinguinen?\n‚ÄúSubstanziell‚Äù bedeutet dabei das Gegenteil von ‚Äúvernachl√§ssigbar gering‚Äù.\nNutzen Sie die folgende Analyse f√ºr Ihre Antwort.\nWir rufen Stan:\n\nüßë‚Äçüè´ Hey, Stan, komm mal r√ºber! Wir haben da eine Frage an dich.\n\n\nü§ñ Beep, beep, beep! Bitte nur gute Fragen.\n\nSetup:\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(penguins)\n\nModell:\n\nm_flipper &lt;- stan_glm(body_mass_g ~ flipper_length_mm, \n               seed = 42,\n               refresh = 0,\n               data = penguins)\n\nParameter:\n\nparameters(m_flipper)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n-5771.7885\n0.95\n-6375.28649\n-5173.68397\n1\n1.000452\n3709.888\nnormal\n4201.754\n2004.8863\n\n\nflipper_length_mm\n49.6391\n0.95\n46.65749\n52.68221\n1\n1.000448\n3760.327\nnormal\n0.000\n142.5777\n\n\n\n\n\n\nRope:\n\nrope(m_flipper)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-80.19545\n80.19545\n0\nfixed\nconditional\n\n\nflipper_length_mm\n0.95\n-80.19545\n80.19545\n1\nfixed\nconditional\n\n\n\n\n\n\nHier wird ein Bereich von ¬±80 Gramm als ‚Äúvernachl√§ssigbar‚Äù (nicht substanziell) angesehen. Diese Voreinstellung sollte nur als grobe Orientierung dienen und sollte an die spezifische Forschungsfrage angepasst werden. Ihr Fachwissen sollte besser sein als dieser Default-Wert.\nVisualisierung:\n\nplot(rope(m_flipper))\n\n\n\n\n\n\n\n\n         \n\n\nL√∂sung\nHier ist also keine klare Aussage zur Frage, ob der Effekt vernachl√§ssigbar klein ist oder gr√∂√üer, m√∂glich.\n\nCategories:\n\nlm\nbayes\nrope\nstring"
  },
  {
    "objectID": "posts/rope-luecke/index.html",
    "href": "posts/rope-luecke/index.html",
    "title": "rope-luecke",
    "section": "",
    "text": "1 Aufgabe\nVervollst√§ndigen Sie die L√ºcke im folgenden Satz:\nLiegt das HDI komplett au√üerhalb des ROPE, so _________ man die Nullhypothese.\nAntwortoptionen\n\nakzeptiert\nverwirft\ntestet\nbestellt\nversteht\nignoriert\nverkauft\nbefreit\nversteckt\nverfremdet\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nverwirft"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html",
    "title": "germeval10-wordvec-rf",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie deutsche Word-Vektoren f√ºr das Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie Wikipedia2Vec als Grundlage f√ºr die Wordembeddings in deutscher Sprache. Laden Sie die Daten herunter (Achtung: ca. 2.8 GB)."
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#deutsche-textvektoren-importieren",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#deutsche-textvektoren-importieren",
    "title": "germeval10-wordvec-rf",
    "section": "Deutsche Textvektoren importieren",
    "text": "Deutsche Textvektoren importieren\n\ntic()\nwiki_de_embeds &lt;- arrow::read_feather(\n  file = \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/part-0.arrow\")\ntoc()\n\nnames(wiki_de_embeds)[1] &lt;- \"word\"\n\nwiki &lt;- as_tibble(wiki_de_embeds)"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#workflow",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#workflow",
    "title": "germeval10-wordvec-rf",
    "section": "Workflow",
    "text": "Workflow\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"classification\",\n              mtry = tune())\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  step_tokenize(text) %&gt;%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") |&gt; \n  step_word_embeddings(text,\n                       embeddings = wiki,\n                       aggregation = \"mean\")\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#preppenbaken",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#preppenbaken",
    "title": "germeval10-wordvec-rf",
    "section": "Preppen/Baken",
    "text": "Preppen/Baken\n\ntic()\nrec1_prepped &lt;- prep(rec1)\ntoc()\n\n\nd_train_baked &lt;-\n  bake(rec1_prepped, new_data = NULL)\nhead(d_train_baked)"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#tuninigfitting",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#tuninigfitting",
    "title": "germeval10-wordvec-rf",
    "section": "Tuninig/Fitting",
    "text": "Tuninig/Fitting\n\ntic()\nwf_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    grid = 5,\n    resamples = vfold_cv(strata = c1, \n                         v = 5,\n                         data = d_train),\n    control = control_grid(save_pred = TRUE,\n                           verbose = TRUE,\n                           save_workflow = FALSE)) \ntoc()\nbeep()\n\nOder das schon in grauer Vorzeit berechnete Objekt importieren:\n\nwf_fit &lt;- read_rds(\"/Users/sebastiansaueruser/github-repos/rexams-exercises/objects/germeval10-wordvec-rf.rds\")"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#plot-performance",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#plot-performance",
    "title": "germeval10-wordvec-rf",
    "section": "Plot performance",
    "text": "Plot performance\n\nautoplot(wf_fit)\n\n\nshow_best(wf_fit)"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#finalisieren",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#finalisieren",
    "title": "germeval10-wordvec-rf",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_params &lt;- select_best(wf_fit)\ntic()\nwf_finalized &lt;- finalize_workflow(wf1, best_params)\nlastfit1 &lt;- fit(wf_finalized, data = d_train)\ntoc()"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#test-set-g√ºte",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#test-set-g√ºte",
    "title": "germeval10-wordvec-rf",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(lastfit1, new_data = germeval_test)\ntoc()\n\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#fazit",
    "href": "posts/germeval10-wordvec-rf/germeval10-wordvec-rf.html#fazit",
    "title": "germeval10-wordvec-rf",
    "section": "Fazit",
    "text": "Fazit\nwikipedia2vec ist f√ºr die deutsche Sprache vorgekocht. Das macht Sinn f√ºr einen deutschsprachigen Corpus.\nDas Modell braucht doch ganz sch√∂n viel Rechenzeit.\nAchtung: Mit dem Parameter save_pred = TRUE wird der Workflow gr√∂√üer als 3 GB.\n\nCategories:\n\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nstring"
  },
  {
    "objectID": "posts/count-emoji/count-emoji.html",
    "href": "posts/count-emoji/count-emoji.html",
    "title": "count-emoji",
    "section": "",
    "text": "Aufgabe\nGegeben eines (mehrelementigen) Strings, my_string, und eines Lexicons, my_lexicon, z√§hlen Sie, wie h√§ufig sich ein Emoji in einem Element des Strings wiederfindet.\n\nmy_string &lt;-\n  c(\"Heute ist ein sch√∂ner Tag üòÑüòÑ\", \"Was geht in dieser Woche?\", \"Super üôÇ\")\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie die Funktion emo::ji.\n\n         \n\n\nL√∂sung\n\nlibrary(emo)\nlibrary(purrr)\n\n\nmap_int(my_string, ji_count)\n\n[1] 2 0 1\n\n\n\nCategories:\n\ntextmining\nnlp\nstring"
  },
  {
    "objectID": "posts/bayes2/bayes2.html",
    "href": "posts/bayes2/bayes2.html",
    "title": "bayes2",
    "section": "",
    "text": "Aufgabe\nWir haben eine M√ºnze \\(n=10\\) Mal geworfen. Unsere Daten (\\(D\\)) sind: 8 Mal lag ‚ÄúKopf‚Äù oben. Gegeben dieser Datenlage, wie hoch ist die Wahrscheinlichkeit f√ºr das Ereignis \\(F\\) (Falschspieler-M√ºnze), dass die M√ºnze also gezinkt ist auf \\(p=.8\\)? Apriori sind wir indifferent, ob die M√ºnze gezinkt ist oder nicht (\\(\\neg F\\), also \\(p=.5\\)). Der Einfachheit halber gehen wir davon aus, dass es nur zwei Zust√§nde f√ºr die M√ºnze geben kann, gezinkt (\\(F\\)) oder nicht gezinkt (\\(\\neg F\\)).\nAufgabe: Berechnen Sie die Wahrscheinlichkeit, dass die M√ºnze gezinkt ist (\\(F\\)), gegeben der Datenlage \\(D\\)!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nGesucht ist die Wahrscheinlichkeit, dass die M√ºnze gezinkt ist, gegeben der beobachteten Daten: \\(Pr(F|D)\\).\n\np_gezinkt = .8\np_fair = .5\nn = 10\nk = 8\n\nWir k√∂nnen Bayes‚Äô Theorem zur L√∂sung nutzen:\n\\(Pr(F|D) = \\frac{L \\times Priori}{Evidenz} = \\frac{Pr(D|F) Pr(F)}{Pr(D)} =  \\frac{Pr(D|F) Pr(F)}{Pr(D|F)Pr(F)  + {Pr(D|\\neg F)Pr(\\neg F)}}\\)\nDie Priori-Wahrscheinlichkeit f√ºr die Hypothese, dass die M√ºnze gezinkt ist, betr√§gt 1/2, da wir indifferent sind: \\(Pr(F) = 1/2\\).\nDie Likelihood, L, f√ºr die Hypothese einer gezinkten M√ºnze, berechnet sich so:\n\nL_gezinkt &lt;- dbinom(x = k, size = n, prob = p_gezinkt)\nL_gezinkt\n\n[1] 0.3019899\n\n\nDer Z√§hler des Bruchs (unstand. Post) berechnet sich so:\n\nPost_unstand &lt;- L_gezinkt * 1/2\nPost_unstand\n\n[1] 0.1509949\n\n\nDie Likelihood f√ºr die Daten, wenn die M√ºnze fair (nicht gezinkt ist), betr√§gt:\n\nL_fair &lt;- dbinom(x = k, size = n, prob = p_fair)\nL_fair\n\n[1] 0.04394531\n\n\nDie unstand. Post-Wahrscheinlichkeit f√ºr die Hypothese, dass die M√ºnze fair ist, gegeben der Daten:\n\nPost_unstand2 &lt;- L_fair * 1/2\nPost_unstand2\n\n[1] 0.02197266\n\n\nDie Evidenz, E, berechnet sich als Summe aller unstand. Post-Wahrscheinlichkeiten (also √ºber alle m√∂glichen Hypothesen, d.h. \\(F\\) und \\(\\neg F\\), also \\(L\\) plus \\(L_2\\)):\n\nE &lt;- Post_unstand + Post_unstand2\nE\n\n[1] 0.1729676\n\n\nDie standardisierte Post-Wahrscheinlichkeit ist also die unstand. Post-Wahrscheinlichkeit geteilt durch die Evidenz:\n\nPost_std &lt;- Post_unstand / E\nPost_std\n\n[1] 0.8729666\n\n\nAntwort: Die L√∂sung betr√§gt 0.87.\nAlternativ zur Formel kann man auch eine Bayesbox verwenden, um die Aufgabe zu l√∂sen.\n\nlibrary(prada)\nbayesbox(hyps = c(\"fair\", \"gezinkt\"),\n         priors = c(1/2, 1/2),\n         liks = c(L_fair, L_gezinkt))\n\n\n\n\n\nhyps\npriors\nliks\npost_unstand\npost_std\n\n\n\n\nfair\n0.5\n0.0439453\n0.0219727\n0.1270334\n\n\ngezinkt\n0.5\n0.3019899\n0.1509949\n0.8729666\n\n\n\n\n\n\n√úbrigens w√ºrde sich die standardisierte Posteriori-Verteilung nicht √§ndern, wenn man als Priori bei den beiden Hypothesen jeweils 1 annehmen w√ºrden.\nDie Likelihood f√ºr die Binomialverteilung kann man auch mit dem Taschenrechner (oder im Kopf‚Ä¶) berechnen: gi Likelihood f√ºr die Daten unter der Annahme einer gezinkten M√ºnze:\n\nchoose(n, k) * p_gezinkt^k * (1-p_gezinkt)^(n-k)\n\n[1] 0.3019899\n\n\nLikelihood f√ºr die Daten unter der Annahme einer fairen M√ºnze:\n\nchoose(n, (n-k)) * p_fair^(n-k) * (1-p_fair)^(k)\n\n[1] 0.04394531\n\n\n\nCategories:\n\nR\nbayes\nprobability\nnum"
  },
  {
    "objectID": "posts/Bayesmod-bestimmen02/Bayesmod-bestimmen02.html",
    "href": "posts/Bayesmod-bestimmen02/Bayesmod-bestimmen02.html",
    "title": "Bayesmod-bestimmen02",
    "section": "",
    "text": "Exercise\nSie m√∂chten, im Rahmen einer Studie, ein einfaches lineare Modell spezifizieren, d.h. den Likelihood und die Priori-Verteilungen benennen.\nFolgende Informationen sind gegeben:\n\nAV: einnahmen\nUV: werbebudget\nAlle empirischen Variablen sind z-standardisiert.\nAlle Variablen sollen als normalverteilt angegeben werden mit Ausnahme der Streuung der AV, diese ist exponenzialverteilt mit Rate 1 zu modellieren.\nStreuungen der Normalverteilung sind mit 2.5 SD anzugeben.\n\nSchreiben Sie in mathematischer Notation folgende Notation auf:\nPriori-Verteilung der Streuung der AV\nHinweise:\n\nVerzichten Sie auf Leerstellen in Ihrer Antwort. \nBenennen Sie \\(\\beta_1\\) mit b1, \\(\\beta_0\\) (auch \\(\\alpha\\) genannt) mit b0 und \\(\\sigma\\) mit s.\nNutzen Sie die Tilde ~ um stochastische Relationen (Verteilungen) anzuzeigen.\nGeben Sie Normalverteilungen als Normal(x,y) und Exponentialverteilung als Exp(x) an (jeweils mit den korrekten Argumenten in der allgemein √ºblichen Form).\n\n         \n\n\nSolution\n\nsol &lt;- \"s~Exp(1)\"\n\ns~Exp(1)\n\nCategories:\n\nregression\nbayes\nprior"
  },
  {
    "objectID": "posts/interpret-koeff/interpret-koeff.html",
    "href": "posts/interpret-koeff/interpret-koeff.html",
    "title": "interpret-koeff",
    "section": "",
    "text": "Exercise\nBetrachten Sie dieses Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars):\n\ndata(mtcars)\nlibrary(rstanarm)\nlibrary(easystats)\nlm1 &lt;- stan_glm(mpg ~ hp, data = mtcars,\n                refresh = 0)\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n30.0859302\n0.95\n26.5705871\n33.3740040\n1\n0.9999767\n2890.407\nnormal\n20.09062\n15.0673701\n\n\nhp\n-0.0678194\n0.95\n-0.0885729\n-0.0465585\n1\n1.0004788\n3040.543\nnormal\n0.00000\n0.2197599\n\n\n\n\n\n\n\nWas bedeuten die Koeffizienten?\nWie ist der Effekt von \\(\\beta_1\\) zu interpretieren?\n\nHinweise:\n\nRunden Sie auf eine Dezimale.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nSolution\n\nIntercept (\\(\\beta_0\\)): Der Achsenabschnitt gibt den gesch√§tzten mittleren Y-Wert (Spritverbrauch) an, wenn \\(x=0\\), also f√ºr ein Auto mit 0 PS (was nicht wirklich Sinn macht). hp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und damit die Steigung der Regressionsgeraden.\nhp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und gibt den statistischen ‚ÄúEffekt‚Äù der PS-Zahl auf den Spritverbrauch an. Vorsicht: Dieser ‚ÄúEffekt‚Äù darf nicht vorschnell als kausaler Effekt verstanden werden. Daher muss man vorsichtig sein, wenn man von einem ‚ÄúEffekt‚Äù spricht. Vorsichtiger w√§re zu sagen: ‚ÄúEin Auto mit einem PS mehr, kommt im Mittel 0,1 (0.07) Meilen weniger weit mit einer Gallone Sprit, laut diesem Modell‚Äù. Den Punktsch√§tzer des Regressionskoeffizienten (\\(\\beta_1\\)) kann man in der Tabelle mit den Parameterwerten auslesen, in der Spalte Median.\n\n\nCategories:\n\nregression\nlm\nbayes\nstats-nutshell"
  },
  {
    "objectID": "posts/predictioncontest1/predictioncontest1.html",
    "href": "posts/predictioncontest1/predictioncontest1.html",
    "title": "predictioncontest1",
    "section": "",
    "text": "Question\n\nAufgabe\nErstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz penguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n\nHalten Sie die Analyse einfach.\nTeilen Sie Test- vs.¬†Train-Set h√§lftig auf.\nTeilen Sie Analysis vs.¬†Assessment-Set 3:1 auf.\nDen Datensatz penguins k√∂nnen Sie entweder aus dem Paket palmerpenguins beziehen oder z.B. von hier via read_csv() importieren.\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nPakete laden:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(easystats)\ndata(\"penguins\", package = \"palmerpenguins\")\n\nMan erinnere sich, dass ein R-Paket erst (einmalig) installiert sein muss, bevor Sie darauf zugreifen k√∂nnen, etwa um Daten - wie den Datensatz penguins - daraus zu beziehen.\nZeilen mischen und Train- vs.¬†Testset aufteilen:\n\npenguins2 &lt;-\n  penguins %&gt;% \n  sample_n(size = nrow(.))\n\nd_train &lt;- penguins2 %&gt;% slice(1:(344/2))\nd_test &lt;- penguins2 %&gt;% slice(173:nrow(penguins))\n\nDas Trainset weiter aufteilen:\n\nd_split &lt;- initial_split(d_train)\n\nd_analysis &lt;- training(d_split)\nd_assessment &lt;- testing(d_split)\n\nRezept definieren:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ ., data = d_analysis) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_normalize(all_numeric(), -all_outcomes())\n\nRezept pr√ºfen:\n\nd_analysis_baked &lt;- \nrec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\ndescribe_distribution(d_analysis_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nbill_length_mm\n0.000\n1.0000\n1.731310\n-2.159228\n2.560870\n0.0760789\n-0.8319692\n129\n0\n\n\nbill_depth_mm\n0.000\n1.0000\n1.469785\n-2.113935\n2.137943\n-0.2111715\n-0.6801013\n129\n0\n\n\nflipper_length_mm\n0.000\n1.0000\n1.707152\n-1.535114\n2.084049\n0.4487826\n-0.9893612\n129\n0\n\n\nyear\n0.000\n1.0000\n2.359469\n-1.198025\n1.161444\n-0.0296827\n-1.6124172\n129\n0\n\n\nbody_mass_g\n4225.969\n851.5118\n1325.000000\n2900.000000\n6300.000000\n0.5405268\n-0.7594811\n129\n0\n\n\n\n\n\n\nWorkflow und CV definieren:\n\nm1 &lt;- \n  linear_reg()\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_recipe(rec1) %&gt;% \n  add_model(m1)\n\ncv_scheme &lt;- vfold_cv(d_analysis, v = 2)\n\nFitten (hier kein Tuning):\n\nfit1 &lt;-\n  wf1 %&gt;% \n  tune_grid(resamples = cv_scheme)\n\nFinalisieren:\n\nshow_best(fit1)\n\n\n\n\n\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\nrmse\nstandard\n315.3654\n2\n15.70452\npre0_mod0_post0\n\n\n\n\n\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(show_best(fit1))\n\n\nwf1_final\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: linear_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_impute_knn()\n‚Ä¢ step_normalize()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nModellg√ºte:\n\nfit1_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\ncollect_metrics(fit1_final)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n226.9887784\npre0_mod0_post0\n\n\nrsq\nstandard\n0.9127546\npre0_mod0_post0\n\n\n\n\n\nfit1_train &lt;-\n  wf1_final %&gt;% \n  fit(d_train)\n\n\nfit1_test &lt;-\n  fit1_train %&gt;% \n  predict(d_test)\n\nhead(fit1_test)\n\n\n\n\n\n.pred\n\n\n\n\n4709.582\n\n\n3836.121\n\n\n4169.211\n\n\n4319.333\n\n\n3383.746\n\n\n3506.382\n\n\n\n\n\n\nVgl https://workflows.tidymodels.org/reference/predict-workflow.html\nSubmitten:\n\nsubm_df &lt;-\n  d_test %&gt;% \n  mutate(id = 173:344) %&gt;% \n  bind_cols(fit1_test) %&gt;% \n  select(id, .pred) %&gt;% \n  rename(pred = .pred)\n\nUnd als CSV-Datei speichern:\n\n#write_csv(subm_df, file = \"submission_blabla.csv\")\n\n\nCategories:\n\nR\nds1\nsose22\nstring"
  },
  {
    "objectID": "posts/pwert/index.html",
    "href": "posts/pwert/index.html",
    "title": "pvalue1",
    "section": "",
    "text": "1 Aufgabe\nWelche Aussage zum p-Wert ist korrekt?\n\nDer p-Wert ist die Wahrscheinlichkeit, dass die Nullhypothese wahr ist.\nDer p-Wert gibt die Wahrscheinlichkeit an, dass die Alternativhypothese falsch ist.\nEin p-Wert von 0,05 bedeutet, dass es eine 5%ige Chance gibt, dass das Ergebnis zuf√§llig entstanden ist.‚Äù\nEin kleinerer p-Wert bedeutet einen st√§rkeren Effekt.\n‚Äúp = 0,049 ist ‚Äòsignifikant‚Äô, aber p = 0,051 ist ‚Äònicht signifikant‚Äô - das sind kategorisch verschiedene Ergebnisse.‚Äù Hinweise:\nEin nicht-signifikanter p-Wert beweist, dass kein Effekt existiert.\nDer p-Wert gibt an, wie wahrscheinlich es ist, dass man das gleiche Ergebnis bei Wiederholung erh√§lt.\np &lt; 0,001 bedeutet, dass das Ergebnis praktisch relevant ist.\n\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nFALSCH. Der p-Wert ist P(Daten|H‚ÇÄ), nicht P(H‚ÇÄ|Daten)\nFALSCH. Der p-Wert macht keine Aussage √ºber die Wahrscheinlichkeit von Hypothesen.\nFALSCH. Der p-Wert macht keine Aussage √ºber die Ursachen eines Befunds.\nFALSCH. Der p-Wert und die Effektgr√∂√üe sind verschiedene Konzepte. Ein kleiner p-Wert bedeutet nicht (notwendig) einen gro√üen Effekt.\nFALSCH. Arbitr√§re Schwellenwerte schaffen keine qualitativen Unterschiede. Der Unterschied zwischen signifikant und nicht-signifikant ist nicht signifikant (Andrew Gelman).\nFalsch! Fehlende Evidenz ‚â† Evidenz f√ºr Fehlen.\nFalsch! Das w√§re die Reproduzierbarkeit, nicht der p-Wert.\nFalsch! Statistische und praktische Signifikanz sind verschiedene Konzepte."
  },
  {
    "objectID": "posts/rope-regr/rope-regr.html",
    "href": "posts/rope-regr/rope-regr.html",
    "title": "rope-regr",
    "section": "",
    "text": "Exercise\nJohn Kruschke hat einen (Absolut-)Wert vorschlagen, als Grenze f√ºr Regressionskoeffizienten ‚Äúvernachl√§ssigbarer‚Äù Gr√∂√üe.\nNennen Sie diesen Wert!\nHinweise:\n\nGeben Sie nur Zahlen ein (und ggf. Dezimaltrennzeichen).\nF√ºhrende Nullen d√ºrfen auch bei Zahlen kleiner als 1 nicht weggelassen werden.\n\n         \n\n\nSolution\n\nsol &lt;- 0.05\n\n0.05\n\nCategories:\n\nbayes\nregression\nrope"
  },
  {
    "objectID": "posts/kausal01/kausal01.html",
    "href": "posts/kausal01/kausal01.html",
    "title": "kausal01",
    "section": "",
    "text": "Gegeben sei der DAG g (s.u.). Welche Variable/n sind zu kontrollieren, um den kausalen Effekt von x auf y zu identifizieren?\n\n\n\n\n\n\n\n\n\nGegeben sei der DAG g (s.o.). Dabei ist zu beachten, dass die gebogene Kurve (keine Gerade) mit zwei Pfeilspitzen keinen Kausaleffekt beschreibt, sondern eine Assoziation. Die dahinterstehende kausale Struktur ist eine Konfundierung. Daher ist der ‚ÄúDoppelpfeil‚Äù als Abk√ºrzung f√ºr eine Konfundierung zu verstehen.\nWelche Variable/n sind zu kontrollieren, um den kausalen Effekt von x auf y zu identifizieren?\n\n\n\nkeine, bereits identifiziert\nx\ny\nm\nkeine, nicht identifizierbar"
  },
  {
    "objectID": "posts/kausal01/kausal01.html#answerlist",
    "href": "posts/kausal01/kausal01.html#answerlist",
    "title": "kausal01",
    "section": "",
    "text": "keine, bereits identifiziert\nx\ny\nm\nkeine, nicht identifizierbar"
  },
  {
    "objectID": "posts/kausal01/kausal01.html#answerlist-1",
    "href": "posts/kausal01/kausal01.html#answerlist-1",
    "title": "kausal01",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal\nexam-22"
  },
  {
    "objectID": "posts/Regr-Bayes-interpret03/Regr-Bayes-interpret03.html",
    "href": "posts/Regr-Bayes-interpret03/Regr-Bayes-interpret03.html",
    "title": "Regr-Bayes-interpret03",
    "section": "",
    "text": "Exercise\nBerechnen Sie das Modell und interpretieren Sie die Ausgabe des folgenden Regressionsmodells. Geben Sie f√ºr jeden Regressionskoeffizienten an, wie sein Wert zu verstehen ist! Interpretieren Sie auch die Interaktion.\nmpg_z ~ hp_z + am + hp_z:am\nHinweise:\n\nFixieren Sie die Zufallszahlen.\nVerwenden Sie Stan zur Berechnung.\nRunden Sie auf 2 Dezimalstellen.\nDas Suffix _z steht f√ºr z-standardisierte Variablen.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Stan, komm her\nlibrary(easystats)  # Komfort\n\ndata(mtcars)\n\nZuerst standardisieren wir die Daten:\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nmtcars2  %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.090625\n6.0269481\n7.525000\n10.4000000\n33.900000\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl\n6.187500\n1.7859216\n4.000000\n4.0000000\n8.000000\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp\n230.721875\n123.9386938\n221.525000\n71.1000000\n472.000000\n0.4202331\n-1.0675234\n32\n0\n\n\nhp\n146.687500\n68.5628685\n84.500000\n52.0000000\n335.000000\n0.7994067\n0.2752116\n32\n0\n\n\ndrat\n3.596563\n0.5346787\n0.840000\n2.7600000\n4.930000\n0.2927802\n-0.4504325\n32\n0\n\n\nwt\n3.217250\n0.9784574\n1.186250\n1.5130000\n5.424000\n0.4659161\n0.4165947\n32\n0\n\n\nqsec\n17.848750\n1.7869432\n2.022500\n14.5000000\n22.900000\n0.4063466\n0.8649307\n32\n0\n\n\nvs\n0.437500\n0.5040161\n1.000000\n0.0000000\n1.000000\n0.2645418\n-2.0632731\n32\n0\n\n\nam\n0.406250\n0.4989909\n1.000000\n0.0000000\n1.000000\n0.4008089\n-1.9665503\n32\n0\n\n\ngear\n3.687500\n0.7378041\n1.000000\n3.0000000\n5.000000\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb\n2.812500\n1.6152000\n2.000000\n1.0000000\n8.000000\n1.1570911\n2.0200593\n32\n0\n\n\nmpg_z\n0.000000\n1.0000000\n1.248559\n-1.6078826\n2.291272\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl_z\n0.000000\n1.0000000\n2.239740\n-1.2248578\n1.014882\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp_z\n0.000000\n1.0000000\n1.787376\n-1.2879099\n1.946754\n0.4202331\n-1.0675234\n32\n0\n\n\nhp_z\n0.000000\n1.0000000\n1.232446\n-1.3810318\n2.746567\n0.7994067\n0.2752116\n32\n0\n\n\ndrat_z\n0.000000\n1.0000000\n1.571037\n-1.5646078\n2.493904\n0.2927802\n-0.4504325\n32\n0\n\n\nwt_z\n0.000000\n1.0000000\n1.212368\n-1.7417722\n2.255336\n0.4659161\n0.4165947\n32\n0\n\n\nqsec_z\n0.000000\n1.0000000\n1.131821\n-1.8740103\n2.826755\n0.4063466\n0.8649307\n32\n0\n\n\nvs_z\n0.000000\n1.0000000\n1.984063\n-0.8680278\n1.116036\n0.2645418\n-2.0632731\n32\n0\n\n\nam_z\n0.000000\n1.0000000\n2.004045\n-0.8141431\n1.189901\n0.4008089\n-1.9665503\n32\n0\n\n\ngear_z\n0.000000\n1.0000000\n1.355373\n-0.9318192\n1.778928\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb_z\n0.000000\n1.0000000\n1.238237\n-1.1221521\n3.211677\n1.1570911\n2.0200593\n32\n0\n\n\n\n\n\n\n\nm1 &lt;- \n  stan_glm(mpg_z ~ hp_z + am + hp_z:am, \n           seed = 42,\n           refresh = 0,\n           data = mtcars2)\n\ncoef(m1)\n\n (Intercept)         hp_z           am      hp_z:am \n-0.357413145 -0.677859338  0.876342434  0.005465839 \n\n\n\nIntercept: Ein Auto mit 0 PS und Automatikantrieb (am=0, s. Hilfe zum Datensatz: help(mtcars)) kann laut Modell mit einer Gallone Sprit ca. -0.36 Meilen fahren. Dieser Wert ist ca. Null, da die AV z-standardisiert ist. Ein Wert von Null in einer z-standardisierten Variablen entspricht dem Mittelwert in den Rohwerten.\nhp: Pro zus√§tzlichem PS kann ein Auto mit Automatikantrieb pro Gallone Sprit ca. -0.68 Meilen weniger weit fahren.\nam: Ein Auto mit 0 PS und Schaltgetriebe (am=1) kommt pro Gallone Sprit ca. 0.88 Meilen weiter als ein Auto mit Automatikantrieb.\nhp:am: Der Interaktionseffekt ist praktisch Null (-0.36): Der Zusammenhang von PS-Zahl und Spritverbrauch unterscheidet sich nicht (wesentlich) zwischen Autos mit bzw. ohne Automatikantrieb.\n\n\nCategories:\n\nbayes\nregression"
  },
  {
    "objectID": "posts/kausal06/kausal06.html",
    "href": "posts/kausal06/kausal06.html",
    "title": "kausal06",
    "section": "",
    "text": "Im Rahmen einer Studie soll untersucht werden, ob eine Influenza-Infektion einen (kausalen) Einfluss auf eine Covid19-Infektion hat. Au√üerdem wird dabei der Nutzen des Medikaments Acetaminophen untersucht.\nIn Wahrheit (aber unbekannt) sei der DAG wie folgt (s.u.).\n\n\n\n\n\n\n\n\n\nIst es sinnvoll, die Einnahme von Fiebersenker (Acetaminophen) zu kontrollieren?\n\n\n\nNein, es ist nicht sinnvoll, da durch eine Kontrolle von Acetaminophen eine Verzerrung erzeugt wird (Kollision)\nJa, nur so ist ein kausaler Effekt identifizierbar\nJa, es ist nicht n√∂tig, aber wird zu exakteren Ergebnissen f√ºhren\nNein, es ist nicht sinnvoll,da durch eine Kontrolle von Acetaminophen eine Verzerrung erzeugt wird (Konfundierung)\nNein, es ist nicht sinnvoll, da es nicht n√∂tig ist (aber auch nicht sch√§dlich)"
  },
  {
    "objectID": "posts/kausal06/kausal06.html#answerlist",
    "href": "posts/kausal06/kausal06.html#answerlist",
    "title": "kausal06",
    "section": "",
    "text": "Nein, es ist nicht sinnvoll, da durch eine Kontrolle von Acetaminophen eine Verzerrung erzeugt wird (Kollision)\nJa, nur so ist ein kausaler Effekt identifizierbar\nJa, es ist nicht n√∂tig, aber wird zu exakteren Ergebnissen f√ºhren\nNein, es ist nicht sinnvoll,da durch eine Kontrolle von Acetaminophen eine Verzerrung erzeugt wird (Konfundierung)\nNein, es ist nicht sinnvoll, da es nicht n√∂tig ist (aber auch nicht sch√§dlich)"
  },
  {
    "objectID": "posts/kausal06/kausal06.html#answerlist-1",
    "href": "posts/kausal06/kausal06.html#answerlist-1",
    "title": "kausal06",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/Logikpruefung1/Logikpruefung1.html",
    "href": "posts/Logikpruefung1/Logikpruefung1.html",
    "title": "Logikpruefung1",
    "section": "",
    "text": "Aufgabe\nWir definieren x wie folgt:\n\nx &lt;- 42\n\nGeben Sie die Syntax an, f√ºr die Pr√ºfung, ob x kleiner 100 und gr√∂√üer 0 ist.\nGeben Sie keine Leerzeichen in Ihre L√∂sung ein.\n         \n\n\nL√∂sung\n\nx&lt;100&x&gt;0\n\n[1] TRUE\n\n\nMit Leerzeichen sieht es aber sch√∂ner aus:\n\nx &lt; 100 & x &gt; 0\n\n[1] TRUE\n\n\n\nCategories:\n\nR\n‚Äò2023‚Äô\nLogikpruefung1"
  },
  {
    "objectID": "posts/pupil-size/pupil-size.html",
    "href": "posts/pupil-size/pupil-size.html",
    "title": "pupil-size",
    "section": "",
    "text": "Aufgabe\nPupillendaten sind ein verbreiteter Analysegegenstand in Bereichen wie Psychologie, Marktforschung und Marketing.\nBetrachten wir dazu ein R-Paket (zum Vorverbarbeitung, preprocessing) und einen Datensatz der Uni M√ºnster.\n\nlibrary(PupilPre)  # installieren, einmalig, nicht vergessen\ndata(\"Pupildat\")\nd &lt;-\n  Pupildat %&gt;% \n  select(size = RIGHT_PUPIL_SIZE,\n         time = TIMESTAMP) %&gt;% \n  mutate(size = size / 100) # in millimeter\n\nMit dem R-Paket eaystats kann man sich bequem typische Statistiken ausgeben lassen. Aber nat√ºrlich k√∂nnen Sie auch mit summarise(mw = mean(size)) o.√Ñ. arbeiten.\n\nlibrary(easystats)\nd %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nsize\n1.000562e+01\n5.107151e+00\n3.88\n1.04\n25.01\n1.2474408\n0.3199426\n45343\n1607\n\n\ntime\n2.990837e+06\n9.874538e+05\n1947161.00\n1443974.00\n4062110.00\n-0.4111739\n-1.6982498\n46950\n0\n\n\n\n\n\n\nWir verzichten hier auf eine Aufbereitung der Daten (was eigentlich n√∂tig w√§re, aber nicht Gegenstand dieser √úbung ist). Stattdessen konzentrieren wir uns auf die Posteriori-Verteilung zur Pupillengr√∂√üe.\nWir sind also interessiert an einem Modell zur Sch√§tzung der (Verteilung der) Pupillengr√∂√üe; die Posteriori-Verteilung bildet das ab.\nAufgaben:\n\nFormulieren Sie ein passendes Modell.\nVerteidigen Sie Ihre Modellspezifikation.\nSimulieren Sie Daten aus der Priori-Verteilung. Kritisieren Sie die Wahl der Priori-Werte.\nBerechnen Sie die Posteriori-Verteilung mit den Pupillendaten d. Geben Sie zentrale Statistiken an.\nGeben Sie ein 95%-Intervall f√ºr die mittlere Pupillengr√∂√üe an auf Basis der Posteriori-Verteilung.\nGeben Sie die Prioris an, die rstanarm verwendet hat.\n\nHinweise:\n\nVerwenden Sie die Defaults von rstanarm f√ºr Ihr Modell.\nFalls Sie Teile der Aufgabe nicht l√∂sen k√∂nnen, weil Ihnen der Stoff dazu fehlt: Einfach ignorieren üòÑ.\n\n         \n\n\nL√∂sung\n\nModelldefinition\n\n\\[\\begin{aligned}\ns_i &\\sim \\mathcal{N}(\\mu, \\sigma)\\qquad \\text{| s wie size }\\\\\n\\mu &\\sim \\mathcal{N}(10, 5)\\\\\n\\sigma &\\sim \\mathcal{E}(.2)\n\\end{aligned}\\]\n\nBegr√ºndung der Modellspezifikation\n\n\\(s_i\\): Pupillengr√∂√üen sind normalverteilt, da viele Gene additiv auf die Gr√∂√üe hin zusammenwirken\n\\(\\mu\\): Da wir nicht viel wissen √ºber die mittlere Pupillengr√∂√üe, entscheiden wir uns f√ºr Normalverteilung f√ºr diesen Parameter, da dies keine weiteren Annahmen (au√üer dass Mittelwert und Streuung endlich sind) hinzuf√ºgt. Ein Modell mit wenig Annahmen nennt man ‚Äúsparsam‚Äù oder konservativ. Es ist w√ºnschenswert, dass Modelle mit so wenig wie m√∂glich Annahmen auskommt (aber so vielen wie n√∂tig).\n\\(\\sigma\\): Die Streuung muss positiv sein, daher kommt keine Normalverteilung in Frage. Eine Exponentialverteilung ist eine von mehreren denkbaren Verteilungen.\nAber welche Werte von lambda kommen in Frage? Probieren wir mal etwas aus:\n\nqexp(p = .5, rate = 1)\n\n[1] 0.6931472\n\n\nMit \\(\\lambda = 1\\) liegt der Median der Streuung der Pupillengr√∂√üen (p = .5) bei ca. 0.7 mm. Dieser Wert erscheint mir etwas wenig\n\nqexp(p = .5, rate = 0.2)\n\n[1] 3.465736\n\n\nHm. Eine Streuung von ca. 3.5mm um den Mittelwert herum; das k√∂nnte passen.\nDie gro√üe Stichprobe wird den Priori-Wert vermutlich √ºberstimmen.\n\nPriori-Pr√§diktiv-Verteilung\n\n\nn &lt;- 1e4\nsim_prior_pred &lt;-\n  tibble(\n    mu = rnorm(n, mean = 10, sd = 5),\n    sigma = runif(n, min = 0, max = 20),\n    size = rnorm(n, mu, sigma)\n  )\n\nsim_prior_pred %&gt;% \n  ggplot(aes(x = size)) +\n  geom_density()\n\n\n\n\n\n\n\n\nDa es viele negative Pupillengr√∂√üe-Werte gibt, sieht man deutlich, dass das Modell nicht gut spezifiziert ist. So k√∂nnte kleinere Streuungswerte zu einem realistischeren Modell f√ºhren. Oder man verwendet Verteilungen, die rein positiv sind (hier nicht weiter ausgef√ºhrt).\n\nBerechnen Sie die Posteriori-Verteilung.\n\nDie Modelle wie stan_glm() tun sich leichter, wenn man nur die relevanten Daten, ohne fehlende Werte und schon sch√∂n fertig vorverarbeitet, zur Analyse in die Modellberechnung gibt:\n\nd3 &lt;-\n  d %&gt;% \n  select(size) %&gt;% \n  drop_na()\n\nDie Posteriori-Verteilung kann man mit dem Paket {rstanarm} d.h. mit der Funktion stan_glm() berechnen:\n\nlibrary(rstanarm)\nm_pupil &lt;- stan_glm(size ~ 1,\n                    data = d3,\n                    seed = 42,\n                    refresh = 0)\n\nDie Daten sind gro√ü, es kann ein paar Sekunden brauchen‚Ä¶\nHier ist eine n√ºtzliche Zusammenfassung der Post-Verteilung.\n\nparameters(m_pupil)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n10.00556\n0.95\n9.958776\n10.05205\n1\n1.000263\n1991.503\nnormal\n10.00562\n12.76788\n\n\n\n\n\n\nHier eine Visualisierung der Parameter:\n\nplot(parameters(m_pupil), show_intercept = TRUE)\n\n\n\n\n\n\n\n\nNat√ºrlich kann man auch die Post-Verteilung plotten (z.B: HDI):\n\nm_hdi &lt;- hdi(m_pupil, ci = c(0.5, 0.95))\n\nplot(m_hdi, show_intercept = TRUE)  # Im Default wird der Intercept nicht gezeigt\n\n\n\n\n\n\n\n\nHier zur Info die ersten paar Zeilen des Post-Verteilung:\n\n\n\n\n\n\n\n\n(Intercept)\nsigma\n\n\n\n\n10.04\n5.13\n\n\n10.00\n5.07\n\n\n9.99\n5.08\n\n\n10.00\n5.08\n\n\n9.99\n5.11\n\n\n\n\n\n\n\n\nGeben Sie ein 95%-Intervall f√ºr die mittlere Pupillengr√∂√üe an auf Basis der Posteriori-Verteilung.\n\n\neti(m_pupil)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n9.958776\n10.05205\nfixed\nconditional\n\n\n\n\n\n\nUnd dann erstellen wir noch ein 89%-PI, einfach zum Spa√ü an der Freude:\n\neti(m_pupil, ci = .89)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.89\n9.966516\n10.04339\nfixed\nconditional\n\n\n\n\n\n\n\nGeben Sie die Prioris an, die rstanarm verwendet hat.\n\nVoil√†:\n\nprior_summary(m_pupil)\n\nPriors for model 'm_pupil' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 10, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 10, scale = 13)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.2)\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\nCategories:\n\nprobability\nbayes\nregression\nstring"
  },
  {
    "objectID": "posts/sicherheit2/sicherheit2.html",
    "href": "posts/sicherheit2/sicherheit2.html",
    "title": "sicherheit2",
    "section": "",
    "text": "Aufgabe\nEin Betreiber eines komplexen technischen Ger√§ts versucht, Sie zu beruhigen: Die Wahrscheinlichkeit eines Ausfalls (Ereignis \\(A\\)) betrage nur 0.001. Allerdings pro Komponente des Ger√§ts. Das Ger√§t besteht aus \\(k=10^3\\) Komponenten.\nBerechnen Sie die Wahrscheinlichkeit, dass das Ger√§t funktioniert (also nicht ausf√§llt)!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nUnterstellen Sie Unabh√§ngigkeit der Komponenten.\n\n         \n\n\nL√∂sung\nDen Ausfall der Komponente \\(i\\) bezeichnen wir als \\(A_i\\) und entsprechend \\(Pr(A_i) = 0.001\\).\n\\(Pr(\\neg A_i) = 1- Pr(A_i)\\)\n\nPr_Ai &lt;- 0.001\nPr_negAi &lt;- 1 - Pr_Ai\nPr_negAi\n\n[1] 0.999\n\n\nDie Wahrscheinlichkeit, dass keine der Komponenten ausf√§llt, ist dann √ºber den Multiplikationssatzu bestimmen:\n\nk &lt;- 10^3\nPr_negA &lt;- Pr_negAi^k\nPr_negA\n\n[1] 0.3676954\n\n\nDie L√∂sung lautet 0.3676954.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/Ziele-Statistik/Ziele-Statistik.html",
    "href": "posts/Ziele-Statistik/Ziele-Statistik.html",
    "title": "Ziele-Statistik",
    "section": "",
    "text": "Welche von den folgenden Optionen geh√∂rt nicht zu den Zielen von Statistik bzw. einer Forschungsfrage mit statistischem Character?\n\n\n\nverstehen\nerkl√§ren\nvorhersagen\nbeschreiben"
  },
  {
    "objectID": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist",
    "href": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist",
    "title": "Ziele-Statistik",
    "section": "",
    "text": "verstehen\nerkl√§ren\nvorhersagen\nbeschreiben"
  },
  {
    "objectID": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist-1",
    "href": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist-1",
    "title": "Ziele-Statistik",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nbasics\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/bfi10/index.html",
    "href": "posts/bfi10/index.html",
    "title": "bfi10",
    "section": "",
    "text": "1 Aufgabe\nAuf der Webseite des Leibniz-Instituts f√ºr Sozialwissenschaften, GESIS kann man u.a. psychologische Skalen f√ºr die Forschung finden. Eine dieser Skalen ist as Big Five Inventory (BFI-10). Autor/in: Rammstedt, B., Kemper, C. J., Klein, M. C., Beierlein, C., & Kovaleva, A. In Tabelle 8 sind ‚ÄúReferenzwerte‚Äù f√ºr das Merkmal ‚ÄúExtraversion‚Äù angegeben. Die Werte sind als Mittelwert und Standardabweichung angegeben:\n\nDen Artikel zu dieser Skala findet man hier.\nGehen wir davon aus, dass das Merkmalsverhalten normalverteilt ist. Dann k√∂nnen wir die Verteilungsfunktion der Extraversion berechnen.\nEine Normalverteilungstabelle findet sich z.B. bei Wikipedia oder z.B. hier.\nEine k√ºrzere Tabelle zur Verteilungsfunktion der Standardnormalverteilung ist hier wiedergegeben.\n\n\n\n\n\nz\np\n\n\n\n\n-2.0\n0.02\n\n\n-1.9\n0.03\n\n\n-1.8\n0.04\n\n\n-1.7\n0.04\n\n\n-1.6\n0.05\n\n\n-1.5\n0.07\n\n\n-1.4\n0.08\n\n\n-1.3\n0.10\n\n\n-1.2\n0.12\n\n\n-1.1\n0.14\n\n\n-1.0\n0.16\n\n\n-0.9\n0.18\n\n\n-0.8\n0.21\n\n\n-0.7\n0.24\n\n\n-0.6\n0.27\n\n\n-0.5\n0.31\n\n\n-0.4\n0.34\n\n\n-0.3\n0.38\n\n\n-0.2\n0.42\n\n\n-0.1\n0.46\n\n\n0.0\n0.50\n\n\n0.1\n0.54\n\n\n0.2\n0.58\n\n\n0.3\n0.62\n\n\n0.4\n0.66\n\n\n0.5\n0.69\n\n\n0.6\n0.73\n\n\n0.7\n0.76\n\n\n0.8\n0.79\n\n\n0.9\n0.82\n\n\n1.0\n0.84\n\n\n1.1\n0.86\n\n\n1.2\n0.88\n\n\n1.3\n0.90\n\n\n1.4\n0.92\n\n\n1.5\n0.93\n\n\n1.6\n0.95\n\n\n1.7\n0.96\n\n\n1.8\n0.96\n\n\n1.9\n0.97\n\n\n2.0\n0.98\n\n\n\n\n\nAufgabe Geben Sie die Wahrscheinlichkeit an, dass ein Mann im Alter von 19 Jahren mit geringer Bildung einen Extraversionsscore von 4.28 oder weniger hat.\n  \n  \n  \n  \n\n\n2 L√∂sung\nMit Hilfe des Computers ist es komfortabel. Wir k√∂nnen die Funktion pnorm verwenden, um die Wahrscheinlichkeit zu berechnen, dass ein Mann im Alter von 19 Jahren mit geringer Bildung einen Extraversionsscore von 4.28 oder weniger hat.\n\npnorm(4.28, mean = 3.42, sd = 0.86)\n\n[1] 0.8413447\n\n\nAnsonsten muss man die Standardnormalverteilungstabelle verwenden. Daf√ºr transformiert man den Wert 4.28 in einen z-Wert.\nDen Z-wert berechnet man mit der Formel:\n\\[z = \\frac{x - \\mu}{\\sigma}\\]\n\nz &lt;- (4.28 - 3.42) / 0.86\nz\n\n[1] 1\n\n\nDen Wert der kumulierten Wahrscheinlichkeit kann man in der Tabelle nachschlagen.\nDas bedeutet, dass die Wahrscheinlichkeit, dass ein Mann im Alter von 19 Jahren mit geringer Bildung einen Extraversionsscore von 4.28 oder weniger hat, .84 betr√§gt.\n\nxpnorm(q = 4.28, mean = 3.42, sd = .86)\n\n\n\n\n\n\n\n\n[1] 0.8413447\n\n\nBonusfrage\nWie hoch ist die Wahrscheinlichkeit, einen jungen Mann mit geringer Bildung (19 Jahre) zu testen, der √ºber einen Extraversionswert von mind. 3.42 verf√ºgt?\nAntwort\n50%, da 3.42 genau dem Mittelwert der Verteilung entspricht. Da die Verteilung symmetrisch ist, ist die Wahrscheinlichkeit, dass ein Wert gr√∂√üer als der Mittelwert ist, gleich der Wahrscheinlichkeit, dass ein Wert kleiner als der Mittelwert ist.\n\nxpnorm(q = 3.42, mean = 3.42, sd = .86)\n\n\n\n\n\n\n\n\n[1] 0.5"
  },
  {
    "objectID": "posts/rf-usemodels/rf-usemodels.html",
    "href": "posts/rf-usemodels/rf-usemodels.html",
    "title": "rf-usemodels",
    "section": "",
    "text": "Berechnen Sie ein pr√§diktives Modell mit dieser Modellgleichung:\nbody_mass_g ~ . (Datensatz: palmerpenguins::penguins).\nNutzen Sie usemodels!\nHinweise: - Tunen Sie mtry - Verwenden Sie Kreuzvalidierung - Verwenden Sie Standardwerte, wo nicht anders angegeben. - Fixieren Sie Zufallszahlen auf den Startwert 42."
  },
  {
    "objectID": "posts/rf-usemodels/rf-usemodels.html#vorbereitung",
    "href": "posts/rf-usemodels/rf-usemodels.html#vorbereitung",
    "title": "rf-usemodels",
    "section": "Vorbereitung:",
    "text": "Vorbereitung:\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# rm NA in the dependent variable:\nd &lt;- d %&gt;% \n  drop_na(body_mass_g)\n\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\nlibrary(usemodels)\nuse_ranger(body_mass_g ~ ., data = d_train)\n\nranger_recipe &lt;- \n  recipe(formula = body_mass_g ~ ., data = d_train) \n\nranger_spec &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"ranger\") \n\nranger_workflow &lt;- \n  workflow() %&gt;% \n  add_recipe(ranger_recipe) %&gt;% \n  add_model(ranger_spec) \n\nset.seed(32162)\nranger_tune &lt;-\n  tune_grid(ranger_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\nOder die resultierende Syntax in die Zwischenablage kopieren lassen:\n\nuse_ranger(body_mass_g ~ ., data = d_train,\n           clipboard = TRUE)  # kopiert Syntax in die Zwischenablage\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie ein Elasticnet. Tunen Sie alle Parameter mit insgesamt 100 Kandidaten.\n\n\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\n\n\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\n\n\n\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#daten",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#daten",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "",
    "text": "Verwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#av-und-uv",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#av-und-uv",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "",
    "text": "Die AV lautet c1. Die (einzige) UV lautet: text."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#hinweise",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#hinweise",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "",
    "text": "Orientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#setup",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#setup",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Setup",
    "text": "Setup\nTrain-Datensatz:\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\nPakete:\n\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(beepr)\nlibrary(finetune)  # anova race\n\nEine Vorlage f√ºr ein Tidymodels-Pipeline findet sich hier."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#learnermodell",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#learnermodell",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Learner/Modell",
    "text": "Learner/Modell\n\nmod &lt;-\n  logistic_reg(mode = \"classification\",\n               penalty = tune(), \n               mixture = tune(),\n               engine = \"glmnet\"\n             )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#gebackenen-datensatz-als-neue-grundlage",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#gebackenen-datensatz-als-neue-grundlage",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Gebackenen Datensatz als neue Grundlage",
    "text": "Gebackenen Datensatz als neue Grundlage\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz. Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind. Die Arbeit des Feature Engineering wurde uns schon abgenommen.\n\nd_train_raw &lt;-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\n\nd_test_baked_raw &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#keine-dummysierung-der-av",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#keine-dummysierung-der-av",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Keine Dummysierung der AV",
    "text": "Keine Dummysierung der AV\nLineare Modelle m√ºssen dummysiert sein. Rezepte wollen das nicht so gerne f√ºr die AV besorgen.\nABER: Klassifikationsmodelle in Tiymodels (parsnip) ben√∂tigen eine factor Variable als AV, sonst werden sie nicht als Klassifikation erkannt.\n\nd_train &lt;-\n  d_train_raw |&gt; \n  mutate(c1 = as.factor(c1)) \n\nlevels(d_train$c1)\n\nTidymodels modelliert die erste Stufe.\n\nd_test_baked &lt;-\n  d_test_baked_raw |&gt; \n  mutate(c1 = as.factor(c1)) \n\nlevels(d_test_baked$c1)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#dummy-rezept",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#dummy-rezept",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Dummy-Rezept",
    "text": "Dummy-Rezept\nPlain, aber mit Dummyisierung:\n\nrec &lt;- \n  recipe(c1 ~ ., data = d_train)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#workflow",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#workflow",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Workflow",
    "text": "Workflow\n\nwf &lt;-\n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#parallelisierung-√ºber-mehrere-kerne",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#parallelisierung-√ºber-mehrere-kerne",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Parallelisierung √ºber mehrere Kerne",
    "text": "Parallelisierung √ºber mehrere Kerne\n\nlibrary(parallel)\nall_cores &lt;- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl &lt;- makeCluster(3)\nplan(cluster, workers = cl)\n\nAchtung: Viele Kerne brauchen auch viel Speicher."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#tuneresamplefit",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#tuneresamplefit",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Tune/Resample/Fit",
    "text": "Tune/Resample/Fit\n\ntic()\nfit_wordvec_senti_elasticnet &lt;-\n  tune_race_anova(\n    wf,\n    grid = 100,\n    resamples = vfold_cv(d_train, v = 5),\n    control = control_race(verbose_elim = TRUE))\ntoc()\nbeep()"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#beste-performance",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#beste-performance",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Beste Performance",
    "text": "Beste Performance\n\nautoplot(fit_wordvec_senti_elasticnet)\n\n\nshow_best(fit_wordvec_senti_elasticnet)\n\nbest_params &lt;- select_best(fit_wordvec_senti_elasticnet)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#finalisieren",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#finalisieren",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Finalisieren",
    "text": "Finalisieren\n\ntic()\nwf_finalized &lt;- finalize_workflow(wf, best_params)\nlastfit &lt;- fit(wf_finalized, data = d_train)\ntoc()"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-elasticnet/germeval-sent-wordvec-elasticnet.html#test-set-g√ºte",
    "title": "germeval03-sent-wordvec-elasticnet",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(lastfit, new_data = d_test_baked)\ntoc()\n\n\nd_test &lt;-\n  d_test_baked |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/count-words01/count-words01.html",
    "href": "posts/count-words01/count-words01.html",
    "title": "count-words01",
    "section": "",
    "text": "Z√§hlen sie die W√∂rter eines Textes. Verwenden Sie verschiedene Verfahren. Untersuchen Sie die Rechenzeit, die die jeweiligen Verfahren ben√∂tigen.\nNutzen Sie die GermEval-2018-Daten. Die Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)), Die Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\nd_train &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/germeval_train.csv\")\nd_test &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/germeval_test.csv\")\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/count-words01/count-words01.html#stringrstr_count",
    "href": "posts/count-words01/count-words01.html#stringrstr_count",
    "title": "count-words01",
    "section": "stringr::str_count",
    "text": "stringr::str_count\n\ntest_text$text |&gt; \n  map_int(str_count, \"\\\\w+\")\n\n[1] 3 2 2 3\n\n\nOder so:\n\ntest_text$text |&gt; \n  map_int(str_count, boundary(\"word\"))\n\n[1] 3 2 2 3\n\n\nDie Funktion map ist nicht n√∂tig:\n\nstr_count(test_text$text, boundary(\"word\"))\n\n[1] 3 2 2 3\n\n\nAls neue Spalte in der Tabelle:\n\ntest_text |&gt; \n  mutate(n_words = str_count(text, boundary(\"word\")))\n\n\n\n\n\nid\ntext\nvalence\nn_words\n\n\n\n\n1\nAbbau ist jetzt\n-1\n3\n\n\n2\nTest heute\n0\n2\n\n\n3\nAbbruch morgen\n-1\n2\n\n\n4\nAbmachung lore ipsum\n1\n3"
  },
  {
    "objectID": "posts/count-words01/count-words01.html#tokenizerscount_words",
    "href": "posts/count-words01/count-words01.html#tokenizerscount_words",
    "title": "count-words01",
    "section": "tokenizers::count_words",
    "text": "tokenizers::count_words\n\ntokenizers::count_words(test_text$text)\n\n[1] 3 2 2 3\n\n\n\ntest_text |&gt; \n  mutate(n_words = tokenizers::count_words(text))\n\n\n\n\n\nid\ntext\nvalence\nn_words\n\n\n\n\n1\nAbbau ist jetzt\n-1\n3\n\n\n2\nTest heute\n0\n2\n\n\n3\nAbbruch morgen\n-1\n2\n\n\n4\nAbmachung lore ipsum\n1\n3"
  },
  {
    "objectID": "posts/count-words01/count-words01.html#qdapwc",
    "href": "posts/count-words01/count-words01.html#qdapwc",
    "title": "count-words01",
    "section": "qdap:wc",
    "text": "qdap:wc\n\nqdap::wc(test_text$text)\n\n[1] 3 2 2 3"
  },
  {
    "objectID": "posts/count-words01/count-words01.html#stringrstr_count-1",
    "href": "posts/count-words01/count-words01.html#stringrstr_count-1",
    "title": "count-words01",
    "section": "stringr::str_count",
    "text": "stringr::str_count\n\ntic()\nmethod1 &lt;- germeval_train$text |&gt; \n  map_int(str_count, \"\\\\w+\")\ntoc()\n\n0.206 sec elapsed\n\nmethod1 |&gt; str()\n\n int [1:5009] 15 19 11 21 15 44 34 8 13 14 ...\n\n\n\nprint(method1, max = 20)\n\n [1] 15 19 11 21 15 44 34  8 13 14 14 28 39 22 43 28 19 23 25 13\n [ reached getOption(\"max.print\") -- omitted 4989 entries ]\n\n\nOder so:\n\ntic()\nmethod2 &lt;- germeval_train$text |&gt; \n  map_int(str_count, boundary(\"word\"))\ntoc()\n\n0.163 sec elapsed\n\n\n\nhead(method2)\n\n[1] 15 19 10 21 15 44\n\n\nDie Funktion map ist nicht n√∂tig:\n\ntic()\nmethod3 &lt;- str_count(germeval_train$text, boundary(\"word\"))\ntoc()\n\n0.021 sec elapsed\n\n\n\nmethod3 |&gt; head()\n\n[1] 15 19 10 21 15 44\n\n\nDann geht es auch viel schneller.\nAls neue Spalte in der Tabelle:\n\ntic()\nmethod4 &lt;- \ngermeval_train |&gt; \n  mutate(n_words = str_count(text, boundary(\"word\")))\ntoc()\n\n0.027 sec elapsed\n\n\n\nstr(method4)\n\n'data.frame':   5009 obs. of  5 variables:\n $ id     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ text   : chr  \"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\" \"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nich\"| __truncated__ \"@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\" \"@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obam\"| __truncated__ ...\n $ c1     : chr  \"OTHER\" \"OTHER\" \"OTHER\" \"OTHER\" ...\n $ c2     : chr  \"OTHER\" \"OTHER\" \"OTHER\" \"OTHER\" ...\n $ n_words: int  15 19 10 21 15 44 34 8 13 14 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\nmethod4 |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntext\nc1\nc2\nn_words\n\n\n\n\n1\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n15\n\n\n2\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n19\n\n\n3\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n10\n\n\n4\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n21\n\n\n5\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n15\n\n\n6\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n44"
  },
  {
    "objectID": "posts/count-words01/count-words01.html#tokenizerscount_words-1",
    "href": "posts/count-words01/count-words01.html#tokenizerscount_words-1",
    "title": "count-words01",
    "section": "tokenizers::count_words",
    "text": "tokenizers::count_words\n\ntic()\nmethod5 &lt;- tokenizers::count_words(germeval_train$text)\ntoc()\n\n0.019 sec elapsed\n\nhead(method5)\n\n[1] 15 19 10 21 15 44\n\n\n\ntic()\nmethod6 &lt;-\ngermeval_train |&gt; \n  mutate(n_words = tokenizers::count_words(text))\ntoc()\n\n0.021 sec elapsed\n\nmethod6 |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntext\nc1\nc2\nn_words\n\n\n\n\n1\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n15\n\n\n2\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n19\n\n\n3\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n10\n\n\n4\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n21\n\n\n5\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n15\n\n\n6\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n44"
  },
  {
    "objectID": "posts/count-words01/count-words01.html#qdapwc-1",
    "href": "posts/count-words01/count-words01.html#qdapwc-1",
    "title": "count-words01",
    "section": "qdap::wc",
    "text": "qdap::wc\n\ntic()\nmethod7 &lt;- qdap::wc(germeval_train$text)\ntoc()\n\n0.99 sec elapsed\n\nmethod7 |&gt; head()\n\n[1] 15 20 10 19 15 42\n\n\nDeutlich langsamer als mit tokenizers.\n\nCategories:\n\ntextmining\ntidymodels\ncount\ngermeval\nstring"
  },
  {
    "objectID": "posts/small-wide-normal/index.html",
    "href": "posts/small-wide-normal/index.html",
    "title": "small-wide-normal",
    "section": "",
    "text": "1 Aufgabe\nDie folgenden Posterior-Verteilungen unterscheiden sich nicht in ihrem Modus, aber in ihrer Sicherheit zur Sch√§tzung des Modus. Welche der folgenden Posterior-Verteilungen ist die sicherste?\nA\n\n\n\n\n\n\n\n\n\nB\n\n\n\n\n\n\n\n\n\nC\n\n\n\n\n\n\n\n\n\nD\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nC"
  },
  {
    "objectID": "posts/adjustieren1/adjustieren1.html",
    "href": "posts/adjustieren1/adjustieren1.html",
    "title": "adjustieren1",
    "section": "",
    "text": "Exercise\nBetrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Pr√§diktor hp, um den Achsenabschnitt besser interpretieren zu k√∂nnen.\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(hp_z = hp - mean(hp))\n\n\nlibrary(rstanarm)\nlm1 &lt;- stan_glm(mpg ~ hp_z, data = mtcars,\n                refresh = 0)\nsummary(lm1)\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 20.1    0.7 19.2  20.1  21.0 \nhp_z        -0.1    0.0 -0.1  -0.1  -0.1 \nsigma        4.0    0.5  3.4   3.9   4.7 \nJetzt k√∂nnen wir aus dem Achsenabschnitt (Intercept) herauslesen, dass ein Auto mit hp_z = 0 - also mit mittlerer PS-Zahl - vielleicht gut 20 Meilen weit mit einer Gallone Sprit kommt.\nZur Verdeutlichung ein Diagramm zum Modell:\n\nmtcars %&gt;% \n  ggplot() +\n  aes(x = hp_z, y = mpg) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAdjustieren Sie im Modell die PS-Zahl um die Art des Schaltgetriebes (am), so dass das neue Modell den statistischen Effekt (nicht notwendig auch kausal) der PS-Zahl bereinigt bzw. unabh√§ngig von der Art des Schaltgetriebes widerspiegelt!\nHinweise:\n\nam=0 ist ein Auto mit Automatikgetriebe.\nWir gehen davon aus, dass der Regressionseffekt gleich stark ist auf allen (beiden) Stufen von am. M.a.W.: Es liegt kein Interaktionseffekt vor.\n\n         \n\n\nSolution\n\nlibrary(rstanarm)\nlm2 &lt;- stan_glm(mpg ~ hp_z + am, data = mtcars,\n                refresh = 0)\nsummary(lm2)\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 26.6    1.5 24.7  26.6  28.5 \nhp          -0.1    0.0 -0.1  -0.1   0.0 \nam           5.3    1.1  3.8   5.3   6.6 \nsigma        3.0    0.4  2.5   3.0   3.5 \nDie Spalte mean gibt den mittleren gesch√§tzten Wert f√ºr den jeweiligen Koeffizienten an, also den Sch√§tzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt f√ºr Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als f√ºr Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\n\nmtcars %&gt;% \n  mutate(am = factor(am)) %&gt;% \n  ggplot() +\n  aes(x = hp_z, y = mpg, color = am) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nMan k√∂nnte hier noch einen Interaktionseffekt erg√§nzen.\n\nCategories:\n\nqm2\nlm\nbayes\nstats-nutshell"
  },
  {
    "objectID": "posts/exp-tab/index.html",
    "href": "posts/exp-tab/index.html",
    "title": "exp-tab",
    "section": "",
    "text": "1 Aufgabe\nGegeben sei\n\\(x \\sim \\text{Exp}(1)\\).\nGesucht ist folgendes Quantil: 95 %.\nNutzen Sie die Tabelle der Exponentialverteilung, um das Quantil zu bestimmen.\n\n\n\n\n\n\nrate\n2.5 %\n5 %\n50 %\n95 %\n97.5 %\n\n\n\n\n1.00\n0.03\n0.05\n0.69\n3.00\n3.69\n\n\n2.00\n0.01\n0.03\n0.35\n1.50\n1.84\n\n\n4.00\n0.01\n0.01\n0.17\n0.75\n0.92\n\n\n8.00\n0.00\n0.01\n0.09\n0.37\n0.46\n\n\n0.50\n0.05\n0.10\n1.39\n5.99\n7.38\n\n\n0.25\n0.10\n0.21\n2.77\n11.98\n14.76\n\n\n0.12\n0.20\n0.41\n5.55\n23.97\n29.51\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nDas 95 % Quantil der Exponentialverteilung mit \\(\\lambda = 1\\) betr√§gt 3.\nHier ist eine Visualisierung der Exponentialverteilung mit \\(\\lambda = 1\\) und dem 95 % Quantil."
  },
  {
    "objectID": "posts/germeval08-schimpf/germeval08-schimpf.html",
    "href": "posts/germeval08-schimpf/germeval08-schimpf.html",
    "title": "germeval08-schimpf",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Schimpfw√∂rter im Rahmen von Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon."
  },
  {
    "objectID": "posts/germeval08-schimpf/germeval08-schimpf.html#workflow",
    "href": "posts/germeval08-schimpf/germeval08-schimpf.html#workflow",
    "title": "germeval08-schimpf",
    "section": "Workflow",
    "text": "Workflow\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"classification\")\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  update_role(text, new_role = \"ignore\") |&gt; \n  step_mutate(n_schimpf = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = schimpfwoerter))  |&gt; \n  step_rm(text)  # Datensatz verschlanken\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval08-schimpf/germeval08-schimpf.html#fit",
    "href": "posts/germeval08-schimpf/germeval08-schimpf.html#fit",
    "title": "germeval08-schimpf",
    "section": "Fit",
    "text": "Fit\nOhne Tuning:\n\ntic()\nfit1 &lt;-\n  fit(wf1,\n      data = d_train)\ntoc()\n#beep()\n\n\nfit1"
  },
  {
    "objectID": "posts/germeval08-schimpf/germeval08-schimpf.html#test-set-g√ºte",
    "href": "posts/germeval08-schimpf/germeval08-schimpf.html#test-set-g√ºte",
    "title": "germeval08-schimpf",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n\nAls Check: Das gepreppte/bebackene Rezept:\n\ntic()\nrec1_prepped &lt;- prep(rec1)\ntoc()\n\n\ntic()\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\ntoc()\n\n\nd_train_baked |&gt; \n  arrange(-n_schimpf) |&gt; \n  head()\n\n\nd_train |&gt; \n  filter(id == 707) |&gt; \n  pull(text)\n\n\nd_train |&gt; \n  filter(id == 707) |&gt; \n  select(text) |&gt; \n  unnest_tokens(output = word, input = text) |&gt; \n  inner_join(schimpfwoerter)\n\n\nd_train |&gt; \n  filter(id == 4493) |&gt; \n  pull(text)\n\n\nd_train |&gt; \n  filter(id == 4493) |&gt; \n  select(text) |&gt; \n  unnest_tokens(output = word, input = text) |&gt; \n  inner_join(schimpfwoerter)\n\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nstring"
  },
  {
    "objectID": "posts/n-se/n-se.html",
    "href": "posts/n-se/n-se.html",
    "title": "n-se",
    "section": "",
    "text": "Gr√∂√üere Stichproben sind zwar aufw√§ndiger zu erheben, aber aussagekr√§ftiger unter sonst gleichen Umst√§nden, wie in der Abbildung dargestellt.\n\nWelche Aussagen sind in diesem Zusammenhang falsch?\n\n\n\nEine M√∂glichkeit zur Quantifizierung der Genauigkeit eines Sch√§tzers auf Basis einer Stichprobe ist das Berechnen der Streuung bei wiederholtem Ziehen der Stichprobe.\nEine typische Kennzahl der Quantifizierung der Genauigkeit eines Sch√§tzers ist der Standardfehler.\nJe gr√∂√üer die Stichprobe, desto kleiner der Standardfehler.\nAb einer Gr√∂√üe von \\(n=30\\) sind Stichproben robust und ausreichend pr√§zise Sch√§tzer f√ºr den gesuchten Populationsparameter."
  },
  {
    "objectID": "posts/n-se/n-se.html#answerlist",
    "href": "posts/n-se/n-se.html#answerlist",
    "title": "n-se",
    "section": "",
    "text": "Eine M√∂glichkeit zur Quantifizierung der Genauigkeit eines Sch√§tzers auf Basis einer Stichprobe ist das Berechnen der Streuung bei wiederholtem Ziehen der Stichprobe.\nEine typische Kennzahl der Quantifizierung der Genauigkeit eines Sch√§tzers ist der Standardfehler.\nJe gr√∂√üer die Stichprobe, desto kleiner der Standardfehler.\nAb einer Gr√∂√üe von \\(n=30\\) sind Stichproben robust und ausreichend pr√§zise Sch√§tzer f√ºr den gesuchten Populationsparameter."
  },
  {
    "objectID": "posts/regex-insert-char/regex-insert-char.html",
    "href": "posts/regex-insert-char/regex-insert-char.html",
    "title": "regex-insert-char",
    "section": "",
    "text": "Aufgabe\nGegeben sei ein String dieser Art (ggf. noch viel l√§nger, aber vom gleichen Aufbau):\n\nmy_string &lt;-c(\n\"word1\",\n\"word2\",\n\"word3\"\n)\n\nwriteLines(my_string)\n\nword1\nword2\nword3\n\n\n(writeLines druckt einen String, wo wie er am Bildschirm erscheint, wenn man einfach nur my_string eingibt, werden Steuerzeichen mitangezeigt.)\nWandeln Sie diesen String (programmatisch) um in folgende Form\n\nmy_string_out &lt;-c(\n'\"word1\"',\n'\"word2\"',\n'\"word3\"'\n)\n\nwriteLines(my_string_out)\n\n\"word1\"\n\"word2\"\n\"word3\"\n\n\n         \n\n\nL√∂sung\n\nlibrary(stringr)\n\n\nstr_replace_all(string = my_string,\n                pattern = \"(^\\\\w)(.+$)\",\n                replacement = '\\\\\"\\\\1\\\\2\\\\\"') %&gt;% \n  writeLines()\n\n\"word1\"\n\"word2\"\n\"word3\"\n\n\nErkl√§rung:\n\n(^\\\\w) ist eine Such-Gruppe, die aus den Treffern besteht, bei denen zu Beginn des Strings ein ‚ÄúWort-Zeichen‚Äù steht vgl. hier.\n(.+$) ist eine Such-Gruppe, die aus Treffern besteht, bei denen zum Ende des Strings ein beliebiges Zeichen steht.\n'\\\\\"\\\\1\\\\2\\\\\"' \\\\\" bezieht sich auf ein Anf√ºhrungszeichen, \\\\1 bezieht sich auf die 1. Such-Gruppe (analog f√ºr \\\\2).\n\nHat man innerhalb eines Strings ein Anf√ºhrungszeichen, so setzt man au√üen das einfache und innerhalb des Strings das doppelte Anf√ºhrungszeichen.\n\nCategories:\n\ntextmining\nregex\nstring"
  },
  {
    "objectID": "posts/fat-tails-Artikel/fat-tails-Artikel.html",
    "href": "posts/fat-tails-Artikel/fat-tails-Artikel.html",
    "title": "fat-tails-Artikel",
    "section": "",
    "text": "Exercise\nIn diesem Diagramm sehen Sie etwas Nomenklatur f√ºr eine Verteilung: Gipfel (Peak), Schultern (shoulders) und R√§nder (tails). Bitte klicken Sie den Link, um sich das Diagramm anzuschauen.\nQuelle: Taleb, N. N. (2019). The statistical consequences of fat tails, papers and commentaries. https://nassimtaleb.org/2020/01/final-version-fat-tails/\nZwar sind viele Daten in der Welt normalverteilt, aber l√§ngst nicht alle. In j√ºngerer Zeit sind sog. ‚ÄúFat Tails‚Äù in die Aufmerksamkeit ger√ºckt. Das sind Variablen, bei denen Werte in den R√§ndern (tails) wahrscheinlicher sind als bei einer Normalverteilung; ein Beispiel f√ºr eine Fat-Tail-Verteilung ist die t-Verteilung mit 1 Freiheitsgrad. Sie m√ºssen diese Verteilung nicht weiter kennen, es ist aber n√ºtzlich, zu wissen, wozu diese Verteilung n√ºtzt.\nRecherchieren Sie (Fach-)Artikel, die argumentieren, dass ein bestimmtes Ph√§nomen Fat-Tails zeigt!\n         \n\n\nSolution\n\nKriege\nPandemien\nErfolg auf der Singleb√∂rse Tinder\nKapitelmarkt\n\n\nCategories:\n\nprobability\ndistributions\nfat-tails"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html",
    "href": "posts/regr-tree01/regr-tree01.html",
    "title": "regr-tree01",
    "section": "",
    "text": "library(tidymodels)"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#setup",
    "href": "posts/regr-tree01/regr-tree01.html#setup",
    "title": "regr-tree01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\n\nF√ºr Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#daten-teilen",
    "href": "posts/regr-tree01/regr-tree01.html#daten-teilen",
    "title": "regr-tree01",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#modelle",
    "href": "posts/regr-tree01/regr-tree01.html#modelle",
    "title": "regr-tree01",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune())"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#rezepte",
    "href": "posts/regr-tree01/regr-tree01.html#rezepte",
    "title": "regr-tree01",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec1 &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#resampling",
    "href": "posts/regr-tree01/regr-tree01.html#resampling",
    "title": "regr-tree01",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#workflow",
    "href": "posts/regr-tree01/regr-tree01.html#workflow",
    "title": "regr-tree01",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec1) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#tuningfitting",
    "href": "posts/regr-tree01/regr-tree01.html#tuningfitting",
    "title": "regr-tree01",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\n\nfit1 &lt;-\n  tune_grid(object = wf1,\n            resamples = rsmpl)"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#bester-kandidat",
    "href": "posts/regr-tree01/regr-tree01.html#bester-kandidat",
    "title": "regr-tree01",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(fit1)\n\n\n\n\n\n\n\n\n\nshow_best(fit1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncost_complexity\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0e+00\nroc_auc\nbinary\n0.5\n2\n0\npre0_mod01_post0\n\n\n0.0e+00\nroc_auc\nbinary\n0.5\n2\n0\npre0_mod02_post0\n\n\n0.0e+00\nroc_auc\nbinary\n0.5\n2\n0\npre0_mod03_post0\n\n\n3.0e-07\nroc_auc\nbinary\n0.5\n2\n0\npre0_mod04_post0\n\n\n2.3e-06\nroc_auc\nbinary\n0.5\n2\n0\npre0_mod05_post0"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#finalisieren",
    "href": "posts/regr-tree01/regr-tree01.html#finalisieren",
    "title": "regr-tree01",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nwf1_finalized &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(fit1))"
  },
  {
    "objectID": "posts/regr-tree01/regr-tree01.html#last-fit",
    "href": "posts/regr-tree01/regr-tree01.html#last-fit",
    "title": "regr-tree01",
    "section": "Last Fit",
    "text": "Last Fit\n\nfinal_fit &lt;- \n  last_fit(object = wf1_finalized, d_split)\n\ncollect_metrics(final_fit)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.8750000\npre0_mod0_post0\n\n\nroc_auc\nbinary\n0.8750000\npre0_mod0_post0\n\n\nbrier_class\nbinary\n0.1157407\npre0_mod0_post0\n\n\n\n\n\n\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nstring"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html",
    "title": "ppv-mtcars1",
    "section": "",
    "text": "Berechnen Sie folgendes Modell (Datensatz mtcars):\nmpg ~ hp\nGeben Sie die Breite eines 50%-ETI an f√ºr eine Beobachtung mit einem z-Wert von 0 im Pr√§diktor!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#setup",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#setup",
    "title": "ppv-mtcars1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  mutate(hp = standardize(hp))"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#modell",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#modell",
    "title": "ppv-mtcars1",
    "section": "Modell",
    "text": "Modell\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, seed = 42, refresh = 0)\n\nModellparameter:\n\ncoef(m1)\n\n(Intercept)          hp \n30.11668130 -0.06820988 \n\n\nModellg√ºte:\n\nr2(m1)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])\n\n\nOder mit z-standardisierten Werten:\n\nm2 &lt;- stan_glm(mpg ~ hp, data = mtcars2, seed = 42, refresh = 0)\ncoef(m2)\n\n(Intercept)          hp \n  20.096771   -4.676665 \n\nr2(m2)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])"
  },
  {
    "objectID": "posts/ppv-mtcars1/ppv-mtcars1.html#ppv",
    "href": "posts/ppv-mtcars1/ppv-mtcars1.html#ppv",
    "title": "ppv-mtcars1",
    "section": "PPV",
    "text": "PPV\n\nm2_ppv &lt;- estimate_prediction(m2, data = tibble(hp = 0), ci = 0.5)\nm2_ppv\n\n\n\n\n\nhp\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n0\n20.08646\n4.077161\n17.47148\n22.67675\n\n\n\n\n\n\nVisualisierung:\n\nplot(estimate_prediction(m2, by = \"hp\"))\n\n\n\n\n\n\n\n\nMan beachte, dass die PPV mit mehr Ungewissheit behaftet ist, als die Post-Verteilung.\n\nplot(estimate_relation(m2))\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nppv\nregression\nnum"
  },
  {
    "objectID": "posts/kausal29/kausal29.html",
    "href": "posts/kausal29/kausal29.html",
    "title": "kausal29",
    "section": "",
    "text": "library(dagitty)\nlibrary(ggdag)\nlibrary(ggplot2)\n\nGegeben sei der DAG (Graph) g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind.\n\ng &lt;-\n  dagify(\n    y ~ z + m,\n    m ~ x + z,\n    exposure = \"x\",\n    outcome = \"y\"\n  )\n\nHier ist die Definition des DAGs:\n\n\ndag {\nm\nx [exposure]\ny [outcome]\nz\nm -&gt; y\nx -&gt; m\nz -&gt; m\nz -&gt; y\n}\n\n\nUnd so sieht er aus:\n\nggdag(g) + theme_dag_blank()\n\n\n\n\n\n\n\n\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x\nAV: y\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n{m}\n{z}\n{m, z}\n{ }\nkeine L√∂sung"
  },
  {
    "objectID": "posts/kausal29/kausal29.html#answerlist",
    "href": "posts/kausal29/kausal29.html#answerlist",
    "title": "kausal29",
    "section": "",
    "text": "{m}\n{z}\n{m, z}\n{ }\nkeine L√∂sung"
  },
  {
    "objectID": "posts/kausal29/kausal29.html#answerlist-1",
    "href": "posts/kausal29/kausal29.html#answerlist-1",
    "title": "kausal29",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nRichtig\nFalsch\n\n\nCategories:\n\ndag\ncausal\nschoice"
  },
  {
    "objectID": "posts/summarise01/summarise01.html",
    "href": "posts/summarise01/summarise01.html",
    "title": "summarise01",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nFassen Sie die Spalte total_pr zusammen und zwar zum maximalwert!\nGeben Sie diese Zahl als Antwort zur√ºck!\nHinweise:\n\nRunden Sie auf die n√§chste ganze Zahl.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nZusammenfassen:\n\nmariokart_klein &lt;- summarise(mariokart, max_preis = max(total_pr)) \nmariokart_klein\n\n\n\n\n\nmax_preis\n\n\n\n\n326.51\n\n\n\n\n\n\nmin analog.\nDie L√∂sung lautet: 327 Euro\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/penguins-stan-05/penguins-stan-05.html",
    "href": "posts/penguins-stan-05/penguins-stan-05.html",
    "title": "penguins-stan-05",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nAufgabe: Wie breit ist das 95%-ETI, wenn Sie nur die Spezies Adelie untersuchen?\nHinweise:\n\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nWeitere Hinweise\nGehen Sie von einer Normalverteilung aus.\n\n         \n\n\nL√∂sung\nZentrieren ist eigentlich immer n√ºtzlich, aber hier streng genommen nicht unbedingt n√∂tig. Der Hauptgrund daf√ºr ist, dass Stan f√ºr uns den Prior f√ºr den Intercept festlegt, und zwar auf Basis der Daten, wir uns also nicht um die komische Frage zu k√ºmmern brauchen, welchen Prior wir f√ºr den unzentrierten Achsenabschnitt vergeben wollten: Wie schwer sind Pinguins der Schnabell√§nge Null? Mit zentrierten Pr√§diktoren ist die Frage nach dem Prior viel einfacher zu beantworten: Wie schwer ist ein Pinguin mit mittelgro√üem Schnabel?\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\npenguins &lt;- data_read(d_path)\npenguins_adelie &lt;- \n  penguins %&gt;% \n  filter(species == \"Adelie\")\n\nglimpse(penguins)\n\nRows: 344\nColumns: 9\n$ rownames          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1‚Ä¶\n$ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"A‚Ä¶\n$ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", ‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;chr&gt; \"male\", \"female\", \"female\", \"\", \"female\", \"male\", \"f‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins_adelie, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1, ci = .95, ci_method = \"eti\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n22.53919\n0.95\n-879.18205\n913.4400\n0.5185\n1.000466\n3934.802\nnormal\n3700.662\n1146.4153\n\n\nbill_length_mm\n94.71685\n0.95\n71.89291\n118.0511\n1.0000\n1.000492\n3910.510\nnormal\n0.000\n430.4322\n\n\n\n\n\n\nDie L√∂sung lautet also, wie in der Ausgabe zu den Parametern ersichtlich, 46.16.\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/tidymodels-poly01/tidymodels-poly01.html",
    "href": "posts/tidymodels-poly01/tidymodels-poly01.html",
    "title": "tidymodels-poly01",
    "section": "",
    "text": "Aufgabe\nFitten Sie ein Polynomial-Modell f√ºr folgende Modellgleichung:\nbody_mass_g ~ bill_length_mm.\nGesucht ist der optimale Polynomgrad im Train-Sample (optimal hinsichtlich minimalem Prognosefehler).\nHinweise:\n\nDatensatz penguins (palmerpenguins)\nVerwenden Sie Tidymodels\nFitten Sie Polynome des Grades 1 bis 10.\nDefinieren Sie die Polynomegrade als Tuningparameter.\nBeziehen Sie sich auf RMSE als Kennzahl der Modellg√ºte.\nEntfernen Sie fehlende Werte in den Pr√§diktoren\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\ndata(penguins, package = \"palmerpenguins\")\n\nRezept:\n\nrec1 &lt;- \n  recipe(body_mass_g ~ bill_length_mm, data = penguins) %&gt;% \n  step_naomit(all_predictors()) %&gt;% \n  step_poly(all_predictors(), degree = tune()) %&gt;% \n  update_role(contains(\"_poly_\"), new_role = \"predictor\")\n\nCheck:\n\nd_baked &lt;- bake(prep(rec1), new_data = NULL)\n\nWorkflow:\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(linear_reg()) %&gt;% \n  add_recipe(rec1)\n\nRezepte mit Tuningparametern kann man nicht preppen/backen.\nTuning:\n\ntune1 &lt;-\n  tune_grid(\n    wf1,\n    resamples = vfold_cv(data = penguins),\n    metrics = metric_set(rmse),\n    grid = grid_regular(degree(range = c(1, 10)),\n                               levels = 10)\n  )\n\n\nautoplot(tune1)\n\n\n\n\n\n\n\n\n\nshow_best(tune1)\n\n\n\n\n\ndegree\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n2\nrmse\nstandard\n643.1677\n10\n20.66274\npre02_mod0_post0\n\n\n5\nrmse\nstandard\n645.4780\n10\n24.29428\npre05_mod0_post0\n\n\n4\nrmse\nstandard\n646.3220\n10\n23.06755\npre04_mod0_post0\n\n\n1\nrmse\nstandard\n647.6321\n10\n18.48407\npre01_mod0_post0\n\n\n3\nrmse\nstandard\n647.6829\n10\n24.19864\npre03_mod0_post0\n\n\n\n\n\n\n\nsol &lt;- show_best(tune1)$degree[1]\nsol\n\n[1] 2\n\n\nDie Antwort lautet: 2.\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/summarise06/summarise06.html",
    "href": "posts/summarise06/summarise06.html",
    "title": "summarise06",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nFassen Sie die Spalte total_pr zusammen und zwar zu verschiedenene Ma√üen der Streuung (keine Gruppierung).\nWelchem Koeffizienten der Streuung schenken Sie am meisten Vertrauen in diesem Fall? Geben Sie den Wert als Antwort an.\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nZusammenfassen:\n\nlibrary(DescTools)\nmariokart_summarised &lt;- summarise(mariokart, \n                                  pr_sd = sd(total_pr),\n                                  pr_iqr = IQR(total_pr),\n                                  pr_maa = mean(abs(total_pr - mean(total_pr))),\n                                  pr_maa2 = MeanAD(total_pr)\n)  # zusammenfassen\nmariokart_summarised\n\n\n\n\n\npr_sd\npr_iqr\npr_maa\npr_maa2\n\n\n\n\n25.68856\n12.815\n10.01811\n10.01811\n\n\n\n\n\n\nM√∂chte man den MAA nicht von Hand ausrechnen, so kann man die Funktion MeanAD aus dem Paket DescTools nutzen (Denken Sie daran, dass Sie das Paket einmalig installiert haben m√ºssen.)\nDa es Extremwerte gibt in total_pr wird die SD besonders hoch sein. Der Grund ist, dass die SD eine Statistik ist, die auf einem Mittelwert beruht. Au√üerdem werden bei der Berechnung der SD die einzelnen Werte quadriert, was gro√üe Werte √ºberproportional vergr√∂√üert. Aus diesem Grund k√∂nnte der IQR hier gegen√ºber anderen Ma√üen bevorzugt werden.\nL√∂sung: 12.82\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nvariability\nnum"
  },
  {
    "objectID": "posts/penguins-lm2/index.html",
    "href": "posts/penguins-lm2/index.html",
    "title": "penguins-lm2",
    "section": "",
    "text": "Consider the dataset penguins. Compute a linear model with body mass as output variable (DV) and a) flipper length and b) sex as input (IV).\n\nTidy up the data set, if and where needed.\nReport the coefficients and interpret them.\nPlot the model and the coefficients.\nReport the model fit (R squared).\nBONUS: predict() the weight of an average flipper-sized animal (male and female). Check out the internet for examples of how to do so in case you need support."
  },
  {
    "objectID": "posts/penguins-lm2/index.html#setup",
    "href": "posts/penguins-lm2/index.html#setup",
    "title": "penguins-lm2",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # visualization\n\n# import data:\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")"
  },
  {
    "objectID": "posts/penguins-lm2/index.html#tidy-up",
    "href": "posts/penguins-lm2/index.html#tidy-up",
    "title": "penguins-lm2",
    "section": "2.2 Tidy up",
    "text": "2.2 Tidy up\n\npenguins_tidier &lt;-\n  penguins |&gt; \n  select(body_mass_g, flipper_length_mm, sex) |&gt; \n  drop_na() |&gt; \n  filter(sex != \"\")  # maybe better to be excluded\n\nNote that, strangely, there are some animals for which the sex is reported as \"\", an empty string value. This is not the same as NA. However, we may want the exclude such animals of unclear sex."
  },
  {
    "objectID": "posts/penguins-lm2/index.html#lets-go",
    "href": "posts/penguins-lm2/index.html#lets-go",
    "title": "penguins-lm2",
    "section": "2.3 Let‚Äôs go",
    "text": "2.3 Let‚Äôs go\n\nlm2 &lt;- \n  lm(body_mass_g ~ flipper_length_mm + sex, \n          data = penguins_tidier)\n\nPlot the model:\n\nplot(estimate_relation(lm2))"
  },
  {
    "objectID": "posts/penguins-stan-02/penguins-stan-02.html",
    "href": "posts/penguins-stan-02/penguins-stan-02.html",
    "title": "penguins-stan-02",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nWie gro√ü ist der statistische Einfluss der UV auf die AV?\nGeben Sie die Breite eines 90%-HDI an (zum Effekt)!\nHinweise:\n\nNutzen Sie den Datensatz zu den Palmer Penguins.\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nZentrieren ist eigentlich immer n√ºtzlich, aber hier streng genommen nicht unbedingt n√∂tig. Der Hauptgrund daf√ºr ist, dass Stan f√ºr uns den Prior f√ºr den Intercept festlegt, und zwar auf Basis der Daten, wir uns also nicht um die komische Frage zu k√ºmmern brauchen, welchen Prior wir f√ºr den unzentrierten Achsenabschnitt vergeben wollten: Wie schwer sind Pinguins der Schnabell√§nge Null? Mit zentrierten Pr√§diktoren ist die Frage nach dem Prior viel einfacher zu beantworten: Wie schwer ist ein Pinguin mit mittelgro√üem Schnabel?\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1, ci_method = \"hdi\", ci = .9, keep = \"bill_length_mm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\nbill_length_mm\n87.4472\n0.9\n76.99955\n98.3694\n1\n1.000491\n4123.761\nnormal\n0\n367.2233\n\n\n\n\n\n\nDie L√∂sung lautet also, wie aus der Ausgabe von parameters() ersichtlich, 21.37.\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/quiz-qm2-verteilungen/index.html",
    "href": "posts/quiz-qm2-verteilungen/index.html",
    "title": "qm2-quiz-verteilungen",
    "section": "",
    "text": "1 Aufgabe\nGeben Sie jeweils an, ob die Aussage richtig oder falsch ist.\n\nDie Zuordnung der Elementarereignisse eines Zufallsexperiments zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable.\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariablen eine Wahrscheinlichkeit zuzuordnen.\nDie Funktion \\(f\\), die den m√∂glichen Realisationen \\(x_i\\) der stetigen Zufallsvariablen \\(X\\) die Eintrittswahrscheinlichkeiten zuordnet, hei√üt Wahrscheinlichkeitsfunktion.\nDie Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist.\nDer Graph einer stetigen Funktion l√§sst sich eine durchg√§ngige Kurve zeichnen.\nBei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen Auspr√§gungen aus; die Wahrscheinlichkeit einer bestimmten Auspr√§gung ist Null: \\(Pr(X=x_j)=0, \\quad j=1,...,+\\infty\\)\nDie Wahrscheinlichkeit bei \\(n=3\\) Z√ºgen \\(k=2\\) Treffer zu erzielen, wenn die Trefferwahrscheinlichkeit bei jedem Zug \\(p=2/5\\) ist, betr√§gt ca. 29%.\nDie Normalverteilung ist eine nicht-schiefe Verteilung. Sie verf√ºgt √ºber genau einen Parameter, \\(\\mu\\), der den Mittelwert angibt.\nDas 50%-Quantil der IQ-Verteilung liegt bei 100.\nDie Standardnormalverteilung hat einen Mittelwert von 0 und eine Standardabweichung von 0.\nDie z-Transformation ist definiert als \\(z = \\frac{x-\\mu}{\\sigma}\\), wobei \\(x\\) die Realisation der Zufallsvariablen \\(X\\) ist, \\(\\mu\\) der Mittelwert und \\(\\sigma\\) die Standardabweichung.\nEin Beispiel f√ºr eine normalverteile Zufallsvariable ist die K√∂rpergr√∂√üe von Menschen eines bestimmten Geschlechts.\nEin Beispiel f√ºr eine randlastig verteilte Zufallsvariable ist die Opferzahl kriegerischer Auseinandersetzungen.\nEin Beispiel f√ºr eine randlastig verteilte Zufallsvariable ist die Anzahl von Treffern beim wiederholten M√ºnzwurf.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nDie Zuordnung der Elementarereignisse eines Zufallsexperiments zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable. R\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariablen eine Wahrscheinlichkeit zuzuordnen. R\nDie Funktion \\(f\\), die den m√∂glichen Realisationen \\(x_i\\) der stetigen Zufallsvariablen \\(X\\) die Eintrittswahrscheinlichkeiten zuordnet, hei√üt Wahrscheinlichkeitsfunktion. F\nDie Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist. R\nDer Graph einer stetigen Funktion l√§sst sich eine durchg√§ngige Kurve zeichnen. R\nBei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen Auspr√§gungen aus; die Wahrscheinlichkeit einer bestimmten Auspr√§gung ist Null: \\(Pr(X=x_j)=0, \\quad j=1,...,+\\infty\\)\nDie Wahrscheinlichkeit bei \\(n=3\\) Z√ºgen \\(k=2\\) Treffer zu erzielen, wenn die Trefferwahrscheinlichkeit bei jedem Zug \\(p=2/5\\) ist, betr√§gt ca. 29%. R\nDie Normalverteilung ist eine nicht-schiefe Verteilung. Sie verf√ºgt √ºber genau einen Parameter, \\(\\mu\\), der den Mittelwert angibt. F\nDas 50%-Quantil der IQ-Verteilung liegt bei 100. R\nDie Standardnormalverteilung hat einen Mittelwert von 0 und eine Standardabweichung von 0. F\nDie z-Transformation ist definiert als \\(z = \\frac{x-\\mu}{\\sigma}\\), wobei \\(x\\) die Realisation der Zufallsvariablen \\(X\\) ist, \\(\\mu\\) der Mittelwert und \\(\\sigma\\) die Standardabweichung. R\nEin Beispiel f√ºr eine normalverteile Zufallsvariable ist die K√∂rpergr√∂√üe von Menschen eines bestimmten Geschlechts. R\nEin Beispiel f√ºr eine randlastig verteilte Zufallsvariable ist die Opferzahl kriegerischer Auseinandersetzungen. R\nEin Beispiel f√ºr eine randlastig verteilte Zufallsvariable ist die Anzahl von Treffern beim wiederholten M√ºnzwurf. F"
  },
  {
    "objectID": "posts/twitter06/twitter06.html",
    "href": "posts/twitter06/twitter06.html",
    "title": "twitter06",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=4\\)) via der Twitter API; die Tweets sollen jeweils an eine prominente Person gerichtet sein.\nBeziehen Sie sich auf folgende Personen bzw. Twitter-Accounts:\n\nMarkus_Soeder\nkarl_lauterbach.\n\nBereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopw√∂rter entfernen, Zahlen entfernen, ‚Ä¶).\nNutzen Sie die Daten dann, um eine Sentimentanalyse zu erstellen.\nVergleichen Sie die Ergebnisse f√ºr alle untersuchten Personen.\n         \n         \n\n\nSolution\n\nlibrary(rtweet)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(lsa)  # Stopw√∂rter\nlibrary(SnowballC)  # Stemming\n\n\ndata(sentiws, package = \"pradadata\")\n\nZuerst muss man sich anmelden und die Tweets herunterladen:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\n\ntweets_to_kl &lt;- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(tweets_to_kl, file = \"tweets_to_kl.rds\", compress = \"gz\")\ntweets_to_ms &lt;- search_tweets(\"@Markus_Soeder\", n = 1e4, include_rts = FALSE)\n#write_rds(tweets_to_ms, file = \"tweets_to_ms.rds\", compress = \"gz\")\n\nDie Vorverarbeitung pro Screenname packen wir in eine Funktion, das macht es hinten raus einfacher:\n\nprepare_tweets &lt;- function(tweets){\n  \n  tweets %&gt;% \n    select(full_text) %&gt;% \n    unnest_tokens(output = word, input = full_text) %&gt;% \n    anti_join(tibble(word = lsa::stopwords_de)) %&gt;% \n    mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %&gt;% \n    mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %&gt;% \n    mutate(word = str_replace_na(word, \" +\")) %&gt;% \n    drop_na()\n}\n\nTest:\n\nkl_prepped &lt;- \n  prepare_tweets(tweets_to_kl_raw)\n\nhead(kl_prepped)\n\n\nms_prepped &lt;-\n  prepare_tweets(tweets_to_ms_raw)\n\nhead(ms_prepped)\n\nScheint zu passen.\nDie Sentimentanalyse packen wir auch in eine Funktion:\n\nget_tweets_sentiments &lt;- function(tweets){\n  \n  tweets %&gt;% \n    inner_join(sentiws) %&gt;% \n    group_by(neg_pos) %&gt;% \n    summarise(senti_avg = mean(value, na.rm = TRUE),\n              senti_sd = sd(value, na.rm = TRUE),\n              senti_n = n()) \n}\n\nTest:\n\nkl_prepped %&gt;% \n  get_tweets_sentiments()\n\nTest:\n\ntweets_to_kl_raw %&gt;% \n  prepare_tweets() %&gt;% \n  get_tweets_sentiments()\n\nScheint zu passen.\nWir k√∂nnten noch die beiden Funktionen in eine wrappen:\n\nprep_sentiments &lt;- function(tweets) {\n\n  tweets %&gt;% \n    prepare_tweets() %&gt;% \n    get_tweets_sentiments()\n}\n\n\ntweets_to_kl_raw %&gt;% \n  prep_sentiments()\n\nOkay, jetzt werden wir die Funktion auf jede Screenname bzw. die Tweets jedes Screennames an.\n\ntweets_list &lt;-\n  list(\n    kl = tweets_to_kl_raw, \n    ms = tweets_to_ms_raw)\n\n\nsentis &lt;-\n  tweets_list %&gt;% \n  map_df(prep_sentiments, .id = \"id\")\n\n\nCategories:\n\ntextmining\ntwitter\nprogramming"
  },
  {
    "objectID": "posts/rethink4e2/rethink4e2.html",
    "href": "posts/rethink4e2/rethink4e2.html",
    "title": "rethink4e2",
    "section": "",
    "text": "Wie viele Parameter sind im folgenden Modell zu sch√§tzen?\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior f√ºr \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{U}(0, 50)\\)\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\n\n0\n1\n2\n3\nmehr"
  },
  {
    "objectID": "posts/rethink4e2/rethink4e2.html#answerlist",
    "href": "posts/rethink4e2/rethink4e2.html#answerlist",
    "title": "rethink4e2",
    "section": "",
    "text": "0\n1\n2\n3\nmehr"
  },
  {
    "objectID": "posts/rethink4e2/rethink4e2.html#answerlist-1",
    "href": "posts/rethink4e2/rethink4e2.html#answerlist-1",
    "title": "rethink4e2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/log-y-regr3/log-y-regr3.html",
    "href": "posts/log-y-regr3/log-y-regr3.html",
    "title": "log-y-regression3",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)\n\nIn dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zun√§chst den Datensatz und verschaffen Sie sich einen √úberblick.\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\"\n\nd &lt;- data_read(d_path)\n\nDokumentation und Quellenangaben zum Datensatz finden sich hier.\n\nglimpse(d)\n\nRows: 2,675\nColumns: 11\n$ rownames &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18‚Ä¶\n$ treat    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ age      &lt;int&gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 2‚Ä¶\n$ educ     &lt;int&gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12‚Ä¶\n$ ethn     &lt;chr&gt; \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\"‚Ä¶\n$ married  &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,‚Ä¶\n$ re74     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ re75     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ re78     &lt;dbl&gt; 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 2‚Ä¶\n$ u74      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ u75      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n\n\nWelcher der Pr√§diktoren hat den st√§rkesten Einfluss auf das Einkommen?\nHinweise:\n\nVerwenden Sie lm zur Modellierung.\nOperationalisieren Sie das Einkommen mit der Variable re74.\nGehen Sie von einem kausalen Effekt der Pr√§diktoren aus.\nGehen Sie von einem multiplikativen Modell aus (log-y).\nLassen Sie die Variablen zur Arbeitslosigkeit au√üen vor.\n\n\n\n\ntreat\nage\neduc\nethn\nmarried"
  },
  {
    "objectID": "posts/log-y-regr3/log-y-regr3.html#answerlist",
    "href": "posts/log-y-regr3/log-y-regr3.html#answerlist",
    "title": "log-y-regression3",
    "section": "",
    "text": "treat\nage\neduc\nethn\nmarried"
  },
  {
    "objectID": "posts/log-y-regr3/log-y-regr3.html#answerlist-1",
    "href": "posts/log-y-regr3/log-y-regr3.html#answerlist-1",
    "title": "log-y-regression3",
    "section": "Answerlist",
    "text": "Answerlist\n\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nCategories:\n\nstats-nutshell\nqm2\nregression\nlog"
  },
  {
    "objectID": "posts/Boosting1/Boosting1.html",
    "href": "posts/Boosting1/Boosting1.html",
    "title": "Boosting1",
    "section": "",
    "text": "Es handelt sich um ein lineares Modell, wenn man unter linear ein Modell folgender Form versteht:\n\\[f(X)=\\sum_{j=1}^p f_i(X_J)\\]\nW√§hlen Sie die am besten passende Begr√ºndung, warum man unter Boosting ein lineares Modell versteht bzw. verstehen kann.\n\n\n\nBoosting-Modelle bestehen aus einer Sequenz von B√§umen mit jeweils nur einer Variablen (Gabelung; internal nodes) und sind daher linear.\nBaumbasierte Modelle sind stets linear; Boosting ist ein baumbasiertes Modell, daher ist Boosting ein lineares Modell.\nBaumbasierte Modelle haben stets den oben skizzierten Funktionsterm \\(f(X)\\).\nBoosting gleicht einem Random-Forest-Modell, nur dass die B√§ume sequenzielle Modelle darstellen und nicht parallel (gleichzeitig) in ein Modell einflie√üen. Daher ist Boosting ein lineares Modell.\nAlle Boosting-Modelle erf√ºllen obige Funktionsgleichung und sind daher immer linear."
  },
  {
    "objectID": "posts/Boosting1/Boosting1.html#answerlist",
    "href": "posts/Boosting1/Boosting1.html#answerlist",
    "title": "Boosting1",
    "section": "",
    "text": "Boosting-Modelle bestehen aus einer Sequenz von B√§umen mit jeweils nur einer Variablen (Gabelung; internal nodes) und sind daher linear.\nBaumbasierte Modelle sind stets linear; Boosting ist ein baumbasiertes Modell, daher ist Boosting ein lineares Modell.\nBaumbasierte Modelle haben stets den oben skizzierten Funktionsterm \\(f(X)\\).\nBoosting gleicht einem Random-Forest-Modell, nur dass die B√§ume sequenzielle Modelle darstellen und nicht parallel (gleichzeitig) in ein Modell einflie√üen. Daher ist Boosting ein lineares Modell.\nAlle Boosting-Modelle erf√ºllen obige Funktionsgleichung und sind daher immer linear."
  },
  {
    "objectID": "posts/Boosting1/Boosting1.html#answerlist-1",
    "href": "posts/Boosting1/Boosting1.html#answerlist-1",
    "title": "Boosting1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nWahr\nWahr\nWahr\nWahr\n\n\nCategories:\nmchoice"
  },
  {
    "objectID": "posts/pd1/index.html",
    "href": "posts/pd1/index.html",
    "title": "pd1",
    "section": "",
    "text": "1 Aufgabe\nWas beschreibt die ‚ÄúProbability of Direction‚Äù (pd) in der Bayes‚Äôschen Statistik?\n\nDie Wahrscheinlichkeit, dass ein Parameter einen bestimmten numerischen Wert annimmt, basierend auf der Prior-Verteilung.\nDen Anteil der Posteriori-Verteilung, der das gleiche Vorzeichen hat wie der Median; und gibt damit die Wahrscheinlichkeit an, dass der Parameter streng positiv bzw. negativ ist.\nDie Wahrscheinlichkeit, dass die Nullhypothese wahr ist, ausgedr√ºckt als Prozentsatz zwischen 0 und 100%.\nDen Korrelationskoeffizienten zwischen Prior- und Posteriori-Verteilung, der angibt, wie stark die Daten die Vorannahmen beeinflussen.\nDie Wahrscheinlichkeit, dass ein Parameter innerhalb des 95%-Kredibilit√§tsintervalls liegt, unabh√§ngig von seinem Vorzeichen.\nDie standardisierte Abweichung des Parameters vom Nullwert, normiert auf eine Skala von 50% bis 100%.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nB\nDie pd gibt an, mit welcher Wahrscheinlichkeit ein Parameter das gleiche Vorzeichen hat wie sein Median und variiert zwischen 50% (maximale Unsicherheit √ºber die Richtung) und 100% (vollst√§ndige Gewissheit √ºber die Richtung des Effekts)."
  },
  {
    "objectID": "posts/globus2/index.html",
    "href": "posts/globus2/index.html",
    "title": "globus2",
    "section": "",
    "text": "1 Aufgabe\nWir werfen einen Globus \\(n=9\\) Mal und erzielen \\(W=9\\) mal das Ereignis ‚ÄúWasser‚Äù.\nWas ist die Wahrscheinlichkeit dieses Ereignisses, wenn wir von einer Wasseranteil, d.h. Wahrscheinlichkeit, von \\(\\pi=.7\\) ausgehen?\n  \n  \n  \n  \n\n\n2 L√∂sung\nHier sind die gegebenen Werte:\n\nW &lt;- 9\nn &lt;- 9\npi &lt;- .7\n\nWir suchen also diese Gr√∂√üe:\n\\[Pr(W=9 | \\pi=0.7, n=9) = ?\\]\nWir k√∂nnen R die Arbeit machen lassen:\n\n\n\n\nListing¬†1: Binomialverteilung mit R\n\n\nloesung &lt;- dbinom(x = W, size = n, prob = pi)\nloesung\n\n\n\n\n[1] 0.04035361\n\n\nOder den Taschenrechner nutzen:\n\nloesung &lt;- choose(n,W) * pi^W * (1-pi)^(n-W)\nloesung\n\n[1] 0.04035361\n\n\nDie Harten unter uns rechnen es per Hand aus.\nDaf√ºr kann man zun√§chst die Anzahl der Pfade mit dem Binomialkoeffizienten berechnen:\n\nanzahl_pfade &lt;- factorial(n) / (factorial(W) * factorial(n-W))\nanzahl_pfade\n\n[1] 1\n\n\nfactorial(W) liefert die Fakult√§t von \\(W\\) zur√ºck.\nDann berechnet man die Wahrscheinlichkeit eines einzelnen Pfades:\n\npfad_wskt &lt;-  pi^W * (1-pi)^(n-W)\npfad_wskt\n\n[1] 0.04035361\n\n\nMultipliziert man die beiden vorherigen Zwischenergebnisse, so erh√§lt man die L√∂sung:\n\nloesung &lt;-  anzahl_pfade * pfad_wskt\nloesung\n\n[1] 0.04035361"
  },
  {
    "objectID": "posts/mtcars-simple1/mtcars-simple1.html",
    "href": "posts/mtcars-simple1/mtcars-simple1.html",
    "title": "mtcars-simple1",
    "section": "",
    "text": "Exercise\nWe will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nCompute the causal effect of horse power given the above model! Report the point estimate.\nNotes:\n\nUse can either use frequentist or bayesian modeling.\nUse R for all computations.\nThere are multiple ways to find a solution.\n\n         \n\n\nSolution\nCompute Model:\n\nlm1_freq &lt;- lm(mpg ~ hp + cyl + disp, data = mtcars)\n\nlibrary(rstanarm)\nlm1_bayes &lt;- stan_glm(mpg ~ hp + cyl + disp, data = mtcars, refresh = 0)\n\nGet parameters:\n\nlibrary(easystats)\n\n\nparameters(lm1_freq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n34.1849192\n2.5907776\n0.95\n28.8779519\n39.4918865\n13.194849\n28\n0.0000000\n\n\nhp\n-0.0146793\n0.0146509\n0.95\n-0.0446903\n0.0153316\n-1.001943\n28\n0.3249519\n\n\ncyl\n-1.2274199\n0.7972763\n0.95\n-2.8605664\n0.4057265\n-1.539516\n28\n0.1349044\n\n\ndisp\n-0.0188381\n0.0104037\n0.95\n-0.0401491\n0.0024729\n-1.810711\n28\n0.0809290\n\n\n\n\n\n\n\nparameters(lm1_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n34.1184814\n0.95\n28.6259426\n39.4782854\n1.00000\n1.0002255\n2542.167\nnormal\n20.09062\n15.0673701\n\n\nhp\n-0.0152531\n0.95\n-0.0446539\n0.0137016\n0.83950\n1.0003025\n2527.877\nnormal\n0.00000\n0.2197599\n\n\ncyl\n-1.1979104\n0.95\n-2.8409640\n0.4723914\n0.92625\n0.9997102\n2025.936\nnormal\n0.00000\n8.4367476\n\n\ndisp\n-0.0192148\n0.95\n-0.0396876\n0.0023142\n0.96300\n0.9997628\n2377.939\nnormal\n0.00000\n0.1215712\n\n\n\n\n\n\nThe coefficient is estimated as about -0.01\n\nCategories:\n\nregression\nen\nbayes\nfrequentist\nqm1\nstats-nutshell"
  },
  {
    "objectID": "posts/tidymodels-penguins05/tidymodels-penguins05.html",
    "href": "posts/tidymodels-penguins05/tidymodels-penguins05.html",
    "title": "tidymodels-penguins05",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=2 CV.\nTunen Sie \\(K\\), setzen Sie den Tuning-Wertebereich auf 1 bis 5.\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs pr√ºfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n1 Recipe Step\n\n‚Ä¢ step_naomit()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nK-Nearest Neighbor Model Specification (regression)\n\nMain Arguments:\n  neighbors = tune()\n\nComputational engine: kknn \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\n34.5\n2900\n\n\n52.2\n3450\n\n\n45.4\n4800\n\n\n42.1\n4000\n\n\n50.0\n5350\n\n\n41.5\n4000\n\n\n\n\n\n\nAuf NA pr√ºfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5, repeats = 2)\nfolds\n\n\n\n\n\n\n\n\n\n\nsplits\nid\nid2\n\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 8 , 9 , 10 , 11 , 12 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 55 , 57 , 58 , 61 , 62 , 63 , 64 , 65 , 66 , 68 , 70 , 71 , 72 , 73 , 75 , 76 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 87 , 88 , 89 , 90 , 91 , 93 , 94 , 96 , 97 , 98 , 99 , 100 , 101 , 103 , 105 , 107 , 108 , 109 , 111 , 112 , 115 , 116 , 117 , 118 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 131 , 132 , 133 , 135 , 136 , 138 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 151 , 152 , 155 , 156 , 157 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 186 , 187 , 190 , 191 , 192 , 193 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 214 , 215 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 227 , 228 , 229 , 230 , 232 , 234 , 235 , 236 , 238 , 239 , 240 , 242 , 243 , 244 , 245 , 246 , 247 , NA , Repeat1 , Fold1\nRepeat1\nFold1\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 10 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 26 , 27 , 28 , 29 , 33 , 34 , 35 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 48 , 50 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 84 , 85 , 86 , 87 , 89 , 90 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 100 , 101 , 102 , 103 , 104 , 105 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 146 , 148 , 150 , 153 , 154 , 155 , 156 , 158 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 169 , 170 , 171 , 172 , 173 , 175 , 176 , 177 , 179 , 180 , 181 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 194 , 196 , 197 , 198 , 199 , 200 , 201 , 204 , 205 , 206 , 208 , 209 , 211 , 213 , 214 , 215 , 216 , 217 , 218 , 220 , 221 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 245 , 247 , 248 , 249 , NA , Repeat1 , Fold2\nRepeat1\nFold2\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 5 , 7 , 8 , 9 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 28 , 29 , 30 , 31 , 32 , 33 , 36 , 41 , 42 , 43 , 44 , 47 , 49 , 50 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 62 , 63 , 64 , 66 , 67 , 69 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 85 , 86 , 88 , 89 , 91 , 92 , 93 , 94 , 95 , 97 , 99 , 100 , 101 , 102 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 121 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 156 , 157 , 158 , 160 , 161 , 163 , 164 , 165 , 166 , 168 , 169 , 171 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 199 , 202 , 203 , 204 , 205 , 206 , 207 , 209 , 210 , 211 , 212 , 213 , 215 , 216 , 217 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 231 , 232 , 233 , 234 , 235 , 237 , 238 , 241 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Repeat1 , Fold3\nRepeat1\nFold3\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 3 , 4 , 6 , 7 , 8 , 10 , 11 , 13 , 14 , 16 , 17 , 18 , 21 , 22 , 23 , 24 , 25 , 27 , 29 , 30 , 31 , 32 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 53 , 54 , 55 , 56 , 58 , 59 , 60 , 61 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 76 , 77 , 78 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 90 , 91 , 92 , 95 , 96 , 98 , 99 , 100 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 122 , 124 , 126 , 127 , 128 , 129 , 130 , 131 , 133 , 134 , 137 , 138 , 139 , 140 , 141 , 142 , 144 , 145 , 146 , 147 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 , 159 , 161 , 162 , 164 , 165 , 167 , 168 , 169 , 170 , 172 , 173 , 174 , 175 , 176 , 178 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 205 , 206 , 207 , 208 , 210 , 211 , 212 , 213 , 214 , 216 , 217 , 218 , 219 , 220 , 222 , 224 , 226 , 229 , 230 , 231 , 232 , 233 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 244 , 245 , 246 , 248 , 249 , NA , Repeat1 , Fold4\nRepeat1\nFold4\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 15 , 19 , 20 , 21 , 22 , 23 , 25 , 26 , 27 , 28 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 56 , 57 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 110 , 111 , 113 , 114 , 115 , 116 , 119 , 120 , 121 , 122 , 123 , 125 , 126 , 127 , 128 , 130 , 132 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 143 , 145 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 162 , 163 , 166 , 167 , 168 , 170 , 171 , 172 , 174 , 175 , 176 , 177 , 178 , 179 , 182 , 183 , 185 , 187 , 188 , 189 , 192 , 193 , 194 , 195 , 196 , 197 , 198 , 200 , 201 , 202 , 203 , 204 , 207 , 208 , 209 , 210 , 212 , 213 , 214 , 215 , 216 , 217 , 218 , 219 , 221 , 222 , 223 , 225 , 226 , 227 , 228 , 230 , 231 , 233 , 234 , 236 , 237 , 239 , 240 , 241 , 242 , 243 , 244 , 246 , 247 , 248 , 249 , NA , Repeat1 , Fold5\nRepeat1\nFold5\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 6 , 7 , 8 , 9 , 10 , 11 , 14 , 16 , 17 , 18 , 20 , 21 , 22 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 47 , 49 , 50 , 51 , 52 , 53 , 54 , 58 , 59 , 60 , 61 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 71 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 81 , 82 , 83 , 84 , 85 , 89 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 100 , 102 , 103 , 104 , 105 , 107 , 108 , 109 , 110 , 111 , 112 , 114 , 116 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 138 , 139 , 141 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 169 , 171 , 172 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 185 , 187 , 189 , 190 , 192 , 194 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 205 , 208 , 210 , 211 , 212 , 214 , 215 , 217 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 235 , 236 , 237 , 240 , 241 , 242 , 243 , 245 , 246 , 247 , 249 , NA , Repeat2 , Fold1\nRepeat2\nFold1\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 15 , 16 , 17 , 18 , 19 , 21 , 22 , 23 , 24 , 25 , 28 , 29 , 30 , 32 , 33 , 34 , 35 , 39 , 40 , 41 , 42 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 66 , 67 , 69 , 70 , 72 , 74 , 75 , 76 , 77 , 78 , 80 , 82 , 83 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 94 , 95 , 96 , 97 , 98 , 99 , 100 , 101 , 102 , 103 , 106 , 108 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 119 , 120 , 121 , 122 , 124 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 142 , 144 , 147 , 148 , 149 , 150 , 153 , 154 , 158 , 159 , 160 , 161 , 162 , 163 , 164 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 176 , 177 , 178 , 179 , 180 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 197 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 209 , 210 , 211 , 212 , 213 , 215 , 216 , 217 , 218 , 219 , 220 , 222 , 223 , 224 , 225 , 226 , 227 , 229 , 230 , 231 , 232 , 234 , 235 , 238 , 239 , 240 , 241 , 242 , 243 , 244 , 245 , 248 , NA , Repeat2 , Fold2\nRepeat2\nFold2\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 2 , 3 , 5 , 7 , 8 , 9 , 10 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 34 , 36 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 53 , 55 , 56 , 57 , 58 , 59 , 61 , 62 , 63 , 65 , 68 , 69 , 70 , 71 , 72 , 73 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 89 , 90 , 93 , 95 , 97 , 98 , 99 , 100 , 101 , 102 , 104 , 105 , 106 , 107 , 108 , 109 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 123 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 175 , 178 , 179 , 181 , 182 , 184 , 185 , 186 , 187 , 188 , 190 , 191 , 192 , 193 , 194 , 198 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 212 , 213 , 214 , 215 , 216 , 217 , 218 , 219 , 221 , 224 , 225 , 226 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Repeat2 , Fold3\nRepeat2\nFold3\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 4 , 5 , 6 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 26 , 27 , 30 , 31 , 32 , 33 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 50 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 62 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 76 , 78 , 79 , 80 , 81 , 84 , 85 , 86 , 87 , 88 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 99 , 101 , 102 , 103 , 104 , 105 , 106 , 107 , 109 , 110 , 111 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 126 , 127 , 128 , 129 , 134 , 135 , 136 , 137 , 138 , 140 , 141 , 142 , 143 , 145 , 146 , 147 , 148 , 151 , 152 , 155 , 156 , 157 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 168 , 170 , 171 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 195 , 196 , 197 , 198 , 199 , 202 , 204 , 206 , 207 , 208 , 209 , 211 , 213 , 214 , 216 , 217 , 218 , 220 , 221 , 222 , 223 , 225 , 226 , 227 , 228 , 229 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 241 , 242 , 243 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Repeat2 , Fold4\nRepeat2\nFold4\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13 , 14 , 15 , 19 , 20 , 22 , 23 , 25 , 26 , 27 , 28 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 43 , 44 , 45 , 46 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 70 , 71 , 73 , 74 , 75 , 77 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 96 , 98 , 100 , 101 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 127 , 129 , 130 , 131 , 132 , 133 , 137 , 138 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 161 , 162 , 163 , 164 , 165 , 167 , 168 , 169 , 170 , 172 , 173 , 174 , 175 , 176 , 177 , 180 , 181 , 183 , 184 , 185 , 186 , 188 , 189 , 191 , 193 , 194 , 195 , 196 , 197 , 198 , 200 , 201 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 213 , 214 , 215 , 216 , 219 , 220 , 221 , 222 , 223 , 224 , 226 , 227 , 228 , 230 , 231 , 233 , 234 , 236 , 237 , 238 , 239 , 240 , 243 , 244 , 246 , 247 , 248 , 249 , NA , Repeat2 , Fold5\nRepeat2\nFold5\n\n\n\n\n\n\nTunen:\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = grid_regular(\n      neighbors(range = c(1, 5))\n    )\n  )\n\nd_resamples\n\n\n\n\n\n\n\n\n\n\n\n\nsplits\nid\nid2\n.metrics\n.notes\n\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 8 , 9 , 10 , 11 , 12 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 55 , 57 , 58 , 61 , 62 , 63 , 64 , 65 , 66 , 68 , 70 , 71 , 72 , 73 , 75 , 76 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 87 , 88 , 89 , 90 , 91 , 93 , 94 , 96 , 97 , 98 , 99 , 100 , 101 , 103 , 105 , 107 , 108 , 109 , 111 , 112 , 115 , 116 , 117 , 118 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 131 , 132 , 133 , 135 , 136 , 138 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 151 , 152 , 155 , 156 , 157 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 186 , 187 , 190 , 191 , 192 , 193 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 214 , 215 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 227 , 228 , 229 , 230 , 232 , 234 , 235 , 236 , 238 , 239 , 240 , 242 , 243 , 244 , 245 , 246 , 247 , NA , Repeat1 , Fold1\nRepeat1\nFold1\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 974.070069348196 , 0.0738300817860576, 765.214764047714 , 0.18902123273618 , 721.886703576122 , 0.257660401148508 , pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 10 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 26 , 27 , 28 , 29 , 33 , 34 , 35 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 48 , 50 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 84 , 85 , 86 , 87 , 89 , 90 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 100 , 101 , 102 , 103 , 104 , 105 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 146 , 148 , 150 , 153 , 154 , 155 , 156 , 158 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 169 , 170 , 171 , 172 , 173 , 175 , 176 , 177 , 179 , 180 , 181 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 194 , 196 , 197 , 198 , 199 , 200 , 201 , 204 , 205 , 206 , 208 , 209 , 211 , 213 , 214 , 215 , 216 , 217 , 218 , 220 , 221 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 245 , 247 , 248 , 249 , NA , Repeat1 , Fold2\nRepeat1\nFold2\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 885.268320906153 , 0.151723076347485, 727.637850557395 , 0.251646361728322, 688.48527827398 , 0.280016289181017, pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 5 , 7 , 8 , 9 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 28 , 29 , 30 , 31 , 32 , 33 , 36 , 41 , 42 , 43 , 44 , 47 , 49 , 50 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 62 , 63 , 64 , 66 , 67 , 69 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 85 , 86 , 88 , 89 , 91 , 92 , 93 , 94 , 95 , 97 , 99 , 100 , 101 , 102 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 121 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 156 , 157 , 158 , 160 , 161 , 163 , 164 , 165 , 166 , 168 , 169 , 171 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 199 , 202 , 203 , 204 , 205 , 206 , 207 , 209 , 210 , 211 , 212 , 213 , 215 , 216 , 217 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 231 , 232 , 233 , 234 , 235 , 237 , 238 , 241 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Repeat1 , Fold3\nRepeat1\nFold3\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 735.654470522677 , 0.263686609570067, 643.942120106023 , 0.302400889614308, 617.270559803398 , 0.329291768180258, pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 3 , 4 , 6 , 7 , 8 , 10 , 11 , 13 , 14 , 16 , 17 , 18 , 21 , 22 , 23 , 24 , 25 , 27 , 29 , 30 , 31 , 32 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 53 , 54 , 55 , 56 , 58 , 59 , 60 , 61 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 76 , 77 , 78 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 90 , 91 , 92 , 95 , 96 , 98 , 99 , 100 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 122 , 124 , 126 , 127 , 128 , 129 , 130 , 131 , 133 , 134 , 137 , 138 , 139 , 140 , 141 , 142 , 144 , 145 , 146 , 147 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 , 159 , 161 , 162 , 164 , 165 , 167 , 168 , 169 , 170 , 172 , 173 , 174 , 175 , 176 , 178 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 205 , 206 , 207 , 208 , 210 , 211 , 212 , 213 , 214 , 216 , 217 , 218 , 219 , 220 , 222 , 224 , 226 , 229 , 230 , 231 , 232 , 233 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 244 , 245 , 246 , 248 , 249 , NA , Repeat1 , Fold4\nRepeat1\nFold4\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 989.058896122976 , 0.0498500341542856, 835.282617294565 , 0.149780661124781 , 771.604569711714 , 0.219804967991395 , pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 15 , 19 , 20 , 21 , 22 , 23 , 25 , 26 , 27 , 28 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 56 , 57 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 110 , 111 , 113 , 114 , 115 , 116 , 119 , 120 , 121 , 122 , 123 , 125 , 126 , 127 , 128 , 130 , 132 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 143 , 145 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 162 , 163 , 166 , 167 , 168 , 170 , 171 , 172 , 174 , 175 , 176 , 177 , 178 , 179 , 182 , 183 , 185 , 187 , 188 , 189 , 192 , 193 , 194 , 195 , 196 , 197 , 198 , 200 , 201 , 202 , 203 , 204 , 207 , 208 , 209 , 210 , 212 , 213 , 214 , 215 , 216 , 217 , 218 , 219 , 221 , 222 , 223 , 225 , 226 , 227 , 228 , 230 , 231 , 233 , 234 , 236 , 237 , 239 , 240 , 241 , 242 , 243 , 244 , 246 , 247 , 248 , 249 , NA , Repeat1 , Fold5\nRepeat1\nFold5\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 919.876877298128 , 0.149068116023328, 757.579615781498 , 0.297868164074025, 749.45672187204 , 0.280562727669961, pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 6 , 7 , 8 , 9 , 10 , 11 , 14 , 16 , 17 , 18 , 20 , 21 , 22 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 47 , 49 , 50 , 51 , 52 , 53 , 54 , 58 , 59 , 60 , 61 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 71 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 81 , 82 , 83 , 84 , 85 , 89 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 100 , 102 , 103 , 104 , 105 , 107 , 108 , 109 , 110 , 111 , 112 , 114 , 116 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 138 , 139 , 141 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 169 , 171 , 172 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 185 , 187 , 189 , 190 , 192 , 194 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 205 , 208 , 210 , 211 , 212 , 214 , 215 , 217 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 235 , 236 , 237 , 240 , 241 , 242 , 243 , 245 , 246 , 247 , 249 , NA , Repeat2 , Fold1\nRepeat2\nFold1\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 940.810820516006 , 0.0965833318037908, 762.226091484978 , 0.316141309460159 , 719.835379513955 , 0.390445176208191 , pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 15 , 16 , 17 , 18 , 19 , 21 , 22 , 23 , 24 , 25 , 28 , 29 , 30 , 32 , 33 , 34 , 35 , 39 , 40 , 41 , 42 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 66 , 67 , 69 , 70 , 72 , 74 , 75 , 76 , 77 , 78 , 80 , 82 , 83 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 94 , 95 , 96 , 97 , 98 , 99 , 100 , 101 , 102 , 103 , 106 , 108 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 119 , 120 , 121 , 122 , 124 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 142 , 144 , 147 , 148 , 149 , 150 , 153 , 154 , 158 , 159 , 160 , 161 , 162 , 163 , 164 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 176 , 177 , 178 , 179 , 180 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 197 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 209 , 210 , 211 , 212 , 213 , 215 , 216 , 217 , 218 , 219 , 220 , 222 , 223 , 224 , 225 , 226 , 227 , 229 , 230 , 231 , 232 , 234 , 235 , 238 , 239 , 240 , 241 , 242 , 243 , 244 , 245 , 248 , NA , Repeat2 , Fold2\nRepeat2\nFold2\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 944.000794491191 , 0.00881397609762216, 841.614837665915 , 0.0305850282416374 , 784.364033851629 , 0.0714684306245134 , pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 2 , 3 , 5 , 7 , 8 , 9 , 10 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 34 , 36 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 53 , 55 , 56 , 57 , 58 , 59 , 61 , 62 , 63 , 65 , 68 , 69 , 70 , 71 , 72 , 73 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 89 , 90 , 93 , 95 , 97 , 98 , 99 , 100 , 101 , 102 , 104 , 105 , 106 , 107 , 108 , 109 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 123 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 175 , 178 , 179 , 181 , 182 , 184 , 185 , 186 , 187 , 188 , 190 , 191 , 192 , 193 , 194 , 198 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 212 , 213 , 214 , 215 , 216 , 217 , 218 , 219 , 221 , 224 , 225 , 226 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Repeat2 , Fold3\nRepeat2\nFold3\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 973.286956657696 , 0.00546689808339815, 711.263498814769 , 0.205445031107556 , 678.833150634234 , 0.256492577646083 , pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 4 , 5 , 6 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 26 , 27 , 30 , 31 , 32 , 33 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 50 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 62 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 76 , 78 , 79 , 80 , 81 , 84 , 85 , 86 , 87 , 88 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 99 , 101 , 102 , 103 , 104 , 105 , 106 , 107 , 109 , 110 , 111 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 126 , 127 , 128 , 129 , 134 , 135 , 136 , 137 , 138 , 140 , 141 , 142 , 143 , 145 , 146 , 147 , 148 , 151 , 152 , 155 , 156 , 157 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 168 , 170 , 171 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 195 , 196 , 197 , 198 , 199 , 202 , 204 , 206 , 207 , 208 , 209 , 211 , 213 , 214 , 216 , 217 , 218 , 220 , 221 , 222 , 223 , 225 , 226 , 227 , 228 , 229 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 241 , 242 , 243 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Repeat2 , Fold4\nRepeat2\nFold4\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 1034.56512603122 , 0.071050695561426, 902.819476719782 , 0.114847836269046, 825.667065589999 , 0.142918716097976, pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13 , 14 , 15 , 19 , 20 , 22 , 23 , 25 , 26 , 27 , 28 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 43 , 44 , 45 , 46 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 70 , 71 , 73 , 74 , 75 , 77 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 96 , 98 , 100 , 101 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 127 , 129 , 130 , 131 , 132 , 133 , 137 , 138 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 161 , 162 , 163 , 164 , 165 , 167 , 168 , 169 , 170 , 172 , 173 , 174 , 175 , 176 , 177 , 180 , 181 , 183 , 184 , 185 , 186 , 188 , 189 , 191 , 193 , 194 , 195 , 196 , 197 , 198 , 200 , 201 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 213 , 214 , 215 , 216 , 219 , 220 , 221 , 222 , 223 , 224 , 226 , 227 , 228 , 230 , 231 , 233 , 234 , 236 , 237 , 238 , 239 , 240 , 243 , 244 , 246 , 247 , 248 , 249 , NA , Repeat2 , Fold5\nRepeat2\nFold5\n1 , 1 , 3 , 3 , 5 , 5 , rmse , rsq , rmse , rsq , rmse , rsq , standard , standard , standard , standard , standard , standard , 1049.81776844306 , 0.0685872081741541, 826.694772114658 , 0.165171625695325 , 777.180435015852 , 0.216245614644632 , pre0_mod1_post0 , pre0_mod1_post0 , pre0_mod2_post0 , pre0_mod2_post0 , pre0_mod3_post0 , pre0_mod3_post0\n\n\n\n\n\n\n\nBester Kandidat:\n\nshow_best(d_resamples)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nneighbors\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n5\nrmse\nstandard\n733.4584\n10\n19.30519\npre0_mod3_post0\n\n\n3\nrmse\nstandard\n777.4276\n10\n23.82036\npre0_mod2_post0\n\n\n1\nrmse\nstandard\n944.6410\n10\n28.01526\npre0_mod1_post0\n\n\n\n\n\n\n\nfitbest &lt;- fit_best(d_resamples)\nfitbest\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n1 Recipe Step\n\n‚Ä¢ step_naomit()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nCall:\nkknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5L,     data, 5))\n\nType of response variable: continuous\nminimal mean absolute error: 497.0257\nMinimal mean squared error: 407926.4\nBest kernel: optimal\nBest k: 5\n\n\nLast Fit:\n\nfit_last &lt;- last_fit(fitbest, d_split)\n\nError in `last_fit()`:\n! `last_fit()` is not well-defined for a fitted workflow.\n\nfit_last\n\nError: object 'fit_last' not found\n\n\nModellg√ºte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\nError: object 'fit_last' not found\n\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\n\nError: object 'fit_last' not found\n\nsol\n\nError: object 'sol' not found\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/kausal26/kausal26.html",
    "href": "posts/kausal26/kausal26.html",
    "title": "kausal26",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber 7 Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\n\n\n\n{ x3 }\n{ x2 }\n{ x1, x2 }\n{ x1 }\n{ x4, x5 }"
  },
  {
    "objectID": "posts/kausal26/kausal26.html#answerlist",
    "href": "posts/kausal26/kausal26.html#answerlist",
    "title": "kausal26",
    "section": "",
    "text": "{ x3 }\n{ x2 }\n{ x1, x2 }\n{ x1 }\n{ x4, x5 }"
  },
  {
    "objectID": "posts/kausal26/kausal26.html#answerlist-1",
    "href": "posts/kausal26/kausal26.html#answerlist-1",
    "title": "kausal26",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/mtcars-abhaengig/mtcars-abhaengig.html",
    "href": "posts/mtcars-abhaengig/mtcars-abhaengig.html",
    "title": "mtcars-abhaengig",
    "section": "",
    "text": "Exercise\nOb wohl die PS-Zahl (Ereignis \\(A\\)) und der Spritverbrauch (Ereignis \\(B\\)) voneinander abh√§ngig sind? Was meinen Sie? Was ist Ihre Einsch√§tzung dazu? Vermutlich haben Sie ein (wenn vielleicht auch implizites) Vorab-Wissen zu dieser Frage. Lassen wir dieses Vorab-Wissen aber einmal au√üen vor und schauen uns rein Daten dazu an. Vereinfachen wir die Frage etwas, indem wir fragen, ob die Ereignisse ‚Äúhoher Spritverbrauch‚Äù (A) und ‚Äúhohe PS-Zahl‚Äù voneinander abh√§ngig sind.\nUm es konkret zu machen, nutzen wir den Datensatz mtcars:\n\nlibrary(tidyverse)\ndata(mtcars)\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,‚Ä¶\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,‚Ä¶\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16‚Ä¶\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180‚Ä¶\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,‚Ä¶\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.‚Ä¶\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18‚Ä¶\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,‚Ä¶\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,‚Ä¶\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,‚Ä¶\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,‚Ä¶\n\n\nWeitere Infos zum Datensatz bekommen Sie mit help(mtcars) in R.\nDefinieren wir uns das Ereignis ‚Äúhohe PS-Zahl‚Äù (und nennen wir es hp_high, klingt cooler). Sagen wir, wenn die PS-Zahl gr√∂√üer ist als der Median, dann trifft hp_high zu, ansonsten nicht:\n\nmtcars %&gt;% \n  summarise(median(hp))\n\n  median(hp)\n1        123\n\n\nMit dieser ‚ÄúWenn-Dann-Abfrage‚Äù k√∂nnen wir die Variable hp_high mit den Stufen TRUE und FALSE definieren:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(hp_high = case_when(\n    hp &gt; 123 ~ TRUE,\n    hp &lt;= 123 ~ FALSE\n  ))\n\nGenauso gehen wir mit dem Spritverbrauch vor (mpg_high):\n\nmtcars &lt;- \n  mtcars %&gt;% \n  mutate(mpg_high = case_when(\n    mpg &gt; median(mpg) ~ TRUE,\n    mpg &lt;= median(mpg) ~ FALSE\n  ))\n\n\nSchauen Sie im Datensatz nach, ob unser Vorgehen (Erstellung von hp_high und mpg_high) √ºberhaupt funktioniert hat. Probieren geht √ºber Studieren.\nVisualisieren Sie in geeigneter Form den Zusammenhang.\nBerechnen Sie \\(Pr(\\text{mpg high}|\\text{hphigh})\\) und \\(Pr(\\text{mpg high}|\\neg \\text{hp high})\\) !\n\n         \n\n\nSolution\n\nSchauen wir mal in den Datensatz:\n\n\nmtcars %&gt;% \n  select(hp, hp_high, mpg, mpg_high) %&gt;% \n  slice_head(n = 5)\n\n                   hp hp_high  mpg mpg_high\nMazda RX4         110   FALSE 21.0     TRUE\nMazda RX4 Wag     110   FALSE 21.0     TRUE\nDatsun 710         93   FALSE 22.8     TRUE\nHornet 4 Drive    110   FALSE 21.4     TRUE\nHornet Sportabout 175    TRUE 18.7    FALSE\n\n\n\n\n\n\nmtcars %&gt;% \n  #select(hp_high, mpg_high) %&gt;% \n  ggplot() +\n  aes(x = hp_high, fill = mpg_high) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nHey, sowas von abh√§ngig voneinander, die zwei Variablen, mpg_high und hp_high!\nDer rechte Balken zeigt \\(Pr(\\text{mpghigh}|\\text{hp high})\\) und \\(Pr(\\neg \\text{mpg high}|\\text{hp high})\\).Der linke Balken zeigt \\(Pr(\\text{mpg high}|\\neg \\text{hp high})\\) und \\(Pr(\\neg \\text{mpg high}|\\neg \\text{hp high})\\).\n\nBerechnen wir die relevanten Anteile:\n\n\nmtcars %&gt;% \n  #select(hp_high, mpg_high) %&gt;% \n  count(hp_high, mpg_high) %&gt;%  # Anzahl pro Zelle der Kontingenztabelle\n  group_by(hp_high) %&gt;%  # die Anteile pro \"Balken\" s. Diagramm\n  mutate(prop = n / sum(n))\n\n# A tibble: 4 √ó 4\n# Groups:   hp_high [2]\n  hp_high mpg_high     n   prop\n  &lt;lgl&gt;   &lt;lgl&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 FALSE   FALSE        3 0.176 \n2 FALSE   TRUE        14 0.824 \n3 TRUE    FALSE       14 0.933 \n4 TRUE    TRUE         1 0.0667\n\n\nAm besten, Sie f√ºhren den letzten Code Schritt f√ºr Schritt aus und schauen sich jeweils das Ergebnis an, das hilft beim Verstehen.\nAlternativ kann man sich die H√§ufigkeiten auch sch√∂n bequem ausgeben lassen:\n\nlibrary(mosaic)\ntally(mpg_high ~ hp_high, \n      data = mtcars, \n      format = \"proportion\")\n\n        hp_high\nmpg_high       TRUE      FALSE\n   TRUE  0.06666667 0.82352941\n   FALSE 0.93333333 0.17647059\n\n\n\nCategories:\n\nprobability\ndependent"
  },
  {
    "objectID": "posts/Priorwahl1/Priorwahl1.html",
    "href": "posts/Priorwahl1/Priorwahl1.html",
    "title": "Priorwahl1",
    "section": "",
    "text": "Exercise\nEi Forschi w√§hlt f√ºr ein Regressionsmodell \\(\\beta \\sim \\mathcal{N}(0,500)\\) (Priori), wobei die empirischen Variablen z-standardisiert sind. Beziehen Sie Stellung zu diesem Prior.\n         \n\n\nSolution\nDie Priori-Verteilung ist nicht sinnvoll spezifiziert. Die Streuung der Normalverteilung ist so gro√ü, dass sie fast schon uniform verteilt ist. Dieser Priori-Verteilung nimmt z.B. an, \\(Pr(|\\beta| &lt; 250) &lt; Pr(|\\beta| &gt; 250)\\), was eine sehr wilde Vorstellung ist. Man k√∂nnte sagen: Die Verteilung nimmt an, dass es wahrscheinlicher ist, dass ihr bester Freund 100 Millionen Lichtjahre entfernt lebt, als dass er n√§her als diese Distanz bei Ihnen lebt.\nWeitere Hinweise hier\nZur Verdeutlichung: Wie wahrscheinlich ist \\(z=1,2,...,10\\) bei einer Normalverteilung zu betrachten?\n(Zur Erinnerung: Ein z-Wert gibt den Abstand vom Mittelwert in SD-Einheiten an.)\nF√ºr \\(q=1\\) betr√§gt die Wahrscheinlichkeit f√ºr einen Wert nicht h√∂her als \\(z=1\\) etwa 84%:\n\npnorm(q = 1) # z = 1\n\n[1] 0.8413447\n\n\nAllgemeiner:\n\noptions(digits = 20)  # Mehr Nachkommastellen\npnorm(q = 1:10)  # von z=1 bis z=10\n\n [1] 0.84134474606854292578 0.97724986805182079141 0.99865010196836989653\n [4] 0.99996832875816688002 0.99999971334842807646 0.99999999901341229958\n [7] 0.99999999999872013490 0.99999999999999933387 1.00000000000000000000\n[10] 1.00000000000000000000\n\n\nDie Wahrscheinlichkeiten f√ºr Sigma-Ereignisse bis zu ¬±7 finden sich z.B. hier.\n\noptions(digits = 2)\n\nVertiefung:\nNassim Taleb hat dieses Argument in seinem Buch ‚ÄúStatistical Consequences of Fat Tails‚Äù aufgegriffen (ein anspruchsvolles Buch). Hier finden Sie eine interessante Darstellung eines Arguments daraus.\n\nCategories:\n\nfat-tails\ndistributions"
  },
  {
    "objectID": "posts/Skalenniveau1a/Skalenniveau1a.html",
    "href": "posts/Skalenniveau1a/Skalenniveau1a.html",
    "title": "Skalenniveau1a",
    "section": "",
    "text": "Verf√ºgt die Variable Rangfolge der Lieblingsspeisen einer Person √ºber ein metrisches Skalenniveau?\n\n\n\nnein\nja"
  },
  {
    "objectID": "posts/Skalenniveau1a/Skalenniveau1a.html#answerlist",
    "href": "posts/Skalenniveau1a/Skalenniveau1a.html#answerlist",
    "title": "Skalenniveau1a",
    "section": "",
    "text": "nein\nja"
  },
  {
    "objectID": "posts/mariokart-sd1/mariokart-sd1.html",
    "href": "posts/mariokart-sd1/mariokart-sd1.html",
    "title": "mariokart-sd1",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die SD des Verkaufspreis (total_pr) f√ºr Spiele, die neu sind oder (auch) √ºber Lenkr√§der (wheels) verf√ºgen.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- data_read(d_url)\n\n\nsolution &lt;-\nmariokart  %&gt;% \n  filter(cond == \"new\" | wheels &gt; 0) %&gt;% \n  summarise(pr_mean = sd(total_pr))\n\nsolution\n\n\n\n\n\npr_mean\n\n\n\n\n27.54928\n\n\n\n\n\n\nL√∂sung: 27.5.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nvariability\nnum"
  },
  {
    "objectID": "posts/mariokart-mean1/mariokart-mean1.html",
    "href": "posts/mariokart-mean1/mariokart-mean1.html",
    "title": "mariokart-mean1",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie den mittleren Verkaufspreis (total_pr)!\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nd  %&gt;% \n  summarise(pr_mean = mean(total_pr))\n\n\n\n\n\npr_mean\n\n\n\n\n49.88049\n\n\n\n\n\n\nL√∂sung: 49.88.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nnum"
  },
  {
    "objectID": "posts/rethink4e3/rethink4e3.html",
    "href": "posts/rethink4e3/rethink4e3.html",
    "title": "rethink4e3",
    "section": "",
    "text": "Exercise\nGegeben dem folgenden Modell, schreiben Sie die passende Form des Bayes-Theorem auf.\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior f√ºr \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{U}(0, 50)\\)\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nSolution\nDie allgemeine Form des Bayes-Theorem hatten wir so kennen gelernt:\n\\[Pr(H|D) = \\frac{Pr(D|H)\\cdot Pr(H)}{Pr(D)}\\]\n\\(Pr(\\mu, \\sigma|h)\\) gibt die Posteriori-Wahrscheinlichkeit f√ºr ein bestimmte Hypothese \\(H\\) an, z.B. f√ºr die Hypothese \\(\\mu=0\\).\n\\(Pr(D|H)\\) ist der Likelihood unserer Daten \\(D\\) gegeben der gerade untersuchten Hypothese \\(H\\).\n\\(Pr(H)\\) ist die Apriori-Wahrscheinlichkeit (das ‚ÄúApriori-Gewicht‚Äù) der gerade untersuchten Hypothese.\nDer Z√§hler gibt die unstandardisierte Posteriori-Wahrscheinlichkeit der gerade untersuchten Hypothese an.\nDer Nenner ist nur ein Normalisierungsfaktor, der daf√ºr sorgt, dass der ganze Bruch die standardisierte Posteriori-Wahrscheinlichkeit angibt.\nIn diesem konkreten Fall untersuchen wir Hypothesen zu einem ‚ÄúParameter-P√§rchen‚Äù, \\(\\mu\\sigma\\). Wir fragen also, wie wahrscheinlich es ist, einen gewissen Mittelwert \\(\\mu\\) und (gleichzeitig) eine gewisse Streuung \\(\\sigma\\) aufzufinden.\nZum Beispiel k√∂nnten wir fragen: ‚ÄúWie wahrscheinlich ist es, dass \\(\\mu=194\\) und \\(\\sigma=12\\)?‚Äù. Bayes‚Äô Theorem gibt uns die Wahrscheinlichkeit f√ºr diese Hypothese.\nZur Erinnerung, Bayes‚Äô Theorem:\n\\[Pr(\\mu \\cap \\sigma|D) = \\frac{Pr(D|\\mu \\cap \\sigma)\\cdot Pr(\\mu) \\cdot Pr(\\sigma)}{Pr(H)}\\]\nHier ist zu beachten, dass die Apriori-Wahrscheinlichkeit auf zwei Termen besteht, \\(Pr(\\mu)\\) und \\(Pr(\\sigma)\\). Sind diese unabh√§ngig, so kann man ihre Wahrscheinlichkeiten multiplizieren, um die gemeinsame Wahrscheinlichkeit zu erhalten, also die Wahrscheinlichkeit f√ºr ein bestimmten ‚ÄúMu-Sigma-P√§rchen‚Äù, etwa \\(\\mu=194,\\sigma=12\\).\n\nCategories:\n\nbayes\nprobability"
  },
  {
    "objectID": "posts/priori-Streuung/priori-streuung.html",
    "href": "posts/priori-Streuung/priori-streuung.html",
    "title": "priori-streuung",
    "section": "",
    "text": "Welche Verteilung ist (am besten) geeignet, um Streuung (\\(\\sigma\\)) zu modellieren?\n\n\n\nN(0,1)\nN(1,1)\nExp(1)\nExp(0)\nExp(-1)"
  },
  {
    "objectID": "posts/priori-Streuung/priori-streuung.html#answerlist",
    "href": "posts/priori-Streuung/priori-streuung.html#answerlist",
    "title": "priori-streuung",
    "section": "",
    "text": "N(0,1)\nN(1,1)\nExp(1)\nExp(0)\nExp(-1)"
  },
  {
    "objectID": "posts/priori-Streuung/priori-streuung.html#answerlist-1",
    "href": "posts/priori-Streuung/priori-streuung.html#answerlist-1",
    "title": "priori-streuung",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\nDa Streuung \\(\\sigma\\) per Definition positiv ist, kommt eine Verteilung, die negative Werte erlaubt, nicht in Frage. Die Normalverteilung scheidet also aus.\nDie Rate der Exponentialverteilung regelt gleichzeitig Streuung und Mittelwert. Allerdings hat \\(Exp(0)\\) eine unendliche Streuung, was nicht w√ºnschenswert ist. Eine negative Rate ist f√ºr die Exponentialverteilung nicht definiert.\nNormalverteilungen:\n\n\n\n\n\\(N(0,1)\\):\n\nlibrary(tidyverse)\n\nggplot(data = data.frame(x = c(-3, 3)), aes(x)) +\n  stat_function(fun = dnorm, n = 101) +\n  labs(y = \"Dichte\", x = \"Merkmal, X\",\n       title = \"N(0,1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\\(N(1,1)\\):\n\nggplot(data = data.frame(x = c(-2, 4)), aes(x)) +\n  stat_function(fun = dnorm, n = 101, args = list(mean = 1, sd = 1)) +\n  labs(y = \"Dichte\", x = \"Merkmal, X\",\n       title = \"N(1,1)\")\n\n\n\n\n\n\n\n\nExponentialverteilungen:\n\n\n\n\\(Exp(1)\\):\n\nggplot(data = data.frame(x = c(-3, 10)), aes(x)) +\n  stat_function(fun = dexp, n = 101) +\n  labs(y = \"Dichte\", x = \"Merkmal, X\",\n       title = \"Exp(1)\")\n\n\n\n\n\n\n\n\n\n\n\n\\(Exp(0)\\):\n\nggplot(data = data.frame(x = c(-3, 10)), aes(x)) +\n  stat_function(fun = dexp, n = 101, args  = list(rate = 0)) +\n  labs(y = \"Dichte\", x = \"Merkmal, X\",\n       title = \"Exp(0)\")\n\n\n\n\n\n\n\n\n\n\n\n\\(Exp(-1)\\):\n\nggplot(data = data.frame(x = c(-3, 10)), aes(x)) +\n  stat_function(fun = dexp, n = 101, args  = list(rate = -1)) +\n  labs(y = \"Dichte\", x = \"Merkmal, X\",\n       title = \"Exp(-1)\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nsimulation\ndistributions\nbayes"
  },
  {
    "objectID": "posts/repro1-sessioninfo/repro1-sessioninfo.html",
    "href": "posts/repro1-sessioninfo/repro1-sessioninfo.html",
    "title": "repro1-sessioninfo",
    "section": "",
    "text": "Aufgabe\nSie analysieren fr√∂hlich, bestens gelaunt geradezu, in Ruhe einige Daten. L√§uft. Pl√∂tzlich: Oh nein! Eine Fehlermeldung! Das darf nicht wahr sein!\nSicherlich ein Bug in R oder in RStudio oder in einem R-Paket‚Ä¶\nSie fragen jemanden um Hilfe und jemand antwortet mit der Frage, ob Sie denn die aktuelle Version von R/RStudio/einem R-Paket h√§tten.\nTja, gute Frage ‚Ä¶ Woher wei√ü man das eigentlich?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nMit dem Befehl sessionInfo bekommen Sie einen √úberblick √ºber die Versionen der aktuell gestarteten R-Pakete sowie von R. Die Version von RStudio ist zumeist nicht wichtig, da RStudio keinen R-Code ausf√ºhrt; das macht nur R.\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] colorout_1.3-2\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.1       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.28    knitr_1.50        jsonlite_1.8.8    xfun_0.52        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.3   \n\n\n\nCategories:\n\nR\nrepro\nstring"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html",
    "href": "posts/tmdb08/tmdb08.html",
    "title": "tmdb08",
    "section": "",
    "text": "Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme.\nDie Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\""
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#train-set-verschlanken",
    "href": "posts/tmdb08/tmdb08.html#train-set-verschlanken",
    "title": "tmdb08",
    "section": "Train-Set verschlanken",
    "text": "Train-Set verschlanken\n\nd_train &lt;-\n  d_train_raw %&gt;% \n  select(id, popularity, runtime, revenue, budget)"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#test-set-verschlanken",
    "href": "posts/tmdb08/tmdb08.html#test-set-verschlanken",
    "title": "tmdb08",
    "section": "Test-Set verschlanken",
    "text": "Test-Set verschlanken\n\nd_test &lt;-\n  d_test_raw %&gt;% \n  select(id,popularity, runtime, budget)"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#rezept-definieren",
    "href": "posts/tmdb08/tmdb08.html#rezept-definieren",
    "title": "tmdb08",
    "section": "Rezept definieren",
    "text": "Rezept definieren\n\nrec2 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  step_mutate(budget = ifelse(budget == 0, 1, budget)) %&gt;%  # log mag keine 0\n  step_log(budget) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())  %&gt;% \n  update_role(id, new_role = \"id\")\n\nrec2"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#lm-regularisiert",
    "href": "posts/tmdb08/tmdb08.html#lm-regularisiert",
    "title": "tmdb08",
    "section": "LM regularisiert",
    "text": "LM regularisiert\nMit mixture = 1 definieren wir ein Lasso.\n\nmod_lm &lt;-\n  linear_reg(penalty = tune(), mixture = 1) %&gt;% \n  set_engine(\"glmnet\")\n\nCheck:\n\nmod_lm\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#finalisieren-1",
    "href": "posts/tmdb08/tmdb08.html#finalisieren-1",
    "title": "tmdb08",
    "section": "Finalisieren",
    "text": "Finalisieren\nFinalisieren bedeutet:\n\nBesten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell)\nDen besten Workflow mit den optimalen Modell-Parametern ausstatten\nDamit dann den ganzen Train-Datensatz fitten\nAuf dieser Basis das Test-Sample vorhersagen\n\n\nbest_wf2 &lt;- \nall_workflows2 %&gt;% \n  extract_workflow(\"rec1_lm1\")\n\nbest_wf2\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: linear_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n4 Recipe Steps\n\n‚Ä¢ step_mutate()\n‚Ä¢ step_log()\n‚Ä¢ step_impute_knn()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\nbest_wf_finalized2 &lt;- \n  best_wf2 %&gt;% \n  finalize_workflow(best_model_params2)\n\nbest_wf_finalized2\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: linear_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n4 Recipe Steps\n\n‚Ä¢ step_mutate()\n‚Ä¢ step_log()\n‚Ä¢ step_impute_knn()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1.24905419571164e-10\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#final-fit",
    "href": "posts/tmdb08/tmdb08.html#final-fit",
    "title": "tmdb08",
    "section": "Final Fit",
    "text": "Final Fit\n\nfit_final2 &lt;-\n  best_wf_finalized2 %&gt;% \n  fit(d_train)\n\nfit_final2\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: linear_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n4 Recipe Steps\n\n‚Ä¢ step_mutate()\n‚Ä¢ step_log()\n‚Ä¢ step_impute_knn()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev   Lambda\n1   0  0.00 63460000\n2   1  3.62 57820000\n3   1  6.62 52680000\n4   1  9.11 48000000\n5   1 11.18 43740000\n6   1 12.90 39850000\n7   2 15.24 36310000\n8   2 17.19 33090000\n9   2 18.81 30150000\n10  2 20.16 27470000\n11  2 21.28 25030000\n12  2 22.21 22800000\n13  3 23.10 20780000\n14  3 23.95 18930000\n15  3 24.66 17250000\n16  3 25.25 15720000\n17  3 25.74 14320000\n18  3 26.15 13050000\n19  3 26.49 11890000\n20  3 26.77 10830000\n21  3 27.00  9872000\n22  3 27.20  8995000\n23  3 27.36  8196000\n24  3 27.49  7467000\n25  3 27.60  6804000\n26  3 27.69  6200000\n27  3 27.77  5649000\n28  3 27.83  5147000\n29  3 27.88  4690000\n30  3 27.93  4273000\n31  3 27.96  3894000\n32  3 27.99  3548000\n33  3 28.02  3232000\n34  3 28.04  2945000\n35  3 28.06  2684000\n36  3 28.07  2445000\n37  3 28.08  2228000\n38  3 28.09  2030000\n39  3 28.10  1850000\n40  3 28.11  1685000\n41  3 28.11  1536000\n42  3 28.12  1399000\n43  3 28.12  1275000\n44  3 28.13  1162000\n45  3 28.13  1058000\n46  3 28.13   964500\n\n...\nand 12 more lines.\n\n\n\npreds &lt;- \nfit_final2 %&gt;% \n  predict(new_data = d_test)\n\nhead(preds)\n\n\n\n\n\n.pred\n\n\n\n\n-14840891\n\n\n10804710\n\n\n11698900\n\n\n99190531\n\n\n41798496\n\n\n29974421"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#submission-df",
    "href": "posts/tmdb08/tmdb08.html#submission-df",
    "title": "tmdb08",
    "section": "Submission df",
    "text": "Submission df\nWir brauchen die ID-Spalte und die Vorhersagen f√ºr die Einreichung:\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n\n\n\n\nid\nrevenue\n\n\n\n\n3001\n-14840891\n\n\n3002\n10804710\n\n\n3003\n11698900\n\n\n3004\n99190531\n\n\n3005\n41798496\n\n\n3006\n29974421\n\n\n\n\n\n\nAbspeichern und einreichen:\n\nwrite_csv(submission_df, file = \"submission_regul_lm.csv\")\n\nLeider ein schlechter Score: 5.77945.\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/tmdb01/tmdb01.html",
    "href": "posts/tmdb01/tmdb01.html",
    "title": "tmdb01",
    "section": "",
    "text": "Aufgabe\nMelden Sie sich an f√ºr die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?.\nSie ben√∂tigen dazu ein Konto; es ist auch m√∂glich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Pr√§diktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verf√ºgung. Eine klassische ‚Äúpredictive Competition‚Äù also :-) Allerdings k√∂nnen immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Random-Forest-Modell mit Tidymodels! Reichen Sie es bei Kaggle ein un berichten Sie den Score!\nHinweise\n\n\nVerzichten Sie auf Vorverarbeitung.\nTunen Sie die typischen Parameter.\nBegrenzen Sie sich auf folgende Pr√§diktoren.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\")\n\n\nAusnahme: Log-transformieren Sie budget.\nTunen Sie die typischen Parameter.\nReichen Sie das Modell ein und berichten Sie Ihren Score.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\", \"status\", \"revenue\")\n\n         \n\n\nL√∂sung\n\nPakete starten\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(doParallel)\n\n\n\nDaten importieren\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nWerfen wir einen Blick in die Daten:\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1‚Ä¶\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C‚Ä¶\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00‚Ä¶\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '‚Ä¶\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht‚Ä¶\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148‚Ä¶\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", ‚Ä¶\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In‚Ä¶\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807‚Ä¶\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh‚Ä¶\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam‚Ä¶\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of‚Ä¶\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/‚Ä¶\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119‚Ä¶\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'‚Ä¶\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol‚Ä¶\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96‚Ä¶\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'‚Ä¶\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep‚Ä¶\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,‚Ä¶\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, ‚Ä¶\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pok√©mon Collection', 'p‚Ä¶\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06‚Ä¶\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n‚Ä¶\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-‚Ä¶\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595‚Ä¶\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", ‚Ä¶\n$ original_title        &lt;chr&gt; \"„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§\", \"Attack of the 50 Foot Wom‚Ä¶\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco‚Ä¶\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680‚Ä¶\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1‚Ä¶\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',‚Ä¶\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3‚Ä¶\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11‚Ä¶\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,‚Ä¶\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_‚Ä¶\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B‚Ä¶\n$ title                 &lt;chr&gt; \"Pok√©mon: The Rise of Darkrai\", \"Attack of the 5‚Ä¶\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok‚àö¬©mon'}, {'id': 1155‚Ä¶\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i‚Ä¶\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep‚Ä¶\n\n\npreds_chosen sind alle Pr√§diktoren im Datensatz, oder nicht? Das pr√ºfen wir mal kurz:\n\npreds_chosen %in% names(d_train) %&gt;% \n  all()\n\n[1] TRUE\n\n\nJa, alle Elemente von preds_chosen sind Pr√§diktoren im (Train-)Datensatz.\n\nCV\nNur um Zeit zu sparen, setzen wir die Anzahl der Folds auf \\(v=4\\). Besser w√§re z.B. \\(v=10\\).\n\ncv_scheme &lt;- vfold_cv(d_train, v = 4)\n\n\n\n\nRezept 1\n\nrec1 &lt;- \n  recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_naomit(all_predictors()) \n\nMan beachte, dass noch 21 Pr√§diktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (‚Äúgebacken‚Äù) wurde.\n\ntidy(rec1)\n\n\n\n\n\nnumber\noperation\ntype\ntrained\nskip\nid\n\n\n\n\n1\nstep\nimpute_bag\nFALSE\nFALSE\nimpute_bag_AzMAg\n\n\n2\nstep\nnaomit\nFALSE\nTRUE\nnaomit_EVt7T\n\n\n\n\n\n\nRezept checken:\n\nprep(rec1)\n\n\nd_train_baked &lt;-\n  rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n\nRows: 3,000\nColumns: 4\n$ budget     &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00, 8.00e+06,‚Ä¶\n$ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.148070, 0.743274‚Ä¶\n$ runtime    &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119, 98, 122, ‚Ä¶\n$ revenue    &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970, 3261638, 8‚Ä¶\n\n\nFehlende Werte noch √ºbrig?\n\nlibrary(easystats)\ndescribe_distribution(d_train_baked) %&gt;% \n  select(Variable, n_Missing)\n\n\n\n\n\nVariable\nn_Missing\n\n\n\n\nbudget\n0\n\n\npopularity\n0\n\n\nruntime\n0\n\n\nrevenue\n0\n\n\n\n\n\n\n\n\nModell 1: RF\n\nmodel1 &lt;- rand_forest(mtry = tune(),\n                        trees = tune(),\n                        min_n = tune()) %&gt;% \n            set_engine('ranger') %&gt;% \n            set_mode('regression')\n\n\n\nWorkflow 1\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model1) %&gt;% \n  add_recipe(rec1)\n\n\n\nModell fitten (und tunen)\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\nrf_fit1 &lt;-\n  wf1 %&gt;% \n  tune_grid(resamples = cv_scheme)\ntoc()\n\n74.436 sec elapsed\n\n\nIrgendwelche Probleme oder Hinweise?\n\nrf_fit1[[\".notes\"]][1]\n\n[[1]]\n# A tibble: 0 √ó 4\n# ‚Ñπ 4 variables: location &lt;chr&gt;, type &lt;chr&gt;, note &lt;chr&gt;, trace &lt;list&gt;\n\n\nNein; bei mir nicht jedenfalls.\n\n\nBester Kandidat\n\nselect_best(rf_fit1)\n\n\n\n\n\nmtry\ntrees\nmin_n\n.config\n\n\n\n\n1\n1777\n23\npre0_mod04_post0\n\n\n\n\n\n\n\n\nWorkflow finalisieren\n\nwf_best &lt;-\n  wf1 %&gt;% \n  finalize_workflow(parameters = select_best(rf_fit1))\n\n\n\nFinal Fit\n\nfit1_final &lt;-\n  wf_best %&gt;% \n  fit(d_train)\n\nfit1_final\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: rand_forest()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_impute_bag()\n‚Ä¢ step_naomit()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), num.trees = ~1777L, min.node.size = min_rows(~23L, x),      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  1777 \nSample size:                      3000 \nNumber of independent variables:  3 \nMtry:                             1 \nTarget node size:                 23 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       6.661954e+15 \nR squared (OOB):                  0.6477978 \n\n\n\npreds &lt;-\n  fit1_final %&gt;% \n  predict(d_test)\n\n\n\nSubmission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n\n\n\n\nid\nrevenue\n\n\n\n\n3001\n5087720\n\n\n3002\n6820306\n\n\n3003\n15710077\n\n\n3004\n38525511\n\n\n3005\n4240279\n\n\n3006\n26635899\n\n\n\n\n\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\n\n\nKaggle Score\nDiese Submission erzielte einen Score von Score: 2.76961 (RMSLE).\n\nsol &lt;-  2.76961\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/tidymodels_workflowset01/tidymodels_workflowset01.html",
    "href": "posts/tidymodels_workflowset01/tidymodels_workflowset01.html",
    "title": "tidymodels_workflowset01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie\n         \n\n\nL√∂sung\n\nCategories:\nnum"
  },
  {
    "objectID": "posts/purrr-map06/purrr-map06.html",
    "href": "posts/purrr-map06/purrr-map06.html",
    "title": "purrr-map06",
    "section": "",
    "text": "library(tidyverse)\n\n\nExercise\nErstellen Sie eine Tabelle mit mit folgenden Spalten:\n\nID-Spalte: \\(1,2,..., 10\\)\nEine Spalte mit Namen ds (ds wie Plural von Datensatz), die als geschachtelt (nested) pro Element jeweils einen der folgenden Datens√§tze enth√§lt: mtcars, iris, chickweight, ToothGrowth (alle in R enthalten)\n\nBerechnen Sie eine Spalte, die die Anzahl der Spalten von ds z√§hlt!\n         \n\n\nSolution\nHier sind einige Datens√§tze, in einer Liste zusammengefasst:\n\nds &lt;- list(mtcars = mtcars, iris = iris, chickweight =  ChickWeight, toothgrowth = ToothGrowth)\n\nDaraus erstellen wir eine Tabelle mit Listenspalte f√ºr die Daten:\n\nd &lt;- \n  tibble(id = 1:length(ds),\n         ds = ds)\n\nJetzt f√ºhren wir die Funktion ncol aus, und zwar f√ºr jedes Element von ds. Wir brauchen also eine Art Schleife, das besorgt map f√ºr uns. Viele Funktionen in R sind ‚Äúauomatisch verschleift‚Äù - das nennt man vektorisiert. Vektorisierte Funktionen werden f√ºr jedes Element eines Vektors ausgef√ºhrt.\nEin Beispiel f√ºr eine vektorisierte Funktion ist die Funktion +:\n\nx &lt;- c(1,2,3)\ny &lt;- c(10, 20, 30)\nx + y\n\n[1] 11 22 33\n\n\nMan k√∂nnte √ºbrigens auch schreiben:\n\n`+`(x, y)\n\n[1] 11 22 33\n\n\nWas zeigt, dass + eine normale Funktion ist.\nZur√ºck zur eigentlichen Aufgabe. Aber ncol ist eben nicht vektorisiert, darum m√ºssen wir da noch eine Schleife dazu bauen, das macht map.\n\nd2 &lt;- \n  d %&gt;% \n  mutate(n_col = map(ds, ncol)) \n\nhead(d2)\n\n\n\n\n\n\n\n\n\n\nid\nds\nn_col\n\n\n\n\n1\n21.000, 21.000, 22.800, 21.400, 18.700, 18.100, 14.300, 24.400, 22.800, 19.200, 17.800, 16.400, 17.300, 15.200, 10.400, 10.400, 14.700, 32.400, 30.400, 33.900, 21.500, 15.500, 15.200, 13.300, 19.200, 27.300, 26.000, 30.400, 15.800, 19.700, 15.000, 21.400, 6.000, 6.000, 4.000, 6.000, 8.000, 6.000, 8.000, 4.000, 4.000, 6.000, 6.000, 8.000, 8.000, 8.000, 8.000, 8.000, 8.000, 4.000, 4.000, 4.000, 4.000, 8.000, 8.000, 8.000, 8.000, 4.000, 4.000, 4.000, 8.000, 6.000, 8.000, 4.000, 160.000, 160.000, 108.000, 258.000, 360.000, 225.000, 360.000, 146.700, 140.800, 167.600, 167.600, 275.800, 275.800, 275.800, 472.000, 460.000, 440.000, 78.700, 75.700, 71.100, 120.100, 318.000, 304.000, 350.000, 400.000, 79.000, 120.300, 95.100, 351.000, 145.000, 301.000, 121.000, 110.000, 110.000, 93.000, 110.000, 175.000, 105.000, 245.000, 62.000, 95.000, 123.000, 123.000, 180.000, 180.000, 180.000, 205.000, 215.000, 230.000, 66.000, 52.000, 65.000, 97.000, 150.000, 150.000, 245.000, 175.000, 66.000, 91.000, 113.000, 264.000, 175.000, 335.000, 109.000, 3.900, 3.900, 3.850, 3.080, 3.150, 2.760, 3.210, 3.690, 3.920, 3.920, 3.920, 3.070, 3.070, 3.070, 2.930, 3.000, 3.230, 4.080, 4.930, 4.220, 3.700, 2.760, 3.150, 3.730, 3.080, 4.080, 4.430, 3.770, 4.220, 3.620, 3.540, 4.110, 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.440, 3.440, 4.070, 3.730, 3.780, 5.250, 5.424, 5.345, 2.200, 1.615, 1.835, 2.465, 3.520, 3.435, 3.840, 3.845, 1.935, 2.140, 1.513, 3.170, 2.770, 3.570, 2.780, 16.460, 17.020, 18.610, 19.440, 17.020, 20.220, 15.840, 20.000, 22.900, 18.300, 18.900, 17.400, 17.600, 18.000, 17.980, 17.820, 17.420, 19.470, 18.520, 19.900, 20.010, 16.870, 17.300, 15.410, 17.050, 18.900, 16.700, 16.900, 14.500, 15.500, 14.600, 18.600, 0.000, 0.000, 1.000, 1.000, 0.000, 1.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 1.000, 0.000, 1.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 3.000, 4.000, 5.000, 5.000, 5.000, 5.000, 5.000, 4.000, 4.000, 4.000, 1.000, 1.000, 2.000, 1.000, 4.000, 2.000, 2.000, 4.000, 4.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 1.000, 2.000, 1.000, 1.000, 2.000, 2.000, 4.000, 2.000, 1.000, 2.000, 2.000, 4.000, 6.000, 8.000, 2.000\n11\n\n\n2\n5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0, 7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9, 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3, 3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0, 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1, 6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0\n5\n\n\n3\n42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 58, 72, 84, 103, 122, 138, 162, 187, 209, 215, 43, 39, 55, 67, 84, 99, 115, 138, 163, 187, 198, 202, 42, 49, 56, 67, 74, 87, 102, 108, 136, 154, 160, 157, 41, 42, 48, 60, 79, 106, 141, 164, 197, 199, 220, 223, 41, 49, 59, 74, 97, 124, 141, 148, 155, 160, 160, 157, 41, 49, 57, 71, 89, 112, 146, 174, 218, 250, 288, 305, 42, 50, 61, 71, 84, 93, 110, 116, 126, 134, 125, 42, 51, 59, 68, 85, 96, 90, 92, 93, 100, 100, 98, 41, 44, 52, 63, 74, 81, 89, 96, 101, 112, 120, 124, 43, 51, 63, 84, 112, 139, 168, 177, 182, 184, 181, 175, 41, 49, 56, 62, 72, 88, 119, 135, 162, 185, 195, 205, 41, 48, 53, 60, 65, 67, 71, 70, 71, 81, 91, 96, 41, 49, 62, 79, 101, 128, 164, 192, 227, 248, 259, 266, 41, 49, 56, 64, 68, 68, 67, 68, 41, 45, 49, 51, 57, 51, 54, 42, 51, 61, 72, 83, 89, 98, 103, 113, 123, 133, 142, 39, 35, 43, 48, 55, 62, 65, 71, 82, 88, 106, 120, 144, 157, 41, 47, 54, 58, 65, 73, 77, 89, 98, 107, 115, 117, 40, 50, 62, 86, 125, 163, 217, 240, 275, 307, 318, 331, 41, 55, 64, 77, 90, 95, 108, 111, 131, 148, 164, 167, 43, 52, 61, 73, 90, 103, 127, 135, 145, 163, 170, 175, 42, 52, 58, 74, 66, 68, 70, 71, 72, 72, 76, 74, 40, 49, 62, 78, 102, 124, 146, 164, 197, 231, 259, 265, 42, 48, 57, 74, 93, 114, 136, 147, 169, 205, 236, 251, 39, 46, 58, 73, 87, 100, 115, 123, 144, 163, 185, 192, 39, 46, 58, 73, 92, 114, 145, 156, 184, 207, 212, 233, 39, 48, 59, 74, 87, 106, 134, 150, 187, 230, 279, 309, 42, 48, 59, 72, 85, 98, 115, 122, 143, 151, 157, 150, 42, 53, 62, 73, 85, 102, 123, 138, 170, 204, 235, 256, 41, 49, 65, 82, 107, 129, 159, 179, 221, 263, 291, 305, 39, 50, 63, 77, 96, 111, 137, 144, 151, 146, 156, 147, 41, 49, 63, 85, 107, 134, 164, 186, 235, 294, 327, 341, 41, 53, 64, 87, 123, 158, 201, 238, 287, 332, 361, 373, 39, 48, 61, 76, 98, 116, 145, 166, 198, 227, 225, 220, 41, 48, 56, 68, 80, 83, 103, 112, 135, 157, 169, 178, 41, 49, 61, 74, 98, 109, 128, 154, 192, 232, 280, 290, 42, 50, 61, 78, 89, 109, 130, 146, 170, 214, 250, 272, 41, 55, 66, 79, 101, 120, 154, 182, 215, 262, 295, 321, 42, 51, 66, 85, 103, 124, 155, 153, 175, 184, 199, 204, 42, 49, 63, 84, 103, 126, 160, 174, 204, 234, 269, 281, 42, 55, 69, 96, 131, 157, 184, 188, 197, 198, 199, 200, 42, 51, 65, 86, 103, 118, 127, 138, 145, 146, 41, 50, 61, 78, 98, 117, 135, 141, 147, 174, 197, 196, 40, 52, 62, 82, 101, 120, 144, 156, 173, 210, 231, 238, 41, 53, 66, 79, 100, 123, 148, 157, 168, 185, 210, 205, 39, 50, 62, 80, 104, 125, 154, 170, 222, 261, 303, 322, 40, 53, 64, 85, 108, 128, 152, 166, 184, 203, 233, 237, 41, 54, 67, 84, 105, 122, 155, 175, 205, 234, 264, 264, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 0, 2, 4, 6, 8, 10, 12, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n4\n\n\n4\n4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5, 15.2, 17.3, 22.5, 17.3, 13.6, 14.5, 18.8, 15.5, 23.6, 18.5, 33.9, 25.5, 26.4, 32.5, 26.7, 21.5, 23.3, 29.5, 15.2, 21.5, 17.6, 9.7, 14.5, 10.0, 8.2, 9.4, 16.5, 9.7, 19.7, 23.3, 23.6, 26.4, 20.0, 25.2, 25.8, 21.2, 14.5, 27.3, 25.5, 26.4, 22.4, 24.5, 24.8, 30.9, 26.4, 27.3, 29.4, 23.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0\n3\n\n\n\n\n\n\nEntnesten wir noch n_col:\n\nd2 %&gt;% \n  unnest(n_col)\n\n\n\n\n\n\n\n\n\n\nid\nds\nn_col\n\n\n\n\n1\n21.000, 21.000, 22.800, 21.400, 18.700, 18.100, 14.300, 24.400, 22.800, 19.200, 17.800, 16.400, 17.300, 15.200, 10.400, 10.400, 14.700, 32.400, 30.400, 33.900, 21.500, 15.500, 15.200, 13.300, 19.200, 27.300, 26.000, 30.400, 15.800, 19.700, 15.000, 21.400, 6.000, 6.000, 4.000, 6.000, 8.000, 6.000, 8.000, 4.000, 4.000, 6.000, 6.000, 8.000, 8.000, 8.000, 8.000, 8.000, 8.000, 4.000, 4.000, 4.000, 4.000, 8.000, 8.000, 8.000, 8.000, 4.000, 4.000, 4.000, 8.000, 6.000, 8.000, 4.000, 160.000, 160.000, 108.000, 258.000, 360.000, 225.000, 360.000, 146.700, 140.800, 167.600, 167.600, 275.800, 275.800, 275.800, 472.000, 460.000, 440.000, 78.700, 75.700, 71.100, 120.100, 318.000, 304.000, 350.000, 400.000, 79.000, 120.300, 95.100, 351.000, 145.000, 301.000, 121.000, 110.000, 110.000, 93.000, 110.000, 175.000, 105.000, 245.000, 62.000, 95.000, 123.000, 123.000, 180.000, 180.000, 180.000, 205.000, 215.000, 230.000, 66.000, 52.000, 65.000, 97.000, 150.000, 150.000, 245.000, 175.000, 66.000, 91.000, 113.000, 264.000, 175.000, 335.000, 109.000, 3.900, 3.900, 3.850, 3.080, 3.150, 2.760, 3.210, 3.690, 3.920, 3.920, 3.920, 3.070, 3.070, 3.070, 2.930, 3.000, 3.230, 4.080, 4.930, 4.220, 3.700, 2.760, 3.150, 3.730, 3.080, 4.080, 4.430, 3.770, 4.220, 3.620, 3.540, 4.110, 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.440, 3.440, 4.070, 3.730, 3.780, 5.250, 5.424, 5.345, 2.200, 1.615, 1.835, 2.465, 3.520, 3.435, 3.840, 3.845, 1.935, 2.140, 1.513, 3.170, 2.770, 3.570, 2.780, 16.460, 17.020, 18.610, 19.440, 17.020, 20.220, 15.840, 20.000, 22.900, 18.300, 18.900, 17.400, 17.600, 18.000, 17.980, 17.820, 17.420, 19.470, 18.520, 19.900, 20.010, 16.870, 17.300, 15.410, 17.050, 18.900, 16.700, 16.900, 14.500, 15.500, 14.600, 18.600, 0.000, 0.000, 1.000, 1.000, 0.000, 1.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 1.000, 0.000, 1.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 3.000, 4.000, 5.000, 5.000, 5.000, 5.000, 5.000, 4.000, 4.000, 4.000, 1.000, 1.000, 2.000, 1.000, 4.000, 2.000, 2.000, 4.000, 4.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 1.000, 2.000, 1.000, 1.000, 2.000, 2.000, 4.000, 2.000, 1.000, 2.000, 2.000, 4.000, 6.000, 8.000, 2.000\n11\n\n\n2\n5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0, 7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9, 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3, 3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0, 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1, 6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0\n5\n\n\n3\n42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 58, 72, 84, 103, 122, 138, 162, 187, 209, 215, 43, 39, 55, 67, 84, 99, 115, 138, 163, 187, 198, 202, 42, 49, 56, 67, 74, 87, 102, 108, 136, 154, 160, 157, 41, 42, 48, 60, 79, 106, 141, 164, 197, 199, 220, 223, 41, 49, 59, 74, 97, 124, 141, 148, 155, 160, 160, 157, 41, 49, 57, 71, 89, 112, 146, 174, 218, 250, 288, 305, 42, 50, 61, 71, 84, 93, 110, 116, 126, 134, 125, 42, 51, 59, 68, 85, 96, 90, 92, 93, 100, 100, 98, 41, 44, 52, 63, 74, 81, 89, 96, 101, 112, 120, 124, 43, 51, 63, 84, 112, 139, 168, 177, 182, 184, 181, 175, 41, 49, 56, 62, 72, 88, 119, 135, 162, 185, 195, 205, 41, 48, 53, 60, 65, 67, 71, 70, 71, 81, 91, 96, 41, 49, 62, 79, 101, 128, 164, 192, 227, 248, 259, 266, 41, 49, 56, 64, 68, 68, 67, 68, 41, 45, 49, 51, 57, 51, 54, 42, 51, 61, 72, 83, 89, 98, 103, 113, 123, 133, 142, 39, 35, 43, 48, 55, 62, 65, 71, 82, 88, 106, 120, 144, 157, 41, 47, 54, 58, 65, 73, 77, 89, 98, 107, 115, 117, 40, 50, 62, 86, 125, 163, 217, 240, 275, 307, 318, 331, 41, 55, 64, 77, 90, 95, 108, 111, 131, 148, 164, 167, 43, 52, 61, 73, 90, 103, 127, 135, 145, 163, 170, 175, 42, 52, 58, 74, 66, 68, 70, 71, 72, 72, 76, 74, 40, 49, 62, 78, 102, 124, 146, 164, 197, 231, 259, 265, 42, 48, 57, 74, 93, 114, 136, 147, 169, 205, 236, 251, 39, 46, 58, 73, 87, 100, 115, 123, 144, 163, 185, 192, 39, 46, 58, 73, 92, 114, 145, 156, 184, 207, 212, 233, 39, 48, 59, 74, 87, 106, 134, 150, 187, 230, 279, 309, 42, 48, 59, 72, 85, 98, 115, 122, 143, 151, 157, 150, 42, 53, 62, 73, 85, 102, 123, 138, 170, 204, 235, 256, 41, 49, 65, 82, 107, 129, 159, 179, 221, 263, 291, 305, 39, 50, 63, 77, 96, 111, 137, 144, 151, 146, 156, 147, 41, 49, 63, 85, 107, 134, 164, 186, 235, 294, 327, 341, 41, 53, 64, 87, 123, 158, 201, 238, 287, 332, 361, 373, 39, 48, 61, 76, 98, 116, 145, 166, 198, 227, 225, 220, 41, 48, 56, 68, 80, 83, 103, 112, 135, 157, 169, 178, 41, 49, 61, 74, 98, 109, 128, 154, 192, 232, 280, 290, 42, 50, 61, 78, 89, 109, 130, 146, 170, 214, 250, 272, 41, 55, 66, 79, 101, 120, 154, 182, 215, 262, 295, 321, 42, 51, 66, 85, 103, 124, 155, 153, 175, 184, 199, 204, 42, 49, 63, 84, 103, 126, 160, 174, 204, 234, 269, 281, 42, 55, 69, 96, 131, 157, 184, 188, 197, 198, 199, 200, 42, 51, 65, 86, 103, 118, 127, 138, 145, 146, 41, 50, 61, 78, 98, 117, 135, 141, 147, 174, 197, 196, 40, 52, 62, 82, 101, 120, 144, 156, 173, 210, 231, 238, 41, 53, 66, 79, 100, 123, 148, 157, 168, 185, 210, 205, 39, 50, 62, 80, 104, 125, 154, 170, 222, 261, 303, 322, 40, 53, 64, 85, 108, 128, 152, 166, 184, 203, 233, 237, 41, 54, 67, 84, 105, 122, 155, 175, 205, 234, 264, 264, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 0, 2, 4, 6, 8, 10, 12, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n4\n\n\n4\n4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5, 15.2, 17.3, 22.5, 17.3, 13.6, 14.5, 18.8, 15.5, 23.6, 18.5, 33.9, 25.5, 26.4, 32.5, 26.7, 21.5, 23.3, 29.5, 15.2, 21.5, 17.6, 9.7, 14.5, 10.0, 8.2, 9.4, 16.5, 9.7, 19.7, 23.3, 23.6, 26.4, 20.0, 25.2, 25.8, 21.2, 14.5, 27.3, 25.5, 26.4, 22.4, 24.5, 24.8, 30.9, 26.4, 27.3, 29.4, 23.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0\n3\n\n\n\n\n\n\nWir k√∂nnen auch gleich map anweisen, keine Liste, sondern eine Zahl (double, reelle ) Zahl zur√ºckzuliefern, dann sparen wir uns das entschachteln:\n\nd %&gt;% \n  mutate(n_col = map_dbl(ds, ncol)) \n\n\n\n\n\n\n\n\n\n\nid\nds\nn_col\n\n\n\n\n1\n21.000, 21.000, 22.800, 21.400, 18.700, 18.100, 14.300, 24.400, 22.800, 19.200, 17.800, 16.400, 17.300, 15.200, 10.400, 10.400, 14.700, 32.400, 30.400, 33.900, 21.500, 15.500, 15.200, 13.300, 19.200, 27.300, 26.000, 30.400, 15.800, 19.700, 15.000, 21.400, 6.000, 6.000, 4.000, 6.000, 8.000, 6.000, 8.000, 4.000, 4.000, 6.000, 6.000, 8.000, 8.000, 8.000, 8.000, 8.000, 8.000, 4.000, 4.000, 4.000, 4.000, 8.000, 8.000, 8.000, 8.000, 4.000, 4.000, 4.000, 8.000, 6.000, 8.000, 4.000, 160.000, 160.000, 108.000, 258.000, 360.000, 225.000, 360.000, 146.700, 140.800, 167.600, 167.600, 275.800, 275.800, 275.800, 472.000, 460.000, 440.000, 78.700, 75.700, 71.100, 120.100, 318.000, 304.000, 350.000, 400.000, 79.000, 120.300, 95.100, 351.000, 145.000, 301.000, 121.000, 110.000, 110.000, 93.000, 110.000, 175.000, 105.000, 245.000, 62.000, 95.000, 123.000, 123.000, 180.000, 180.000, 180.000, 205.000, 215.000, 230.000, 66.000, 52.000, 65.000, 97.000, 150.000, 150.000, 245.000, 175.000, 66.000, 91.000, 113.000, 264.000, 175.000, 335.000, 109.000, 3.900, 3.900, 3.850, 3.080, 3.150, 2.760, 3.210, 3.690, 3.920, 3.920, 3.920, 3.070, 3.070, 3.070, 2.930, 3.000, 3.230, 4.080, 4.930, 4.220, 3.700, 2.760, 3.150, 3.730, 3.080, 4.080, 4.430, 3.770, 4.220, 3.620, 3.540, 4.110, 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.440, 3.440, 4.070, 3.730, 3.780, 5.250, 5.424, 5.345, 2.200, 1.615, 1.835, 2.465, 3.520, 3.435, 3.840, 3.845, 1.935, 2.140, 1.513, 3.170, 2.770, 3.570, 2.780, 16.460, 17.020, 18.610, 19.440, 17.020, 20.220, 15.840, 20.000, 22.900, 18.300, 18.900, 17.400, 17.600, 18.000, 17.980, 17.820, 17.420, 19.470, 18.520, 19.900, 20.010, 16.870, 17.300, 15.410, 17.050, 18.900, 16.700, 16.900, 14.500, 15.500, 14.600, 18.600, 0.000, 0.000, 1.000, 1.000, 0.000, 1.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 1.000, 0.000, 1.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 0.000, 0.000, 0.000, 0.000, 0.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 3.000, 3.000, 3.000, 3.000, 3.000, 4.000, 5.000, 5.000, 5.000, 5.000, 5.000, 4.000, 4.000, 4.000, 1.000, 1.000, 2.000, 1.000, 4.000, 2.000, 2.000, 4.000, 4.000, 3.000, 3.000, 3.000, 4.000, 4.000, 4.000, 1.000, 2.000, 1.000, 1.000, 2.000, 2.000, 4.000, 2.000, 1.000, 2.000, 2.000, 4.000, 6.000, 8.000, 2.000\n11\n\n\n2\n5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0, 7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9, 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3, 3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0, 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1, 6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0\n5\n\n\n3\n42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 58, 72, 84, 103, 122, 138, 162, 187, 209, 215, 43, 39, 55, 67, 84, 99, 115, 138, 163, 187, 198, 202, 42, 49, 56, 67, 74, 87, 102, 108, 136, 154, 160, 157, 41, 42, 48, 60, 79, 106, 141, 164, 197, 199, 220, 223, 41, 49, 59, 74, 97, 124, 141, 148, 155, 160, 160, 157, 41, 49, 57, 71, 89, 112, 146, 174, 218, 250, 288, 305, 42, 50, 61, 71, 84, 93, 110, 116, 126, 134, 125, 42, 51, 59, 68, 85, 96, 90, 92, 93, 100, 100, 98, 41, 44, 52, 63, 74, 81, 89, 96, 101, 112, 120, 124, 43, 51, 63, 84, 112, 139, 168, 177, 182, 184, 181, 175, 41, 49, 56, 62, 72, 88, 119, 135, 162, 185, 195, 205, 41, 48, 53, 60, 65, 67, 71, 70, 71, 81, 91, 96, 41, 49, 62, 79, 101, 128, 164, 192, 227, 248, 259, 266, 41, 49, 56, 64, 68, 68, 67, 68, 41, 45, 49, 51, 57, 51, 54, 42, 51, 61, 72, 83, 89, 98, 103, 113, 123, 133, 142, 39, 35, 43, 48, 55, 62, 65, 71, 82, 88, 106, 120, 144, 157, 41, 47, 54, 58, 65, 73, 77, 89, 98, 107, 115, 117, 40, 50, 62, 86, 125, 163, 217, 240, 275, 307, 318, 331, 41, 55, 64, 77, 90, 95, 108, 111, 131, 148, 164, 167, 43, 52, 61, 73, 90, 103, 127, 135, 145, 163, 170, 175, 42, 52, 58, 74, 66, 68, 70, 71, 72, 72, 76, 74, 40, 49, 62, 78, 102, 124, 146, 164, 197, 231, 259, 265, 42, 48, 57, 74, 93, 114, 136, 147, 169, 205, 236, 251, 39, 46, 58, 73, 87, 100, 115, 123, 144, 163, 185, 192, 39, 46, 58, 73, 92, 114, 145, 156, 184, 207, 212, 233, 39, 48, 59, 74, 87, 106, 134, 150, 187, 230, 279, 309, 42, 48, 59, 72, 85, 98, 115, 122, 143, 151, 157, 150, 42, 53, 62, 73, 85, 102, 123, 138, 170, 204, 235, 256, 41, 49, 65, 82, 107, 129, 159, 179, 221, 263, 291, 305, 39, 50, 63, 77, 96, 111, 137, 144, 151, 146, 156, 147, 41, 49, 63, 85, 107, 134, 164, 186, 235, 294, 327, 341, 41, 53, 64, 87, 123, 158, 201, 238, 287, 332, 361, 373, 39, 48, 61, 76, 98, 116, 145, 166, 198, 227, 225, 220, 41, 48, 56, 68, 80, 83, 103, 112, 135, 157, 169, 178, 41, 49, 61, 74, 98, 109, 128, 154, 192, 232, 280, 290, 42, 50, 61, 78, 89, 109, 130, 146, 170, 214, 250, 272, 41, 55, 66, 79, 101, 120, 154, 182, 215, 262, 295, 321, 42, 51, 66, 85, 103, 124, 155, 153, 175, 184, 199, 204, 42, 49, 63, 84, 103, 126, 160, 174, 204, 234, 269, 281, 42, 55, 69, 96, 131, 157, 184, 188, 197, 198, 199, 200, 42, 51, 65, 86, 103, 118, 127, 138, 145, 146, 41, 50, 61, 78, 98, 117, 135, 141, 147, 174, 197, 196, 40, 52, 62, 82, 101, 120, 144, 156, 173, 210, 231, 238, 41, 53, 66, 79, 100, 123, 148, 157, 168, 185, 210, 205, 39, 50, 62, 80, 104, 125, 154, 170, 222, 261, 303, 322, 40, 53, 64, 85, 108, 128, 152, 166, 184, 203, 233, 237, 41, 54, 67, 84, 105, 122, 155, 175, 205, 234, 264, 264, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 0, 2, 4, 6, 8, 10, 12, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n4\n\n\n4\n4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5, 15.2, 17.3, 22.5, 17.3, 13.6, 14.5, 18.8, 15.5, 23.6, 18.5, 33.9, 25.5, 26.4, 32.5, 26.7, 21.5, 23.3, 29.5, 15.2, 21.5, 17.6, 9.7, 14.5, 10.0, 8.2, 9.4, 16.5, 9.7, 19.7, 23.3, 23.6, 26.4, 20.0, 25.2, 25.8, 21.2, 14.5, 27.3, 25.5, 26.4, 22.4, 24.5, 24.8, 30.9, 26.4, 27.3, 29.4, 23.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0\n3\n\n\n\n\n\n\n\nCategories:\n\nprogramming\nloop"
  },
  {
    "objectID": "posts/emojis1/emojis1.html",
    "href": "posts/emojis1/emojis1.html",
    "title": "emojis1",
    "section": "",
    "text": "Extrahieren Sie die Anzahl der Emojis aus einem Text.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\nlibrary(easystats)\ndata(\"germeval_train\", package = \"pradadata\")\n\nNutzen Sie diesen Text-Datensatz, bevor Sie den gr√∂√üeren germeval-Datensatz verwenden:"
  },
  {
    "objectID": "posts/emojis1/emojis1.html#setup",
    "href": "posts/emojis1/emojis1.html#setup",
    "title": "emojis1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(emoji)  # emoji_xxx\nlibrary(tidyEmoji)"
  },
  {
    "objectID": "posts/emojis1/emojis1.html#test-1",
    "href": "posts/emojis1/emojis1.html#test-1",
    "title": "emojis1",
    "section": "Test 1",
    "text": "Test 1\n\ntest_text |&gt; \n  mutate(n_emojis = emoji_count(text))\n\n\n\n\n\nid\ntext\nn_emo\nn_emojis\n\n\n\n\n1\nAbbau, Abbruch ist jetzt\n2\n0\n\n\n2\nTest üßë‚Äçüéì üòÑ heute!!\n0\n3\n\n\n3\nAbbruch #morgen #perfekt\n2\n0\n\n\n4\nAbmachung‚Ä¶ LORE IPSUM\n1\n0\n\n\n5\nboese ja\n1\n0\n\n\n6\nb√∂se nein\n1\n0\n\n\n7\nhallo ?! www.google.de\n0\n0\n\n\n8\ngut schlecht I am you are he she it is\n2\n0\n\n\n\n\n\n\nDas Paket emoji beinhaltet eine Menge Emojis:\n\nemoji_name |&gt; length()\n\n[1] 4698"
  },
  {
    "objectID": "posts/emojis1/emojis1.html#test2",
    "href": "posts/emojis1/emojis1.html#test2",
    "title": "emojis1",
    "section": "Test2",
    "text": "Test2\n\ntest_text$text |&gt; \n  emoji_subset()\n\n[1] \"Test   üßë‚Äçüéì üòÑ heute!!\""
  },
  {
    "objectID": "posts/emojis1/emojis1.html#tidyemoji---emojis-kategorisieren",
    "href": "posts/emojis1/emojis1.html#tidyemoji---emojis-kategorisieren",
    "title": "emojis1",
    "section": "TidyEmoji - Emojis kategorisieren",
    "text": "TidyEmoji - Emojis kategorisieren\n\ndata.frame(tweets = c(\"I love tidyverse \\U0001f600\\U0001f603\\U0001f603\",\n\"R is my language! \\U0001f601\\U0001f606\\U0001f605\",\n\"This Tweet does not have Emoji!\",\n\"Wearing a mask\\U0001f637\\U0001f637\\U0001f637.\",\n\"Emoji does not appear in all Tweets\",\n\"A flag \\U0001f600\\U0001f3c1\")) %&gt;%\nemoji_categorize(tweets)\n\n\n\n\n\ntweets\n.emoji_category\n\n\n\n\nI love tidyverse üòÄüòÉüòÉ\nSmileys & Emotion\n\n\nR is my language! üòÅüòÜüòÖ\nSmileys & Emotion\n\n\nWearing a masküò∑üò∑üò∑.\nSmileys & Emotion\n\n\nA flag üòÄüèÅ\nSmileys & Emotion|Flags\n\n\n\n\n\n\n\ntest_text |&gt; \n  emoji_categorize(text)\n\n\n\n\n\n\n\n\n\n\n\nid\ntext\nn_emo\n.emoji_category\n\n\n\n\n2\nTest üßë‚Äçüéì üòÑ heute!!\n0\nSmileys & Emotion|People & Body|Objects\n\n\n\n\n\n\n\ndata(wild_emojis, package = \"pradadata\")\n\n\nwild_emojis |&gt; \n  emoji_categorize(emoji)\n\n\n\n\n\n\n\n\n\nemoji\n.emoji_category\n\n\n\n\nüí£\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüíÄ\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\n‚ò†Ô∏è\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò†\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüëπ\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüí©\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò°\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nü§¢\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nü§Æ\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüòñ\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò£\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò©\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò®\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüòù\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò≥\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò¨\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò±\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüòµ\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\nüò§\nSmileys & Emotion|NULL|NULL|NULL|NULL|NULL\n\n\n‚úä\nNULL|c(‚ÄúPeople & Body‚Äù, ‚ÄúPeople & Body‚Äù)|NULL|NULL|NULL|NULL\n\n\nüñï\nNULL|People & Body|NULL|NULL|NULL|NULL\n\n\nüëéÔ∏è\nNULL|People & Body|NULL|NULL|NULL|NULL\n\n\nü§¶‚Äç‚ôÄÔ∏è\nNULL|People & Body|NULL|NULL|NULL|Symbols\n\n\nü§¶‚Äç\nNULL|People & Body|NULL|NULL|NULL|NULL\n\n\nüî™\nNULL|NULL|Food & Drink|NULL|NULL|NULL\n\n\nüöë\nNULL|NULL|NULL|Travel & Places|NULL|NULL\n\n\nüî´\nNULL|NULL|NULL|NULL|Objects|NULL\n\n\nüóë\nNULL|NULL|NULL|NULL|Objects|NULL\n\n\n\n\n\n\nAlternativ kann man auch via Regex und Unicode Regex ansprechen‚Ä¶ emoji_pattern &lt;- \"\\\\p{So}\".\nDas ist vermutlich cleverer ü§ì.\n\nCategories:\n\nemoji\ntextmining\nstring"
  },
  {
    "objectID": "posts/filter-na1/filter-na1.html",
    "href": "posts/filter-na1/filter-na1.html",
    "title": "filter-na1",
    "section": "",
    "text": "Filtern Sie alle Zeilen ohne fehlende Werte im Datensatz penguins!"
  },
  {
    "objectID": "posts/filter-na1/filter-na1.html#setup",
    "href": "posts/filter-na1/filter-na1.html#setup",
    "title": "filter-na1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\nnrow(d)\n\n[1] 344"
  },
  {
    "objectID": "posts/filter-na1/filter-na1.html#weg-1",
    "href": "posts/filter-na1/filter-na1.html#weg-1",
    "title": "filter-na1",
    "section": "Weg 1",
    "text": "Weg 1\n\nd_nona &lt;-\n  d %&gt;% \n  filter(complete.cases(.))\n\nnrow(d_nona)\n\n[1] 333"
  },
  {
    "objectID": "posts/filter-na1/filter-na1.html#weg-2",
    "href": "posts/filter-na1/filter-na1.html#weg-2",
    "title": "filter-na1",
    "section": "Weg 2",
    "text": "Weg 2\n\nd %&gt;% \n  filter(if_all(everything(), ~ !is.na(.))) %&gt;% \n  nrow()\n\n[1] 333"
  },
  {
    "objectID": "posts/filter-na1/filter-na1.html#weg-3",
    "href": "posts/filter-na1/filter-na1.html#weg-3",
    "title": "filter-na1",
    "section": "Weg 3",
    "text": "Weg 3\n\nd |&gt; \n  drop_na() |&gt; \n  nrow()\n\n[1] 333\n\n\n\nCategories:\n\n2023\neda\nna\nstring"
  },
  {
    "objectID": "posts/penguins-stan-04/penguins-stan-04.html",
    "href": "posts/penguins-stan-04/penguins-stan-04.html",
    "title": "penguins-stan-04",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nWie gro√ü ist die Wahrscheinlichkeit, dass der Effekt vorhanden ist (also gr√∂√üer als Null ist), die ‚ÄúEffektwahrscheinlichkeit‚Äù? Geben Sie die Wahrscheinlichkeit an.\nHinweise:\n\nNutzen Sie den Datensatz zu den Palmer Penguins.\nVerwenden Sie Methoden der Bayes-Statistik und die Software Stan.\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nZentrieren ist eigentlich immer n√ºtzlich, aber hier streng genommen nicht unbedingt n√∂tig. Der Hauptgrund daf√ºr ist, dass Stan f√ºr uns den Prior f√ºr den Intercept festlegt, und zwar auf Basis der Daten, wir uns also nicht um die komische Frage zu k√ºmmern brauchen, welchen Prior wir f√ºr den unzentrierten Achsenabschnitt vergeben wollten: Wie schwer sind Pinguins der Schnabell√§nge Null? Mit zentrierten Pr√§diktoren ist die Frage nach dem Prior viel einfacher zu beantworten: Wie schwer ist ein Pinguin mit mittelgro√üem Schnabel?\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\nMit pd() kann man sich die Effektwahrscheinlichkeit (‚Äúprobability of direction‚Äù) ausgeben lassen:\n\npd(m1)\n\n\n\n\n\nParameter\npd\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.89575\nfixed\nconditional\n\n\nbill_length_mm\n1.00000\nfixed\nconditional\n\n\n\n\n\n\nMehr Informationen zu dieser Statistik findet sich hier oder hier.\nAlternativ bekommt man die Statistik auch mit parameters().\nDie L√∂sung lautet also 1.\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/bed-wskt3/bed-wskt3.html",
    "href": "posts/bed-wskt3/bed-wskt3.html",
    "title": "Bed-Wskt3",
    "section": "",
    "text": "Aufgabe\nAls Bildungsforscher(in) untersuchen Sie den Lernerfolg in einem Statistikkurs.\nEine Gruppe von Studierenden absolviert einen Statistikkurs. Ein Teil lernt gut mit (Ereignis \\(A\\)), ein Teil nicht (Ereignis \\(A^C\\)). Ein Teil besteht die Pr√ºfung (Ereignis \\(B\\)); ein Teil nicht (\\(B^C\\)).\n(Eselsbr√ºcke: Das Ereignis ‚ÄúA‚Äù steht f√ºr ‚ÄúAh, hat Aufgepasst.)\nWir ziehen zuf√§llig eine/n Studierende/n: Siehe da ‚Äì Die Person hat bestanden. Yeah!\nDie Anteile der Gruppen (bzw. Wahrscheinlichkeit des Ereignisses) lassen sich unten stehender Tabelle entnehmen.\nd %&gt;% \n  select(row_ids, B, Bneg)  %&gt;% \n  mutate(across(c(B, Bneg), \\(x) round(x, digits = 2))) %&gt;% \n  mutate(Summe = B + Bneg) %&gt;% \n  gt()\n\n\n\n\n\n\nrow_ids\nB\nBneg\nSumme\n\n\n\n\nA\n0.41\n0.11\n0.52\n\n\nA_neg\n0.33\n0.15\n0.48\n\n\nSumme\n0.73\n0.26\n0.99\n\n\n\n\n\nAufgabe: Gesucht ist die (bedingte) Wahrscheinlichkeit, dass diese Person gut mitgelernt hat, gegeben der Tatsache, dass sie bestanden hat. Geben Sie die Wahrscheinlichkeit des gesuchten Ereignisses an!\nHinweise:\n\nRunden Sie auf 2 Dezimalstellen.\nGeben Sie Anteile stets in der Form 0.42 an (mit f√ºhrender Null und Dezimalpunkt).\n‚ÄúA_neg‚Äù bezieht sich auf das Komplement√§rereignis zu A.\n\n         \n\n\nL√∂sung\n\nsol &lt;- A_cond_B %&gt;% round(2) \n\nDer gesuchte Wert lautet: 0.55.\n\nCategories:\n\nprobability\nbayes\nnum"
  },
  {
    "objectID": "posts/rope1/rope1.html",
    "href": "posts/rope1/rope1.html",
    "title": "rope1",
    "section": "",
    "text": "Question\nDas Testen von Nullhypothesen wird u.a. deswegen kritisiert, weil die Nullhypothese zumeist apriori als falsch bekannt ist, weswegen es keinen Sinne mache, so die Kritiker, sie zu testen.\nNennen Sie ein Verfahren von John Kruschke, das einen √Ñquivalenzbereich testet und insofern eine Alternative zum Testen von Nullhypothesen anbietet.\nHinweise:\n\nGeben Sie nur Kleinbuchstaben ein.\nGeben Sie nur ein einziges Wort ein.\n\n\n\nSolution\nrope"
  },
  {
    "objectID": "posts/Linearitaet1a/Linearitaet1a.html",
    "href": "posts/Linearitaet1a/Linearitaet1a.html",
    "title": "Linearitaet1a",
    "section": "",
    "text": "Bei welcher der Abbildungen ist eine Regression mit linearem Graph angemessen?\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/Linearitaet1a/Linearitaet1a.html#answerlist",
    "href": "posts/Linearitaet1a/Linearitaet1a.html#answerlist",
    "title": "Linearitaet1a",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/Linearitaet1a/Linearitaet1a.html#answerlist-1",
    "href": "posts/Linearitaet1a/Linearitaet1a.html#answerlist-1",
    "title": "Linearitaet1a",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nlm\nregression\nlinear\nschoice"
  },
  {
    "objectID": "posts/nasa06/nasa06.html",
    "href": "posts/nasa06/nasa06.html",
    "title": "nasa06",
    "section": "",
    "text": "Aufgabe\nViele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read_csv(data_path, skip = 1)\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgaben\n\nFassen Sie immer 10 Jahre (eine Dekade) an Jahren zusammen.\nPr√§sentieren Sie g√§ngige Statistiken pro Dekade f√ºr alle Monate.\n\nHinweise:\n\nSie m√ºssen zuerst die Dekade als neue Spalte berechnen.\nTreffen Sie Annahmen, wo n√∂tig.\nBeachten Sie die Hinweise.\n\n         \n\n\nL√∂sung\nTabelle in die Lang-Form bringen:\n\nd_long &lt;- \n  d %&gt;% \n  select(Year, Jan:Dec) %&gt;% \n  mutate(across(Jan:Dec, as.numeric)) %&gt;% \n  pivot_longer(cols = Jan:Dec, values_to = \"temp\", names_to = \"month\") \n\nEin Blick in die Tabelle:\n\nhead(d_long)\n\n\n\n\n\nYear\nmonth\ntemp\n\n\n\n\n1880\nJan\n-0.19\n\n\n1880\nFeb\n-0.25\n\n\n1880\nMar\n-0.09\n\n\n1880\nApr\n-0.16\n\n\n1880\nMay\n-0.10\n\n\n1880\nJun\n-0.21\n\n\n\n\n\n\nDekade berechnen:\n\nd_long2 &lt;-\n  d_long %&gt;% \n  mutate(decade = round(Year/10) * 10)\n\n\ntail(d_long2)  # letzten paar Zeilen der Tabelle \"d_long2\"\n\n\n\n\n\nYear\nmonth\ntemp\ndecade\n\n\n\n\n2025\nJul\n1.01\n2020\n\n\n2025\nAug\n1.14\n2020\n\n\n2025\nSep\nNA\n2020\n\n\n2025\nOct\nNA\n2020\n\n\n2025\nNov\nNA\n2020\n\n\n2025\nDec\nNA\n2020\n\n\n\n\n\n\n\nd_summarized &lt;-\nd_long2 %&gt;% \n  group_by(decade, month) %&gt;% \n  summarise(temp_mean = mean(temp, na.rm = TRUE),\n            temp_sd = sd(temp, na.rm = TRUE))\n\n\n\n\n\n\n\ndecade\nmonth\ntemp_mean\ntemp_sd\n\n\n\n\n1880\nApr\n-0.2133333\n0.1747760\n\n\n1880\nAug\n-0.1516667\n0.1128568\n\n\n1880\nDec\n-0.1883333\n0.1202359\n\n\n1880\nFeb\n-0.1700000\n0.1888915\n\n\n1880\nJan\n-0.2050000\n0.2395621\n\n\n1880\nJul\n-0.1716667\n0.1293703\n\n\n\n\n\n\nZum Visualisieren gibt es meist viele Wege. Hier ist ein Weg mit ggplot2:\n\nd_summarized %&gt;% \n  ggplot(aes(x = decade, y = temp_mean)) +\n  geom_point(color = \"darkblue\") +\n  geom_errorbar(aes(ymin = temp_mean - temp_sd, ymax = temp_mean + temp_sd)) +\n  geom_line(alpha = .7) +\n  facet_wrap(~ month) +\n  labs(caption = \"Fehlerbalken zeigen plus/minus 1 SD\")\n\n\n\n\n\n\n\n\nMonate zu einem Jahreswert zusammen:\n\nd_summarized2 &lt;- \n  d_summarized %&gt;% \n  group_by(decade) %&gt;% \n  summarise(temp_mean = mean(temp_mean),\n            temp_sd = sd(temp_sd))\n\nd_summarized2\n\n\n\n\n\ndecade\ntemp_mean\ntemp_sd\n\n\n\n\n1880\n-0.1922222\n0.0579576\n\n\n1890\n-0.2700000\n0.0538612\n\n\n1900\n-0.2357576\n0.0216727\n\n\n1910\n-0.3722222\n0.0450286\n\n\n1920\n-0.2844697\n0.0586502\n\n\n1930\n-0.1945370\n0.0473414\n\n\n1940\n0.0294697\n0.0292688\n\n\n1950\n-0.0688889\n0.0352598\n\n\n1960\n-0.0345455\n0.0307651\n\n\n1970\n-0.0070370\n0.0398311\n\n\n1980\n0.1454545\n0.0305521\n\n\n1990\n0.3088889\n0.0237046\n\n\n2000\n0.5093182\n0.0235646\n\n\n2010\n0.6543519\n0.0411242\n\n\n2020\n0.9973712\n0.0354472\n\n\n\n\n\n\nAlternativ k√∂nnen Sie zum Visualisieren der Daten z.B. das Paket ggpubr nutzen:\n\nlibrary(ggpubr)\nggscatter(d_summarized2, x = \"decade\", y = \"temp_mean\", add = \"reg.line\")\n\n\n\n\n\n\n\n\nOder auch mit den Facetten pro Monat:\n\nggscatter(d_summarized, x = \"decade\", y = \"temp_mean\", add = \"reg.line\",\n          facet.by = \"month\")\n\n\n\n\n\n\n\n\n√Ñhnlich sieht es mit DataExplorer aus:\n\nlibrary(DataExplorer)\nd_summarized2 |&gt; \n  select(temp_mean, decade) |&gt; \n  plot_scatterplot(by = \"decade\")\n\nd_summarized2 |&gt; \n  select(temp_sd, decade) |&gt; \n  plot_scatterplot(by = \"decade\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie weltweilte Temperatur steigt. Bleibt u.a. die Frage, ob eine lineare Funktion angemessen ist, oder ob die Steigung nicht vielleicht prozentual steigt (das w√§re eine exponenzielle Steigerung)?\nFalls Sie Teile der R-Syntax nicht kennen: Machen Sie sich nichts daraus. üòÑ\n\nCategories:\n\ndata\neda\nlagema√üe\nstring"
  },
  {
    "objectID": "posts/Regression3/Regression3.html",
    "href": "posts/Regression3/Regression3.html",
    "title": "Regression3",
    "section": "",
    "text": "Eine Forscherin berechnet ein Regressionsmodell mit einer metrischen AV y und einer metrischen UV x.\nDazu kommt noch eine Gruppierungsvariable \\(g\\) (mit den Stufen 0 und 1). Das Modell lautet also: y ~ x + g.\nDas folgende Diagramm stellt das Modell dar (vgl. Farbe und Form der Punkte zur Darstellung von g).\n\n\n\n\n\n\n\n\n\nW√§hlen Sie das (f√ºr die Population) am besten passende Modell aus der Liste aus!\nHinweis: Ein Interaktionseffekt der Variablen \\(x\\) und \\(g\\) ist mit \\(xg\\) gekennzeichnet.\n\n\n\n\\(y = 40 + 10\\cdot x + 40 \\cdot g + 0 \\cdot xg + \\epsilon\\)\n\\(y = -40 + -10\\cdot x + 0 \\cdot g + 0 \\cdot xg + \\epsilon\\)\n\\(y = -40 + 10\\cdot x + -40 \\cdot g + 0 \\cdot xg + \\epsilon\\)\n\\(y = -40 + -10\\cdot x + -40 \\cdot g + 0 \\cdot xg + \\epsilon\\)"
  },
  {
    "objectID": "posts/Regression3/Regression3.html#answerlist",
    "href": "posts/Regression3/Regression3.html#answerlist",
    "title": "Regression3",
    "section": "",
    "text": "\\(y = 40 + 10\\cdot x + 40 \\cdot g + 0 \\cdot xg + \\epsilon\\)\n\\(y = -40 + -10\\cdot x + 0 \\cdot g + 0 \\cdot xg + \\epsilon\\)\n\\(y = -40 + 10\\cdot x + -40 \\cdot g + 0 \\cdot xg + \\epsilon\\)\n\\(y = -40 + -10\\cdot x + -40 \\cdot g + 0 \\cdot xg + \\epsilon\\)"
  },
  {
    "objectID": "posts/Regression3/Regression3.html#answerlist-1",
    "href": "posts/Regression3/Regression3.html#answerlist-1",
    "title": "Regression3",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\ndyn\nregression\nlm\nschoice"
  },
  {
    "objectID": "posts/ausreisser1/ausreisser1.html",
    "href": "posts/ausreisser1/ausreisser1.html",
    "title": "ausreisser1",
    "section": "",
    "text": "Entfernen Sie alle Ausrei√üer im Datensatz mariokart!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nDefinieren Sie ‚ÄúAusrei√üer‚Äù als Werte, die mehr als 3SD vom Mittelwert entfernt sind."
  },
  {
    "objectID": "posts/ausreisser1/ausreisser1.html#setup",
    "href": "posts/ausreisser1/ausreisser1.html#setup",
    "title": "ausreisser1",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "posts/ausreisser1/ausreisser1.html#√ºberblick",
    "href": "posts/ausreisser1/ausreisser1.html#√ºberblick",
    "title": "ausreisser1",
    "section": "√úberblick",
    "text": "√úberblick\nWir verschaffen uns einen √úberblick √ºber die Verteilungen:\n\nplot_histogram(mariokart)  # aus Paket `DataExplorer`\n\n\n\n\n\n\n\n\nWie man sieht gibt es einige Ausrei√üer, z.B. bei ship_pr und total_pr."
  },
  {
    "objectID": "posts/ausreisser1/ausreisser1.html#daten-aufbereiten-mit-z-transformation",
    "href": "posts/ausreisser1/ausreisser1.html#daten-aufbereiten-mit-z-transformation",
    "title": "ausreisser1",
    "section": "Daten aufbereiten mit z-Transformation",
    "text": "Daten aufbereiten mit z-Transformation\n\nmariokart2 &lt;-\n  mariokart %&gt;% \n  select(-id) %&gt;% \n  mutate(across(  # \"across\" wiederholt die Funktionen \".fns\" √ºber alle Spalten \".cols\"\n    .cols = where(is.numeric),\n    .fns = ~ as.numeric(standardize(.x))))\n\nLeider gibt standardize kein vern√ºnftiges numerisches Objekt zur√ºck, so dass wir mit as.numeric die Daten noch zur R√§son rufen m√ºssen.\nWie man sieht, √§ndert sich die Verteilungsform nicht durch die z-Transformation (oder durch irgendeine lineare Transformation):\n\nplot_histogram(mariokart2)"
  },
  {
    "objectID": "posts/ausreisser1/ausreisser1.html#extremwerte-durch-mw-ersetzen",
    "href": "posts/ausreisser1/ausreisser1.html#extremwerte-durch-mw-ersetzen",
    "title": "ausreisser1",
    "section": "Extremwerte durch MW ersetzen",
    "text": "Extremwerte durch MW ersetzen\n\nmariokart3 &lt;-\n  mariokart2 %&gt;% \n  mutate(across(\n    .cols = where(is.numeric),\n    .fns = ~ case_when(abs(.x) &lt;= 3 ~ .x,\n                       abs(.x) &gt; 3 ~ mean(.x))\n  ))\n\n\nplot_histogram(mariokart3)\n\n\n\n\n\n\n\n\nJetzt sind die Daten deutlich weniger extrem.\n\nCategories:\n\neda\ndatawrangling\ntidyverse\nausreisser\nstring"
  },
  {
    "objectID": "posts/iq01a/index.html",
    "href": "posts/iq01a/index.html",
    "title": "iq01a",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt. Ab einem Testwert von 130 Punkten nennt man die getestete Person hochbegabt.\nWie gro√ü ist die Wahrscheinlichkeit, dass die n√§chste Person, die Sie treffen, hochbetagthochbegabt ist? Geben Sie die Wahrscheinlichkeit (als Anteil) an.\nHinweise:\n\nNutzen Sie keine Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nGeben Sie keine Prozentzahlen, sondern stets Anteile an.\nWir gehen von einer Normalverteilung aus.\nBeachten Sie die √ºbrigen Hinwise des Datenwerks.\n\n         \n\n\nL√∂sung\nL√∂sung: Die gesuchte Wahrscheinlichkeit betr√§gt ca. 2% bzw. 0.02.\nEs kann sich anbieten, diesen Wert auswendig zu wissen.\nMan kann auch einen Computer befragen:\n\npnorm(130, mean = 100, sd = 15, lower.tail = FALSE)\n\n[1] 0.02275013\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nexam-22\nnum"
  },
  {
    "objectID": "posts/bayesbox3/index.html",
    "href": "posts/bayesbox3/index.html",
    "title": "bayesbox3",
    "section": "",
    "text": "1 Setup\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\n\n2 Aufgabe\nSie f√ºhren ein zweiwertiges (binomiales) Zufallsexperiment \\(n\\)-mal durch, dabei erzielen Sie \\(k\\) Treffer. Die Wiederholungen sind unabh√§ngig voneinander, und die Trefferwahrscheinlichkeit \\(\\pi\\) bleibt konstant.\n(Eine M√ºnze wiederholt werfen w√§re das typische Beispiel f√ºr ein solches Zufallexperiment.)\nGehen Sie von folgenden Parameterwerten aus:\n\nn &lt;- 14\nk &lt;- 7  # Trefferzahl\n\nWelcher Parameterwert \\(\\pi\\) ist am wahrscheinlichsten, wenn Sie keine weiteren Informationen haben?\nSie √ºberpr√ºfen alle 11 Parameterwerte f√ºr \\(\\pi\\) von 0 bis 1 (in Schritten von 0.1.)\nUm diese Frage zu beantworten, berechnen Sie die Wahrscheinlichkeiten f√ºr alle m√∂glichen Parameterwerte \\(\\pi\\) von 0 bis 1 in Schritten von 0.1 anhand einer Bayesbox. Dabei gehen wir von einer Binomialverteilung aus:\n\\(k \\sim Bin(n, \\pi)\\).\n\n\n\n\nListing¬†1: Parameterwerte (Gitter) f√ºr Trefferwahrscheinlichkeit: 0, 0.1, 0.2, ‚Ä¶, 1\n\n\npis &lt;- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte\npis\n\n\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten gegeben jeweils eines Parameterwerts:\n\nLikelihood &lt;- dbinom(k, size = n, prob = pis)\nLikelihood\n\n [1] 0.0000000000 0.0001641515 0.0092127048 0.0618133587 0.1574076993\n [6] 0.2094726563 0.1574076993 0.0618133587 0.0092127048 0.0001641515\n[11] 0.0000000000\n\n\nAuf dieser Basis erstellen wir eine Bayes-Box, um die Posteriori-Wahrscheinlichkeiten f√ºr alle Parameterwerte zu berechnen, s. Listing¬†2.\n\n\n\n\nListing¬†2: Wir basteln uns eine Bayes-Box\n\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (die Parameterwerte, p): \n    p = pis,\n    # Lege den Priori-Wert fest:\n    Priori  = 1/11) |&gt; \n    mutate(\n      # berechne Likelihood f√ºr jeden Wasseranteil (Parameterwert):\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\n\n\n\nDie Bayes-Box (Table¬†1) zeigt, wie sich die Post-Verteilung berechnet.\nLeider sind die zentralen Spalten ausgeblendet. ü§¨\n\n\n\n\nTable¬†1: Die Bayes-Box\n\n\n\n\n\n\nid\np\nPriori\n\n\n\n\n1\n0.0\n0.09\n\n\n2\n0.1\n0.09\n\n\n3\n0.2\n0.09\n\n\n4\n0.3\n0.09\n\n\n5\n0.4\n0.09\n\n\n6\n0.5\n0.09\n\n\n7\n0.6\n0.09\n\n\n8\n0.7\n0.09\n\n\n9\n0.8\n0.09\n\n\n10\n0.9\n0.09\n\n\n11\n1.0\n0.09\n\n\n\n\n\n\n\n\nAufgabe: Welcher Parameterwert \\(\\pi\\) ist am wahrscheinlichsten?\n  \n  \n  \n  \n\n\n3 L√∂sung\nDer wahrscheinlichste Parameterwert \\(\\pi\\) ist derjenige, der die h√∂chste Posteriori-Wahrscheinlichkeit hat.\nBei gleichverteilten Prirori-Werten ist der wahrscheinlichste Parameterwert derjenige, der die h√∂chste Likelihood hat: 7/14 = 0.5.\nMan braucht also die Bayesbox gar nicht ¬†ü§™.\n\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n\n1\n0.0\n0.09\n0.00\n0.00\n0.06\n0.00\n\n\n2\n0.1\n0.09\n0.00\n0.00\n0.06\n0.00\n\n\n3\n0.2\n0.09\n0.01\n0.00\n0.06\n0.01\n\n\n4\n0.3\n0.09\n0.06\n0.01\n0.06\n0.09\n\n\n5\n0.4\n0.09\n0.16\n0.01\n0.06\n0.24\n\n\n6\n0.5\n0.09\n0.21\n0.02\n0.06\n0.31\n\n\n7\n0.6\n0.09\n0.16\n0.01\n0.06\n0.24\n\n\n8\n0.7\n0.09\n0.06\n0.01\n0.06\n0.09\n\n\n9\n0.8\n0.09\n0.01\n0.00\n0.06\n0.01\n\n\n10\n0.9\n0.09\n0.00\n0.00\n0.06\n0.00\n\n\n11\n1.0\n0.09\n0.00\n0.00\n0.06\n0.00\n\n\n\n\n\nHier ist eine Visualisierung der Posteriori-Wahrscheinlichkeiten:\n\nggline(d, x = \"p\", y = \"Post\", \n       xlab = \"Trefferwahrscheinlichkeit\", ylab = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Posteriori-Wahrscheinlichkeiten f√ºr Trefferwahrscheinlichkeit\",\n       add = c(\"point\", \"smooth\"))"
  },
  {
    "objectID": "posts/wskt-quiz04/wskt-quiz04.html",
    "href": "posts/wskt-quiz04/wskt-quiz04.html",
    "title": "wskt-quiz04",
    "section": "",
    "text": "Sei \\(X \\sim Bin(10, 1/2)\\). Dann ist die zugeh√∂rige Verteilung (von \\(X\\)) symmetrisch.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz04/wskt-quiz04.html#answerlist",
    "href": "posts/wskt-quiz04/wskt-quiz04.html#answerlist",
    "title": "wskt-quiz04",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz04/wskt-quiz04.html#answerlist-1",
    "href": "posts/wskt-quiz04/wskt-quiz04.html#answerlist-1",
    "title": "wskt-quiz04",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html",
    "href": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html",
    "title": "Verteilungen-Quiz-11",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nBei einer Verteilung gilt: \\(\\bar{x} = Md = \\text{Modus}\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist",
    "href": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist",
    "title": "Verteilungen-Quiz-11",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist-1",
    "title": "Verteilungen-Quiz-11",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/adjustieren2a/adjustieren2a.html",
    "href": "posts/adjustieren2a/adjustieren2a.html",
    "title": "adjustieren2a",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgendes Modell, das den Zusammenhang des Preises (price) und dem Gewicht (carat) von Diamanten untersucht (Datensatz diamonds).\n\nlibrary(tidyverse)\nlibrary(easystats)\ndiamonds &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n\nAber zuerst zentrieren wir den metrischen Pr√§diktor carat, um den Achsenabschnitt besser interpretieren zu k√∂nnen.\n\ndiamonds &lt;-\n  diamonds %&gt;% \n  mutate(carat_z = carat - mean(carat, na.rm = TRUE))\n\nDann berechnen wir ein (nicht-bayesianisches, sondern frequentistisches) Regressionsmodell:\n\nlm1 &lt;- lm(price ~ carat_z, data = diamonds)\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n3932.800\n6.667655\n0.95\n3919.731\n3945.868\n589.8325\n53938\n0\n\n\ncarat_z\n7756.426\n14.066579\n0.95\n7728.855\n7783.996\n551.4081\n53938\n0\n\n\n\n\n\n\nZur Verdeutlichung ein Diagramm zum Modell:\n\nestimate_relation(lm1) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgaben:\n\nWas kostet in Diamant mittlerer Gr√∂√üe laut Modell lm1? Runden Sie auf eine Dezimale. Geben Sie nur eine Zahl ein.\nGeben Sie eine Regressionsformel an, die lm1 erg√§nzt, so dass die Schliffart (cut) des Diamanten kontrolliert (adjustiert) wird. Anders gesagt: Das Modell soll die mittleren Preise f√ºr jede der f√ºnf Schliffarten angeben. Geben Sie nur die Regressionsformel an. Lassen Sie zwischen Termen jeweils ein Leerzeichen Abstand.\n\nHinweis: Es gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\n\ndiamonds %&gt;% \n  distinct(cut)\n\n\n\n\n\ncut\n\n\n\n\nIdeal\n\n\nPremium\n\n\nGood\n\n\nVery Good\n\n\nFair\n\n\n\n\n\n\n         \n\n\nL√∂sung\n\nUnser Modell lm1 sch√§tzt den Preis eines Diamanten mittlerer Gr√∂√üe auf etwa 3932.5 (was immer auch die Einheiten sind, Dollar vermutlich). Da der Pr√§diktor carat_z zentriert ist, entspricht ein Wert von 0 dem Mittelwert der urspr√ºnglichen Verteilung, carat. Der Y-Wert, wenn X=0, wird vom Intercept angegeben.\n\n\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n3932.800\n6.667655\n0.95\n3919.731\n3945.868\n589.8325\n53938\n0\n\n\ncarat_z\n7756.426\n14.066579\n0.95\n7728.855\n7783.996\n551.4081\n53938\n0\n\n\n\n\n\n\nOder so:\n\ncoef(lm1)\n\n(Intercept)     carat_z \n   3932.800    7756.426 \n\n\nAlternativ k√∂nnen wir uns mit predict f√ºr jeden beliebigen Wert des Pr√§diktors die Vorhersage des Modells ausgeben lassen.\nWir definieren eine (hier sehr kurze) Tabelle mit Pr√§diktorwerten, f√ºr die wir die Vorhersage laut lm1 wissen m√∂chten:\n\nneue_daten &lt;-\n  tibble(carat_z = 0)\n\nDann weisen wir unseren Lieblingsroboter an, auf Basis von lm1 eine Vorhersage (prediction) f√ºr neue_daten zu erstellen.\n\npredict(lm1, newdata = neue_daten)\n\n     1 \n3932.8 \n\n\n\nprice ~ carat_z + cut\n\nDieses zweite Modell k√∂nnten wir so berechnen:\n\nlm2 &lt;- lm(price ~ carat_z + cut, data = diamonds)\nparameters(lm2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n2405.180\n37.82838\n0.95\n2331.036\n2479.324\n63.58136\n53934\n0\n\n\ncarat_z\n7871.082\n13.97963\n0.95\n7843.682\n7898.482\n563.03950\n53934\n0\n\n\ncutGood\n1120.332\n43.49923\n0.95\n1035.073\n1205.591\n25.75521\n53934\n0\n\n\ncutIdeal\n1800.924\n39.34443\n0.95\n1723.809\n1878.039\n45.77329\n53934\n0\n\n\ncutPremium\n1439.077\n39.86533\n0.95\n1360.941\n1517.214\n36.09846\n53934\n0\n\n\ncutVery Good\n1510.135\n40.24008\n0.95\n1431.265\n1589.006\n37.52814\n53934\n0\n\n\n\n\n\n\nMan k√∂nnte hier noch einen Interaktionseffekt erg√§nzen, wenn man Grund zur Annahme hat, dass es einen gibt.\n\nCategories:\n\nregression\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/iq10/iq10.html",
    "href": "posts/iq10/iq10.html",
    "title": "iq10",
    "section": "",
    "text": "Aufgabe\nEine Forscherin, Prof.¬†Weiss-Ois, untersucht den Effekt von Cannabis auf die Intelligenz.\nDazu untersucht Sie die Intelligenz langj√§hriger Konsumentis.\nProf.¬†Weiss-Ois geht apriori von gleichverteilter Intelligenz aus. Ihre zentrale Hypothese ist \\(\\mu = 90\\pm5\\).\nMit gro√üer Spannung wurden die Messdaten zur Intelligenz erwartet (die erst nach langem Streit √ºber die zu verwendenden Intelligenztests erhoben werden konnten). Insgesamt wurden \\(N=541\\) Personen untersucht.\nTats√§chlich sei die wahre IQ-Verteilung jener Cannabis-Konsumentis wie folgt: \\(IQ \\sim N(92.5, 7.5)\\). Nat√ºrlich kennt die Forscherin diese Verteilung nicht.\nWie wahrscheinlich ist die Hypothese der Forscherin im Lichte der Daten?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^4\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nGitterwerte f√ºr die Intelligenz k√∂nnten z.B. 75 bis 130 sein.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nZun√§chst basteln wir die Bayes-Box:\n\nn &lt;- 100\n\nset.seed(42)\npostvert &lt;-\n  tibble(p_grid = seq(from = 75, to = 130, length.out = n),\n         prior  = 1) %&gt;% \n  mutate(likelihood = dnorm(x = p_grid, mean = 92.5, sd = 7.5)) %&gt;% \n  mutate(unstand_post = likelihood * prior,\n         post = unstand_post / sum(unstand_post))\n\nWarum 75 bis 130? Das ist ein beliebiger Wert, in dem Sinne, dass Sie sich inhaltlich √ºberlegen m√ºssen, welchen Wertebereich Sie f√ºr plausibel halten. Untersucht man IQ-Mittelwerte so erscheint (mir) ein Wertebereich von 75 bis 130 mehr als ausreichend. Untersucht man Mittelwerte der K√∂rpergr√∂√üe (heutiger Menschen in bekannten Zivilisationen) so erscheint (mir) ein Wertebereich von 140 cm bis 200cm als ausreichend.\nAus der Post-Verteilung ziehen wir Stichproben:\n\nset.seed(42)\npostvert_stipros &lt;-\n  postvert %&gt;% \n  slice_sample(\n    n = 1e4,\n    weight_by = post,\n    replace = T) %&gt;% \n  select(p_grid)\n\nDamit haben wir unsere Stichproben-Post-Verteilung.\nDa slice_sample auch zuf√§llig Stichproben zieht, m√ºssen wir auch hier die Zufallszahlen fixieren, wenn wir die exakt gleichen Ergebnisse reproduzieren wollen.\nJetzt schauen wir (mit Spannung), wie hoch die Wahrscheinlichkeit ist f√ºr Parameterwete (p_grid) innerhalb des Intervalls wie von der Forscherin vorgegeben.\n\npostvert_stipros %&gt;% \n  count(between(p_grid, left = 85, right = 95))\n\n\n\n\n\nbetween(p_grid, left = 85, right = 95)\nn\n\n\n\n\nFALSE\n5002\n\n\nTRUE\n4998\n\n\n\n\n\n\nbetween ist eine Komfortfuntion; ins Deutsche √ºbersetzt sagt die Syntax:\nNimm die Tabelle postvert_stipros und dann ...\n  z√§hle den Anteil der Werte von p_grid zwischen 85 und 95.\nDie Wahrscheinlichkeit der Hypothese der Forscherin betr√§gt also ca. 50%.\nOb das viel oder weniger ist, ist eine subjektive Frage. Das beste Vorgehen w√§re jetzt, die Hypothesen anderer Forschis dagegen zu legen. Dann w√ºrde man sehen, welche Hypothese am besten zu den Daten passt.\nBasteln wir zum Vergleich eine Bayes-Box mit Gitterwerte von von 60 bis 145:\n\nn &lt;- 100\n\nset.seed(42)\npostvert2 &lt;-\n  tibble(p_grid = seq(from = 60, to = 145, length.out = n),\n         prior  = 1) %&gt;% \n  mutate(likelihood = dnorm(x = p_grid, mean = 92.5, sd = 7.5)) %&gt;% \n  mutate(unstand_post = likelihood * prior,\n         post = unstand_post / sum(unstand_post))\n\nset.seed(42)\npostvert_stipros2 &lt;-\n  postvert2 %&gt;% \n  slice_sample(\n    n = 1e4,\n    weight_by = post,\n    replace = T) %&gt;% \n  select(p_grid)\n\nOb sich das Ergebnis √§ndert, jetzt, da wir einen breiteren Bereich an Gitterwerten untersuchzen?\nJetzt schauen wir wieder (mit Spannung), wie hoch die Wahrscheinlichkeit ist f√ºr Parameterwete (p_grid) innerhalb des Intervalls wie von der Forscherin vorgegeben.\n\npostvert_stipros2 %&gt;% \n  count(between(p_grid, left = 85, right = 95)) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n\n\nbetween(p_grid, left = 85, right = 95)\nn\nprop\n\n\n\n\nFALSE\n5455\n0.5455\n\n\nTRUE\n4545\n0.4545\n\n\n\n\n\n\nDie Ergebnisse sind leicht anders als oben, wo wir den engeren Wertebereich als m√∂gliche Werte angegeben haben.\nAber bedenken Sie: Wir behaupten in postvert2 ernsthaft, dass ein Mittelwert der Intelligenz in dieser Population mit gleicher Wascheinlichkeit 60 oder 145 sein k√∂nnte! Laut Wikipedia beginnt mit 130 die Hochbegabung und unter 85 f√§ngt die Lernbehinderung an. Dass diese Menschen super schlau oder mental behindert sind, erscheint uns gleich plausibel. Das ist eine sehr starke Apriori-Verteilung!\nViel konservativer w√§re zu sagen: ‚ÄúOkay, vermutlich sind diese Menschen so schlau wie alle anderen auch, vielleicht etwas mehr oder etwas weniger. Aber mit sehr hoher Wahrscheinlichkeit sind sie im Durchschnitt keine Einsteins oder nicht extrem mental eingeschr√§nkt.‚Äù\nWir brauchen also besser nicht gleichverteilte Priori-Verteilungen. Dazu an anderer Stelle mehr.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nbayes\nbayesbox\nnum"
  },
  {
    "objectID": "posts/affairs-dplyr/affairs-dplyr.html",
    "href": "posts/affairs-dplyr/affairs-dplyr.html",
    "title": "affairs-dplyr",
    "section": "",
    "text": "Aufgabe\nLaden Sie den Datensatz affairs:\n\naffairs_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv\"\n\n\naffairs &lt;- read.csv(affairs_path)\n\nLesen Sie das Data Dictionnary hier.\nWir definieren als ‚ÄúHalodrie‚Äù eine Person mit mindestens einer Aff√§re (laut Datensatz).\nBearbeiten Sie folgende Aufgaben:\n\nFiltern Sie mal nach Halodries!\nSortieren Sie (absteigend) nach Anzahl der Aff√§ren!\nW√§hlen Sie die Spalten zu Anzahl der Aff√§ren, ob es Kinder in der Ehe gibt und die Zufriedenheit mit der Ehe. Dann sortieren Sie dann nach Anzahl der Kinder und danach nach der Anzahl der Aff√§ren.\nBerechnen Sie die mittlere Anzahl der Aff√§ren!\nBerechnen Sie die mittlere Anzahl der Aff√§ren pro Geschlecht und aufgeteilt auf Partnerschaften mit bzw. ohne Kinder.\nGeben Sie f√ºr jede Person die h√∂here der zwei Zahlen von Religi√∂sit√§t und Ehezufriedenheit aus!\nBerechnen Sie jeweils das Heiratsalter!\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nAd 1.\n\naffairs %&gt;% \n  filter(affairs &gt; 0) %&gt;% \n  head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\naffairs\ngender\nage\nyearsmarried\nchildren\nreligiousness\neducation\noccupation\nrating\n\n\n\n\n6\n3\nmale\n27\n1.500\nno\n3\n18\n4\n4\n\n\n\n‚Ä¶.\n:::\n:::\nHinweis: head(10) begrenzt die Ausgabe auf 10 Zeilen, einfach um den Bildschirm nicht vollzum√ºllen.\nAd 2.\n\naffairs %&gt;% \n  arrange(-affairs) %&gt;% \n  head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\naffairs\ngender\nage\nyearsmarried\nchildren\nreligiousness\neducation\noccupation\nrating\n\n\n\n\n53\n12\nfemale\n32\n10.0\nyes\n3\n17\n5\n2\n\n\n122\n12\nmale\n37\n15.0\nyes\n4\n14\n5\n2\n\n\n174\n12\nfemale\n42\n15.0\nyes\n5\n9\n4\n1\n\n\n176\n12\nmale\n37\n10.0\nyes\n2\n20\n6\n2\n\n\n181\n12\nfemale\n32\n15.0\nyes\n3\n14\n1\n2\n\n\n252\n12\nmale\n27\n1.5\nyes\n3\n17\n5\n4\n\n\n\n‚Ä¶.\n:::\n:::\nAd 3.\n\naffairs %&gt;% \n  select(affairs, rating, children) %&gt;% \n  arrange(children, affairs) %&gt;% \n  head(10)\n\n\n\n\n\naffairs\nrating\nchildren\n\n\n\n\n0\n4\nno\n\n\n0\n4\nno\n\n\n0\n3\nno\n\n\n0\n5\nno\n\n\n0\n3\nno\n\n\n0\n5\nno\n\n\n\n‚Ä¶.\n:::\n:::\nAd 4.\n\naffairs %&gt;% \n  summarise(affairs_mean = mean(affairs)) %&gt;% \n  head(10)\n\n\n\n\n\naffairs_mean\n\n\n\n\n1.455907\n\n\n\n\n\n\nAd 5.\n\naffairs %&gt;% \n  group_by(gender, children) %&gt;% \n  summarise(affairs_mean = mean(affairs)) %&gt;% \n  head(10)\n\n\n\n\n\ngender\nchildren\naffairs_mean\n\n\n\n\nfemale\nno\n0.8383838\n\n\nfemale\nyes\n1.6851852\n\n\nmale\nno\n1.0138889\n\n\nmale\nyes\n1.6588785\n\n\n\n\n\n\nAd 6.\n\naffairs %&gt;% \n  rowwise() %&gt;% \n  summarise(max(c(religiousness, rating))) %&gt;% \n  head(10)\n\n\n\n\n\nmax(c(religiousness, rating))\n\n\n\n\n4\n\n\n4\n\n\n4\n\n\n5\n\n\n3\n\n\n5\n\n\n\n‚Ä¶.\n:::\n:::\nAd 7.\n\naffairs %&gt;% \n  mutate(heiratsalter = age - yearsmarried) %&gt;%\n  head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\naffairs\ngender\nage\nyearsmarried\nchildren\nreligiousness\neducation\noccupation\nrating\nheiratsalter\n\n\n\n\n4\n0\nmale\n37\n10.00\nno\n3\n18\n7\n4\n27.00\n\n\n5\n0\nfemale\n27\n4.00\nno\n4\n14\n6\n4\n23.00\n\n\n11\n0\nfemale\n32\n15.00\nyes\n1\n12\n1\n4\n17.00\n\n\n16\n0\nmale\n57\n15.00\nyes\n5\n18\n6\n5\n42.00\n\n\n23\n0\nmale\n22\n0.75\nno\n2\n17\n6\n3\n21.25\n\n\n29\n0\nfemale\n32\n1.50\nno\n2\n17\n5\n5\n30.50\n\n\n\n‚Ä¶.\n:::\n:::\n\nCategories:\n\ndatawrangling\neda\nstring"
  },
  {
    "objectID": "posts/regex03/regex03.html",
    "href": "posts/regex03/regex03.html",
    "title": "regex03",
    "section": "",
    "text": "Aufgabe\nGegeben sein ein String-Vektor, x. Dieser Vektor enth√§lt Vornamen mehrerer Personen. Extrahieren Sie den ersten Vornamen jeder Person.\n\nx &lt;-\n  c(\"Anna\",\n    \"Berta Brigitte\",\n    \"Carla-Klara\",\n    \"Dana Dora Diana\",\n    \"Emilia E\",\n    \"F-Franziska\",\n    \" Gabi\",\n    \"Jana die Erste\")\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nlibrary(stringr)  # Teil von tidyvserse\nlibrary(purrr)\n\nLiest man alle Zeichen vom Typ w aus, so sind Bindestriche nicht enthalten:\n\nstr_match(x, \"\\\\w+\")\n\n     [,1]    \n[1,] \"Anna\"  \n[2,] \"Berta\" \n[3,] \"Carla\" \n[4,] \"Dana\"  \n[5,] \"Emilia\"\n[6,] \"F\"     \n[7,] \"Gabi\"  \n[8,] \"Jana\"  \n\n\nDaher macht es vermutlich mehr Sinn, umgekehrt zu sagen, was man nicht will, n√§mlich Leerzeichen, also s:\n\nstr_match(x, \"[^\\\\s]+\")\n\n     [,1]         \n[1,] \"Anna\"       \n[2,] \"Berta\"      \n[3,] \"Carla-Klara\"\n[4,] \"Dana\"       \n[5,] \"Emilia\"     \n[6,] \"F-Franziska\"\n[7,] \"Gabi\"       \n[8,] \"Jana\"       \n\n\nDie Ausgabe kann man noch vereinfachen, in dem wir aus der resultieren Matrix (Tabelle) die ersten Spalte ausw√§hlen:\n\n\n[1] \"Anna\"        \"Berta\"       \"Carla-Klara\" \"Dana\"        \"Emilia\"     \n[6] \"F-Franziska\" \"Gabi\"        \"Jana\"       \n\n\n\nCategories:\n\nregex\ntextmining\nstring"
  },
  {
    "objectID": "posts/prob-vereinigung/index.html",
    "href": "posts/prob-vereinigung/index.html",
    "title": "prob-vereinigung",
    "section": "",
    "text": "1 Aufgabe\n¬†Folgende Wahrscheinlichkeiten zweier Ereignisse (A und B) seien gegeben:\nA: 70%\nB: 40%\nAB: 30% (gemeinsame Wahrscheinlichkeit)\nWie gro√ü ist die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt?\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nUm die Wahrscheinlichkeit zu berechnen, dass mindestens eines der beiden Ereignisse (A oder B) eintritt, verwenden wir die Formel f√ºr die Wahrscheinlichkeit der Vereinigung zweier Ereignisse:\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\\[\n\\begin{align*}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0,70 + 0,40 - 0,30 \\\\\n&= 1,10 - 0,30 \\\\\n&= 0,80\n\\end{align*}\n\\]\nDie Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt, betr√§gt 80%.\n\n\n3 Alternative\nGegeben:\n\npr_A &lt;- .6\npr_B &lt;- .3\npr_AB &lt;- .2\n\nGesucht:\n\\(Pr(A\\cup B)\\)\nL√∂sung:\n\npr_AorB &lt;- pr_A + pr_B - pr_AB\npr_AorB\n\n[1] 0.7"
  },
  {
    "objectID": "posts/wrangle1/wrangle1.html",
    "href": "posts/wrangle1/wrangle1.html",
    "title": "wrangle1",
    "section": "",
    "text": "Welche der folgenden Spalte ist nicht Teil des Datensatzes flights aus dem R-Paket nycflights13?\nAlternativ k√∂nnen Sie den Datensatz hier beziehen. Hilfe zum Datensatz (Codebook) finden Sie hier.\n\n\n\nyear\nmonth\n\nday\ndep_time\nsched_dep_time\nestimated_dep_time\narr_time\nsched_arr_time"
  },
  {
    "objectID": "posts/wrangle1/wrangle1.html#answerlist",
    "href": "posts/wrangle1/wrangle1.html#answerlist",
    "title": "wrangle1",
    "section": "",
    "text": "year\nmonth\n\nday\ndep_time\nsched_dep_time\nestimated_dep_time\narr_time\nsched_arr_time"
  },
  {
    "objectID": "posts/wrangle1/wrangle1.html#answerlist-1",
    "href": "posts/wrangle1/wrangle1.html#answerlist-1",
    "title": "wrangle1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\neda\ndatawrangling\ntidyverse\ndplyr\nschoice"
  },
  {
    "objectID": "posts/tidymodels-ames-02/tidymodels-ames-02.html",
    "href": "posts/tidymodels-ames-02/tidymodels-ames-02.html",
    "title": "tidymodels-ames-02",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price)) %&gt;% \n  select(Sale_Price, Gr_Liv_Area)\n\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\n\nset.seed(42)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nModell fitten:\n\nfit1 &lt;-\n  m1 %&gt;% \n  fit(Sale_Price ~ Gr_Liv_Area, data = ames)\n\n\nfit1 %&gt;% pluck(\"fit\") \n\nModellg√ºte im Train-Sample:\n\nfit1_performance &lt;-\n  fit1 %&gt;% \n  extract_fit_engine()  # identisch zu pluck(\"fit\")\n\nModellg√ºte im Train-Sample:\n\nfit1_performance %&gt;% summary()\n\nR-Quadrat via easystats:\n\nlibrary(easystats)\nfit1_performance %&gt;% r2()  # rmse()\n\n\ntidy(fit1_performance)  # √§hnlich zu parameters()\n\nVorhersagen im Test-Sample:\n\npreds &lt;- predict(fit1, new_data = ames_test)  # liefert TABELLE (tibble) zur√ºck\nhead(preds)\n\npreds ist ein Tibble, also m√ºssen wir noch die Spalte .pred. herausziehen, z.B. mit pluck(preds, \".pred\"):\n\npreds_vec &lt;- preds$.pred\n\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = pluck(preds, \".pred\"),  # pluck aus der Tabelle rausziehen\n         .pred = preds_vec)  # oder  mit dem Dollar-Operator\n\nhead(ames_test2)\n\nOder mit unnest:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = preds) %&gt;% \n  unnest(preds) # Listenspalte \"entschachteln\"\n\nhead(ames_test2)\n\nOder wir binden einfach die Spalte an den Tibble:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  bind_cols(preds = preds)  # nimmt Tabelle und bindet die Spalten dieser Tabelle an eine Tabelle\n\nhead(ames_test2)\n\nModellg√ºte im Test-Sample:\n\nrsq(ames_test2,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\nsol &lt;- 0.51679\n\nZur Interpretation von Log10-Werten\n\n5e5\n5*10^5 - 500000\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-ames-05/tidymodels-ames-05.html",
    "href": "posts/tidymodels-ames-05/tidymodels-ames-05.html",
    "title": "tidymodels-ames-05",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein knn-Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: log(Sale_Price) ~ ., data = ames_train.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nDenken Sie daran, die nominal skalierten Variablen in Dummy-Variablen umzurechnen.\nDenken Sie daran, dass kNN gleich skalierte Pr√§diktoren ben√∂tigt.\nNutzen Sie eine v=10,r=1 CV.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\ndata(ames)\n\nAV loggen:\n\names &lt;-\n  ames %&gt;% \n  mutate(Sale_Price = log(Sale_Price, base = 10))\n\nDatensatz reduzieren, um Zeit zu sparen bei der Berechnung:\n\names &lt;-\n  ames |&gt; \n  select(Sale_Price, where(is.numeric))\n\nDatensatz aufteilen:\n\nset.seed(42)\ndata_split &lt;- initial_split(ames, strata = \"Sale_Price\")\names_train &lt;- training(data_split)\names_test &lt;- testing(data_split)\n\nWorkflow:\n\names_rec &lt;-\n  recipe(Sale_Price ~ ., data = ames_train) %&gt;%\n  # step_log(Sale_Price, base = 10) %&gt;%   No!\n # step_other(Neighborhood, threshold = .1)  %&gt;%\n  step_dummy(all_nominal()) %&gt;%\n  step_zv(all_predictors()) \n\nknn_model2 &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()  # Wir tunen \"neighbors\"\n  ) \n\names_wflow2 &lt;-\n  workflow() %&gt;%\n  add_recipe(ames_rec) %&gt;%\n  add_model(knn_model2)\n\names_wflow2\n\nCV:\n\nset.seed(42)\names_folds &lt;- vfold_cv(ames_train, strata = \"Sale_Price\", v = 2)\names_folds\n\nTunen:\n\ntic()\names_grid_search &lt;-\n  tune_grid(\n    knn_model2,\n    ames_rec,\n    resamples = ames_folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = 2,  # 2 Tuningparameterwerte, hier nur zum Zeit sparen\n  )\ntoc()\names_grid_search\n\nModellg√ºte im Train-Samples √ºber die Tuningparameter hinweg:\n\nautoplot(ames_grid_search)\n\nFitte besten Modellkandidaten (Paket tune &gt;= V1.1.0 ben√∂tigt):\n\nfit1_final &lt;- fit_best(ames_grid_search)\n\nVorhersagen:\n\npreds &lt;-\n  predict(fit1_final, ames_test)\n\nModellg√ºte im Test-Sample:\n\nfit1_metrics &lt;-\n  preds %&gt;% \n  bind_cols(ames_test %&gt;% select(Sale_Price)) %&gt;% \n  rsq(truth = Sale_Price, estimate = .pred)\n\nfit1_metrics\n\nR-Quadrat:\n\nsol &lt;- fit1_metrics %&gt;% pull(.estimate)\nsol\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html",
    "href": "posts/saratoga-cor1/saratoga-cor1.html",
    "title": "saratoga-cor1",
    "section": "",
    "text": "Importieren Sie den Datensatz saratoga.\nGruppieren Sie den Datensatz in die Quartile f√ºr livingArea.\nBerechnen Sie dann den Zusammenhang zwischen price und bedrooms pro Quartil von livingArea.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nTipp: Die Funktion ntile aus {dplyr} teilt eine Variable var in Quartile auf, wenn Sie schreiben ntile(var, 4)."
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#setup",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#setup",
    "title": "saratoga-cor1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#gruppieren",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#gruppieren",
    "title": "saratoga-cor1",
    "section": "Gruppieren",
    "text": "Gruppieren\n\nd2 &lt;-\n  SaratogaHouses |&gt; \n  mutate(q = ntile(livingArea, 4)) |&gt; \n  group_by(q)"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#statistiken",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#statistiken",
    "title": "saratoga-cor1",
    "section": "Statistiken",
    "text": "Statistiken\n\nd2 |&gt; \n  summarise(korrelation = cor(bedrooms, price))\n\n\n\n\n\nq\nkorrelation\n\n\n\n\n1\n0.1262003\n\n\n2\n0.0780997\n\n\n3\n-0.1427274\n\n\n4\n-0.0478333"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#visualisierung",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#visualisierung",
    "title": "saratoga-cor1",
    "section": "Visualisierung",
    "text": "Visualisierung\n\nggscatter(d2, \n          x = \"bedrooms\",\n          y = \"price\",\n          facet.by = \"q\",\n          add = \"reg.line\")"
  },
  {
    "objectID": "posts/wskt-quiz05/wskt-quiz05.html",
    "href": "posts/wskt-quiz05/wskt-quiz05.html",
    "title": "wskt-quiz05",
    "section": "",
    "text": "Wasserplanet entdeckt (Er wurde auf den Namen ‚ÄúBath42‚Äù getauft)! Die ganze Oberfl√§che besteht aus Wasser. Jemand presentiert uns die Probe von diesem Planeten: Wasser! Allerdings ohne zu sagen, ob die Probe vom Wasserplaneten oder von der Erde (E) kommt. Hm.\nGilt die folgende Gleichung: \\(Pr(W|E) = Pr(E|W)\\)?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz05/wskt-quiz05.html#answerlist",
    "href": "posts/wskt-quiz05/wskt-quiz05.html#answerlist",
    "title": "wskt-quiz05",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz05/wskt-quiz05.html#answerlist-1",
    "href": "posts/wskt-quiz05/wskt-quiz05.html#answerlist-1",
    "title": "wskt-quiz05",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\ndistributions\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/sd-vergleich/sd-vergleich.html",
    "href": "posts/sd-vergleich/sd-vergleich.html",
    "title": "sd-vergleich",
    "section": "",
    "text": "Welches der folgenden Diagramm hat die gr√∂√üte Streuung, gemessen in Standardabweichung (sd, sigma)?\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nalle gleich\nkeine Antwort m√∂glich"
  },
  {
    "objectID": "posts/sd-vergleich/sd-vergleich.html#answerlist",
    "href": "posts/sd-vergleich/sd-vergleich.html#answerlist",
    "title": "sd-vergleich",
    "section": "",
    "text": "A\nB\nC\nalle gleich\nkeine Antwort m√∂glich"
  },
  {
    "objectID": "posts/sd-vergleich/sd-vergleich.html#answerlist-1",
    "href": "posts/sd-vergleich/sd-vergleich.html#answerlist-1",
    "title": "sd-vergleich",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Dieses Diagramm hat die kleinste Streuung\nFalsch.\nWahr.\nFalsch. Die Streuungen sind unterschiedlich.\nFalsch.\n\n\nCategories:\n\ndatawrangling\neda\ntidyverse\nvis\nvariability\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html",
    "href": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html",
    "title": "Verteilungen-Quiz-17",
    "section": "",
    "text": "Ei Forschi untersucht die mittlere K√∂rpergr√∂√üe eines bis dato unbekannten Urwaldvolks. Dabei findet sich aposteriori (also als Ergebnis der Untersuchung) \\(\\bar{x} \\sim N(160,5)\\) (in Zentimetern).\nDis Forschi res√ºmiert: ‚ÄúMit sehr hoher Wahrscheinlichkeit, also 95%, sind diese Menschen im Schnitt gr√∂√üer als 1 Meter 60 Zentimeter gro√ü‚Äù.\nIst diese Aussage korrekt (gegeben der Angaben)?\nHinweise:\n\nNutzen Sie Simulationsmethoden zur L√∂sung\nFixieren Sie die Zufallszahlen auf die Startzahl 42.\nZiehen Sie \\(10^5\\) Zufallszahlen aus der gegebenen Verteilung.\n\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist",
    "href": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist",
    "title": "Verteilungen-Quiz-17",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist-1",
    "title": "Verteilungen-Quiz-17",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/wskt-quiz02/wskt-quiz02.html",
    "href": "posts/wskt-quiz02/wskt-quiz02.html",
    "title": "wskt-quiz02",
    "section": "",
    "text": "Gilt \\(Pr(AB) = Pr(A\\cap B) = Pr(A) \\cdot Pr(B)\\), so sind die Ereignisse \\(A\\) und \\(B\\) abh√§ngig.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz02/wskt-quiz02.html#answerlist",
    "href": "posts/wskt-quiz02/wskt-quiz02.html#answerlist",
    "title": "wskt-quiz02",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz02/wskt-quiz02.html#answerlist-1",
    "href": "posts/wskt-quiz02/wskt-quiz02.html#answerlist-1",
    "title": "wskt-quiz02",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Ja, denn es ist die Definition f√ºr stochastische Unabh√§ngigkeit angegeben.\nWahr. Nein, denn es war nicht nach Abh√§ngigkeit, sondern nach Unabh√§ngigkeit gefragt.\n\n\nCategories:\n\nquiz\nprobability\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/pupil-size2/index.html",
    "href": "posts/pupil-size2/index.html",
    "title": "pupil-size2",
    "section": "",
    "text": "Aufgabe\nPupillendaten sind ein verbreiteter Analysegegenstand in Bereichen wie Psychologie, Marktforschung und Marketing.\nBetrachten wir dazu ein R-Paket (zum Vorverbarbeitung, preprocessing) und einen Datensatz der Uni M√ºnster.\n\nlibrary(tidyverse)\nlibrary(PupilPre)  # installieren, einmalig, nicht vergessen\ndata(\"Pupildat\")\nd &lt;-\n  Pupildat %&gt;% \n  select(size = RIGHT_PUPIL_SIZE,\n         time = TIMESTAMP) %&gt;% \n  mutate(size = size / 100) # in millimeter\n\nEin Forschungsteam untersucht den Datensatz und m√∂chte ein Modell zur Sch√§tzung der Pupillengr√∂√üe aufstellen.\nMit dem R-Paket eaystats kann man sich bequem typische Statistiken ausgeben lassen, was das Forschungsteam auch macht.\n\nlibrary(easystats)\nd %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nsize\n1.000562e+01\n5.107151e+00\n3.88\n1.04\n25.01\n1.2474408\n0.3199426\n45343\n1607\n\n\ntime\n2.990837e+06\n9.874538e+05\n1947161.00\n1443974.00\n4062110.00\n-0.4111739\n-1.6982498\n46950\n0\n\n\n\n\n\n\nDs Forschungsteam verzichtet hier auf eine Aufbereitung der Daten (was eigentlich n√∂tig w√§re, aber nicht Gegenstand dieser √úbung ist). Stattdessen konzentrieren wir uns auf die Posteriori-Verteilung zur Pupillengr√∂√üe.\nDas Forschungsteam ist interessiert an einem Modell zur Sch√§tzung der (Verteilung der) Pupillengr√∂√üe; die Posteriori-Verteilung bildet das ab.\nZuerst definiert das Forschungsteam ein Modell:\n\\[\\begin{aligned}\ns_i &\\sim \\mathcal{N}(\\mu, \\sigma)\\qquad \\text{| s wie size }\\\\\n\\mu &\\sim \\mathcal{N}(10, 5)\\\\\n\\sigma &\\sim \\mathcal{E}(.2)\n\\end{aligned}\\]\nF√ºr das Modell wird folgende Begr√ºndung vom Forschungsteam gegeben:\n\\(s_i\\): Pupillengr√∂√üen sind normalverteilt, da viele Gene additiv auf die Gr√∂√üe hin zusammenwirken\n\\(\\mu\\): Da wir nicht viel wissen √ºber die mittlere Pupillengr√∂√üe, entscheiden wir uns f√ºr Normalverteilung f√ºr diesen Parameter, da dies keine weiteren Annahmen (au√üer dass Mittelwert und Streuung endlich sind) hinzuf√ºgt. Ein Modell mit wenig Annahmen nennt man ‚Äúsparsam‚Äù oder konservativ. Es ist w√ºnschenswert, dass Modelle mit so wenig wie m√∂glich Annahmen auskommt (aber so vielen wie n√∂tig).\n\\(\\sigma\\): Die Streuung muss positiv sein, daher kommt keine Normalverteilung in Frage. Eine Exponentialverteilung ist eine von mehreren denkbaren Verteilungen.\nAber welche Werte von lambda kommen in Frage? Das Forschungsteam probiert etwas herum:\n\nqexp(p = .5, rate = 1)\n\n[1] 0.6931472\n\n\nMit \\(\\lambda = 1\\) liegt der Median der Streuung der Pupillengr√∂√üen (p = .5) bei ca. 0.7 mm. Dieser Wert erscheint etwas klein.\n\nqexp(p = .5, rate = 0.2)\n\n[1] 3.465736\n\n\nHm. Eine Streuung der Pupillengr√∂√üen von ca. 3.5mm (im Median) um den Mittelwert herum; das k√∂nnte passen.\nDie gro√üe Stichprobe wird den Priori-Wert vermutlich √ºberstimmen, √ºberlegt das Forschungsteam (und hat im Gro√üen und Ganzen Recht).\nDie Modelle wie stan_glm() tun sich leichter, wenn man nur die relevanten Daten, ohne fehlende Werte und schon sch√∂n fertig vorverarbeitet, zur Analyse in die Modellberechnung gibt:\n\nd3 &lt;-\n  d %&gt;% \n  select(size) %&gt;% \n  drop_na()\n\nDie Posteriori-Verteilung kann man mit dem Paket {rstanarm} d.h. mit der Funktion stan_glm() berechnen:\n\nlibrary(rstanarm)\nm_pupil &lt;- stan_glm(size ~ 1,\n                    data = d3,\n                    seed = 42,\n                    refresh = 0)\n\nDie Daten sind gro√ü, es kann ein paar Sekunden brauchen‚Ä¶\nHier ist eine n√ºtzliche Zusammenfassung der Post-Verteilung.\n\nparameters(m_pupil)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n10.00556\n0.95\n9.958776\n10.05205\n1\n1.000263\n1991.503\nnormal\n10.00562\n12.76788\n\n\n\n\n\n\nHier eine Visualisierung der Parameter:\n\nplot(parameters(m_pupil), show_intercept = TRUE)\n\n\n\n\n\n\n\n\nNat√ºrlich kann man auch die Post-Verteilung plotten (z.B: HDI):\n\nm_hdi &lt;- hdi(m_pupil, ci = c(0.5, 0.95))\n\nplot(m_hdi, show_intercept = TRUE)  # Im Default wird der Intercept nicht gezeigt\n\n\n\n\n\n\n\n\nHier zur Info die ersten paar Zeilen des Post-Verteilung:\n\n\n\n\n\n\n\n\n(Intercept)\nsigma\n\n\n\n\n10.04\n5.13\n\n\n10.00\n5.07\n\n\n9.99\n5.08\n\n\n10.00\n5.08\n\n\n9.99\n5.11\n\n\n\n\n\n\n\nDas Forschungsteam l√§sst sich folgende Statistiken zum Modell ausgeben:\n\neti(m_pupil)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n9.958776\n10.05205\nfixed\nconditional\n\n\n\n\n\n\n\nhdi(m_pupil)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n9.95854\n10.05182\nfixed\nconditional\n\n\n\n\n\n\n\neti(m_pupil, ci = .89)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.89\n9.966516\n10.04339\nfixed\nconditional\n\n\n\n\n\n\n\nprior_summary(m_pupil)\n\nPriors for model 'm_pupil' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 10, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 10, scale = 13)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.2)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nAufgabe Berichten Sie die Breite des 95% Equal Tails Intervalls.\nHinweise:\n\nVerwenden Sie die Defaults von rstanarm f√ºr Ihr Modell.\nBeachten Sie die √ºblichen Hinweise des Datenwerks\nFalls Sie Teile der Aufgabe nicht l√∂sen k√∂nnen, weil Ihnen der Stoff dazu fehlt: Einfach ignorieren üòÑ.\n\n\n\nL√∂sung\n         \nMan kann die Breite des 95% ETI aus der Ausgabe von eti() ablesen:\n\n\n[1] 0.09327839\n\n\neti() verwendet im Default eine 95%-Intervall.\n\nCategories:\n\nprobability\nbayes\nregression\nstring"
  },
  {
    "objectID": "posts/flights-delay/index.html",
    "href": "posts/flights-delay/index.html",
    "title": "flights-delay",
    "section": "",
    "text": "Wir untersuchen die Forschungsfrage Was sind Pr√§diktoren von Flugversp√§tungen. Dazu nutzen wir lineare Modelle als Modellierungsmethoden.\nDieser Post kn√ºpft an den Post zur explorativen Datenanalyse der Flugversp√§tungen an (es gibt auch hier, Teil 1 und hier, Teil 2 ein Video zu diesem EDA-Post)."
  },
  {
    "objectID": "posts/flights-delay/index.html#pakete-laden",
    "href": "posts/flights-delay/index.html#pakete-laden",
    "title": "flights-delay",
    "section": "2.1 Pakete laden",
    "text": "2.1 Pakete laden\nWirklich wichtig sind nur tidymodels und tidyverse. Die restlichen Pakete werden nur am Rande ben√∂tigt. Man sollte auch nur die Pakete laden, die man f√ºr die Analyse ben√∂tigt.\n\nlibrary(\"tidymodels\")  # Train- und Test-Sample aufteilen\nlibrary(\"tidyverse\")  # data wrangling\nlibrary(\"conflicted\")  # Name clashes finden\nlibrary(\"easystats\")  # stats made easy"
  },
  {
    "objectID": "posts/flights-delay/index.html#daten-laden-flights-2023",
    "href": "posts/flights-delay/index.html#daten-laden-flights-2023",
    "title": "flights-delay",
    "section": "2.2 Daten laden: Flights 2023",
    "text": "2.2 Daten laden: Flights 2023\nAus Gr√ºnden der Daten√∂konomie nutzen wir eine kleinere Version des Datensatz flights. Wir nutzen nicht mehr die Daten aus dem 2013, sondern die neueren Daten aus dem Jahr 2023.\n\nlibrary(nycflights23)\ndata(flights)\n\nset.seed(42)  # Reproduzierbarkeit\nflights &lt;- \n  flights |&gt; \n  sample_n(size = 3e4)\n\nAchtung: flights ist recht gro√ü; die Regressionsmodelle k√∂nnen leicht ein paar Hundert Megabyte gro√ü werden. Das bringt u.U. auch einen modernen Computer irgendwann ins Straucheln."
  },
  {
    "objectID": "posts/flights-delay/index.html#mehr-geht-immer",
    "href": "posts/flights-delay/index.html#mehr-geht-immer",
    "title": "flights-delay",
    "section": "23.1 Mehr geht immer‚Ä¶",
    "text": "23.1 Mehr geht immer‚Ä¶\nEin n√§chster Schritt k√∂nnte sein, sich folgende Punkte anzuschauen:\n\nInteraktionen\nPolynome\nVoraussetzungen\n\nEine Faustregel zu Interaktionen lautet: Wenn zwei Variablen jeweils einen starken Haupteffekt haben, lohnt es sich u.U., den Interaktionseffekt anzuschauen (vgl. Gelman & Hill, 2007, S. 69)."
  },
  {
    "objectID": "posts/flights-delay/index.html#tidymodels",
    "href": "posts/flights-delay/index.html#tidymodels",
    "title": "flights-delay",
    "section": "23.2 Tidymodels",
    "text": "23.2 Tidymodels\nDas st√§ndige Updaten des Test-Datensatzes nervt; mit tidymodels wird es komfortabler und man hat Zugang zu leistungsf√§higeren Prognosemodellen. Hier findet sich ein Einstieg und hier eine Fallstudie mit Tutorial."
  },
  {
    "objectID": "posts/samples-nyc2/index.html",
    "href": "posts/samples-nyc2/index.html",
    "title": "samples-nyc2",
    "section": "",
    "text": "Drei Studierende arbeiten f√ºr die New Yorker Flughafenbeh√∂rde als Werkstudenten. Fragt ihre Chefin eines Tages: ‚ÄúWelcher der drei New Yorker Flugh√§fen hat im Schnitt die h√∂chste Versp√§tung? Zieht mal eine kleine Stichprobe und gebt mir eine gute Antwort.‚Äù\nStudi A √ºberlegt: ‚ÄúHm, ich schaue mir mal die ersten 1000 Fl√ºge des Jahres und diesen Mittelwert nehme ich als Sch√§tzwert f√ºr die Versp√§tung des ganzen Jahres.‚Äù\nStudi B argumentiert so: ‚ÄúHm, ich nehme die ersten 100 Fl√ºge von jedem Monat, rechne davon den Mittelwert aus. Das ist dann mein Sch√§tzwert f√ºr die Versp√§tung des ganzen Jahres, pro Flughafen.‚Äù\nStudi C hingegen ist folgender Meinung: ‚ÄúIch ziehe mal eine Zufallsstichprobe, habe ich in der Statistik-Vorlesung gelernt. N=100 sollte gen√ºgen.‚Äù\nDie Chefin bezieht sich √ºbrigens auf das Jahr 2023.\nAufgabe: Welcher der drei Studis macht die beste Vorhersage? Rechnen Sie nach und begr√ºnden Sie Ihre Meinung!"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#setup",
    "href": "posts/samples-nyc2/index.html#setup",
    "title": "samples-nyc2",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(nycflights23)  # Dataset \"flights\"\ndata(\"flights\")\nlibrary(tidyverse)\n\nWie viele Fl√ºge gab es?\n\nnrow(flights)\n\n[1] 435352\n\n\nViele!\nWelche Variablen gibt es im Datensatz?\n\nglimpse(flights)\n\nRows: 435,352\nColumns: 19\n$ year           &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2‚Ä¶\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ dep_time       &lt;int&gt; 1, 18, 31, 33, 36, 503, 520, 524, 537, 547, 549, 551, 5‚Ä¶\n$ sched_dep_time &lt;int&gt; 2038, 2300, 2344, 2140, 2048, 500, 510, 530, 520, 545, ‚Ä¶\n$ dep_delay      &lt;dbl&gt; 203, 78, 47, 173, 228, 3, 10, -6, 17, 2, -10, -9, -7, -‚Ä¶\n$ arr_time       &lt;int&gt; 328, 228, 500, 238, 223, 808, 948, 645, 926, 845, 905, ‚Ä¶\n$ sched_arr_time &lt;int&gt; 3, 135, 426, 2352, 2252, 815, 949, 710, 818, 852, 901, ‚Ä¶\n$ arr_delay      &lt;dbl&gt; 205, 53, 34, 166, 211, -7, -1, -25, 68, -7, 4, -13, -14‚Ä¶\n$ carrier        &lt;chr&gt; \"UA\", \"DL\", \"B6\", \"B6\", \"UA\", \"AA\", \"B6\", \"AA\", \"UA\", \"‚Ä¶\n$ flight         &lt;int&gt; 628, 393, 371, 1053, 219, 499, 996, 981, 206, 225, 800,‚Ä¶\n$ tailnum        &lt;chr&gt; \"N25201\", \"N830DN\", \"N807JB\", \"N265JB\", \"N17730\", \"N925‚Ä¶\n$ origin         &lt;chr&gt; \"EWR\", \"JFK\", \"JFK\", \"JFK\", \"EWR\", \"EWR\", \"JFK\", \"EWR\",‚Ä¶\n$ dest           &lt;chr&gt; \"SMF\", \"ATL\", \"BQN\", \"CHS\", \"DTW\", \"MIA\", \"BQN\", \"ORD\",‚Ä¶\n$ air_time       &lt;dbl&gt; 367, 108, 190, 108, 80, 154, 192, 119, 258, 157, 164, 1‚Ä¶\n$ distance       &lt;dbl&gt; 2500, 760, 1576, 636, 488, 1085, 1576, 719, 1400, 1065,‚Ä¶\n$ hour           &lt;dbl&gt; 20, 23, 23, 21, 20, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6,‚Ä¶\n$ minute         &lt;dbl&gt; 38, 0, 44, 40, 48, 0, 10, 30, 20, 45, 59, 0, 59, 0, 0, ‚Ä¶\n$ time_hour      &lt;dttm&gt; 2023-01-01 20:00:00, 2023-01-01 23:00:00, 2023-01-01 2‚Ä¶\n\n\nNehmen wir dep_delay als Zielvariable. Die Chefin hat nicht genau gesagt, welche Variable sie meint. Da sieht man es mal wieder: Man muss Annahmen treffen. Ist aber auch sch√∂n, denn man kann selber entscheiden, was einem besser gef√§llt."
  },
  {
    "objectID": "posts/samples-nyc2/index.html#los-gehts",
    "href": "posts/samples-nyc2/index.html#los-gehts",
    "title": "samples-nyc2",
    "section": "2.2 Los geht‚Äôs",
    "text": "2.2 Los geht‚Äôs\n\n2.2.1 Studentin A\n\nestimate_A &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  slice(1:1000) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_A\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n26.1\n\n\nJFK\n19.9\n\n\nLGA\n9.4\n\n\n\n\n\n\n‚ÄúKlares (?) Ergebnis! EWR, also Newark, hat die gr√∂√üte Versp√§tung!‚Äù\n\n\n2.2.2 Student B\n\nestimate_B &lt;-\nflights |&gt; \n  select(dep_delay, origin, month) |&gt; \n  drop_na() |&gt; \n  group_by(month, origin) |&gt; \n  slice(1:100) |&gt; \n  summarise(dep_delay = mean(dep_delay)) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_B\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n8.47\n\n\nJFK\n9.74\n\n\nLGA\n0.76\n\n\n\n\n\n\n‚ÄúKnapp! EWR hat fast so viel Versp√§tung wie JFK.‚Äù\n\n\n2.2.3 Studentin C\n\nset.seed(73)\n\nestimate_C &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_C\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n2.0\n\n\nJFK\n14.3\n\n\nLGA\n8.8\n\n\n\n\n\n\n‚ÄúGlasklares (?) Ergebnis! JFK, also John-F-Kennedy, hat die gr√∂√üte Versp√§tung! Newark ist hingegen superp√ºnktlich!‚Äù"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#moment",
    "href": "posts/samples-nyc2/index.html#moment",
    "title": "samples-nyc2",
    "section": "2.3 Moment",
    "text": "2.3 Moment\nLeider entbrennt hier ein Streit. Vermutlich einige Eifersuchtsmomente hinter den Kulissen, aber wir wissen nichts Genaues.\nStudentin A: ‚ÄúSo ein Quatsch, C, du hast die Zufallszahl auf 73 festgelegt, warum gerade diese Zahl?! Bei einer anderen Zahl k√∂nnte ein ganz andere Stichprobe und damit ein ganz anderes Ergebnis herauskommen!‚Äù\nStudentin C: ‚ÄúIch habe k√ºrzlich gelernt, dass nicht 42, sondern 73 die beste Zahl ist. Also musste ich 73 nehmen!\nStudent B: ‚ÄúAber was k√§me heraus, wenn du 42 als Zufallszahl nehmen w√ºrdest, nur mal theoretisch?‚Äù\nStudentin C: ‚Äú√Ñh‚Ä¶‚Äù\n\nset.seed(42)\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n28.3\n\n\nJFK\n7.5\n\n\nLGA\n9.9\n\n\n\n\n\n\nStudentin C: ‚Äú√Ñh, also‚Ä¶ Das spielt doch gar keine Rolle, was rauskommt, denn bei jeder Zahl kann ja was anderes rauskommen.‚Äù\nA: ‚ÄúDu m√ºsstest also dein Vorgehen √§ndern‚Ä¶ Jede Zahl ausprobieren oder so.‚Äù\nC: ‚ÄúLiebe A, du mit deinen Fl√ºgen vom Jahresbeginn, das ist doch totaler Quatsch, an deiner Stelle w√§re ich lieber still.‚Äù\nA: ‚ÄúAber es kommt was Gutes raus mit meiner Methode!‚Äù\nB: ‚ÄúWoher willst du √ºberhaupt wissen, ob es was Gutes ist?‚Äù\nA: ‚ÄúWirst schon sehen!‚Äù\nC: ‚ÄúPuh, also gut, ich rechne noch mal. Ich zieh einfach ne Menge Stichproben, mit zuf√§lligen Seed-Nummern ‚Ä¶‚Äù\nA: ‚ÄúWhatever!‚Äù\nC: ‚ÄúMoment.., hier kommt Newark, EWR.‚Äù\n\nn_reps &lt;- 100  # Anzahl von Stichproben\nsample_size &lt;- 100  # Umfang jeder Stichprobe\n\newr_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"EWR\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\newr_viele_schaetzwerte\n\n[1] 15\n\n\nB: ‚ÄúWow, C, du bist halt schon die Statistik-Checkerin‚Ä¶‚Äù.\nA: ‚ÄúHey B, h√∂r gef√§lligst auf, dich bei A einzuschmeicheln!‚Äù\nB: ‚ÄúJedenfalls ist das Ergebnis von A ‚Ä¶ anders als unsere!‚Äù\nC: ‚ÄúHier noch mal mein Prinzip f√ºr die anderen Flugh√§fen. JFK:‚Äù\n\njfk_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"JFK\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\njfk_viele_schaetzwerte\n\n[1] 16\n\n\nC: ‚ÄúUnd LaGuardia:‚Äù\n\nlga_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"LGA\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\nlga_viele_schaetzwerte\n\n[1] 11\n\n\nC: ‚ÄúAlso, unterm Strich, LGA rules! LGA hat die geringste Versp√§tung im Schnitt, nach meiner Rechnung.‚Äù\n\nlga_viele_schaetzwerte\n\n[1] 11\n\newr_viele_schaetzwerte\n\n[1] 15\n\njfk_viele_schaetzwerte\n\n[1] 16"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#fazit",
    "href": "posts/samples-nyc2/index.html#fazit",
    "title": "samples-nyc2",
    "section": "2.4 Fazit?",
    "text": "2.4 Fazit?\nA: ‚ÄúOkay, meine Methode war ein bisschen zu einfach. Aber hat auch am wenigsten Arbeit gemacht. Das nennt man wirtschaftlich vorgehen, nur darum geht‚Äôs im Business. Also hab ich trotzdem gewonnen!‚Äù\nB: ‚ÄúNope, mein Vorgehen ist in Wirklichkeit das Beste. Ich hab von jedem Monat 100 Fl√ºge genommen, so hat sich alles super ausgeglichen, Jahreszeiten und so, glaub ich. Und es w√§re nicht so viel Aufwand wie die zich Tausend Stichproben, die C gezogen hat.‚Äù\nC: ‚ÄúKann ja alles sein, aber mein Vorgehen hat am meisten Spa√ü gemacht. √úbrigens B, wir k√∂nnten uns, also unsere beiden Ideen, doch zusammenlegn, kombinieren. Das m√ºsste ein super Ergebnis geben. Wollen wir zwei uns das mal zusammen anschauen, nur wir zwei?‚Äù"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#wahre-versp√§tung",
    "href": "posts/samples-nyc2/index.html#wahre-versp√§tung",
    "title": "samples-nyc2",
    "section": "3.1 Wahre Versp√§tung",
    "text": "3.1 Wahre Versp√§tung\nDie Chefin berechnet die wahre Versp√§tung √ºber alle Fl√ºge 2023 (in YNC) insgesamt (also in der Population der NYC-Fl√ºge von 2023):\n\nwahre_verspaetung &lt;- \n  flights |&gt; \n  select(origin, dep_delay) |&gt; \n  drop_na() |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nwahre_verspaetung\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n15\n\n\nJFK\n16\n\n\nLGA\n11\n\n\n\n\n\n\nChefin: ‚ÄúLaGuardia hat am wenigsten Versp√§tung. JFK am meisten, aber dicht gefolgt von EWR.‚Äù\nChefin: ‚ÄúJetzt schauen wir mal, wer pro Flughafen am genauesten gesch√§tzt hat.‚Äù\n\nmodellgueten &lt;-\n  wahre_verspaetung |&gt; \n  mutate(estimate_A = estimate_A$dep_delay,\n         estimate_B = estimate_B$dep_delay,\n         estimate_C = c(\n           ewr_viele_schaetzwerte,\n           jfk_viele_schaetzwerte,\n           lga_viele_schaetzwerte)\n  ) |&gt; \n  pivot_longer(contains(\"estimate\"), \n               names_to = \"student\", \n               values_to = \"estimate\") |&gt; \n  mutate(error_abs = abs(dep_delay - estimate)) \n\nChefin: ‚ÄúLaGuardia wurde ingesamt am genauesten gesch√§tzt, von allen drei Studenten. Aber Studentin A √ºbersch√§tzt die Versp√§tung massiv bei Newark und bei JFK.‚Äù\nChefin: ‚ÄúHier sind die Details.‚Äù\n\nmodellgueten |&gt; \n  ggplot(aes(y = estimate, x = origin)) +\n # geom_line() +\n  geom_col(data = wahre_verspaetung,\n    aes(x = origin, y = dep_delay)) +\n  geom_col(aes(fill = student),\n    position = \"dodge\",\n    alpha = .8) +\n  labs(caption = \"black bars show true delay\",\n       y = \"estimated delay\",\n       fill = \"students' estimates\")"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#and-the-winner-is",
    "href": "posts/samples-nyc2/index.html#and-the-winner-is",
    "title": "samples-nyc2",
    "section": "3.2 And the winner is ‚Ä¶",
    "text": "3.2 And the winner is ‚Ä¶\nChefin: ‚ÄúAnd the winner is ‚Ä¶‚Äù\n\nmodellgueten |&gt; \n  ggplot(aes(x = student, y = error_abs)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nmodellgueten_summ &lt;-\n  modellgueten |&gt; \n  group_by(student) |&gt; \n  summarise(error_abs = mean(error_abs)) |&gt; \n  arrange(error_abs)\n\nmodellgueten_summ\n\n\n\n\n\nstudent\nerror_abs\n\n\n\n\nestimate_C\n0.22\n\n\nestimate_A\n5.34\n\n\nestimate_B\n7.72\n\n\n\n\n\n\nChefin: ‚ÄúSieht so aus, als h√§tte B knapp gewonnen, vor C. A ist leider weit abgeschlagen.‚Äù\nA: ‚ÄúMensch, B, du bist hier der Datenhecht!‚Äù\nB: ‚ÄúIch glaub‚Äôs ja nicht, ich meine, ich hab‚Äôs immer gewusst!‚Äù\nC: ‚ÄúMoment, mein Vorgehen m√ºsste in der Theorie das Beste sein?!‚Äù"
  },
  {
    "objectID": "posts/iq02a/index.html",
    "href": "posts/iq02a/index.html",
    "title": "iq02a",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nWie gro√ü ist die Wahrscheinlichkeit, dass die n√§chste Person, die Sie treffen, mindestens zwei Streuungseinheiten √ºber dem Mittelwert liegt?\nHinweise:\n\nNutzen Sie keine Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nBeachten Sie die √ºbrigen Hinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nL√∂sung: Die gesuchte Wahrscheinlichkeit betr√§gt ca. 2% bzw. 0.02.\n\npnorm(130, mean = 100, sd = 15, lower.tail = FALSE)\n\n[1] 0.02275013\n\n\nJa, diese Aufgaben ist faktisch identische zur Aufgabe iq01a. Darum ging es: Sie sollen erkennen, dass ein IQ-Wert von 130 das gleiche ist wie MW+2sd.\n√úbrigens: ‚ÄúWie viele SD-Einheiten liegt der Wert von Beobachtung \\(i\\) √ºber dem Mittelwert, \\(\\bar{X}\\) ?‚Äù ist die Frage, die der z-Wert beantwortet:\n\\(z_i = \\frac{x_i - \\bar{X}}{sd(x)}\\)\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/bed-wskt2/bed-wskt2.html",
    "href": "posts/bed-wskt2/bed-wskt2.html",
    "title": "Bed-Wskt2",
    "section": "",
    "text": "Als Bildungsforscher(in) untersuchen Sie den Lernerfolg in einem Statistikkurs.\nEine Gruppe von Studierenden absolviert einen Statistikkurs. Ein Teil lernt gut mit (Ereignis \\(A\\)), ein Teil nicht (Ereignis \\(A^C\\)). Ein Teil besteht die Pr√ºfung (Ereignis \\(B\\)); ein Teil nicht (\\(B^C\\)).\n(Eselsbr√ºcke: Das Ereignis ‚ÄúA‚Äù steht f√ºr ‚ÄúAh, hat Aufgepasst.)\nHinweis: Das Gegenereignis zum Ereignis \\(A\\) wird oft das Komplement√§rereignis oder kurz Komplement von \\(A\\) genannt und mit \\(A^C\\) bezeichnet.\nWir ziehen zuf√§llig eine/n Studierende/n: Siehe da ‚Äì Die Person hat bestanden. Yeah!\nAufgabe: Gesucht ist die Wahrscheinlichkeit, dass diese Person gut mitgelernt hat, gegeben der Tatsache, dass dieser Person bestanden hat.\nDie Anteile der Gruppen (bzw. Wahrscheinlichkeit des Ereignisses) lassen sich unten stehender Tabelle entnehmen.\nd %&gt;% \n  select(row_ids, B, Bneg)  %&gt;% \n  filter(row_ids != \"row_sum\") %&gt;% \n  mutate(across(c(B, Bneg), \\(x) sprintf(x, fmt = \"%.2f\"))) %&gt;% \n  gt()\n\n\n\n\n\n\nrow_ids\nB\nBneg\n\n\n\n\nA\n0.38\n0.30\n\n\nAneg\n0.22\n0.10\n\n\n\n\n\nHinweise:\n\nRunden Sie auf 2 Dezimalstellen.\nGeben Sie Anteile stets in der Form 0.42 an (mit f√ºhrender Null und Dezimalzeichen).\n‚ÄúAneg‚Äù bezieht sich auf das Komplement√§rereignis zu A (‚ÄúA negativ‚Äù)\nBer√ºcksichtigen Sie die √ºblichen Hinweise des Datenwerks.\n\n\nitems &lt;-\n  c(\"Zeichnen Sie (per Hand) ein Baumdiagramm, um die gemeinsamen Wahrscheinlichkeiten darzustellen. Weiterhin sollen die Randwahrscheinlichkeiten f√ºr $A$ dargestellt sein.\",\n    \n    \"Zeichnen Sie (per Hand) ein Baumdiagramm, um diesen Sachverhalt darzustellen.\",\n\n    \"Geben Sie die Wahrscheinlichkeit des gesuchten Ereignisses an.\"\n  )\n\n\n\n\nZeichnen Sie (per Hand) ein Baumdiagramm, um die gemeinsamen Wahrscheinlichkeiten darzustellen. Weiterhin sollen die Randwahrscheinlichkeiten f√ºr \\(A\\) dargestellt sein.\nZeichnen Sie (per Hand) ein Baumdiagramm, um diesen Sachverhalt darzustellen.\nGeben Sie die Wahrscheinlichkeit des gesuchten Ereignisses an."
  },
  {
    "objectID": "posts/bed-wskt2/bed-wskt2.html#answerlist",
    "href": "posts/bed-wskt2/bed-wskt2.html#answerlist",
    "title": "Bed-Wskt2",
    "section": "",
    "text": "Zeichnen Sie (per Hand) ein Baumdiagramm, um die gemeinsamen Wahrscheinlichkeiten darzustellen. Weiterhin sollen die Randwahrscheinlichkeiten f√ºr \\(A\\) dargestellt sein.\nZeichnen Sie (per Hand) ein Baumdiagramm, um diesen Sachverhalt darzustellen.\nGeben Sie die Wahrscheinlichkeit des gesuchten Ereignisses an."
  },
  {
    "objectID": "posts/nasa07/index.html",
    "href": "posts/nasa07/index.html",
    "title": "nasa07",
    "section": "",
    "text": "Aufgabe\nViele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read_csv(data_path, skip = 1)\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgabe\nBerechnen Sie die folgende Statistiken pro Dekade:\n\nMittelwert der Temperatur im Januar\nSD der Temperatur im Januar\n\nHinweise:\n\nSie m√ºssen zuerst die Dekade als neue Spalte berechnen.\n\n         \n\n\nL√∂sung\nDekade (Jahrzehnt) berechnen:\n\nd &lt;-\n  d %&gt;% \n  mutate(decade = round(Year/10))\n\nDas ist ein m√∂glicher Weg, um aus einer Jahreszahl die Dekade zu berechnen.\nStatistiken pro Dekade:\n\nd_summarized &lt;- \n  d %&gt;% \n  group_by(decade) %&gt;% \n  summarise(temp_mean = mean(Jan),\n            temp_sd = sd(Jan))\n\nd_summarized\n\n\n\n\n\n\n\n\n\ndecade\ntemp_mean\ntemp_sd\n\n\n\n\n188\n‚àí0.20\n0.24\n\n\n189\n‚àí0.44\n0.22\n\n\n190\n‚àí0.27\n0.16\n\n\n191\n‚àí0.40\n0.22\n\n\n192\n‚àí0.29\n0.15\n\n\n193\n‚àí0.14\n0.22\n\n\n194\n0.02\n0.21\n\n\n195\n‚àí0.05\n0.19\n\n\n196\n0.03\n0.15\n\n\n197\n‚àí0.07\n0.17\n\n\n198\n0.21\n0.19\n\n\n199\n0.35\n0.13\n\n\n200\n0.51\n0.19\n\n\n201\n0.63\n0.21\n\n\n202\n1.02\n0.19\n\n\n\n\n\n\n\nZur Veranschaulichung visualisieren wir die Ergebnisse:\n\nd_summarized %&gt;% \n  pivot_longer(-decade) %&gt;% \n  ggplot(aes(x = decade, y = value)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ name)\n\n\n\n\n\n\n\n\nAlternativ k√∂nnen Sie zum Visualisieren der Daten z.B. das Paket DataExplorer oder das Paket ggpubr nutzen:\n\nlibrary(DataExplorer)\nd_summarized |&gt; \n  select(decade, temp_mean) |&gt; \n  plot_scatterplot(by = \"temp_mean\")\n\nd_summarized |&gt; \n  select(decade, temp_sd) |&gt; \n  plot_scatterplot(by = \"temp_sd\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggpubr)\nggscatter(d_summarized, x = \"decade\", y = \"temp_mean\", add = \"reg.line\")\nggscatter(d_summarized, x = \"decade\", y = \"temp_sd\", add = \"reg.line\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFalls Sie Teile der R-Syntax nicht kennen: Machen Sie sich nichts daraus. üòÑ\n\nCategories:\n\ndata\neda\nlagema√üe\nvariability\nstring"
  },
  {
    "objectID": "posts/korr02/korr02.html",
    "href": "posts/korr02/korr02.html",
    "title": "korr02",
    "section": "",
    "text": "Aufgabe\nWelcher Korrelationswert (Pearson) beschreibt die Korrelation in den Daten am besten?\n\n.9\n.4\n0\n-0.4\n-0.9\n\n\n\n\n\n\n\n\n\n\n         \n\n\nL√∂sung\nDie Korrelation in der zugeh√∂rigen (bivariaten) Population betr√§gt 0.4.\nIn der Stichprobe kann der zugeh√∂rige Wert (etwas abweichen).\nDas ist genauso, wie wenn man sagt, dass der ‚Äúmittlere deutsche Mann‚Äù 1,80m gro√ü sei, aber wenn Sie eine Stichprobe ziehen, muss der Mittelwert ja auch nicht (notwendigerweise) exakt bei 1,80m liegen.\n\n\n\n\n\n\n\n\n\n\nCategories:\n\ndyn\neda\nassociation\nnum"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html",
    "title": "ttest-skalenniveau",
    "section": "",
    "text": "Der t-Test ist ein inferenzstatistisches Verfahren des Frequentismus. Der t-Test √ºberpr√ºft die Nullhypothese, dass die Mittelwerte zweier Gruppen gleich sind.\nWelches Skalenniveau passt zu diesem Verfahren?\nHinweisse:\n\nDie folgende Abbildung gibt Tipps. Sie zeigt die Skaleniveaus.\nInformationen, die zur L√∂sung einer Aufgabe nicht n√∂tig sind, sollte man ignorieren.\n\n\ndata(penguins, package = \"palmerpenguins\")\n\npenguins |&gt; \n  drop_na(sex) |&gt; \n  ggplot(aes(x = sex, y = body_mass_g)) +\n  geom_jitter(width=.1, alpha = .5) +\n  stat_summary(color = \"red\", size = 1)\n\n\n\n\n\n\n\n\n\n\n\nUV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist",
    "title": "ttest-skalenniveau",
    "section": "",
    "text": "UV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist-1",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist-1",
    "title": "ttest-skalenniveau",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nttest\nregression\nvariable-levels"
  },
  {
    "objectID": "posts/wrangle7/wrangle7.html",
    "href": "posts/wrangle7/wrangle7.html",
    "title": "wrangle7",
    "section": "",
    "text": "Welche Aussage zur Funktion filter() aus dem R-Paket dplyr ist richtig?\n\n\n\nfilter() filtert (beh√§lt) Zeilen, f√ºr die eine Pr√ºfung TRUE ergibt\nfilter() filtert (beh√§lt)Zeilen, f√ºr die eine Pr√ºfung FALSE ergibt\nfilter() filtert (beh√§lt) Zeilen, f√ºr die eine Pr√ºfung TRUE oder NA ergibt\nM√∂chte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, x == NA).\nM√∂chte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, is.na(x))."
  },
  {
    "objectID": "posts/wrangle7/wrangle7.html#answerlist",
    "href": "posts/wrangle7/wrangle7.html#answerlist",
    "title": "wrangle7",
    "section": "",
    "text": "filter() filtert (beh√§lt) Zeilen, f√ºr die eine Pr√ºfung TRUE ergibt\nfilter() filtert (beh√§lt)Zeilen, f√ºr die eine Pr√ºfung FALSE ergibt\nfilter() filtert (beh√§lt) Zeilen, f√ºr die eine Pr√ºfung TRUE oder NA ergibt\nM√∂chte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, x == NA).\nM√∂chte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, is.na(x))."
  },
  {
    "objectID": "posts/wrangle7/wrangle7.html#answerlist-1",
    "href": "posts/wrangle7/wrangle7.html#answerlist-1",
    "title": "wrangle7",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\neda\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/adjustieren1a/adjustieren1a.html",
    "href": "posts/adjustieren1a/adjustieren1a.html",
    "title": "adjustieren1a",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Pr√§diktor hp, um den Achsenabschnitt besser interpretieren zu k√∂nnen.\n\nlibrary(tidyverse)\nlibrary(easystats)\ndata(mtcars)\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(hp_z = hp - mean(hp))\n\n\nlm1 &lt;- lm(mpg ~ hp_z, data = mtcars)\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n20.0906250\n0.6828817\n0.95\n18.6959945\n21.4852555\n29.420359\n30\n0e+00\n\n\nhp_z\n-0.0682283\n0.0101193\n0.95\n-0.0888947\n-0.0475619\n-6.742388\n30\n2e-07\n\n\n\n\n\n\nJetzt k√∂nnen wir aus dem Achsenabschnitt (Intercept) herauslesen, dass ein Auto mit hp_z = 0 - also mit mittlerer PS-Zahl - vielleicht gut 20 Meilen weit mit einer Gallone Sprit kommt.\nZur Verdeutlichung ein Diagramm zum Modell:\n\nestimate_relation(lm1) |&gt; plot()\n\n\n\n\n\n\n\n\nAdjustieren Sie im Modell die PS-Zahl um die Art des Schaltgetriebes (am), so dass das neue Modell den statistischen Effekt (nicht notwendig auch kausal) der PS-Zahl bereinigt bzw. unabh√§ngig von der Art des Schaltgetriebes widerspiegelt!\nGeben Sie den Punktsch√§tzer f√ºr den Effekt von am in diesem Modell an!\nHinweise:\n\nam=0 ist ein Auto mit Automatikgetriebe.\nWir gehen davon aus, dass der Regressionseffekt gleich stark ist auf allen (beiden) Stufen von am. M.a.W.: Es liegt kein Interaktionseffekt vor.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\nNutzen Sie lm, um das Modell zu berechnen.\n\n         \n\n\nL√∂sung\n\nlm2 &lt;- lm(mpg ~ hp_z + am, data = mtcars)\nparameters(lm2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n17.9468091\n0.6758845\n0.95\n16.5644701\n19.329148\n26.553072\n29\n0.00e+00\n\n\nhp_z\n-0.0588878\n0.0078567\n0.95\n-0.0749567\n-0.042819\n-7.495191\n29\n0.00e+00\n\n\nam\n5.2770853\n1.0795406\n0.95\n3.0691769\n7.484994\n4.888269\n29\n3.46e-05\n\n\n\n\n\n\nDie Spalte Coefficient gibt den mittleren gesch√§tzten Wert f√ºr den jeweiligen Koeffizienten an, also den Sch√§tzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt f√ºr Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als f√ºr Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\n\nestimate_relation(lm2) |&gt; plot()\n\n\n\n\n\n\n\n\nam wird als numerische Variable erkannt. Das ist nicht sinnvoll, da am eher eine kategoriale Variable ist.\nDas k√∂nnen wir so √§ndern:\n\nmtcars &lt;- \n  mtcars |&gt; \n  mutate(am = factor(am))\n\n\nlm3 &lt;- lm(mpg ~ hp_z + am, data = mtcars)\nparameters(lm3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n17.9468091\n0.6758845\n0.95\n16.5644701\n19.329148\n26.553072\n29\n0.00e+00\n\n\nhp_z\n-0.0588878\n0.0078567\n0.95\n-0.0749567\n-0.042819\n-7.495191\n29\n0.00e+00\n\n\nam1\n5.2770853\n1.0795406\n0.95\n3.0691769\n7.484994\n4.888269\n29\n3.46e-05\n\n\n\n\n\n\nDie Koeffizienten bleiben gleich.\nL√∂sung: 5.28.\nAber im Diagramm wird am jetzt als Faktor-Variable erkannt, was Sinn macht:\n\nestimate_relation(lm3) |&gt; plot()\n\n\n\n\n\n\n\n\nMan k√∂nnte hier noch einen Interaktionseffekt erg√§nzen.\n\nCategories:\n\nregression\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html",
    "href": "posts/within-design-analysis1/within-design-analysis1.html",
    "title": "within-design-analysis1",
    "section": "",
    "text": "Analysieren Sie die Ver√§nderung in einem l√§ngsschnittlichen Experiment (Within-Design).\nIm Zuge des Experiments durchliefen alle \\(n\\) Versuchspersonen 3 Bedingungen. Entsprechend liegen f√ºr jede Versuchsperson 3 Messungen vor (y1, y2, y3). Anders gesagt gab es drei Messzeitpunkte (t1, t2, t3), zu denen die abh√§ngige Variable (y) jeweils gemessen wurde Die Messung bestand bei jeder Bedingung aus 10 Items, wobei die Wahrscheinlichkeit, ein Item zu l√∂sen zwischen den Bedingungen unterschiedlich war.\nPr√ºfen Sie die folgende Hypothesen:\n\n\\(y_{t2} - y_{t1} &gt; 0\\)\n\\(y_{t3} - y_{t2} &gt; 0\\)\n\nGehen Sie von folgenden (hier einfach simulierten) Daten aus:\n\nn &lt;- 40  # Anzahl Versuchspersonen\nn_items &lt;- 10  # Anzahl Items pro Messung von y\nprob &lt;- c(.5, .7, .9)  # L√∂sungswahrscheinlichkeit pro Messzeitpunkt (t1, t2, t3)\n\n\nlibrary(tidyverse)\nset.seed(42)\nd &lt;-\n  tibble(id = 1:n,\n         y1 = rbinom(n = n, size = n_items, prob = prob[1]),\n         y2 = rbinom(n = n, size = n_items, prob = prob[2]),\n         y3 = rbinom(n = n, size = n_items, prob = prob[3]),\n         g = c(rep(times = n/2, x = \"A\"), rep(times = n/2, x = \"B\"))\n         )\nhead(d)\n\n\n\n\n\nid\ny1\ny2\ny3\ng\n\n\n\n\n1\n7\n8\n9\nA\n\n\n2\n7\n7\n10\nA\n\n\n3\n4\n9\n9\nA\n\n\n4\n7\n4\n9\nA\n\n\n5\n6\n7\n8\nA\n\n\n6\n5\n4\n9\nA\n\n\n\n\n\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#pakete-starten",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#pakete-starten",
    "title": "within-design-analysis1",
    "section": "Pakete starten",
    "text": "Pakete starten\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-aufbereiten",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-aufbereiten",
    "title": "within-design-analysis1",
    "section": "Daten aufbereiten",
    "text": "Daten aufbereiten\nUm die Daten (besser) analysieren zu k√∂nnen, formen wir sie ins ‚Äúlange Format‚Äù um.\n\nd_long &lt;-\n  d %&gt;% \n  pivot_longer(cols = c(y1, y2, y3), names_to = \"time\", values_to = \"y\")"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen",
    "title": "within-design-analysis1",
    "section": "Daten zusammenfassen",
    "text": "Daten zusammenfassen\n\nd_long %&gt;% \n  group_by(time) %&gt;% \n  summarise(y_mean = mean(y),\n            y_sd = sd(y)) %&gt;% \n  mutate(delta = y_mean - lag(y_mean))\n\n\n\n\n\ntime\ny_mean\ny_sd\ndelta\n\n\n\n\ny1\n5.450\n1.7386998\nNA\n\n\ny2\n7.050\n1.5516740\n1.600\n\n\ny3\n8.975\n0.8911963\n1.925"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-visualisieren",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-visualisieren",
    "title": "within-design-analysis1",
    "section": "Daten visualisieren",
    "text": "Daten visualisieren\n\nd_long %&gt;% \n  ggplot(aes(x = time, y = y)) +\n  geom_jitter(width = .1) +\n  stat_summary(fun.y = mean, geom = \"point\", color = \"red\", size = 3) +\n  stat_summary(fun.y = mean, geom = \"line\", color = \"red\", linewidth = 1, group = 1) \n\n\n\n\n\n\n\n\nMan sieht, dass der Wert von Y steigt von t1 zu t2 und genauso von t2 zu t3."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-transformieren",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-transformieren",
    "title": "within-design-analysis1",
    "section": "Daten transformieren",
    "text": "Daten transformieren\nMan kann auch die Ver√§nderung (das ‚Äúdelta‚Äù) zwischen den Messzeitpunkten berechnen, um dann zu pr√ºfen, ob dieses delta dann positiv ist.\n\nd2 &lt;-\n  d %&gt;% \n  mutate(t2mt1 = y2 - y1,  # t2 *m*inus t1\n         t3mt2 = y3 - y2,  # t3 minus t2\n         t3mt1 = y3 - y1)  # t3 mind t1, die Gesamtver√§nderung von \"Anfang\" zu \"Ende\"\n\n\nd2_long &lt;- \n  d2 %&gt;% \n  pivot_longer(cols = c(t2mt1, t3mt2, t3mt1), names_to = \"time\", values_to = \"delta\")"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen-1",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen-1",
    "title": "within-design-analysis1",
    "section": "Daten zusammenfassen",
    "text": "Daten zusammenfassen\n\nd2_long %&gt;% \n  group_by(time) %&gt;% \n  summarise(delta_mean = mean(delta),\n            delta_sd = sd(delta)) %&gt;% \n  mutate(delta2 = delta_mean - lag(delta_mean))\n\n\n\n\n\ntime\ndelta_mean\ndelta_sd\ndelta2\n\n\n\n\nt2mt1\n1.600\n2.629224\nNA\n\n\nt3mt1\n3.525\n1.782932\n1.925\n\n\nt3mt2\n1.925\n1.966221\n-1.600\n\n\n\n\n\n\nWie man sieht, ist das Delta t2mt1 positiv, im Mittelwert steigt also y. Gleiches gilt f√ºr t3mt2 und t3mt1.\n\nd2_long %&gt;% \n  filter(time != \"t3mt1\") %&gt;% \n  ggplot(aes(x = time, y = delta)) +\n  geom_jitter(width = .1) +\n  stat_summary(fun.y = mean, geom = \"point\", color = \"red\", size = 3) +\n  stat_summary(fun.y = mean, geom = \"line\", color = \"red\", linewidth = 1, group = 1) \n\n\n\n\n\n\n\n\nDie Ver√§nderungen von t1 zu t2 (t2mt1) sind √§hnlich zu denen von t2 zu t3 (t3mt2)."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#modell-t2mt1",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#modell-t2mt1",
    "title": "within-design-analysis1",
    "section": "Modell t2mt1",
    "text": "Modell t2mt1\nDas entsprechende Regressionsmodell f√ºr t2mt2 liefert einfach den Mittelwert des Deltas.\n\nm1_t2mt1 &lt;- lm(t2mt1 ~ 1, data = d2)\ncoef(m1_t2mt1)\n\n(Intercept) \n        1.6 \n\n\nEin Bayes-Modell hat den Vorteil, dass es uns einfach zu interpretierende Inferenzstatistik gibt.\n\nm1_bayes &lt;- stan_glm(t2mt1 ~ 1, data = d2, refresh = 0)\ncoef(m1_bayes)\n\n(Intercept) \n   1.602565 \n\n\n\nparameters(m1_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n1.602565\n0.95\n0.7677561\n2.471188\n0.9995\n1.000112\n2448.837\nnormal\n1.6\n6.573061\n\n\n\n\n\n\nMit einer Wahrscheinlichkeit von 100% ist das Delta positiv (laut m1_bayes). Das kann man aus dem Koeffizienten pd ablesen (probability of direction)."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#m_t3mt2",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#m_t3mt2",
    "title": "within-design-analysis1",
    "section": "m_t3mt2",
    "text": "m_t3mt2\n\nm_t3mt2_bayes &lt;- stan_glm(t3mt2 ~ 1, data = d2, refresh = 0)\nparameters(m_t3mt2_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n1.928811\n0.95\n1.32115\n2.530593\n1\n1.000633\n2752.526\nnormal\n1.925\n4.915553\n\n\n\n\n\n\nAuch hier ist das Modell sehr meinungsstark: Mit einer Wahrscheinlichkeit von 100% ist der Koeffizient (Ver√§nderung von t2 zu t3) positiv.\n\nCategories:\n\nregression\nwithin-design\nresearchdesign\nfopro\nstring"
  },
  {
    "objectID": "posts/tidymodels-ames-03/tidymodels-ames-03.html",
    "href": "posts/tidymodels-ames-03/tidymodels-ames-03.html",
    "title": "tidymodels-ames-03",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nR√ºcktransformieren Sie die Log-Werte in ‚ÄúRoh-Dollar‚Äù.\nGeben Sie den mittleren Vorhersagewert an als L√∂sung.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price)) %&gt;% \n  select(Sale_Price, Gr_Liv_Area)\n\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\n\nset.seed(42)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nModell fitten:\n\nfit1 &lt;-\n  m1 %&gt;% \n  fit(Sale_Price ~ Gr_Liv_Area, data = ames)\n\n\nfit1 %&gt;% pluck(\"fit\") \n\nModellg√ºte im Train-Sample:\n\nfit1_performance &lt;-\n  fit1 %&gt;% \n  extract_fit_engine()  # identisch zu pluck(\"fit\")\n\nModellg√ºte im Train-Sample:\n\nfit1_performance %&gt;% summary()\n\nR-Quadrat via easystats:\n\nlibrary(easystats)\nfit1_performance %&gt;% r2()  # rmse()\n\n\ntidy(fit1_performance)  # √§hnlich zu parameters()\n\nVorhersagen im Test-Sample:\n\npreds &lt;- predict(fit1, new_data = ames_test)  # liefert TABELLE (tibble) zur√ºck\nhead(preds)\n\npreds ist ein Tibble, also m√ºssen wir noch die Spalte .pred. herausziehen, z.B. mit pluck(preds, \".pred\"):\n\npreds_vec &lt;- preds$.pred\n\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = pluck(preds, \".pred\"),  # pluck aus der Tabelle rausziehen\n         .pred = preds_vec)  # oder  mit dem Dollar-Operator\n\nhead(ames_test2)\n\nOder mit unnest:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = preds) %&gt;% \n  unnest(preds) # Listenspalte \"entschachteln\"\n\nhead(ames_test2)\n\nOder wir binden einfach die Spalte an den Tibble:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  bind_cols(preds = preds)  # nimmt Tabelle und bindet die Spalten dieser Tabelle an eine Tabelle\n\nhead(ames_test2)\n\nModellg√ºte im Test-Sample:\n\nrsq(ames_test2,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\nsol &lt;- 0.51679\n\nZur Interpretation von Log10-Werten\n\n5e5\n5*10^5 - 500000\n\nR√ºcktransformation (ohne Bias-Korrektur):\n\names_test2 &lt;-\n  ames_test2 %&gt;% \n  mutate(pred_raw = 10^(.pred))\n\nMittelwert der Vorhersagen:\n\nsol &lt;- mean(ames_test2$pred_raw)\nsol\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/penguins-stan-05a/index.html",
    "href": "posts/penguins-stan-05a/index.html",
    "title": "penguins-stan-05a",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nAufgabe: Wie breit ist das 95%-ETI, wenn Sie nur die Spezies Adelie untersuchen?\nHinweise:\n\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nWeitere Hinweise\nGehen Sie von einer Normalverteilung aus.\n\nNutzen Sie die folgende Analyse als Grundlage Ihrer Antwort.\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\npenguins &lt;- data_read(d_path)\npenguins_adelie &lt;- \n  penguins %&gt;% \n  filter(species == \"Adelie\")\n\nglimpse(penguins)\n\nRows: 344\nColumns: 9\n$ rownames          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1‚Ä¶\n$ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"A‚Ä¶\n$ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", ‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;chr&gt; \"male\", \"female\", \"female\", \"\", \"female\", \"male\", \"f‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber ‚Äì was Golems betrifft ‚Äì ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins_adelie, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1, ci = .95, ci_method = \"eti\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n22.53919\n0.95\n-879.18205\n913.4400\n0.5185\n1.000466\n3934.802\nnormal\n3700.662\n1146.4153\n\n\nbill_length_mm\n94.71685\n0.95\n71.89291\n118.0511\n1.0000\n1.000492\n3910.510\nnormal\n0.000\n430.4322\n\n\n\n\n\n\n         \n\n\nL√∂sung\nDie L√∂sung lautet also, wie in der Ausgabe zu den Parametern ersichtlich, 46.16."
  },
  {
    "objectID": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html",
    "href": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html",
    "title": "Wertzuweisen_mc",
    "section": "",
    "text": "Welche der folgenden Syntax-Varianten ist/sind formal (‚Äúsyntaktisch‚Äù) korrekt?\n\n\n\nloesung &lt;-42\nloesung &lt; - 42\nloesung-&gt;42\nloesung==42\nloesung&lt;-\"42\""
  },
  {
    "objectID": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist",
    "href": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist",
    "title": "Wertzuweisen_mc",
    "section": "",
    "text": "loesung &lt;-42\nloesung &lt; - 42\nloesung-&gt;42\nloesung==42\nloesung&lt;-\"42\""
  },
  {
    "objectID": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist-1",
    "href": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist-1",
    "title": "Wertzuweisen_mc",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nR\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/rethink3m1/rethink3m1.html",
    "href": "posts/rethink3m1/rethink3m1.html",
    "title": "rethink3m1",
    "section": "",
    "text": "Aufgabe\nNehmen wir an, wir haben 8 (Wasser-)‚ÄúTreffer‚Äù (\\(W=8\\)) bei 15 W√ºrfen (\\(N=15\\)) erhalten (wieder im Globusversuch). Gehen Sie wieder von einer ‚Äúflachen‚Äù, also gleichverteilten, Priori-Verteilung aus.\nüëâ Aufgabe: Berechnen Sie die Posteriori-Verteilung und visualisieren Sie sie. Nutzen Sie die Gittermethode.\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nL√∂sung\n\np_grid &lt;- seq(from = 0, to = 1, length.out = 100)\nprior &lt;- rep(1, 100)\nlikelihood &lt;- dbinom(8, size = 15, prob = p_grid)\npost_unstand &lt;- likelihood * prior\nposterior &lt;- post_unstand / sum(post_unstand)\n\nd &lt;- tibble(p = p_grid, posterior = posterior)\n\nJetzt visualisieren; mit ggplot2:\n\nlibrary(tidyverse)\n d %&gt;%\n  ggplot(aes(x = p, y = posterior)) +\n # geom_point() +\n  geom_line() +\n  labs(x = \"Anteil Wasser (p)\", y = \"Posterior Density\")\n\n\n\n\n\n\n\n\nOder mit ggpubr:\n\nlibrary(ggpubr)\n\nggline(d, x = \"p\", y = \"posterior\",\n       plot_type = \"l\")\n\n\n\n\n\n\n\n\nQuelle\n\nCategories:\n\nbayes\nppv\nprobability\nstring"
  },
  {
    "objectID": "posts/Shrinkage1/Shrinkage1.html",
    "href": "posts/Shrinkage1/Shrinkage1.html",
    "title": "Shrinkage1",
    "section": "",
    "text": "Shrinkage (Penalisierung) ist eine Erweiterung der klassischen Linearen Modelle. Welche Aussage dazu ist richtig?\n\n\n\nDie Modellkoeffizienten von penalisierten linearen Modelle k√∂nnen wie normale lineare Modelle interpretiert werden.\nDie L2-Norm der Penalisierung kann zur Auswahl von Pr√§diktoren herangezogen werden.\nDie L1-Norm der Penalisierung wird auch als Ridge-Regression bezeichnet.\nDie Ridge-Regression ist ein Algorithmus, der eine Gr√∂√üe minimiert, in der ein Strafterm zum √ºblichen Least-Square-Termin hinzuaddiert wird, wobei dieser Strafterm die (mit \\(\\lambda\\)) gewichtete Summe der Absolutwerte der \\(\\beta\\)-Koeffizienten beschreibt.\nDie Lasso-Regression liefert im Vergleich zur Ridge-Regression tendenziell bessere Ergebnisse, wenn das Kriterium eine Funktion von vielen Pr√§diktoren ist, deren Koeffizienten jeweils etwa gleich stark sind."
  },
  {
    "objectID": "posts/Shrinkage1/Shrinkage1.html#answerlist",
    "href": "posts/Shrinkage1/Shrinkage1.html#answerlist",
    "title": "Shrinkage1",
    "section": "",
    "text": "Die Modellkoeffizienten von penalisierten linearen Modelle k√∂nnen wie normale lineare Modelle interpretiert werden.\nDie L2-Norm der Penalisierung kann zur Auswahl von Pr√§diktoren herangezogen werden.\nDie L1-Norm der Penalisierung wird auch als Ridge-Regression bezeichnet.\nDie Ridge-Regression ist ein Algorithmus, der eine Gr√∂√üe minimiert, in der ein Strafterm zum √ºblichen Least-Square-Termin hinzuaddiert wird, wobei dieser Strafterm die (mit \\(\\lambda\\)) gewichtete Summe der Absolutwerte der \\(\\beta\\)-Koeffizienten beschreibt.\nDie Lasso-Regression liefert im Vergleich zur Ridge-Regression tendenziell bessere Ergebnisse, wenn das Kriterium eine Funktion von vielen Pr√§diktoren ist, deren Koeffizienten jeweils etwa gleich stark sind."
  },
  {
    "objectID": "posts/Shrinkage1/Shrinkage1.html#answerlist-1",
    "href": "posts/Shrinkage1/Shrinkage1.html#answerlist-1",
    "title": "Shrinkage1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/mtcars-abhaengig_var3/mtcars-abhaengig_var3.html",
    "href": "posts/mtcars-abhaengig_var3/mtcars-abhaengig_var3.html",
    "title": "mtcars-abhaengig_var3",
    "section": "",
    "text": "Aufgabe\nIm Folgenden ist der Datensatz mtcars zu analysieren. Er ist unter dieser Quelle erh√§ltlich.\nDer Datensatz ist z.B. als CSV-Datei von dieser Webseite abrufbar.\nHilfe zum Datensatz ist via help(\"name_des_datensatzes\") oder auf dieser Webseite abrufbar.\nOb die Variable hp (UV; Ereignis \\(A\\)) und Spritverbrauch (mpg; AV; Ereignis \\(B\\)) wohl voneinander abh√§ngig sind? Was meinen Sie? Was ist Ihre Einsch√§tzung dazu? Vermutlich haben Sie ein (wenn vielleicht auch implizites) Vorab-Wissen zu dieser Frage. Lassen wir dieses Vorab-Wissen aber einmal au√üen vor und schauen uns rein Daten dazu an. Vereinfachen wir die Frage etwas, indem wir beide Variablen am Mittelwert aufteilen: Wenn eine Beobachtung (d.h. ein Auto) einen Wert in der jeweiligen Variablen h√∂chstens so gro√ü wie der Mittelwert der Variable aufweist, geben wir der Beobachtung der Wert 0, ansonsten den Wert 1.\nDie resultierenden bin√§ren Variablen nennen wir av_high bzw. uv_high (im sch√∂nsten Denglisch).\nBerechnen Sie: \\(Pr(\\neg \\text{uvhigh} \\, | \\,  \\text{avhigh})\\)\nHinweise:\n\nDas ‚ÄúEllbogen-Zeichen‚Äù \\(\\neg\\) kennzeichnet eine logische Negierung (das Gegenteil).\nDie angegebene Wahrscheinlichkeit ist eine bedingte Wahrscheinlichkeit.\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nDieser Pr√§diktor wurde als UV bestimmt:\n\n\n[1] \"hp\"\n\n\nSchauen wir zuerst mal in den Datensatz:\n\nd %&gt;% \n  select(mpg, one_of(pred_chosen)) %&gt;% \n  slice_head(n = 5)\n\n# A tibble: 5 √ó 2\n    mpg    hp\n  &lt;dbl&gt; &lt;dbl&gt;\n1  21     110\n2  21     110\n3  22.8    93\n4  21.4   110\n5  18.7   175\n\n\nDann berechnen wir die bin√§ren Variablen:\n\n# split by mean:\nd2 &lt;-\n  d %&gt;% \n  select(mpg, all_of(pred_chosen)) %&gt;% \n  mutate(av_high = case_when(\n    mpg &lt;= mean(mpg) ~ 0,\n    mpg &gt; mean(mpg) ~ 1\n  )) %&gt;% \n  select(-mpg) \n\n\n# split at mean:\nd2[1] &lt;- ifelse(d[[pred_chosen]] &lt; mean(d[[pred_chosen]]), 0, 1)\nnames(d2)[1] &lt;- \"uv_high\"\n\n# abstracted variables names:\npred_binary_name &lt;- names(d2)[1]\nav_binary_name &lt;- names(d2)[2]\n\nDann filtern wir die gesuchten Wahrscheinlichkeiten bzw. Anteile der AV: ::: {.cell hash=‚Äòmtcars-abhaengig_var3_cache/html/unnamed-chunk-5_1c021dbbf8846c7ce55f26f992a3136b‚Äô}\nd3 &lt;-\n  d2 %&gt;% \n  filter(av_high == 1)\n\nav_high_sum &lt;- nrow(d3)\nav_high_sum\n\n[1] 14\n\n:::\nEs gibt also 14 Autos, die den oben gesuchten ‚Äúhinteren Teil‚Äù der Bedingung erf√ºllen (av_high = TRUE).\nFiltern wir als n√§chstes nach dem ‚Äúvorderen Teil‚Äù der gesuchten Wahrscheinlichkeit (was das gleiche ist wie ein Anteil in diesem Fall):\n\nd3a &lt;- \n  d3 %&gt;% \n  count(uv_high) \n\nBetrachten wir die nach av_high = TRUE gefilterte H√§ufigkeitstabelle:\n\n\n\n\n\n\n\n\nuv_high\nn\n\n\n\n\n0\n14\n\n\n1\n1\n\n\n\n\n\n\n\nUnd dann z√§hlen wir die relativen H√§ufigkeiten der UV, und zwar f√ºr uv_high == FALSE:\n\nprop_not_uv_high_cond_av_high &lt;- \n  d3a %&gt;% \n  mutate(prop = n / av_high_sum) %&gt;% \n  filter(uv_high == 0) %&gt;% \n  pull(prop)\n\n\n\nsol &lt;- prop_not_uv_high_cond_av_high\nsol\n\n[1] 1\n\n\nDer gesuchte Wert betr√§gt also 1.\nVisualisieren wir noch die bedingten Wahrscheinlichkeiten, so k√∂nnte man die gesuchten Anteile einfach abz√§hlen:\n\nd2 %&gt;% \n  mutate(across(everything(), factor)) %&gt;%  # factor() brauchn wir nur f√ºr die Farbf√ºllung\n  ggplot() +\n  aes_string(x = av_binary_name, fill = pred_binary_name) +\n  geom_bar() +\n  scale_y_continuous(breaks = 1:100) +\n  scale_x_discrete(drop = FALSE)  # zeigt Kategorien ohne Daten in der Legende an.\n\n\n\n\n\n\n\n\nSieht man in dem Diagramm nur eine Farbe (anstelle von zweien), so hei√üt das, dass es nur eine Gruppe gibt (und nicht zwei). Die H√§ufigkeit der nicht vorhandenen Gruppe ist demnach Null.\nAm besten, Sie f√ºhren den letzten Code Schritt f√ºr Schritt aus und schauen sich jeweils das Ergebnis an, das hilft beim Verstehen.\nAlternativ kann man sich die H√§ufigkeiten auch so ausgeben lassen:\n\n\n       av_high\nuv_high         0         1\n      0 0.1666667 1.0000000\n      1 0.8333333 0.0000000\n\n\n\nCategories:\n\ndyn\nprobability\nnum"
  },
  {
    "objectID": "posts/Kausale-Verben/Kausale-Verben.html",
    "href": "posts/Kausale-Verben/Kausale-Verben.html",
    "title": "Kausale-Verben",
    "section": "",
    "text": "Question"
  },
  {
    "objectID": "posts/Kausale-Verben/Kausale-Verben.html#answerlist",
    "href": "posts/Kausale-Verben/Kausale-Verben.html#answerlist",
    "title": "Kausale-Verben",
    "section": "Answerlist",
    "text": "Answerlist\n\nX hat einen Effekt auf Y\nX steht mit Y in Zusammenhang\nHohe Werte in X geht mit hohen Werten in Y einher (und umgekehrt)\nEs wird ein statistischer Effekt von X auf Y erwartet\nX reallokiert die Werte von Y"
  },
  {
    "objectID": "posts/Kausale-Verben/Kausale-Verben.html#answerlist-1",
    "href": "posts/Kausale-Verben/Kausale-Verben.html#answerlist-1",
    "title": "Kausale-Verben",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\nRichtig\n\n\nCategories:\n\ncausal\nresearch-question\nmchoice"
  },
  {
    "objectID": "posts/qm2-quiz-inferenz/index.html",
    "href": "posts/qm2-quiz-inferenz/index.html",
    "title": "qm2-quiz-inferenz",
    "section": "",
    "text": "1 Aufgabe\nGeben Sie jeweils an, ob die Aussage richtig oder falsch ist.\n\nMan kann die Zielarten der Statistik in drei Gruppen fassen: Beschreiben, Vorhersagen und Entscheiden.\nDie Deskriptivstatistik fasst eine Stichprobe zusammen (in eine Zahl, die die Stichprobe repr√§sentiert).\nDie Inferenzstatistik schlie√üt von einer Stichprobe auf die Grundgesamtheit und ist daher frei von Ungewissheit.\nKennzahlen einer Population nennt man auch eine Statistik.\nUm die Streuung einer Population zu benennen, wird in der Statistik h√§ufig der griechische Buchstabe \\(\\mu\\) verwendet.\nEine Forscherin testen zwei Varianten ihres Webshops hinsichtlich der mittleren Verweildauer auf der Seite. Sie geht davon aus, dass die Verweildauer in Variante 1 \\(\\mu_{V1}\\) h√∂her ist als in Variante zwei \\(\\mu_{V2}\\). Ihre Hypothese formalisiert sie richtigerweise so: \\(\\mu_{V1} &gt; \\mu_{V2}\\).\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\nDie Ungewissheit eines wissenschaftlichen Modells kann man in zwei Arten aufteilen: Ungewissheit zu den Koeffizienten und Ungewissheit zur Modellspezifikation.\nDer Grund f√ºr die Schwankungen der Modellparameter zwischen den Stichproben ist die Zuf√§lligkeit des Stichprobenziehens.\nDie Grenzen eines Konfidenzintervall markieren einen Bereich plausibler Werte f√ºr einen Parameter.\nDie Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als objektiv zur√ºckgewiesen.\nDer zentrale Kennwert des Frequentismus hei√üt der p-Wert.\nDie Definition eines Konfidenzintervalls im Frequentismus lautet: ‚ÄúDer Konfidenzbereich, z.B. von 95%, repr√§sentiert den Anteil der Konfidenzintervalle bei sehr vielen (oder unendlich vielen) Wiederholungen des Experiments, die den echten Parameterwert enthalten w√ºrden.‚Äù\nDie Definition eines Konfidenzintervalls im Bayes‚Äôschen Ansatz lautet: ‚ÄúDer Konfidenzbereich, z.B. von 95%, gibt die Wahrscheinlichkeit an, dass der wahre Parameterwert innerhalb des Intervalls liegt.‚Äù\nEin frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters).\nEin Bayes‚Äôsches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters).\nDer Bayes‚Äôsche Ansatz wird subjektiv genannt, weil er das Vorwissen eines Forschers ber√ºcksichtigt.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nMan kann die Zielarten der Statistik in drei Gruppen fassen: Beschreiben, Vorhersagen und Entscheiden. F\nDie Deskriptivstatistik fasst eine Stichprobe zusammen (in eine Zahl, die die Stichprobe repr√§sentiert). R\nDie Inferenzstatistik schlie√üt von einer Stichprobe auf die Grundgesamtheit und ist daher frei von Ungewissheit. F\nKennzahlen einer Population nennt man auch eine Statistik. F\nUm die Streuung einer Population zu benennen, wird in der Statistik h√§ufig der griechische Buchstabe \\(\\mu\\) verwendet. F\nEine Forscherin testen zwei Varianten ihres Webshops hinsichtlich der mittleren Verweildauer auf der Seite. Sie geht davon aus, dass die Verweildauer in Variante 1 \\(\\mu_{V1}\\) h√∂her ist als in Variante zwei \\(\\mu_{V2}\\). Ihre Hypothese formalisiert sie richtigerweise so: \\(\\mu_{V1} &gt; \\mu_{V2}\\). R\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit. R\nDie Ungewissheit eines wissenschaftlichen Modells kann man in zwei Arten aufteilen: Ungewissheit zu den Koeffizienten und Ungewissheit zur Modellspezifikation. R\nDer Grund f√ºr die Schwankungen der Modellparameter zwischen den Stichproben ist die Zuf√§lligkeit des Stichprobenziehens. R\nDie Grenzen eines Konfidenzintervall markieren einen Bereich plausibler Werte f√ºr einen Parameter. R\nDie Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als objektiv zur√ºckgewiesen. F\nDer zentrale Kennwert des Frequentismus hei√üt der p-Wert. R\nDie Definition eines Konfidenzintervalls im Frequentismus lautet: ‚ÄúDer Konfidenzbereich, z.B. von 95%, repr√§sentiert den Anteil der Konfidenzintervalle bei sehr vielen (oder unendlich vielen) Wiederholungen des Experiments, die den echten Parameterwert enthalten w√ºrden.‚Äù R\nDie Definition eines Konfidenzintervalls im Bayes‚Äôschen Ansatz lautet: ‚ÄúDer Konfidenzbereich, z.B. von 95%, gibt die Wahrscheinlichkeit an, dass der wahre Parameterwert innerhalb des Intervalls liegt.‚Äù R\nEin frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters). R\nEin Bayes‚Äôsches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters). F\nDer Bayes‚Äôsche Ansatz wird subjektiv genannt, weil er das Vorwissen eines Forschers ber√ºcksichtigt. R"
  },
  {
    "objectID": "posts/chatgpt-sentiment-simple/chatgpt-sentiment-simple.html",
    "href": "posts/chatgpt-sentiment-simple/chatgpt-sentiment-simple.html",
    "title": "chatgpt-sentiment-simple",
    "section": "",
    "text": "Aufgabe\nFragen Sie ChatGPT via API zum Sentiment des ersten Texts aus dem Germeval-2018-Datensatz (Train).\n\n\n\n\n\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen.\n\n         \n\n\nL√∂sung\n\nOpenAI hat eine neue API (Stand: 2023-11-23). Der Code der alten API bricht. üíî \\(\\square\\)\n\nModule importieren:\n\nfrom openai import OpenAI\n\nModuleNotFoundError: No module named 'openai'\n\n\nAnmelden bei OpenAI:\n\nclient = OpenAI()\n\nNameError: name 'OpenAI' is not defined\n\n\n\n\n\n\n\n\nNote\n\n\n\nDieses Verfahren setzt voraus, dass in .Renviron die Variable OPENAI_API_KEY hinterlegt ist. \\(\\square\\)\n\n\nTextschnipsel, das zu klassifizieren ist:\n\ntext = \"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"\n\nPrompt definieren:\n\nmy_prompt  = f\"Analysieren Sie das Sentiment des folgenden Texts:\\n{text}\"\n\nAnfrage an die API, in eine Funktion gepackt:\n\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n  model=model,\n  messages=messages,\n  max_tokens=50,\n  temperature=0,\n  )\n  return response.choices[0].message.content\n\nUnd los:\n\nget_completion(my_prompt, client) \n\nNameError: name 'client' is not defined"
  },
  {
    "objectID": "posts/smape/smape.html",
    "href": "posts/smape/smape.html",
    "title": "smape",
    "section": "",
    "text": "Zur Bemessung der (pr√§diktiven) G√ºte eines Modells existieren verschiedene Kennzahlen, auch abh√§ngig davon, ob es sich um eine Regression oder Klassifikation handelt. Eine Kennzahl hei√üt SMAPE (Symmetric Mean Absolute Percentage). Welche Aussage zu dieser Kennzahl ist falsch?\n\n\n\nDie SMAPE-Werte von Variablen verschiedener Skalierung sind kaum zu vergleichen.\nSMAPE hat einen Wertebereich von 0 bis 1, d.h. SMAPE \\(\\in [0,1]\\).\nGr√∂√üere Werte zeigen schlechtere Vorhersageg√ºte an.\nDer SMAPE kann nicht negativ werden."
  },
  {
    "objectID": "posts/smape/smape.html#answerlist",
    "href": "posts/smape/smape.html#answerlist",
    "title": "smape",
    "section": "",
    "text": "Die SMAPE-Werte von Variablen verschiedener Skalierung sind kaum zu vergleichen.\nSMAPE hat einen Wertebereich von 0 bis 1, d.h. SMAPE \\(\\in [0,1]\\).\nGr√∂√üere Werte zeigen schlechtere Vorhersageg√ºte an.\nDer SMAPE kann nicht negativ werden."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode2/Flex-vs-nichtflex-Methode2.html",
    "href": "posts/Flex-vs-nichtflex-Methode2/Flex-vs-nichtflex-Methode2.html",
    "title": "Flex-vs-nichtflex-Methode2",
    "section": "",
    "text": "Algorithmen des statistischen Lernens lassen sich unterteilen hinsichtlich ihrer Flexibilit√§t; es gibt mehr bzw. weniger flexible Algorithmen.\nWelche der folgenden Aussagen ist in diesem Zusammenhang korrekt?\n\n\n\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund von h√∂herem Overfitting.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell besser ab als eine weniger flexible Methode aufgrund von geringerem Overfitting.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell besser ab als eine weniger flexible Methode aufgrund von geringerer Verzerrung.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund von h√∂herer Verzerrung.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund von h√∂herer Verzerrung und von h√∂herem Overfitting."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode2/Flex-vs-nichtflex-Methode2.html#answerlist",
    "href": "posts/Flex-vs-nichtflex-Methode2/Flex-vs-nichtflex-Methode2.html#answerlist",
    "title": "Flex-vs-nichtflex-Methode2",
    "section": "",
    "text": "Bei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund von h√∂herem Overfitting.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell besser ab als eine weniger flexible Methode aufgrund von geringerem Overfitting.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell besser ab als eine weniger flexible Methode aufgrund von geringerer Verzerrung.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund von h√∂herer Verzerrung.\nBei kleiner Stichprobe und gro√üer Zahl an Pr√§diktoren schneidet eine flexible Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund von h√∂herer Verzerrung und von h√∂herem Overfitting."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode2/Flex-vs-nichtflex-Methode2.html#answerlist-1",
    "href": "posts/Flex-vs-nichtflex-Methode2/Flex-vs-nichtflex-Methode2.html#answerlist-1",
    "title": "Flex-vs-nichtflex-Methode2",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nstatlearning\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/mtcars-post3a/index.html",
    "href": "posts/mtcars-post3a/index.html",
    "title": "mtcars-post3a",
    "section": "",
    "text": "Im Datensatz mtcars: Wie gro√ü ist die Wahrscheinlichkeit, dass der Effekt der UV vs auf die AV mpg positiv ist?\nHinweise\nDaf√ºr wird folgende Modell berechnet.\nSetup:\n\ndata(mtcars)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats) \nlibrary(ggpubr)\n\nModell berechnen:\n\nm1 &lt;- stan_glm(mpg ~ vs, data = mtcars,\n               seed = 42,\n               refresh = 0)\n\n\npost_m1_vs &lt;- parameters(m1)\npost_m1_vs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n16.630748\n0.95\n14.470104\n18.88016\n1\n0.999871\n3893.829\nnormal\n20.09062\n15.06737\n\n\nvs\n7.912506\n0.95\n4.603783\n11.26223\n1\n1.000498\n3797.040\nnormal\n0.00000\n29.89462\n\n\n\n\n\n\nHier ist die Post-Verteilung visualisiert.\n\nm1 %&gt;% \n  as_tibble() %&gt;% \n  ggdensity(x = \"vs\", fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n\nAufgabe W√§hlen Sie die am besten passende Option:\n\n\n\n.42\n.73\n.23\n1\n0"
  },
  {
    "objectID": "posts/mtcars-post3a/index.html#answerlist",
    "href": "posts/mtcars-post3a/index.html#answerlist",
    "title": "mtcars-post3a",
    "section": "",
    "text": ".42\n.73\n.23\n1\n0"
  },
  {
    "objectID": "posts/mtcars-post3a/index.html#answerlist-1",
    "href": "posts/mtcars-post3a/index.html#answerlist-1",
    "title": "mtcars-post3a",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\nbayes\nregression\npost\nexam-22"
  },
  {
    "objectID": "posts/iq02/iq02.html",
    "href": "posts/iq02/iq02.html",
    "title": "iq02",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nWie gro√ü ist die Wahrscheinlichkeit, dass die n√§chste Person, die Sie treffen, mindestens zwei Streuungseinheiten √ºber dem Mittelwert liegt?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^3\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nWir wollen hier keine Post-Verteilung berechnen, sondern lediglich Werte simulieren.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)  # Reproduzierbarkeit\nd &lt;- tibble(\n  id = 1:10^3,  # Der Doppelpunkt hei√üt \"bis\", also \"von 1 bis 10 hoch 3\". Diese Spalte ist nicht so wichtig.\n  iq = rnorm(n = 10^3, mean = 100, sd = 15))\n\nhead(d)  # Die ersten paar Zeilen\n\n\n\n\n\nid\niq\n\n\n\n\n1\n120.56438\n\n\n2\n91.52953\n\n\n3\n105.44693\n\n\n4\n109.49294\n\n\n5\n106.06402\n\n\n6\n98.40813\n\n\n\n\n\n\nDa \\(\\sigma=15\\), filtern wir ab 130, da 130 genau 2 SD-Einheiten √ºber dem Mittelwert liegt: 130 - 2*15 = 100.\n\nd %&gt;% \n  count(iq &gt;= 130)\n\n\n\n\n\niq &gt;= 130\nn\n\n\n\n\nFALSE\n979\n\n\nTRUE\n21\n\n\n\n\n\n\n21/1000 sind ca. 0.02.\nDie Wahrscheinlichkeit betr√§gt ca. 2%.\nJa, diese Aufgaben ist faktisch identische zur Aufgabe iq01. Darum ging es: Sie sollen erkennen, dass ein IQ-Wert von 130 das gleiche ist wie MW+2sd.\n√úbrigens: ‚ÄúWie viele SD-Einheiten liegt der Wert von Beobachtung \\(i\\) √ºber dem Mittelwert, \\(\\bar{X}\\) ?‚Äù ist die Frage, die der z-Wert beantwortet:\n\\(z_i = \\frac{x_i - \\bar{X}}{sd(x)}\\)\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/iq05/iq05.html",
    "href": "posts/iq05/iq05.html",
    "title": "iq05",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nWie intelligent muss man sein, um zu den schlauesten Promill der Bev√∂lkerung zu geh√∂ren?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\)\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^5\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten)\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd &lt;- tibble(\n  id = 1:10^5,\n  iq = rnorm(n = 10^5, mean = 100, sd= 15))\n\nWir filtern die schlauesten 0,1 Prozent:\n\nd %&gt;% \n  summarise(iq_top_0komma1_prozent = quantile(iq, prob = .999))\n\n\n\n\n\niq_top_0komma1_prozent\n\n\n\n\n145.901\n\n\n\n\n\n\nMan muss mindestens √ºber einen IQ von ca. 145 verf√ºgen.\nAchtung: Das sind immer Zahlen als der ‚Äúkleinen Welt‚Äù des Modells. Sollten unsere Annahmen nicht stimmen (normalverteilt mit MW 100 und SD 15), dann stimmt nat√ºrlich unser Ergebnis auch nicht.\nOb unsere Annahmen stimmen, kann der Computer nicht sagen. Das ist weiterhin Menschenjob.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/wskt-quiz11/wskt-quiz11.html",
    "href": "posts/wskt-quiz11/wskt-quiz11.html",
    "title": "wskt-quiz11",
    "section": "",
    "text": "Sei \\(X \\sim N(100, 15)\\).\nBehauptung: Es gilt: \\(Pr(X \\ge 115) &lt; .2\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz11/wskt-quiz11.html#answerlist",
    "href": "posts/wskt-quiz11/wskt-quiz11.html#answerlist",
    "title": "wskt-quiz11",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz11/wskt-quiz11.html#answerlist-1",
    "href": "posts/wskt-quiz11/wskt-quiz11.html#answerlist-1",
    "title": "wskt-quiz11",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/gem-wskt3/gem-wskt3.html",
    "href": "posts/gem-wskt3/gem-wskt3.html",
    "title": "Gem-Wskt3",
    "section": "",
    "text": "Aufgabe\nEin renommiertes Unternehmen sucht ei Kandidati (m/w/d) f√ºr eine (hoch dotierte) F√ºhrungsposition. Das k√∂nnten Sie sein. Ein Managementberatungsunternehmung f√ºhrt ein Assessmentcenter durch, welches pro Kandidati eine positive bzw. negative Empfehlung ergibt. Aus fr√ºheren Erfahrungen heraus wissen die Berater, dass die tats√§chlich geeigneten Kandidaten (Ereignis \\(E\\) wie eligible) mit \\(70\\%\\) eine positive Empfehlung f√ºr die Stelle ausgesprochen bekommen (Ereignis \\(R\\) wie recommendation). Weiterhin bekommen von den nicht geeigneten Kandidaten \\(77\\%\\) eine negative Empfehlung. Insgesamt wissen die Berater, dass \\(6\\%\\) der Bewerber/innen tats√§chlich geeignet sind.\nGeben Sie den Wert folgender Kenngr√∂√üe aus der entsprechenden Kontingenztabelle an: \\(\\overline{E} \\cap R\\)!\nHinweise:\n\n\\(\\overline{R}=R^C= \\neg R\\) (logische Verneinung).\n\\(\\cap\\) meint das logische ‚ÄúUnd‚Äù.\nGeben Sie Wahrscheinlichkeiten nicht als Prozentzahlen, sondern als Anteile an.\nRunden Sie auf zwei Dezimalstellen.\nAchten Sie darauf, das richtige Dezimaltrennzeichen Ihres Systems zu verwenden.\n\n         \n\n\nL√∂sung\nEinige Wahrscheinlichkeiten lassen sich direkt aus dem Text errechnen:\n\\(P(E \\cap R) = P(R | E) \\cdot P(E) = 0.7 \\cdot 0.06 = 0.042 = 4.2\\%\\)\n\\(P(\\overline{E} \\cap \\overline{R}) =\n    P(\\overline{R} | \\overline{E}) \\cdot P(\\overline{E}) = 0.77 \\cdot 0.94 = 0.7238 = 72.38\\%\\)\nDie restlichen gemeinsamen Wahrscheinlichkeiten lassen sich durch Addieren und Subtrahieren in der Kontingenztabelle errechnen:\n\n\n\n\n\n\n\n\n\n\n\\(R\\)\n\\(\\overline{R}\\)\nSumme\n\n\n\n\n\\(E\\)\n4.20\n1.80\n6.00\n\n\n\\(\\overline{E}\\)\n21.62\n72.38\n94.00\n\n\nSumme\n25.82\n74.18\n100.00\n\n\n\n\nsol &lt;- sol %&gt;% round(2)\nsol &lt;- sol[sol_sample_idx]\n\nL√∂sung: Der gesuchte Wert lautet: 0.22.\n\nCategories:\n\nprobability\ndyn\nbayes\nnum"
  },
  {
    "objectID": "posts/gem-wskt4/index.html",
    "href": "posts/gem-wskt4/index.html",
    "title": "gem-wskt4",
    "section": "",
    "text": "1 Aufgabe\nBetrachten wir das Zufallsexperiment, bei dem ein W√ºrfel geworfen wird. Wir haben keinen Grund zu glauben, dass eine bestimmte Augenzahl bevorzugt wird, und nehmen daher an, dass alle Augenzahlen gleich wahrscheinlich sind.\nSei \\(A\\) das Ereignis, dass eine gerade Zahl geworfen wird. Sei \\(B\\) das Ereignis, dass eine Zahl gr√∂√üer als 3 geworfen wird.\nWas ist die Wahrscheinlichkeit, f√ºr das Ereignis \\(A \\cap B\\), also das gemeinsame Eintreten von \\(A\\) und \\(B\\)?\n  \n  \n  \n  \n\n\n2 L√∂sung\n\na &lt;- c(2,4,6)\nb &lt;- c(4,5,6)\n\nintersect(a,b)\n\n[1] 4 6\n\n\nDie Schnittmenge von \\(A\\) und \\(B\\) ist also \\(\\{4,6\\}\\), also die Menge der geraden Zahlen, die gr√∂√üer als 3 sind. Das sind 2 von 6 m√∂glichen Ergebnissen, also ist die Wahrscheinlichkeit \\(P(A \\cap B) = \\frac{2}{6} = \\frac{1}{3}\\)."
  },
  {
    "objectID": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html",
    "href": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html",
    "title": "Verteilungen-Quiz-03",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nWenn eine Verteilung einer stetigen Zufallsvariablen \\(X\\) (z.B. die Posteriori-Verteilung einer Bayes-Analyse) normalverteilt ist, gilt dann \\(Pr(X \\ge\\bar{x}) = 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist",
    "href": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist",
    "title": "Verteilungen-Quiz-03",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist-1",
    "title": "Verteilungen-Quiz-03",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/penguins-stan-01a/index.html",
    "href": "posts/penguins-stan-01a/index.html",
    "title": "penguins-stan-01a",
    "section": "",
    "text": "Wir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir in dem Zusammenhang den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nAufgabe:\nWie gro√ü ist der statistische Einfluss der UV auf die AV?\n\nGeben Sie den Punktsch√§tzer des Effekts an!\nWie viele Parameter hat das Modell?\nGeben Sie die Breite eines 90%-HDI an (zum Effekt)!\nWie gro√ü ist die Wahrscheinlichkeit, dass der Effekt vorhanden ist (also gr√∂√üer als Null ist), die ‚ÄúEffektwahrscheinlichkeit‚Äù?\n\nNutzen Sie die folgende Analyse als Grundlage Ihrer Antworten.\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)  # oder z.B. mit read_csv \n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm1_params &lt;- parameters(m1, ci_method = \"hdi\", ci = .9)\nm1_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n359.9393\n0.9\n-112.36003\n834.8034\n0.89575\n1.000485\n4117.553\nnormal\n4201.754\n2004.8863\n\n\nbill_length_mm\n87.4472\n0.9\n76.99955\n98.3694\n1.00000\n1.000491\n4123.761\nnormal\n0.000\n367.2233"
  },
  {
    "objectID": "posts/penguins-stan-01a/index.html#punktsch√§tzer",
    "href": "posts/penguins-stan-01a/index.html#punktsch√§tzer",
    "title": "penguins-stan-01a",
    "section": "Punktsch√§tzer",
    "text": "Punktsch√§tzer\nDer Punktsch√§tzer ist in der Spalte Median in der Tabelle parameters zu finden. Sein Wert ist:\n\n\n[1] 87.4472\n\n\n\nm1_params |&gt; plot()"
  },
  {
    "objectID": "posts/penguins-stan-01a/index.html#anzahl-parameter",
    "href": "posts/penguins-stan-01a/index.html#anzahl-parameter",
    "title": "penguins-stan-01a",
    "section": "Anzahl Parameter",
    "text": "Anzahl Parameter\nDas Modell hat 3 Parameter:\n\n\\(\\beta_0\\) (oder \\(\\alpha\\))\n\\(\\beta_01\\)\n\\(\\sigma\\)"
  },
  {
    "objectID": "posts/penguins-stan-01a/index.html#breite-des-intervalls",
    "href": "posts/penguins-stan-01a/index.html#breite-des-intervalls",
    "title": "penguins-stan-01a",
    "section": "Breite des Intervalls",
    "text": "Breite des Intervalls\nDazu liest man die Intervallgrenzen (90% CI) in der richtigen Zeile ab (Tabelle parameters):\n\n\n[1] 21.36985\n\n\nEinheit: mm"
  },
  {
    "objectID": "posts/penguins-stan-01a/index.html#effektwahrscheinlichkeit",
    "href": "posts/penguins-stan-01a/index.html#effektwahrscheinlichkeit",
    "title": "penguins-stan-01a",
    "section": "Effektwahrscheinlichkeit",
    "text": "Effektwahrscheinlichkeit\nMan kann diesen Wert aus der Tabelle oben (Ausgabe von parameters()) einfach in der Spalte pd ablesen. pd steht f√ºr probability of direction, s. Details hier.\nOder so, ist auch einfach:\n\npd_m1 &lt;- p_direction(m1) # aus Paket easystats\npd_m1\n\n\n\n\n\nParameter\npd\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.89575\nfixed\nconditional\n\n\nbill_length_mm\n1.00000\nfixed\nconditional\n\n\n\n\n\n\nUnd plotten ist meist hilfreich: plot(pd_m1).\nMan kann sich auch ein ‚ÄúDashboard‚Äù mit allen Ergebnissen des Modells ausgeben lassen:\n\nmodel_dashboard(m1)"
  },
  {
    "objectID": "posts/wskt-quiz20/wskt-quiz20.html",
    "href": "posts/wskt-quiz20/wskt-quiz20.html",
    "title": "wskt-quiz20",
    "section": "",
    "text": "Behauptung:\nMann (Frau auch) kann jede Kennzahl der Deskriptivstatistik mit Methoden der Inferenzstatistik untersuchen.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz20/wskt-quiz20.html#answerlist",
    "href": "posts/wskt-quiz20/wskt-quiz20.html#answerlist",
    "title": "wskt-quiz20",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz20/wskt-quiz20.html#answerlist-1",
    "href": "posts/wskt-quiz20/wskt-quiz20.html#answerlist-1",
    "title": "wskt-quiz20",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\ninference\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/germeval05/germeval05.html",
    "href": "posts/germeval05/germeval05.html",
    "title": "germeval05",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Word-Vektoren f√ºr das Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels."
  },
  {
    "objectID": "posts/germeval05/germeval05.html#textvektoren-importieren",
    "href": "posts/germeval05/germeval05.html#textvektoren-importieren",
    "title": "germeval05",
    "section": "Textvektoren importieren",
    "text": "Textvektoren importieren\n\nlibrary(textdata)\n\nglove_embedding &lt;- embedding_glove6b(\n  dir = \"/Users/sebastiansaueruser/datasets\",\n  return_path = TRUE,\n  manual_download = TRUE\n)\n\nhead(glove_embedding)"
  },
  {
    "objectID": "posts/germeval05/germeval05.html#workflow",
    "href": "posts/germeval05/germeval05.html#workflow",
    "title": "germeval05",
    "section": "Workflow",
    "text": "Workflow\n\n# model:\nmod1 &lt;-\n  logistic_reg()\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train, v = 5)\n\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  step_tokenize(text) %&gt;%\n  step_stopwords(text, keep = FALSE) %&gt;%\n  step_word_embeddings(text,\n                       embeddings = glove_embedding,\n                       aggregation = \"mean\") |&gt; \n  step_normalize(all_numeric_predictors()) \n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval05/germeval05.html#tuiningfitting",
    "href": "posts/germeval05/germeval05.html#tuiningfitting",
    "title": "germeval05",
    "section": "Tuining/Fitting",
    "text": "Tuining/Fitting\n\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit_resamples(\n    resamples = rsmpl,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE))\ntoc()\nbeep()\n\n\nwf1_fit |&gt; collect_metrics()\n\nBester Fold:\n\nshow_best(wf1_fit)"
  },
  {
    "objectID": "posts/germeval05/germeval05.html#fit",
    "href": "posts/germeval05/germeval05.html#fit",
    "title": "germeval05",
    "section": "Fit",
    "text": "Fit\n\nfit1 &lt;- \n  wf1 |&gt; \n  fit(data = d_train)"
  },
  {
    "objectID": "posts/germeval05/germeval05.html#test-set-g√ºte",
    "href": "posts/germeval05/germeval05.html#test-set-g√ºte",
    "title": "germeval05",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval05/germeval05.html#fazit",
    "href": "posts/germeval05/germeval05.html#fazit",
    "title": "germeval05",
    "section": "Fazit",
    "text": "Fazit\nglove6b ist f√ºr die englische Sprache vorgekocht. Das macht wenig Sinn f√ºr einen deutschsprachigen Corpus.\n\nCategories:\n\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nwordvec\nstring"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html",
    "href": "posts/wuerfel01/wuerfel01.html",
    "title": "wuerfel01",
    "section": "",
    "text": "Wie hoch ist die Wahrscheinlichkeit, mit zwei fairen W√ºrfeln genau 10 Augen zu werfen?\nHinweise:\n\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nRunden Sie auf zwei Dezimalstellen.\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nMit expand_grid k√∂nnen Sie komfortabel alle 36 Ereignisse dieses Zufallsexperiments in einen Dataframe bringen.\n\nW√§hlen Sie die am besten passende Option:\n\n\n\n.04\n.08\n.12\n.16\n.20"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html#answerlist",
    "href": "posts/wuerfel01/wuerfel01.html#answerlist",
    "title": "wuerfel01",
    "section": "",
    "text": ".04\n.08\n.12\n.16\n.20"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html#answerlist-1",
    "href": "posts/wuerfel01/wuerfel01.html#answerlist-1",
    "title": "wuerfel01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch.\nWahr.\nFalsch.\nFalsch.\nFalsch.\n\n\nCategories:\n\nprobability\ndice\nexam-22"
  },
  {
    "objectID": "posts/mariokart-korr3/mariokart-korr3.html",
    "href": "posts/mariokart-korr3/mariokart-korr3.html",
    "title": "mariokart-korr3",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die Korrelation von mittlerem Verkaufspreis (total_pr) und Startgebot (start_pr) f√ºr Spiele, die sowohl neu sind und √ºber Lenkr√§der (wheels) verf√ºgen.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\nBeachten Sie die Hinweise des Datenwerk.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  filter(cond == \"new\" & wheels &gt; 0) %&gt;% \n  summarise(pr_corr = cor(total_pr, start_pr))\n\nsolution\n\n    pr_corr\n1 0.4315485\n\n\nAlternativ kann man (komfortabel) die Korrelation z.B. so berechnen:\n\nd %&gt;% \n  select(start_pr, total_pr, cond, wheels) %&gt;% \n  filter(cond == \"new\" & wheels &gt; 0) %&gt;%  # logisches UND\n  correlation()\n\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |    r |        95% CI | t(53) |         p\n------------------------------------------------------------------\nstart_pr   |   total_pr | 0.43 | [ 0.19, 0.63] |  3.48 | 0.002**  \nstart_pr   |     wheels | 0.12 | [-0.15, 0.37] |  0.86 | 0.393    \ntotal_pr   |     wheels | 0.77 | [ 0.64, 0.86] |  8.82 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 55\n\n\nL√∂sung: 0.4.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nassociation\nnum"
  },
  {
    "objectID": "posts/ppv-dyn1/ppv-dyn1.html",
    "href": "posts/ppv-dyn1/ppv-dyn1.html",
    "title": "ppv-dyn1",
    "section": "",
    "text": "Berechnen Sie folgendes Modell (Datensatz mtcars):\nmpg ~ hp\nGeben Sie die Breite eines 50%-ETI an f√ºr eine Beobachtung mit einem z-Wert von 0 im Pr√§diktor!\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/ppv-dyn1/ppv-dyn1.html#setup",
    "href": "posts/ppv-dyn1/ppv-dyn1.html#setup",
    "title": "ppv-dyn1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  mutate(hp = standardize(hp))"
  },
  {
    "objectID": "posts/ppv-dyn1/ppv-dyn1.html#modell",
    "href": "posts/ppv-dyn1/ppv-dyn1.html#modell",
    "title": "ppv-dyn1",
    "section": "Modell",
    "text": "Modell\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, seed = 42, refresh = 0)\ncoef(m1)\n\n(Intercept)          hp \n30.11668130 -0.06820988 \n\nr2(m1)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])\n\n\nOder mit z-standardisierten Werten:\n\nm2 &lt;- stan_glm(mpg ~ hp, data = mtcars2, seed = 42, refresh = 0)\ncoef(m2)\n\n(Intercept)          hp \n  20.096771   -4.676665 \n\nr2(m2)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.586 (95% CI [0.378, 0.746])"
  },
  {
    "objectID": "posts/ppv-dyn1/ppv-dyn1.html#ppv",
    "href": "posts/ppv-dyn1/ppv-dyn1.html#ppv",
    "title": "ppv-dyn1",
    "section": "PPV",
    "text": "PPV\n\nm2_ppv &lt;- estimate_prediction(m2, data = tibble(hp = 0), ci = 0.5)\nm2_ppv\n\n\n\n\n\nhp\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n0\n20.18996\n4.05918\n17.43457\n22.91714\n\n\n\n\n\n\nVisualisierung:\n\nplot(estimate_prediction(m2, by = \"hp\"))\n\n\n\n\n\n\n\n\nMan beachte, dass die PPV mit mehr Ungewissheit behaftet ist, als die Post-Verteilung.\n\nplot(estimate_relation(m2))\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nppv\nregression\nnum"
  },
  {
    "objectID": "posts/wskt-quiz18/wskt-quiz18.html",
    "href": "posts/wskt-quiz18/wskt-quiz18.html",
    "title": "wskt-quiz18",
    "section": "",
    "text": "Behauptung:\nHat eine Hypothese die Priori-Wahrscheinlichkeit von 1, so wird die Post-Wahrscheinlichkeit dieser Hypothese 1 sein.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz18/wskt-quiz18.html#answerlist",
    "href": "posts/wskt-quiz18/wskt-quiz18.html#answerlist",
    "title": "wskt-quiz18",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz18/wskt-quiz18.html#answerlist-1",
    "href": "posts/wskt-quiz18/wskt-quiz18.html#answerlist-1",
    "title": "wskt-quiz18",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/interpret-ci/index.html",
    "href": "posts/interpret-ci/index.html",
    "title": "interpret-ci",
    "section": "",
    "text": "1 Aufgabe\nWelche der folgenden Aussagen zur Interpretation eines Populationsparameters (z.B. \\(\\mu\\)) eines Konfidenzintervalls der Art 95% CI [182cm; 184cm] ist richtig bzw. passt am besten?\n\nMit 95% Wahrscheinlichkeit liegt der wahre Wert des zugrundeliegenden Parameters zwischen 182cm und 184cm.\n\n\nPasst nur zur Bayesianischen, nicht zur Frequentistischen Statistik\nPasst nur zur Frequentistischen, nicht zur Bayesianischen Statistik\nPasst sowohl zur Frequentistischen, als auch zur Bayesianischen Statistik\n\nPasst weder zur Frequentistischen, noch zur Bayesianischen Statistik\n\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nPasst nur zur Bayesianischen, nicht zur Frequentistischen Statistik"
  },
  {
    "objectID": "posts/fofrage-regrformel2/index.html",
    "href": "posts/fofrage-regrformel2/index.html",
    "title": "fofrage-regrformel2",
    "section": "",
    "text": "1 Aufgabe\nBetrachten Sie folgende Forschungsformel:\n\nGibt es einen Interaktionseffekt zwischen Geschlecht und Schnabell√§nge auf das Gewicht eines Pinguins? Liegen auch Haupteffekte vor?\n\nAuf Basis der folgenden Analyse ist folgende Frage zu untersuchen. Liegt ein Interaktionseffekt vor?\nHinweise:\n\nUnter ‚ÄúHaupteffekt‚Äù versteht man den Effekt einer UV auf die AV (im Gegensatz zu einem Interaktionseffekt, der ja der gemeinsame Effekt mehrerer UV auf die AV ist).\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\nBeziehen Sie sich auf den Datensatz penguins.\n\n\nlibrary(palmerpenguins)\ndata(penguins)\n\npenguins &lt;-\n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\") |&gt; \n  drop_na()\n\n\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(rstanarm)\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nZur besseren Interpretierbarkeit sind die metrischen UV standardisiert:\n\npenguins_z &lt;- standardize(penguins, select = bill_length_mm, append = TRUE)\n\nEs werden verschiedenen Modelle berechnet, die sich in ihrem Regressionsformel unterscheiden:\n\nm1 &lt;- stan_glm(body_mass_g ~ sex, data = penguins_z, \n               refresh = 0)\nm2 &lt;- stan_glm(body_mass_g ~ sex + bill_length_mm_z, data = penguins_z, \n               refresh = 0)\nm3 &lt;- stan_glm(body_mass_g ~ sex + bill_length_mm_z + sex:bill_length_mm_z, data = penguins_z, \n               refresh = 0)\nm4 &lt;- stan_glm(body_mass_g ~ sex:bill_length_mm_z, data = penguins_z, \n               refresh = 0)\n\nParameter m1:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n3861.44\n(3746.15, 3976.46)\n100%\n0.999\n3744.00\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n685.48\n(527.35, 839.91)\n100%\n1.000\n3914.00\nNormal (0.00 +- 4020.19)\n\n\n\n\n\n\n\n\n\n\n\n\nParameter m2:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n3997.87\n(3902.86, 4100.09)\n100%\n1.000\n4352.00\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n404.20\n(260.25, 547.75)\n100%\n0.999\n4062.00\nNormal (0.00 +- 4020.19)\n\n\nbill_length_mm_z\n405.02\n(332.41, 474.78)\n100%\n0.999\n3912.00\nNormal (0.00 +- 2009.70)\n\n\n\n\n\n\n\n\n\n\n\n\nParameter m3:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4007.58\n(3901.18, 4109.34)\n100%\n1.001\n3112.00\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n403.51\n(261.36, 550.59)\n100%\n0.999\n3451.00\nNormal (0.00 +- 4020.19)\n\n\nbill_length_mm_z\n431.34\n(321.55, 539.94)\n100%\n0.999\n2423.00\nNormal (0.00 +- 2009.70)\n\n\nsexmale:bill_length_mm_z\n-49.99\n(-193.08, 96.77)\n75.12%\n1.000\n2370.00\nNormal (0.00 +- 2798.31)\n\n\n\n\n\n\n\n\n\n\n\n\nParameter m4:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4211.78\n(4134.77, 4286.61)\n100%\n1.000\n4260.00\nNormal (4207.06 +- 2013.04)\n\n\nsexfemale:bill_length_mm_z\n505.18\n(398.87, 614.19)\n100%\n1.000\n4807.00\nNormal (0.00 +- 3082.48)\n\n\nsexmale:bill_length_mm_z\n448.19\n(345.98, 543.46)\n100%\n1.000\n4955.00\nNormal (0.00 +- 2798.31)\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nDie Regressionsformel lautet: body_mass_g ~ sex + bill_length_mm + sex:bill_length_mm.\nDaher ist m3 korrekt.\nDie Parameterwerte von m3 zeigen, dass ein Interaktionseffekt nicht best√§tigt werden kann, bzw. dass die Null, also keine Interaktion, im Bereich plausibler Werte (d.h. innerhalb des Konfidenzintervalls) liegt."
  },
  {
    "objectID": "posts/warum-bayes/warum-bayes.html",
    "href": "posts/warum-bayes/warum-bayes.html",
    "title": "Warum-Bayes",
    "section": "",
    "text": "Exercise\nNennen Sie einen (fachlichen) Grund, warum Sie eine Bayes-Analyse machen w√ºrden (und nicht etwa ein Analyse auf Basis der frequentistischen Statistik).\nHinweise:\n\nZu sagen, ‚Äúmein Dozent hat mich gezwungen‚Äù ist zwar (vielleicht) bestechend ehrlich, aber nicht die Antwort, die wir suchen.\n\n         \n\n\nSolution\nEs existieren mehrere Gr√ºnde, einige wichtige sind:\n\nBayes-Analysen erlauben es, Vorwissen in die Analyse einflie√üen zu lassen.\nBayes-Analysen geben die Wahrscheinlichkeit einer Hypothese bzw. eines Parameterwerts zur√ºck.\nBayes-Analysen erlauben es, Modelle exakt und flexibel zu spezifizieren.\nBayes-Analysen sind bei kleineren Stichproben genauer.\n\n‚ÄúQuantifizierung‚Äù ist keine ausreichende Begr√ºndung f√ºr die Verwendung der Bayes-Statistik, da auch z.B. eine Frequentistische Analyse Quantifizierung bietet. Hingegen ist ‚ÄúQuantifizierung der Wahrscheinlichkeit der Forschungshypothese‚Äù ein valider Grund, denn der Frequentismus erlaubt nicht die Wahrscheinlichkeit einer Hypothese zu quantifizieren.\n‚ÄúWahrscheinlichkeitsaussagen‚Äù ist ebenfalls keine ausreichende Begr√ºndung f√ºr Bayes, denn auch im Frequentismus gibt es Wahrscheinlichkeitsaussagen, auch wenn diese weniger stark in die Wahrscheinlichkeitstheorie gekn√ºpft sind als die Bayes-Inferenz (vgl. Jaynes, 2003).\nEs ist als Begr√ºndung nicht ausreichend, z.B. von ‚ÄúErwartungen ans die Auswertung‚Äù zu sprechen, wenn man auf die Priori-Verteilung als (valider) Vorteil der Bayes-Inferenz abzielen m√∂chte.\nEbenso ist es nicht ausreichend, allgemein auf eine ‚Äúh√∂here Zuverl√§ssigkeit‚Äù o.√Ñ. der Bayes-Inferenz hinzuweisen.\nDas ROPE ist eine praktische, sinnvolle Methode, allerdings gibt es mittlerweile vergleichbare Verfahren im Frequentismus, sog. √Ñquivalenztests.\nDer Grund, warum Bayes-Analysen bei kleineren Stichproben zu genaueren Ergebnissen kommen, liegt im Priori-Wissen. Spezifiziert man z.B. eine Normalverteilung mit Sigma=1 und findet in den Daten einen Wert von zB. Sigma=6, also einen extremen Ausrei√üer, so wird die Priori-Verteilung daf√ºr sorgen, den Extremwert ‚Äúzurechtzustutzen‚Äù auf einen Wert n√§her der Mittelwert der Verteilung. Sofern dies sinnvoll/korrekt ist, wird man mit diesem Vorgehen zu genaueren Ergebnissen kommen. Die Hoffnung ist, dass einzelne Extremwerte eher Messfehler sind.\n\nCategories:\n\nqm2\nbayes\nprobability"
  },
  {
    "objectID": "posts/iq03/iq03.html",
    "href": "posts/iq03/iq03.html",
    "title": "iq03",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nPersonen mit einem Testwert von h√∂chstens 100 Punkten kann man als ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù bezeichnen.\nDefinieren wir also das Ereignis ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù als ‚Äúdie n√§chste Person, die Sie treffen, hat einen IQ von h√∂chstens 100 Punkten‚Äù.\nWie gro√ü ist die Wahrscheinlichkeit, dass die n√§chste Person, die Sie treffen, nicht √ºberdurchschnittlich intelligent ist?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^3\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nGeben Sie keine Prozentzahlen, sondern stets Anteile an.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd &lt;- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd= 15))\n\nDa \\(\\sigma=15\\), filtern wir bis h√∂chstens 100:\n\nsolution_d &lt;- \n  d %&gt;% \n  count(iq &lt;= 100) %&gt;% \n  mutate(prop = n / sum(n))\n\nsolution_d\n\n\n\n\n\niq &lt;= 100\nn\nprop\n\n\n\n\nFALSE\n485\n0.485\n\n\nTRUE\n515\n0.515\n\n\n\n\n\n\nL√∂sung: Die Wahrscheinlichkeit f√ºr ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù betr√§gt ca. 0.52.\nDas Ereignis ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù kann man vielleicht einfacher - und auf jeden Fall pr√§ziser benennen mit \\(iq \\le 100\\).\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/sentiws2/sentiws2.html",
    "href": "posts/sentiws2/sentiws2.html",
    "title": "sentiws2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie das sentiws Lexikon:\n\nlibrary(tidyverse)\nsentiws &lt;- read_csv(\"https://osf.io/x89wq/?action=download\")\n\nDie Spalte inflections birgt eine Reihe von Word-Varianten. Es scheint sinnvoll zu sein, diese W√∂rter zu nutzen. Aber um sie zu nutzen, muss man sie tokenisieren.\nAufgabe: Tokenisieren Sie die Tabelle sentiws, Spalte inflections.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nlibrary(tidytext)\n\n\nsenti_unnest &lt;- \nsentiws %&gt;% \n  unnest_tokens(input = inflections, output = word)\n\nDas ging einfach!\nNur die NAs sollten wir vielleicht noch entfernen.\n\nsentiws2 &lt;- \nsentiws %&gt;% \n  unnest_tokens(input = inflections, output = word) %&gt;% \n  drop_na(word)\n\n\nCategories:\n\ntextmining\ntokenizer\nstring"
  },
  {
    "objectID": "posts/bootstrap/bootstrap.html",
    "href": "posts/bootstrap/bootstrap.html",
    "title": "bootstrap",
    "section": "",
    "text": "In einer Analyse ist ein Team von Analysten interessiert, den Spritverbrauch von Fahrzeugen (gemessen in Meilen per Gallone mpg) in einem bestimmten Marksegment zu modellieren auf Basis der PS-Zahl (horse power, hp).\nDas Team analysiert die vorliegenden Daten des Trainings-Datensatzes und stellt folgendes Modell auf:\n\ndata(mtcars)\nlm1 &lt;- lm(mpg ~ hp, data = mtcars)\ncoef(lm1)\n\n(Intercept)          hp \n30.09886054 -0.06822828 \n\n\nDas Einflussgewicht des Pr√§diktors wird auf 0 gesch√§tzt.\nIm Testdatensatz wird nun der mittlere Verbrauch mittels Bootstrapping-Methode bestimmt. Es ergibt sich folgendes Diagramm:\n\n\n\n\n\n\n\n\n\nWelche Aussage l√§sst sich aus diesem Diagramm ableiten?\n\n\n\nDas 95%-Konfidenzintervall f√ºr den Einfluss von hp liegt ca. zwischen -0.10 und -0.05.\nDas 95%-Konfidenzintervall f√ºr den Einfluss von hp liegt bei ca. -0.07.\nDie resultierende Verteilung ist normalverteilt.\nEine Entscheidung zur statistischen Signifikanz des Pr√§diktors hp kann nicht abgeleitet werden."
  },
  {
    "objectID": "posts/bootstrap/bootstrap.html#answerlist",
    "href": "posts/bootstrap/bootstrap.html#answerlist",
    "title": "bootstrap",
    "section": "",
    "text": "Das 95%-Konfidenzintervall f√ºr den Einfluss von hp liegt ca. zwischen -0.10 und -0.05.\nDas 95%-Konfidenzintervall f√ºr den Einfluss von hp liegt bei ca. -0.07.\nDie resultierende Verteilung ist normalverteilt.\nEine Entscheidung zur statistischen Signifikanz des Pr√§diktors hp kann nicht abgeleitet werden."
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html",
    "title": "tidymodels-tree1",
    "section": "",
    "text": "library(tidymodels)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#setup",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#setup",
    "title": "tidymodels-tree1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\nlibrary(baguette)\n\nF√ºr Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#daten-teilen",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#daten-teilen",
    "title": "tidymodels-tree1",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#modelle",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#modelle",
    "title": "tidymodels-tree1",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())\n\nmod_bag &lt;-\n  bag_tree(mode = \"classification\",\n           cost_complexity = tune(),\n           tree_depth = tune(),\n           min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#rezepte",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#rezepte",
    "title": "tidymodels-tree1",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#resampling",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#resampling",
    "title": "tidymodels-tree1",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#workflows",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#workflows",
    "title": "tidymodels-tree1",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)\n\n\nwf_bag &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_bag)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#tuningfitting",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#tuningfitting",
    "title": "tidymodels-tree1",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\ntune_grid\n\nDa beide Modelle die gleichen Tuningparameter aufweisen, brauchen wir nur ein Grid zu erstellen.\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\nfit_tree\n\n\ntic()\nfit_bag &lt;-\n  tune_grid(object = wf_bag,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#bester-kandidat",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#bester-kandidat",
    "title": "tidymodels-tree1",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nshow_best(fit_tree)\n\n\nshow_best(fit_bag)\n\nBagging erzielte eine klar bessere Modellg√ºte (in den Validierungssamples) als das Entscheidungsbaum-Modell."
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#finalisieren",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#finalisieren",
    "title": "tidymodels-tree1",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nwf_best_finalized &lt;-\n  wf_bag %&gt;% \n  finalize_workflow(select_best(fit_bag))"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#last-fit",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#last-fit",
    "title": "tidymodels-tree1",
    "section": "Last Fit",
    "text": "Last Fit\n\nfinal_fit &lt;- \n  last_fit(object = wf_best_finalized, d_split)\n\ncollect_metrics(final_fit)\n\nWie man sieht, ist die Modellg√ºte im Test-Sample schlechter als in den Train- bzw. Validierungssamples; ein typischer Befund.\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nstring"
  },
  {
    "objectID": "posts/penguins-simpson/index.html",
    "href": "posts/penguins-simpson/index.html",
    "title": "penguins-simpson",
    "section": "",
    "text": "Laden Sie den Datensatz penguins (Palmerpenguins). Tipp: Es gibt ein R-Paket, in dem diese Daten wohnen. Im Skript QM2 finden sich diese Daten auch. Oder im weiten Internet.\n\n\n\n\nBerechnen Sie ein Modell, um den Zusammenhang zwischen Schnabeltiefe (UV) und K√∂rpergewicht (AV) statistisch zu sch√§tzen.\n\n\n\nTipp 1: estimate_relation() aus dem Paket easystats, s. QM1 oder QM2. Aber es gibt auch andere Wege.\nTipp 2: Fragen Sie ChatGPT.\n\n\n\nGeben Sie die Pr√§zision der Regressionskoeffizienten an. Interpretieren Sie das Ergebnis.\n\n\n\n\n\n\nBerechnen Sie folgendes Modell: Gewicht als Funktion von Schnabeltiefe und von Spezies\n\n\n\nwie oben\n\n\n\nVergleichen Sie die Pr√§zision der Regressionskoeffizienten mit dem Modell 1. Interpretieren Sie das Ergebnis."
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-1",
    "href": "posts/penguins-simpson/index.html#modell-1",
    "title": "penguins-simpson",
    "section": "",
    "text": "Berechnen Sie ein Modell, um den Zusammenhang zwischen Schnabeltiefe (UV) und K√∂rpergewicht (AV) statistisch zu sch√§tzen.\n\n\n\nTipp 1: estimate_relation() aus dem Paket easystats, s. QM1 oder QM2. Aber es gibt auch andere Wege.\nTipp 2: Fragen Sie ChatGPT.\n\n\n\nGeben Sie die Pr√§zision der Regressionskoeffizienten an. Interpretieren Sie das Ergebnis."
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-2-gewicht-als-funktion-von-schnabeltiefe-und-von-spezies",
    "href": "posts/penguins-simpson/index.html#modell-2-gewicht-als-funktion-von-schnabeltiefe-und-von-spezies",
    "title": "penguins-simpson",
    "section": "",
    "text": "Berechnen Sie folgendes Modell: Gewicht als Funktion von Schnabeltiefe und von Spezies\n\n\n\nwie oben\n\n\n\nVergleichen Sie die Pr√§zision der Regressionskoeffizienten mit dem Modell 1. Interpretieren Sie das Ergebnis."
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-1-1",
    "href": "posts/penguins-simpson/index.html#modell-1-1",
    "title": "penguins-simpson",
    "section": "2.1 Modell 1",
    "text": "2.1 Modell 1\nDaten importieren:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nAchtung: Das Paket muss installiert sein.\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nModell berechnen mit lm, d.h. ‚Äúfrequentistisch‚Äù:\n\nm1_freq &lt;- \n  lm(body_mass_g ~ bill_depth_mm, data = penguins)\n\nMit Bayes:\n\nlibrary(rstanarm)  # Paket muss installiert sein\nm1_bayes &lt;- \n  stan_glm(body_mass_g ~ bill_depth_mm, data = penguins,\n           refresh = 0)\n\nModellparameter:\n\nparameters(m1_freq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n7488.6524\n335.21782\n0.95\n6829.2904\n8148.0144\n22.339661\n340\n0\n\n\nbill_depth_mm\n-191.6428\n19.41698\n0.95\n-229.8353\n-153.4502\n-9.869853\n340\n0\n\n\n\n\n\n\nPro Millimeter Schnabeltiefe sinkt das Gewicht um knapp 200g, im Schnitt, laut Modell.\nDie Null ist NICHT im Sch√§tzbereich enthalten, also k√∂nnen wir die Hypothese, dass der Zusammenhang zwischen Schnabeltiefe und Gewicht 0 ist, verwerfen.\nWir entscheiden uns also zu glauben, dass es einen Zusammenhang gibt. Wir k√∂nnen nicht ganz sicher sein, aber das Modell bef√ºrwortet diese Entscheidung.\nAllerdings sind wir nicht sicher, ob das ein Scheinzusammenhang ist oder ein ‚Äúechter‚Äù, d.h. kausaler Zusammenhang.\n\nparameters(m1_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n7492.4114\n0.95\n6829.9136\n8164.6554\n1\n0.9997712\n3898.876\nnormal\n4201.754\n2004.886\n\n\nbill_depth_mm\n-191.6729\n0.95\n-230.8608\n-153.8502\n1\n0.9997105\n3867.976\nnormal\n0.000\n1015.239\n\n\n\n\n\n\nEin typischer Befund: Frequentistische und Bayes-Ergebnisse sind - bei gen√ºgend gro√üen Stichproben - sehr √§hnlich, was die Zahlen betrifft. Sehr unterschiedlich ist aber die Interpretation.\nBayes-Interpretation:\n‚ÄúMit 95% Wahrscheinlichkeit liegt der Effekt zwischen -230g und 150g pro Millimeter Schnabeltiefe, laut dem Modell.‚Äù\nFrequentistische Interpretation:\n‚ÄúW√ºrde man sehhhr viele Stichproben aus der zugrundeliegenden Population ziehen und f√ºr jede Stichprobe ein 95%-Konfindenzintervall berechnen w√ºrde, dann w√ºrde in 95% der F√§lle das wahre Populationsmittel in diesem Intervall liegen. In unserer konkreten Stichprobe lagen die Grenzen bei ca. -230 bis -150. Ob der wahre Wert in diesem bestimmten Intervall liegt, k√∂nnen wir aber nicht sagen.‚Äù\nModell visualisieren:\n\nestimate_relation(m1_freq) |&gt; plot()"
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-2",
    "href": "posts/penguins-simpson/index.html#modell-2",
    "title": "penguins-simpson",
    "section": "2.2 Modell 2",
    "text": "2.2 Modell 2\nModell berechnen mit lm, d.h. ‚Äúfrequentistisch‚Äù:\n\nm2_freq &lt;- \n  lm(body_mass_g ~ bill_depth_mm + species, data = penguins)\n\nMit Bayes:\n\nlibrary(rstanarm)  # Paket muss installiert sein\nm2_bayes &lt;- \n  stan_glm(body_mass_g ~ bill_depth_mm + species, data = penguins, refresh = 0)\n\nModellparameter:\n\nparameters(m2_freq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n-1007.28112\n323.56097\n0.95\n-1643.72793\n-370.8343\n-3.1131107\n338\n0.0020093\n\n\nbill_depth_mm\n256.61461\n17.56282\n0.95\n222.06840\n291.1608\n14.6112380\n338\n0.0000000\n\n\nspeciesChinstrap\n13.37732\n52.94712\n0.95\n-90.77005\n117.5247\n0.2526544\n338\n0.8006889\n\n\nspeciesGentoo\n2238.66811\n73.68183\n0.95\n2093.73542\n2383.6008\n30.3829071\n338\n0.0000000\n\n\n\n\n\nparameters(m2_bayes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n-1006.76639\n0.95\n-1629.69103\n-343.4282\n0.99875\n1.000287\n3014.707\nnormal\n4201.754\n2004.886\n\n\nbill_depth_mm\n256.53866\n0.95\n221.08996\n290.5195\n1.00000\n1.000239\n3060.064\nnormal\n0.000\n1015.239\n\n\nspeciesChinstrap\n13.05655\n0.95\n-91.14321\n115.5515\n0.60600\n1.000133\n3728.648\nnormal\n0.000\n5015.916\n\n\nspeciesGentoo\n2237.31299\n0.95\n2091.80848\n2381.4340\n1.00000\n1.000734\n3000.973\nnormal\n0.000\n4171.626\n\n\n\n\n\n\n√Ñh, Moment ‚Ä¶ Jetzt ist der Zusammenhang zwischen Schnabeltiefe und Gewicht nicht mehr negativ, sondern POSITIV?! Der Effekt geht in die entgegengesetzte Richtung? Kann das sein?!\nEin Bild zur Hilfe:\n\nm2_freq |&gt; estimate_relation() |&gt; plot()\n\n\n\n\n\n\n\n\nTats√§chlich! Jetzt ist der Zusammenhang innerhalb jeder Gruppe (Spezies) POSITIV.\nDas bedeutet: Wenn wir die Spezies ber√ºcksichtigen, dann ist der Zusammenhang zwischen Schnabeltiefe und Gewicht positiv.\nDiesen Vorzeichenwechsel nennt man ‚ÄúSimpson-Paradox‚Äù.\n\n2.2.1 Fazit: Welches Modell ist jetzt richtig?\nDa sich die Effekte komplett widersprechen (negativ vs.¬†positiver Zusammenhang) stellt sich die Frage: Welchem Modell - Modell 1 oder Modell 2 - glauben wir jetzt?\nDie Antwort ist ein klares: Kommt drauf an. Kommt drauf an, welcher Theorie zum kausalen Zusammenhang der betreffenden Variablen wir glauben."
  },
  {
    "objectID": "posts/Wertberechnen2/Wertberechnen2.html",
    "href": "posts/Wertberechnen2/Wertberechnen2.html",
    "title": "Wertberechnen2",
    "section": "",
    "text": "Aufgabe\nWelchen Wert bzw. welches Ergebnis liefert folgende R-Syntax f√ºr ergebnis zur√ºck?\nx hat zu Beginn den Wert 24.\nHinweise:\n\nsqrt(x) liefert die (positive) Quadratwurzel von x zur√ºck.\nx^2 liefert die zweite Potenz von x zur√ºck.\n\n\ny &lt;- 1\n\nx &lt;- x + y - 1\n\ny = x\n\ny &lt;- y * 2\n\nx &lt;- x + 1\n\nx &lt;- sqrt(x)\n\nergebnis &lt;- x^2\n\n         \n\n\nL√∂sung\nEs wird 25 zur√ºckgeliefert.\n\nCategories:\n\nR\ndyn\nnum"
  },
  {
    "objectID": "posts/there-is-no-package/there-is-no-package.html",
    "href": "posts/there-is-no-package/there-is-no-package.html",
    "title": "there-is-no-package",
    "section": "",
    "text": "Sie f√ºhren folgende R-Syntax aus:\nlibrary(tidyverse)\nUnd bekommen als Antwort eine Fehlermeldung quittiert:\nthere is no package called 'tidyverse'.\nWas ist die Ursache bzw. zu tun?\n\n\n\nEs existiert kein Paket namens tidyverse.\nEs existiert kein Paket namens tidyverse auf Ihrem Rechner.\nDas Paket tidyverse ist nicht gestartet.\nDas Paket tidyverse ist kaputt.\nR ist in Sie verliebt und versucht auf ungelenke Weise Kontakt aufzunehmen."
  },
  {
    "objectID": "posts/there-is-no-package/there-is-no-package.html#answerlist",
    "href": "posts/there-is-no-package/there-is-no-package.html#answerlist",
    "title": "there-is-no-package",
    "section": "",
    "text": "Es existiert kein Paket namens tidyverse.\nEs existiert kein Paket namens tidyverse auf Ihrem Rechner.\nDas Paket tidyverse ist nicht gestartet.\nDas Paket tidyverse ist kaputt.\nR ist in Sie verliebt und versucht auf ungelenke Weise Kontakt aufzunehmen."
  },
  {
    "objectID": "posts/there-is-no-package/there-is-no-package.html#answerlist-1",
    "href": "posts/there-is-no-package/there-is-no-package.html#answerlist-1",
    "title": "there-is-no-package",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nR\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/inferenz-fuer-alle/inferenz-fuer-alle.html",
    "href": "posts/inferenz-fuer-alle/inferenz-fuer-alle.html",
    "title": "inferenz-fuer-alle",
    "section": "",
    "text": "Exercise\nDie Inferenzstatistik ist eine Sammlung an Verfahren zur Bemessung von Unsicherheit in statistischen Schl√ºssen.\n\nF√ºr welche Statistiken - also Kennzahlen der Deskriptivstatistik wie etwa \\(\\bar{X}, sd, r\\) - kann man die Inferenzstatistik verwenden?\nF√ºr welche Forschungsfragen oder -bereiche kann man die Inferenzstatistik verwenden?\nGibt es besondere F√§lle, in denen man nicht die Inferenzstatistik verwenden m√∂chte? Wenn ja, welche?\n\n         \n\n\nSolution\n\nF√ºr (grunds√§tzlich) alle: F√ºr jede Statistik kann man prinzipiell von der jeweiligen Stichprobe (auf Basis derer die Statistik berechnet wurde) auf eine zugeh√∂rige Grundgesamtheit schlie√üen.\nF√ºr (grunds√§tzlich) alle: Die Methoden der Inferenzstatistik sind prinzipiell unabh√§ngig von den Spezifika bestimmter Forschungsfragen oder -bereiche. In den meisten Forschungsfragen ist man daran interessiert allgemeing√ºltige Aussagen zu treffen. Da Statistiken sich nur auf eine Stichprobe - also einen zumeist nur kleinen Teil einer Grundgesamtheit beziehen - wird man sich kaum mit einer Statistik zufrieden geben, sondern nach Inferenzstatistik verlangen.\nIn einigen Ausnahmef√§llen wird man auf eine Inferenzstatistik verzichten. Etwa wenn man bereits eine Vollerhebung durchgef√ºhrt hat, z.B. alle Mitarbeitis eines Unternehmens befragt hat, dann kennt man ja bereits den wahren Populationswert. Ein anderer Fall ist, wenn man nicht an Verallgemeinerungen interessiert ist: Kennt man etwa die √úberlebenschance \\(p\\) des Titanic-Ungl√ºcks, so ist es fraglich auf welche Grundgesamtheit man die Statistik \\(p\\) bzw. zu welchem Parameter \\(\\pi\\) (kleines Pi) man generalisieren m√∂chte.\n\n\nCategories:\n\nqm2\ninference"
  },
  {
    "objectID": "posts/rethink3e1-7-paper/index.html",
    "href": "posts/rethink3e1-7-paper/index.html",
    "title": "ReThink3e1-7-paper",
    "section": "",
    "text": "Aufgabe\nEs soll die Posteriori-Verteilung f√ºr den Globusversuch erstellt werden. Folgende Parameter wurden verwendet: \\(W=6, N = 9\\). F√ºr \\(\\pi\\) wurden alle Werte von 0 bis 1 mit einer Aufl√∂sung von 20 Parameterwerten.\nDaf√ºr wurde folgende Syntax verwendet.\n\np_grid &lt;- seq( from=0 , to=1 , length.out=20 )  # Gitterwerte\n\nprior &lt;- rep( 1 , 20 )  # Priori-Gewichte\n\nlikelihood &lt;- dbinom( 6 , size=9 , prob=p_grid ) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nHier ist die resultierende Bayesbox:\n\nbayesbox(hyps = p_grid, priors = prior, liks = likelihood)\n\n\n\n\n\nhyps\npriors\nliks\npost_unstand\npost_std\n\n\n\n\n0.0000000\n1\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0526316\n1\n0.0000015\n0.0000015\n0.0000008\n\n\n0.1052632\n1\n0.0000819\n0.0000819\n0.0000431\n\n\n0.1578947\n1\n0.0007773\n0.0007773\n0.0004091\n\n\n0.2105263\n1\n0.0035986\n0.0035986\n0.0018939\n\n\n0.2631579\n1\n0.0111609\n0.0111609\n0.0058739\n\n\n0.3157895\n1\n0.0266830\n0.0266830\n0.0140429\n\n\n0.3684211\n1\n0.0529211\n0.0529211\n0.0278517\n\n\n0.4210526\n1\n0.0908270\n0.0908270\n0.0478012\n\n\n0.4736842\n1\n0.1383413\n0.1383413\n0.0728074\n\n\n0.5263158\n1\n0.1897686\n0.1897686\n0.0998730\n\n\n0.5789474\n1\n0.2361147\n0.2361147\n0.1242643\n\n\n0.6315789\n1\n0.2666113\n0.2666113\n0.1403143\n\n\n0.6842105\n1\n0.2714006\n0.2714006\n0.1428349\n\n\n0.7368421\n1\n0.2450051\n0.2450051\n0.1289433\n\n\n0.7894737\n1\n0.1897686\n0.1897686\n0.0998730\n\n\n0.8421053\n1\n0.1179181\n0.1179181\n0.0620589\n\n\n0.8947368\n1\n0.0502667\n0.0502667\n0.0264548\n\n\n0.9473684\n1\n0.0088538\n0.0088538\n0.0046597\n\n\n1.0000000\n1\n0.0000000\n0.0000000\n0.0000000\n\n\n\n\n\n\nDann wurde die Stichproben-Posterior-Verteilung erstellt:\n\n# um die Zufallszahlen festzulegen, damit wir alle die gleichen Zahlen bekommen zum Schnluss: \nset.seed(42) \n\n# Stichproben ziehen aus der Posteriori-Verteilung\nsamples &lt;- \n  tibble(\n    p = sample( p_grid , prob=posterior, size=1e4, replace=TRUE)) \n\nHier ist eine Visualisierung der Posteriori-Verteilung:\n\n\n\n\n\n\n\n\n\nAufgaben:\nSch√§tzen Sie die Werte zu den folgenden Aufgaben aus der Visualisierung der Post-Veteilung ab!\n\nWie viel Wahrscheinlichkeitsmasse liegt unter \\(p=0.2\\)?\nWie viel Wahrscheinlichkeitsmasse liegt √ºber \\(p=0.9\\)?\nWelcher Anteil der Posteriori-Verteilung liegt zwischen \\(p=0.2\\) und \\(p=0.9\\)?\nUnter welchem Wasseranteil \\(p\\) liegen 50% der Posteriori-Verteilung?\n√úber welchem Wasseranteil \\(p\\) liegen 10% der Posteriori-Verteilung?\nWelches schm√§lstes Intervall von \\(p\\) enth√§lt 90% der Posteriori-Wahrscheinlichkeit? W√§hlen Sie das Intervall der folgenden, das am besten passt: \\([.1, .9], [.5,.7], [.3,.8]\\)\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nSolution\nEs finden sich auch L√∂sungsvorschl√§ge online, z.B. hier\n\nWie viel Wahrscheinlichkeitsmasse liegt unter \\(p=0.2\\)?\n\nFast nix, wie man im Diagramm sieht.\nAu√üerdem kann man nachrechnen:\n\nsamples %&gt;% \n  count(p &lt; 0.2)\n\n\n\n\n\np &lt; 0.2\nn\n\n\n\n\nFALSE\n9995\n\n\nTRUE\n5\n\n\n\n\n\n\n\nWie viel Wahrscheinlichkeitsmasse liegt √ºber \\(p=0.9\\)?\n\nFast nix, wie man im Diagramm sieht!\n\nsamples %&gt;% \n  count(p &gt; 0.9)\n\n\n\n\n\np &gt; 0.9\nn\n\n\n\n\nFALSE\n9954\n\n\nTRUE\n46\n\n\n\n\n\n\nNaja, so gut 1%!\n\nWelcher Anteil der Posteriori-Verteilung liegt zwischen \\(p=0.2\\) und \\(p=0.9\\)?\n\nKnapp 99%, wie man aus den vorherigen Aufgaben ableiten kann oder sich hier nocheinmal √ºberlegen kann.\nWer nachrechnen (bzw. nachz√§hlen) will:\n\nsamples %&gt;% \n  count(p &gt; 0.2 & p &lt; 0.9) \n\n\n\n\n\np &gt; 0.2 & p &lt; 0.9\nn\n\n\n\n\nFALSE\n51\n\n\nTRUE\n9949\n\n\n\n\n\n\n\nUnter welchem Wasseranteil \\(p\\) liegen 50% der Posteriori-Verteilung?\n\nPuh, das geht optisch nur grob. Gef√ºhlt so bei p = .65\nWer es genauer will: Eine M√∂glichkeit: Wir sortieren \\(p\\) der Gr√∂√üe nach (aufsteigend), filtern dann so, dass wir nur die ersten 20% der Zeilen behalten und schauen dann, was der gr√∂√üte Wert ist.\n\nsamples %&gt;% \n  arrange(p) %&gt;% \n  slice_head(prop = 0.5) %&gt;% \n  summarise(quantil_20 = max(p))\n\n\n\n\n\nquantil_20\n\n\n\n\n0.6315789\n\n\n\n\n\n\nAndererseits: Das, was wir gerade gemacht haben, nennt man auch ein Quantil berechnen, s. auch hier. Daf√ºr gibt‚Äôs fertige Funktionen in R, wie quantile():\n\nsamples %&gt;% \n  summarise(q_20 = quantile(p, 0.2))\n\n\n\n\n\nq_20\n\n\n\n\n0.5263158\n\n\n\n\n\n\n\n√úber welchem Wasseranteil \\(p\\) liegen 10% der Posteriori-Verteilung?\n\nWieder ist das optisch nicht so leicht. Aber grob gesagt, so bei p = .8 vielleicht.\nHier die genaue Antwort:\n\nsamples %&gt;% \n  summarise(quantile(p, 0.9))\n\n\n\n\n\nquantile(p, 0.9)\n\n\n\n\n0.7894737\n\n\n\n\n\n\nMit 90% Wahrscheinlichkeit ist der Wasseranteil h√∂chstens bei 81%.\n\nWelches schm√§lstes Intervall von \\(p\\) enth√§lt 90% der Posteriori-Wahrscheinlichkeit? W√§hlen Sie das Intervall der folgenden, das am besten passt: \\([.1, .9], [.5,.7], [.3,.8]\\)\n\n\\([.3,.8]\\) passt optisch am besten.\nF√ºr Detail-Freunde:\n\nlibrary(easystats)\nhdi(samples, ci = 0.90)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np\n0.9\n0.4210526\n0.8421053\n\n\n\n\n\n\n\nCategories:\n\nbayes\nprobability\npost"
  },
  {
    "objectID": "posts/wikipedia/index.html",
    "href": "posts/wikipedia/index.html",
    "title": "wikipedia",
    "section": "",
    "text": "1 Aufgabe\nIn Ihrem Buch ‚ÄúActive Statistics‚Äù beschreiben die Autoren eine Studie der Wikipedia-Organisation (Gelman & Vehtari, 2024), vgl. S. 33f.\nIn der Studie - ein kontrolliertes Experiment, auch ‚ÄúA/B-Test‚Äù genannt - wurde der Effekt von abgerundeten vs.¬†quadratischen Ecken von Textboxen auf die Spendenbereitschaft untersucht (s. Abb. 2, S. 34). (Das Buch ist kostenfrei auf der Webseite zum Buch erh√§ltlich.)\nRunde Ecken: \nQuadratische Ecken: \nDas Wikipedia-Team gab folgende Stichprobengr√∂√üen an:\n\nn_control_group &lt;- 954630  # runde Ecken\nn_exp_group &lt;- 1082180  # quadratische Ecken\nn_total &lt;- n_control_group + n_exp_group\n\nDamit liegt der Anteil der Experimentalgruppe am Gesamtstichprobenumfang bei 53%:\n\nn_exp_group / n_total\n\n[1] 0.5313112\n\n\nWie hoch ist die Wahrscheinlichkeit, einen so gro√üen, d.h. 53% vs.¬†47%, (oder noch gr√∂√üeren) Unterschied in den Umf√§ngen der beiden Stichproben zu erhalten, unter der Annahme einer zuf√§lligen Aufteilung?\nHinweise:\n\nNutzen Sie Simulationstechniken.\nDie Wahrscheinlichkeit ist auf 2 Dezimalen zu runden.\n\n\n\n2 L√∂sung\n\nlibrary(tidyverse)\nlibrary(ggpubr)  # Visualisierung\n\nWir f√ºhren probehalber den Versuch einmal durch. Hat jemand mal eben zwei Millionen M√ºnzen? Anstelle von M√ºnzen k√∂nnen wir auch den Computer nutzen.\nWir bezeichnen die beiden Ausg√§nge des M√ºnzwurfexperiments mit 0 (Kontrollgruppe) und 1 (Experimentalgruppe). Eine 1 bedeutet also, dass eine Person der Experimentalgruppe zugeordnet wurde und eine 0, dass sie der Kontrollgruppe zugeordnet wurde.\nDen M√ºnzwurf wiederholen wir n_total Mal:\n\nset.seed(42)  # Zufallszahlen festlegen, zur Reproduzierbarkeit\nwikipedia_experiment &lt;- sample(\n  x = c(0,1),  # Ergebnisraum\n  size = n_total,  # Anzahl der M√ºnzen\n  replace = TRUE)  # Ziehen mit Zur√ºcklegen\n\nMit sample k√∂nnen wir Stichproben ziehen, z.B. von M√ºnzw√ºrfen.\nDas Ergebnis ist ein lange Reihe von 0 und 1, die die jeweiligen Ergebnisse der M√ºnzw√ºrfe darstellt. Hier sind die ersten paar Ergebnisse:\n\nhead(wikipedia_experiment, n = 20)\n\n [1] 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1\n\n\nWenn wir jetzt den Mittelwert berechnen, haben wir damit den Anteil der Experimentalgruppe an der Gesamtstichprobe:\n\nanteil_exp_gruppe &lt;- mean(wikipedia_experiment)\nanteil_exp_gruppe\n\n[1] 0.5002185\n\n\nSehr nah dran an der exakten H√§lfte! Dieser Versuchsausgang spricht dagegen, dass 53% dass Ergebnis einer Zufallsaufteilung (in Experimental- und Kontrollgruppe) ist. Aber vielleicht war es nur Pech bzw. Gl√ºck? Vielleicht w√ºrde das Experiment, wenn wir nochmal die ca. 2 Millionen M√ºnzen werfen, zu einem ganz anderen Ergebnis kommen?\nProbieren wir es aus! Wir wiederholen das Experiment sagen wir n_reps = 100 Mal und notieren jedes Mal den Anteil der Experimentalgruppe am Stichprobenumfang.\n\nn_reps &lt;- 100\n\nDazu hilft die Funktion replicate, die die M√ºnzwurf (Funktion sample plus (danach) mean) beliebig oft wiederholt:\n\nset.seed(42)\nviele_versuche &lt;- replicate(n_reps, \n                            sample(x = c(0,1), \n                                   size = n_total,\n                                   replace = TRUE) |&gt; \n                              mean())\n\nHier sind die Ergebnisse:\n\nviele_versuche\n\n  [1] 0.5002185 0.5001561 0.5004016 0.4997148 0.4999867 0.4998606 0.5006157\n  [8] 0.4999214 0.4997987 0.5005185 0.5001198 0.5008940 0.4995905 0.4995876\n [15] 0.5000462 0.5000658 0.5000570 0.5002308 0.5000756 0.5002509 0.4999126\n [22] 0.4995596 0.4996062 0.4993976 0.5003250 0.5002921 0.5004021 0.4996809\n [29] 0.5000844 0.4997948 0.4999995 0.5002170 0.5000025 0.5005086 0.4999362\n [36] 0.5003211 0.5008872 0.4996401 0.4998296 0.5004311 0.5002288 0.4998660\n [43] 0.4993681 0.4996784 0.5001031 0.4996779 0.5003638 0.4997722 0.4999656\n [50] 0.4993347 0.4998650 0.4998871 0.5000128 0.5000786 0.5005307 0.5001576\n [57] 0.5000417 0.4998424 0.4998449 0.4998606 0.5005715 0.5002686 0.4999651\n [64] 0.5001060 0.4996313 0.5003024 0.5000948 0.5005975 0.5002897 0.4995689\n [71] 0.5002278 0.4997894 0.5002254 0.5000304 0.4998719 0.5005464 0.4998012\n [78] 0.4998714 0.4999396 0.4999008 0.4995149 0.5001267 0.5003800 0.4999273\n [85] 0.4995100 0.5000584 0.5000172 0.5005818 0.5003000 0.4997800 0.4999887\n [92] 0.4998915 0.5001939 0.4997683 0.4999651 0.4996475 0.5001630 0.4998046\n [99] 0.5006564 0.4997820\n\n\nEin paar Statistiken dazu:\n\nmean(viele_versuche)\n\n[1] 0.5000308\n\nsd(viele_versuche)\n\n[1] 0.0003243425\n\nmedian(viele_versuche)\n\n[1] 0.5000076\n\nIQR(viele_versuche)\n\n[1] 0.0004255429\n\n\nWie man sieht, ist die Streuung sehr gering: Alle Ergebnisse streuen sehr eng um 1/2 (50%). Von 3 Prozentpunkten Abweichung ist nichts zu sehen.\nVielleicht ist es n√ºtzlich, wenn man diesen Vektor (viele_versuche) visualisiert, z.B. mit einem Histogramm aus ggpubr.\nDie Daten ben√∂tigen wir dazu als Dataframe:\n\nd &lt;- tibble(viele_versuche)\n\nglimpse(d)\n\nRows: 100\nColumns: 1\n$ viele_versuche &lt;dbl&gt; 0.5002185, 0.5001561, 0.5004016, 0.4997148, 0.4999867, ‚Ä¶\n\n\n\ngghistogram(d, x = \"viele_versuche\",\n            add = \"mean\")\n\n\n\n\n\n\n\n\nHier noch ein Dichtediagramm, da sieht man die Verteilungsform besser:\n\nggdensity(d, x = \"viele_versuche\")\n\n\n\n\n\n\n\n\nUnter der Annahme einer Normalverteilung (was man als hinreichend gegeben betrachten kann), liegen ca. 95% der Werte zwischen MW ¬± 2 sd, bzw. ca. 99% nicht weiter als 3 sd vom MW entfernt.\nFazit: Unsere Simulation zeigt, dass die Wahrscheinlichkeit f√ºr einen Stichprobenanteil von 53% sehr klein ist, kleiner als 1 von 100 in unserer Simulation (1%) und vermutlich noch deutlich kleiner als 1%.\nWir k√∂nnen daraus schlie√üen, dass die Zufallszuteilung (Randomisierung) nicht richtig funktioniert hat. H√§tte sie funktioniert, w√§re eine Aufteilung von 53% zu 47% kaum zu erwarten gewesen.\nAnders gesagt verwerfen wir die (Null-)Hypothese einer zuf√§lligen Zuteilung zu den Gruppen.\n\n\n\n\n\n\n\nReferences\n\nGelman, A., & Vehtari, A. (2024). Active statistics: Stories, games, problems, and hands-on demonstrations for applied regression and causal inference (1st ed.). Cambridge University Press. https://doi.org/10.1017/9781009436243"
  },
  {
    "objectID": "posts/germeval03/germeval03.html",
    "href": "posts/germeval03/germeval03.html",
    "title": "germeval03-sent-textfeatures-rand-for",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon."
  },
  {
    "objectID": "posts/germeval03/germeval03.html#workflow",
    "href": "posts/germeval03/germeval03.html#workflow",
    "title": "germeval03-sent-textfeatures-rand-for",
    "section": "Workflow",
    "text": "Workflow\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"classification\")\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  update_role(text, new_role = \"ignore\") |&gt; \n  step_mutate(n_emo = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = sentiws))  |&gt; \n  step_rm(text)  # Datensatz verschlanken\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval03/germeval03.html#fit",
    "href": "posts/germeval03/germeval03.html#fit",
    "title": "germeval03-sent-textfeatures-rand-for",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;-\n  fit(wf1,\n      data = d_train)\ntoc()\nbeep()\n\n\nfit1"
  },
  {
    "objectID": "posts/germeval03/germeval03.html#test-set-g√ºte",
    "href": "posts/germeval03/germeval03.html#test-set-g√ºte",
    "title": "germeval03-sent-textfeatures-rand-for",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nsentiment\nstring"
  },
  {
    "objectID": "posts/alphafehler-inflation4/alphafehler-inflation4.html",
    "href": "posts/alphafehler-inflation4/alphafehler-inflation4.html",
    "title": "alphafehler-inflation4",
    "section": "",
    "text": "Aufgabe\nEine Klettererin verwendet ein Seil, dass eine Sicherheit von \\(r=.99\\) hat: mit einer Wahrscheinlichkeit von 1% rei√üt das Seil. Jetzt kn√ºpft sie mehrere dieser Seile (hintereinander, Seil an Seil) zusammen zu einem ‚ÄúGesamtseil‚Äù. Wie gro√ü ist die Gefahr, dass das ‚ÄûGesamtseil‚Äú reist?\nHinweise:\n\nEtwaige (physikalisch plausible) Verringerung der Zugfestigkeit durch (Seilbiegung aufgrund der) Knoten ist zu vernachl√§ssigen.\nUnterstellen Sie Unabh√§ngkeit der einzelnen Ereignisse.\nWie immer, beachten sie die √ºbrigen Hinweise des Datenwerks.\n\nBetrachten wir mehrere F√§lle:\n\nSie kn√ºpft 2 zusammen.\nSie kn√ºpft 5 zusammen.\nSie kn√ºpft 10 zusammen.\nSie kn√ºpft 20 zusammen.\n\n         \n\n\nL√∂sung\nSei \\(R\\) die Wahrscheinlichkeit, dass das Gesamtseil h√§lt (nicht rei√üt). \\(1-R\\) ist dann die Wahrscheinlichkeit des Gegenereignisses: das Gesamtseil rei√üt.\nAllgemein ist \\(R\\) bei k Tests gleich r hoch k: \\(R=r^k\\). (Das Aufaddieren der Fehlalarm-Wahrscheinlichkeit bezeichnet man als Alphafehler-Inflation.)\n\nlibrary(tidyverse)\nr &lt;- .99\nR2 &lt;- r^2 %&gt;% round(2)  # Auf 2 Dezimalen runden\nR5  &lt;- r^5  %&gt;% round(2)\nR10 &lt;- r^10  %&gt;% round(2)\nR20 &lt;- r^20  %&gt;% round(2)\n\nDie Gesamtsicherheiten lauten also:\n\nR2\n\n[1] 0.98\n\nR5\n\n[1] 0.95\n\nR10\n\n[1] 0.9\n\nR20\n\n[1] 0.82\n\n\nDie Seilriss-Gefahr ist dann:\n\n1 - R2\n\n[1] 0.02\n\n1 - R5\n\n[1] 0.05\n\n1 - R10\n\n[1] 0.1\n\n1 - R20\n\n[1] 0.18\n\n\n\n\nVertiefung\nBetrachten wir abschlie√üend aus Neugier die Wahrscheinlichkeit, dass die Klettererin abst√ºrzt (\\(1-R\\)) als Funktion der Anzahl der Seie.\nDiese √úberlegung ist etwas weiterf√ºhrender und nicht ganz so zentral, aber ziemlich interessant.\nDefinieren wir die Parameter:\n\nanz_seile &lt;- 1:20  # von 1 bis max 20 Seile\nr &lt;- c(.9, .95, .99, .999)  # verschiedene Seil-Sicherheiten\n\nJetzt erstellen wir einen Tabelle, die alle anz_seile * r Werte kombiniert:\n\nd &lt;- \n  expand_grid(anz_seile, r)\n\nhead(d)\n\n\n\n\n\nanz_seile\nr\n\n\n\n\n1\n0.900\n\n\n1\n0.950\n\n\n1\n0.990\n\n\n1\n0.999\n\n\n2\n0.900\n\n\n2\n0.950\n\n\n\n\n\n\nJetzt berechnen wir f√ºr jede Kombination die Gesamtsicherheit R sowie die Wahrscheinlichkeit, dass das Seil rei√üt, \\(1-R\\):\n\nd &lt;-\n  d %&gt;% \n  mutate(R = r^anz_seile,\n         seil_reisst_prob = 1 - R)\n\nUnd plotten das Ganze mit dem Paket ggpubr:\n\nlibrary(ggpubr)\nd &lt;-\n  d |&gt; \n  mutate(r_fctr = factor(r))  # um \"r\" zum Gruppieren zu verwenden, sollte es eine nominale Variable sein, daher wandeln wir mit \"factor\" in eine nominale Variable um.\n\nggline(d,\n       x = \"anz_seile\",\n       y = \"seil_reisst_prob\",\n       color = \"r_fctr\",\n       linetype = \"r_fctr\",\n       group = \"r_fctr\") +\n  labs(color = \"Rei√üfestigkeit\",\n       linetype = \"Rei√üfestigkeit\")\n\n\n\n\n\n\n\n\nOder mit ggplot plotten:\n\nd %&gt;% \n  ggplot(aes(x = anz_seile,\n             y = seil_reisst_prob,\n             color = factor(r))) +\n  geom_line() +\n  labs(color = \"Rei√üfestigkeit\")\n\n\n\n\n\n\n\n\nHat ein Seil eine Sicherheit von 90%, dann will man nicht dranh√§ngen, wenn 20 Seile zusammengeknotet sind!\nAntworten:\n\n\\(R_2 = r\\cdot r = r^2 = 0.98\\)\n\\(R_5 =  r^5 = 0.95\\)\n\\(R_{10}= r^{10} = 0.9\\)\n\\(R_{20}= r^{20} = 0.82\\)\n\n\nCategories:\n\nprobability\nR\ninference\nstring"
  },
  {
    "objectID": "posts/tidydata1/tidydata1.html",
    "href": "posts/tidydata1/tidydata1.html",
    "title": "tidydata1",
    "section": "",
    "text": "Laden Sie die folgende Tabellen mit folgendem Befehl aus dem Paket tidyverse:\n\ntable1_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tidy-table1.csv\"\ntable1 &lt;- read_csv(table1_path)\n\nInsgesamt sollten Sie als folgende Tabellen in Ihrem environment verf√ºgbar haben:\n\ntable1\ntable2\ntable3\ntable4\ntable5\n\nWelche der Tabellen ist in der Normalform?\n\n\n\ntable1\ntable2\ntable3\ntable4\ntable5"
  },
  {
    "objectID": "posts/tidydata1/tidydata1.html#answerlist",
    "href": "posts/tidydata1/tidydata1.html#answerlist",
    "title": "tidydata1",
    "section": "",
    "text": "table1\ntable2\ntable3\ntable4\ntable5"
  },
  {
    "objectID": "posts/tidydata1/tidydata1.html#answerlist-1",
    "href": "posts/tidydata1/tidydata1.html#answerlist-1",
    "title": "tidydata1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndatawrangling\ntidy\nschoice"
  },
  {
    "objectID": "posts/Typ-Fehler-R-01/Typ-Fehler-R-01.html",
    "href": "posts/Typ-Fehler-R-01/Typ-Fehler-R-01.html",
    "title": "Typ-Fehler-R-01",
    "section": "",
    "text": "Aufgabe\nKorrigieren Sie den Fehler in der Syntax:\n\nmean(x = c(1, 5, 10, 52)\n\n√Ñndern Sie nur diejenigen Teile der Syntax, die zwingend ge√§ndert werden m√ºssen, damit der Fehler korrigiert wird.\nGeben Sie in der L√∂sung keine Leerzeichen ein.\n         \n\n\nL√∂sung\n\nmean(x=c(1,5,10,52))\n\n[1] 17\n\n\nDie Antwort lautet: mean(x=c(1,5,10,52)).\n\nCategories:\n\nR\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/korr-als-regr/korr-als-regr.html",
    "href": "posts/korr-als-regr/korr-als-regr.html",
    "title": "korr-als-regr",
    "section": "",
    "text": "options(digits=2)\noptions(width = 80)\n\n\nAufgabe\nDie Korrelation pr√ºft, ob bzw. inwieweit zwei Merkmale linear zusammenh√§ngen.\nWie viele andere Verfahren kann die Korrelation als ein Spezialfall der Regression bzw. des linearen Modells \\(y = \\beta_0 + \\beta_1 + \\ldots \\beta_n + \\epsilon\\) betrachtet werden.\nAls ein spezielles Beispiel betrachten wir die Frage, ob das Gewicht eines Diamanten (carat) mit dem Preis (price) zusammenh√§ngt (Datensatz diamonds).\nDen Datensatz k√∂nnen Sie so laden:\n\nlibrary(tidyverse)\ndata(diamonds)\n\n\nGeben Sie das Skalenniveau beider Variablen an!\nBetrachten Sie die Ausgabe von R:\n\n\nlm1 &lt;- lm(price ~ carat, data = diamonds)\nsummary(lm1)\n\n\nCall:\nlm(formula = price ~ carat, data = diamonds)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-18585   -805    -19    537  12732 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2256.4       13.1    -173   &lt;2e-16 ***\ncarat         7756.4       14.1     551   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1550 on 53938 degrees of freedom\nMultiple R-squared:  0.849, Adjusted R-squared:  0.849 \nF-statistic: 3.04e+05 on 1 and 53938 DF,  p-value: &lt;2e-16\n\n\nWie (bzw. wo) ist aus dieser Ausgabe die Korrelation herauszulesen?\n\nMacht es einen Unterschied, ob man Preis mit Karat bzw. Karat mit Preis korreliert?\nIn der klassischen Inferenzstatistik ist der \\(p\\)-Wert eine zentrale Gr√∂√üe; ist er klein (\\(p&lt;.05\\)) so nennt man die zugeh√∂rige Statistik signifikant und verwirft die getestete Hypothese.\nIm Folgenden sehen Sie einen Korrelationstest auf statistische Signifikanz, mit R durchgef√ºhrt. Zeigt der Test ein (statistisch) signifikantes Ergebnis? Wie gro√ü ist der ‚ÄúUnsicherheitskorridor‚Äù, um den Korrelationswert (zugleich Punktsch√§tzer f√ºr den Populationswert)?\n\n\nlibrary(easystats)\ndiamonds %&gt;% \n  sample_n(30) %&gt;% \n  select(price, carat) %&gt;% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nprice\ncarat\n0.97\n0.95\n0.94\n0.99\n21\n28\n0\nPearson correlation\n30\n\n\n\n\n\n\n         \n\n\nL√∂sung\n\ncarat ist metrisch (verh√§ltnisskaliert) und price ist metrisch (verh√§ltnisskaliert)\n\\(R^2\\) kann bei einer einfachen (univariaten) Regression als das Quadrat von \\(r\\) berechnet werden. Daher \\(r = \\sqrt{R^2}\\).\n\n\nsqrt(0.8493)\n\n[1] 0.92\n\n\nZum Vergleich\n\ndiamonds %&gt;% \n  summarise(r = cor(price, carat))\n\n\n\n\n\nr\n\n\n\n\n0.92\n\n\n\n\n\n\nMan kann den Wert der Korrelation auch noch anderweitig berechnen (\\(\\beta\\) umrechnen in \\(\\rho\\)).\n\nNein. Die Korrelation ist eine symmetrische Relation.\nJa; die Zahl ‚Äú3.81e-14‚Äù bezeichnet eine positive Zahl kleiner eins mit 13 Nullern vor der ersten Ziffer, die nicht Null ist (3.81 in diesem Fall). Der ‚ÄúUnsicherheitskorridor‚Äù reicht von etwa 0.87 bis 0.97.\n\n\nCategories:\n\ncorrelation\nlm\nregression\nstring"
  },
  {
    "objectID": "posts/germeval04/germeval04.html",
    "href": "posts/germeval04/germeval04.html",
    "title": "germeval04",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon."
  },
  {
    "objectID": "posts/germeval04/germeval04.html#finalisieren",
    "href": "posts/germeval04/germeval04.html#finalisieren",
    "title": "germeval04",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nfit1_best &lt;- select_best(wf1_fit)\n\n\nwf1_final &lt;- finalize_workflow(wf1, fit1_best)\nwf1_final_fit &lt;- fit(wf1_final, data = d_train)\n\nVorhersagen:\n\npreds &lt;- predict(wf1_final_fit, germeval_test)"
  },
  {
    "objectID": "posts/germeval04/germeval04.html#test-set-g√ºte",
    "href": "posts/germeval04/germeval04.html#test-set-g√ºte",
    "title": "germeval04",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval04/germeval04.html#fazit",
    "href": "posts/germeval04/germeval04.html#fazit",
    "title": "germeval04",
    "section": "Fazit",
    "text": "Fazit\nEine Reihe der Text-Features passen nicht gut auf nicht-englische Texte.\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nsentiment\nstring"
  },
  {
    "objectID": "posts/mariokart-korr2/mariokart-korr2.html",
    "href": "posts/mariokart-korr2/mariokart-korr2.html",
    "title": "mariokart-korr2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Filtern Sie die neuen Spiele. Berechnen Sie die Korrelation von Verkaufspreis (total_pr) und Startgebot (start_pr)!\nHinweise:\n\nRunden Sie auf 2 Dezimalstellen.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\nOder so:\n\ndata(mariokart, package = \"openintro\")\n\n\nsolution &lt;- \nd  %&gt;% \n  filter(cond == \"new\") %&gt;% \n  summarise(pr_cor = cor(total_pr, start_pr))\nsolution\n\n\n\n\n\npr_cor\n\n\n\n\n0.405102\n\n\n\n\n\n\nAlternativ kann man (komfortabel) die Korrelation z.B. so berechnen:\n\nd %&gt;% \n  select(start_pr, total_pr, cond) %&gt;% \n  filter(cond == \"new\") %&gt;% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nstart_pr\ntotal_pr\n0.405102\n0.95\n0.1662683\n0.5990402\n3.345235\n57\n0.001459\nPearson correlation\n59\n\n\n\n\n\n\nL√∂sung: 0.41.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nassociation\nnum"
  },
  {
    "objectID": "posts/Regr-Bayes-interpret03a/Regr-Bayes-interpret03a.html",
    "href": "posts/Regr-Bayes-interpret03a/Regr-Bayes-interpret03a.html",
    "title": "Regr-Bayes-interpret03a",
    "section": "",
    "text": "Exercise\nBerechnen Sie das Modell und interpretieren Sie die Ausgabe des folgenden Regressionsmodells. Geben Sie f√ºr jeden Regressionskoeffizienten an, wie sein Wert zu verstehen ist! Interpretieren Sie auch die Interaktion.\nmpg_z ~ hp_z + am + hp_z:am\nHinweise:\n\nFixieren Sie die Zufallszahlen.\nVerwenden Sie Stan zur Berechnung.\nRunden Sie auf 2 Dezimalstellen.\nDas Suffix _z steht f√ºr z-standardisierte Variablen.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Stan, komm her\nlibrary(easystats)  # Komfort\n\ndata(mtcars)\n\nZuerst standardisieren wir die Daten:\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nmtcars2  %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.090625\n6.0269481\n7.525000\n10.4000000\n33.900000\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl\n6.187500\n1.7859216\n4.000000\n4.0000000\n8.000000\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp\n230.721875\n123.9386938\n221.525000\n71.1000000\n472.000000\n0.4202331\n-1.0675234\n32\n0\n\n\nhp\n146.687500\n68.5628685\n84.500000\n52.0000000\n335.000000\n0.7994067\n0.2752116\n32\n0\n\n\ndrat\n3.596563\n0.5346787\n0.840000\n2.7600000\n4.930000\n0.2927802\n-0.4504325\n32\n0\n\n\nwt\n3.217250\n0.9784574\n1.186250\n1.5130000\n5.424000\n0.4659161\n0.4165947\n32\n0\n\n\nqsec\n17.848750\n1.7869432\n2.022500\n14.5000000\n22.900000\n0.4063466\n0.8649307\n32\n0\n\n\nvs\n0.437500\n0.5040161\n1.000000\n0.0000000\n1.000000\n0.2645418\n-2.0632731\n32\n0\n\n\nam\n0.406250\n0.4989909\n1.000000\n0.0000000\n1.000000\n0.4008089\n-1.9665503\n32\n0\n\n\ngear\n3.687500\n0.7378041\n1.000000\n3.0000000\n5.000000\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb\n2.812500\n1.6152000\n2.000000\n1.0000000\n8.000000\n1.1570911\n2.0200593\n32\n0\n\n\nmpg_z\n0.000000\n1.0000000\n1.248559\n-1.6078826\n2.291272\n0.6723771\n-0.0220063\n32\n0\n\n\ncyl_z\n0.000000\n1.0000000\n2.239740\n-1.2248578\n1.014882\n-0.1922609\n-1.7627939\n32\n0\n\n\ndisp_z\n0.000000\n1.0000000\n1.787376\n-1.2879099\n1.946754\n0.4202331\n-1.0675234\n32\n0\n\n\nhp_z\n0.000000\n1.0000000\n1.232446\n-1.3810318\n2.746567\n0.7994067\n0.2752116\n32\n0\n\n\ndrat_z\n0.000000\n1.0000000\n1.571037\n-1.5646078\n2.493904\n0.2927802\n-0.4504325\n32\n0\n\n\nwt_z\n0.000000\n1.0000000\n1.212368\n-1.7417722\n2.255336\n0.4659161\n0.4165947\n32\n0\n\n\nqsec_z\n0.000000\n1.0000000\n1.131821\n-1.8740103\n2.826755\n0.4063466\n0.8649307\n32\n0\n\n\nvs_z\n0.000000\n1.0000000\n1.984063\n-0.8680278\n1.116036\n0.2645418\n-2.0632731\n32\n0\n\n\nam_z\n0.000000\n1.0000000\n2.004045\n-0.8141431\n1.189901\n0.4008089\n-1.9665503\n32\n0\n\n\ngear_z\n0.000000\n1.0000000\n1.355373\n-0.9318192\n1.778928\n0.5823086\n-0.8952916\n32\n0\n\n\ncarb_z\n0.000000\n1.0000000\n1.238237\n-1.1221521\n3.211677\n1.1570911\n2.0200593\n32\n0\n\n\n\n\n\n\n\nm1 &lt;- \n  stan_glm(mpg_z ~ hp_z + am + hp_z:am, \n           seed = 42,\n           refresh = 0,\n           data = mtcars2)\n\ncoef(m1)\n\n (Intercept)         hp_z           am      hp_z:am \n-0.357413145 -0.677859338  0.876342434  0.005465839 \n\n\n\nIntercept: Ein Auto mit 0 PS und Automatikantrieb (am=0, s. Hilfe zum Datensatz: help(mtcars)) kann laut Modell mit einer Gallone Sprit ca. -0.36 Meilen fahren. Dieser Wert ist ca. Null, da die AV z-standardisiert ist. Ein Wert von Null in einer z-standardisierten Variablen entspricht dem Mittelwert in den Rohwerten.\nhp: Pro zus√§tzlichem PS kann ein Auto mit Automatikantrieb pro Gallone Sprit ca. -0.68 Meilen weniger weit fahren.\nam: Ein Auto mit 0 PS und Schaltgetriebe (am=1) kommt pro Gallone Sprit ca. 0.88 Meilen weiter als ein Auto mit Automatikantrieb.\nhp:am: Der Interaktionseffekt ist praktisch Null (-0.36): Der Zusammenhang von PS-Zahl und Spritverbrauch unterscheidet sich nicht (wesentlich) zwischen Autos mit bzw. ohne Automatikantrieb.\n\n\nCategories:\n\nbayes\nregression\npaper"
  },
  {
    "objectID": "posts/wskt-quiz17/wskt-quiz17.html",
    "href": "posts/wskt-quiz17/wskt-quiz17.html",
    "title": "wskt-quiz17",
    "section": "",
    "text": "Behauptung:\nHat eine Hypothese die Priori-Wahrscheinlichkeit von 0, so wird die Post-Wahrscheinlichkeit dieser Hypothese 0 sein.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz17/wskt-quiz17.html#answerlist",
    "href": "posts/wskt-quiz17/wskt-quiz17.html#answerlist",
    "title": "wskt-quiz17",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz17/wskt-quiz17.html#answerlist-1",
    "href": "posts/wskt-quiz17/wskt-quiz17.html#answerlist-1",
    "title": "wskt-quiz17",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/gem-wskt2/gem-wskt2.html",
    "href": "posts/gem-wskt2/gem-wskt2.html",
    "title": "Gem-Wskt2",
    "section": "",
    "text": "Ein renommiertes Unternehmen sucht einen Kandidaten f√ºr eine (hoch dotierte) F√ºhrungsposition. Ein Managementberatungsunternehmung f√ºhrt ein Assessmentcenter durch, welches pro Kandidat/in eine positive bzw. negative Empfehlung ergibt. Aus fr√ºheren Erfahrungen heraus wissen die Berater, dass die tats√§chlich geeigneten Kandidaten (Ereignis \\(E\\) wie eligible) mit \\(75\\%\\) eine positive Empfehlung f√ºr die Stelle ausgesprochen bekommen (Ereignis \\(R\\) wie recommendation). Weiterhin bekommen von den nicht geeigneten Kandidaten \\(62\\%\\) eine negative Empfehlung. Insgesamt wissen die Berater, dass \\(7\\%\\) der Bewerber/innen tats√§chlich geeignet sind.\nAufgabe: Was ist die entsprechende H√§ufigkeitstabelle? Geben Sie alle vier Eintr√§ge in Prozent an!\nHinweis: Das Gegenereignis vom Ereignis \\(A\\) wird als Komplement√§rereignis oder kurz als Komplement bezeichnet und mit \\(A^C\\) oder \\(\\overline{A}\\) abgek√ºrzt. Im vorliegenden Fall meint \\(\\overline{R}=R^C\\) das Ereignis, dass ein Kandidat keine Empfehlung ausgesprochen bekommt.\n\n\n\n\\(P(E \\cap R)\\)\n\\(P(\\overline{E} \\cap R)\\)\n\\(P(E \\cap \\overline{R})\\)\n\\(P(\\overline{E} \\cap \\overline{R})\\)"
  },
  {
    "objectID": "posts/gem-wskt2/gem-wskt2.html#answerlist",
    "href": "posts/gem-wskt2/gem-wskt2.html#answerlist",
    "title": "Gem-Wskt2",
    "section": "",
    "text": "\\(P(E \\cap R)\\)\n\\(P(\\overline{E} \\cap R)\\)\n\\(P(E \\cap \\overline{R})\\)\n\\(P(\\overline{E} \\cap \\overline{R})\\)"
  },
  {
    "objectID": "posts/gem-wskt2/gem-wskt2.html#answerlist-1",
    "href": "posts/gem-wskt2/gem-wskt2.html#answerlist-1",
    "title": "Gem-Wskt2",
    "section": "Answerlist",
    "text": "Answerlist\n\n\\(P(E \\cap R) =  5.25\\%\\)\n\\(P(\\overline{E} \\cap R) = 35.34\\%\\)\n\\(P(E \\cap \\overline{R}) =  1.75\\%\\)\n\\(P(\\overline{E} \\cap \\overline{R}) = 57.66\\%\\)\n\n\nCategories:\n\nprobability\nbayes\ncloze"
  },
  {
    "objectID": "posts/fattails02/fattails02.html",
    "href": "posts/fattails02/fattails02.html",
    "title": "fattails02",
    "section": "",
    "text": "Exercise\nIn seinem Buch ‚ÄúStatistical Consequences of Fat Tails‚Äù schreibt der Autor, Nassim Taleb (S. 53):\n\nIn the summer of 1998, the hedge fund called ‚ÄúLong Term Capital Management‚Äù (LTCM) proved to have a very short life; it went bust from some deviations in the markets ‚Äìthose ‚Äúof an unexpected nature‚Äù. The loss was a yuuuge deal because two of the partners received the Swedish Riksbank Prize, marketed as the ‚ÄúNobel‚Äù in economics. (‚Ä¶) At least two of the partners made the statement that it was a ‚Äú10 sigma‚Äù event (10 standard deviations), hence they should be absolved of all accusations of incompetence (I was Ô¨Årst hand witness of two such statements).\n\nWir testen in diesem Zusammenhang zwei Hypothesen: \\(H_N\\), dass der Finanzmarkt normalverteilt ist und \\(H_F\\), dass die Variable fat tailed ist, also nicht normalverteilt, sondernn einer Verteilung entspringt, in der ‚ÄúExtremereignisse‚Äù √ºblicher sind als in einer Normalverteilung.\nUm die Fat-Tails-Verteilung mit \\(n=100\\) zu simulieren, nutzen wir hier folgende Funktion:\n\nfat_tail_data &lt;- rt(n = 100, df = 2)\nfat_tail_data &lt;- rt(n = 100, df = 2)\n\nDabei bedeutet df = 1, dass die Verteilung sehr randlastig (fat tailed) sein soll (genauer gesagt eine t-Verteilung mit zwei Freiheitsgraden). Details zu dieser R-Funktion sollen uns hier nicht interessieren.\nBerechnen wir die Wahrscheinlichkeit, dass die Daten einer Normalverteilung entspringen (und nicht der Fat-Tail-Verteilung).\nDie Wahrscheinlichkeit eines 10-Sigma-Events ist √ºbrigens ‚Ä¶ klein. Taleb berichtet sie mit \\(1.31 \\cdot 10^{-23}\\):\n\nL_norm &lt;- 1.31e-23\n\nDas sind 22 Nuller nach dem Komma, danach kommt die 1.\nF√ºr die t-Verteilung ist der entsprechende Wert:\n\nL_fat &lt;- 1 - pt(q = 10, df = 2)\nL_fat\n\n[1] 0.004926229\n\n\nWie hoch ist die Post-Wahrscheinlichkeit, dass die Variable normalverteilt ist?\nHinweise:\n\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nApriori soll und die Hypothese der Normalverteilung 1000 Mal plausibler sein als die der t-Verteilung.\n\n\n\nAnswerlist\n\nkleiner als 50%\nkleiner als 5%\nkleiner als 0.5%\nkleiner als 0.05%\nkleiner als 0.005%\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nErstellen wir erstmal den ersten Teil einer Bayes-Box:\n\nd &lt;-\n  tibble(H = c(\"Normalverteilt\", \"Randlastig verteilt\"),\n         Prior = c(1e3,1))\n\nd\n\n# A tibble: 2 √ó 2\n  H                   Prior\n  &lt;chr&gt;               &lt;dbl&gt;\n1 Normalverteilt       1000\n2 Randlastig verteilt     1\n\n\nDann f√ºgen wir den Likelihood jeder Hypothese dazu:\n\nd &lt;-\n  d %&gt;% \n  mutate(L = c(L_norm, L_fat))\n\nd\n\n# A tibble: 2 √ó 3\n  H                   Prior        L\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 Normalverteilt       1000 1.31e-23\n2 Randlastig verteilt     1 4.93e- 3\n\n\nDann berechnen wir die Post-Wahrscheinlichkeit:\n\nd &lt;-\n  d %&gt;% \n  mutate(Post_unstand = Prior * L,\n         Post = Post_unstand / sum(Post_unstand))\nd\n\n# A tibble: 2 √ó 5\n  H                   Prior        L Post_unstand     Post\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Normalverteilt       1000 1.31e-23     1.31e-20 2.66e-18\n2 Randlastig verteilt     1 4.93e- 3     4.93e- 3 1   e+ 0\n\n\nDie Wahrscheinlichkeit, dass die Variable normalverteilt ist, ist seeeeehr klein, ca. \\(10^{-18}\\).\n\n\nAnswerlist\n\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/titanic_casestudy/titanic_casestudy.html",
    "href": "posts/titanic_casestudy/titanic_casestudy.html",
    "title": "titanic_casestudy",
    "section": "",
    "text": "Aufgabe\nFallstudie\nEine Analystin untersucht die Daten zum Titanic-Ungl√ºck.\n\nlibrary(tidyverse)\nlibrary(mosaic)\ndata(titanic_train, package = \"titanic\")\n\nZun√§chst berechnet Sie die Gesamt-√úberlebensrate:\n\ntally(Survived ~ 1, data = titanic_train, format = \"percent\")\n\n        1\nSurvived        1\n       0 61.61616\n       1 38.38384\n\n\nDanach √ºberpr√ºft sie, ob sich die Geschlechter hinsichtlich der √úberlebensrate unterscheiden.\n\nmosaicplot(Sex ~ Survived, data = titanic_train)\n\n\n\n\n\n\n\n\nAls dritten Schritt versucht Sie, die √úberlebensrate auf Basis mehrerer Variablen vorherzusagen, dazu verwendet Sie ein lineares (Logit-)Modell.\n\nlm_titanic1 &lt;- glm(Survived ~ Sex + Age + Fare, \n                   data = titanic_train, family = \"binomial\")\n\nsummary(lm_titanic1)\n\n\nCall:\nglm(formula = Survived ~ Sex + Age + Fare, family = \"binomial\", \n    data = titanic_train)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.934841   0.239101   3.910 9.24e-05 ***\nSexmale     -2.347599   0.189956 -12.359  &lt; 2e-16 ***\nAge         -0.010570   0.006498  -1.627    0.104    \nFare         0.012773   0.002696   4.738 2.16e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 964.52  on 713  degrees of freedom\nResidual deviance: 716.07  on 710  degrees of freedom\n  (177 observations deleted due to missingness)\nAIC: 724.07\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nInterpretieren Sie das Ergebnis des Mosaicplots!\nKann man (fundiert) auf Basis dieses Modells sagen, dass das Geschlecht eine Ursache des √úberlebens ist? Begr√ºnden Sie!\nWelche Variablen eignen sich (laut diesem Modell), um √úberleben vorherzusagen?\nWelche Variable ist die wichtigste (laut diesem Modell)?\n\n         \n\n\nL√∂sung\nInterpretieren Sie das Ergebnis des Mosaicplots!\n\nFrauen haben eine deutlich h√∂here √úberlebensrate als M√§nner.\nEs gibt deutlich mehr M√§nner als Frauen.\n\nKann man (fundiert) auf Basis dieses Modells sagen, dass das Geschlecht eine Ursache des √úberlebens ist? Begr√ºnden Sie!\n\nNein.\nZwar ist Geschlecht mit √úberlebens korreliert (bzw. die beiden Variablen sind abh√§ngig), aber das hei√üt noch nicht (zwingend), dass es eine kausale Beziehung ist. So wie ‚ÄúSt√∂rche‚Äù und ‚ÄúBabies‚Äù nur ‚Äúscheinkorreliert‚Äù sind, k√∂nnte hier ebenfalls eine Scheinkorrelation vorliegen.\n\nWelche Variablen eignen sich (laut diesem Modell), um √úberleben vorherzusagen?\n\nZu diesem Zweck wird mitunter die Signifikanz der Regressiongewichte \\(\\beta\\) herangezogen.\nHier sind sex und fare signifikant.\n\nWelche Variable ist die wichtigste (laut diesem Modell)?\n\nZu diesem Zweck kann der t-Wert herangezogen werden.\nF√ºr sexMale ist dieser Wert (im Modell) am gr√∂√üten.\n\n\nsol &lt;- \"s. text\"\n\n\nCategories:\nstring"
  },
  {
    "objectID": "posts/groesse01/groesse01.html",
    "href": "posts/groesse01/groesse01.html",
    "title": "groesse01",
    "section": "",
    "text": "Aufgabe\nWir interessieren uns f√ºr die typische K√∂rpergr√∂√üe deutscher Studentis. Hier findet sich dazu ein Datensatz.\nAusgehend von der Annahme, dass sich die K√∂rpergr√∂√üe normalverteilt (innerhalb eines Geschlechts) suchen wir die Parameter der Normalverteilung, also Mittelwert und Streuung.\nGehen wir von folgenden Apriori-Wahrscheinlichkeiten f√ºr die Parameter der Normalverteilung aus:\n\nMittelwert: 150cm bis 200 cm, jeder Wert gleich plausibel, alle anderen Werte unm√∂glich\nSD: 1cm bis 20cm, jeder Wert gleich plausibel, alle anderen Werte unm√∂glich\n\nJa, das sind ziemlich einf√§ltige Annahmen, aber gut, fangen wir damit an.\nErstellen Sie eine Bayes-Box!\nHinweise:\n\nUntersuchen Sie den angegebenen Parameterbereich in 1cm-Schritten.\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nlibrary(pradadata)  # f√ºr den Datensatz `wo_men`\nlibrary(prada)  # f√ºr bayesbox, alternativ mit `source`\nlibrary(tidyverse)\nlibrary(ggpubr)\n\nDaten importieren:\n\ndata(wo_men)\n\nAlternativ per URL:\n\nwo_men &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/wo_men.csv\")\n\nMittelwert in der Stichprobe:\n\nwo_men |&gt; \n  group_by(sex) |&gt; \n  summarise(height_avg = mean(height, na.rm = TRUE),\n            height_sd = sd(height, na.rm = TRUE))\n\n\n\n\n\nsex\nheight_avg\nheight_sd\n\n\n\n\nman\n183.1111\n9.958082\n\n\nwoman\n161.3095\n42.782380\n\n\nNA\nNaN\nNA\n\n\n\n\n\n\nZur Berechnung der Likelihoods diskretisieren wir die stetige Variable height in Stufen von jeweils 1cm, der Einfachheit halber.\nDie Wahrscheinlichkeit f√ºr das 1cm-Intervall um unserem Stichprobenergebnis herem (182.5cm bis 183.5cm), bei z.B. einem Mittelwert von 180cm und einer SD von 10cm, entspricht dann dieser Differenz:\n\nobere_grenze &lt;- pnorm(q = 183 + 0.5, mean = 180, sd = 10)\nuntere_grenze &lt;- pnorm(q = 183 - 0.5, mean = 180, sd = 10)\n\nobere_grenze\n\n[1] 0.6368307\n\nuntere_grenze\n\n[1] 0.5987063\n\nobere_grenze - untere_grenze\n\n[1] 0.03812433\n\n\nVisualisieren wir uns kurz dieses Intervall.\n\nlibrary(mosaic)\nxpnorm(q = c(182.5, 183.5), mean = 180, sd = 10)\n\n\n\n\n\n\n\n\n[1] 0.5987063 0.6368307\n\n\nAls n√§chstes legen wir die Werte f√ºr unsere Bayes-Box fest.\n\nnorm_mean &lt;- seq(from = 150, to = 200, by = 1)\nnorm_sd &lt;- seq(from = 1, to = 20, by = 1)\n\nJetzt bauen wir unsere Bayes-Box.\nWenn wir die Wahrscheinlichkeiten der Parameter f√ºr alle Kombinationen aus 51 Mittelwerten und 20 SD-Werten pr√ºfen wollen, wird die Tabelle ganz sch√∂n lang:\n\nanzahl_kombinationen &lt;- length(norm_mean) * length(norm_sd)\nanzahl_kombinationen\n\n[1] 1020\n\n\nMit expand_grid kann man sich eine Tabelle erstellen lassen, die alle Kombinationen zweier Variablen aufschreibt:\n\nbayes_box &lt;-\n  expand_grid(norm_mean, norm_sd)\n\nhead(bayes_box)\n\n\n\n\n\nnorm_mean\nnorm_sd\n\n\n\n\n150\n1\n\n\n150\n2\n\n\n150\n3\n\n\n150\n4\n\n\n150\n5\n\n\n150\n6\n\n\n\n\n\n\nDas sind unsere Parameterwerte: Jede Kombination eines Mittelwerts und einer Streuung ist eine Hypothese. Insgesamt haben wir also 1020 Parameterwerte.\nSo, bauen wir die Bayes-Box weiter:\n\nL &lt;- pnorm(183.5, mean = bayes_box$norm_mean, sd = bayes_box$norm_sd)\n\nbayes_box2 &lt;-\n  bayes_box |&gt; \n  mutate(hyp = 1:anzahl_kombinationen,\n         lik = L,\n         post_unstand = hyp * lik,\n         post_std = post_unstand / sum(post_unstand))\n\nSchauen wir uns die Post-Verteilung einmal an:\n\nggline(bayes_box2,\n       x = \"hyp\",\n       y = \"post_std\")\n\n\n\n\n\n\n\n\nOhje! Da stimmt was nicht! Warum sieht die Post-Verteilung so komisch aus?\nDie Antwort ist, dass f√ºr einen bestimmten Mittelwert jeweils 10 verschiedene SD-Werte zugeordnet sind. Und jeder SD-Wert (f√ºr einen MW-Wert) hat eine andere Post-Wahrscheinlichkeit!\nWas wir machen k√∂nnen, ist die beiden Parameter MW und SD einzeln aufzuschl√ºsseln, aber gemeinsam zu betrachten:\n\nbayes_box2 |&gt; \n  ggplot() +\n  aes(x = norm_sd,\n      y = norm_mean,\n      fill = post_std) +\n  geom_tile() +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\nCategories:\n\n2023\nbayes\nbayesbox\nstring"
  },
  {
    "objectID": "posts/iq-studentis/iq-studentis.html",
    "href": "posts/iq-studentis/iq-studentis.html",
    "title": "iq-studentis",
    "section": "",
    "text": "Exercise\nIntelligenz von Studentis\nEine Psychologin m√∂chte die Intelligenz von Studentis bestimmen: Was ist wohl der Mittelwert? Wie schlau sind die schlausten 10%? Von wo bis wo geht das mittlere 90%-Intervall von IQ-Werten? Nat√ºrlich ist ihr klar, dass es nicht reicht, einen Mittelwert zu sch√§tzen. Nein, sie will alles, sprich: die Posteriori-Verteilung.\nZuerst √ºberlegt sie sich die Prioris: ‚ÄúWas ist meine Einsch√§tzung zur Intelligenz von Studentis?‚Äù. Dazu liest sie alle verf√ºgbare Literatur, beurteilt die methodische Qualit√§t jeder einzelnen Studie und spricht mit den Expertis. Auf dieser Basis kommt sie zu folgenden Prioris:\n\\[\\mu \\sim \\mathcal{N}(115, 5)\\] Ein paar √úberlegungen, die unsere Psychologin dazu hatte: Die Studentis sind im Mittel schlauer als die Normalbev√∂lkerung. Um ein Gef√ºhl f√ºr die Verteilungsfunktion vom IQ zu bekommen, nutzt sie folgenden R-Befehl:\n\npnorm(q = 115, mean = 100, sd = 15)\n\n[1] 0.8413447\n\n\nDieser Befehl gibt ihr an, welcher Prozentsatz der allgemeinen Bev√∂lkerung (die Wahrscheinlichkeitsmasse) nicht schlauer ist als 115.\nDann versucht sie ein Gef√ºhl f√ºr die Streuung (\\(\\sigma\\)) zu bekommen, folgender R-Befehl hilft ihr:\n\nq_iq &lt;- 50\nrate_lambda &lt;- 0.1\npexp(q = q_iq, rate = rate_lambda)\n\n[1] 0.9932621\n\n\nAh! Nimmt man an, dass Sigma exponentialverteilt ist mit einer Rate von 0.1, dass sind etwa 99 Prozent der Leute nicht mehr als q_iq IQ-Punkte vom Mittelwert \\(\\mu\\) entfernt. Das deckt sich mit ihren Informationen aus der Literatur.\nDamit sind die Priors spezifiziert.\nAugaben:\n\nGeben Sie die Priors an.\nSimulieren Sie die Prior-Pr√§diktiv-Verteilung dazu.\nBefragen Sie die Prior-Pr√§diktiv-Verteilung mit geeigneten Fragen Ihrer Wahl.\n\n         \nHinweise\n\n\nSolution\n\nGeben Sie die Priors an.\n\n\\[\\mu \\sim \\mathcal{N}(115, 5)\\]\n\\[\\sigma \\sim \\mathcal{E}(0.1)\\]\n\nSimulieren Sie die Prior-Pr√§diktiv-Verteilung dazu.\n\nZiehen wir Zufallszahlen entsprechend der Priori-Werte:\n\nlibrary(tidyverse)\nn &lt;- 1e4\n\nsim &lt;-\n  tibble(\n    sample_mu = rnorm(n,\n      mean = 115,\n      sd   = 10\n    ),\n    sample_sigma = rexp(n,\n      rate = 0.1\n    ),\n    iq = rnorm(n,\n      mean = sample_mu,\n      sd   = sample_sigma\n    )\n  )\n\nWas ist wohl der Mittelwert und die SD dieser Priori-Pr√§diktiv-Verteilung?\n\nheight_sim_sd &lt;-\n  sd(sim$iq) %&gt;% round()\nheight_sim_sd\n\n[1] 17\n\n\n\nheight_sim_mean &lt;-\n  mean(sim$iq) %&gt;% round()\nheight_sim_mean\n\n[1] 115\n\n\nUnd jetzt plotten wir diese Verteilung:\n\nsim %&gt;%\n  ggplot() +\n  aes(x = iq) +\n  geom_histogram() +\n  geom_point(\n    y = 0, x = height_sim_mean, size = 5,\n    color = \"blue\", alpha = .5\n  ) +\n  geom_vline(\n    xintercept = c(\n      height_sim_mean + height_sim_sd,\n      height_sim_mean - height_sim_sd\n    ),\n    linetype = \"dotted\"\n  ) +\n  labs(caption = \"Der blaue Punkt zeigt den Mittelwert; die gepunkteten Linien MD¬±SD\") +\n  scale_x_continuous(\n    limits = c(70, 145),\n    breaks = seq(70, 145, by = 5)\n  )\n\n\n\n\n\n\n\n\nOder vielleicht besser als Dichte-Diagramm, das zeigt das ‚ÄúBig Picture‚Äù vielleicht besser:\n\nsim %&gt;%\n  ggplot() +\n  aes(x = iq) +\n  geom_density()\n\n\n\n\n\n\n\n\nHm, etwas randlastig die Verteilung.\nZoomen wir etwas mehr rein:\n\nsim %&gt;%\n  ggplot() +\n  aes(x = iq) +\n  geom_density() +\n  scale_x_continuous(limits = c(65, 165))\n\n\n\n\n\n\n\n\n\nBefragen Sie die Prior-Pr√§diktiv-Verteilung mit geeigneten Fragen Ihrer Wahl.\n\nWas ist der Mittelwert und die SD und die √ºblichen deskriptiven Kennwerte?\n\nlibrary(easystats)\n\n\nsim %&gt;%\n  select(iq) %&gt;%\n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\niq\n114.9435\n17.04762\n17.85691\n9.422287\n314.2702\n0.2625464\n6.304434\n10000\n0\n\n\n\n\n\n\nIn welchem Bereich liegen die mittleren 95% der IQ-Werte?\n\nsim %&gt;%\n  eti()\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\nsample_mu\n0.95\n95.149648\n134.28994\n\n\nsample_sigma\n0.95\n0.253327\n36.54489\n\n\niq\n0.95\n81.525775\n149.68331\n\n\n\n\n\n\nAlternativ k√∂nnten wir in z-transformierten Daten denken:\n\nsim2 &lt;-\n  tibble(\n    sample_mu =\n      rnorm(n,\n        mean = 0,\n        sd   = 1\n      ),\n    sample_sigma =\n      rexp(n,\n        rate = 1\n      )\n  ) %&gt;%\n  mutate(\n    iq =\n      rnorm(n,\n        mean = sample_mu,\n        sd   = sample_sigma\n      )\n  )\n\n\nsim2 %&gt;%\n  ggplot() +\n  aes(x = iq) +\n  geom_density()\n\n\n\n\n\n\n\n\nMann kann auch ggpubr zum Visualisieren nutzen, anstelle von ggplot2:\n\nlibrary(ggpubr)\nggdensity(sim2, x = \"iq\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Rethink2m4/Rethink2m4.html",
    "href": "posts/Rethink2m4/Rethink2m4.html",
    "title": "Rethink2m4",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\n2M4. Suppose you have a deck with only three cards. Each card has only two sides, and each side is either black or white. One card has two black sides. The second card has one black and one white side. The third card has two white sides. Now suppose all three cards are placed in a bag and shuffled. Someone reaches into the bag and pulls out a card and places it flat on a table. A black side is shown facing up, but you don‚Äôt know the color of the side facing down. Show that the probability that the other side is also black is 2/3. Use the counting method (Section 2 of the chapter) to approach this problem. This means counting up the ways that each card could produce the observed data (a black side faceing up on the table).\n         \n\n\nL√∂sung\nLet‚Äôs firmly remember that our data is a black side is facing up.\nWe have three cards in the deck, giving us three hypothesises. Let‚Äôs label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nWanted is the probability that both sides are black (bb), given one side is black (1b): \\(Pr(bb|1b)\\).\nLet‚Äôs count the ways how the data - one black side - can come up in each conjecture (hypothesis), bb, bw, ww. Let‚Äôs denote ‚Äúfirst side black‚Äù as 1b‚Äù and ‚Äúsecond side black‚Äù as 2b (and similarly for white).\nHypothesis bb has 2 valid paths:\n\n[&lt;start&gt;st] -&gt; [1b: valid]\n[&lt;start&gt;st] -&gt; [2b: valid]\n\n\nThat is, if the card is black on both sides, there are two ways to get a black side.\nHypothesis bw has 1 valid path:\n\n[&lt;start&gt;st] -&gt; [1b: valid]\n[&lt;start&gt;st] -&gt; [1w: invalid]\n\nGiven that we have observed a black side already, the other side must be white ‚Äì assuming the card is bw.\nHypothesis ww has 0 valid path:\n\n[&lt;start&gt;st] -&gt; [1w: invalid]\n[&lt;start&gt;st] -&gt; [2w: invalid]\n\nThe Bayes-Box nicely summarizes these data:\n\n\n\n\n\n\n\n\nHyp\nPrior\nLikelihood\nunstand_post\nstd_post\n\n\n\n\nbb\n1\n2\n2\n0.67\n\n\nbw\n1\n1\n1\n0.33\n\n\nww\n1\n0\n0\n0.00\n\n\n\n\n\n\n\nThe important piece is that there are two ways that a all-black card (bb) can show a black side, since ist has two black sides.\n\nCategories:\n\nprobability\nbayes\nbayesbox\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/sophie-kann-fliegen/index.html",
    "href": "posts/sophie-kann-fliegen/index.html",
    "title": "sophie-kann-fliegen",
    "section": "",
    "text": "1 Aufgabe\nSei \\(A\\): ‚ÄúSophie ist ein Einhorn‚Äù. Und sei \\(B\\): ‚ÄúEinh√∂rner k√∂nnen (alle) fliegen‚Äù.\nWas ist \\(Pr(A|B)\\) ?\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\\(Pr(A|B)\\) = 1"
  },
  {
    "objectID": "posts/mw-berechnen/mw-berechnen2.html",
    "href": "posts/mw-berechnen/mw-berechnen2.html",
    "title": "mw-berechnen2",
    "section": "",
    "text": "Question\n\nAufgabe\nBerechnen Sie den Mittelwert folgender Zahlenreihe; ignorieren sie etwaige fehlende Werte.\n\nzahlenreihe &lt;- c(0.25, -1.85, -0.50,  2.56,  0.90)\nzahlenreihe\n\n[1]  0.25 -1.85 -0.50  2.56  0.90\n\n\nHinweise:\n\nRunden Sie auf zwei Dezimalstellen.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nL√∂sung\n\nmean(zahlenreihe)\n\n[1] 0.272\n\n\nAntwort: Der Mittelwert liegt bei 0.27.\n\nCategories:\n\neda\ndatawrangling\ndyn\nnum"
  },
  {
    "objectID": "posts/Rethink2m3/Rethink2m3.html",
    "href": "posts/Rethink2m3/Rethink2m3.html",
    "title": "Rethink2m3",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\n2M3. Suppose there are two globes, one for Earth and one for Mars. The Earth globe is 70% covered in water. The Mars globe is 100% land. Further suppose that one of these globes‚Äîyou don‚Äôt know which‚Äîwas tossed in the air and produced a ‚Äúland‚Äù observatiion. Assume that each globe was equally likely to be tossed. Show that the posterior probability that the globe was the Earth, conditional on seeing ‚Äúland‚Äù (Pr(Earth|land)), is 0.23.\n         \n\n\nL√∂sung\nMan kann die Aufgabe entweder mit einer Bayes-Box l√∂sen oder durch die Formel des Bayes‚Äô Theorem.\n\n\nBayes-Box\n\n\n\nHyp\nPrior\nL\nPo-unstand\nPo-stand\n\n\n\n\nE\n1\n3/10\n.3\n3/13 (.77)\n\n\nM\n1\n10/10\n1\n10/13 (.23)\n\n\n\n\n\nBayes-Theorem\nZur Erinnerung:\n\\[\\begin{aligned}\nPr(A) &= Pr(A \\cap B) + Pr(A \\cap B^C)  \\qquad \\text{| totale Wskt, bei disjunkten Ereignissen}\\\\\nPr(A \\cap B) &= Pr(A|B) \\cdot Pr(B)\\\\\nPr(A \\cap B^C) &= Pr(A|B^C) \\cdot Pr(B^C)\n\\end{aligned}\\]\nWobei \\(A^C\\) das komplement√§re Ereignis zu \\(A\\) meint.\nThe solution is taken from this source.\nHier sind die gegebenen Infos:\n\n# probability of land, given Earth:\np_le &lt;- 0.3\n\n# probability of land, given Mars:\np_lm &lt;- 1.0\n\n# probability of Earth:\np_e &lt;- 0.5\n\n# prob. of Mars:\np_m &lt;- 0.5\n\nHier sind die gemeinsamen Wahrscheinlichkeiten:\n\nWahrscheinlichkeit, dass es die Erde ist und Land geworfen wurde: \\(Pr(Earth \\cap Land)\\)\n\n\n# probability of land and Earth:\np_l_and_e &lt;- p_e * p_le\np_l_and_e\n\n[1] 0.15\n\n\n\nWahrscheinlichkeit, dass es Mars ist und Land geworfen wurde: \\(Pr(Mars \\cap Land)\\)\n\n\n# proability of land and Mars:\np_l_and_m &lt;- p_m * p_lm\np_l_and_m\n\n[1] 0.5\n\n\nDie totale Wahrscheinlichkeit f√ºr Land betr√§gt also:\n\n# probability of land:\np_l &lt;- p_l_and_e  + p_l_and_m\np_l\n\n[1] 0.65\n\n\nIm Z√§hler von Bayes-Theorem steht dann: p_l_and_e und im Nenner p_l.\nDann kann man die Posteriori-Wahrscheinlichkeit f√ºr Land berechnen:\n\n# probability of Earth, given land (using Bayes' Theorem):\np_el &lt;- p_l_and_e / p_l\np_el\n\n[1] 0.2307692\n\n\nDie Wahrscheinlichkeit, dass die Erde geworfen wurde, betr√§gt also 3/13 oder 0.23.\nEinfacher als die Rechnung ist vielleicht ein Baumdiagramm:\n\n\n\n\n\n\nInsgesamt kann man also 3/20 + 10/20 = 13/20 als Wahrscheinlichkeit f√ºr Land berechnen. Davon entfallen 3/20 auf die Erde. Das ergibt 3/13.\n\nCategories:\n\nprobability\nbayes\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/variation01/variation01.html",
    "href": "posts/variation01/variation01.html",
    "title": "variability01",
    "section": "",
    "text": "In welchem Datensatz, \\(x1, x2, x3, x4\\), gibt es am meisten Variation?\nDatensatz x1:\n\n\n\n\n\nx1\n\n\n\n\n0.14\n\n\n-0.06\n\n\n0.04\n\n\n0.06\n\n\n0.04\n\n\n-0.01\n\n\n0.15\n\n\n-9.47e-03\n\n\n0.20\n\n\n-6.27e-03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatensatz x2:\n\n\n\n\n\nx2\n\n\n\n\n1.30\n\n\n2.29\n\n\n-1.39\n\n\n-0.28\n\n\n-0.13\n\n\n0.64\n\n\n-0.28\n\n\n-2.66\n\n\n-2.44\n\n\n1.32\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatensatz x3:\n\n\n\n\n\nx3\n\n\n\n\n-3.07\n\n\n-17.81\n\n\n-1.72\n\n\n12.15\n\n\n18.95\n\n\n-4.30\n\n\n-2.57\n\n\n-17.63\n\n\n4.60\n\n\n-6.40\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatensatz x4:\n\n\n\n\n\nx4\n\n\n\n\n45.55\n\n\n70.48\n\n\n103.51\n\n\n-60.89\n\n\n50.50\n\n\n-171.70\n\n\n-78.45\n\n\n-85.09\n\n\n-241.42\n\n\n3.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/variation01/variation01.html#answerlist",
    "href": "posts/variation01/variation01.html#answerlist",
    "title": "variability01",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/variation01/variation01.html#answerlist-1",
    "href": "posts/variation01/variation01.html#answerlist-1",
    "title": "variability01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvariablity\nbasics\nschoice"
  },
  {
    "objectID": "posts/streuung-post/index.html",
    "href": "posts/streuung-post/index.html",
    "title": "streuung-post",
    "section": "",
    "text": "1 Aufgabe\nEin Student behauptet, der Effekt einer Stunde lernen f√ºr die Statistikklausur l√§ge bei ‚Äúetwa 0.4 bis 0.6‚Äù Punkten.\nUnter der Annahme, dass der Effekt existiert, normalverteilt ist und dass der oben angef√ºhrte Wertebereich dem 95%-ETI einer Posterior-Verteilung entspricht: Wie gro√ü ist die Streuung der Posterior-Verteilung\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n0.05"
  },
  {
    "objectID": "posts/max-corr1/max-corr1.html",
    "href": "posts/max-corr1/max-corr1.html",
    "title": "max-corr1",
    "section": "",
    "text": "Aufgabe\nWelches Diagramm zeigt den st√§rksten (absoluten) linearen Zusammenhang (Korrelation)?\nGeben Sie die Nummer ein, die in der Kopfzeile jedes Teildiagramms angezeigt wird.\n         \n\n\nL√∂sung\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nnum"
  },
  {
    "objectID": "posts/kausal03/kausal03.html",
    "href": "posts/kausal03/kausal03.html",
    "title": "kausal03",
    "section": "",
    "text": "Gegeben sei der DAG g (s.u.). Was ist die minimale Menge an Variablen, die man kontrollieren muss, um den kausalen Effekt von x auf y zu identifizieren?\n\n\n\n\n\n\n\n\n\nHinweise:\n\nGebogene Kurven mit doppelter Pfeilspitze zeigen keine Kausaleinfl√ºsse ein (was in DAGs nicht erlaubt w√§re).\nStattdessen zeigen Sie eine Assoziation bedingt durch eine (nicht aufgef√ºhrte) Konfundierungsvariable an.\n\n\n\n\n{ w1, w2, z2 }\n{ w2, z2 }\n{ w1, w2 }\n{ w1, z2 }\n{ w1 }"
  },
  {
    "objectID": "posts/kausal03/kausal03.html#answerlist",
    "href": "posts/kausal03/kausal03.html#answerlist",
    "title": "kausal03",
    "section": "",
    "text": "{ w1, w2, z2 }\n{ w2, z2 }\n{ w1, w2 }\n{ w1, z2 }\n{ w1 }"
  },
  {
    "objectID": "posts/kausal03/kausal03.html#answerlist-1",
    "href": "posts/kausal03/kausal03.html#answerlist-1",
    "title": "kausal03",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal\nexam-22"
  },
  {
    "objectID": "posts/count-emojis/count-emojis.html",
    "href": "posts/count-emojis/count-emojis.html",
    "title": "count-emojis",
    "section": "",
    "text": "Z√§hlen sie die Emojis eines Textes.\nUntersuchen Sie die Rechenzeit, die die jeweiligen Verfahren ben√∂tigen.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/count-emojis/count-emojis.html#stringrstr_count",
    "href": "posts/count-emojis/count-emojis.html#stringrstr_count",
    "title": "count-emojis",
    "section": "stringr::str_count",
    "text": "stringr::str_count\nMan kann den Unicode-Code von Emojis ansprechen, praktische Sache:\n\nemoji_pattern &lt;- \"\\\\p{So}\" \n\n\ntest_text$text |&gt; \n  map_int(str_count, emoji_pattern)\n\n[1] 0 3 1 2\n\n\nDie Funktion map ist nicht n√∂tig:\n\nstr_count(test_text$text, \"\\\\p{So}\")\n\n[1] 0 3 1 2\n\n\nAls neue Spalte in der Tabelle:\n\ntest_text |&gt;\n  mutate(n_emojis = str_count(text, \"\\\\p{So}\"))\n\n\n\n\n\nid\ntext\nvalence\nn_emojis\n\n\n\n\n1\nAbbau ist jetzt\n0\n0\n\n\n2\nHello üòäüåéüöÄ\n1\n3\n\n\n3\nüî´\n-1\n1\n\n\n4\nüî´ üî™\n-2\n2"
  },
  {
    "objectID": "posts/count-emojis/count-emojis.html#stringrstr_count-1",
    "href": "posts/count-emojis/count-emojis.html#stringrstr_count-1",
    "title": "count-emojis",
    "section": "stringr::str_count",
    "text": "stringr::str_count\n\ntic()\nmethod1 &lt;- germeval_train$text |&gt; \n  map_int(str_count, emoji_pattern)\ntoc()\n\n0.474 sec elapsed\n\nmethod1 |&gt; str()\n\n int [1:5009] 0 0 1 0 0 0 0 0 0 1 ...\n\n\n\nprint(method1, max = 20)\n\n [1] 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 4 0 0\n [ reached getOption(\"max.print\") -- omitted 4989 entries ]\n\n\nDie Funktion map ist nicht n√∂tig:\n\ntic()\nmethod3 &lt;- \n  str_count(germeval_train$text, emoji_pattern)\ntoc()\n\n0.011 sec elapsed\n\n\n\nmethod3 |&gt; head()\n\n[1] 0 0 1 0 0 0\n\n\nDann geht es auch viel schneller.\nAls neue Spalte in der Tabelle:\n\ntic()\nmethod4 &lt;- \ngermeval_train |&gt; \n  mutate(n_words = str_count(text, emoji_pattern))\ntoc()\n\n0.017 sec elapsed\n\n\n\nstr(method4)\n\n'data.frame':   5009 obs. of  5 variables:\n $ id     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ text   : chr  \"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\" \"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nich\"| __truncated__ \"@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\" \"@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obam\"| __truncated__ ...\n $ c1     : chr  \"OTHER\" \"OTHER\" \"OTHER\" \"OTHER\" ...\n $ c2     : chr  \"OTHER\" \"OTHER\" \"OTHER\" \"OTHER\" ...\n $ n_words: int  0 0 1 0 0 0 0 0 0 1 ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\nmethod4 |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntext\nc1\nc2\nn_words\n\n\n\n\n1\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n0\n\n\n2\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n0\n\n\n3\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n1\n\n\n4\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n0\n\n\n5\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n0\n\n\n6\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n0\n\n\n\n\n\n\n\nCategories:\n\ntextmining\ntidymodels\ncount\ngermeval\nemojis\nstring"
  },
  {
    "objectID": "posts/kausal04/kausal04.html",
    "href": "posts/kausal04/kausal04.html",
    "title": "kausal04",
    "section": "",
    "text": "Gegeben sei ein DAG g (s.u.). Was ist die minimale Menge an Variablen (minimal adjustment set), die man kontrollieren muss, um den kausalen Effekt von smoking auf arrest zu identifizieren?\n\n\n\n\n\n\n\n\n\n\n\n\n{ Cholestorol }\n{ Weight }\nkeine, da nicht identifiziferbar\n{ Cholestrol, Unhealty Lifestyle }\n{ Cholestorol, Weight }"
  },
  {
    "objectID": "posts/kausal04/kausal04.html#answerlist",
    "href": "posts/kausal04/kausal04.html#answerlist",
    "title": "kausal04",
    "section": "",
    "text": "{ Cholestorol }\n{ Weight }\nkeine, da nicht identifiziferbar\n{ Cholestrol, Unhealty Lifestyle }\n{ Cholestorol, Weight }"
  },
  {
    "objectID": "posts/kausal04/kausal04.html#answerlist-1",
    "href": "posts/kausal04/kausal04.html#answerlist-1",
    "title": "kausal04",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "title": "tidymodels-lasso3",
    "section": "",
    "text": "Schreiben Sie eine prototypische Analyse f√ºr ein Vorhersagemodell mit dem Lasso.\nBerichten Sie, welche Pr√§diktoren nach dem Lasso im Modell verbleiben.\nHinweise:\n\nTunen Sie die Penalisierung.\nVerwenden Sie Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ ."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "title": "tidymodels-lasso3",
    "section": "Standardvorgehen",
    "text": "Standardvorgehen\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variablenbedeutung\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellg√ºte im Test-Set:\ncollect_metrics(wf1_fit_final)"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "title": "tidymodels-lasso3",
    "section": "Inspektion der Tuningparameter",
    "text": "Inspektion der Tuningparameter\n\nautoplot(wf1_fit)\n\nDie Standard-Wahl der Tuningparameter-Werte war offenbar nicht so ideal, zumindest sieht man kaum Unterschiede zwischen der Modellg√ºte in Abh√§ngigkeit von den Werten der Tuningparameter."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "title": "tidymodels-lasso3",
    "section": "Variablenbedeutung",
    "text": "Variablenbedeutung\n\nlibrary(vip)\n\nvi_preds &lt;- \nwf1_fit_final %&gt;% \n  extract_fit_engine() %&gt;% \n  vi()\n\nvi_preds\n\n\nvi_preds %&gt;% \n  ggplot(aes(x = Importance, y = reorder(Variable, Importance), fill = Sign)) +\n  geom_col()\n\nMan beachte: F√ºr regulierte Modelle sind Zentrierung und Skalierung n√∂tig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nstring\ntemplate"
  },
  {
    "objectID": "posts/schmalste-post/index.html",
    "href": "posts/schmalste-post/index.html",
    "title": "schmalste-post",
    "section": "",
    "text": "1 Aufgabe\nDie folgenden Posterior-Verteilungen f√ºr den Effekt der UV X unterscheiden sich ihrer Sicherheit zur Sch√§tzung des Modus. Welche der folgenden Posterior-Verteilungen sch√§tzt den Modus am sichersten?\n\n\\(X \\sim N(0,1)\\)\n\\(X \\sim N(0,2)\\)\n\\(X \\sim N(1,2)\\)\n\\(X \\sim N(2,4)\\)\n\\(X \\sim N(4,4)\\)\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nA"
  },
  {
    "objectID": "posts/Rethink2m2/Rethink2m2.html",
    "href": "posts/Rethink2m2/Rethink2m2.html",
    "title": "Rethink2m2",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\nRecall the globe tossing model from the chapter (also see exercise globus1). Compute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p.\nData:\n\nWWW\nWWWL\nLWWLWWW\n\nNow assume a prior for p that is equal to zero when p &lt; 0.5 and is a positive constant when p ‚â• 0.5. Again compute and plot the grid approximate posterior distribution for each of the sets of observations in the problem just above.\nNB:\n\nConsider 21 different values for p such that \\(p = (0, .05, 1., .15, \\ldots, 1)\\).\nRound to 2 decimal places.\n\n         \n\n\nL√∂sung\nThe solution is taken from this source.\n\nlibrary(tidyverse)\n\ndist &lt;- \n  tibble(\n    # Gridwerte bestimmen:\n    p_grid = seq(from = 0, to = 1, length.out = 21),\n    # Priori-Wskt bestimmen:\n    prior  = case_when(\n      p_grid &lt; 0.5 ~ 0,  # Null, wenn p &lt; 0.5 \n      p_grid &gt;= 0.5 ~ 1)) %&gt;%  # 1, wenn p &gt;= 0.5\n  mutate(\n    # Likelihood berechnen:\n    likelihood_1 = dbinom(3, size = 3, prob = p_grid),\n    likelihood_2 = dbinom(3, size = 4, prob = p_grid),\n    likelihood_3 = dbinom(5, size = 7, prob = p_grid),\n    # unstand. Posterior-Wskt:\n    unstand_post_1 = likelihood_1 * prior,\n    unstand_post_2 = likelihood_2 * prior,\n    unstand_post_3 = likelihood_3 * prior,\n    # stand. Post-Wskt:\n    std_post_1 = unstand_post_1 / sum(unstand_post_1),\n    std_post_2 = unstand_post_2 / sum(unstand_post_2),\n    std_post_3 = unstand_post_3 / sum(unstand_post_3)\n    ) \n\nHere is the Bayes Box:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood_1\nlikelihood_2\nlikelihood_3\nunstand_post_1\nunstand_post_2\nunstand_post_3\nstd_post_1\nstd_post_2\nstd_post_3\n\n\n\n\n0.00\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.05\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.10\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.15\n0\n0.00\n0.01\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.20\n0\n0.01\n0.03\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.25\n0\n0.02\n0.05\n0.01\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.30\n0\n0.03\n0.08\n0.03\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.35\n0\n0.04\n0.11\n0.05\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.40\n0\n0.06\n0.15\n0.08\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.45\n0\n0.09\n0.20\n0.12\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.50\n1\n0.12\n0.25\n0.16\n0.12\n0.25\n0.16\n0.02\n0.07\n0.07\n\n\n0.55\n1\n0.17\n0.30\n0.21\n0.17\n0.30\n0.21\n0.03\n0.09\n0.10\n\n\n0.60\n1\n0.22\n0.35\n0.26\n0.22\n0.35\n0.26\n0.04\n0.10\n0.12\n\n\n0.65\n1\n0.27\n0.38\n0.30\n0.27\n0.38\n0.30\n0.05\n0.11\n0.13\n\n\n0.70\n1\n0.34\n0.41\n0.32\n0.34\n0.41\n0.32\n0.07\n0.12\n0.14\n\n\n0.75\n1\n0.42\n0.42\n0.31\n0.42\n0.42\n0.31\n0.08\n0.13\n0.14\n\n\n0.80\n1\n0.51\n0.41\n0.28\n0.51\n0.41\n0.28\n0.10\n0.12\n0.12\n\n\n0.85\n1\n0.61\n0.37\n0.21\n0.61\n0.37\n0.21\n0.12\n0.11\n0.09\n\n\n0.90\n1\n0.73\n0.29\n0.12\n0.73\n0.29\n0.12\n0.14\n0.09\n0.06\n\n\n0.95\n1\n0.86\n0.17\n0.04\n0.86\n0.17\n0.04\n0.16\n0.05\n0.02\n\n\n1.00\n1\n1.00\n0.00\n0.00\n1.00\n0.00\n0.00\n0.19\n0.00\n0.00\n\n\n\n\n\nJetzt k√∂nnen wir das Diagramm zeichnen.\nMit ggpubr:\n\nlibrary(ggpubr)\nggline(dist, \n       x = \"p_grid\", \n       y = \"std_post_1\")\n\n\n\n\n\n\n\n\nOder mit ggplot2:\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_1) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWW\")\n\n\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_2) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWWL\")\n\n\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_3) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: LWWLWWW\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayesbox\nbayes\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/bath42/bath42.html",
    "href": "posts/bath42/bath42.html",
    "title": "bath42",
    "section": "",
    "text": "p &lt;- .9\nk &lt;- 6\nwasser_erde &lt;- .7\nwasser_bath42 &lt;- .9\nn &lt;- 9\n\nMehrere Proben werden zu einem unbekannten Planeten geschossen. Die Forschungsfrage lautet: Ist es die Erde 0.7 oder der Planet ‚ÄúBath42‚Äù mit 0.9 Wasseranteil?\nWir sind indifferent (apriori) zu den Parameterwerten.\nDaten: 6 Treffer (Wasser) von 9 Versuchen (Proben).\nBehauptung: ‚ÄúDas ist fast sicher Bath42!‚Äù.\nAufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass es sich um Bath42 handelt (und nicht um die Erde)?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/bath42/bath42.html#answerlist",
    "href": "posts/bath42/bath42.html#answerlist",
    "title": "bath42",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nnum"
  },
  {
    "objectID": "posts/bike04/bike04.html",
    "href": "posts/bike04/bike04.html",
    "title": "bike04",
    "section": "",
    "text": "Kann man die Anzahl gerade verliehener Fahrr√§der eines entsprechenden Anbieters anhand der Temperatur vorhersagen?\nIn dieser √úbung untersuchen wir diese Frage.\nSie k√∂nnen die Daten von der Webseite der UCI herunterladen.\nWir beziehen uns auf den Datensatz day.\nBerechnen Sie einen Entscheidungsbaum mit der Anzahl der aktuell vermieteten R√§der als AV und der aktuellen Temperatur als UV!\nTunen Sie alle Paramter; lassen Sie sich 20 Tuningparameter vorschlagen.\nGeben Sie den MSE an!\nHinweise"
  },
  {
    "objectID": "posts/bike04/bike04.html#data-split",
    "href": "posts/bike04/bike04.html#data-split",
    "title": "bike04",
    "section": "Data split",
    "text": "Data split\n\nset.seed(42)\nd_split &lt;- initial_split(d, strata = cnt)\n\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/bike04/bike04.html#define-recipe",
    "href": "posts/bike04/bike04.html#define-recipe",
    "title": "bike04",
    "section": "Define recipe",
    "text": "Define recipe\n\nrec1 &lt;- \n  recipe(cnt ~ temp, data = d)"
  },
  {
    "objectID": "posts/bike04/bike04.html#define-model",
    "href": "posts/bike04/bike04.html#define-model",
    "title": "bike04",
    "section": "Define model",
    "text": "Define model\n\nm1 &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune(),\n                mode = \"regression\")"
  },
  {
    "objectID": "posts/bike04/bike04.html#tuning-grid",
    "href": "posts/bike04/bike04.html#tuning-grid",
    "title": "bike04",
    "section": "Tuning grid",
    "text": "Tuning grid\n\ngrid &lt;-\n  grid_latin_hypercube(cost_complexity(), \n               tree_depth(),\n               min_n(),\n               size = 20)\ngrid\n\nAlternativ:\n\ngrid &lt;-\n  grid_latin_hypercube(extract_parameter_set_dials(m1), size = 50)\ngrid"
  },
  {
    "objectID": "posts/bike04/bike04.html#define-resamples",
    "href": "posts/bike04/bike04.html#define-resamples",
    "title": "bike04",
    "section": "Define Resamples",
    "text": "Define Resamples\n\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/bike04/bike04.html#workflow",
    "href": "posts/bike04/bike04.html#workflow",
    "title": "bike04",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(m1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/bike04/bike04.html#fit",
    "href": "posts/bike04/bike04.html#fit",
    "title": "bike04",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;- tune_grid(\n  object = wf1, \n  resamples = rsmpl)\ntoc()\nfit1"
  },
  {
    "objectID": "posts/bike04/bike04.html#bester-kandidat",
    "href": "posts/bike04/bike04.html#bester-kandidat",
    "title": "bike04",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nshow_best(fit1)\n\n\nwf1_best &lt;-\n  wf1 %&gt;% \n  finalize_workflow(parameters = select_best(fit1))"
  },
  {
    "objectID": "posts/bike04/bike04.html#last-fit",
    "href": "posts/bike04/bike04.html#last-fit",
    "title": "bike04",
    "section": "Last Fit",
    "text": "Last Fit\n\nfit_testsample &lt;- last_fit(wf1_best, d_split)"
  },
  {
    "objectID": "posts/bike04/bike04.html#model-performance-metrics-in-test-set",
    "href": "posts/bike04/bike04.html#model-performance-metrics-in-test-set",
    "title": "bike04",
    "section": "Model performance (metrics) in test set",
    "text": "Model performance (metrics) in test set\n\nfit_testsample %&gt;% collect_metrics()\n\n\nMSE &lt;- fit_testsample %&gt;% collect_metrics() %&gt;% pluck(3, 1)\nMSE\n\nSolution:\n\nCategories:\n\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/Post-befragen1/Post-befragen1.html",
    "href": "posts/Post-befragen1/Post-befragen1.html",
    "title": "Post-befragen1",
    "section": "",
    "text": "Welcher R-Code passt am besten, um folgende Frage aus der Post-Verteilung herauszulesen:\n\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?\n\nHinweise:\n\na ist der Achsenabschnitt, b ist das Regressionsgewicht.\npost_tab_df ist eine Tabelle (in Form eines R-Dataframe), die die Stichproben aus der Post-Verteilung enth√§lt.\nEs handelt sich um Regressionsmodell, das mit der Bayes-Methode berechnet wurde.\nDer bzw. die Pr√§diktoren sind zentriert.\nEs handelt sich um den Datensatz aus McElreath‚Äô Lehrbuch (Statistical Rethinking).\n\nCode A\n\npost_tab_df %&gt;% \n  count(gross = a == 155) %&gt;% \n  mutate(prop = n / sum(n))\n\nCode B\n\npost_tab_df %&gt;% \n\n  count(gross = a &gt; 155) %&gt;% \n  mutate(prop = n / sum(n))\n\nCode C\n\npost_tab_df %&gt;% \n  count(gross = a &lt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\nCode D\n\npost_tab_df %&gt;% \n  count(gross = a &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\nCode E\n\npost_tab_df %&gt;% \n  count(gross = a &lt; 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n\nCode A\nCode B\nCode C\nCode D\nCode E"
  },
  {
    "objectID": "posts/Post-befragen1/Post-befragen1.html#answerlist",
    "href": "posts/Post-befragen1/Post-befragen1.html#answerlist",
    "title": "Post-befragen1",
    "section": "",
    "text": "Code A\nCode B\nCode C\nCode D\nCode E"
  },
  {
    "objectID": "posts/Post-befragen1/Post-befragen1.html#answerlist-1",
    "href": "posts/Post-befragen1/Post-befragen1.html#answerlist-1",
    "title": "Post-befragen1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\nregression\nbayes\npost"
  },
  {
    "objectID": "posts/tidymodels1/tidymodels1.html",
    "href": "posts/tidymodels1/tidymodels1.html",
    "title": "tidymodels1",
    "section": "",
    "text": "Prof.¬†S. √ºbt sich im statistischen Lernen. Dazu will er das √úberleben im Titanic-Ungl√ºck Vorhersagen; es handelt sich um eine klassische Aufgabe im statistischen Lernen. Betrachten Sie dazu den folgenden R-Code sowie die Kommentare dazu. W√§hlen Sie die am besten passende Aussage.\nZuerst l√§dt er die n√∂tigen R-Pakete:\n\nlibrary(tidyverse)  # data wrangling\nlibrary(tidymodels)  # modelling\nlibrary(broom)  # tidy model output\nlibrary(parallel)  # multiple cores -- *nix only, d.h. Mac und Linux\nlibrary(finetune)  # tune race anova\n\nDann initialisiert er die Anzahl der Prozessoren auf seinem Computer:\n\ncores &lt;- parallel::detectCores(logical = FALSE)\ncores\n\n[1] 4\n\n\nDaten importieren:\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre\"\ntraindata_path_url  &lt;- \"/main/data/titanic/titanic_train.csv\"\ntestdata_path_url &lt;- \"/main/data/titanic/titanic_test.csv\"\n\ntraindata_url &lt;- paste0(data_path, traindata_path_url)\ntestdata_url &lt;- paste0(data_path, testdata_path_url)\n\n\n# import the data:\ntrain_raw &lt;- read_csv(traindata_url)\ntest &lt;- read_csv(testdata_url)\n\nUnd aufbereiten:\n\n# drop unused variables:\ntrain &lt;-\n  train_raw %&gt;% \n  select(-c(Name, Cabin, Ticket))\n\n# convert string to factors:\ntrain2 &lt;- \n  train %&gt;% \n  mutate(across(where(is.character), as.factor))\n  \n# convert numeric outcome to nominal, to indicate classification:\ntrain2 &lt;- \n  train2 %&gt;% \n  mutate(Survived = as.factor(Survived))\n\nGibt es fehlende Werte in der AV?\n\nsum(is.na(train2$Survived))\n\n[1] 0\n\n\nVorverarbeitung des Datensatzes macht er via ein recipe aus tidymodels:\n\ntitanic_recipe &lt;- \n  \n  # define model formula:\n  recipe(Survived ~ ., data = train2) %&gt;%\n  \n  # Use \"ID\" etc as ID, not as predictor:\n  update_role(PassengerId, new_role = \"ID\") %&gt;% \n  \n   # impute missing values:\n  step_impute_bag(all_predictors()) %&gt;% \n  \n  # convert to dummy variables:\n  step_dummy(all_nominal_predictors())\n\nCheck no missings:\n\ntitanic_train_baked &lt;- titanic_recipe %&gt;% prep() %&gt;% bake(new_data = NULL)\n\nsum(is.na(titanic_train_baked))\n\n[1] 0\n\n\nDann definiert ein ein Modell:\n\nrf_mod2 &lt;- \n  rand_forest(mtry = tune(), # tune mtry\n              min_n = tune(), # tune minimal n per node\n              trees = 1000) %&gt;%  # set number of trees to 1000\n  set_engine(\"ranger\", \n             num.threads = cores) %&gt;% \n  set_mode(\"classification\")\n\n‚Ä¶ und ein Kreuzvalidierungsschema:\n\ntrain_cv &lt;- vfold_cv(train2, \n                     v = 10,\n                     repeats = 1, \n                     strata = \"Survived\")\n\nAus der Hilfe zu vfold_cv:\n\nV-Fold Cross-Validation\nDescription\nV-fold cross-validation randomly splits the data into V groups of roughly equal size (called ‚Äúfolds‚Äù). A resample of the analysis data consisted of V-1 of the folds while the assessment set contains the final fold. In basic V-fold cross-validation (i.e.¬†no repeats), the number of resamples is equal to V.\nUsage\nvfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, ...)\nArguments\ndata A data frame.\nv The number of partitions of the data set.\nrepeats The number of times to repeat the V-fold partitioning.\nstrata A variable that is used to conduct stratified sampling to create the folds. This could be a single character value or a variable name that corresponds to a variable that exists in the data frame.\nbreaks A single number giving the number of bins desired to stratify a numeric stratification variable.\n... Not currently used.\nDetails\nThe strata argument causes the random sampling to be conducted within the stratification variable. This can help ensure that the number of data points in the analysis data is equivalent to the proportions in the original data set. (Strata below 10% of the total are pooled together.) When more than one repeat is requested, the basic V-fold cross-validation is conducted each time. For example, if three repeats are used with v = 10, there are a total of 30 splits which as three groups of 10 that are generated separately.\n\nSo entsteht dieser Workflow:\n\ntitanic_rf_wf2 &lt;-\n  workflow() %&gt;% \n  add_model(rf_mod2) %&gt;% \n  add_recipe(titanic_recipe)\n\nJetzt: Fit the grid!\n\nset.seed(42)\n\nn_candidates &lt;- 2\n\nrf_res2 &lt;- \n  titanic_rf_wf2 %&gt;% \n  tune_race_anova(\n    resamples = train_cv,\n    grid = n_candidates,  # test 25 different tuning parameter values\n    #control = control_grid(save_pred = TRUE),\n    metrics = metric_set(roc_auc))\n\nMit dem Parameter grid kann man die Anzahl der zu berechnenden Kandidaten-Modelle festlegen.\nF√ºr gute Vorhersagen bieten sich hohe Werte an; das kostet aber Rechenzeit.\nAus den Resampling-Kandidaten w√§hlt er nun das beste aus:\n\nrf_best2 &lt;- \n  rf_res2 %&gt;% \n  select_best(metric = \"roc_auc\")\nrf_best2\n\n\n\n\n\nmtry\nmin_n\n.config\n\n\n\n\n8\n2\npre0_mod2_post0\n\n\n\n\n\n\nDas beste Kandidatenmodell nutzt er nun, um den ganzen Train-Datensatz zu ‚Äúfitten‚Äù:\n\n# write best parameter values to the workflow:\nrf_final_wf2 &lt;- \n  titanic_rf_wf2 %&gt;% \n  finalize_workflow(rf_best2)\n\n# fit the model:\nrf_final_model2 &lt;- \nrf_final_wf2 %&gt;% \n  fit(train2)\n\nZum Abschluss speichert er die Vorhersagen, die er dann bei Kaggle einreichen will:\n\nrf2_preds &lt;- \n  predict(rf_final_model2, new_data = test)  # compute prediction on test set\n\nEin letzter Blick auf die Verteilung der vorhergesagten Werte:\n\ncount(rf2_preds, .pred_class)\n\n\n\n\n\n.pred_class\nn\n\n\n\n\n0\n263\n\n\n1\n155\n\n\n\n\n\n\nAuf Basis dieser Analyse: W√§hlen Sie am besten passende Aussage!\n\n\n\nEs wurden 2 Kandidaten von Tuningparameterwerten in die Analyse einbezogen.\nEs wurde kein Parameter-Tuning durchgef√ºhrt.\nDie Metrik \\(AUC\\) sollte nicht f√ºr Klassifikationsmodelle verwendet werden.\nEs wurde eine 10-fache Kreuzvalidierung (ohne Wiederholungen) verwendet.\nDie Anzahl der B√§ume im Random Forest wurde hier nicht ins Parametertuning einbezogen; allerdings w√§re es sinnvoll (und √ºblich), dies zu tun.\nder Parameter mtry wurde hier nicht ins Parametertuning einbezogen."
  },
  {
    "objectID": "posts/tidymodels1/tidymodels1.html#answerlist",
    "href": "posts/tidymodels1/tidymodels1.html#answerlist",
    "title": "tidymodels1",
    "section": "",
    "text": "Es wurden 2 Kandidaten von Tuningparameterwerten in die Analyse einbezogen.\nEs wurde kein Parameter-Tuning durchgef√ºhrt.\nDie Metrik \\(AUC\\) sollte nicht f√ºr Klassifikationsmodelle verwendet werden.\nEs wurde eine 10-fache Kreuzvalidierung (ohne Wiederholungen) verwendet.\nDie Anzahl der B√§ume im Random Forest wurde hier nicht ins Parametertuning einbezogen; allerdings w√§re es sinnvoll (und √ºblich), dies zu tun.\nder Parameter mtry wurde hier nicht ins Parametertuning einbezogen."
  },
  {
    "objectID": "posts/tidymodels1/tidymodels1.html#answerlist-1",
    "href": "posts/tidymodels1/tidymodels1.html#answerlist-1",
    "title": "tidymodels1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\ndyn\nschoice"
  },
  {
    "objectID": "posts/Bayesmod-bestimmen01/Bayesmod-bestimmen01.html",
    "href": "posts/Bayesmod-bestimmen01/Bayesmod-bestimmen01.html",
    "title": "Bayesmod-bestimmen01",
    "section": "",
    "text": "Exercise\nSie m√∂chten, im Rahmen einer Studie, ein einfaches lineare Modell spezifizieren, d.h. den Likelihood und die Priori-Verteilungen benennen.\nFolgende Informationen sind gegeben:\n\nAV: einnahmen\nUV: werbebudget\nAlle empirischen Variablen sind z-standardisiert.\nAlle Variablen sollen als normalverteilt angegeben werden mit Ausnahme der Streuung der AV, diese ist exponentialverteilt mit Rate (\\(\\lambda\\)) 1 zu modellieren.\nStreuungen der Normalverteilung sind mit mit MW=0 und SD=1.5 anzugeben..\n\nAufgabe\nSchreiben Sie in mathematischer Notation folgende Notation auf:\nDie Priori-Verteilung des Regressionsgewichts\nHinweise:\n\nVerzichten Sie auf Leerstellen in Ihrer Antwort. \nBenennen Sie \\(\\beta_1\\) mit b1, \\(\\beta_0\\) (auch \\(\\alpha\\) genannt) mit b0 und \\(\\sigma\\) mit s.\nNutzen Sie die Tilde ~ um stochastische Relationen (Verteilungen) anzuzeigen.\nGeben Sie Normalverteilungen als Normal(x,y) und Exponentialverteilung als Exp(x) an (jeweils mit den korrekten Argumenten in der allgemein √ºblichen Form).\n\n         \n\n\nSolution\n\nsol &lt;- \"b~Normal(0, 1.5)\"\n\nb~Normal(0, 1.5)\n\nCategories:\n\nregression\nbayes\nprior"
  },
  {
    "objectID": "posts/Bootstrap1/Bootstrap1.html",
    "href": "posts/Bootstrap1/Bootstrap1.html",
    "title": "Bootstrap1",
    "section": "",
    "text": "Die Bootstrap-Methode ist eine beliebte numerische Methode im statistischen Lernen und in der Statistik allgemein. Welche der folgenden Aussagen zum Bootstrapping ist richtig?\n\n\n\nBootstrapping ist (u.a.) eine alternative Methode zur Kreuzvalidierung.\nBootstrapping sollte nur bei normalverteilten Variablen verwendet werden.\nBootstrapping basiert auf Ziehen ohne Zur√ºcklegen.\nBootstrapping sollte nur verwendet werden, wo gleichzeitig eine analytische (exakte) Methode bekannt ist.\nBootstrapping sollte nicht verwendet werden, um Standardfehler zu sch√§tzen."
  },
  {
    "objectID": "posts/Bootstrap1/Bootstrap1.html#answerlist",
    "href": "posts/Bootstrap1/Bootstrap1.html#answerlist",
    "title": "Bootstrap1",
    "section": "",
    "text": "Bootstrapping ist (u.a.) eine alternative Methode zur Kreuzvalidierung.\nBootstrapping sollte nur bei normalverteilten Variablen verwendet werden.\nBootstrapping basiert auf Ziehen ohne Zur√ºcklegen.\nBootstrapping sollte nur verwendet werden, wo gleichzeitig eine analytische (exakte) Methode bekannt ist.\nBootstrapping sollte nicht verwendet werden, um Standardfehler zu sch√§tzen."
  },
  {
    "objectID": "posts/Bootstrap1/Bootstrap1.html#answerlist-1",
    "href": "posts/Bootstrap1/Bootstrap1.html#answerlist-1",
    "title": "Bootstrap1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nstatlearning\nds1\nschoice"
  },
  {
    "objectID": "posts/Kennwert-robust/Kennwert-robust.html",
    "href": "posts/Kennwert-robust/Kennwert-robust.html",
    "title": "Kennwert-robust",
    "section": "",
    "text": "Welcher der folgenden Kennwerte ist robust (im statistischen Sinn)?\n\n\n\nMedian\nMittelwert\nKorrelation\nStandardabweichung\nVarianz\nMaximalwert\nMinimalwert"
  },
  {
    "objectID": "posts/Kennwert-robust/Kennwert-robust.html#answerlist",
    "href": "posts/Kennwert-robust/Kennwert-robust.html#answerlist",
    "title": "Kennwert-robust",
    "section": "",
    "text": "Median\nMittelwert\nKorrelation\nStandardabweichung\nVarianz\nMaximalwert\nMinimalwert"
  },
  {
    "objectID": "posts/Kennwert-robust/Kennwert-robust.html#answerlist-1",
    "href": "posts/Kennwert-robust/Kennwert-robust.html#answerlist-1",
    "title": "Kennwert-robust",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\neda\nlagema√üe\nvariability\nschoice"
  },
  {
    "objectID": "posts/penguins-postbreite/index.html",
    "href": "posts/penguins-postbreite/index.html",
    "title": "penguins-postbreite",
    "section": "",
    "text": "1 Aufgabe\nEine Forscherin untersucht folgende Forschungsfrage: Gibt es einen substanziellen Zusammenhang von Flossenl√§nge (mm, Flipper, UV) und Gewicht (g, AV) bei Pinguinen? Sie verwendet den Datensatz ‚ÄúPalmerpenguins‚Äù. Ihre Bayes-Analyse findet folgendes 95%-ETI f√ºr den Effekt der UV: 47 Gramm bis 53 Gramm. Auf Basis ihres biologischen Fachwissens sch√§tzt sie Gewichtsunterschiede (im Mittelwert) von max. 100 Gramm als ‚Äúvernachl√§ssigbar‚Äù (nicht substanziell) ein. Auf Basis dieser Ergebnisse: Wie soll die Forscherin ihre Forschungsfrage beantworten?\n\nDer Zusammenhang ist substanziell.\nDer Zusammenhang ist vernachl√§ssigbar.\nEs ist ohne weitere Annahmen bzw. Angaben keine Aussage m√∂glich.\nDie Befundlage ist unklar.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nB"
  },
  {
    "objectID": "posts/kausal05/kausal05.html",
    "href": "posts/kausal05/kausal05.html",
    "title": "kausal05",
    "section": "",
    "text": "Im Rahmen einer Studie soll untersucht werden, ob eine Influenza-Infektion einen (kausalen) Einfluss auf eine Covid19-Infektion hat.\nIn Wahrheit (aber unbekannt) sei der DAG wie folgt (s.u.).\n\n\n\n\n\n\n\n\n\nIst es sinnvoll, das Auftreten von Fieber (Fever) zu kontrollieren?\n\n\n\nNein, da durch eine Kontrolle von Fever eine Verzerrung erzeugt wird (Kollisionsverzerrung)\nJa, durch eine Kontrolle von Fever ist ein kausaler Effekt identifizierbar\nJa, eine Kontrolle von Fever ist zwar nicht n√∂tig, aber wird zu exakteren Ergebnissen f√ºhren\nNein, da eine Kontrolle von Fever eine Verzerrung erzeugt wird (Konfundierung)\nNein, da eine Kontrolle von Fever nicht n√∂tig ist (aber auch nicht sch√§dlich)"
  },
  {
    "objectID": "posts/kausal05/kausal05.html#answerlist",
    "href": "posts/kausal05/kausal05.html#answerlist",
    "title": "kausal05",
    "section": "",
    "text": "Nein, da durch eine Kontrolle von Fever eine Verzerrung erzeugt wird (Kollisionsverzerrung)\nJa, durch eine Kontrolle von Fever ist ein kausaler Effekt identifizierbar\nJa, eine Kontrolle von Fever ist zwar nicht n√∂tig, aber wird zu exakteren Ergebnissen f√ºhren\nNein, da eine Kontrolle von Fever eine Verzerrung erzeugt wird (Konfundierung)\nNein, da eine Kontrolle von Fever nicht n√∂tig ist (aber auch nicht sch√§dlich)"
  },
  {
    "objectID": "posts/kausal05/kausal05.html#answerlist-1",
    "href": "posts/kausal05/kausal05.html#answerlist-1",
    "title": "kausal05",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/postvert-vis-zwielicht/postvert-vis-zwielicht.html",
    "href": "posts/postvert-vis-zwielicht/postvert-vis-zwielicht.html",
    "title": "postvert-vis-zwielicht",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "posts/postvert-vis-zwielicht/postvert-vis-zwielicht.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "posts/postvert-vis-zwielicht/postvert-vis-zwielicht.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "postvert-vis-zwielicht",
    "section": "Der zwielichte Dozent: Stichproben-Vert. vs.¬†Post-Vert.",
    "text": "Der zwielichte Dozent: Stichproben-Vert. vs.¬†Post-Vert.\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem Gl√ºcksspiel heraus1. M√ºnzwurf; wenn er gewinnt, m√ºssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? Nat√ºrlich nehmen Sie sofort an.\nSie spielen also M√ºnzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal2.\nIst die M√ºnze fair oder zieht der mich √ºber den Tisch?, das ist die Frage, die Ihnen brennend durch den Kopf zieht.\n‚ÄúSind 9 von 10 Treffern noch realistisch erwartbar, wenn es mit rechten Dingen zugeht, oder beweist das Ergebnis, dass die M√ºnze gezinkt ist?‚Äù\nW√ºtend (und mit leeren Taschen) ziehen Sie von dannen.\nZusammengefasst: Daten: 9 von 10 Treffern beim M√ºnzwurf. Forschungsfrage: Ist die M√ºnze fair?\nSchauen wir uns zun√§chst einmal an, wie wahrscheinlich 9 von 10 Treffern sind, wenn die M√ºnze fair ist, s. Figure¬†1, links.\nDie Stichprobenverteilung zeigt, wie wahrscheinlich die empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) sind, gegeben eines Parameterwerts \\(\\pi\\) (z.B. \\(p=0.5\\)): \\(Pr(D|\\pi)\\)3.\nAnders gesagt, die Stichprobenverteilung zeigt die Verteilung der Likelihoods eines bestimmten Parameterwerts.\nIn der Bayes-Statistik ist die Post-Verteilung Dreh- und Angelpunkt der Entscheidung √ºber eine Hypothese. In Figure¬†1 ist die Posteriori-Verteilung f√ºr die Daten zum zwielichten Dozent dargestellt.\n\n# Post-Verteilung:\nd_zwielicht &lt;-\n  tibble(\n    p_grid = seq( from=0 , to=1 , length.out=100),\n    prior = 1,  # Priori-Gewichte\n    likelihood = dbinom(8, size = 10, prob=p_grid) ,\n    unstandardisierte_posterior = likelihood * prior ,\n    posterior = unstandardisierte_posterior / sum(unstandardisierte_posterior))\n\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples_zwielicht &lt;- \n  tibble(\n    gewinnchance_muenze = sample(\n      d_zwielicht$p_grid , \n      prob=d_zwielicht$posterior, \n      size=1e4, \n      replace=TRUE)) %&gt;% \n  mutate(\n    id = row_number())\n\n\n\n\n\n\n\n\n\nFigure¬†1: Post-Verteilung f√ºr den Parameter p zu den Daten des zwielichten Dozenten (9 von 10 Treffern im wiederholten M√ºnzwurf)\n\n\n\n\n\n\ngghistogram(samples_zwielicht,\n            x = \"gewinnchance_muenze\",\n            title = \"Posteriori-Verteilung f√ºr p\",\n            subtitle = \"Priori: Gleichverteilung; Daten: 9 von 10 Treffern, binomialverteilt\",\n            xlab = \"p (Gewinchance der M√ºnze)\",\n            fill = \"grey60\") +\n  geom_vline(xintercept = 0.5)\n\nAufgab:e Bauen Sie daraufhin die oben gezeigte Abbildung nach.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/postvert-vis-zwielicht/postvert-vis-zwielicht.html#footnotes",
    "href": "posts/postvert-vis-zwielicht/postvert-vis-zwielicht.html#footnotes",
    "title": "postvert-vis-zwielicht",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHier br√§uchte es ein passendes Meme; Vorschl√§ge bitte an mich.‚Ü©Ô∏é\nwas er mit lautem Gel√§chter quittiert‚Ü©Ô∏é\nDas griechische kleine \\(p\\) wird ‚Äúpi‚Äù genannt und \\(\\pi\\) geschrieben. Zur Erinnerung: Parameter- oder Populationskennwerte werden in der Statistik h√§ufig mit griechischen Buchstaben benannt, um sie von Stichprobenkennwerten abzugrenzen.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html",
    "href": "posts/verteilungsfunktion-penguins/index.html",
    "title": "verteilungsfunktion-penguins",
    "section": "",
    "text": "In dieser Aufgabe besch√§ftigen wir uns mit der Sch√§tzung von Wahrscheinlichkeitsaussagen auf Basis der deskriptiven Statistik.\n\n\n\n\nTable¬†1: Gegen√ºberstellung von Wahrscheinlichkeitstheorie und deskriptiver Statistik\n\n\n\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDeskriptive Statistik\n\n\n\n\nZufallsvariable\nMerkmal\n\n\nWahrscheinlichkeit\nrelative H√§ufigkeit, Anteil\n\n\nWahrscheinlichkeitsverteilung\neinfache relative H√§ufigkeitsverteilung\n\n\nVerteilungsfunktion\nkumulierte relative H√§ufigkeitsverteilung\n\n\nErwartungswert\nMittelwert\n\n\nVarianz\nVarianz\n\n\n\n\n\n\n\n\n\n\nDabei nutzen wir den Datensatz penguins.\n\nlibrary(palmerpenguins)\ndata(penguins)\n\n\nWelche Variable entspricht der Zufallsvariable Gewicht des Tieres?\nWas ist die Wahrscheinlichkeit, dass ein Pinguin weiblich ist?\nVisualisieren Sie die Wahrscheinlichkeitsverteilung des Gewichts.\nVisualisieren Sie die Verteilungsfunktion des Gewichts.\nVisualisieren Sie den Erwartungswert des Gewichts.\nVisualisieren Sie die Varianz des Gewichts.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/mutate03/mutate03.html",
    "href": "posts/mutate03/mutate03.html",
    "title": "mutate03",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nGrupieren Sie die den Datensatz in zwei Gruppen:\n\nkeinem oder einem Lenkrad\n2 oder mehr Lenkr√§der\n\nBerechnen Sie dann den Mittelwert zum Verkaufspreis der Spiele der 1. Gruppe.\nHinweise:\n\nRunden Sie auf die n√§chste ganze Zahl.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nWie ist die Verteilung von wheels?\n\nmariokart |&gt; \n  mutate(Anz_wheels_gruppe = \n           case_when(wheels &lt;= 1 ~ \"0-1\",\n                     wheels &gt;= 1 ~ \"2 oder mehr\")) |&gt; \n  group_by(Anz_wheels_gruppe) |&gt; \n  summarise(total_pr = mean(total_pr))\n\n\n\n\n\nAnz_wheels_gruppe\ntotal_pr\n\n\n\n\n0-1\n42.87629\n\n\n2 oder mehr\n61.42444\n\n\n\n\n\n\nDie Antwort lautet: 43.\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/kausal02/kausal02.html",
    "href": "posts/kausal02/kausal02.html",
    "title": "kausal02",
    "section": "",
    "text": "Gegeben sei der DAG g (s.u.). Welche Variable/n sind zu kontrollieren, um den kausalen Effekt von x auf y zu identifizieren?\n\n\n\n\n\n\n\n\n\n\n\n\nz\nkeine, bereits identifiziert\nx\ny\nkeine, nicht identifizierbar"
  },
  {
    "objectID": "posts/kausal02/kausal02.html#answerlist",
    "href": "posts/kausal02/kausal02.html#answerlist",
    "title": "kausal02",
    "section": "",
    "text": "z\nkeine, bereits identifiziert\nx\ny\nkeine, nicht identifizierbar"
  },
  {
    "objectID": "posts/kausal02/kausal02.html#answerlist-1",
    "href": "posts/kausal02/kausal02.html#answerlist-1",
    "title": "kausal02",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal\nexam-22"
  },
  {
    "objectID": "posts/kekse02/kekse02.html",
    "href": "posts/kekse02/kekse02.html",
    "title": "kekse02",
    "section": "",
    "text": "Aufgabe\nIn Think Bayes stellt Allen Downey folgende Aufgabe:\n‚ÄúNext let‚Äôs solve a cookie problem with 101 bowls:\nBowl 0 contains 0% vanilla cookies,\nBowl 1 contains 1% vanilla cookies,\nBowl 2 contains 2% vanilla cookies,\nand so on, up to\nBowl 99 contains 99% vanilla cookies, and\nBowl 100 contains all vanilla cookies.\nAs in the previous version, there are only two kinds of cookies, vanilla and chocolate. So Bowl 0 is all chocolate cookies, Bowl 1 is 99% chocolate, and so on.\nSuppose we choose a bowl at random, choose a cookie at random, and it turns out to be vanilla. What is the probability that the cookie came from Bowl \\(x\\), for each value of \\(x\\)?‚Äù\nHinweise:\n\nUntersuchen Sie die Hypothesen \\(\\pi_0 = 0, \\pi_1 = 0.1, \\pi_2 = 0.2, ..., \\pi_{10} = 1\\) f√ºr die Trefferwahrscheinlichkeit\nErstellen Sie ein Bayes-Gitter zur L√∂sung dieser Aufgabe.\nGehen Sie davon aus, dass Sie (apriori) indifferent gegen√ºber der Hypothesen zu den Parameterwerten sind.\nGeben Sie Prozentzahlen immer als Anteil an und lassen Sie die f√ºhrende Null weg (z.B. .42).\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (das \"Gitter\"): \n    p_Gitter = 0:100 / 101,\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %&gt;%  \n    mutate(\n      # berechne Likelihood f√ºr jeden Gitterwert:\n      Likelihood = p_Gitter,\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.01\n1\n0.01\n0.01\n0.00\n\n\n0.02\n1\n0.02\n0.02\n0.00\n\n\n0.03\n1\n0.03\n0.03\n0.00\n\n\n0.04\n1\n0.04\n0.04\n0.00\n\n\n0.05\n1\n0.05\n0.05\n0.00\n\n\n0.06\n1\n0.06\n0.06\n0.00\n\n\n0.07\n1\n0.07\n0.07\n0.00\n\n\n0.08\n1\n0.08\n0.08\n0.00\n\n\n0.09\n1\n0.09\n0.09\n0.00\n\n\n0.10\n1\n0.10\n0.10\n0.00\n\n\n0.11\n1\n0.11\n0.11\n0.00\n\n\n0.12\n1\n0.12\n0.12\n0.00\n\n\n0.13\n1\n0.13\n0.13\n0.00\n\n\n0.14\n1\n0.14\n0.14\n0.00\n\n\n0.15\n1\n0.15\n0.15\n0.00\n\n\n0.16\n1\n0.16\n0.16\n0.00\n\n\n0.17\n1\n0.17\n0.17\n0.00\n\n\n0.18\n1\n0.18\n0.18\n0.00\n\n\n0.19\n1\n0.19\n0.19\n0.00\n\n\n0.20\n1\n0.20\n0.20\n0.00\n\n\n0.21\n1\n0.21\n0.21\n0.00\n\n\n0.22\n1\n0.22\n0.22\n0.00\n\n\n0.23\n1\n0.23\n0.23\n0.00\n\n\n0.24\n1\n0.24\n0.24\n0.00\n\n\n0.25\n1\n0.25\n0.25\n0.00\n\n\n0.26\n1\n0.26\n0.26\n0.01\n\n\n0.27\n1\n0.27\n0.27\n0.01\n\n\n0.28\n1\n0.28\n0.28\n0.01\n\n\n0.29\n1\n0.29\n0.29\n0.01\n\n\n0.30\n1\n0.30\n0.30\n0.01\n\n\n0.31\n1\n0.31\n0.31\n0.01\n\n\n0.32\n1\n0.32\n0.32\n0.01\n\n\n0.33\n1\n0.33\n0.33\n0.01\n\n\n0.34\n1\n0.34\n0.34\n0.01\n\n\n0.35\n1\n0.35\n0.35\n0.01\n\n\n0.36\n1\n0.36\n0.36\n0.01\n\n\n0.37\n1\n0.37\n0.37\n0.01\n\n\n0.38\n1\n0.38\n0.38\n0.01\n\n\n0.39\n1\n0.39\n0.39\n0.01\n\n\n0.40\n1\n0.40\n0.40\n0.01\n\n\n0.41\n1\n0.41\n0.41\n0.01\n\n\n0.42\n1\n0.42\n0.42\n0.01\n\n\n0.43\n1\n0.43\n0.43\n0.01\n\n\n0.44\n1\n0.44\n0.44\n0.01\n\n\n0.45\n1\n0.45\n0.45\n0.01\n\n\n0.46\n1\n0.46\n0.46\n0.01\n\n\n0.47\n1\n0.47\n0.47\n0.01\n\n\n0.48\n1\n0.48\n0.48\n0.01\n\n\n0.49\n1\n0.49\n0.49\n0.01\n\n\n0.50\n1\n0.50\n0.50\n0.01\n\n\n0.50\n1\n0.50\n0.50\n0.01\n\n\n0.51\n1\n0.51\n0.51\n0.01\n\n\n0.52\n1\n0.52\n0.52\n0.01\n\n\n0.53\n1\n0.53\n0.53\n0.01\n\n\n0.54\n1\n0.54\n0.54\n0.01\n\n\n0.55\n1\n0.55\n0.55\n0.01\n\n\n0.56\n1\n0.56\n0.56\n0.01\n\n\n0.57\n1\n0.57\n0.57\n0.01\n\n\n0.58\n1\n0.58\n0.58\n0.01\n\n\n0.59\n1\n0.59\n0.59\n0.01\n\n\n0.60\n1\n0.60\n0.60\n0.01\n\n\n0.61\n1\n0.61\n0.61\n0.01\n\n\n0.62\n1\n0.62\n0.62\n0.01\n\n\n0.63\n1\n0.63\n0.63\n0.01\n\n\n0.64\n1\n0.64\n0.64\n0.01\n\n\n0.65\n1\n0.65\n0.65\n0.01\n\n\n0.66\n1\n0.66\n0.66\n0.01\n\n\n0.67\n1\n0.67\n0.67\n0.01\n\n\n0.68\n1\n0.68\n0.68\n0.01\n\n\n0.69\n1\n0.69\n0.69\n0.01\n\n\n0.70\n1\n0.70\n0.70\n0.01\n\n\n0.71\n1\n0.71\n0.71\n0.01\n\n\n0.72\n1\n0.72\n0.72\n0.01\n\n\n0.73\n1\n0.73\n0.73\n0.01\n\n\n0.74\n1\n0.74\n0.74\n0.01\n\n\n0.75\n1\n0.75\n0.75\n0.02\n\n\n0.76\n1\n0.76\n0.76\n0.02\n\n\n0.77\n1\n0.77\n0.77\n0.02\n\n\n0.78\n1\n0.78\n0.78\n0.02\n\n\n0.79\n1\n0.79\n0.79\n0.02\n\n\n0.80\n1\n0.80\n0.80\n0.02\n\n\n0.81\n1\n0.81\n0.81\n0.02\n\n\n0.82\n1\n0.82\n0.82\n0.02\n\n\n0.83\n1\n0.83\n0.83\n0.02\n\n\n0.84\n1\n0.84\n0.84\n0.02\n\n\n0.85\n1\n0.85\n0.85\n0.02\n\n\n0.86\n1\n0.86\n0.86\n0.02\n\n\n0.87\n1\n0.87\n0.87\n0.02\n\n\n0.88\n1\n0.88\n0.88\n0.02\n\n\n0.89\n1\n0.89\n0.89\n0.02\n\n\n0.90\n1\n0.90\n0.90\n0.02\n\n\n0.91\n1\n0.91\n0.91\n0.02\n\n\n0.92\n1\n0.92\n0.92\n0.02\n\n\n0.93\n1\n0.93\n0.93\n0.02\n\n\n0.94\n1\n0.94\n0.94\n0.02\n\n\n0.95\n1\n0.95\n0.95\n0.02\n\n\n0.96\n1\n0.96\n0.96\n0.02\n\n\n0.97\n1\n0.97\n0.97\n0.02\n\n\n0.98\n1\n0.98\n0.98\n0.02\n\n\n0.99\n1\n0.99\n0.99\n0.02\n\n\n\n\n\n\nggplot(d) +\n  aes(x = p_Gitter, y = Post) + \n  geom_line()\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayesbox\nnum"
  },
  {
    "objectID": "posts/globus-bin2/index.html",
    "href": "posts/globus-bin2/index.html",
    "title": "globus-bin2",
    "section": "",
    "text": "1 Aufgabe\nSie werfen einen Globus \\(n=5\\) Mal. (Wenn Sie nach l√§ngerem Suchen keinen Globus finden, dann nehmen Sie eine M√ºnze. Das geht genauso, macht aber weniger Spa√ü.)\nDer Versuch l√§uft so ab: Sie werfen den Globus. Hoch! Und fangen ihn wieder auf. Dann schauen Sie zur Stelle unter Ihrem Zeigefinger. Ist dort Land oder Wasser?\nGehen Sie von einer Trefferwahrscheinlichkeit (f√ºr ‚ÄúWasser‚Äù) von \\(\\pi=.7\\) aus.\nAufgabe Berechnen Sie die Wahrscheinlichkeit, dass Sie genau \\(0,1,2,\\ldots,n\\) mal ‚ÄúWasser‚Äù sehen.\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nn &lt;- 5\npi &lt;- .7\n\n\ndbinom(x = 0:n, size = n, prob = pi)\n\n[1] 0.00243 0.02835 0.13230 0.30870 0.36015 0.16807\n\n\n\n\n\n\n\n\n\n\n\nVon Hand k√∂nnte man z.B. so rechnen:\n\nW &lt;- 3\n\nF√ºr \\(W=3\\):\n\nchoose(n, W) * pi^(W) * (1-pi)^(n-W)\n\n[1] 0.3087"
  },
  {
    "objectID": "posts/pca/pca.html",
    "href": "posts/pca/pca.html",
    "title": "pca",
    "section": "",
    "text": "Die zwei Hauptkomponenten sind nicht orthogonal (unabh√§ngig).\nDie erste Hauptkomponente ist stets durch den k√ºrzeren Pfeil gekennzeichnet.\nDie erste Hauptkomponente ist unkorrelliert zur ersten.\nDie erste Hauptkomponenten beinhaltet weniger Variation als die erste."
  },
  {
    "objectID": "posts/pca/pca.html#answerlist",
    "href": "posts/pca/pca.html#answerlist",
    "title": "pca",
    "section": "",
    "text": "Die zwei Hauptkomponenten sind nicht orthogonal (unabh√§ngig).\nDie erste Hauptkomponente ist stets durch den k√ºrzeren Pfeil gekennzeichnet.\nDie erste Hauptkomponente ist unkorrelliert zur ersten.\nDie erste Hauptkomponenten beinhaltet weniger Variation als die erste."
  },
  {
    "objectID": "posts/Logikpruefung2/Logikpruefung2.html",
    "href": "posts/Logikpruefung2/Logikpruefung2.html",
    "title": "Logikpruefung2",
    "section": "",
    "text": "Aufgabe\nWir definieren x wie folgt:\n\nx &lt;- c(-1, 0, 1)\n\nGeben Sie die Syntax an, f√ºr die Pr√ºfung, ob x positiv ist.\n         \n\n\nL√∂sung\n\nx &gt; 0\n\n[1] FALSE FALSE  TRUE\n\n\n\nCategories:\n\nR\n‚Äò2023‚Äô\nLogikpruefung2"
  },
  {
    "objectID": "posts/bayes-ziel1/bayes-ziel1.html",
    "href": "posts/bayes-ziel1/bayes-ziel1.html",
    "title": "Bayes-Ziel1",
    "section": "",
    "text": "Was ist nicht Ziel oder Gegenstand einer Bayes-Analyse?\n\n\n\nupdating beliefs\nquantifying uncertainty\nincluding prior knowledge of the domain, possibly of subjective nature\ndrawing inferential conclusions solely based on the likelihood"
  },
  {
    "objectID": "posts/bayes-ziel1/bayes-ziel1.html#answerlist",
    "href": "posts/bayes-ziel1/bayes-ziel1.html#answerlist",
    "title": "Bayes-Ziel1",
    "section": "",
    "text": "updating beliefs\nquantifying uncertainty\nincluding prior knowledge of the domain, possibly of subjective nature\ndrawing inferential conclusions solely based on the likelihood"
  },
  {
    "objectID": "posts/bayes-ziel1/bayes-ziel1.html#answerlist-1",
    "href": "posts/bayes-ziel1/bayes-ziel1.html#answerlist-1",
    "title": "Bayes-Ziel1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nregression\nbayes"
  },
  {
    "objectID": "posts/Likelihood2/Likelihood2.html",
    "href": "posts/Likelihood2/Likelihood2.html",
    "title": "Likelihood2",
    "section": "",
    "text": "Der Likelihood eines Datensatzes ist definiert als das Produkt der Likelihoods aller Beobachtungen:\n\\[\\mathcal{L} = \\prod_{i=1}^n \\mathcal{L_i}\\]\nwobei die Beobachtungen bzw. ihre Likelihood als unabh√§ngig angenommen werden: \\(\\mathcal{L_i} \\perp \\mathcal{L_j}, \\quad i \\ne j\\).\nJe gr√∂√üer \\(n\\), desto ‚Ä¶‚Ä¶.. \\(\\mathcal{L}\\)!\nF√ºllen Sie die L√ºcke!\n\n\n\ngr√∂√üer\nkleiner\nunabh√§ngig voneinander\nkeine Aussage m√∂glich\nkommt auf weitere, hier nicht benannte Bedingungen an"
  },
  {
    "objectID": "posts/Likelihood2/Likelihood2.html#answerlist",
    "href": "posts/Likelihood2/Likelihood2.html#answerlist",
    "title": "Likelihood2",
    "section": "",
    "text": "gr√∂√üer\nkleiner\nunabh√§ngig voneinander\nkeine Aussage m√∂glich\nkommt auf weitere, hier nicht benannte Bedingungen an"
  },
  {
    "objectID": "posts/Likelihood2/Likelihood2.html#answerlist-1",
    "href": "posts/Likelihood2/Likelihood2.html#answerlist-1",
    "title": "Likelihood2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nregression\nbayes\nlikelihood"
  },
  {
    "objectID": "posts/tidymodels-lasso2/tidymodels-lasso2.html",
    "href": "posts/tidymodels-lasso2/tidymodels-lasso2.html",
    "title": "tidymodels-lasso2",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine minimale Analyse f√ºr ein Vorhersagemodell mit dem Lasso.\nHinweise:\n\nVerzichten Sie auf Tuning der Penalisierung; setzen Sie den Wert auf 0.1\nVerzichten Sie auf die Unterteilung von Train- und Test-Set.\nVerzichten Sie auf Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ .\n\n         \n\n\nL√∂sung\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\n# d_train &lt;- training(d_split)\n# d_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = 0.1,\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\n# set.seed(42)\n# rsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit(data = d)\ntoc()\n\n# best candidate:\nwf1_fit\n\n\n\n# Modellg√ºte:\n\npredict(wf1_fit, new_data = d) %&gt;% \n  bind_cols(d %&gt;% select(body_mass_g)) %&gt;% \n  rmse(truth = body_mass_g,\n       estimate = .pred)\n\nMan beachte: F√ºr regulierte Modelle sind Zentrierung und Skalierung n√∂tig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nsimple\nstring\ntemplate"
  },
  {
    "objectID": "posts/import-data/index.html",
    "href": "posts/import-data/index.html",
    "title": "import-mtcars",
    "section": "",
    "text": "1 Aufgabe\nFinden Sie den Datensatz ‚Äúmtcars‚Äù online! ‚Äúmtcars.csv‚Äù . Tipp: Die Webseite ‚Äúvincentarelbundock‚Äù ist ein guter Ort zum Suchen. Laden Sie dann den Datensatz heruter.\nImportieren Sie dann den Datensatz von Ihrer Festplatte in R.\nSagen Sie mir den Namen der letzten Spalte und dort den ersten Wert!\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nlibrary(tidyverse)\n\nHier gibt‚Äôs die Daten:\n\nmtcars_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\"\n\nIn welchem Verzeichnis bin ich eigentlich?\n\ngetwd()  # gwr working directory\n\n[1] \"/Users/sebastiansaueruser/github-repos/datenwerk/posts/import-data\"\n\n\nIn einem RStudio-Projekt geht auch:\n\nhere::here()\n\n[1] \"/Users/sebastiansaueruser/github-repos/datenwerk\"\n\n\nDas gibt die Root-Ebene des Projekts zur√ºck.\nHerunterladen:\n\ndownload.file(mtcars_path, destfile = \"mtcars.csv\")\n\nImportieren:\n\nmtcars &lt;- read.csv(\"mtcars.csv\")\n\nNamen der letzten Spalte:\n\nnames(mtcars)\n\n [1] \"rownames\" \"mpg\"      \"cyl\"      \"disp\"     \"hp\"       \"drat\"    \n [7] \"wt\"       \"qsec\"     \"vs\"       \"am\"       \"gear\"     \"carb\"    \n\n\nErster Wert der letzten Spalte:\n\nmtcars |&gt; \n  select(carb) |&gt; \n  slice(1)\n\n\n\n\n\ncarb\n\n\n\n\n4"
  },
  {
    "objectID": "posts/boxhist/boxhist.html",
    "href": "posts/boxhist/boxhist.html",
    "title": "boxhist",
    "section": "",
    "text": "boxhist.csv draw a histogram, and a boxplot. Based on the graphics, answer the following questions or check the correct statements, respectively. (Comment: The tolerance for numeric answers is \\(\\pm0.2\\), the true/false statements are either about correct or clearly wrong.)\n\n\n\nThe distribution is unimodal.\nThe distribution is not unimodal.\nThe distribution is symmetric.\nThe distribution is right-skewed.\nThe distribution is left-skewed.\nThe boxplot shows outliers.\nThe boxplot shows no outliers.\nA quarter of the observations is smaller than which value?\nA quarter of the observations is greater than which value?\nHalf of the observations are greater than which value?"
  },
  {
    "objectID": "posts/boxhist/boxhist.html#answerlist",
    "href": "posts/boxhist/boxhist.html#answerlist",
    "title": "boxhist",
    "section": "",
    "text": "The distribution is unimodal.\nThe distribution is not unimodal.\nThe distribution is symmetric.\nThe distribution is right-skewed.\nThe distribution is left-skewed.\nThe boxplot shows outliers.\nThe boxplot shows no outliers.\nA quarter of the observations is smaller than which value?\nA quarter of the observations is greater than which value?\nHalf of the observations are greater than which value?"
  },
  {
    "objectID": "posts/boxhist/boxhist.html#answerlist-1",
    "href": "posts/boxhist/boxhist.html#answerlist-1",
    "title": "boxhist",
    "section": "Answerlist",
    "text": "Answerlist\n\nTrue.\nFalse.\nTrue.\nFalse.\nFalse.\nTrue.\nFalse.\n3.44.\n4.58.\n\n\n\n\n\nCategories:\n\nvis\neda\nen\ncloze"
  },
  {
    "objectID": "posts/anteil-apple/anteil-apple.html",
    "href": "posts/anteil-apple/anteil-apple.html",
    "title": "Anteil-Apple",
    "section": "",
    "text": "Exercise\nZ√§hlen Sie, wie viele der Studentis im Raum mindestens ein Apple-Ger√§t besitzen (iPhone, Macbook,‚Ä¶).\nSei \\(\\pi\\) der Anteil der Studentis, die mindestens ein Apple-Ger√§t besitzen.\nBerechnen Sie die Posteriori-Verteilung f√ºr \\(\\pi\\), verwenden Sie eine Bayesbox!\nHinweise:\n\nErstellen Sie eine Bayes-Box (Gittermethode).\nFalls Sie keine Erhebung durchf√ºhren k√∂nnen oder wollen, erfinden Sie Zahlen.\nVisualisieren Sie die Post-Verteilung\n\n         \n\n\nSolution\nWir berechnen die Posteriori-Verteilung mit Hilfe der Bayesbox:\n\nlibrary(tidyverse)\nd &lt;-\n  tibble(\n    p_grid = seq(0,1, by = .01),\n    prior = 1,\n    Likelihood = dbinom(x = 9,\n                        size = 12,\n                        prob = p_grid),\n    post_unstand = prior * Likelihood,\n    post_stand = post_unstand / sum(post_unstand)\n  )\n\nhead(d)\n\n\n\n\n\np_grid\nprior\nLikelihood\npost_unstand\npost_stand\n\n\n\n\n0.00\n1\n0\n0\n0\n\n\n0.01\n1\n0\n0\n0\n\n\n0.02\n1\n0\n0\n0\n\n\n0.03\n1\n0\n0\n0\n\n\n0.04\n1\n0\n0\n0\n\n\n0.05\n1\n0\n0\n0\n\n\n\n\n\n\nVisualisieren der Posteriori-Verteilung:\n\nd %&gt;% \n  ggplot(aes(x = p_grid, y = post_stand)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nbayesbox"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html",
    "href": "posts/flights-yacsda-eda/index.html",
    "title": "flights-yacsda-eda",
    "section": "",
    "text": "Diese Fallstudie zeigt einige m√∂gliche/typische Schritte der explorativen Datenanalyse (EDA) im Hinblick auf die Forschungsfrage ‚ÄúWelche Variablen steht in Zusammenhang mit Flugversp√§tungen?‚Äù."
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#wie-√§hnlich-sind-ankunfts--und-abflugsversp√§tung",
    "href": "posts/flights-yacsda-eda/index.html#wie-√§hnlich-sind-ankunfts--und-abflugsversp√§tung",
    "title": "flights-yacsda-eda",
    "section": "4.1 Wie √§hnlich sind Ankunfts- und Abflugsversp√§tung?",
    "text": "4.1 Wie √§hnlich sind Ankunfts- und Abflugsversp√§tung?\nDa der Datensatz so gro√ü ist, ziehen wir eine Stichprobe (mit sample_n), dann geht alles schneller. Hier nicht wichtig, nur um etwas Zeit beim Plotten zu sparen. In der Praxis w√ºrde ich in an dieser Stelle keine Stichprobe ziehen, bzw. mit dem Gesamtdatensatz weiterarbeiten (was wir ja auch im Folgenden tun).\n\nflights_sample &lt;- \nflights |&gt; \n  sample_n(size = 1000) \n\n\n4.1.1 Diagramm mit DataExplorer\n\nflights_sample |&gt; \n  select(dep_delay, arr_delay) |&gt; \n  plot_scatterplot(by = \"arr_delay\")\n\n\n\n\n\n\n\n\n\n\n4.1.2 Diagramm mit ggplot\n\nflights_sample |&gt; \n  ggplot() +\n  aes(y = dep_delay, x = arr_delay) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n4.1.3 Statistiken\n\nflights %&gt;%\n  drop_na(dep_delay, arr_delay) %&gt;% \n  summarise(sd(dep_delay),\n            sd(arr_delay))\n\n\n\n\nsd(dep_delay)\nsd(arr_delay)\n\n\n\n\n40.06569\n44.63329\n\n\n\n\n\nDas sind ca. 10% Differenz in der Skalierung; wir k√∂nnen die Skalierung komplett angleichen, um Abweichungen, die auf unterschiedlichen Mustern beruhen, besser zu sehen. Dazu hilft uns die z-Transformation.\nDie beiden Variablen scheinen ziemlich stark korreliert zu sein.\n\nflights %&gt;% \n  drop_na(dep_delay, arr_delay) %&gt;% \n  summarise(cor(dep_delay, arr_delay))\n\n\n\n\ncor(dep_delay, arr_delay)\n\n\n\n\n0.9148028\n\n\n\n\n\nJa, sind sie. Dann ist es vielleicht egal, welche der beiden Variablen wir verwenden. Nehmen wir dep_delay.\n\n\n4.1.4 Vertiefung: z-Skalierung\n\nflights %&gt;% \n  select(contains(\"delay\")) %&gt;% \n  drop_na() %&gt;% \n  mutate(dep_delay = scale(dep_delay),  # z-Transformation\n         arr_delay = scale(arr_delay)) %&gt;%   # z-Transformation\n  ggplot() +\n  aes(x = arr_delay, y = dep_delay) +\n  geom_bin2d() +\n  geom_abline(linetype = \"dashed\",\n              color = \"grey60\")\n\n\n\n\n\n\n\n\nbin2d wurde hier nur aus dem Grund verwendet, da das Plotten von ein paar Hunderttausend Punkte recht lange dauert. bin2d hingegen ist sehr schnell."
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#visualisierung",
    "href": "posts/flights-yacsda-eda/index.html#visualisierung",
    "title": "flights-yacsda-eda",
    "section": "5.1 Visualisierung",
    "text": "5.1 Visualisierung\n\nMit DataExplorerMit ggplot\n\n\n\nflights |&gt; \n  select(dep_delay) |&gt; \n  plot_density()\n\n\n\n\n\n\n\n\n\n\n\nflights %&gt;% \n  ggplot() +\n  aes(x = dep_delay) %&gt;% \n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\nEin sehr langer rechter Rand; die meisten Fl√ºge sind nicht/kaum versp√§tet; aber einige wenige sind sehr stark versp√§tet.\nZentrale deskriptive Statistiken k√∂nnte man sich mit summary ausgeben lassen:\n\nflights %&gt;%\n  filter(!is.na(dep_delay)) %&gt;%  # keine fehlenden Werte\n  summarise(depdelay_mean = mean(dep_delay),\n            depdelay_sd = sd(dep_delay),\n            depdelay_md = median(dep_delay),\n            depdelay_iqr = IQR(dep_delay)) \n\n\n\n\ndepdelay_mean\ndepdelay_sd\ndepdelay_md\ndepdelay_iqr\n\n\n\n\n12.63907\n40.21006\n-2\n16\n\n\n\n\n\n\n5.1.1 Vertiefung: Wiederholung mit across\nOder man benutzt den Befehl across, der es erlaubt, eine oder mehrere Funktionen auf eine oder mehrere Spalten wiederholtanzuwenden (Man spricht von einer ‚ÄúSchleife‚Äù). In diesem Beispiel wenden wir mehrere Funktionen (adressiert mit .fns) auf eine Spalte (dep_delay), adressiert mit dem Argument .cols an. Au√üerdem kann man die Namen der resultierenden Spalten bestimmen mit dem Argument .names. In der geschweiften Klammer steht eine interne Variable, die den Namen der jeweils berechneten Funktion ({fn}) an den Namen der neu erstellten Spalte anf√ºgt; in der Ausgabe sieht man das gut.\n\nflights %&gt;% \n  summarise(across(\n    .cols = dep_delay,\n    .fns = list(mean = mean, \n                md = median, \n                sd = sd, \n                iqr = IQR), na.rm = TRUE,\n    .names = \"depdelay_{fn}\"\n  ))\n\n\n\n\ndepdelay_mean\ndepdelay_md\ndepdelay_sd\ndepdelay_iqr\n\n\n\n\n12.63907\n-2\n40.21006\n16"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#flights2-extremwerte-der-versp√§tung-definieren",
    "href": "posts/flights-yacsda-eda/index.html#flights2-extremwerte-der-versp√§tung-definieren",
    "title": "flights-yacsda-eda",
    "section": "5.2 flights2: Extremwerte (der Versp√§tung) definieren",
    "text": "5.2 flights2: Extremwerte (der Versp√§tung) definieren\nEs gibt keinen sicheren Weg, mit Extremwerten umzugehen. H√§ufig macht es Sinn, die Ergebnisse mehrerer Analysen zu vergleichen mit, oder ohne Extremwerten.\n\n‚ÄúWann ist ein Flug sehr versp√§tet?\n\n5.2.1 Boxplot-Methode\nEine M√∂glichkeit ist die ‚ÄúBoxplot-Methode‚Äù: Entferne alle Fl√ºge, die mehr versp√§tet sind als als das 1.5-fache der IQR √ºber dem 3. Quartil (75. Perzentil): \\(q75+1.5iqr\\)\nBerechnen wir zun√§chst das 75. Perzentil (3. Quartil):\n\nflights %&gt;% \n  summarise(q75 = quantile(dep_delay, \n                           prob = .75, \n                           na.rm = TRUE))\n\n\n\n\nq75\n\n\n\n\n11\n\n\n\n\n\nDas sind also etwa 11 Minuten, die die Grenzlinie zwischen den 75% weniger bzw. den 25% st√§rker versp√§teten Fl√ºgen markieren.\nDann berechnen wir den IQR:\n\nflights %&gt;% \n  summarise(depdelay_iqr = IQR(dep_delay, na.rm = TRUE))\n\n\n\n\ndepdelay_iqr\n\n\n\n\n16\n\n\n\n\n\nDer Grenzwert liegt dem zufolge bei:\n\ngrenzwert &lt;- 11 + 1.5*16\n\nDas ist kein ‚Äúgottgegebener‚Äù Wert, sondern ein pragmatischer Versuch, einen Grenzwert zu finden. Die N√ºtzlichkeit dieses Grenzwerts m√ºsste sich noch erweisen. Viele andere Grenzwerte lassen sich verteidigen.\n\nflights2 &lt;-\n  flights %&gt;% \n  mutate(is_extreme = case_when(\n    dep_delay &gt; 11 + 1.5 * 16 ~ TRUE, # Versp√§tung &gt; 35 Min.\n    dep_delay &lt;= 35 ~ FALSE  # in den anderen F√§llen (&lt;= 35 Min.), dann kein Extremwert\n  ))"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#fehlende-werte-berechnen",
    "href": "posts/flights-yacsda-eda/index.html#fehlende-werte-berechnen",
    "title": "flights-yacsda-eda",
    "section": "5.3 Fehlende Werte berechnen",
    "text": "5.3 Fehlende Werte berechnen\nWie viele fehlende Werte gibt es eigentlich in dep_delay?\n\nflights |&gt; \n  describe_distribution(dep_delay)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\ndep_delay\n12.63907\n40.21006\n16\n-43\n1301\n4.802541\n43.95012\n328521\n8255\n\n\n\n\n\nAlternativ, und weniger komfortabel k√∂nnte man sagen\n\nHey R,\nnimm die Tabelle flights und dann\nfasse die Spalte dep_delay zu einer Zahl zusammen und zwar\nanhand der Summe (sum) der fehlenden Werten (is.na)\n\n\nflights %&gt;% \n  summarise(sum(is.na(dep_delay)))  # fehlende Werte z√§hlen\n\n\n\n\nsum(is.na(dep_delay))\n\n\n\n\n8255\n\n\n\n\n\nWie viele F√§lle gingen verloren, wenn wir die F√§lle mit fehlenden Werten bei dep_delay entfernten?\n\nflights %&gt;% \n  drop_na(dep_delay) %&gt;% \n  nrow()\n\n[1] 328521\n\n\nUnd wenn wir alle fehlenden Werte entfernen w√ºrden?\n\nflights %&gt;% \n  drop_na() %&gt;% \n  nrow()\n\n[1] 327346\n\n\nWir verlieren nicht viele F√§lle mehr, wenn wir die fehlenden Werte aller Variablen (Spalten) entfernen. Also machen wir das mal.\n\n5.3.1 Vertiefung: across\nSo bekommt man die fehlenden Werte f√ºr alle Spalten auf einmal:\n\nflights %&gt;% \n  summarise(across(everything(), ~ sum(is.na(.x))))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\n\n\n0\n0\n0\n8255\n0\n8255\n8713\n0\n9430\n0\n0\n2512\n0\n0\n9430\n0\n0\n0\n0\n\n\n\n\n\nEhrlicherweise muss man sagen, dass man mit describe_distribution auch komfortabel die fehlenden Werte f√ºr alle Spalten bekommt."
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#flights3",
    "href": "posts/flights-yacsda-eda/index.html#flights3",
    "title": "flights-yacsda-eda",
    "section": "5.4 flights3",
    "text": "5.4 flights3\nAchtung: dieses Vorgehen hier ist gef√§hrlich. U.U. verliert man sehr viele Zeilen (Beobachtungen).\n\nflights3 &lt;-\n  flights2 %&gt;% \n  drop_na() %&gt;% \n  select(-year)\n\nDie Spalte year ist kontant (immer der Wert ‚Äú2013‚Äù); daher ist die Spalte nutzlos, sie birgt keine Information. Wir k√∂nnen sie gefahrlos l√∂schen."
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#mit-summarise",
    "href": "posts/flights-yacsda-eda/index.html#mit-summarise",
    "title": "flights-yacsda-eda",
    "section": "6.1 Mit summarise",
    "text": "6.1 Mit summarise\nDas kann machen mit summarise. Einfach, kann aber viel Tipperei bedeuten:\n\nflights2 %&gt;% \n  summarise(mean(dep_delay),\n            sd(dep_delay),\n            mean(arr_delay),\n            sd(arr_delay))  # und so weiter\n\n\n\n\nmean(dep_delay)\nsd(dep_delay)\nmean(arr_delay)\nsd(arr_delay)\n\n\n\n\nNA\nNA\nNA\nNA"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#mit-describe_distribution",
    "href": "posts/flights-yacsda-eda/index.html#mit-describe_distribution",
    "title": "flights-yacsda-eda",
    "section": "6.2 Mit describe_distribution",
    "text": "6.2 Mit describe_distribution\ndescribe_distribution ist sehr praktisch; man bekommt viele Statistiken auf einmal gezeigt; das spart viel Tipperei.\n\nflights %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nyear\n2013.000000\n0.000000\n0\n2013\n2013\nNaN\nNaN\n336776\n0\n\n\nmonth\n6.548510\n3.414457\n6\n1\n12\n-0.0133999\n-1.1869501\n336776\n0\n\n\nday\n15.710787\n8.768607\n15\n1\n31\n0.0077445\n-1.1859454\n336776\n0\n\n\ndep_time\n1349.109947\n488.281791\n837\n1\n2400\n-0.0247435\n-1.0883200\n328521\n8255\n\n\nsched_dep_time\n1344.254840\n467.335756\n823\n106\n2359\n-0.0058581\n-1.1979031\n336776\n0\n\n\ndep_delay\n12.639070\n40.210061\n16\n-43\n1301\n4.8025405\n43.9501160\n328521\n8255\n\n\narr_time\n1502.054999\n533.264132\n836\n1\n2400\n-0.4678191\n-0.1926344\n328063\n8713\n\n\nsched_arr_time\n1536.380220\n497.457141\n821\n1\n2359\n-0.3531381\n-0.3822478\n336776\n0\n\n\narr_delay\n6.895377\n44.633292\n31\n-86\n1272\n3.7168175\n29.2330440\n327346\n9430\n\n\nflight\n1971.923620\n1632.471938\n2912\n1\n8500\n0.6616036\n-0.8485607\n336776\n0\n\n\nair_time\n150.686460\n93.688305\n110\n20\n695\n1.0707052\n0.8630770\n327346\n9430\n\n\ndistance\n1039.912604\n733.233033\n887\n17\n4983\n1.1286902\n1.1936399\n336776\n0\n\n\nhour\n13.180247\n4.661316\n8\n1\n23\n-0.0005427\n-1.2064161\n336776\n0\n\n\nminute\n26.230100\n19.300846\n36\n0\n59\n0.0929309\n-1.2350180\n336776\n0"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#metrische-pr√§diktoren",
    "href": "posts/flights-yacsda-eda/index.html#metrische-pr√§diktoren",
    "title": "flights-yacsda-eda",
    "section": "7.1 Metrische Pr√§diktoren",
    "text": "7.1 Metrische Pr√§diktoren\n\n7.1.1 Nur mit cor\nAm einfachsten geht es so. Der Nachteil ist mehr (viel) Tipperei:\n\nflights3 %&gt;% \n  select(where(is.numeric)) %&gt;%  # w√§hle alle numerischen Spalten\n  summarise(cor_month = cor(dep_delay, month),\n            cor_day = cor(dep_delay, day),\n            cor_dep_time = cor(dep_delay, dep_time))  # etc\n\n\n\n\ncor_month\ncor_day\ncor_dep_time\n\n\n\n\n-0.0200547\n0.0005914\n0.2596127\n\n\n\n\n\n\n\n7.1.2 Mit easystats\n\nflights |&gt; \n  select(where(is.numeric)) %&gt;% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nyear\nmonth\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\nday\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\ndep_time\nNA\n0.95\nNA\nNA\nNA\n328519\nNA\nPearson correlation\n328521\n\n\nyear\nsched_dep_time\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\ndep_delay\nNA\n0.95\nNA\nNA\nNA\n328519\nNA\nPearson correlation\n328521\n\n\nyear\narr_time\nNA\n0.95\nNA\nNA\nNA\n328061\nNA\nPearson correlation\n328063\n\n\nyear\nsched_arr_time\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\narr_delay\nNA\n0.95\nNA\nNA\nNA\n327344\nNA\nPearson correlation\n327346\n\n\nyear\nflight\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\nair_time\nNA\n0.95\nNA\nNA\nNA\n327344\nNA\nPearson correlation\n327346\n\n\nyear\ndistance\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\nhour\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nyear\nminute\nNA\n0.95\nNA\nNA\nNA\n336774\nNA\nPearson correlation\n336776\n\n\nmonth\nday\n0.0029423\n0.95\n-0.0004350\n0.0063197\n1.7075186\n336774\n1.0000000\nPearson correlation\n336776\n\n\nmonth\ndep_time\n-0.0039324\n0.95\n-0.0073519\n-0.0005129\n-2.2539453\n328519\n0.3388037\nPearson correlation\n328521\n\n\nmonth\nsched_dep_time\n-0.0045726\n0.95\n-0.0079499\n-0.0011953\n-2.6536338\n336774\n0.1274143\nPearson correlation\n336776\n\n\nmonth\ndep_delay\n-0.0200570\n0.95\n-0.0234749\n-0.0166386\n-11.4983104\n328519\n0.0000000\nPearson correlation\n328521\n\n\nmonth\narr_time\n-0.0025199\n0.95\n-0.0059418\n0.0009020\n-1.4433357\n328061\n1.0000000\nPearson correlation\n328063\n\n\nmonth\nsched_arr_time\n-0.0041727\n0.95\n-0.0075500\n-0.0007954\n-2.4215548\n336774\n0.2318219\nPearson correlation\n336776\n\n\nmonth\narr_delay\n-0.0173820\n0.95\n-0.0208064\n-0.0139572\n-9.9464509\n327344\n0.0000000\nPearson correlation\n327346\n\n\nmonth\nflight\n-0.0008341\n0.95\n-0.0042114\n0.0025433\n-0.4840347\n336774\n1.0000000\nPearson correlation\n336776\n\n\nmonth\nair_time\n0.0109242\n0.95\n0.0074988\n0.0143493\n6.2505247\n327344\n0.0000000\nPearson correlation\n327346\n\n\nmonth\ndistance\n0.0216356\n0.95\n0.0182596\n0.0250112\n12.5585894\n336774\n0.0000000\nPearson correlation\n336776\n\n\nmonth\nhour\n-0.0052274\n0.95\n-0.0086046\n-0.0018501\n-3.0336183\n336774\n0.0410819\nPearson correlation\n336776\n\n\nmonth\nminute\n0.0155277\n0.95\n0.0121509\n0.0189040\n9.0121387\n336774\n0.0000000\nPearson correlation\n336776\n\n\nday\ndep_time\n-0.0004674\n0.95\n-0.0038869\n0.0029522\n-0.2678812\n328519\n1.0000000\nPearson correlation\n328521\n\n\nday\nsched_dep_time\n-0.0000144\n0.95\n-0.0033917\n0.0033630\n-0.0083485\n336774\n1.0000000\nPearson correlation\n336776\n\n\nday\ndep_delay\n0.0004200\n0.95\n-0.0029995\n0.0038395\n0.2407375\n328519\n1.0000000\nPearson correlation\n328521\n\n\nday\narr_time\n-0.0055369\n0.95\n-0.0089587\n-0.0021151\n-3.1714238\n328061\n0.0273074\nPearson correlation\n328063\n\n\nday\nsched_arr_time\n-0.0024028\n0.95\n-0.0057801\n0.0009746\n-1.3943765\n336774\n1.0000000\nPearson correlation\n336776\n\n\nday\narr_delay\n-0.0003192\n0.95\n-0.0037448\n0.0031065\n-0.1826024\n327344\n1.0000000\nPearson correlation\n327346\n\n\nday\nflight\n-0.0017908\n0.95\n-0.0051681\n0.0015866\n-1.0392164\n336774\n1.0000000\nPearson correlation\n336776\n\n\nday\nair_time\n0.0022364\n0.95\n-0.0011893\n0.0056620\n1.2795263\n327344\n1.0000000\nPearson correlation\n327346\n\n\nday\ndistance\n0.0030413\n0.95\n-0.0003361\n0.0064186\n1.7649426\n336774\n1.0000000\nPearson correlation\n336776\n\n\nday\nhour\n-0.0000553\n0.95\n-0.0034326\n0.0033221\n-0.0320789\n336774\n1.0000000\nPearson correlation\n336776\n\n\nday\nminute\n0.0009867\n0.95\n-0.0023907\n0.0043640\n0.5725883\n336774\n1.0000000\nPearson correlation\n336776\n\n\ndep_time\nsched_dep_time\n0.9546169\n0.95\n0.9543125\n0.9549192\n1837.0937739\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_time\ndep_delay\n0.2602312\n0.95\n0.2570404\n0.2634164\n154.4779649\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_time\narr_time\n0.6607789\n0.95\n0.6588467\n0.6627023\n504.2386087\n328061\n0.0000000\nPearson correlation\n328063\n\n\ndep_time\nsched_arr_time\n0.7846824\n0.95\n0.7833648\n0.7859929\n725.5275036\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_time\narr_delay\n0.2323057\n0.95\n0.2290624\n0.2355439\n136.6497146\n327344\n0.0000000\nPearson correlation\n327346\n\n\ndep_time\nflight\n0.0419571\n0.95\n0.0385431\n0.0453701\n24.0695668\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_time\nair_time\n-0.0146195\n0.95\n-0.0180442\n-0.0111944\n-8.3652793\n327344\n0.0000000\nPearson correlation\n327346\n\n\ndep_time\ndistance\n-0.0139982\n0.95\n-0.0174169\n-0.0105792\n-8.0240834\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_time\nhour\n0.9533056\n0.95\n0.9529927\n0.9536165\n1809.2355940\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_time\nminute\n0.0915767\n0.95\n0.0881848\n0.0949665\n52.7101121\n328519\n0.0000000\nPearson correlation\n328521\n\n\nsched_dep_time\ndep_delay\n0.1988867\n0.95\n0.1956002\n0.2021688\n116.3188193\n328519\n0.0000000\nPearson correlation\n328521\n\n\nsched_dep_time\narr_time\n0.6426802\n0.95\n0.6406672\n0.6446843\n480.4710020\n328061\n0.0000000\nPearson correlation\n328063\n\n\nsched_dep_time\nsched_arr_time\n0.7833425\n0.95\n0.7820341\n0.7846440\n731.3355602\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_dep_time\narr_delay\n0.1738962\n0.95\n0.1705721\n0.1772163\n101.0322717\n327344\n0.0000000\nPearson correlation\n327346\n\n\nsched_dep_time\nflight\n0.0364947\n0.95\n0.0331214\n0.0398672\n21.1928124\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_dep_time\nair_time\n-0.0155321\n0.95\n-0.0189568\n-0.0121071\n-8.8876246\n327344\n0.0000000\nPearson correlation\n327346\n\n\nsched_dep_time\ndistance\n-0.0179950\n0.95\n-0.0213710\n-0.0146185\n-10.4445684\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_dep_time\nhour\n0.9991483\n0.95\n0.9991425\n0.9991540\n14051.7706130\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_dep_time\nminute\n0.0829598\n0.95\n0.0796047\n0.0863129\n48.3099293\n336774\n0.0000000\nPearson correlation\n336776\n\n\ndep_delay\narr_time\n0.0287288\n0.95\n0.0253094\n0.0321476\n16.4616791\n328061\n0.0000000\nPearson correlation\n328063\n\n\ndep_delay\nsched_arr_time\n0.1604885\n0.95\n0.1571552\n0.1638181\n93.1945228\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_delay\narr_delay\n0.9148028\n0.95\n0.9142422\n0.9153599\n1295.8504088\n327344\n0.0000000\nPearson correlation\n327346\n\n\ndep_delay\nflight\n0.0547337\n0.95\n0.0513238\n0.0581424\n31.4185914\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_delay\nair_time\n-0.0224051\n0.95\n-0.0258288\n-0.0189809\n-12.8220570\n327344\n0.0000000\nPearson correlation\n327346\n\n\ndep_delay\ndistance\n-0.0216708\n0.95\n-0.0250885\n-0.0182526\n-12.4238721\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_delay\nhour\n0.1982259\n0.95\n0.1949385\n0.2015089\n115.9165150\n328519\n0.0000000\nPearson correlation\n328521\n\n\ndep_delay\nminute\n0.0284409\n0.95\n0.0250238\n0.0318573\n16.3079309\n328519\n0.0000000\nPearson correlation\n328521\n\n\narr_time\nsched_arr_time\n0.7889971\n0.95\n0.7877018\n0.7902853\n735.5354750\n328061\n0.0000000\nPearson correlation\n328063\n\n\narr_time\narr_delay\n0.0244821\n0.95\n0.0210582\n0.0279055\n14.0114093\n327344\n0.0000000\nPearson correlation\n327346\n\n\narr_time\nflight\n0.0250418\n0.95\n0.0216217\n0.0284613\n14.3475801\n328061\n0.0000000\nPearson correlation\n328063\n\n\narr_time\nair_time\n0.0542960\n0.95\n0.0508798\n0.0577110\n31.1108134\n327344\n0.0000000\nPearson correlation\n327346\n\n\narr_time\ndistance\n0.0469912\n0.95\n0.0435763\n0.0504051\n26.9447568\n328061\n0.0000000\nPearson correlation\n328063\n\n\narr_time\nhour\n0.6426514\n0.95\n0.6406383\n0.6446556\n480.4342878\n328061\n0.0000000\nPearson correlation\n328063\n\n\narr_time\nminute\n0.0409691\n0.95\n0.0375524\n0.0443848\n23.4854231\n328061\n0.0000000\nPearson correlation\n328063\n\n\nsched_arr_time\narr_delay\n0.1332613\n0.95\n0.1298949\n0.1366246\n76.9302376\n327344\n0.0000000\nPearson correlation\n327346\n\n\nsched_arr_time\nflight\n0.0215937\n0.95\n0.0182176\n0.0249692\n12.5342010\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_arr_time\nair_time\n0.0789183\n0.95\n0.0755131\n0.0823217\n45.2935710\n327344\n0.0000000\nPearson correlation\n327346\n\n\nsched_arr_time\ndistance\n0.0687259\n0.95\n0.0653637\n0.0720865\n39.9777082\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_arr_time\nhour\n0.7832825\n0.95\n0.7819738\n0.7845843\n731.1906842\n336774\n0.0000000\nPearson correlation\n336776\n\n\nsched_arr_time\nminute\n0.0503212\n0.95\n0.0469518\n0.0536895\n29.2395738\n336774\n0.0000000\nPearson correlation\n336776\n\n\narr_delay\nflight\n0.0728621\n0.95\n0.0694537\n0.0762687\n41.7983960\n327344\n0.0000000\nPearson correlation\n327346\n\n\narr_delay\nair_time\n-0.0352971\n0.95\n-0.0387181\n-0.0318753\n-20.2074620\n327344\n0.0000000\nPearson correlation\n327346\n\n\narr_delay\ndistance\n-0.0618678\n0.95\n-0.0652796\n-0.0584545\n-35.4649465\n327344\n0.0000000\nPearson correlation\n327346\n\n\narr_delay\nhour\n0.1734556\n0.95\n0.1701310\n0.1767762\n100.7683213\n327344\n0.0000000\nPearson correlation\n327346\n\n\narr_delay\nminute\n0.0215222\n0.95\n0.0180979\n0.0249460\n12.3165691\n327344\n0.0000000\nPearson correlation\n327346\n\n\nflight\nair_time\n-0.4728384\n0.95\n-0.4754938\n-0.4701743\n-307.0191395\n327344\n0.0000000\nPearson correlation\n327346\n\n\nflight\ndistance\n-0.4841654\n0.95\n-0.4867468\n-0.4815755\n-321.1194483\n336774\n0.0000000\nPearson correlation\n336776\n\n\nflight\nhour\n0.0358380\n0.95\n0.0324646\n0.0392106\n20.8109689\n336774\n0.0000000\nPearson correlation\n336776\n\n\nflight\nminute\n0.0181366\n0.95\n0.0147602\n0.0215127\n10.5268290\n336774\n0.0000000\nPearson correlation\n336776\n\n\nair_time\ndistance\n0.9906496\n0.95\n0.9905857\n0.9907132\n4154.4244720\n327344\n0.0000000\nPearson correlation\n327346\n\n\nair_time\nhour\n-0.0162773\n0.95\n-0.0197018\n-0.0128523\n-9.3141118\n327344\n0.0000000\nPearson correlation\n327346\n\n\nair_time\nminute\n0.0170318\n0.95\n0.0136070\n0.0204563\n9.7459979\n327344\n0.0000000\nPearson correlation\n327346\n\n\ndistance\nhour\n-0.0188605\n0.95\n-0.0222364\n-0.0154841\n-10.9470924\n336774\n0.0000000\nPearson correlation\n336776\n\n\ndistance\nminute\n0.0197798\n0.95\n0.0164035\n0.0231556\n11.4809042\n336774\n0.0000000\nPearson correlation\n336776\n\n\nhour\nminute\n0.0417676\n0.95\n0.0383957\n0.0451386\n24.2598646\n336774\n0.0000000\nPearson correlation\n336776\n\n\n\n\n\n\n\n7.1.3 Vertiefung: Mit across\nBerechnen wir die Korrelationen jetzt mit dem Befehl across. Der Punkt . spricht hier jeweils eine Spalte an, die von across ausgew√§hlt wurde. Der Effekt ist, dass eine Korrelation von jeder Spalte mit dep_delay berechnet wird.\n\nflights3 %&gt;% \n  select(where(is.numeric)) %&gt;%  # nur die numerischen Spalten ausw√§hlen\n  summarise(across(\n    .cols = everything(),\n    .fns = ~ cor(., dep_delay))) %&gt;% \n  pivot_longer(everything()) %&gt;%  # von breit auf lang\n  arrange(-value)  # absteigend sortieren\n\n\n\n\nname\nvalue\n\n\n\n\ndep_delay\n1.0000000\n\n\narr_delay\n0.9148028\n\n\ndep_time\n0.2596127\n\n\nsched_dep_time\n0.1989235\n\n\nhour\n0.1982692\n\n\nsched_arr_time\n0.1604972\n\n\nflight\n0.0539697\n\n\narr_time\n0.0294210\n\n\nminute\n0.0282514\n\n\nday\n0.0005914\n\n\nmonth\n-0.0200547\n\n\ndistance\n-0.0216809\n\n\nair_time\n-0.0224051"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#nominale-pr√§diktoren",
    "href": "posts/flights-yacsda-eda/index.html#nominale-pr√§diktoren",
    "title": "flights-yacsda-eda",
    "section": "7.2 Nominale Pr√§diktoren",
    "text": "7.2 Nominale Pr√§diktoren\n\n7.2.1 Welche nominalen Pr√§diktoren gibt es?\nHey R, w√§hle alle nicht numerischen Spalten aus und sage mir deren Namen:\n\nflights2 %&gt;% \n  select(where(negate(is.numeric))) %&gt;% \n  names()\n\n[1] \"carrier\"    \"tailnum\"    \"origin\"     \"dest\"       \"time_hour\" \n[6] \"is_extreme\"\n\n\nJetzt kann man f√ºr jede nominale Variable die Anzahl der unterschiedlichen Auspr√§gungen abfragen:\n\nflights2 %&gt;% \n  summarise(n_distinct(carrier))\n\n\n\n\nn_distinct(carrier)\n\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.2 Carrier\ncarrier meint die Fluggesellschaft, die den jeweiligen Flug durchgef√ºhrt hat. Da stellen sich eine Reihe interessanter Fragen:\n\nWie viele verschiedene Fluggesellschaften gibt es?\nWie viele Fl√ºge hat jede davon ausgef√ºhrt?\nWelche Fluggesellschaft hat die meisten Fl√ºge ausgef√ºhrt?\nGibt es gro√üe Unterschiede in de Zahl der ausgef√ºhrten Fl√ºge.\nWer hat eigentlich die fl√ºssige Seife erfunden?\n\nFragen √ºber Fragen‚Ä¶\n\nflights2_count &lt;- \nflights2 %&gt;% \n  select(carrier) %&gt;% \n  count(carrier, sort = TRUE) \n\nflights2_count\n\n\n\n\ncarrier\nn\n\n\n\n\nUA\n58665\n\n\nB6\n54635\n\n\nEV\n54173\n\n\nDL\n48110\n\n\nAA\n32729\n\n\nMQ\n26397\n\n\nUS\n20536\n\n\n9E\n18460\n\n\nWN\n12275\n\n\nVX\n5162\n\n\nFL\n3260\n\n\nAS\n714\n\n\nF9\n685\n\n\nYV\n601\n\n\nHA\n342\n\n\nOO\n32\n\n\n\n\n\nWir brauchen eine Visualisierung dazu; das beantwortet vielleicht einen Teil der obigen Fragen.\n\n\n7.2.3 Visualisierung von carrier\n\n\n7.2.4 Mit DataExplorer\n\nflights2_count |&gt; \n  plot_scatterplot(by = \"n\")\n\n\n\n\n\n\n\n\n\n\n7.2.5 Mit ggplot\n\nplot1 &lt;- \n  flights2_count |&gt; \n  ggplot() +\n  aes(y = carrier, x = n) +\n  geom_point(color = \"red\") +\n  geom_line(group = 1)\n\nplot1\n\n\n\n\n\n\n\n\nWir m√ºssen die Werte von carrier sortieren anhand der Anzahl der Fl√ºge, sonst ist es zu un√ºbersichtlich.\n\n\n7.2.6 Vertiefung: Achsen-Labels anpassen\nDieser Abschnitt ist zur Vertiefung, er ist nicht inhaltlich wichtig\nSagen wir, wir m√∂chten die Labels der X-Achse anpassen, und zwar m√∂chten wir die Werte 25.000, 50.000, und 75.0000.\n\nplot1 +\n  scale_x_continuous(breaks = c(0, 25000, 50000, 75000),\n                     limits = c(0, 100000),\n                     labels = c(\"keine\", \"wenig\", \"mittel\", \"viel\"))\n\n\n\n\n\n\n\n\nHm, sch√∂n sieht es noch nicht aus; die limits machen nicht unbedingt Sinn. Die labels sind auch wenig sinnvoll.\nMehr zum Thema ‚ÄúAchsen aufh√ºbschen‚Äù findet sich z.B. hier.\n\n\n7.2.7 ‚ÄúLumpsensammler-Kategorie‚Äù\n\nflights2 &lt;-\n  flights2 %&gt;% \n  mutate(carrier = factor(carrier)) %&gt;%   # nicht `character`, sondern `factor` wollen\n  mutate(carrier_lump = fct_lump(carrier, n = 8)) \n\nHier fassen wir mit fct_lump alle Stufen von carrier zu acht Stufen (daher n = 8) zusammen plus einer ‚ÄúLumpensammler-Kategorie‚Äù zusammen. Dazu muss die Variable aber als factor vorliegen, was wir in der Zeile davor erledigt haben.\nJetzt haben wir noch nur 9 (8 plus Lumpensammler-Gruppe) Gruppen:\n\nflights2_lump_count &lt;-\n  flights2 %&gt;% \n  # select(carrier) %&gt;% \n  # mutate(carrier_lump = fct_lump(carrier, n = 8)) |&gt; \n  count(carrier_lump, sort = TRUE)\n\nflights2_lump_count\n\n\n\n\ncarrier_lump\nn\n\n\n\n\nUA\n58665\n\n\nB6\n54635\n\n\nEV\n54173\n\n\nDL\n48110\n\n\nAA\n32729\n\n\nMQ\n26397\n\n\nOther\n23071\n\n\nUS\n20536\n\n\n9E\n18460\n\n\n\n\n\n\n\n7.2.8 Visualisierung der Lumpensammler\n\nflights2_count &lt;-\n  flights2_count |&gt; \n  mutate(carrier =  fct_reorder(carrier, n)) |&gt; \n  count(carrier, sort = TRUE)\n\nMit fct_reorder haben wir die Werte von carrier (UA, B6, AA, ‚Ä¶) sortiert und zwar anhand der Werte von n, also anhand der H√§ufigkeit. Es resultiert eine Rangfolge: UA &gt; B6 &gt; EV &gt; DL &gt; ... etc. (Nur) Mit einer sortierten Faktorvariable l√§sst sich entsprechendes Diagramm gut sortiert darstellen.\n\n7.2.8.1 Mit ggplot\nLiniendiagramm:\n\nflights2_lump_count |&gt; \n  ggplot() +\n  aes(y = carrier_lump, x = n) +\n  geom_point(color = \"red\") +\n  geom_line(group = 1)\n\n\n\n\n\n\n\n\nAh, schon besser. Aber recht informationsarm, das Diagramm. Informationsreicher als das Liniendiagramm ist ein Boxplot:\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  ggplot() +\n  aes(x = carrier_lump, \n      y = dep_delay) %&gt;% \n  geom_boxplot()\n\n\n\n\n\n\n\n\nEine alternative Darstellung w√§re ein Letter Value Plot.\nSchauen wir uns mal die Mediane genauer an:\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  group_by(carrier_lump) %&gt;% \n  summarise(dep_delay = median(dep_delay, na.rm = TRUE)) %&gt;% \n  arrange(dep_delay)\n\n\n\n\ncarrier_lump\ndep_delay\n\n\n\n\nUS\n-5\n\n\nMQ\n-4\n\n\n9E\n-3\n\n\nAA\n-3\n\n\nDL\n-3\n\n\nEV\n-3\n\n\nB6\n-2\n\n\nUA\n-1\n\n\nOther\n0\n\n\n\n\n\nDie Reihenfolge entspricht der dem obigen Diagramm."
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#korrelation-von-carrier-mit-versp√§tung",
    "href": "posts/flights-yacsda-eda/index.html#korrelation-von-carrier-mit-versp√§tung",
    "title": "flights-yacsda-eda",
    "section": "7.3 Korrelation von carrier mit Versp√§tung",
    "text": "7.3 Korrelation von carrier mit Versp√§tung\nHier mit ‚ÄúDummysierung‚Äù aller nicht-numerischer Spalten. Ein Beispiel zur Verdeutlichung:\n\nflights2 &lt;- \n  flights2 %&gt;% \n  mutate(\n    originJFK = case_when(\n      origin == \"JFK\" ~ 1,  # \"1\" wenn JFK, \n      origin != \"JFK\" ~ 0   # ansonsten 0\n    ),  \n    originLGA = case_when(\n      origin == \"LGA\" ~ 1,  # \"1\" wenn LGA,\n      TRUE ~ 0,  # in allen anderen F√§llen (\"TRUE\") 0\n    )\n  )\n\n\nflights2 %&gt;% \n  select(origin, originJFK, originLGA) %&gt;% \n  slice(1:5)\n\n\n\n\norigin\noriginJFK\noriginLGA\n\n\n\n\nEWR\n0\n0\n\n\nLGA\n0\n1\n\n\nJFK\n1\n0\n\n\nJFK\n1\n0\n\n\nLGA\n0\n1\n\n\n\n\n\nDiese Art der Umwandlung von mehrstufig-nominal in eine bin√§re Variable (0-1-Variable, oder ‚ÄúIndikatorvariable‚Äù) kann man sich auch z.B. mit der Funktion dummy_cols() (aus dem Paket fastDummies) bewerkstelligen lassen:\n\nflights2 %&gt;% \n  select(origin, dep_delay) %&gt;% \n  dummy_cols() %&gt;%  # aus dem Paket `fastDummies`\n  head()  # slice(1:6)\n\n\n\n\norigin\ndep_delay\norigin_EWR\norigin_JFK\norigin_LGA\n\n\n\n\nEWR\n2\n1\n0\n0\n\n\nLGA\n4\n0\n0\n1\n\n\nJFK\n2\n0\n1\n0\n\n\nJFK\n-1\n0\n1\n0\n\n\nLGA\n-6\n0\n0\n1\n\n\nEWR\n-4\n1\n0\n0\n\n\n\n\n\nMit den ‚Äúdummyisierten‚Äù Spalten k√∂nnen wir jetzt Korrelationen rechnen, denn jetzt haben wir Zahlen. Achtung: Die Variablen bleiben nominalskaliert, trotz der 0-1-Transformation. Auf diese Art Korrelationen zu berechnen ist nur f√ºr dummysierte Variablen (‚ÄúIndikatorvariablen‚Äù) sinnvoll. Die Schiefe der Verteilung begrenzt hier √ºbrigens die St√§rke der Korrelation.\n\nflights2 %&gt;% \n  select(dep_delay, carrier) %&gt;% \n  dummy_cols() %&gt;%   # \"Dummysierung\"\n  select(-carrier) %&gt;% \n  pivot_longer(-dep_delay,\n               names_to = \"carrier\",\n               values_to = \"value\") %&gt;% \n  group_by(carrier) %&gt;% \n  summarise(cor_depdelay_carrier = cor(dep_delay, value,\n                                       use = \"complete.obs\")) %&gt;% \n  arrange(-abs(cor_depdelay_carrier)) %&gt;% \n  filter(abs(cor_depdelay_carrier) &gt; 0.10)\n\n\n\n\ncarrier\ncor_depdelay_carrier\n\n\n\n\n\n\n\nKeine Korrelation war (im Betrag) gr√∂√üer als 0.1. Also gab es nur vernachl√§ssigbare Korrelationen und im Output wurde daher nichts angezeigt.\nZur Erinnerung: Es ist nicht unbedingt n√∂tig, die ‚ÄúDummyisierung‚Äù durchzuf√ºhren, ein einfaches Vergleichen der Mittelwerte (oder Mediane) mit ihrer Streuung f√ºhrt zu einem √§hnlichen Ergebnis. Die Regression mit lm f√ºhrt f√ºr Sie automatisch die Dummyisierung durch.\n\n7.3.1 Hour\n\n7.3.1.1 Mit ggplot\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(dep_delay, hour) %&gt;% \n  mutate(hour = factor(hour)) %&gt;% \n  ggplot() +\n  aes(x = fct_reorder(hour, dep_delay,\n                      na.rm = TRUE), \n      y = dep_delay) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n7.3.1.2 Mit DataExplorer\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(dep_delay, hour) %&gt;% \n  mutate(hour = factor(hour)) %&gt;% \n  plot_boxplot(by = \"hour\")\n\n\n\n\n\n\n\n\n\n\n\n7.3.2 Origin\n\n7.3.2.1 Mit ggplot\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(origin, dep_delay) %&gt;% \n  ggplot() +\n  aes(x = origin, y = dep_delay) %&gt;% \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n7.3.2.2 Mit DataExplorer\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(origin, dep_delay) %&gt;% \n  plot_boxplot(by = \"origin\")"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#drei-variablen-origin-hour-dep_delay",
    "href": "posts/flights-yacsda-eda/index.html#drei-variablen-origin-hour-dep_delay",
    "title": "flights-yacsda-eda",
    "section": "7.4 Drei Variablen: Origin, hour, dep_delay",
    "text": "7.4 Drei Variablen: Origin, hour, dep_delay\n\n7.4.0.1 Mit ggplot\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(origin, dep_delay, hour) %&gt;% \n  mutate(hour = factor(hour, levels = 5:23)) %&gt;% \n  ggplot() +\n  aes(x = hour, y = dep_delay) +\n  geom_boxplot() +\n  facet_wrap(~ origin)\n\n\n\n\n\n\n\n\n\n\n7.4.0.2 Mit ggpubr\n\nflights2 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(origin, dep_delay, hour) %&gt;% \n  mutate(hour = factor(hour, levels = 5:23)) %&gt;% \n  ggboxplot(x = \"hour\", y = \"dep_delay\", facet.by = \"origin\")"
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#vertiefung-alle-nominale-variablen",
    "href": "posts/flights-yacsda-eda/index.html#vertiefung-alle-nominale-variablen",
    "title": "flights-yacsda-eda",
    "section": "7.5 Vertiefung: Alle nominale Variablen",
    "text": "7.5 Vertiefung: Alle nominale Variablen\nNat√ºrlich k√∂nnte man ‚Äúh√§ndisch‚Äù alle nominalskalierten Variablen explizit benennen, etwa so:\n\nflights3 %&gt;% \n  select(carrier, tailnum, origin, dest, time_hour) %&gt;% \n  slice(1:3)\n\n\n\n\ncarrier\ntailnum\norigin\ndest\ntime_hour\n\n\n\n\nUA\nN14228\nEWR\nIAH\n2013-01-01 05:00:00\n\n\nUA\nN24211\nLGA\nIAH\n2013-01-01 05:00:00\n\n\nAA\nN619AA\nJFK\nMIA\n2013-01-01 05:00:00\n\n\n\n\n\nAber es geht auch etwas ‚Äúcooler‚Äù mit weniger Tipperei:\n\nflights3 %&gt;% \n  select(where(~ !is.numeric(.))) %&gt;%  # w√§hle alle nicht-numerischen Spalten\n  names()\n\n[1] \"carrier\"    \"tailnum\"    \"origin\"     \"dest\"       \"time_hour\" \n[6] \"is_extreme\"\n\n\n\n7.5.1 flights4\n\nflights4 &lt;-\nflights3 %&gt;% \n  mutate(dest = fct_lump_prop(dest, prop = .025)) \n\nMit fct_lump_prop fassen wir alle Stufen zu einer zusammen, die jeweils weniger als 2.5% der F√§√§le ausmachen.\n\nflights4 %&gt;% \n  count(dest, sort = T)\n\n\n\n\ndest\nn\n\n\n\n\nOther\n172061\n\n\nATL\n16837\n\n\nORD\n16566\n\n\nLAX\n16026\n\n\nBOS\n15022\n\n\nMCO\n13967\n\n\nCLT\n13674\n\n\nSFO\n13173\n\n\nFLL\n11897\n\n\nMIA\n11593\n\n\nDCA\n9111\n\n\nDTW\n9031\n\n\nDFW\n8388\n\n\n\n\n\n\n\n7.5.2 Visualisierung im Grid\n\nflights4 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(dep_delay, dest, origin, carrier) %&gt;% \n  group_by(dest, origin, carrier) %&gt;% \n  summarise(depdelay_md = median(dep_delay, na.rm = T)) %&gt;% \n  ggplot() +\n  aes(x = origin, y = depdelay_md, color = origin) +\n  facet_grid(dest ~ carrier) +\n  geom_point()\n\n\n\n\n\n\n\n\nPuh, das Diagramm ist nicht sehr aussagekr√§ftig. Vielleicht besser als Tabelle?\n\nflights4 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(dep_delay, dest, origin, carrier) %&gt;% \n  group_by(dest, origin, carrier) %&gt;% \n  summarise(depdelay_md = median(dep_delay, na.rm = T))\n\n# A tibble: 128 √ó 4\n# Groups:   dest, origin [37]\n   dest  origin carrier depdelay_md\n   &lt;fct&gt; &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;\n 1 ATL   EWR    9E               -6\n 2 ATL   EWR    DL               -3\n 3 ATL   EWR    EV               -2\n 4 ATL   EWR    UA               -1\n 5 ATL   JFK    9E               -2\n 6 ATL   JFK    DL               -1\n 7 ATL   LGA    DL               -3\n 8 ATL   LGA    EV               30\n 9 ATL   LGA    FL                0\n10 ATL   LGA    MQ               -4\n# ‚Ñπ 118 more rows\n\n\nHm, ist auch nicht gerade n√ºtzlich.\nDas Beispiel zeigt, dass die Datenvisualisierung bei einer gr√∂√üeren Zahl an Dimensionen und/oder vielen Werten an ihre Grenzen kommen kann."
  },
  {
    "objectID": "posts/flights-yacsda-eda/index.html#anzahl-von-fl√ºge",
    "href": "posts/flights-yacsda-eda/index.html#anzahl-von-fl√ºge",
    "title": "flights-yacsda-eda",
    "section": "7.6 Anzahl von Fl√ºge",
    "text": "7.6 Anzahl von Fl√ºge\n\n7.6.1 Vorbereitung\n\nflights4_sum &lt;- \n  flights4 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(month, origin, dep_delay) %&gt;% \n  drop_na() %&gt;% \n  group_by(month, origin) %&gt;% \n  summarise(delay_md = median(dep_delay),\n            delay_iqr = IQR(dep_delay),\n            delay_n = n()) %&gt;% \n  mutate(month = factor(month),\n         delay_n = as.numeric(delay_n))\n\n\n\n7.6.2 Visualisierung mit ggplot\n\nflights4 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(month, origin, dep_delay) %&gt;% \n  mutate(month = factor(month)) %&gt;% \n  drop_na() %&gt;% \n  ggplot() +\n  aes(x = month, y = dep_delay, color = origin) +\n  geom_violin() +\n  geom_point(data = flights4_sum, \n             aes(y = delay_md,\n                 x = month)) +\n  facet_wrap( ~ origin)\n\n\n\n\n\n\n\n\n\n\n7.6.3 Visualisierung mit ggpubr\n\nflights4 %&gt;% \n  filter(!is_extreme) %&gt;% \n  select(month, origin, dep_delay) %&gt;% \n  mutate(month = factor(month)) %&gt;% \n  drop_na() %&gt;% \n  ggviolin(x = \"month\", y = \"dep_delay\", facet.by = \"origin\",\n           color = \"origin\")"
  },
  {
    "objectID": "posts/Rethink2m5/Rethink2m5.html",
    "href": "posts/Rethink2m5/Rethink2m5.html",
    "title": "Rethink2m5",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\n2M5. Now suppose there are four cards: B/B, B/W, W/W, and another B/B. Again suppose a card is drawn from the bag and a black side appears face up. Again calculate the probability that the other side is black.\n         \n\n\nL√∂sung\nThe only difference to the question 2M4 is that we now have two bb cards, rendering the prior plausibility for balck twice as high. The rest is the same as in 2M4.\nLet‚Äôs label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nWanted is the probability that the second side of the card is black (2b), given one side is already identified as black (1b): \\(Pr(2b|1b)\\).\n\nlibrary(tidyverse)\n\n\nd &lt;-\n  tibble::tribble(\n  ~Hyp, ~Prior,\n  \"bb\",     2, \n  \"bw\",     1,   \n  \"ww\",     1, \n  ) %&gt;% \n  mutate(Likelihood = c(2,1,0),\n         unstand_post = Prior*Likelihood,\n         std_post = unstand_post / sum(unstand_post))\n\n\n\n\n\n\n\n\n\nHyp\nPrior\nLikelihood\nunstand_post\nstd_post\n\n\n\n\nbb\n2\n2\n4\n0.80\n\n\nbw\n1\n1\n1\n0.20\n\n\nww\n1\n0\n0\n0.00\n\n\n\n\n\n\n\nTables like this are sometimes called ‚ÄúBayes Box‚Äù or ‚ÄúBayes Grid‚Äù.\nAlternatively, we can write out the two black cards not in one, but in two rows, so that each black card gets it own row.\n\n\n\n\n\n\n\n\nHyp\nPrior\nLikelihood\nunstand_post\nstd_post\n\n\n\n\nbb\n1\n2\n2\n0.40\n\n\nbb\n1\n2\n2\n0.40\n\n\nbw\n1\n1\n1\n0.20\n\n\nww\n1\n0\n0\n0.00\n\n\n\n\n\n\n\nThe second Bayes Box yields the same probability as the first, which is reassuring. However, it feels a bit akward (at least to me) to write down the same hypothesis twice.\n\nCategories:\n\nprobability\nbayes\nbayesbox\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/bike03/bike03.html",
    "href": "posts/bike03/bike03.html",
    "title": "bike03",
    "section": "",
    "text": "Kann man die Anzahl gerade verliehener Fahrr√§der eines entsprechenden Anbieters anhand der Temperatur vorhersagen?\nIn dieser √úbung untersuchen wir diese Frage.\nSie k√∂nnen die Daten von der Webseite der UCI herunterladen.\nWir beziehen uns auf den Datensatz day.\nBerechnen Sie einen Entscheidungsbaum mit der Anzahl der aktuell vermieteten R√§der als AV und der aktuellen Temperatur als UV!\nTunen Sie den Cp-Parameter des Baumes; lassen Sie sich 20 Tuningparameter vorschlagen.\nGeben Sie den MSE an!\nHinweise"
  },
  {
    "objectID": "posts/bike03/bike03.html#data-split",
    "href": "posts/bike03/bike03.html#data-split",
    "title": "bike03",
    "section": "Data split",
    "text": "Data split\n\nset.seed(42)\nd_split &lt;- initial_split(d, strata = cnt)\n\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/bike03/bike03.html#define-recipe",
    "href": "posts/bike03/bike03.html#define-recipe",
    "title": "bike03",
    "section": "Define recipe",
    "text": "Define recipe\n\nrec1 &lt;- \n  recipe(cnt ~ temp, data = d)"
  },
  {
    "objectID": "posts/bike03/bike03.html#define-model",
    "href": "posts/bike03/bike03.html#define-model",
    "title": "bike03",
    "section": "Define model",
    "text": "Define model\n\nm1 &lt;-\n  decision_tree(cost_complexity = tune(),\n                mode = \"regression\")"
  },
  {
    "objectID": "posts/bike03/bike03.html#tuning-grid",
    "href": "posts/bike03/bike03.html#tuning-grid",
    "title": "bike03",
    "section": "Tuning grid",
    "text": "Tuning grid\n\ngrid &lt;-\n  grid_regular(cost_complexity(), levels = 20)\ngrid\n\nAlternativ:\n\ngrid &lt;-\n  grid_regular(extract_parameter_set_dials(m1), levels = 20)\ngrid"
  },
  {
    "objectID": "posts/bike03/bike03.html#define-resamples",
    "href": "posts/bike03/bike03.html#define-resamples",
    "title": "bike03",
    "section": "Define Resamples",
    "text": "Define Resamples\n\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/bike03/bike03.html#workflow",
    "href": "posts/bike03/bike03.html#workflow",
    "title": "bike03",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(m1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/bike03/bike03.html#fit",
    "href": "posts/bike03/bike03.html#fit",
    "title": "bike03",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;- tune_grid(\n  object = wf1, \n  resamples = rsmpl)\ntoc()\nfit1"
  },
  {
    "objectID": "posts/bike03/bike03.html#bester-kandidat",
    "href": "posts/bike03/bike03.html#bester-kandidat",
    "title": "bike03",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nshow_best(fit1)\n\n\nwf1_best &lt;-\n  wf1 %&gt;% \n  finalize_workflow(parameters = select_best(fit1))"
  },
  {
    "objectID": "posts/bike03/bike03.html#last-fit",
    "href": "posts/bike03/bike03.html#last-fit",
    "title": "bike03",
    "section": "Last Fit",
    "text": "Last Fit\n\nfit_testsample &lt;- last_fit(wf1_best, d_split)"
  },
  {
    "objectID": "posts/bike03/bike03.html#model-performance-metrics-in-test-set",
    "href": "posts/bike03/bike03.html#model-performance-metrics-in-test-set",
    "title": "bike03",
    "section": "Model performance (metrics) in test set",
    "text": "Model performance (metrics) in test set\n\nfit_testsample %&gt;% collect_metrics()\n\n\nMSE &lt;- fit_testsample %&gt;% collect_metrics() %&gt;% pluck(3, 1)\nMSE\n\nSolution:\n\nCategories:\n\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/Postvert-Regr-01/Postvert-Regr-01.html",
    "href": "posts/Postvert-Regr-01/Postvert-Regr-01.html",
    "title": "Postvert-Regr-01",
    "section": "",
    "text": "Nach der Berechnung bzw. Sch√§tzung der Modellparameter eines Regressionsmodells (mit Methoden der Bayes-Inferenz) erh√§lt man u.a. auf den Pr√§diktorwert \\(x\\) und die Modellparameter \\(\\theta\\) bedingte Wahrscheinlichkeiten \\(p\\) f√ºr den Wert der AV, \\(y = k\\), oder anders gesagt f√ºr \\(y = k|(X,\\theta)\\) (mit \\(\\theta\\) f√ºr die Modellparameter).\nBetrachten Sie dazu folgende Aussage:\n\\(Pr(y|x, \\alpha, \\beta, \\sigma) = c\\)\nWelche der Aussagen ist in diesem Zusammenhang falsch?\n\n\n\nDas Regressionsmodell hat 3 Parameter.\nDas Regressionsmodell hat 1 Pr√§diktor (im Sinne von 1 Inputvariablen).\n\\(Pr(y = a |x = a', \\beta_0, \\beta_1, \\sigma) &gt; Pr(y = b|x = b', \\beta_0, \\beta_1, \\sigma)\\)\n\\(\\sum_{k = -\\infty}^{+\\infty} Pr(y = k|x_i, \\alpha, \\beta, \\sigma) = 1\\)\n\\(Pr(y = k|x, \\beta_0, \\beta_1, \\sigma) = p, \\qquad p \\in [0,1]\\)"
  },
  {
    "objectID": "posts/Postvert-Regr-01/Postvert-Regr-01.html#answerlist",
    "href": "posts/Postvert-Regr-01/Postvert-Regr-01.html#answerlist",
    "title": "Postvert-Regr-01",
    "section": "",
    "text": "Das Regressionsmodell hat 3 Parameter.\nDas Regressionsmodell hat 1 Pr√§diktor (im Sinne von 1 Inputvariablen).\n\\(Pr(y = a |x = a', \\beta_0, \\beta_1, \\sigma) &gt; Pr(y = b|x = b', \\beta_0, \\beta_1, \\sigma)\\)\n\\(\\sum_{k = -\\infty}^{+\\infty} Pr(y = k|x_i, \\alpha, \\beta, \\sigma) = 1\\)\n\\(Pr(y = k|x, \\beta_0, \\beta_1, \\sigma) = p, \\qquad p \\in [0,1]\\)"
  },
  {
    "objectID": "posts/Postvert-Regr-01/Postvert-Regr-01.html#answerlist-1",
    "href": "posts/Postvert-Regr-01/Postvert-Regr-01.html#answerlist-1",
    "title": "Postvert-Regr-01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Das Modell hat tats√§chlich drei zu sch√§tzende Parameter: \\(\\alpha, \\beta, \\sigma\\).\nWahr. Das Modell hat tats√§chlich einen Pr√§diktor, \\(x_i\\).\nWahr. Die Aussage beahuptet, dass die Wahrscheinlichkeit f√ºr \\(y = a\\) bei \\(x = a'\\) gr√∂√üer ist als die Wahrscheinlichkeit f√ºr \\(y = b\\) bei \\(x = b'\\). Das ist nicht immer, d.h. f√ºr alle m√∂glichen Werte von \\(y\\) und \\(x\\) zwangsl√§ufig richtig. Wenn es nicht immer richtig ist ist die Aussage daher falsch.\nWahr. Die Wahrscheinlichkeiten f√ºr alle m√∂glichen \\(y\\) f√ºr eine bestimmte Beobachtung summiert sich tats√§chlich zu 1 auf.\nWahr. Eine Wahrscheinlichkeit kann tats√§chlich zwischen 0 und 1 liegen, wobei die Grenzen nur in Extremf√§llen vorkommen.\n\n\nCategories:\n\nregression\nbayes\npost"
  },
  {
    "objectID": "posts/Test-MSE2/Test-MSE2.html",
    "href": "posts/Test-MSE2/Test-MSE2.html",
    "title": "Test-MSE2",
    "section": "",
    "text": "Anhand der folgenden Abbildung sollen Aussagen zur Test-MSE (Mean Squared Error) untersucht werden.\n\nIn der linken Teil-Abbildung zeigt die Gerade die wahre Funktion; die √ºbrigen Kurven sind verschiedene gesch√§tzte Funktionen. In der rechten Teil-Abbildungen sind verschiedene Fehlerarten der gesch√§tzten Funktionen dargestellt (in Bezug zur linken Teil-Abbildung).\nWelche Aussage zur rechten Teil-Abbildung ist richtig?\n\n\n\nDie obere (konvexe, nach rechts ansteigende) Kurve zeigt den Test-Fehler.\nDie obere (konvexe, nach rechts ansteigende) Kurve zeigt den Train-Fehler.\nKurven, die den Testfehler in Abh√§ngigkeit der Modellflexibilit√§t zeigen, sind nicht U-f√∂rmig.\nKurven, die den Trainfehler in Abh√§ngigkeit der Modellflexibilit√§t zeigen, gehen nicht gegen Null.\nBei sehr hoher Modellflexibilit√§t n√§hern sich die Kurven f√ºr Train- und Testfehler zunehmend an."
  },
  {
    "objectID": "posts/Test-MSE2/Test-MSE2.html#answerlist",
    "href": "posts/Test-MSE2/Test-MSE2.html#answerlist",
    "title": "Test-MSE2",
    "section": "",
    "text": "Die obere (konvexe, nach rechts ansteigende) Kurve zeigt den Test-Fehler.\nDie obere (konvexe, nach rechts ansteigende) Kurve zeigt den Train-Fehler.\nKurven, die den Testfehler in Abh√§ngigkeit der Modellflexibilit√§t zeigen, sind nicht U-f√∂rmig.\nKurven, die den Trainfehler in Abh√§ngigkeit der Modellflexibilit√§t zeigen, gehen nicht gegen Null.\nBei sehr hoher Modellflexibilit√§t n√§hern sich die Kurven f√ºr Train- und Testfehler zunehmend an."
  },
  {
    "objectID": "posts/Test-MSE2/Test-MSE2.html#answerlist-1",
    "href": "posts/Test-MSE2/Test-MSE2.html#answerlist-1",
    "title": "Test-MSE2",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/kollision-eignung/kollision-eignung.html",
    "href": "posts/kollision-eignung/kollision-eignung.html",
    "title": "kollision-eignung",
    "section": "",
    "text": "Sagen wir, √ºber die Eignung, e, f√ºr ein Studium w√ºrden nur (die individuellen Auspr√§gungen) von Intelligenz (iq) und Fleiss (fleiss) entscheiden, s. den DAG in Figure¬†1.\n\n\n\n\n\n\n\n\nFigure¬†1: Kollisionsstruktur im Dag zur Studiumseignung, mit s f√ºr Studium, f f√ºr fleiss und iq f√ºr Intelligenz\n\n\n\n\n\nBei positiver Eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\nEignung (f√ºrs Studium) sei definiert als die Summe von iq und fleiss, plus etwas Gl√ºck, s. Listing¬†1.\n\n\n\n\nListing¬†1: Eignung ist die Summe von Fleiss und Intelligenz, plus ein Quentchen Gl√ºck\n\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\n\n\n\nLaut unserem Modell setzt sich Eignung zur H√§lfte aus Intelligenz und zur H√§lfte aus Fleiss zusammen, plus etwas Gl√ºck.\nAufgabe: Zeigen Sie, dass eine Scheinkorrelation entsteht zwischen fleiss und iq, wenn man studium kontrolliert. Zeigen Sie au√üerdem, dass die Scheinkorrelation verschwindet, wenn man studium nicht kontrolliert.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks."
  },
  {
    "objectID": "posts/kollision-eignung/kollision-eignung.html#setup",
    "href": "posts/kollision-eignung/kollision-eignung.html#setup",
    "title": "kollision-eignung",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/kollision-eignung/kollision-eignung.html#modell-nur-studis",
    "href": "posts/kollision-eignung/kollision-eignung.html#modell-nur-studis",
    "title": "kollision-eignung",
    "section": "Modell Nur-Studis",
    "text": "Modell Nur-Studis\nHier ist das Modell, in dem wir nur Studenten betrachten, also studium == 1.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, \n           data = d_eignung %&gt;%  filter(studium == 1), \n           refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n0.7004608\n0.8596029\nfixed\nconditional\n\n\nfleiss\n0.95\n-0.5266816\n-0.3634545\nfixed\nconditional\n\n\n\n\n\nplot(estimate_relation(m_eignung))\n\n\n\n\n\n\n\n\nWie man sieht, gibt es einen Zusammenhang zwischen Fleiss und Intelligenz."
  },
  {
    "objectID": "posts/kollision-eignung/kollision-eignung.html#modell-alle-menschen",
    "href": "posts/kollision-eignung/kollision-eignung.html#modell-alle-menschen",
    "title": "kollision-eignung",
    "section": "Modell Alle-Menschen",
    "text": "Modell Alle-Menschen\n\nm_eignung_gesamtpop &lt;-\n  stan_glm(iq ~ fleiss, \n           data = d_eignung , \n           refresh = 0)\n\nplot(estimate_relation(m_eignung_gesamtpop))\n\nhdi(m_eignung_gesamtpop)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-0.0878065\n0.0344352\nfixed\nconditional\n\n\nfleiss\n0.95\n-0.0509851\n0.0723826\nfixed\nconditional\n\n\n\n\n\n\n\n\n\n\n\n\n\nWie man sieht, l√∂st sich der Zusammenhang zwischen Fleiss und Intelligenz auf, wenn man studium nicht kontrolliert."
  },
  {
    "objectID": "posts/mutate02/mutate02.html",
    "href": "posts/mutate02/mutate02.html",
    "title": "mutate02",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nErzeugen Sie eine Spalte zu_teuer, die folgende Pr√ºfung durchf√ºhrt: total_pr &gt; 100.\nBerechnen Sie dann den Mittelwert der ‚Äúzu teueren‚Äù Spiele.\nHinweise:\n\nRunden Sie auf die n√§chste ganze Zahl.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nmariokart |&gt; \n  mutate(zu_teuer = total_pr &gt; 100) |&gt; \n  filter(zu_teuer == TRUE) |&gt; \n  summarise(mw_zu_teuere_spiele = mean(total_pr))\n\n\n\n\n\nmw_zu_teuere_spiele\n\n\n\n\n222.505\n\n\n\n\n\n\nDie Antwort lautet: 223.\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/anim01/anim01.html",
    "href": "posts/anim01/anim01.html",
    "title": "anim01",
    "section": "",
    "text": "Visualisieren Sie in animierter Form den Zusammenhang von Lebenserwartung und Bruttosozialprodukt im Verlauf der Jahre (Datensatz gapminder); der Kontinent soll in der Visualisierung ber√ºcksichtigt sein.\nHinweise:\n\nNutzen Sie gganimate zur Visualisierung."
  },
  {
    "objectID": "posts/anim01/anim01.html#setup",
    "href": "posts/anim01/anim01.html#setup",
    "title": "anim01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(gganimate)\ndata(gapminder)"
  },
  {
    "objectID": "posts/anim01/anim01.html#statisches-diagramm",
    "href": "posts/anim01/anim01.html#statisches-diagramm",
    "title": "anim01",
    "section": "Statisches Diagramm",
    "text": "Statisches Diagramm\n\np &lt;- gapminder %&gt;% \n  ggplot(aes(x = gdpPercap, y = lifeExp, color = continent, frame = year)) +\n  geom_point()+\n  scale_x_log10()\np"
  },
  {
    "objectID": "posts/anim01/anim01.html#animation",
    "href": "posts/anim01/anim01.html#animation",
    "title": "anim01",
    "section": "Animation",
    "text": "Animation\n\ngapminder$continent &lt;- as.factor(gapminder$continent)\n\np_animated &lt;- ggplot(gapminder,\n            aes(x = gdpPercap, \n                y = lifeExp, \n                color = continent)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_discrete() +   # &lt;- force discrete scale\n  labs(title = \"Year: {frame_time}\") +\n  transition_time(year)\n\np_animated\n\nDieser Post orientiert sich an dieser Quelle; dort finden sich auch mehr Beispiele.\n\nCategories:\n\n2023\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/kekse03/index.html",
    "href": "posts/kekse03/index.html",
    "title": "kekse03",
    "section": "",
    "text": "Exercise\nStellen Sie sich vor, vor Ihnen stehen drei Schalen mit Keksen. Lecker.\n  \nSchale 1 enth√§lt 30 Vanillekekse und 10 Schokoladenkekse. Schale 2 ist identisch zu Schale 1. Schale 3 enth√§lt 20 Vanillekekse und 20 Schokoladenkekse. Schalen 1 und 2 sind blau . Schale 3 ist rot .\nSie w√§hlen eine der Schalen zuf√§llig aus und ziehen ohne hinzusehen einen Keks. Der Keks ist Vanille. \nAufgabe Mit welcher Wahrscheinlichkeit stammt der Keks aus einer blauen  Schale? Berechnen Sie die Wahrscheinlichkeit!\n(Basierend auf einer Aufgabe aus Think Bayes von Allen Downey.)\nHinweise:\n\nErstellen Sie eine Bayesbox zur L√∂sung dieser Aufgabe.\nGehen Sie davon aus, dass Sie (apriori) indifferent gegen√ºber der Hypothesen sind.\nGeben Sie Prozentzahlen immer als Anteil an und lassen Sie die f√ºhrende Null weg (z.B. .42).\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\n\n\n\n\nHypothesen\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\nblau\n0.67\n0.75\n0.50\n0.75\n\n\nrot\n0.33\n0.50\n0.17\n0.25\n\n\n\n\n\n\nggbarplot(data = d, x = \"Hypothesen\", y = \"Post\", \n       ylab = \"Posteriori-Wahrscheinlichkeit\", xlab = \"Hypothesen\",\n       title = \"Posteriori-Wahrscheinlichkeit f√ºr Vanillekeks aus Schale 1\",\n       label = TRUE)\n\n\n\n\n\n\n\n\nDie Antwort lautet: 0.75.\nEs ist √ºbrigens egal, welche konkreten Zahlen Sie f√ºr die Priori-Wahrscheinlichkeit w√§hlen. Das Ergebnis bleibt das gleiche. Das Verh√§ltnis der Zahlen muss nur gleich bleiben, also: 2,1 und 2/3, 1/3 stehen jeweils im Verh√§ltnis 3:1. Probieren Sie es aus!\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\nblau\n2\n0.75\n1.5\n0.75\n\n\nrot\n1\n0.50\n0.5\n0.25"
  },
  {
    "objectID": "posts/rf-finalize/rf-finalize.html",
    "href": "posts/rf-finalize/rf-finalize.html",
    "title": "rf-finalize",
    "section": "",
    "text": "Aufgabe\n\nBerechnen Sie ein pr√§diktives Modell mit dieser Modellgleichung:\nbody_mass_g ~ . (Datensatz: palmerpenguins::penguins).\nBerichten Sie den RSMSE im Test-Sample!\nHinweise: - Tunen Sie mtry - Verwenden Sie Kreuzvalidierung - Verwenden Sie Standardwerte, wo nicht anders angegeben. - Fixieren Sie Zufallszahlen auf den Startwert 42.\n         \n\n\nL√∂sung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# rm NA in the dependent variable:\nd &lt;- d %&gt;% \n  drop_na(body_mass_g)\n\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_rf &lt;-\n  rand_forest(mode = \"regression\",\n           mtry = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_rf) %&gt;% \n  add_recipe(rec_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n21.808 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n\n\n\nmtry\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n3\nrmse\nstandard\n280.8153\n10\n11.206073\npre0_mod3_post0\n\n\n2\nrmse\nstandard\n282.0886\n10\n11.401888\npre0_mod2_post0\n\n\n6\nrmse\nstandard\n283.1617\n10\n9.830670\npre0_mod6_post0\n\n\n8\nrmse\nstandard\n283.1983\n10\n10.600386\npre0_mod8_post0\n\n\n7\nrmse\nstandard\n283.2110\n10\n9.983912\npre0_mod7_post0\n\n\n\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellg√ºte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n322.7491683\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8228114\npre0_mod0_post0\n\n\n\n\n\n\nAchtung: step_impute_knn scheint Probleme zu haben, wenn es Charakter-Variablen gibt.\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/kausal-bedrooms1/kausal-bedrooms1.html",
    "href": "posts/kausal-bedrooms1/kausal-bedrooms1.html",
    "title": "kausal-bedrooms1",
    "section": "",
    "text": "Exercise\nBetrachten wir den Datensatz SaratogaHouses, den Sie hier herunterladen k√∂nnen. Ein Codebook findet sich hier.\nSie kommen auch so an die Daten ran:\n\nlibrary(mosaicData)\ndata(\"SaratogaHouses\")\n\nGegeben sei in diesem Zusammenhang folgender DAG:\n\ndag1 &lt;- \"\ndag{\na -&gt; p\na -&gt; b -&gt; p\n}\n\"\n\nWobei a f√ºr (living) area steht, also der Wohnfl√§che eines Hauses, b f√ºr bedrooms, der Anzahl der Schlafzimmer und p f√ºr prize, den Preis, den das Haus beim Verkauf erzielt hat.\nSo sieht das dann aus:\n\nggdag(dag1) + theme_dag()\n\n\n\n\n\n\n\n\nUV sei a; AV sei p.\n\nBerechnen Sie den direkten Effekt der Wohnfl√§che auf den Preis!\nBerechnen Sie den totalen Effekt der Wohnfl√§che auf den Preis!\n\nMit direkter Effekt ist der kausale Effekt von UV auf AV - ohne Zwischenglieder (Mediatoren) - gemeint. Mit indirekter Effekt ist der kausale Effekt von UV √ºber einen (oder ggf. mehrere) Mediator(en) auf die AV gemeint. Mit totaler Effekt ist die Summe des direkten plus des oder der indirekten Effekte gemeint.\nDas folgende Diagramm verdeutlicht diese drei Arten von Kausal-Effekten.\n\n(CC-BY-SA, 3275Sartell, Wikipedia)\nHinweise:\n\nGeben Sie jeweils den Punktsch√§tzer eines linearen Regressionsmodells an!\nGehen Sie vom oben genannten DAG aus.\nRunden Sie ohne Dezimalstellen.\n\n         \n\n\nSolution\n\nd &lt;-\n  SaratogaHouses %&gt;% \n  select(price, bedrooms, livingArea) %&gt;% \n  drop_na()\n\n\ndirekter Effekt:\n\n\ndirekter_eff_lm &lt;-\n  stan_glm(price ~ bedrooms + livingArea, \n           data = d,\n           refresh = 0)\ncoef(direkter_eff_lm)\n\n(Intercept)    bedrooms  livingArea \n 36658.5282 -14124.9083    125.4117 \n\n\nUm einen direkten Effekt zu berechnen, m√ºssen wir den spezifischen, uniquen Effekt der UV berechnen. Das erreichen wir durch eine multiple Regression, in der also die √ºbrigen Pr√§diktoren aufgenommen sind. Das Resultat ist ein Koeffizient f√ºr die Assoziation der UV mit der AV, bereinigt um die Zusammenh√§nge der √ºbrigen Pr√§diktoren.\nZur Erinnerung: Die multiple Regression liefert Koeffizienten pro Pr√§diktor, die bereinigt sind um den (statistischen) Einfluss der anderen Pr√§diktoren, mit anderne Worten: die Koeffizienten der multiplen Regression zeigen den Effekt von ‚Äúnur diesem Pr√§diktor‚Äù.\nDer Punktsch√§tzer f√ºr den direkten Effekt (von Wohnfl√§che) ist:\n\ndirekter_eff &lt;-\n  coef(direkter_eff_lm)[3] %&gt;% \n  round(0)\n\ndirekter_eff\n\nlivingArea \n       125 \n\n\n\ntotaler Effekt:\n\n\n\n(Intercept)  livingArea \n 13299.5700    113.1698 \n\n\nDer totale Effekt l√§sst sich berechnen, in dem man keine weiteren Pr√§diktoren neben der UV in die Regression mitaufnimmt. Die einfache (univariate) Regression zeigt den totalen Effekt der UV auf die AV.\nDer Punktsch√§tzer f√ºr den totalen Effekt betr√§gt:\n\n\nlivingArea \n       113 \n\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/bike02/bike02.html",
    "href": "posts/bike02/bike02.html",
    "title": "bike02",
    "section": "",
    "text": "Kann man die Anzahl gerade verliehener Fahrr√§der eines entsprechenden Anbieters anhand der Temperatur vorhersagen?\nIn dieser √úbung untersuchen wir diese Frage.\nSie k√∂nnen die Daten von der Webseite der UCI herunterladen.\nWir beziehen uns auf den Datensatz day.\nBerechnen Sie einen Entscheidungsbaum mit der Anzahl der aktuell vermieteten R√§der als AV und der aktuellen Temperatur als UV!\nTunen Sie den Cp-Parameter des Baumes.\nGeben Sie den MSE an!\nHinweise"
  },
  {
    "objectID": "posts/bike02/bike02.html#data-split",
    "href": "posts/bike02/bike02.html#data-split",
    "title": "bike02",
    "section": "Data split",
    "text": "Data split\n\nset.seed(42)\nd_split &lt;- initial_split(d, strata = cnt)\n\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/bike02/bike02.html#define-recipe",
    "href": "posts/bike02/bike02.html#define-recipe",
    "title": "bike02",
    "section": "Define recipe",
    "text": "Define recipe\n\nrec1 &lt;- \n  recipe(cnt ~ temp, data = d)"
  },
  {
    "objectID": "posts/bike02/bike02.html#define-model",
    "href": "posts/bike02/bike02.html#define-model",
    "title": "bike02",
    "section": "Define model",
    "text": "Define model\n\nm1 &lt;-\n  decision_tree(cost_complexity = tune(),\n                mode = \"regression\")"
  },
  {
    "objectID": "posts/bike02/bike02.html#define-resamples",
    "href": "posts/bike02/bike02.html#define-resamples",
    "title": "bike02",
    "section": "Define Resamples",
    "text": "Define Resamples\n\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/bike02/bike02.html#workflow",
    "href": "posts/bike02/bike02.html#workflow",
    "title": "bike02",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(m1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/bike02/bike02.html#fit",
    "href": "posts/bike02/bike02.html#fit",
    "title": "bike02",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;- tune_grid(\n  object = wf1, \n  resamples = rsmpl)\ntoc()\nfit1"
  },
  {
    "objectID": "posts/bike02/bike02.html#bester-kandidat",
    "href": "posts/bike02/bike02.html#bester-kandidat",
    "title": "bike02",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nshow_best(fit1)\n\n\nwf1_best &lt;-\n  wf1 %&gt;% \n  finalize_workflow(parameters = select_best(fit1))"
  },
  {
    "objectID": "posts/bike02/bike02.html#last-fit",
    "href": "posts/bike02/bike02.html#last-fit",
    "title": "bike02",
    "section": "Last Fit",
    "text": "Last Fit\n\nfit_testsample &lt;- last_fit(wf1_best, d_split)"
  },
  {
    "objectID": "posts/bike02/bike02.html#model-performance-metrics-in-test-set",
    "href": "posts/bike02/bike02.html#model-performance-metrics-in-test-set",
    "title": "bike02",
    "section": "Model performance (metrics) in test set",
    "text": "Model performance (metrics) in test set\n\nfit_testsample %&gt;% collect_metrics()\n\n\nMSE &lt;- fit_testsample %&gt;% collect_metrics() %&gt;% pluck(3, 1)\nMSE\n\nSolution:\n\nCategories:\n\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/mw-berechnen/mw-berechnen.html",
    "href": "posts/mw-berechnen/mw-berechnen.html",
    "title": "mw-berechnen",
    "section": "",
    "text": "Question\n\nAufgabe\nBerechnen Sie den Mittelwert folgender zahlenreihe; ignorieren sie etwaige fehlende Werte. Runden Sie auf zwei Dezimalstellen.\n\n\n[1] -0.02  0.59 -0.20  0.82 -1.27    NA\n\n\n         \n\n\nL√∂sung\nDer Mittelwert liegt bei -0.02.\nDie Antwort lautet -0.02.\nIn R kann man den Mittelwert z.B. so berechnen:\n\nmean(zahlenreihe, na.rm = TRUE)\n\n[1] -0.016\n\n\nDas Argument na.rm = TRUE sorgt daf√ºr, dass R auch bei Vorhandensein fehlender Werte ein Ergebnis ausgibt. Ohne dieses Argument w√ºrde R ein spr√∂des NA zur√ºckgeben, falls fehlende Werte vorliegen. Dieses Verhalten von R ist recht defensiv, getreu dem Motto: Wenn es ein Problem gibt, sollte man so fr√ºh wie m√∂glich dar√ºber deutlich informiert werden (und nicht erst, wenn die Marsrakete gestartet ist‚Ä¶).\n\nCategories:\n\neda\ndatawrangling\ndyn\nnum"
  },
  {
    "objectID": "posts/rope2a/index.html",
    "href": "posts/rope2a/index.html",
    "title": "rope2a",
    "section": "",
    "text": "Im Datensatz mtcars: Ist der (mittlere) Unterschied im Spritverbrauch (mpg) zwischen den beiden Gruppen Automatik vs.¬†Schaltgetriebe vernachl√§ssigbar?\nWir definieren ‚Äúvernachl√§ssigbar klein‚Äù als ‚Äúh√∂chstens eine Meile‚Äù.\nPr√ºfen Sie rechnerisch, anhand des angegebenen Datensatzes, folgende Behauptung:\nBehauptung: ‚ÄúDer Unterschied ist vernachl√§ssigbar klein!‚Äù\nNutzen Sie das ROPE-Konzept mit den Standardwerten im Befehl rope aus {easystats}.\nW√§hlen Sie die Antwortoption, die am besten zu der obigen Behauptung passt!\nHinweise"
  },
  {
    "objectID": "posts/rope2a/index.html#answerlist",
    "href": "posts/rope2a/index.html#answerlist",
    "title": "rope2a",
    "section": "Answerlist",
    "text": "Answerlist\n\nJa, die Behauptung ist korrekt.\nNein, die Behauptung ist falsch.\nDie Daten sind bzw. das Modell nicht konkludent; es ist keine Entscheidung √ºber die Behauptung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Antwort m√∂glich."
  },
  {
    "objectID": "posts/rope2a/index.html#answerlist-1",
    "href": "posts/rope2a/index.html#answerlist-1",
    "title": "rope2a",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\nrope\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/penguins-regr02a/index.html",
    "href": "posts/penguins-regr02a/index.html",
    "title": "penguins-regr02a",
    "section": "",
    "text": "library(tidyverse)\n\n\nAufgabe\nBeantworten Sie folgende Forschungsfrage:\nGibt es einen Zusammenhang von Schnabell√§nge und Gewicht (AV) bei Pinguinen?\nNutzen Sie die folgende Analyse f√ºr Ihre Antwort.\nWir rufen Stan:\n\nüßë‚Äçüè´ Hey, Stan, komm mal r√ºber! Wir haben da eine Frage an dich.\n\n\nü§ñ Beep, beep, beep! Bitte nur gute Fragen.\n\nSetup:\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(penguins)\n\nModell:\n\nm1 &lt;- stan_glm(body_mass_g ~ bill_length_mm, \n               seed = 42,\n               refresh = 0,\n               data = penguins)\n\nParameter:\n\nparameters(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n359.9393\n0.95\n-210.59190\n927.8249\n0.89575\n1.000485\n4117.553\nnormal\n4201.754\n2004.8863\n\n\nbill_length_mm\n87.4472\n0.95\n74.55696\n100.2532\n1.00000\n1.000491\n4123.761\nnormal\n0.000\n367.2233\n\n\n\n\n\n\nRope:\n\nrope(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-80.19545\n80.19545\n0.1084211\nfixed\nconditional\n\n\nbill_length_mm\n0.95\n-80.19545\n80.19545\n0.1131579\nfixed\nconditional\n\n\n\n\n\n\nHier wird ein Bereich von ¬±80 Gramm als ‚Äúvernachl√§ssigbar‚Äù angesehen. Diese Voreinstellung sollte nur als grobe Orientierung dienen und sollte an die spezifische Forschungsfrage angepasst werden. Ihr Fachwissen sollte besser sein als dieser Default-Wert.\nVisualisierung:\n\nplot(rope(m1))\n\n\n\n\n\n\n\n\n         \n\n\nL√∂sung\nHier ist also keine klare Aussage zur Frage, ob der Effekt vernachl√§ssigbar klein ist oder gr√∂√üer, m√∂glich.\n\nCategories:\n\nlm\nbayes\nrope\nstring"
  },
  {
    "objectID": "posts/ames-kaggle1/ames-kaggle1.html",
    "href": "posts/ames-kaggle1/ames-kaggle1.html",
    "title": "ames-kaggle1",
    "section": "",
    "text": "Berechnen Sie ein einfaches lineare Modell f√ºr die Ames House Price Kaggle Competition.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/ames-kaggle1/ames-kaggle1.html#pakete-starten",
    "href": "posts/ames-kaggle1/ames-kaggle1.html#pakete-starten",
    "title": "ames-kaggle1",
    "section": "Pakete starten",
    "text": "Pakete starten\n\nlibrary(tidyverse)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/ames-kaggle1/ames-kaggle1.html#daten-importieren",
    "href": "posts/ames-kaggle1/ames-kaggle1.html#daten-importieren",
    "title": "ames-kaggle1",
    "section": "Daten importieren",
    "text": "Daten importieren\n\nd_train_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/train.csv\"\nd_test_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/test.csv\"\nd_train &lt;- read_csv(d_train_path_online)\nd_test &lt;- read_csv(d_test_path_online)"
  },
  {
    "objectID": "posts/ames-kaggle1/ames-kaggle1.html#model-definieren",
    "href": "posts/ames-kaggle1/ames-kaggle1.html#model-definieren",
    "title": "ames-kaggle1",
    "section": "Model definieren",
    "text": "Model definieren\n\nm1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)"
  },
  {
    "objectID": "posts/ames-kaggle1/ames-kaggle1.html#neue-daten-vorhersagen",
    "href": "posts/ames-kaggle1/ames-kaggle1.html#neue-daten-vorhersagen",
    "title": "ames-kaggle1",
    "section": "Neue Daten vorhersagen",
    "text": "Neue Daten vorhersagen\n\nm1_pred &lt;- predict(m1, newdata = d_test)"
  },
  {
    "objectID": "posts/ames-kaggle1/ames-kaggle1.html#daten-einreichen",
    "href": "posts/ames-kaggle1/ames-kaggle1.html#daten-einreichen",
    "title": "ames-kaggle1",
    "section": "Daten einreichen",
    "text": "Daten einreichen\n\nd_subm &lt;-\n  d_test %&gt;% \n  select(Id) %&gt;% \n  mutate(SalePrice = m1_pred)\n\nhead(d_subm)\n\n\n\n\n\nId\nSalePrice\n\n\n\n\n1461\n130972.9\n\n\n1462\n176408.7\n\n\n1463\n130972.9\n\n\n1464\n176408.7\n\n\n1465\n267280.3\n\n\n1466\n176408.7\n\n\n\n\n\n\n\nwrite_csv(d_subm, file = \"einreichen-kaggle-modell1-yeah.csv\")\n\n\nCategories:\n\nregression\names\nkaggle\nstring"
  },
  {
    "objectID": "posts/totale-wskt1/totale-wskt1.html",
    "href": "posts/totale-wskt1/totale-wskt1.html",
    "title": "totale-Wskt1",
    "section": "",
    "text": "Aufgabe\nWas ist die Wahrscheinlichkeit, bei einem Krebstest ein positives Testergebnis (Ereignis \\(T\\)) zu bekommen?\nEs gibt zwei M√∂glichkeiten f√ºr ein positives Testergebnis: Wenn man Krebs hat (\\(K\\)) und wenn man nicht Krebs hat (\\(\\neg K\\)).\n\\(Pr(T|K) = 9/10\\), das ist die ‚ÄúKrebs-Erkenn-Sicherheit‚Äù des Tests.\n\\(Pr(T|\\neg K) = 99/891\\), das ist die ‚ÄúFehlalarm-Quote‚Äù des Tests.\nDie Grundrate von Krebs sei \\(Pr(K) = .01\\).\nAufgabe Berechnen Sie die Wahrscheinlichkeit \\(Pr(T)\\), dass ein positives Testergebnis vorliegt.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nDie Ereignisse \\(K\\) und \\(\\neg K\\) bilden ein vollst√§ndiges Ereignissystem. Daher ist der Satz von der totalen Wahrscheinlichkeit anzuwenden.\n\\(Pr(T) = Pr(T|K) \\cdot Pr(K) + Pr(T| \\neg K) \\cdot Pr(\\neg K)\\).\n\nPr_T_geg_K &lt;- 9/10\nPr_K &lt;- .01\nPr_NK &lt;- 1 - Pr_K  # Wskt f√ºr Nicht-Krebs\nPr_T_geg_NK &lt;- 99/990  # 10% Fehlerrate (falsch positiv)\nPr_T &lt;- Pr_T_geg_K * Pr_K + Pr_T_geg_NK * Pr_NK\nPr_T\n\n[1] 0.108\n\n\n\nT: Test (auf Krebs) ist positiv\nK: Krebs liegt vor\nNK: Krebs liegt nicht vor\n\nDie L√∂sung lautet 0.108.\nEinfacher vielleicht ist ein Baumdiagramm:\n\n\n\n\n\n\nflowchart LR\n  A[1000 Personen] -. K_Pos .-&gt; B[10]\n  A -. K_neg .-&gt; C[990]\n  B -. T_pos .-&gt; D[9]\n  B -. T_neg .-&gt; E[1]\n  C -. T_pos .-&gt; F[99]\n  C -. T_neg .-&gt; G[891]\n  D --- H[9/10 richtig positiv]\n  E --- I[1/10 falsch negativ]\n  F --- J[99/990 falsch positiv]\n  G --- K[891/990 richtig negativ]\n\n\n\n\nFigure¬†1: G√ºnstige Pfade\n\n\n\n\n\nInsgesamt bekommen also 9+99 = 108 Personen (von 1000), d.h. ca. 11%, ein positives Testergebnis, davon sind 9 tats√§chlich krank und 99 sind gesund.\n\nCategories:\n\nR\nprobability\nbayes\nnum"
  },
  {
    "objectID": "posts/tidymodels-vorlage/tidymodels-vorlage.html",
    "href": "posts/tidymodels-vorlage/tidymodels-vorlage.html",
    "title": "tidymodels-vorlage",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse f√ºr ein Vorhersagemodell, das sich als Vorlage f√ºr Analysen dieser Art eignet!\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie mind. einen Parameter des Modells\nVerwenden Sie Kreuzvalidierung\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\n# 2023-05-08\n\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(baguette)  # Bagged-Trees\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_bag &lt;-\n  bag_tree(mode = \"regression\",\n           cost_complexity = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- recipe(body_mass_g ~  ., data = d_train)\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_bag) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n53.406 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncost_complexity\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0064392\nrmse\nstandard\n302.1977\n10\n16.11540\npre0_mod09_post0\n\n\n0.0000010\nrmse\nstandard\n303.9024\n10\n19.22696\npre0_mod05_post0\n\n\n0.0000000\nrmse\nstandard\n305.0243\n10\n15.34343\npre0_mod03_post0\n\n\n0.0000429\nrmse\nstandard\n305.2490\n10\n19.95539\npre0_mod07_post0\n\n\n0.0000043\nrmse\nstandard\n308.3078\n10\n16.17880\npre0_mod06_post0\n\n\n\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellg√ºte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n329.9022032\npre0_mod0_post0\n\n\nrsq\nstandard\n0.8458163\npre0_mod0_post0\n\n\n\n\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/prob-voll-esystem/index.html",
    "href": "posts/prob-voll-esystem/index.html",
    "title": "prob-voll-esystem",
    "section": "",
    "text": "1 Aufgabe\nEine Menge von Ereignissen \\(\\{A_1, A_2, A_3\\}\\) bildet ein vollst√§ndiges (disjunktes) Ereignissystem. Was wissen Sie sicher √ºber die Wahrscheinlichkeiten dieser Ereignisse?\n\n\\(Pr(A_1) = Pr(A_2) = Pr(A_3)\\)\n\\(Pr(A_1 \\cap A_2 \\cap  A_3) = 1\\)\n\\(Pr(A_1 \\cup A_2 \\cup  A_3) = 1\\)\n\\(Pr(A_1) + Pr(A_2) + Pr(A_3) = 1\\)\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\n\\(Pr(A_1 \\cup A_2 \\cup  A_3) = 1\\)\n\\(Pr(A_1) + Pr(A_2) + Pr(A_3) = 1\\)\n\n\n\n\n\n\n\n\n\nOption\nRichtig/Falsch\nBegr√ºndung\n\n\n\n\nA\n‚ùå Falsch\nWahrscheinlichkeiten m√ºssen nicht gleich sein\n\n\nB\n‚ùå Falsch\nSchnittmenge ist leer, nicht 1\n\n\nC\n‚úÖ Richtig\nVereinigung = Grundraum ‚Üí Wahrscheinlichkeit 1\n\n\nD\n‚úÖ Richtig\nDisjunkt + vollst√§ndig ‚Üí Summe = 1"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html",
    "href": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html",
    "title": "Verteilungen-Quiz-05",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nIst eine stetige Verteilung symmetrisch, dann gilt\n\\(Pr(X \\ge \\bar{x} + 1) = Pr(X \\le \\bar{x} - 1)\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html#answerlist",
    "href": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html#answerlist",
    "title": "Verteilungen-Quiz-05",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/wskt-quiz10/wskt-quiz10.html",
    "href": "posts/wskt-quiz10/wskt-quiz10.html",
    "title": "wskt-quiz10",
    "section": "",
    "text": "Sei \\(X \\sim U(0, 2)\\).\nBehauptung: Es gilt: \\(f(X=1) = .5\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz10/wskt-quiz10.html#answerlist",
    "href": "posts/wskt-quiz10/wskt-quiz10.html#answerlist",
    "title": "wskt-quiz10",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz10/wskt-quiz10.html#answerlist-1",
    "href": "posts/wskt-quiz10/wskt-quiz10.html#answerlist-1",
    "title": "wskt-quiz10",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistributions\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html",
    "href": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html",
    "title": "Verteilungen-Quiz-02",
    "section": "",
    "text": "Beziehen Sie sich auf den Standard-Globusversuch mit \\(N=9\\) W√ºrfen und \\(W=6\\) Wassertreffern (binomialverteilt).\nAufgabe: Ist es (auf dieser Basis) plausibler von einem 50%-PI [.6,.8] auszugehen als von einem 50%-PI [.05,.95]?\n\n\n  Ja    Nein    Keine Antwort m√∂glich \n\nAntworten"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html#answerlist",
    "href": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html#answerlist",
    "title": "Verteilungen-Quiz-02",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/options-print/options-print.html",
    "href": "posts/options-print/options-print.html",
    "title": "options-print",
    "section": "",
    "text": "Aufgabe\nWie kann man in R kontrollieren, wie viele Zeilen eines Tibbles gedruckt werden (am Bildschrirm)?\nFixieren Sie die Werte auf min. 5 und max. 10.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\noptions(paged.print = FALSE,\n        pillar.print_max = 15, \n        pillar.print_min = 5)\n\n\nmtcars\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\nMerc 450SE\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\nMerc 450SL\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\nMerc 450SLC\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\nCadillac Fleetwood\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\nLincoln Continental\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\nChrysler Imperial\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\nFiat 128\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\nHonda Civic\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\nToyota Corolla\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\nToyota Corona\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\nmtcars &lt;- as_tibble(mtcars)\nmtcars\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n\n\n\nCategories:\n\n2023\nR\ntidyverse\nmarkdown\nstring"
  },
  {
    "objectID": "posts/mtcars-regr01/mtcars-regr01.html",
    "href": "posts/mtcars-regr01/mtcars-regr01.html",
    "title": "mtcars-regr01",
    "section": "",
    "text": "Aufgabe\n\ndata(\"mtcars\")\n\nBetrachten Sie folgendes Modell (Datensatz mtcars):\nmpg ~ disp\nAnders gesagt: Wie gut kann man den Spritverbrauch vorhersagen auf Basis des Hubraums eines Autos?\n\nBerechnen Sie die Modellkoeffizienten! Tipp: lm()\nBerechnen Sie im Anschluss die Vorhersagen dieses Modells. Tipp: predict() mit mutate()\nVisualisieren Sie dann das Modell Tipp: ggplot() und geom_smooth() oder mittels einer anderer Methode.\nBerechnen Sie die Residuen: e = echtem Y-Wert und vorhergesagtem Y-Wert. Tipp: mutate().\nBerechnen Sie die Korrelation zwischen Spritverbrauch und Hubraum! Tipp: summarise() mitcor()`.\n\n         \n\n\nL√∂sung\n\n\nVorbereitung\n\nlibrary(tidyverse)\ndata(mtcars)\n\n\n\nAd 1\n\nlm1 &lt;- lm(mpg ~ disp, data = mtcars)\nlm1\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122  \n\n\n\n\nAd 2\nNicht einfach nur predicten:\n\npredict(lm1)\n\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive \n           23.00544            23.00544            25.14862            18.96635 \n  Hornet Sportabout             Valiant          Duster 360           Merc 240D \n           14.76241            20.32645            14.76241            23.55360 \n           Merc 230            Merc 280           Merc 280C          Merc 450SE \n           23.79677            22.69220            22.69220            18.23272 \n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental \n           18.23272            18.23272            10.14632            10.64090 \n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla \n           11.46520            26.35622            26.47987            26.66946 \n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 \n           24.64992            16.49345            17.07046            15.17456 \n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa \n           13.11381            26.34386            24.64168            25.68030 \n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E \n           15.13335            23.62366            17.19410            24.61283 \n\n\nSondern die Predictions als neue Spalte in mtcars anlegen. Viel sauberer!\n\nmtcars2  &lt;- \n  mtcars %&gt;% \n  mutate(preds_lm1 = predict(lm1))\n\n\n\nAd 3\n\nggplot(mtcars2) +\n  aes(y = mpg, x = disp) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAndere Visualisierung:\n\nmtcars2 %&gt;% \n  ggplot(aes(x = disp, y = preds_lm1)) +\n  geom_point(size = 2, alpha = .8, color = \"pink\") +\n  geom_line() +\n  labs(y = \"Vorhergesagte MPG-Werte\",\n       title = \"Vorhersage-Modell lm1\")\n\n\n\n\n\n\n\n\nOder so:\n\nlibrary(easystats)\nestimate_expectation(lm1, by = \"disp\") %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\nAd 4\n\nmtcars2 &lt;- \n  mtcars2 %&gt;% \n  mutate(e = abs(mpg - preds_lm1))  # abs steht f√ºr \"Absolutwert\"\n\nDer ‚ÄúAbsolutwert‚Äù kickt das Vorzeichen weg. Das machen wir, wenn wir meinen, dass das Vorzeichen egal ist.\n\n\nBonus-Aufgabe\nBerechnen Sie den mittleren Fehler √ºber alle e!\n\nmtcars2 %&gt;% \n  summarise(e_avg = mean(e))\n\n\n\n\n\ne_avg\n\n\n\n\n2.605473\n\n\n\n\n\n\n\n\nAd 5\n\nmtcars %&gt;% \n  summarise(cor_mpg_disp = cor(mpg, disp))\n\n\n\n\n\ncor_mpg_disp\n\n\n\n\n-0.8475514\n\n\n\n\n\n\n\nCategories:\n\nlm\nmtcars\ncorrelation\nregression\nstring"
  },
  {
    "objectID": "posts/alphafehler-inflation3/alphafehler-inflation3.html",
    "href": "posts/alphafehler-inflation3/alphafehler-inflation3.html",
    "title": "alphafehler-inflation3",
    "section": "",
    "text": "Aufgabe\nEine Klettererin verwendet ein Seil, dass eine Sicherheit von \\(r=.99\\) hat: mit einer Wahrscheinlichkeit von 1% rei√üt das Seil. Jetzt kn√ºpft sie mehrere dieser Seile (hintereinander, Seil an Seil) zusammen zu einem ‚ÄúGesamtseil‚Äù. Wie gro√ü ist die Gefahr, dass das ‚ÄûGesamtseil‚Äú reist?\nHinweise:\n\nEtwaige (physikalisch plausible) Verringerung der Zugfestigkeit durch (Seilbiegung aufgrund der) Knoten ist zu vernachl√§ssigen.\nSie kn√ºpft 10 Seile zusammen.\nBeachten Sie die sonstigen Hinweise auf dem Datenwerk.\nUnterstellen Sie Unabh√§ngkeit der einzelnen Ereignisse.\n\n         \n\n\nL√∂sung\nSei \\(R\\) die Wahrscheinlichkeit, dass das Gesamtseil h√§lt (nicht rei√üt). \\(1-R\\) ist dann die Wahrscheinlichkeit des Gegenereignisses: das Gesamtseil rei√üt.\nAllgemein ist \\(R\\) bei \\(k\\) Tests (Seilen) gleich \\(r\\) hoch \\(k\\): \\(R=r^k\\). (Das Aufaddieren der Fehlalarm-Wahrscheinlichkeit bezeichnet man als Alphafehler-Inflation.)\n\nr &lt;- .99  #  Rei√üfestigkeit des einfaches Seils\nR10 &lt;- r^10  %&gt;% round(2)  # Rei√üfestigkeit des 10-fachen Seils\n\nDie Gesamtsicherheit lauten also:\n\nR10\n\n[1] 0.9\n\n\nDie Antwort (solution) ist aber \\(1-R\\):\n\nsolution &lt;- 1-R10\nsolution\n\n[1] 0.1\n\n\n\n\nVertiefung\nBetrachten wir abschlie√üend aus Neugier die Wahrscheinlichkeit, dass die Klettererin abst√ºrzt (\\(1-R\\)) als Funktion der Anzahl der Seie.\nDiese √úberlegung ist etwas weiterf√ºhrender und nicht ganz so zentral, aber ziemlich interessant.\nDefinieren wir die Parameter:\n\nanz_seile &lt;- 1:20  # von 1 bis max 20 Seile\nr &lt;- c(.9, .95, .99, .999)  # verschiedene Seil-Sicherheiten\n\nJetzt erstellen wir einen Tabelle, die alle anz_seile * r Werte kombiniert:\n\nd &lt;- \n  expand_grid(anz_seile, r)\n\nhead(d)\n\n\n\n\n\nanz_seile\nr\n\n\n\n\n1\n0.900\n\n\n1\n0.950\n\n\n1\n0.990\n\n\n1\n0.999\n\n\n2\n0.900\n\n\n2\n0.950\n\n\n\n\n\n\nJetzt berechnen wir f√ºr jede Kombination die Gesamtsicherheit R sowie die Wahrscheinlichkeit, dass das Seil rei√üt, \\(1-R\\):\n\nd &lt;-\n  d %&gt;% \n  mutate(R = r^anz_seile,\n         seil_reisst_prob = 1 - R)\n\nplotten das Ganze mit dem Paket ggpubr:\n\nlibrary(ggpubr)\nd &lt;-\n  d |&gt; \n  mutate(r_fctr = factor(r))  # um \"r\" zum Gruppieren zu verwenden, sollte es eine nominale Variable sein, daher wandeln wir mit \"factor\" in eine nominale Variable um.\n\nggline(d,\n       x = \"anz_seile\",\n       y = \"seil_reisst_prob\",\n       color = \"r_fctr\",\n       linetype = \"r_fctr\",\n       group = \"r_fctr\") +\n  labs(color = \"Rei√üfestigkeit\",\n       linetype = \"Rei√üfestigkeit\")\n\n\n\n\n\n\n\n\nOder mit ggplot plotten:\n\nd %&gt;% \n  ggplot(aes(x = anz_seile,\n             y = seil_reisst_prob,\n             color = factor(r))) +\n  geom_line() +\n  labs(color = \"Rei√üfestigkeit\")\n\n\n\n\n\n\n\n\nHat ein Seil eine Sicherheit von 90%, dann will man nicht dranh√§ngen, wenn 20 Seile zusammengeknotet sind!\nDie Antwort lautet:\n\n\\(R_{10}= 1-r^{10} = 1 - 0.9 = 0.1\\)\n\n\nCategories:\n\nprobability\nR\ninference\nnum"
  },
  {
    "objectID": "posts/Cluster02/Cluster02.html",
    "href": "posts/Cluster02/Cluster02.html",
    "title": "Cluster02",
    "section": "",
    "text": "F√ºr einen bestimmten Datensatz soll ein hierarchisches Clustering vorgenommen werden, einmal mittels Single Linkage und einmal mittels Complete Linkage.\nZu einem bestimmten Punkt im mittels Single-Linkage-Verfahren erstellten Dendrogramm fusionieren die Cluster \\({5}\\) und \\({6}\\). Im Dendrogramm, das durch Complete-Linkage erstellt wurde, fusionieren die Cluster \\({5}\\) und \\({6}\\) ebenfalls an einem bestimmten Punkt. Bei welchem der beiden Verfahren liegt der Fusionierungspunkt h√∂her im Baum (Dendrogramm)?\n\n\n\nDer Fusionierungspunkt liegt auf der gleichen H√∂he.\nDer Fusionierungspunkt liegt beim Single-Linkage-Verfahren h√∂her im Baum als beim Complete-Linkage-Verfahren.\nDer Fusionierungspunkt liegt beim Single-Linkage-Verfahren tiefer im Baum als beim Complete-Linkage-Verfahren.\nDie Angaben lassen keine Aussage zu."
  },
  {
    "objectID": "posts/Cluster02/Cluster02.html#answerlist",
    "href": "posts/Cluster02/Cluster02.html#answerlist",
    "title": "Cluster02",
    "section": "",
    "text": "Der Fusionierungspunkt liegt auf der gleichen H√∂he.\nDer Fusionierungspunkt liegt beim Single-Linkage-Verfahren h√∂her im Baum als beim Complete-Linkage-Verfahren.\nDer Fusionierungspunkt liegt beim Single-Linkage-Verfahren tiefer im Baum als beim Complete-Linkage-Verfahren.\nDie Angaben lassen keine Aussage zu."
  },
  {
    "objectID": "posts/Cluster02/Cluster02.html#answerlist-1",
    "href": "posts/Cluster02/Cluster02.html#answerlist-1",
    "title": "Cluster02",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html",
    "title": "Wskt-Schluckspecht",
    "section": "",
    "text": "Pr√ºfen Sie folgende Hypothese:\n\nAutos mit viel PS haben einen h√∂heren Spritverbrauch als Autos mit wenig PS.\n\nQuantifizieren Sie die Wahrscheinlichkeit dieser Hypothese!\nHinweise:\n\n‚Äúviel PS‚Äù definieren wir als ‚Äúmehr als der Median‚Äù.\nVerwenden Sie den Datensatz mtcars.\nNutzen Sie die Bayes-Statistik mit Stan.\nBeachten Sie die Standardhinweise des Datenwerks."
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#setup",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#setup",
    "title": "Wskt-Schluckspecht",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell",
    "title": "Wskt-Schluckspecht",
    "section": "Modell",
    "text": "Modell\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{mpg}_{PS=0} &gt; \\text{mpg}_{PS=1}\\],\nwobei \\(PS=0\\) die Autos mit wenig PS meint."
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#vorverarbeitung",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#vorverarbeitung",
    "title": "Wskt-Schluckspecht",
    "section": "Vorverarbeitung",
    "text": "Vorverarbeitung\n\nmtcars &lt;-\n  mtcars |&gt; \n  mutate(PS = case_when(\n    mpg &gt; median(mpg) ~ 1,\n    mpg &lt;= median(mpg) ~ 0\n  ))"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell-berechnen",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell-berechnen",
    "title": "Wskt-Schluckspecht",
    "section": "Modell berechnen",
    "text": "Modell berechnen\n\nm &lt;- stan_glm(mpg ~ PS,\n              data = mtcars,\n              refresh = 0,\n              seed = 42)\n\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n15.676776\n0.95\n13.809508\n17.53648\n1\n0.9996718\n3301.939\nnormal\n20.09062\n15.06737\n\n\nPS\n9.418845\n0.95\n6.789333\n12.12306\n1\n0.9997315\n3548.579\nnormal\n0.00000\n29.71825"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#post-verteilung-auslesen",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#post-verteilung-auslesen",
    "title": "Wskt-Schluckspecht",
    "section": "Post-Verteilung auslesen",
    "text": "Post-Verteilung auslesen\n\nm_post &lt;-\n  m |&gt;\n  as_tibble()\n\nprop &lt;- \nm_post |&gt; \n  count(PS &gt;= 0) |&gt; \n  mutate(prop = n/sum(n))\n\nprop\n\n\n\n\n\nPS &gt;= 0\nn\nprop\n\n\n\n\nTRUE\n4000\n1"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#antwort",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#antwort",
    "title": "Wskt-Schluckspecht",
    "section": "Antwort",
    "text": "Antwort\nLaut unserem Modell betr√§gt die Wahrscheinlichkeit f√ºr obige Hypothese 1."
  },
  {
    "objectID": "posts/wskt-quiz19/wskt-quiz19.html",
    "href": "posts/wskt-quiz19/wskt-quiz19.html",
    "title": "wskt-quiz19",
    "section": "",
    "text": "Behauptung:\nDie folgenden Variablen haben (alle) ‚ÄúFat Tails‚Äù: Intelligenz (IQ) und das Einkommen von Musikern.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz19/wskt-quiz19.html#answerlist",
    "href": "posts/wskt-quiz19/wskt-quiz19.html#answerlist",
    "title": "wskt-quiz19",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz19/wskt-quiz19.html#answerlist-1",
    "href": "posts/wskt-quiz19/wskt-quiz19.html#answerlist-1",
    "title": "wskt-quiz19",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/interpret-ci2/index.html",
    "href": "posts/interpret-ci2/index.html",
    "title": "interpret-ci2",
    "section": "",
    "text": "1 Aufgabe\nWelche der folgenden Aussagen zur Interpretation eines Populationsparameters (z.B. \\(\\mu\\)) eines Konfidenzintervalls der Art 95% CI [182cm; 184cm] ist richtig bzw. passt am besten?\n\nW√ºrde man die Studie sehr oft wiederholen, w√ºrden 95% der entstehenden Konfidenzintervalle den wahren Wert beinhalten.\n\n\nPasst nur zur Bayesianischen, nicht zur Frequentistischen Statistik\nPasst nur zur Frequentistischen, nicht zur Bayesianischen Statistik\nPasst sowohl zur Frequentistischen, als auch zur Bayesianischen Statistik\nPasst weder zur Frequentistischen, noch zur Bayesianischen Statistik\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nPasst nur zur Frequentistischen, nicht zur Bayesianischen Statistik"
  },
  {
    "objectID": "posts/penguins-stan-02a/index.html",
    "href": "posts/penguins-stan-02a/index.html",
    "title": "penguins-stan-02a",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nAufgabe:\nWie gro√ü ist der statistische Einfluss der UV auf die AV?\nGeben Sie die Breite eines 90%-HDI an (zum Effekt)!\nHinweise:\n\nNutzen Sie den Datensatz zu den Palmer Penguins.\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nWeitere Hinweise\nNutzen Sie die folgende Analyse als Grundlage Ihrer Antwort.\n\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1, ci_method = \"hdi\", ci = .9, keep = \"bill_length_mm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\nbill_length_mm\n87.4472\n0.9\n76.99955\n98.3694\n1\n1.000491\n4123.761\nnormal\n0\n367.2233\n\n\n\n\n\n\n         \n\n\nL√∂sung\nDie L√∂sung lautet also, wie aus der Ausgabe von parameters() ersichtlich, 21.37.\n\nhdi(m1, ci = .9) |&gt; plot()\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/gruppenvergleich-regression/index.html",
    "href": "posts/gruppenvergleich-regression/index.html",
    "title": "gruppenvergleich-regression",
    "section": "",
    "text": "Beurteilen Sie folgende Aussagen:\n\nMan kann die Forschungsfrage, ob sich zwei Gruppen (Populationen) hinsichtlich ihres Mittelwerts unterscheiden, mit einer Regressionsanalyse untersuchen.\n\n\n\n\nNein, man sollte stattdessen einen t-Test verwenden.\nJa, beide Verfahren sind gleichwertig.\nJa, beide Verfahren sind analog, aber die Regression hat Vorz√ºge.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/gruppenvergleich-regression/index.html#antwortoptionen",
    "href": "posts/gruppenvergleich-regression/index.html#antwortoptionen",
    "title": "gruppenvergleich-regression",
    "section": "",
    "text": "Nein, man sollte stattdessen einen t-Test verwenden.\nJa, beide Verfahren sind gleichwertig.\nJa, beide Verfahren sind analog, aber die Regression hat Vorz√ºge.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/likelihood-nv/likelihood-nv.html",
    "href": "posts/likelihood-nv/likelihood-nv.html",
    "title": "likelihood-nv",
    "section": "",
    "text": "1 Aufgabe\nWas ist die Wahrscheinlichkeit, einen IQ-Wert von max. 115 zu beobachten, wenn mu=100 und sd=15?\nIn Kurzschreibweise:\n\\(L(X=115|\\mu = 100, \\sigma = 15), X \\sim N\\)\nHinweise:\n\nIQ wird normalverteilt angenommen.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n84%"
  },
  {
    "objectID": "posts/Typ-Fehler-R-08-name-clash/Typ-Fehler-R-08-name-clash.html",
    "href": "posts/Typ-Fehler-R-08-name-clash/Typ-Fehler-R-08-name-clash.html",
    "title": "Typ-Fehler-R-08-name-clash",
    "section": "",
    "text": "Aufgabe\nR spuckt eine komische Fehlermeldung aus. Was ist nur los? Hat R einen schlechten Tag?\nSchauen wir uns die Sache n√§her an:\n\nlibrary(dplyr)\nlibrary(MASS)\n\nmtcars_small &lt;-\n  mtcars %&gt;% \n  select(hp, am)\n\nError in select(., hp, am): unused arguments (hp, am)\n\n\nOh nein! Fehler!\nWas ist nur los?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nDas Problem ist, dass es in beiden Paketen, {MASS} und {dplyr} (dasjenige Paket im tidyverse, in dem select() wohnt), eine Funktion namens select vorhanden ist.\nEs kommt zu einem ‚ÄúName Clash‚Äù, einer Namenskollision.\nWenn mehrere Funktion gleichen Namens geladen (‚Äúattached‚Äù) sind, so ‚Äúgewinnt‚Äù diejenige Funktion, die als letztes geladen wurde, in unserem Fall ist das die Funktion aus {MASS}.\nEs gibt eine Reihe von L√∂sungen.\n\nNur das ben√∂tigte Paket starten\n\nZuerst ‚Äúentladen‚Äù wir MASS, da wir es nicht ben√∂tigen:\n\ndetach(\"package:MASS\", unload = TRUE)\n\nAlternativ (und einfacher) k√∂nnten wir R neu starten: Session &gt; Restart R.\n\nlibrary(dplyr)\n#library(MASS)\n\nmtcars %&gt;% \n  select(hp, am)\n\nError in select(., hp, am): unused arguments (hp, am)\n\n\nUnd schon geht‚Äôs!\n\nPaketnamen vor Funktionsnamen anf√ºgen\n\n\n#library(dplyr)\n#library(MASS)\n\nmtcars %&gt;% \n  dplyr::select(hp, am) %&gt;% \n  dplyr::filter(hp &gt; 200)\n\n\n\n\n\n\nhp\nam\n\n\n\n\nDuster 360\n245\n0\n\n\nCadillac Fleetwood\n205\n0\n\n\nLincoln Continental\n215\n0\n\n\nChrysler Imperial\n230\n0\n\n\nCamaro Z28\n245\n0\n\n\nFord Pantera L\n264\n1\n\n\nMaserati Bora\n335\n1\n\n\n\n\n\n\n\nPaket conflicted nutzen\n\nHier gibt‚Äôs dazu n√§here Infos.\n\nCategories:\n\nR\nerror\nstring"
  },
  {
    "objectID": "posts/penguins-rope/index.html",
    "href": "posts/penguins-rope/index.html",
    "title": "penguins-rope",
    "section": "",
    "text": "1 Aufgabe\nWir untersuchen folgende Forschungsfrage:\n\nUnterscheiden sich die K√∂rpermasse von Pinguinen der Arten Adelie und Gentoo signifikant voneinander?\n\nHinweise:\n\nDabei verstehen wir hier unter ‚Äúsignifikant‚Äù einen Unterschied von mindestens 500g (in Bezug auf die Grenzen eines 89%-HDI).\nWeniger als der genannte Wert w√ºrde forschungsinhaltlich ein vernachl√§ssigbar geringer Wert bedeuten.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\nAchtung: Viele Forscher verstehen unter ‚Äúsignifikant‚Äù etwas ganz anderes. (Interessanterweise sind sich aber einige Forscher nicht sicher, was sie darunter verstehen. Fragen Sie sie doch mal.)\nWir berechnen folgendes Modell zur Beantwortung der Forschungsfrage:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\nm &lt;- stan_glm(body_mass_g ~ species, \n              data = penguins, \n              refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n              seed = 42  # zur Reproduzierbarkeit\n)\n\nDann betrachten wir die Parameter des Modells:\n\nm_params &lt;- parameters(m, ci_method = \"HDI\", ci =.89)\nm_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n3700.6231\n0.89\n3638.81696\n3757.2271\n1.00000\n0.9993739\n4057.018\nnormal\n4201.754\n2004.886\n\n\nspeciesChinstrap\n32.4854\n0.89\n-81.93567\n140.5625\n0.68525\n0.9999821\n4281.545\nnormal\n0.000\n5015.916\n\n\nspeciesGentoo\n1374.4328\n0.89\n1283.91409\n1469.9053\n1.00000\n1.0002181\n4453.515\nnormal\n0.000\n4171.626\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nWie man in der Tabelle sieht, ist der Unterschied der K√∂rpermasse von Pinguinen der Arten Adelie und Gentoo signifikant. Der Unterschied betr√§gt mind. 1283.9140872 g, laut dem Modell und dem 89%-HDI.\nDas sieht man auch im Diagramm:\n\nm_params |&gt; plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nUnd noch etwas deutlicher in diesem Diagramm:\n\nm |&gt; hdi(ci = .89, parameters = \"speciesGentoo\") |&gt; \n  plot() +\n  annotate(\"rect\", xmin = -500, xmax = 500, ymin = 0, ymax = Inf, alpha = 0.5, fill = \"pink\") +\n  labs(subtitle = \"ROPE shown in pink color\")\n\n\n\n\n\n\n\n\nDie Rope-Statistiken sagen klar, dass wir die ROPE-Hypothese ablehnen k√∂nnen f√ºr 500g Unterschied:\n\nm |&gt; rope(range = c(-500, 500))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-500\n500\n0\nfixed\nconditional\n\n\nspeciesChinstrap\n0.95\n-500\n500\n1\nfixed\nconditional\n\n\nspeciesGentoo\n0.95\n-500\n500\n0\nfixed\nconditional\n\n\n\n\n\n\nDas sieht man auch im ROPE-Diagramm gut (ROPE als blaues Rechteck dargestellt):\n\nm |&gt; rope(range = c(-500, 500)) |&gt; plot()"
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode3/Flex-vs-nichtflex-Methode3.html",
    "href": "posts/Flex-vs-nichtflex-Methode3/Flex-vs-nichtflex-Methode3.html",
    "title": "Flex-vs-nichtflex-Methode3",
    "section": "",
    "text": "Algorithmen des statistischen Lernens lassen sich unterteilen in ihrer Flexibilit√§t; es gibt mehr bzw. weniger flexible Algorithmen.\nWelche der folgenden Aussagen ist in diesem Zusammenhang korrekt?\n\n\n\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund der hohen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell besser ab als eine weniger flexible Methode aufgrund der hohen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell besser ab als eine weniger flexible Methode aufgrund der geringen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund der geringen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund der hohen Verzerrung in der Test-\\(MSE\\)."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode3/Flex-vs-nichtflex-Methode3.html#answerlist",
    "href": "posts/Flex-vs-nichtflex-Methode3/Flex-vs-nichtflex-Methode3.html#answerlist",
    "title": "Flex-vs-nichtflex-Methode3",
    "section": "",
    "text": "Weisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund der hohen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell besser ab als eine weniger flexible Methode aufgrund der hohen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell besser ab als eine weniger flexible Methode aufgrund der geringen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund der geringen Varianz in der Test-\\(MSE\\).\nWeisen die Fehler eine hohe Streuung auf (\\(\\sigma^2 = Var(\\epsilon)\\)), so schneidet eine flexiblere Methode tendenziell schlechter ab als eine weniger flexible Methode aufgrund der hohen Verzerrung in der Test-\\(MSE\\)."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode3/Flex-vs-nichtflex-Methode3.html#answerlist-1",
    "href": "posts/Flex-vs-nichtflex-Methode3/Flex-vs-nichtflex-Methode3.html#answerlist-1",
    "title": "Flex-vs-nichtflex-Methode3",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nstatlearning\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/kaefer2/kaefer2.html",
    "href": "posts/kaefer2/kaefer2.html",
    "title": "kaefer2",
    "section": "",
    "text": "Weltsensation?! Der Insektenforscher Prof.¬†M√ºgge ist der Meinung, eine bislang unbekannte K√§ferart entdeckt zu haben. Nach nur 18 Monaten Feldforschung im brasilianischen Regenwald gelang ihm dieser Durchbruch. Wenn es denn nun wirklich eine neue Art ist. Gerade untersucht er ein Exemplar unter dem Mikroskop. Hm, was ist das f√ºr ein Tier? üêõ üî¨\nDrei Arten kommen in Frage, \\(A_1, A_2, A_3\\).\nDabei ist die Art \\(A_1\\) sehr verbreitet und schon l√§ngst bekannt, \\(A_2\\) ist die neue Art, Exemplare dieser Art sind selten und \\(A_3\\) ist auch bekannt und eher h√§ufig anzutreffen. Allerdings spricht das Aussehen am ehesten f√ºr \\(A_2\\), der seltenen Art.\nüëâ Aufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass Prof.¬†M√ºgge wirklich einen gro√üen Fang gemacht hat und einen unbekannten K√§fer entdeckt hat?\nGeben Sie diese Wahrscheinlichkeit an!\nHier sind die genauen Vorkommensh√§ufigkeiten:\n\nPr_A1 &lt;- .6\nPr_A2 &lt;- .1\nPr_A3 &lt;- .4\n\nUnd hier die genauen Wahrscheinlichkeiten, wie typisch das beobachtete Objekt f√ºr einen Vertreter der jeweiligen Art ist:\n\nL_A1 &lt;- .5\nL_A2 &lt;- .9\nL_A3 &lt;- .4\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/kaefer2/kaefer2.html#setup",
    "href": "posts/kaefer2/kaefer2.html#setup",
    "title": "kaefer2",
    "section": "Setup",
    "text": "Setup\n\n# Falls Sie das Paket `prada` noch nicht installiert haben, k√∂nnen Sie das mit folgendem Befehl tun:\nlibrary(devtools)\ninstall_github(\"sebastiansauer/prada\")\n\n\nlibrary(tidyverse)\nlibrary(prada)  # f√ºr Funktion `bayesbox`\nlibrary(easystats)\n\nMit der Funktion bayesbox aus prada k√∂nnen wir die Bayes‚Äôsche Analyse durchf√ºhren. Wir geben die Hypothesen, die Prior- und Likelihood-Verteilungen an und erhalten die Posterior-Verteilungen.\nNat√ºrlich k√∂nnen wir auch die Berechnungen manuell durchf√ºhren, aber das ist aufw√§ndiger und fehleranf√§lliger.\n\n# bayesbox kommt aus dem Paket `prada`\nbb &lt;- bayesbox(hyps = 1:3,\n               priors = c(Pr_A1, Pr_A2, Pr_A3),\n               liks = c(L_A1, L_A2, L_A3))\n\nbb\n\n\n\n\n\nhyps\npriors\nliks\npost_unstand\npost_std\n\n\n\n\n1\n0.6\n0.5\n0.30\n0.55\n\n\n2\n0.1\n0.9\n0.09\n0.16\n\n\n3\n0.4\n0.4\n0.16\n0.29\n\n\n\n\n\n\nAntwort: Die Wahrscheinlichkeit, dass der K√§fer zur Art ‚ÄúB‚Äù geh√∂rt, ist relativ klein, ca.: 0.16.\n\nCategories:\n\nR\nbayes\nbayesbox\nnum"
  },
  {
    "objectID": "posts/DAG-Graph/DAG-Graph.html",
    "href": "posts/DAG-Graph/DAG-Graph.html",
    "title": "dag-graph",
    "section": "",
    "text": "Aufgabe\nF√ºr ein Forschungsprojekt hat ein Forschungsteam die Frage getestet, ob Personen, die einen animierten Graphen zu Auswirkungen von Stress gesehen haben danach eine h√∂here Motivation haben, ihr Stresspensum anzugehen, als Personen, die einen statischen Graph gesehen haben. Dazu wurde jeweils in einem Fragebogen die Ver√§nderungsbereitschaft auf das Stressniveau angepasst abgefragt, dann den jeweiligen Graphen gezeigt und danach dieselben Fragen wie davor nochmals gestellt. Die Personen wurden randomisiert den beiden Bedingungen (statisch vs.¬†animiert) zugeordnet. Es handelt sich um ein Between-Group-Design.\nZur Auswertung wurde nun zu jeder der Fragen zur Ver√§nderungsbereitschaft die Mittelwerte der Vor-sehen-des-Graphen-Gruppe von der Nach-sehen-des-Graphen-Gruppe abgezogen und diese Werte dann verglichen von dem animierten und dem statischen Graphen. Dabei konnte der gew√ºnschten Effekt deutlich erkannt werden, hypothesenkonform.\nZeichnen Sie den DAG f√ºr dieses Studiendesign\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(ggplot2)\n\n\nmy_dag &lt;-\n  dagitty(\"dag{g -&gt; mot; u -&gt; mot}\")\n\n\ntidy_dagitty(my_dag)\n\n# A DAG with 3 nodes and 2 edges\n#\n# A tibble: 3 √ó 8\n  name      x       y direction to     xend   yend circular\n  &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;   \n1 g      1.36 -0.0962 -&gt;        mot    2.05  0.823 FALSE   \n2 mot    2.05  0.823  &lt;NA&gt;      &lt;NA&gt;  NA    NA     FALSE   \n3 u      2.74  1.74   -&gt;        mot    2.05  0.823 FALSE   \n\n\n\nggdag(my_dag) +\n  theme_dag()\n\n\n\n\n\n\n\n\nDie AV ist mit mot bezeichnet; die UV mit g (wie Gruppe). u steht f√ºr sonstige Einfl√ºsse auf die AV.\n\nCategories:\n\nfopro\nresearchdesign\ncausal\nstring"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html",
    "title": "wfsets_penguins02",
    "section": "",
    "text": "Berechnen Sie die Vorhersageg√ºte (RMSE) f√ºr folgende Lernalgorithmen:\n\nlineares Modell\nknn (neighbors: tune)\n\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nTunen Sie bei neighbors folgende Werte: 5, 10, 15, 20, 35, 30 und betrachten Sie deren Modellg√ºte.\nNutzen Sie minimale Vorverarbeitung.\nBerichten Sie die den RSME."
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#setup",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#setup",
    "title": "wfsets_penguins02",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tidyverse)\ndata(penguins, package = \"palmerpenguins\")"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#daten",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#daten",
    "title": "wfsets_penguins02",
    "section": "Daten",
    "text": "Daten\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()\n\n\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#modelle",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#modelle",
    "title": "wfsets_penguins02",
    "section": "Modelle",
    "text": "Modelle\nLineares Modell:\n\nmod_lin &lt;- linear_reg()\n\nmod_knn &lt;- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#rezepte",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#rezepte",
    "title": "wfsets_penguins02",
    "section": "Rezepte",
    "text": "Rezepte\n\nrec_basic &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n         step_normalize(all_predictors())"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#resampling",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#resampling",
    "title": "wfsets_penguins02",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpls &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#workflow-set",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#workflow-set",
    "title": "wfsets_penguins02",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic),\n    models = list(mod_lm = mod_lin,\n                  mod_nn = mod_knn)\n  )"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#tuningparameter-werte-bestimmen",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#tuningparameter-werte-bestimmen",
    "title": "wfsets_penguins02",
    "section": "Tuningparameter-Werte bestimmen",
    "text": "Tuningparameter-Werte bestimmen\nWelche Tuningparameter hatten wir noch mal ausgewiesen?\n\nmod_knn %&gt;% \n  extract_parameter_set_dials()\n\nUpdaten wir die Parameter mit unseren Werten, also min. 5 Nachbarn und max. 20 Nachbarn.\n\nparams_knn &lt;- \nmod_knn %&gt;% \n  extract_parameter_set_dials() %&gt;% \n  update(neighbors = neighbors(c(5, 20)))\n\nDiese Infos erg√§nzen wir jetzt in das Workflow-Set-Objekt f√ºr den Workflow mit der ID ‚Äúrec_simple_mod_nn‚Äù unter der Spalte ‚ÄúOptions‚Äù:\n\nwf_set &lt;- \nwf_set %&gt;% \n  option_add(param_info = params_knn, id = \"rec_simple_mod_nn\")"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#fitten",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#fitten",
    "title": "wfsets_penguins02",
    "section": "Fitten",
    "text": "Fitten\n\nwf_set_fit &lt;-\n  wf_set %&gt;% \n  workflow_map(resamples = rsmpls)\n\nCheck:\n\nwf_set_fit %&gt;% pluck(\"result\")"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#bester-kandidat",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#bester-kandidat",
    "title": "wfsets_penguins02",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(wf_set_fit)\n\n\n\n\n\n\n\n\n\nrank_results(wf_set_fit, rank_metric = \"rmse\") %&gt;% \n  filter(.metric == \"rmse\")\n\nAm besten war das lineare Modell, aber schauen wir uns auch mal das knn-Modell an, v.a. um zu wissen, wie man den besten Tuningparameter-Wert sieht:\n\nwf_knn &lt;- \n  extract_workflow_set_result(wf_set_fit, \"rec_simple_mod_nn\")\n\n\nwf_knn %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nwf_knn %&gt;% select_best()"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#last-fit",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#last-fit",
    "title": "wfsets_penguins02",
    "section": "Last Fit",
    "text": "Last Fit\n\nbest_wf &lt;-\n  wf_set_fit %&gt;% \n  extract_workflow(\"rec_simple_mod_lm\")\n\nFinalisieren m√ºssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\nfit_final &lt;-\n  best_wf %&gt;% \n  last_fit(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#modellg√ºte-im-test-set",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#modellg√ºte-im-test-set",
    "title": "wfsets_penguins02",
    "section": "Modellg√ºte im Test-Set",
    "text": "Modellg√ºte im Test-Set\n\ncollect_metrics(fit_final)\n\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/regression1a/regression1a.html",
    "href": "posts/regression1a/regression1a.html",
    "title": "regression1a",
    "section": "",
    "text": "Die folgende Frage bezieht sich auf dieses Ergebnis einer Regressionsanalyse:\n\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.119 -1.183  0.002  1.204  4.744 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.201      0.214    0.94  0.34898    \nx             -0.721      0.202   -3.57  0.00061 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.9 on 80 degrees of freedom\nMultiple R-squared:  0.137, Adjusted R-squared:  0.127 \nF-statistic: 12.7 on 1 and 80 DF,  p-value: 0.000607\n\n\nZusammengefasst sind die Koeffizienten (beta0 und beta1) also:\n\ncoef(m)\n\n(Intercept)           x \n  0.2014558  -0.7213274 \n\n\nWelche der folgenden Aussagen passt am besten?\n\n\n\nDer Mittelwert der abh√§ngigen Variaben y sinkt mit zunehmenden x.\nWenn x=0, dann ist ein Mittelwert von y in H√∂he von etwa -0.52 zu erwarten.\nWenn x=1, dann ist ein Mittelwert von y in H√∂he von ca. 0.2 zu erwarten.\nWenn x=2, dann ist ein Mittelwert von y in H√∂he von ca. -0.52 zu erwarten.\nDas (nicht-adjustierte) \\(R^2\\) liegt im Modell bei -0.72."
  },
  {
    "objectID": "posts/regression1a/regression1a.html#answerlist",
    "href": "posts/regression1a/regression1a.html#answerlist",
    "title": "regression1a",
    "section": "",
    "text": "Der Mittelwert der abh√§ngigen Variaben y sinkt mit zunehmenden x.\nWenn x=0, dann ist ein Mittelwert von y in H√∂he von etwa -0.52 zu erwarten.\nWenn x=1, dann ist ein Mittelwert von y in H√∂he von ca. 0.2 zu erwarten.\nWenn x=2, dann ist ein Mittelwert von y in H√∂he von ca. -0.52 zu erwarten.\nDas (nicht-adjustierte) \\(R^2\\) liegt im Modell bei -0.72."
  },
  {
    "objectID": "posts/regression1a/regression1a.html#answerlist-1",
    "href": "posts/regression1a/regression1a.html#answerlist-1",
    "title": "regression1a",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nregression\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/mariokart-max2/mariokart-max2.html",
    "href": "posts/mariokart-max2/mariokart-max2.html",
    "title": "mariokart-max2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die maximale Verkaufspreise (total_pr) f√ºr Spiele, die mit 0, 1, 2, ‚Ä¶ Lenkr√§der (wheels) gekauft werden. Dieser Kennwert hei√üe pr_max. Ber√ºcksichtigen Sie aber nur neue Spiele. Bilden Sie von pr_max den Mittelwert und geben Sie diesen an.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  filter(cond == \"new\") %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_max = max(total_pr)) %&gt;% \n  summarise(pr_max_mean = mean(pr_max))\n\nsolution\n\n\n\n\n\npr_max_mean\n\n\n\n\n63.1725\n\n\n\n\n\n\nL√∂sung:\n\n\n\n\npr_max_mean\n\n\n\n\n63.17\n\n\n\n\n.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nnum"
  },
  {
    "objectID": "posts/iq04/iq04.html",
    "href": "posts/iq04/iq04.html",
    "title": "iq04",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nWie intelligent muss man sein, um zu den schlauesten 2% Personen in der Allgemeinbev√∂lkerung zu geh√∂ren?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^3\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nGeben Sie keine Prozentzahlen, sondern stets Anteile an.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd &lt;- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd = 15))\n\nWir filtern die schlauesten 2 Prozent:\n\nsolution_d &lt;- \n  d %&gt;% \n  arrange(iq) %&gt;% \n  slice_tail(prop = 0.02) %&gt;%  # schneide \"hinten an der Tabelle\" einen Anteil (prop) von 0.02 (2%) ab\n  summarise(min(iq))  # was ist der kleinste Wert in diesen 2%?\n\nsolution_d\n\n\n\n\n\nmin(iq)\n\n\n\n\n130.2984\n\n\n\n\n\n\nDie Syntax auf Deutsch √ºbersetzt:\nDefiniere solution_d wie folgt:\nnimm die Tabelle d und dann ...\nsortiere (aufsteigend) die Spalte iq und dann ...\nschneide hinten (\"am Schwanz\") einen Anteil von 2% ab und dann ...\nfasse diese Liste an Werten zusammen zu ihrem Minimum (also dem kleinsten Wert).\nAlternativ k√∂nnte man schreiben:\n\nsolution &lt;- \n  d %&gt;% \n  summarise(iq_top_2komma3_prozent = quantile(iq, prob = .98))\n\nsolution\n\n\n\n\n\niq_top_2komma3_prozent\n\n\n\n\n130.2768\n\n\n\n\n\n\nL√∂sung:\n\n\n\n\niq_top_2komma3_prozent\n\n\n\n\n130.2768\n\n\n\n\n.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/abh-ereignisse2/abh-ereignisse2.html",
    "href": "posts/abh-ereignisse2/abh-ereignisse2.html",
    "title": "abh-ereignisse2",
    "section": "",
    "text": "Aufgabe\n\n\n\n\n\n\n\n\n\nBerechnen Sie folgende Wahrscheinlichkeiten:\n\n\\(Pr(BA)\\)\n\\(Pr(AB)\\)\n\nHinweise:\n\nDas Ereignis ‚ÄúB tritt ein‚Äù ist mit ‚ÄúB+‚Äù im Diagramm eingezeichnet (entsprechend f√ºr A). Analog ist das Ereignis ‚ÄúB tritt nicht ein‚Äù mit ‚ÄúB-‚Äù eingezeichnet (entsprechend f√ºr A).\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\n\\(Pr(AB) = Pr(A|B) \\cdot Pr(B) = 3/4 \\cdot 1/2 = 3/8\\)\n\\(Pr(BA) = Pr(B|A) \\cdot Pr(A) = 3/5 \\cdot 5/8 = 3/8\\)\n\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/wuerfel06/wuerfel06.html",
    "href": "posts/wuerfel06/wuerfel06.html",
    "title": "wuerfel06",
    "section": "",
    "text": "Aufgabe\nWas ist die Wahrscheinlichkeit, bei 10 Wiederholungen des Werfens zweier W√ºrfel mindestens einen Sechserpasch zu werfen?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nSei \\(A_i\\) das Ereignis ‚ÄúSechserpach‚Äù in der \\(i\\)-ten Wiederholung.\nEs gilt: \\(Pr(A_i) = 1/36\\).\nNennen wir \\(A\\) ‚Äúkeinen Sechserpasch in jeder Wiederholung‚Äù, wir suchen die Wahrscheinlichkeit von A.\n‚ÄúMindestens einen Sechserpasch‚Äù - Das Gegenteil davon ist ‚Äúkeinen Sechserpasch‚Äù.\n\\(Pr(\\neg A_i) = 35/36\\).\nBezeichnen wir mit \\(X\\) eine Zufallsvariable, die die Anzahl der Sechserpasche z√§hlt.\nDie Wiederholungen sind voneinander unabh√§ngig, es gilt also\n\\(Pr(X=0) = Pr(\\neg A) = \\left(\\frac{35}{36} \\right)^{10}\\)\n\nPr_kein_Secherpasch &lt;- (35/36)^10\nPr_kein_Secherpasch\n\n[1] 0.7544934\n\n\nDas Gegenteil (Komplement) von \\(\\neg A\\), also \\(A\\) ist das gesuchte Ereignis.\n\nPr_A &lt;- 1 - Pr_kein_Secherpasch\nPr_A\n\n[1] 0.2455066\n\n\nDie L√∂sung lautet 0.2455066.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/mariokart-korr4/mariokart-korr4.html",
    "href": "posts/mariokart-korr4/mariokart-korr4.html",
    "title": "mariokart-korr4",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die Korrelation von mittlerem Verkaufspreis (total_pr) und Startgebot (start_pr) f√ºr Spiele, die sowohl neu sind oder √ºber Lenkr√§der (wheels) verf√ºgen.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\nBeachten Sie die Hinweise des Datenwerk.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- read.csv(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  filter(cond == \"new\" | wheels &gt; 0) %&gt;% \n  summarise(pr_corr = cor(total_pr, start_pr))\n\nsolution\n\n     pr_corr\n1 0.04725486\n\n\nAlternativ kann man (komfortabel) die Korrelation z.B. so berechnen:\n\nd %&gt;% \n  select(start_pr, total_pr, cond, wheels) %&gt;% \n  filter(cond == \"new\" | wheels &gt; 0) %&gt;%   # logisches ODER\n  correlation()  # aus dem Paket `easystats`\n\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |    r |        95% CI | t(108) |       p\n-----------------------------------------------------------------\nstart_pr   |   total_pr | 0.05 | [-0.14, 0.23] |   0.49 | 0.762  \nstart_pr   |     wheels | 0.08 | [-0.10, 0.27] |   0.88 | 0.762  \ntotal_pr   |     wheels | 0.28 | [ 0.10, 0.45] |   3.09 | 0.008**\n\np-value adjustment method: Holm (1979)\nObservations: 110\n\n\nL√∂sung: 0.0.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nassociation\nnum"
  },
  {
    "objectID": "posts/germeval02/germeval02.html",
    "href": "posts/germeval02/germeval02.html",
    "title": "germeval02",
    "section": "",
    "text": "F√ºhren Sie eine Sentiment-Analyse durch. Verwenden Sie verschiedene Verfahren.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/germeval02/germeval02.html#sentimentanalyse-mit-regex",
    "href": "posts/germeval02/germeval02.html#sentimentanalyse-mit-regex",
    "title": "germeval02",
    "section": "Sentimentanalyse mit Regex",
    "text": "Sentimentanalyse mit Regex\nDie Funktion count_lexicon stammt aus {prada}.\nTipp: Mit ?count_lexicon sehen Sie den Quelltext (jeder Funktion).\n\ntest_text  |&gt; \n  mutate(n_emowords = map_int(text, prada::count_lexicon, sentiws$word))\n\n\ntic()\ngermeval_train |&gt; \n  mutate(n_emowords = map_int(text, ~ prada::count_lexicon(.x, sentiws$word))) |&gt; \n  head()\ntoc()\n\nPuh! Viel zu langsam."
  },
  {
    "objectID": "posts/germeval02/germeval02.html#sentimentanalyse-mit-unnest_tokens",
    "href": "posts/germeval02/germeval02.html#sentimentanalyse-mit-unnest_tokens",
    "title": "germeval02",
    "section": "Sentimentanalyse mit unnest_tokens",
    "text": "Sentimentanalyse mit unnest_tokens\nProbieren wir es mit unnest_tokens:\nJaa,‚Ä¶ aber die Strings ohne Treffer werden ignoriert.\n\ntest_text |&gt; \n  unnest_tokens(word, text) |&gt; \n  right_join(sentiws |&gt; select(word)) |&gt; \n  count(id)\n\nProbieren wir es so:\n\n#' Count words in a lexicon\n#' \n#' Counts how many of the words of the character vector `text` are\n#' found in a lexicon `lex` \n#' `text` is transformed via tolower.\n#'\n#' @param text corpus, character vector\n#'\n#' @return number of hits per element of the corpus\n#' @export\n#'\n#' @examples\n#' count_lex(my_text, my_lex)\ncount_lex &lt;- function(text) {\n  \n  stopifnot(class(text) == \"character\")\n  \n  doc &lt;- tibble(text = tolower(text),\n                id = 1:length(text))\n  \n  doc1 &lt;- \n    doc |&gt; \n    tidytext::unnest_tokens(word, text) |&gt; \n    dplyr::inner_join(sentiws |&gt; dplyr::select(word), by = \"word\") |&gt; \n    count(id)\n  \n  doc2 &lt;-\n    doc1 |&gt; \n    dplyr::full_join(doc |&gt; select(id), by = \"id\")\n  \n  doc2$n &lt;- ifelse(is.na(doc2$n), 0,doc2$n)\n  \n  doc2 &lt;- doc2 |&gt; dplyr::arrange(id)\n  \n  doc2 |&gt; pull(n)\n}\n\nMit dem Paket box kann man Funktionen, die nicht in Paketen stehen, importieren.\n\ncount_lex(test_text$text)\n\nAls neue Spalte im Datensatz:\n\ntest_text |&gt; \n  mutate(n_emowords = count_lex(text))"
  },
  {
    "objectID": "posts/germeval02/germeval02.html#sentimentanalyse-mit-syuzhet",
    "href": "posts/germeval02/germeval02.html#sentimentanalyse-mit-syuzhet",
    "title": "germeval02",
    "section": "Sentimentanalyse mit {syuzhet}",
    "text": "Sentimentanalyse mit {syuzhet}\n\nMit dem Lexicon nrc\n\nget_nrc_sentiment(test_text$text, language = \"german\")\n\nTja, nicht so viele Treffer ‚Ä¶\nIn der Zusammenfassung:\n\nget_nrc_values(text, language = \"german\")\n\nTja, leider keine Treffer. Merkw√ºrdig.\n\nget_sentiment(text,\n              method = \"nrc\",\n              language = \"german\")\n\nNaja, ok.\n\n\nMit einem eigenen Lexikon\nBeispiel vom Autor des Pakets:\n\nmy_text &lt;- \"I love when I see something beautiful.  I hate it when ugly feelings creep into my head.\"\nchar_v &lt;- get_sentences(my_text)\nmethod &lt;- \"custom\"\ncustom_lexicon &lt;- data.frame(word=c(\"love\", \"hate\", \"beautiful\", \"ugly\"), value=c(1,-1,1, -1))\nmy_custom_values &lt;- get_sentiment(char_v, method = method, lexicon = custom_lexicon)\nmy_custom_values\n\n\nget_sentiment(text,\n              method = \"custom\",\n              lexicon = sentiws)"
  },
  {
    "objectID": "posts/germeval02/germeval02.html#test",
    "href": "posts/germeval02/germeval02.html#test",
    "title": "germeval02",
    "section": "Test",
    "text": "Test\n\ntic()\nsentiments &lt;-\n  get_sentiment(germeval_train$text,\n              method = \"custom\",\n              lexicon = sentiws)\ntoc()\n\n\nlength(sentiments)\nhead(sentiments)\n\nDie Geschwindigkeit scheint deutlich besser zu sein, als bei den Regex-Ans√§tzen."
  },
  {
    "objectID": "posts/germeval02/germeval02.html#als-spalte-in-die-tabelle",
    "href": "posts/germeval02/germeval02.html#als-spalte-in-die-tabelle",
    "title": "germeval02",
    "section": "Als Spalte in die Tabelle",
    "text": "Als Spalte in die Tabelle\n\ntic()\nd &lt;-\n  germeval_train |&gt; \n  mutate(n_emo = get_sentiment(germeval_train$text,\n              method = \"custom\",\n              lexicon = sentiws))\ntoc()\n\nhead(d)"
  },
  {
    "objectID": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html",
    "href": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html",
    "title": "Typ-Fehler-R-07",
    "section": "",
    "text": "Question"
  },
  {
    "objectID": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist",
    "href": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist",
    "title": "Typ-Fehler-R-07",
    "section": "Answerlist",
    "text": "Answerlist\n\nR ist abgest√ºrzt; am besten neu starten.\nR vertr√§gt im Standard nur Gr√º√üe in englischer Sprache. Sprachpakete updaten.\nR wartet auf das Ende der Text-Auszeichnung, also auf das schlie√üende Anf√ºhrungszeichen. Das muss noch eingegeben werden. Alternativ kann man ‚ÄúEscape‚Äù dr√ºcken.\nEs gibt kein Problem; man kann einfach den n√§chsten Befehl eingeben.\nR hat gewartet auf das Ende der Text-Auszeichnung, also auf das schlie√üende Anf√ºhrungszeichen. Jetzt ist R abgest√ºrzt und muss neu gestartet werden."
  },
  {
    "objectID": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist-1",
    "href": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist-1",
    "title": "Typ-Fehler-R-07",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\nR\nerror\nmchoice"
  },
  {
    "objectID": "posts/alphafehler-inflation2/alphafehler-inflation2.html",
    "href": "posts/alphafehler-inflation2/alphafehler-inflation2.html",
    "title": "alphafehler-inflation2",
    "section": "",
    "text": "Aufgabe\nDas ‚ÄúMaschinendisaster‚Äù sei als folgendes Szenario beschrieben:\nEine Maschine bestehe aus einer Menge Teile, die alle recht zuverl√§ssig arbeiten. Au√üerdem arbeiten alle Teile unabh√§ngig voneinander (vermutlich keine ganz realistische Annahme). Die Zuverl√§ssigkeit eines Teils sei \\(r=.9999\\) f√ºr ein bestimmtes Zeitintervall \\(t\\). Mit \\(1-r\\) f√§llt also ein Teil innerhalb von \\(t\\) aus.\nEin interessanter Schn√∂rkel ist, dass man ‚ÄúMaschine‚Äù auch als ‚ÄúComputerprogramm‚Äù oder ‚Äúbiologisches System‚Äù lesen kann.\nEine Forscherin fragt sich, aus wie vielen \\(k\\) Teilen die Maschine h√∂chstens bestehen darf, damit es mit einer Wahrscheinlichkeit von 99% zu keinem Ausfall innerhalb von \\(t=1\\) kommt.\n         \n\n\nL√∂sung\n\nr &lt;- .9999\nloesung &lt;- \n  log(.99, base = r) %&gt;% \n  trunc()\nloesung\n\n[1] 100\n\n\ntrunc() schneidet die Dezimalstellen ab, rundet also ab.\n\\[\n\\begin{aligned}\nr^k  &= .99 \\qquad |log_r \\\\\nlog_r(r^k) &= log_r(.99) \\\\\nk &\\approx 100\n\\end{aligned}\n\\]\nDie L√∂sung lautet also 100.\n\nCategories:\n\nprobability\nR\ninference\nnum"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html",
    "href": "posts/oecd-yacsda/index.html",
    "title": "oecd-yacsda",
    "section": "",
    "text": "Fallstudie: Explorative Datenanalyse zum Datensatz ‚ÄúOECD Wellbeing‚Äù\n(YACSDA: Yet another Case Study on Data Analysis)"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#hintergrund",
    "href": "posts/oecd-yacsda/index.html#hintergrund",
    "title": "oecd-yacsda",
    "section": "1.1 Hintergrund",
    "text": "1.1 Hintergrund\nIn diesem Post untersuchen wir einige Aspekte der explorativen Datenanalyse f√ºr den Datensatz oecd wellbeing aus dem Jahr 2016.\nHinweis: Als Vertiefung gekennzeichnete Abschnitt sind nicht pr√ºfungsrelevant."
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#ben√∂tigte-pakete",
    "href": "posts/oecd-yacsda/index.html#ben√∂tigte-pakete",
    "title": "oecd-yacsda",
    "section": "1.2 Ben√∂tigte Pakete",
    "text": "1.2 Ben√∂tigte Pakete\nEin Standard-Paket zur grundlegenden Datenanalyse bzw. des Datenjudos ist tidyverse. Dar√ºber hinaus verwenden wir noch zwei Pakete zur Visualisierung und eines f√ºr den Komfort.\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(easystats)  # Komfort \nlibrary(DataExplorer)  # Data vis\nlibrary(ggpubr)  # Data vis"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#datensatz-laden",
    "href": "posts/oecd-yacsda/index.html#datensatz-laden",
    "title": "oecd-yacsda",
    "section": "1.3 Datensatz laden",
    "text": "1.3 Datensatz laden\nDer Datensatz kann hier bezogen werden.\nDoi: https://doi.org/10.1787/data-00707-en.\nFalls der Datensatz lokal (auf Ihrem Rechner) vorliegt, k√∂nnen Sie ihn in gewohnter Manier importieren. Geben Sie dazu den Pfad zum Datensatz ein; bei mir sieht das so aus:\n\noecd &lt;- read.csv(\"/Users/sebastiansaueruser/datasets/oecd_wellbeing.csv\")\n\nLiegt die Datendatei im gleichen Verzeichnis wie Ihre R-/Quarto-/Rmd-Datei, dann brauchen Sie nur den Dateinamen, nicht den Pfad, anzugeben.\nAlternativ k√∂nnen Sie die Daten direkt von einem Server beziehen:\n\noecd &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/2021-sose/master/data/OECD/oecd-wellbeing.csv\")"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#erster-blick",
    "href": "posts/oecd-yacsda/index.html#erster-blick",
    "title": "oecd-yacsda",
    "section": "1.4 Erster Blick",
    "text": "1.4 Erster Blick\n\nglimpse(oecd)\n\nRows: 429\nColumns: 15\n$ Country                  &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\", \"Austr‚Ä¶\n$ Region                   &lt;chr&gt; \"New South Wales\", \"Victoria\", \"Queensland\", ‚Ä¶\n$ region_type              &lt;chr&gt; \"country_part\", \"country_part\", \"country_part‚Ä¶\n$ Code                     &lt;chr&gt; \"AU1\", \"AU2\", \"AU3\", \"AU4\", \"AU5\", \"AU6\", \"AU‚Ä¶\n$ Education                &lt;dbl&gt; 8.0, 8.1, 7.8, 7.3, 7.6, 6.5, 8.1, 9.5, 8.8, ‚Ä¶\n$ Jobs                     &lt;dbl&gt; 8.1, 7.9, 8.1, 7.8, 8.8, 7.6, 8.7, 9.3, 7.8, ‚Ä¶\n$ Income                   &lt;dbl&gt; 6.8, 5.9, 6.3, 6.1, 7.9, 5.4, 8.2, 10.0, 5.7,‚Ä¶\n$ Safety                   &lt;dbl&gt; 8.8, 9.5, 9.5, 9.0, 8.6, 8.8, 0.0, 10.0, 9.7,‚Ä¶\n$ Health                   &lt;dbl&gt; 9.0, 9.5, 8.3, 8.5, 9.3, 5.4, 2.4, 9.3, 6.7, ‚Ä¶\n$ Environment              &lt;dbl&gt; 9.8, 8.6, 9.9, 9.4, 9.6, 10.0, 9.2, 9.1, 3.5,‚Ä¶\n$ Civic_engagement         &lt;dbl&gt; 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 8.4, 10.0‚Ä¶\n$ Accessiblity_to_services &lt;dbl&gt; 7.2, 7.5, 7.7, 7.2, 7.8, 6.8, 7.8, 8.7, 8.0, ‚Ä¶\n$ Housing                  &lt;dbl&gt; 7.2, 7.8, 8.3, 8.3, 8.9, 8.3, 5.6, 8.3, 6.1, ‚Ä¶\n$ Community                &lt;dbl&gt; 8.9, 9.3, 8.6, 8.6, 8.5, 8.6, 10.0, 9.8, 8.3,‚Ä¶\n$ Life_satisfaction        &lt;dbl&gt; 7.8, 8.5, 8.1, 8.5, 7.8, 9.6, 7.0, 9.6, 7.8, ‚Ä¶\n\n\nWie glimpse() aufzeigt, liegen also einige qualitative (kategoriale, chr, vom Typ ‚ÄúText‚Äù) und einige quantitative (metrische, dbl) Variablen vor. Die qualitativen Variablen sind f√ºr eine direkte Analyse weniger interessant; vielmehr ist es interessant, die Statistiken auf die Gruppen (Stufen, Level) der qualitativen Variablen aufzusplitten.\nBetrachten wir aber zu Beginn die metrischen Variablen einzeln (univariat)."
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#deskriptive-statistiken-zu-den-metrischen-variablen-einzeln-univariat",
    "href": "posts/oecd-yacsda/index.html#deskriptive-statistiken-zu-den-metrischen-variablen-einzeln-univariat",
    "title": "oecd-yacsda",
    "section": "1.5 Deskriptive Statistiken zu den metrischen Variablen, einzeln (univariat)",
    "text": "1.5 Deskriptive Statistiken zu den metrischen Variablen, einzeln (univariat)\nZentrale Statistiken zu den metrischen Variablen lassen sich auf mehreren Wegen mit R berechnen. Hier ist ein Weg:\n\ndescribe_distribution(oecd)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nEducation\n6.81\n2.97\n3.50\n0\n10\n-1.08\n-0.02\n426\n3\n\n\nJobs\n6.45\n2.41\n2.90\n0\n10\n-0.96\n0.48\n429\n0\n\n\nIncome\n4.11\n2.70\n3.40\n0\n10\n0.44\n-0.38\n429\n0\n\n\nSafety\n7.05\n3.23\n3.80\n0\n10\n-1.18\n0.10\n429\n0\n\n\nHealth\n5.73\n2.93\n5.20\n0\n10\n-0.33\n-1.15\n429\n0\n\n\nEnvironment\n5.40\n2.73\n4.35\n0\n10\n-0.11\n-0.89\n429\n0\n\n\nCivic_engagement\n5.05\n2.85\n4.10\n0\n10\n-0.03\n-0.91\n429\n0\n\n\nAccessiblity_to_services\n6.53\n2.65\n2.60\n0\n10\n-1.13\n0.50\n429\n0\n\n\nHousing\n4.80\n3.02\n5.50\n0\n10\n-0.06\n-1.12\n427\n2\n\n\nCommunity\n6.88\n2.75\n3.25\n0\n10\n-1.13\n0.32\n425\n4\n\n\nLife_satisfaction\n5.80\n2.90\n4.90\n0\n10\n-0.47\n-0.87\n425\n4\n\n\n\n\n\nJetzt gehen wir weiter zur Visualisierung der Verteilung der metrischen Variablen. Auch hier gibt es wieder viele L√∂sungen.\nEs reicht, wenn Sie mit einer L√∂sung vertraut sind.\n\n1.5.1 Mit ggpubr\n\noecd |&gt; \ngghistogram(x = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\n\n\n1.5.2 Mit DataExplorer\n\noecd |&gt; \n  select(Life_satisfaction) |&gt; \n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n1.5.3 Mit ggplot\nDas R-Paket ggplot wird durch das ‚ÄúMeta-Paket‚Äù tidyverse gestartet. Sie m√ºssen es also nicht extra starten.\n\noecd %&gt;% \n  ggplot(aes(x = Life_satisfaction)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nEine √§hnliche Aussage liefert das Dichte-Diagramm:\n\noecd %&gt;% \n  ggplot(aes(x = Life_satisfaction)) +\n  geom_density()\n\n\n\n\n\n\n\n\nDie Dichte gibt an, welcher Anteil der Beobachtungen an der jeweiligen Stelle der X-Achse l√§gen, wenn man eine Einheit betrachtet (z.B. die Lebenszufriedenheit von 5-6)."
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#histogramm-nach-gruppen-lebenszufriedenheit-in-de-und-fr",
    "href": "posts/oecd-yacsda/index.html#histogramm-nach-gruppen-lebenszufriedenheit-in-de-und-fr",
    "title": "oecd-yacsda",
    "section": "1.6 Histogramm nach Gruppen: Lebenszufriedenheit in De und Fr",
    "text": "1.6 Histogramm nach Gruppen: Lebenszufriedenheit in De und Fr\nAngenommen, man m√∂chte Deutschland mit Frankreich vergleichen im Hinblick auf die Lebenszufriedenheit.\nZun√§chst filtern wir den OECD-Datensatz, so dass nur die beiden genannten L√§nder enthalten bleiben:\n\noecd_de_fr &lt;- \noecd %&gt;% \n  filter(Country == \"Germany\" | Country == \"France\") \n\nDann visualisieren wir wieder.\n\n1.6.1 Mit ggpubr\n\noecd_de_fr |&gt; \n  gghistogram(x = \"Life_satisfaction\", facet.by = \"Country\")\n\n\n\n\n\n\n\n\n\n\n1.6.2 Mit DataExplorer\nLeider unterst√ºtzt DataExplorer nicht direkt den Vergleich von Grupen mit einem Histogramm. Man k√∂nnte aber einen Boxplot verwenden stattdessen.\n\noecd_de_fr |&gt; \n  select(Life_satisfaction, Country) |&gt; \n  plot_boxplot(by = \"Country\")\n\n\n\n\n\n\n\n\n\n\n1.6.3 Mit ggplot\n\noecd_de_fr %&gt;% \n  ggplot(aes(x = Life_satisfaction)) +\n  geom_histogram(bins = 15) +\n  facet_wrap(~ Country)"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#histogramm-f√ºr-alle-metrischen-variablen-auf-einmal",
    "href": "posts/oecd-yacsda/index.html#histogramm-f√ºr-alle-metrischen-variablen-auf-einmal",
    "title": "oecd-yacsda",
    "section": "1.7 Histogramm f√ºr alle metrischen Variablen auf einmal",
    "text": "1.7 Histogramm f√ºr alle metrischen Variablen auf einmal\nUm einen √úberblick √ºber die Verteilungen zu bekommen, bietet es sich an, sich alle Verteilungen anzuschauen. Malen wir einmal alle Histogramme auf einmal. Das geht wiederum mit DataExplorer sehr einfach:\n\noecd |&gt; \n  plot_histogram()"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#vertiefung-histogramm-f√ºr-alle-variablen-auf-kompliziert",
    "href": "posts/oecd-yacsda/index.html#vertiefung-histogramm-f√ºr-alle-variablen-auf-kompliziert",
    "title": "oecd-yacsda",
    "section": "1.8 VERTIEFUNG: Histogramm f√ºr alle Variablen auf kompliziert",
    "text": "1.8 VERTIEFUNG: Histogramm f√ºr alle Variablen auf kompliziert\n\n\n\n\n\n\nNote\n\n\n\nDieser Abschnitt ist eine Vertiefung; Sie k√∂nnen in √ºberspringen, ohne den Anschluss zu den folgenden Abschnitten zu verlieren. \\(\\square\\)\n\n\nAls erstes erzeugen wir einen langen Dataframe (der nur aus metrischen Variablen besteht):\n\noecd_de_fr %&gt;% \n  select(where(is.numeric)) %&gt;%  # w√§hle alle Spalten aus, wo sich Nummern finden\n  pivot_longer(everything()) %&gt;%  # baue alle Variablen in ein langes Format um\n  slice(1:10) # zeige die Zeilen 1 bis 10\n\n# A tibble: 10 √ó 2\n   name                     value\n   &lt;chr&gt;                    &lt;dbl&gt;\n 1 Education                  7.8\n 2 Jobs                       6  \n 3 Income                     6.3\n 4 Safety                     8.6\n 5 Health                    10  \n 6 Environment                3.5\n 7 Civic_engagement           7.4\n 8 Accessiblity_to_services   8.6\n 9 Housing                    3.3\n10 Community                  7.9\n\n\nDann plotten wir Histogramme, wobei wir nach den L√§ndern (key) gruppieren. Aber zuerst speichern wir uns den ‚Äúlangen‚Äù Datensatz ab:\n\noecd_de_fr_long &lt;- \noecd_de_fr %&gt;% \n  select(where(is.numeric)) %&gt;%  # w√§hle alle Spalten aus, wo sich Nummern finden\n  pivot_longer(everything()) \n\nBetrachten Sie diesen Daten einmal zur √úbung.\nDann plotten wir in gewohnter Manier:\n\noecd_de_fr_long %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(~ name)"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#hintergrund-1",
    "href": "posts/oecd-yacsda/index.html#hintergrund-1",
    "title": "oecd-yacsda",
    "section": "2.1 Hintergrund",
    "text": "2.1 Hintergrund\nHat Deutschland in Vergleich zu anderen L√§ndern eine hohe Lebenszufriedenheit?\nDie Frage ist noch recht unpr√§zise formuliert, aber daf√ºr gibt sie Raum f√ºr eine Menge von Untersuchungsans√§tzen.\n\n2.1.1 Datensatz filtern - nur L√§nder, keine Landesteile\nDer Datensatz in seiner aktuellen Form verst√∂√üt gegen die Regel der ‚ÄúNormalform‚Äù, dass in jeder Zeile (genau) eine Beobachtungseinheit steht und in jeder Zeile (genau) eine Variable. In einigen Zeilen stehen L√§nder, in den meisten anderen aber Landesteile (wie Bayern, Baden-W√ºrttemberg etc.). Filtern wir uns nur die L√§nder, und exkdluieren die Landesteile:\n\noecd_short &lt;-\n  filter(oecd, region_type == \"country_whole\") \n\nDie Anzahl der Zeilen dieses Datensatz oecd_short gibt uns Aufschluss √ºber die Anzahl der untersuchten L√§nder.\n\n\n2.1.2 Visualisierung der Lebenszufriedenheit der L√§nder\n\n2.1.2.1 Mit DataExplorer\n\noecd_short |&gt; \n  select(Country, Life_satisfaction) |&gt; \n  plot_scatterplot(by = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\n\n\n2.1.2.2 Mit ggplot\n\noecd_short %&gt;% \n  ggplot(aes(x = Country, y = Life_satisfaction)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n2.1.2.3 Sieht nicht so sch√∂n aus\nHm, unser Punktediagramm sieht nicht √ºbersichtlich aus. Besser w√§re es, die Punkte absteigend zu sortieren.\nBetrachten wir dazu die Variable country n√§her: Es handelt sich um eine Character-Variable:\n\nstr(oecd)\n\n'data.frame':   429 obs. of  15 variables:\n $ Country                 : chr  \"Australia\" \"Australia\" \"Australia\" \"Australia\" ...\n $ Region                  : chr  \"New South Wales\" \"Victoria\" \"Queensland\" \"South Australia\" ...\n $ region_type             : chr  \"country_part\" \"country_part\" \"country_part\" \"country_part\" ...\n $ Code                    : chr  \"AU1\" \"AU2\" \"AU3\" \"AU4\" ...\n $ Education               : num  8 8.1 7.8 7.3 7.6 6.5 8.1 9.5 8.8 8.5 ...\n $ Jobs                    : num  8.1 7.9 8.1 7.8 8.8 7.6 8.7 9.3 7.8 8.2 ...\n $ Income                  : num  6.8 5.9 6.3 6.1 7.9 5.4 8.2 10 5.7 5.9 ...\n $ Safety                  : num  8.8 9.5 9.5 9 8.6 8.8 0 10 9.7 9.8 ...\n $ Health                  : num  9 9.5 8.3 8.5 9.3 5.4 2.4 9.3 6.7 6.6 ...\n $ Environment             : num  9.8 8.6 9.9 9.4 9.6 10 9.2 9.1 3.5 2.6 ...\n $ Civic_engagement        : num  10 10 10 10 10 10 8.4 10 8.6 8.1 ...\n $ Accessiblity_to_services: num  7.2 7.5 7.7 7.2 7.8 6.8 7.8 8.7 8 7.4 ...\n $ Housing                 : num  7.2 7.8 8.3 8.3 8.9 8.3 5.6 8.3 6.1 5.6 ...\n $ Community               : num  8.9 9.3 8.6 8.6 8.5 8.6 10 9.8 8.3 7.8 ...\n $ Life_satisfaction       : num  7.8 8.5 8.1 8.5 7.8 9.6 7 9.6 7.8 8.1 ...\n\n\nEine Variable des Typs character steht f√ºr Text, z.B. \"Germany\".\nOffensichtlich sind diese alphabetisch geordnet ‚Äì nach dieser Ordnung richtet sich die Ordnung im Diagramm.\n\n\n\n2.1.3 Umwandling in eine Faktor-Variable\nIn solchen F√§llen bietet es sich an, die Character-Variable in eine Factor-Variable umzuwandeln; dann geht das Weitere einfacher.\n\noecd_short &lt;- \noecd_short %&gt;% \n  mutate(Country = factor(Country))\n\n√úbrigens: M√∂chte man wissen, wie viele unterschiedliche Werte eine Variable enth√§lt, dann kann die Funktion distinct() verwenden:\n\noecd_short %&gt;% \n  distinct(Country)\n\n           Country\n1        Australia\n2          Austria\n3          Belgium\n4           Canada\n5            Chile\n6   Czech Republic\n7          Denmark\n8          Estonia\n9          Finland\n10          France\n11         Germany\n12          Greece\n13         Hungary\n14         Iceland\n15         Ireland\n16          Israel\n17           Italy\n18           Japan\n19           Korea\n20      Luxembourg\n21          Mexico\n22     Netherlands\n23     New Zealand\n24          Norway\n25          Poland\n26        Portugal\n27 Slovak Republic\n28        Slovenia\n29           Spain\n30          Sweden\n31     Switzerland\n32          Turkey\n33  United Kingdom\n34   United States"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#ranking-und-top-10-prozent-der-zufriedenheit",
    "href": "posts/oecd-yacsda/index.html#ranking-und-top-10-prozent-der-zufriedenheit",
    "title": "oecd-yacsda",
    "section": "2.2 Ranking und Top-10-Prozent der Zufriedenheit",
    "text": "2.2 Ranking und Top-10-Prozent der Zufriedenheit\n\n2.2.1 Top-10\nSchauen wir uns die ‚ÄúHappy-Top-10‚Äù an, die 10 L√§nder mit der h√∂chsten Lebenszufriedenheit:\n\noecd_short %&gt;% \n  arrange(-Life_satisfaction) %&gt;%  # absteigend sortieren\n  select(Country, Life_satisfaction) %&gt;% \n  slice(1:10)\n\n       Country Life_satisfaction\n1      Denmark              10.0\n2  Switzerland              10.0\n3      Finland               9.7\n4  Netherlands               9.7\n5       Norway               9.7\n6       Canada               9.3\n7      Iceland               9.3\n8       Sweden               9.3\n9    Australia               8.8\n10     Austria               8.8\n\n\n\n\n2.2.2 Die oberen 10% der Zufriedenheit\nMit welcher Lebenszufriedenheit geh√∂rt ein Land zu den Top-10-Prozent der zufriedenen L√§nder?\n\noecd_short %&gt;% \n  summarise(quantile(Life_satisfaction, probs = .90))\n\n  quantile(Life_satisfaction, probs = 0.9)\n1                                      9.7\n\n\nAh, L√§nder mit einer Lebenszufriedenheit von mind. 9.7 geh√∂ren zu den oberen Top-10-Prozent. Filtern wir mal entsprechend:\n\noecd_short %&gt;% \n  filter(Life_satisfaction &gt;= 9.7) %&gt;% \n  select(Country, Life_satisfaction)\n\n      Country Life_satisfaction\n1     Denmark              10.0\n2     Finland               9.7\n3 Netherlands               9.7\n4      Norway               9.7\n5 Switzerland              10.0"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#vertiefung",
    "href": "posts/oecd-yacsda/index.html#vertiefung",
    "title": "oecd-yacsda",
    "section": "2.3 Vertiefung",
    "text": "2.3 Vertiefung\n√Ñndern wir die Sortierung! Mit reorder() kann man die Sortierung √§ndern (re-ordnen, daher der Name):\n\noecd_short_reordered &lt;- \noecd_short %&gt;% \n  mutate(Country_sorted = reorder(Country, Life_satisfaction)) \n\nIst das jetzt geordnet? str() (wie structure) verr√§t es uns:\n\nstr(oecd_short_reordered)\n\n'data.frame':   34 obs. of  16 variables:\n $ Country                 : Factor w/ 34 levels \"Australia\",\"Austria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Region                  : chr  \"Australia\" \"Austria\" \"Belgium\" \"Canada\" ...\n $ region_type             : chr  \"country_whole\" \"country_whole\" \"country_whole\" \"country_whole\" ...\n $ Code                    : chr  \"AUS\" \"AUT\" \"BEL\" \"CAN\" ...\n $ Education               : num  7.6 8.4 7.5 9.2 7.2 10 6.7 9.6 8.7 7.6 ...\n $ Jobs                    : num  7.9 7.7 5 6.6 6.2 7.3 7.9 6.6 6.4 5.2 ...\n $ Income                  : num  9.5 7.9 6.2 7.4 0.4 2.8 5.1 1 5.6 7 ...\n $ Safety                  : num  8.4 10 5.7 6.5 0.6 6.1 10 0 10 8.4 ...\n $ Health                  : num  9 7.2 6.6 8.5 4.2 2.7 5.8 2.1 7.3 9.3 ...\n $ Environment             : num  9.7 2.8 1.9 7.4 8.5 1.4 5.8 6.4 7.9 4.5 ...\n $ Civic_engagement        : num  10 6.2 9.7 4.7 0.1 2.6 8.9 3.7 4.8 7.5 ...\n $ Accessiblity_to_services: num  6.9 7.2 7.6 8.1 0 6.7 8.3 7.6 9 6.9 ...\n $ Housing                 : num  9.5 5.1 8.8 10 1.5 2.9 6.6 1.5 6.6 5.1 ...\n $ Community               : num  8.8 7.6 7.7 8.5 2.5 5.1 9.6 4.6 8.7 7.6 ...\n $ Life_satisfaction       : num  8.8 8.8 7.9 9.3 4.9 5.3 10 0.4 9.7 6.2 ...\n $ Country_sorted          : Factor w/ 34 levels \"Hungary\",\"Portugal\",..: 23 24 20 27 12 13 33 4 30 15 ...\n  ..- attr(*, \"scores\")= num [1:34(1d)] 8.8 8.8 7.9 9.3 4.9 5.3 10 0.4 9.7 6.2 ...\n  .. ..- attr(*, \"dimnames\")=List of 1\n  .. .. ..$ : chr [1:34] \"Australia\" \"Austria\" \"Belgium\" \"Canada\" ...\n\n\nWie man sieht, ist Country_sorted jetzt anders sortiert.\nVisualisieren wir das Ergebnis:\n\n2.3.1 Mit DataExplorer\n\noecd_short_reordered |&gt; \n  select(Country_sorted, Life_satisfaction) |&gt; \n  plot_scatterplot(by = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\nOh, DataExplorer macht die Reihenfolge wieder kaputt.\n\n\n2.3.2 Mit ggpubr\n\noecd_short_reordered |&gt; \n  ggscatter(x = \"Country_sorted\",\n            y = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\n\n\n2.3.3 Mit ggplot\n\nplot_sorted &lt;- oecd_short_reordered %&gt;% \n  ggplot(aes(x = Country_sorted, y = Life_satisfaction)) +\n  geom_point()\n\nplot_sorted\n\n\n\n\n\n\n\n\nSchon besser. Man kann z.B. die Achsen nicht lesen üò≠. Was k√∂nnte man da blo√ü tun?\n\n\n2.3.4 Achsenu um 90 Grad drehen\nMit + coord_flip() lassen sich die Achsen um 90 Grad drehen:\n\nplot_sorted + coord_flip()\n\n\n\n\n\n\n\n\nSch√∂n üòÑ.\nMan h√§tte das Sortieren und Achsen drehen auch in einem Haps machen k√∂nnen:\n\noecd_short_reordered %&gt;% \n  ggplot(aes(x = Country_sorted, y = Life_satisfaction)) +\n  geom_point() + coord_flip()\n\n\n\n\n\n\n\n\nAber √ºbersichtlicher ist es, die Dinge nacheinander zu tun.\n\n\n2.3.5 Mittelwert ins Diagramm\nSch√∂n w√§re es noch, im Bild den Mittelwert o.√Ñ. im Diagramm zu sehen:\n\noecd_short_reordered %&gt;% \n  ggplot(aes(x = Country_sorted, y = Life_satisfaction)) +\n  geom_point() +\n  geom_hline(yintercept = 6.08, data = NA, color = \"firebrick\") + \n  coord_flip()\n\n\n\n\n\n\n\n\nTja, die W√ºnsche h√∂ren nie auf‚Ä¶ W√§re es nicht noch nett, wenn ‚ÄúDeutschland‚Äù hervorgehoben w√§re, optisch, so dass es im Diagramm hervorsticht. Nehmen wir an, wir sind an diesem Land besonders interessiert.\n\noecd_short_reordered &lt;- \n  oecd_short_reordered %&gt;% \n  mutate(is_Germany = Country == \"Germany\")\n\nDamit haben wir eine Spalte erstellt, die angibt, ob ein Land Deutschland ist (TRUE) oder nicht (FALSE). Diese neue Variable nehmen wir her, um die Farbe, Gr√∂√üe und Form der Punkte zu bestimmen:\n\noecd_short_reordered %&gt;% \n  ggplot(aes(x = Country_sorted, y = Life_satisfaction)) +\n  geom_point(aes(color = is_Germany, shape = is_Germany, size = is_Germany)) +\n  geom_hline(yintercept = 6.08, data = NA, color = \"firebrick\") + \n  geom_hline(yintercept = 6.08, data = NA, color = \"grey60\") %&gt;% \n  geom_vline(xintercept = 16, data = NA, color = \"grey80\") +\n  coord_flip()"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#zusammenhang-zweier-metrischer-variablen-punktediagramm",
    "href": "posts/oecd-yacsda/index.html#zusammenhang-zweier-metrischer-variablen-punktediagramm",
    "title": "oecd-yacsda",
    "section": "2.4 Zusammenhang zweier metrischer Variablen ‚Äì Punktediagramm",
    "text": "2.4 Zusammenhang zweier metrischer Variablen ‚Äì Punktediagramm\nH√§ngt die Lebenszufriedenheit mit Civic_engagment zusammen?\nVisualisieren wir diesen (m√∂glichen) Zusammenhang.\n\n2.4.1 Mit ggpubr\n\noecd_short_reordered |&gt; \n  ggscatter(x = \"Civic_engagement\",\n            y = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\n\n\n2.4.2 Mit DataExplorer\n\noecd_short_reordered |&gt; \n  select(Civic_engagement, Life_satisfaction) |&gt; \n  plot_scatterplot(by = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\nDataExplorer bietet den Vorteil, dass man einfach √ºberpr√ºfen kann, ob irgendeine Variable mit Lebenszufriedenheit zusammenh√§ngt:\n\noecd_short_reordered |&gt; \n  #select(Civic_engagement, Life_satisfaction) |&gt; \n  plot_scatterplot(by = \"Life_satisfaction\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.3 Mit ggplot\n\noecd_short_reordered %&gt;% \n  ggplot(aes(x = Civic_engagement, y = Life_satisfaction)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n2.4.4 Insgesamt wenig Zusammenhang\nHm, es ist kein starker Trend zu erkennen.\nWas sagt die Korrelation dazu:\n\noecd_short_reordered %&gt;% \n  summarise(cor_ce_ls = cor(Civic_engagement, Life_satisfaction))\n\n  cor_ce_ls\n1 0.4021292\n\n\nImmerhin, kein ganz unwesentlicher Wert.\n\n\n2.4.5 Und so weiter\nDieses Prinzip mit dem Punktediagramm k√∂nnte man jetzt weiterf√ºhren ad nauseam.\n\n\n2.4.6 Korrelationsdiagramm\n\noecd_short_reordered |&gt; \n  plot_correlation()"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#zusammenhang-zweier-variablen-unter-ber√ºcksichtigung-von-drittvariablen",
    "href": "posts/oecd-yacsda/index.html#zusammenhang-zweier-variablen-unter-ber√ºcksichtigung-von-drittvariablen",
    "title": "oecd-yacsda",
    "section": "2.5 Zusammenhang zweier Variablen unter Ber√ºcksichtigung von Drittvariablen",
    "text": "2.5 Zusammenhang zweier Variablen unter Ber√ºcksichtigung von Drittvariablen\nOben haben wir gesehen, dass Lebenszufriedenheit und Civiv Engagement zusammenh√§ngen (zumindest ein bisschen).\nAber vielleicht h√§ngt dieser Zusammenhang wiederum von der finanziellen Absicherung ab? Nur wenn man materiell abgesichert ist, so k√∂nnte man argumentieren, wird b√ºrgerliches Engagement (bzw. die M√∂glichkeit zu) eine Einflussgr√∂√üe auf die Lebenszufriedenheit.\nAnders gesagt: Man k√∂nnte behaupten, der Zusammenahng von Lebenszufriedenheit und Civiv Engagement ist abh√§ngig von einer dritten Variable, dem Einkommen.\nUm diese Frage zu untersuchen, teilen wir Income in zwei Stufen, hoch und gering. Dann untersuchen wir jeweils den Zusammenhang von Lebenszufriedenheit und b√ºrgerlichem Engagement.\nAchtung! Eine metrische Variablen in zwei H√§lften zu spalten birgt einen hohen Informationsverlust. Da wir aber nur eine grobe Untersuchung vorhaben (und uns noch nicht fortgeschrittener Technik bedienen wollen), bleiben wir erstmal bei dieser sog. Dichotomisierung.\nNehmen wir den Median des Einkommen als Teilungspunkt; man spricht von einem ‚ÄúMediansplit‚Äù:\n\noecd_short %&gt;% \n  summarise(Income_md = median(Income))\n\n  Income_md\n1      5.15\n\n\nZuerst erstellen wir eine Variable Income_high mit den Stufen 0 (nein) und 1 (ja):\n\noecd_short_reordered &lt;- \n  oecd_short_reordered %&gt;% \n    mutate(Income_high = \n           case_when( Income &gt;= median(Income) ~ 1,\n                      Income &lt; median(Income) ~ 0))\n\n\n2.5.1 Visualisierung\nJetzt plotten wir den Zusammenhang:\n\n2.5.1.1 Mit ggpubr\n\noecd_short_reordered |&gt; \n  ggscatter(y = \"Country_sorted\",\n            x = \"Life_satisfaction\",\n            facet.by = \"Income_high\")\n\n\n\n\n\n\n\n\n\n\n2.5.1.2 Mit ggplot\n\nincome_labels &lt;- c(`0` = \"arm\", \n                   `1` =\"reich\")\n\noecd_short_reordered %&gt;% \n  ggplot(aes(x = Country_sorted, y = Life_satisfaction)) +\n  geom_point() +\n  facet_wrap(~ Income_high, \n             labeller = labeller(Income_high = income_labels))  +\n  coord_flip() +\n  labs(y = \"L√§nder\",\n       x = \"Lebenszufriedenheit\",\n       title = \"Lebenszufriedenheit in armen und reichen L√§ndern \") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 Vertiefung: Korrelation pro Gruppe\nUm die Korrelation pro Gruppe zu erhalten, k√∂nnten wir jeweils einen Dataframe pro Gruppe erzeugen (mit filter()) und dann jeweils die Korrelation von Zufriedenheit und Engagement berechnen.\nEine andere, etwas elegantere M√∂glichkeit kann so aussehen:\n\noecd_short_reordered %&gt;%\n  group_by(Income_high) %&gt;% \n  summarise(cor_zuf_eng = cor(Life_satisfaction, Civic_engagement))\n\n# A tibble: 2 √ó 2\n  Income_high cor_zuf_eng\n        &lt;dbl&gt;       &lt;dbl&gt;\n1           0       0.367\n2           1       0.140\n\n\nInteressanterweise ist die Korrelation durchaus verschieden in den beiden Gruppen.\nNat√ºrlich sind die beiden Gruppen nur Stichproben - es stellt sich die Frage, ob die Unterschiede nur durch Zuf√§lligkeiten des Stichprobenziehens entstanden sind oder auch in der Grundgesatmtheit der ‚Äúreichen‚Äù und ‚Äúarmen‚Äù L√§ndern existieren? Dazu sp√§ter mehr!"
  },
  {
    "objectID": "posts/oecd-yacsda/index.html#deskriptive-statistiken-nach-l√§ndern",
    "href": "posts/oecd-yacsda/index.html#deskriptive-statistiken-nach-l√§ndern",
    "title": "oecd-yacsda",
    "section": "2.6 Deskriptive Statistiken nach L√§ndern",
    "text": "2.6 Deskriptive Statistiken nach L√§ndern\n\n2.6.1 Lebenszufriedenheit\n\n2.6.1.1 Mit easystats\nDas ist relativ einfach:\n\noecd_short_reordered %&gt;% \n  select(Life_satisfaction) %&gt;% \n  describe_distribution()\n\nVariable          | Mean |   SD |  IQR |         Range | Skewness | Kurtosis |  n | n_Missing\n---------------------------------------------------------------------------------------------\nLife_satisfaction | 6.07 | 3.38 | 6.33 | [0.00, 10.00] |    -0.58 |    -1.08 | 34 |         0\n\n\n\n\n2.6.1.2 Mit tidyverse\n\noecd_short_reordered %&gt;% \n  summarise(satis_mean = mean(Life_satisfaction),\n            satis_median = median(Life_satisfaction),\n            satis_sd = sd(Life_satisfaction),\n            satis_iqr = IQR(Life_satisfaction))\n\n  satis_mean satis_median satis_sd satis_iqr\n1   6.070588          7.3 3.379397     5.975"
  },
  {
    "objectID": "posts/Def-Statistik01/Def-Statistik01.html",
    "href": "posts/Def-Statistik01/Def-Statistik01.html",
    "title": "Def-Statistik01",
    "section": "",
    "text": "Welche Definition von Statistik passt am besten?\n\n\n\nStatistik fasst Daten zusammen.\nStatistik vervielfacht Daten.\nStatistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen .\nStatistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen und beschreibt die Ungewissheit unserer Schl√ºsse."
  },
  {
    "objectID": "posts/Def-Statistik01/Def-Statistik01.html#answerlist",
    "href": "posts/Def-Statistik01/Def-Statistik01.html#answerlist",
    "title": "Def-Statistik01",
    "section": "",
    "text": "Statistik fasst Daten zusammen.\nStatistik vervielfacht Daten.\nStatistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen .\nStatistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen und beschreibt die Ungewissheit unserer Schl√ºsse."
  },
  {
    "objectID": "posts/Def-Statistik01/Def-Statistik01.html#answerlist-1",
    "href": "posts/Def-Statistik01/Def-Statistik01.html#answerlist-1",
    "title": "Def-Statistik01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz16/wskt-quiz16.html",
    "href": "posts/wskt-quiz16/wskt-quiz16.html",
    "title": "wskt-quiz16",
    "section": "",
    "text": "Behauptung:\n\\(Pr(A|B) = Pr(AB) / Pr(B)\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz16/wskt-quiz16.html#answerlist",
    "href": "posts/wskt-quiz16/wskt-quiz16.html#answerlist",
    "title": "wskt-quiz16",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz16/wskt-quiz16.html#answerlist-1",
    "href": "posts/wskt-quiz16/wskt-quiz16.html#answerlist-1",
    "title": "wskt-quiz16",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/stan_glm_parameterzahl_simple/stan_glm_parameterzahl_simple.html",
    "href": "posts/stan_glm_parameterzahl_simple/stan_glm_parameterzahl_simple.html",
    "title": "stan_glm_parameterzahl_simple",
    "section": "",
    "text": "Exercise\nBetrachten Sie dazu dieses Modell:\nstan_glm(price ~ cut, data = diamonds)\nWie viele Parameter gibt es in diesem Modell?\nHinweise:\n\nGeben Sie nur eine (ganze) Zahl ein.\n\n         \n\n\nSolution\nGrunds√§tzlich hat ein Regressionsmodell die folgenden Parameter:\n\neinen Parameter f√ºr den Intercept (Achsenabschnitt), \\(\\beta_0\\)\npro UV ein weiterer Parameter, \\(\\beta_1, \\beta_2, \\ldots\\)\nf√ºr sigma (\\(\\sigma\\)) noch ein zus√§tzlicher Parameter\n\nZu beachten ist aber, dass bei einer nominalen Variablen mit zwei Stufen nur ein Regressionsgewicht (\\(\\beta_1\\)) berechnet wird. Allgemein gilt bei nominalen also, dass bei \\(k\\) Stufen nur \\(k-1\\) Regressionsgewichte berechnet werden.\nFazit: Im vorliegenden Fall hat die Variable cut 5 Stufen, also werden 4 Regressiongewichte berechnet, zus√§tzlich zum Achsenabschnitt.\n\nsol &lt;- 6\n\nAntwort: Die Anzahl der Parameter in diesem Modell ist also: 6."
  },
  {
    "objectID": "posts/nyc_casestudy/nyc_casestudy.html",
    "href": "posts/nyc_casestudy/nyc_casestudy.html",
    "title": "nyc_casestudy",
    "section": "",
    "text": "Aufgabe\nFallstudie\nEine Analystin untersucht Versp√§tungen der New Yorker Fl√ºge. Sie gibt folgenden Code ein und erh√§lt unten stehendes Ergebnis.\n\nlibrary(sjmisc)\nlibrary(tidyverse)\nlibrary(caret)\ndata(flights, package = \"nycflights13\")\n\nmy_crossval &lt;- trainControl(method = \"cv\",\n                            number = 5,\n                            allowParallel = TRUE,\n                            verboseIter = FALSE)\n\ndoMC::registerDoMC(cores = 2)\n\n\nflights2 &lt;- flights %&gt;%\n  select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% \n  select(-c(year, dep_delay)) %&gt;% \n  std(suffix = \"\")  \n\nn_uebung &lt;- round(.8 * nrow(flights2), digits = 0)\n\nuebung_index &lt;- sample(1:nrow(flights2), size = n_uebung)\n\nuebung_df &lt;- filter(flights2, row_number() %in% uebung_index)\ntest_df &lt;- filter(flights2, !(row_number() %in% uebung_index))\n\nlm_fit1 &lt;- train(arr_delay ~ .,\n                 data = uebung_df,\n                 method = \"lm\",\n                 trControl = my_crossval)\n\nsummary(lm_fit1)\n\n\nCall:\nlm(formula = .outcome ~ ., data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0953 -0.4702 -0.2033  0.1599 29.2400 \n\nCoefficients: (1 not defined because of singularities)\n                 Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)    -0.0009503  0.0017921   -0.530   0.5959    \nmonth          -0.0017658  0.0017979   -0.982   0.3260    \nday             0.0009082  0.0017928    0.507   0.6124    \ndep_time        0.8225147  0.0062273  132.081   &lt;2e-16 ***\nsched_dep_time -0.5863701  0.0441450  -13.283   &lt;2e-16 ***\narr_time       -0.2787396  0.0029549  -94.332   &lt;2e-16 ***\nsched_arr_time  0.0968838  0.0036361   26.645   &lt;2e-16 ***\nflight          0.0385112  0.0020520   18.768   &lt;2e-16 ***\nair_time        1.4220104  0.0132370  107.427   &lt;2e-16 ***\ndistance       -1.4407468  0.0132872 -108.431   &lt;2e-16 ***\nhour            0.0802044  0.0435578    1.841   0.0656 .  \nminute                 NA         NA       NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9171 on 261866 degrees of freedom\nMultiple R-squared:  0.1515,    Adjusted R-squared:  0.1514 \nF-statistic:  4675 on 10 and 261866 DF,  p-value: &lt; 2.2e-16\n\n\nIm Folgenden untersucht sie die pr√§diktive G√ºte am Testdatensatz.\n\nlm1_pred &lt;- predict(lm_fit1, newdata = test_df)\n\nlm1_pred_fit &lt;- postResample(pred = lm1_pred, obs = test_df$arr_delay)\nlm1_pred_fit\n\n     RMSE  Rsquared       MAE \n0.9372781 0.1516473 0.5521067 \n\n\nSchlie√ülich berechnet sie noch ein Random-Forest-Modell. Um Zeit zu sparen, verringert sie den Datensatz in dieser ersten Analyse.\n\nrf_grid &lt;- data.frame(\n  .mtry = c(4, 5, 6, 7),\n  .splitrule = \"variance\",\n  .min.node.size = 5)\n\nuebung_df_small &lt;- sample_n(uebung_df, size = 1000)\n\nrf_fit1 &lt;- train(arr_delay ~ .,\n                 data = uebung_df_small,\n                 method = \"ranger\",\n                 trControl = my_crossval)\n\nAuch hier l√§sst sie sich wieder die G√ºtekoeffizienten ausgeben.\n\nrf1_pred &lt;- predict(rf_fit1, newdata = test_df)\nrf1_pred_fit &lt;- postResample(pred = rf1_pred, obs = test_df$arr_delay)\nrf1_pred_fit\n\n     RMSE  Rsquared       MAE \n0.6001004 0.7181543 0.3510000 \n\n\n\nInterpretieren Sie die Koeffizienten des Pr√§diktors NA des Modells lm1 (s. Spalten Estimate bis Pr(&gt;|t|))!\nWelcher Pr√§diktor des Modells lm1 ist am wichtigsten? Begr√ºnden Sie Ihre Antwort!\nInterpretieren Sie die Ausgabe des Objekts lm1_pred_fit!\nWelche Gefahren bzw. Probleme k√∂nnen damit verbunden sein, dass die Analystin die Stichprobe auf \\(n=1000\\) verkleinert?\nVergleichen Sie die G√ºtekoeffizienten der beiden Modelle im Test-Datensatz!\nDiskutieren Sie einen (m√∂glichen) Grund f√ºr die Unterschiede in den G√ºtekriterien zwischen den beiden Modellen!\n\n         \n\n\nL√∂sung\nInterpretieren Sie die Koeffizienten des Pr√§diktors NA des Modells lm1!\n\nEstimate: Punktsch√§tzer des Einflussgewichts\nStd. Err: Standardfehler, ein Koeffizient zur Beurteilung der (Un-)Genauigkeit des Punktsch√§tzers\nt value: Estimate geteilt durch Std. Error, Signal-Noise-Ratio, z-Wert\nPr: p-Wert\n\nWelcher Pr√§diktor des Modells lm1 ist am wichtigsten? Begr√ºnden Sie Ihre Antwort!\n\nEine M√∂glichkeit zur Bestimmung der Pr√§diktorenrelevanz besteht darin, den Pr√§diktor mit h√∂chstem Absolutwert in der Spalte t value heranzuziehen.\nIn diesem Fall ist das dep_time.\n\nInterpretieren Sie die Ausgabe des Objekts lm1_pred_fit!\n\nEs werden drei G√ºtekriterien berichtet: R-Quadrat, MSE und MAE. MSE gibt den mittleren Quadratfehler der vorhersage an; MAE den mittleren Absolutfehler.\nJe h√∂her \\(R^2\\) und je geringer MAE bzw. MSE sind, desto besser ist das Modell.\n\nWelche Gefahren bzw. Probleme k√∂nnen damit verbunden sein, dass die Analystin die Stichprobe auf \\(n=1000\\) verkleinert?\n\nKleinere Stichproben sch√§tzen die Population ungenauer.\nDurch die Stichprobenziehung k√∂nnten sich die Verteilungen ver√§ndern, was wiederum einen Einfluss auf die Vorhersagen haben kann.\n\nVergleichen Sie die G√ºtekoeffizienten der beiden Modelle im Test-Datensatz!\n\nDas Random-Forest-Modell hat deutlich besser abgeschnitten als das lineare Modell.\n\nDiskutieren Sie einen (m√∂glichen) Grund f√ºr die Unterschiede in den G√ºtekriterien zwischen den beiden Modellen!\n\nEin lineares Modell wird dort gute Vorhersagen leisten, wo seine Voraussetzungen erf√ºllt sind. Eine wichtige Vorausssetzung sind lineare Beziehungen der Pr√§diktoren zum Kriterium.\nHier k√∂nnte der Fall vorliegen, dass die Beziehungen nicht linear sind, so dass ein Modell - wie das Random-Forest-Modell - das nicht auf lineare Beziehungen abzielt, bessere Vorhersagen treffen kann.\n\n\nsol &lt;- \"s. text\"\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nstring"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html",
    "href": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html",
    "title": "Verteilungen-Quiz-04",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nIst eine stetige Verteilung symmetrisch, dann ist sie normalverteilt.\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist",
    "href": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist",
    "title": "Verteilungen-Quiz-04",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist-1",
    "title": "Verteilungen-Quiz-04",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Diamonds-Histogramm-Vergleich2/Diamonds-Histogramm-Vergleich2.html",
    "href": "posts/Diamonds-Histogramm-Vergleich2/Diamonds-Histogramm-Vergleich2.html",
    "title": "Diamonds-Histogramm-Vergleich2",
    "section": "",
    "text": "Die Daten beziehen sich auf den Datensatz diamonds und sind hier einzusehen bzw. k√∂nnen bei Interesse dort heruntergeladen werden.\nAlternativ kann der Datensatz von hier bezogen werden.\n\n\n\n\n\n\n\n\n\n\n\n\nIm Diagramm A wird ein Ma√ü der zentralen Tendenz gruppenbezogen gezeigt, also den jeweiligen Kennwert der Gruppe (Schliffart) wiedergegeben.\nIm Diagramm B wird die Gesamtverteilung √ºber die drei Gruppen hinweg (in hellgrau) dargestellt; in den kr√§ftigeren Farbt√∂nen wird die Verteilung pro Gruppe (Schliffart) dargestellt.\nInsgesamt sind die Verteilung linksschief.\nInsgesamt sind die Verteilung rechtssteil."
  },
  {
    "objectID": "posts/Diamonds-Histogramm-Vergleich2/Diamonds-Histogramm-Vergleich2.html#answerlist",
    "href": "posts/Diamonds-Histogramm-Vergleich2/Diamonds-Histogramm-Vergleich2.html#answerlist",
    "title": "Diamonds-Histogramm-Vergleich2",
    "section": "",
    "text": "Im Diagramm A wird ein Ma√ü der zentralen Tendenz gruppenbezogen gezeigt, also den jeweiligen Kennwert der Gruppe (Schliffart) wiedergegeben.\nIm Diagramm B wird die Gesamtverteilung √ºber die drei Gruppen hinweg (in hellgrau) dargestellt; in den kr√§ftigeren Farbt√∂nen wird die Verteilung pro Gruppe (Schliffart) dargestellt.\nInsgesamt sind die Verteilung linksschief.\nInsgesamt sind die Verteilung rechtssteil."
  },
  {
    "objectID": "posts/Diamonds-Histogramm-Vergleich2/Diamonds-Histogramm-Vergleich2.html#answerlist-1",
    "href": "posts/Diamonds-Histogramm-Vergleich2/Diamonds-Histogramm-Vergleich2.html#answerlist-1",
    "title": "Diamonds-Histogramm-Vergleich2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/simu-uniform/index.html",
    "href": "posts/simu-uniform/index.html",
    "title": "simu-uniform",
    "section": "",
    "text": "1 Aufgabe\nWelcher der folgenden Syntax-Befehle in R ist korrekt, um eine Zufallszahl aus einer gleichverteilten Zufallsvariablen (Min: 0, Max: 10) zu generieren?\nA\n\nrunif(n = 1, min = 0, max = 10) \n\nB\n\nunif(n = 1, min = 0, max = 10) \n\nC\n\nrbinom(n = 1, min = 0, max = 11) \n\nD\n\nrnorm(n = 1, min = 0, max = 10) \n\n  \n  \n  \n  \n\n\n2 L√∂sung\nA"
  },
  {
    "objectID": "posts/bertie-bott3/index.html",
    "href": "posts/bertie-bott3/index.html",
    "title": "bertie-bott3",
    "section": "",
    "text": "1 Aufgabe\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=3\\) furchtbar scheu√üliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erkl√§rt, \\(k=3\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt hei√üt es tapfer sein. Ziehen und runter damit!\nWie gro√ü ist die Wahrscheinlichkeit, genau eine scheu√üliche Bohne zu erwischen?\nHinweis:\n\nGeben Sie das Ergebnis auf 3 Nachkommastellen gerundet an.\nBeachten Sie die Hinweise des Datenwerks\n\n           \n\n\n2 L√∂sung\nEs gibt drei Pfade f√ºr 1 Treffer bei 3 Wiederholungen:\n\nPfad1 &lt;- 3/20 * 17/19 * 16/18\nPfad2 &lt;- 17/20 * 3/19 * 16/18\nPfad3 &lt;- 17/20 * 16/19 * 3/18\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 + Pfad3\nGesamt_Pr\n\n[1] 0.3578947"
  },
  {
    "objectID": "posts/klausuren-bestehen/klausuren-bestehen.html",
    "href": "posts/klausuren-bestehen/klausuren-bestehen.html",
    "title": "Klausuren-bestehen",
    "section": "",
    "text": "Aufgabe\nEine Studentin hat zwei Klausuren, \\(A\\) und \\(B\\) geschrieben. Sie sch√§tzt ihre Chancen zu bestehen auf 35% bzw. auf 60%. Unterstellen Sie Unabh√§ngigkeit der Ereignisse.\nAufgabe: Wie gro√ü ist die Chance, mindestens eine der beiden Klausuren zu bestehen?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nPr_A &lt;- .35\nPr_B &lt;- .6\n\nDie Wahrscheinlichkeit, beide Klausuren zu bestehen:\n\nPr_AB &lt;- Pr_A * Pr_B\nPr_AB\n\n[1] 0.21\n\n\nDie Wahrscheinlichkeit, durch beide Klausuren durchzurasseln nennen wir Pr_negA_negB:\n\nPr_NA &lt;- 1 - Pr_A\nPr_NB &lt;- 1 - Pr_B\n\nPr_negA_negB &lt;- Pr_NA * Pr_NB\nPr_negA_negB\n\n[1] 0.26\n\n\nDas Gegenteil von Pr_negA_negB ist, mindestens eine Klausur zu bestehen:\n\nPr_mind1_bestanden &lt;- 1 - Pr_negA_negB\nPr_mind1_bestanden\n\n[1] 0.74\n\n\nDie L√∂sung lautet 0.74.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode/Flex-vs-nichtflex-Methode.html",
    "href": "posts/Flex-vs-nichtflex-Methode/Flex-vs-nichtflex-Methode.html",
    "title": "Flex-vs-nichtflex-Methode",
    "section": "",
    "text": "Algorithmen des statistischen Lernens lassen sich unterteilen hinsichtlich ihrer Flexibilit√§t; es gibt mehr bzw. weniger flexible Algorithmen.\nWelche der folgenden Aussagen ist in diesem Zusammenhang korrekt?\n\n\n\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine geringere Verzerrung (bias).\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine h√∂here Verzerrung (bias).\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine kleinere Varianz.\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine kleinere Varianz und eine h√∂here Verzerrung.\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine h√∂here Varianz und eine h√∂here Verzerrung."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode/Flex-vs-nichtflex-Methode.html#answerlist",
    "href": "posts/Flex-vs-nichtflex-Methode/Flex-vs-nichtflex-Methode.html#answerlist",
    "title": "Flex-vs-nichtflex-Methode",
    "section": "",
    "text": "Bei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine geringere Verzerrung (bias).\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine h√∂here Verzerrung (bias).\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine kleinere Varianz.\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine kleinere Varianz und eine h√∂here Verzerrung.\nBei gro√üer Stichprobe (\\(n\\)) und kleiner Zahl an Pr√§diktoren (\\(p\\)) haben flexible Algorithmen im Vergleich zu weniger flexiblen Methoden eine h√∂here Varianz und eine h√∂here Verzerrung."
  },
  {
    "objectID": "posts/Flex-vs-nichtflex-Methode/Flex-vs-nichtflex-Methode.html#answerlist-1",
    "href": "posts/Flex-vs-nichtflex-Methode/Flex-vs-nichtflex-Methode.html#answerlist-1",
    "title": "Flex-vs-nichtflex-Methode",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nstatlearning\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/modelldef-regrformel/index.html",
    "href": "posts/modelldef-regrformel/index.html",
    "title": "modelldef-regrformel",
    "section": "",
    "text": "1 Aufgabe\n√úbersetzen Sie folgende Modelldefinition in die korrekte Regressionsformel:\n\\[\n\\begin{aligned}\n\\text{y}_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{x1}_i + \\beta_2\\text{x2}_i \\\\\n\\beta_0, \\beta_1, \\beta_2  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\]\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\ny ~ x1 + x2"
  },
  {
    "objectID": "posts/Sim-Prior/Sim-Prior.html",
    "href": "posts/Sim-Prior/Sim-Prior.html",
    "title": "Sim-Prior",
    "section": "",
    "text": "Exercise\nGegeben dem folgenden Modell, simulieren Sie Daten aus der Prior-Verteilung (Priori-Pr√§diktiv-Verteilung).\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(0, 1)\\)\nPrior f√ºr \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{U}(0, 10)\\)\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nn &lt;- 1e4\n\n\nsim &lt;- tibble(\n  mu = rnorm(n = n),  # Default-Werte sind mean=0, sd = 1\n  sigma = runif(n = n, 0, 10)) %&gt;%\n  mutate(\n    y = rnorm(n = n, mean = mu, sd = sigma))\n\nggplot(sim, aes(x = y)) +\n  geom_density() +\n  labs(x = \"y\", y = \"Dichte\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/modellguete-testset/modellguete-testset.html",
    "href": "posts/modellguete-testset/modellguete-testset.html",
    "title": "modellguete-testset",
    "section": "",
    "text": "Berechnen Sie die Modellg√ºte (RMSE) im Test-Sample.\nGehen Sie von folgenden Annahmen aus.\n\nDieses Test-Sample\nAV: count\nDieses Train-Sample\nGehen Sie als Vorhersage vom Mittelwert der AV im Train-Sample aus (f√ºr alle Beobachtungen im Test-Sample).\n\nHinweise:\n\nHier finden Sie ein Data-Dictionary.\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/modellguete-testset/modellguete-testset.html#setup",
    "href": "posts/modellguete-testset/modellguete-testset.html#setup",
    "title": "modellguete-testset",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\n\nd_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/yacsda-bikerental/main/data/bikeshare_train.csv\")\nd_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/yacsda-bikerental/main/data/bikeshare_control.csv\")"
  },
  {
    "objectID": "posts/modellguete-testset/modellguete-testset.html#mittelwert-der-av-im-train-sample-berechnen",
    "href": "posts/modellguete-testset/modellguete-testset.html#mittelwert-der-av-im-train-sample-berechnen",
    "title": "modellguete-testset",
    "section": "Mittelwert der AV im Train-Sample berechnen",
    "text": "Mittelwert der AV im Train-Sample berechnen\n\nmean_count_train_sample &lt;- \n  d_train |&gt; \n  summarise(count_avg = mean(count))\n\nmean_count_train_sample\n\n\n\n\n\ncount_avg\n\n\n\n\n703.7913\n\n\n\n\n\n\n\nd_test &lt;-\n  d_test |&gt; \n  mutate(pred = 704)\n\nAnstelle von 704 k√∂nnten Sie auch Ihre eigenen Vorhersagen Ihrer Modelle einsetzen, etwa:\n\nd_test &lt;-\n  d_test |&gt; \n  mutate(pred = meine_vorhersagen)"
  },
  {
    "objectID": "posts/modellguete-testset/modellguete-testset.html#modellg√ºte-im-test-sample-berechnen",
    "href": "posts/modellguete-testset/modellguete-testset.html#modellg√ºte-im-test-sample-berechnen",
    "title": "modellguete-testset",
    "section": "Modellg√ºte im Test-Sample berechnen",
    "text": "Modellg√ºte im Test-Sample berechnen\n\nd_test |&gt; \n  rmse(truth = count,\n       estimate = pred)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrmse\nstandard\n646.4874\n\n\n\n\n\n\nF√ºr R-Quadrat geht das analog:\n\nd_test |&gt; \n  rsq(truth = count,\n       estimate = pred)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\nrsq\nstandard\nNA\n\n\n\n\n\n\nLeider ist das R-Quadrat in diesem Fall (per Definition) Null: Der Mittelwert als Vorhersagewert ist was ‚ÄúR-Quadrat gleich Null‚Äù meint.\n(Dar√ºber hinaus wird das R-Quadrat hier auf Basis der Korrelation berechnet, und wir haben einen konstanten Wert bei pred).\n\nCategories:\n\nregression\nmodelling\nperformance\nrmse\nstring"
  },
  {
    "objectID": "posts/lm1/lm1.html",
    "href": "posts/lm1/lm1.html",
    "title": "lm1",
    "section": "",
    "text": "Laden Sie den Datensatz mtcars aus dieser Quelle.\nBerechnen Sie eine Regression mit mpg als Ausgabevariable und hp als Eingabevariable!\nWelche Aussage ist f√ºr diese Analyse richtig?\n\n\n\nmpg und hp sind positiv korreliert laut dem Modell.\nDer Achsenabschnitt ist nahe Null.\nDie Analyse beinhaltet einen nominal skalierten Pr√§diktor.\nDas gesch√§tzte Betagewicht f√ºr hp liegt bei 30.099.\nDas gesch√§tzte Betagewicht f√ºr hp liegt bei -0.068."
  },
  {
    "objectID": "posts/lm1/lm1.html#answerlist",
    "href": "posts/lm1/lm1.html#answerlist",
    "title": "lm1",
    "section": "",
    "text": "mpg und hp sind positiv korreliert laut dem Modell.\nDer Achsenabschnitt ist nahe Null.\nDie Analyse beinhaltet einen nominal skalierten Pr√§diktor.\nDas gesch√§tzte Betagewicht f√ºr hp liegt bei 30.099.\nDas gesch√§tzte Betagewicht f√ºr hp liegt bei -0.068."
  },
  {
    "objectID": "posts/lm1/lm1.html#answerlist-1",
    "href": "posts/lm1/lm1.html#answerlist-1",
    "title": "lm1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nRichtig\n\n\nCategories:\n\nregression\nlm\nstats-nutshell\nschoice"
  },
  {
    "objectID": "posts/lm-mario2/lm-mario2.html",
    "href": "posts/lm-mario2/lm-mario2.html",
    "title": "lm-mario2",
    "section": "",
    "text": "Sagen Sie den Verkaufspreis vorher f√ºr ein Spiel mit 3 Euro Versandkosten (ship_pr)!"
  },
  {
    "objectID": "posts/lm-mario2/lm-mario2.html#setup",
    "href": "posts/lm-mario2/lm-mario2.html#setup",
    "title": "lm-mario2",
    "section": "Setup",
    "text": "Setup\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nlibrary(tidyverse)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/lm-mario2/lm-mario2.html#regressionsgerade-berechnen",
    "href": "posts/lm-mario2/lm-mario2.html#regressionsgerade-berechnen",
    "title": "lm-mario2",
    "section": "Regressionsgerade berechnen",
    "text": "Regressionsgerade berechnen\n\nlm_mariokart &lt;- lm(total_pr ~ ship_pr, data = mariokart) # \"lm\" wie *l*lineares *M*odell, also eine Gerade.\nlm_mariokart\n\n\nCall:\nlm(formula = total_pr ~ ship_pr, data = mariokart)\n\nCoefficients:\n(Intercept)      ship_pr  \n     36.246        4.337"
  },
  {
    "objectID": "posts/lm-mario2/lm-mario2.html#vorhersagen",
    "href": "posts/lm-mario2/lm-mario2.html#vorhersagen",
    "title": "lm-mario2",
    "section": "Vorhersagen",
    "text": "Vorhersagen\nVorhersagen funktionieren mit dem Befehl predict:\n\nneues_spiel &lt;- tibble(ship_pr = 3)  # oder \"data.frame\" statt \"tibble\"\nneues_spiel\n\n\n\n\n\nship_pr\n\n\n\n\n3\n\n\n\n\n\n\n\npredict(lm_mariokart, neues_spiel)  # predicte mir den Verkaufspreis\n\n      1 \n49.2572 \n\n\n\nCategories:\n\nR\nlm\npredict\nnum"
  },
  {
    "objectID": "posts/confounder-example/index.html",
    "href": "posts/confounder-example/index.html",
    "title": "confounder-example",
    "section": "",
    "text": "library(dagitty)\n\n\n1 Aufgabe\nEin Forscherteam hat folgende Hypothesen:\n\nWerbung, die als ‚ÄúKI-generiert‚Äù gekennzeichnet ist, f√ºhrt (im Durchschnitt) zu geringer Kaufabsicht im Vergleich zu Werbung ohne KI-Kennzeichnung (unabh√§ngig davon, ob die Werbung tats√§chlich von KI generiert wurde).\n\nNat√ºrlich ist diese Hypothese wohl basiert auf Theorien und bestehenden Befunden, die hier aber nicht weiter ausgef√ºhrt sind ‚Ä¶\nDar√ºber hinaus untersuchen sie noch eine zweite Hypothese, n√§mlich ob KI generierte Produkte eine h√∂here Kaufabsicht hervorrufen als nicht KI-generierte Produkte.\nEs handelt sich also um eine zweifaktorielles Design. Die Forschergruppe will ein Experiment durchf√ºhren, wobei die Stichproben bei ca. \\(n=20\\) liegt pro Gruppe/Bedingung.\nDer DAG der Forschergruppe sieht aus wie folgt:\n\ndag1 &lt;-\n  \"\n  dag{\nKIK -&gt; KA\nKI -&gt; KA\nU -&gt; KA\n}\n\"\n\ngraphLayout(dag1) |&gt; plot()\n\n\n\n\n\n\n\n\nKIK: KI-Kennzeichnung; KA: Kaufabsicht; KI: KI-Generierung, U: unbekannte Einfl√ºsse\nDie Forschergruppe geht davon aus, dass keine Konfundierer vorliegen. Au√üerdem sollte etwaige Konfundierung durch die Randomisierung (und experimentelle Kontrolle) ausgeschaltet werden.\nAufgabe Hat die Forschergruppe Recht? Was ist Ihre Meinung? F√§llt Ihnen ein plausibler Konfundierer ein? Was raten Sie der Forschergruppe.\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nEin m√∂glicher Konfundierer ist das Pers√∂nlichkeitsmerkmal ‚ÄúSkeptizismus‚Äù, mit dem hier eine skeptische Grundeinstellung gemeint ist.\nMenschen mit hohem Wert in Skeptizismus (‚Äúskeptische Menschen‚Äù) sind insgesamt weniger kaufgeneigt, kaufen also weniger. Der Grund ist, dass sie dem Wert eines Produkts nicht trauen bzw. nicht vom Wert √ºberzeugt sind. Au√üerdem sehen sie Schwachstellen in der Argumentation, warum ein Produkt gekauft werden sollte.\nZum Zweiten w√ºrden solche skeptischen Personen es vorziehen, wenn ein Produkt √ºber eine KI-Kennzeichnung verf√ºgt. Denn damit bekommen sie mehr Informationen als ohne Kennzeichnung (unter der Annahme, dass die Kennzeichnung auch relevant ist in dem Sinne, dass sie mit tats√§chlicher KI-Generierung einher geht). Demnach w√§re man ohne KI-Kennzeichnung im Ungewissen, mit KI-Kennzeichnung hingegen ist man besser informiert.\n\ndag2 &lt;-\n  \"\n  dag{\nKIK -&gt; KA\nKI -&gt; KA\nU -&gt; KA\nS -&gt; KA\nS -&gt; KIK\n}\n\"\n\ngraphLayout(dag2) |&gt; plot()\n\n\n\n\n\n\n\n\nKIK: KI-Kennzeichnung; KA: Kaufabsicht; KI: KI-Generierung, S: Skeptizismus; U: unbekannte Einfl√ºsse\nMan k√∂nnte argumentieren, dass Skeptizismus mit dem Interaktionseffekt von KI-Kennzeichnung und KI-Generiertheit zusammenh√§ngt (aber nicht mit KI-Kennzeichnung als Haupteffekt).\nDar√ºber hinaus hat die Forschergruppe das Problem, dass etwaige Konfundierer nicht zwingend durch die Randomisierung neutralisiert werden. Der Grund davon ist die kleine Stichprobengr√∂√üe. Bei kleinen Stichproben wirkt der ‚ÄúZufall‚Äù der Aufteilung, das Gesetz der gro√üen Zahl, noch nicht (unbedingt und umf√§nglich).\nInsgesamt ist der Forschergruppe zu raten, ggf. auf Konfundierung durch Skeptizismus oder andere (Pers√∂nlichkeit-)Merkmale zu kontrollieren."
  },
  {
    "objectID": "posts/wrangle9/wrangle9.html",
    "href": "posts/wrangle9/wrangle9.html",
    "title": "wrangle9",
    "section": "",
    "text": "Aufgabe\nUm Variablen in einem Datensatz anzulegen oder zu ver√§ndern, nutzt man mutate() im tidyverse. mutate() ist n√ºtzlich f√ºr vektorielles Rechnen. In diesem Zusammenhang: Was ist das Ergebnis folgenden Ausdrucks?\n\nsum(1:3 + 1:3)\n\n         \n\n\nL√∂sung\n12\n\nsum(1:3 + 1:3)\n\n[1] 12\n\n\n\nCategories:\n\neda\n‚Äò2023‚Äô\nnum"
  },
  {
    "objectID": "posts/regex02/regex02.html",
    "href": "posts/regex02/regex02.html",
    "title": "regex02",
    "section": "",
    "text": "Aufgabe\nMatchen Sie Elemente des Vektors txt3, die nur aus Ziffern bestehen:\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\n\n[1] FALSE FALSE  TRUE  TRUE FALSE FALSE\n\n\nMan kann z.B. auch \\\\d verwenden anstelle von [:digit:].\nSicherlich gibt es noch mehrere weitere L√∂sungen.\n\nCategories:\n\ntextmining\nregex\nstring"
  },
  {
    "objectID": "posts/tidy1/tidy1.html",
    "href": "posts/tidy1/tidy1.html",
    "title": "tidy1",
    "section": "",
    "text": "Das Konzept von ‚Äútidy‚Äù Daten (‚ÄúTidyformat‚Äù) spielt in der Datenanalyse eine wichtige Rolle.\nBetrachten Sie die Tabellen im Folgenden. Welche ist ‚Äútidy‚Äù?\nHinweise:\n\nAlle Variablen sollen nicht konstant sein, also mehr als einen uniquen Wert aufweisen.\nAlle Variablen sollen keine fehlenden Werte aufweisen, also komplett sein.\nAlle Variablen sollen numerisch sein.\n\nTabelle A:\n\n\n\n\n\n\n\n\nTabelle A\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\nA\n1\n\n\n2\n20\nB\n1\n\n\n1\n30\nC\n2\n\n\n2\n40\nD\n2\n\n\n\n\n\n\n\nTabelle B:\n\n\n\n\n\n\n\n\nTabelle B\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1\n1\n\n\n2\n20\n1\n1\n\n\n1\n30\n1\n2\n\n\n2\n40\n1\n2\n\n\n\n\n\n\n\nTabelle C:\n\n\n\n\n\n\n\n\nTabelle C\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1\n1\n\n\n2\n20\n2\n1\n\n\n1\n30\n3\n2\n\n\n2\n40\n4\n2\n\n\n\n\n\n\n\nTabelle D:\n\n\n\n\n\n\n\n\nTabelle D\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1,2\n1\n\n\n2\n20\nid1\n1\n\n\n1\n30\nid1\n2\n\n\n2\n40\nid1\n2\n\n\n\n\n\n\n\nTabelle E:\n\n\n\n\n\n\n\n\nTabelle E\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1,2\n1\n\n\n2\n20\n1,2\n1\n\n\n1\n30\n1,2\n2\n\n\n2\n40\n1,2\n2\n\n\n\n\n\n\n\n\n\n\nTabelle A\nTabelle B\nTabelle C\nTabelle D\nTabelle E"
  },
  {
    "objectID": "posts/tidy1/tidy1.html#answerlist",
    "href": "posts/tidy1/tidy1.html#answerlist",
    "title": "tidy1",
    "section": "",
    "text": "Tabelle A\nTabelle B\nTabelle C\nTabelle D\nTabelle E"
  },
  {
    "objectID": "posts/tidy1/tidy1.html#answerlist-1",
    "href": "posts/tidy1/tidy1.html#answerlist-1",
    "title": "tidy1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Alle Werte sollen numerisch sein\nFalsch. Variablen sollen nicht konstant sein.\nRichtig. Das ist ein ‚Äòtidy Tibble‚Äô.\nFalsch. Die Spalte id1wei√üt einen nicht erlaubten Wert auf.\nFalsch. In einer Zelle darf nur ein (numerischer) Wert stehen.\n\n\nCategories:\n\ntidy\ndatawrangling\nschoice"
  },
  {
    "objectID": "posts/prob-disjunkt/index.html",
    "href": "posts/prob-disjunkt/index.html",
    "title": "prob-disjunkt",
    "section": "",
    "text": "1 Aufgabe\nZwei Ereignisse A und B hei√üen disjunkt (oder unvereinbar), wenn gilt:\n\n\\(A \\cup B = \\Omega\\) (Die Vereinigung ergibt den gesamten Ereignisraum.)\n\\(Pr(A\\cap B)=Pr(A)\\cdot Pr(B)\\) (Sie sind stochastisch unabh√§ngig.)\n\\(A\\cap B= \\emptyset\\) (Ihr Durchschnitt ist die leere Menge.)\n\\(A \\subset B\\) (Das Ereignis A ist eine echte Untermenge von B.)\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\n\\(A\\cap B= \\emptyset\\) (Ihr Durchschnitt ist die leere Menge.)"
  },
  {
    "objectID": "posts/tidymodels-ames-04/tidymodels-ames-04.html",
    "href": "posts/tidymodels-ames-04/tidymodels-ames-04.html",
    "title": "tidymodels-ames-04",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nVerwenden Sie die Funktion last_fit.\n\n         \n\n\nL√∂sung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price)) %&gt;% \n  select(Sale_Price, Gr_Liv_Area)\n\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\n\nset.seed(42)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nRezept definieren:\n\nrec1 &lt;- \n  recipe(Sale_Price ~ Gr_Liv_Area, data = ames) \n\nVorhersagen mit last_fit:\n\nfit1_last &lt;- last_fit(object = m1, preprocessor = rec1, split = ames_split)  \nfit1_last\n\nWir bekommen ein Objekt, in dem Fit, Modellg√ºte, Vorhersagen und Hinweise enthalten sind.\nOhne Rezept l√§sst sich last_fit nicht anwenden.\nVorhersagen:\n\nfit1_last %&gt;% collect_predictions() %&gt;% \n  head()\n\nModellg√ºte im Test-Sample:\n\nfit1_last %&gt;% collect_metrics()\n\nR-Quadrat:\n\nsol &lt;- 0.517\nsol\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/mtcars-post_paper/index.html",
    "href": "posts/mtcars-post_paper/index.html",
    "title": "mtcars-post_paper",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mtcars: Berichten Sie die Breite eines Sch√§tzintervalls (89%, HDI) zum mittleren Spritverbrauch! Nutzen Sie Methoden der Bayes-Statistik.\nHinweise\nDazu sei folgendes Modell gegeben.\nSetup:\n\ndata(mtcars)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(ggpubr)\n\nModell berechnen:\n\nm1 &lt;- stan_glm(mpg ~ 1, \n               data = mtcars,\n               seed = 42,\n               refresh = 0)\n\nDann gibt es verschiedene Einstellungen f√ºr die Funktion parameters():\n\nparameters(m1, ci = .89, ci_method = \"hdi\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n20.10377\n0.89\n18.26377\n21.63711\n1\n1.000792\n2838.234\nnormal\n20.09062\n15.06737\n\n\n\n\n\n\nIm Standard wird ein 95%-ETI berichtet:\n\nparameters(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n20.10377\n0.95\n18.0073\n22.15085\n1\n1.000792\n2838.234\nnormal\n20.09062\n15.06737\n\n\n\n\n\n\n         \n\n\nL√∂sung\nIm Standard wird ein 95%-Perzentilintervall berechnet, s. die Dokumentation zur Funktion hier.\nDaher m√ºssen wir explizit das 89%-HDI anfordern.\nDie L√∂sung ist also aus der Tabelle oben ablesbar als Differenz der Gr√∂√üen des Sch√§tzbereichs (Konfidenzintervalls, CI).\n\n\n[1] 3.373347\n\n\n\nCategories:\n\nbayes\npost\nestimation\nexam-22"
  },
  {
    "objectID": "posts/ziel-bayes/index.html",
    "href": "posts/ziel-bayes/index.html",
    "title": "ziel-bayes",
    "section": "",
    "text": "1 Aufgabe\nWelche Wahrscheinlichkeit wird durch Bayes‚Äô Theorem berechnet?\nA. \\(Pr(D|H)\\) B. \\(Pr(H|D)\\) C. \\(Pr(H)\\) D. \\(Pr(D)\\) E. \\(p\\)-Wert F. \\(Pr(HD)\\) G. \\(Pr(H,D)\\) H. \\(Pr(P) * Pr(D)\\) I. Keine der genannten Optionen\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung"
  },
  {
    "objectID": "posts/kausal-einfach/kausal-einfach.html",
    "href": "posts/kausal-einfach/kausal-einfach.html",
    "title": "kausal-einfach",
    "section": "",
    "text": "Eine Forscher:in aus Kalifornien entdeckt, dass Haiangriffe mit Eisverkauf korreliert sind: Haiangriffe treten geh√§uft dann auf, wenn am Strand viel Eis verkauft wird. Dieser Zusammenhang ist zwar nicht perfekt, aber die Forscher:in findet in ihren Daten einen starken, sogar ‚Äúsignifikanten‚Äù Zusammenhang.\nWelche Schl√ºsse sind aus diesen Daten zu ziehen? W√§hlen Sie die Antwort, die am besten passt!\n\n\n\nDa Eisverkauf die UV und Haiangriff die AV ist, sind die Daten im Sinne eines Kausalschlusses ‚ÄúEisverkauf f√ºhrt (tendenziell) zu Haiangriffen‚Äù zu interpretieren. Nat√ºrlich gilt dies nur f√ºr linearen Zusammenh√§nge, da Korrelationen nur linearen Zusammenh√§nge identifizieren k√∂nnen.\nEs ist kein Kausalschluss m√∂glich; eine Drittvariable k√∂nnte den Zusammenhang der beobachteten Variablen konfundieren.\nDie Daten (soweit bekannt bzw. oben aufgef√ºhrt sind) machen deutlich, dass es einen Zusammenhang zwischen den beiden Variablen gibt; folglich ist die eine Variable Ursache und die andere Wirkung. Die Daten lassen aber keine Aussage zu, welche der beiden Variablen Ursache und welche Wirkung ist.\nEs ist davon auszugehen, dass Haiangriff die Ursache ist und Eisverkauf die Wirkung.\nDa es sich nur um Beobachtungsdaten, nicht um Experimentaldaten handelt, ist keine Aussage m√∂glich."
  },
  {
    "objectID": "posts/kausal-einfach/kausal-einfach.html#answerlist",
    "href": "posts/kausal-einfach/kausal-einfach.html#answerlist",
    "title": "kausal-einfach",
    "section": "",
    "text": "Da Eisverkauf die UV und Haiangriff die AV ist, sind die Daten im Sinne eines Kausalschlusses ‚ÄúEisverkauf f√ºhrt (tendenziell) zu Haiangriffen‚Äù zu interpretieren. Nat√ºrlich gilt dies nur f√ºr linearen Zusammenh√§nge, da Korrelationen nur linearen Zusammenh√§nge identifizieren k√∂nnen.\nEs ist kein Kausalschluss m√∂glich; eine Drittvariable k√∂nnte den Zusammenhang der beobachteten Variablen konfundieren.\nDie Daten (soweit bekannt bzw. oben aufgef√ºhrt sind) machen deutlich, dass es einen Zusammenhang zwischen den beiden Variablen gibt; folglich ist die eine Variable Ursache und die andere Wirkung. Die Daten lassen aber keine Aussage zu, welche der beiden Variablen Ursache und welche Wirkung ist.\nEs ist davon auszugehen, dass Haiangriff die Ursache ist und Eisverkauf die Wirkung.\nDa es sich nur um Beobachtungsdaten, nicht um Experimentaldaten handelt, ist keine Aussage m√∂glich."
  },
  {
    "objectID": "posts/kausal-einfach/kausal-einfach.html#answerlist-1",
    "href": "posts/kausal-einfach/kausal-einfach.html#answerlist-1",
    "title": "kausal-einfach",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/Regression5/Regression5.html",
    "href": "posts/Regression5/Regression5.html",
    "title": "Regression5",
    "section": "",
    "text": "Aufgabe\nGegeben sei ein Datensatz mit f√ºnf Pr√§diktoren, wobei Studierende die Beobachtungseinheit darstellen:\n\n\\(X_1\\): Geschlecht_Frau (0: nein, 1: ja)\n\\(X_2\\): Letzte Mathenote (z-Wert)\n\\(X_3\\): Matheanteil im Studium (z-Wert)\n\\(X_4\\): Interaktion von \\(X1\\) und \\(X2\\)\n\nDie vorherzusagende Variable (\\(Y\\); Kriterium) ist Gehalt nach Studienabschluss.\nWie lautet das Kriterium \\(y\\) f√ºr eine Person mit folgenden Werten:\n\n\\(x_1\\): 0\n\\(x_2\\): 1.59\n\\(x_3\\): 0.35\n\nBerechnen Sie dazu ein Regressionsmodell (Least Squares) anhand folgender Modellparameter:\n\n\\(\\beta_0: 50\\)\n\\(\\beta_1: 40\\)\n\\(\\beta_2: 8\\)\n\\(\\beta_3: 1\\)\n\\(\\beta_4: 7\\)\n\nGeben Sie als Antwort den vorhergesagten \\(Y\\)-Wert an!\nHinweis: Runden Sie auf zwei Dezimalstellen.\n         \n\n\nL√∂sung\nDie Antwort lautet 63.07.\n\nCategories:\n\ndyn\nregression\nlm\nnum"
  },
  {
    "objectID": "posts/count-lexicon/count-lexicon.html",
    "href": "posts/count-lexicon/count-lexicon.html",
    "title": "count-lexicon",
    "section": "",
    "text": "Aufgabe\nGegeben eines (mehrelementigen) Strings, my_string, und eines Lexicons, my_lexicon, z√§hlen Sie, wie h√§ufig sich ein Wort aus dem Lexikon in einem Element des Strings wiederfindet.\n\nmy_string &lt;-\n  c(\"Heute ist ein sch√∂ner Tag\", \"Was geht in dieser Woche?\")\n\n\nmy_lexicon &lt;- c(\"Tag\", \"Woche\", \"Jahr\")\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie die Funktion count_lexicon aus {prada}. Das Paket k√∂nnen Sie hier herunterladen/installieren.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\n\n\nPaket prada\nEine M√∂glichkeit ist es, die Funktion count_lexion aus dem Paket prada zu nutzen.\nMan kann es so installieren: remotes::install_github(\"sebastiansauer/prada\").\n\nlibrary(prada)\n\n\nmap_int(my_string,  \n        ~ count_lexicon(.x, my_lexicon))\n\n[1] 1 1\n\n\nSo k√∂nnen Sie sich den Quellcode einer Funktion, z.B. count_lexicon() anschauen:\n\ncount_lexicon\n\nfunction(txt, lexicon){\n  # convert strings to lower letters:\n  txt &lt;- tolower(txt)\n  lexicon &lt;- tolower(lexicon)\n\n  # build regex query:\n  lexicon_regex &lt;- paste0(\"^\", lexicon, \"$\", collapse = \"|\")\n\n  # split string into words:\n  string_in_words &lt;- unlist(stringr::str_split(txt, pattern = stringr::boundary(\"word\")))\n\n  # search:\n  pattern_detected_in_string_count &lt;- sum(stringr::str_detect(string_in_words, pattern = lexicon_regex))\n\n  # return:\n  return(pattern_detected_in_string_count)\n}\n&lt;bytecode: 0x7fa06cf514d8&gt;\n&lt;environment: namespace:prada&gt;\n\n\nIn dem Paket gibt es noch zwei Varianten f√ºr diese Funktion, die auf einem Join aufbauen.\n\n\nSelbstgestrickt\nHier ist eine zweite Variante ohne besondere Pakete (au√üer stringr).\nWir definieren eine entsprechende Funktion:\n\n# Funktion, um die Anzahl der √úbereinstimmungen eines Lexikons in einem String zu z√§hlen\ncount_lexicon_matches &lt;- function(string, lexicon) {\n  # Verketten Sie die W√∂rter im Lexikon mit dem |-Operator, um ein regul√§res Ausdrucksmuster zu erstellen\n  lexicon_pattern &lt;- paste(lexicon, collapse = \"|\")\n  # Verwenden Sie str_count, um die Anzahl der √úbereinstimmungen zu z√§hlen\n  matches &lt;- str_count(string, lexicon_pattern)\n  return(matches)\n}\n\nWir z√§hlen die √úbereinstimmungen in jedem Element des Strings:\n\nmatches_per_element &lt;- sapply(my_string, count_lexicon_matches, lexicon = my_lexicon)\n\n# Ergebnis ausgeben:\nprint(matches_per_element)\n\nHeute ist ein sch√∂ner Tag Was geht in dieser Woche? \n                        1                         1 \n\n\nAnstelle von sapply kann man das tidyverse-Pendant, map nutzen:\n\nmap_int(my_string,  \n        ~ count_lexicon_matches(.x, my_lexicon))\n\n[1] 1 1\n\n\n\nCategories:\n\ntextmining\nnlp\nregex\nstring"
  },
  {
    "objectID": "posts/vis-mariokart-variab/vis-mariokart-variab.html",
    "href": "posts/vis-mariokart-variab/vis-mariokart-variab.html",
    "title": "vis-mariokart-variab",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nVisualisieren Sie die Streuung der Variablen total_pr.\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\nlibrary(DataExplorer)  # Data-Vis\nlibrary(ggpubr)  # Data-Vis\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nVisualisieren:\nMit dataExplorer:\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  plot_density()  # oder \"plot_histogram()\"\n\n\n\n\n\n\n\n\nMit ggpubr:\n\ngghistogram(mariokart, x = \"total_pr\")\n\n\n\n\n\n\n\n\nMit ggplot:\n\nmariokart %&gt;% \n  ggplot(aes(x = total_pr)) +\n  geom_density()  # oder \"geom_histogram()\"\n\n\n\n\n\n\n\n\nFalls Sie Teile der R-Syntax nicht kennen: Im Zweifel einfach ignorieren :-)\n\nCategories:\n\ndatawrangling\neda\ntidyverse\nvis\nvariability\nstring"
  },
  {
    "objectID": "posts/Regression2/Regression2.html",
    "href": "posts/Regression2/Regression2.html",
    "title": "Regression2",
    "section": "",
    "text": "Ein Streudiagramm von \\(x\\) und \\(y\\) ergibt folgende Abbildung:\n\n\n\n\n\n\n\n\n\nW√§hlen Sie das am besten passende Modell aus der Liste aus!\n\n\n\n\\(y = 40 + 10 \\cdot x + \\epsilon\\)\n\\(y = 40 + -10 \\cdot x + \\epsilon\\)\n\\(y = -40 + -10 \\cdot x + \\epsilon\\)\n\\(y = -40 + 10 \\cdot x + \\epsilon\\)\n\\(y = 0 + -40 \\cdot x + \\epsilon\\)"
  },
  {
    "objectID": "posts/Regression2/Regression2.html#answerlist",
    "href": "posts/Regression2/Regression2.html#answerlist",
    "title": "Regression2",
    "section": "",
    "text": "\\(y = 40 + 10 \\cdot x + \\epsilon\\)\n\\(y = 40 + -10 \\cdot x + \\epsilon\\)\n\\(y = -40 + -10 \\cdot x + \\epsilon\\)\n\\(y = -40 + 10 \\cdot x + \\epsilon\\)\n\\(y = 0 + -40 \\cdot x + \\epsilon\\)"
  },
  {
    "objectID": "posts/Regression2/Regression2.html#answerlist-1",
    "href": "posts/Regression2/Regression2.html#answerlist-1",
    "title": "Regression2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nRichtig\nFalsch\n\n\nCategories:\n\nregression\ndyn"
  },
  {
    "objectID": "posts/wskt-schluckspecht2/index.html",
    "href": "posts/wskt-schluckspecht2/index.html",
    "title": "Wskt-Schluckspecht2",
    "section": "",
    "text": "Gepr√ºft werden soll folgende Hypothese:\n\nAutos mit viel PS haben einen h√∂heren (mittleren) Spritverbrauch als Autos mit wenig PS.\n\nH√∂herer Spritverbrauch bedeutet geringere Spritsparsamkeit.\nDaf√ºr ist folgende Analyse gegeben.\n\n\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(mtcars)\n\n\n\n\nDie Variable mpg (Miles per Gallone) misst die Spritsparsamkeit.\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{mpg}_{PS=1} &lt; \\text{mpg}_{PS=0},\\]\n‚ÄúDie mittlere Spritsparsamkeit von Autos mit viel PS ist kleiner als die von Autos mit viel PS‚Äù.\nDabei meint \\(PS=0\\) die Autos mit wenig PS (und \\(PS=1\\) die Autos mit viel PS).\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!\n\n\n\n\nWir definieren PS als eine bin√§re Variable, die angibt, ob ein Auto mehr oder weniger PS hat als der Median der PS-Werte:\n\nmtcars &lt;-\n  mtcars |&gt; \n  mutate(PS = case_when(\n    hp &gt; median(hp) ~ 1,\n    hp &lt;= median(hp) ~ 0\n  ))\n\n\n\n\n\nm &lt;- stan_glm(mpg ~ PS,  # Regressionsformel\n              data = mtcars,  # Datensatz\n              refresh = 0,  # Nicht so viel Detail-Ausgabe\n              seed = 42)  # Reproduzierbarkeit\n\nHier sind die Modellparameter:\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n24.219612\n0.95\n22.07170\n26.170915\n1\n1.0007744\n3505.490\nnormal\n20.09062\n15.06737\n\n\nPS\n-8.802191\n0.95\n-11.61645\n-5.804179\n1\n0.9995466\n3526.436\nnormal\n0.00000\n29.71825\n\n\n\n\n\n\nDer Effekt von PS ist negativ, was bedeutet, dass Autos der Gruppe PS=1 einen um ca. 9 Meilen geringeren MPG-Wert haben als Autos der Gruppe PS=0. Das bedeutet, dass Autos mit viel PS einen h√∂heren Spritverbrauch haben als Autos mit wenig PS.\n\n\n\nHier ist das HDI (95%) zum Effekt von PS:\n\nhdi(m) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgabe\n\nSprechen die Ergebnisse daf√ºr, dass Autos mit viel PS einen h√∂heren Spritverbrauch haben als Autos mit wenig PS? Begr√ºnden Sie.\nWie hoch ist die Wahrscheinlichkeit, dass die Hypothese wahr ist (laut unserem Modell)?\nWas ist Ihr Punktsch√§tzer f√ºr den Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS?\nMit einer Wahrscheinlichkeit von 95% liegt der Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS zwischen welchen Werten (laut unserem Modell)?\nGeben Sie die Skalenniveaus der Variablen in der Regressionsformel an."
  },
  {
    "objectID": "posts/wskt-schluckspecht2/index.html#setup",
    "href": "posts/wskt-schluckspecht2/index.html#setup",
    "title": "Wskt-Schluckspecht2",
    "section": "",
    "text": "library(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/wskt-schluckspecht2/index.html#modell-und-hypothese",
    "href": "posts/wskt-schluckspecht2/index.html#modell-und-hypothese",
    "title": "Wskt-Schluckspecht2",
    "section": "",
    "text": "Die Variable mpg (Miles per Gallone) misst die Spritsparsamkeit.\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{mpg}_{PS=1} &lt; \\text{mpg}_{PS=0},\\]\n‚ÄúDie mittlere Spritsparsamkeit von Autos mit viel PS ist kleiner als die von Autos mit viel PS‚Äù.\nDabei meint \\(PS=0\\) die Autos mit wenig PS (und \\(PS=1\\) die Autos mit viel PS).\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!"
  },
  {
    "objectID": "posts/wskt-schluckspecht2/index.html#vorverarbeitung",
    "href": "posts/wskt-schluckspecht2/index.html#vorverarbeitung",
    "title": "Wskt-Schluckspecht2",
    "section": "",
    "text": "Wir definieren PS als eine bin√§re Variable, die angibt, ob ein Auto mehr oder weniger PS hat als der Median der PS-Werte:\n\nmtcars &lt;-\n  mtcars |&gt; \n  mutate(PS = case_when(\n    hp &gt; median(hp) ~ 1,\n    hp &lt;= median(hp) ~ 0\n  ))"
  },
  {
    "objectID": "posts/wskt-schluckspecht2/index.html#modell-berechnen",
    "href": "posts/wskt-schluckspecht2/index.html#modell-berechnen",
    "title": "Wskt-Schluckspecht2",
    "section": "",
    "text": "m &lt;- stan_glm(mpg ~ PS,  # Regressionsformel\n              data = mtcars,  # Datensatz\n              refresh = 0,  # Nicht so viel Detail-Ausgabe\n              seed = 42)  # Reproduzierbarkeit\n\nHier sind die Modellparameter:\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n24.219612\n0.95\n22.07170\n26.170915\n1\n1.0007744\n3505.490\nnormal\n20.09062\n15.06737\n\n\nPS\n-8.802191\n0.95\n-11.61645\n-5.804179\n1\n0.9995466\n3526.436\nnormal\n0.00000\n29.71825\n\n\n\n\n\n\nDer Effekt von PS ist negativ, was bedeutet, dass Autos der Gruppe PS=1 einen um ca. 9 Meilen geringeren MPG-Wert haben als Autos der Gruppe PS=0. Das bedeutet, dass Autos mit viel PS einen h√∂heren Spritverbrauch haben als Autos mit wenig PS."
  },
  {
    "objectID": "posts/wskt-schluckspecht2/index.html#post-verteilung-auslesen",
    "href": "posts/wskt-schluckspecht2/index.html#post-verteilung-auslesen",
    "title": "Wskt-Schluckspecht2",
    "section": "",
    "text": "Hier ist das HDI (95%) zum Effekt von PS:\n\nhdi(m) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgabe\n\nSprechen die Ergebnisse daf√ºr, dass Autos mit viel PS einen h√∂heren Spritverbrauch haben als Autos mit wenig PS? Begr√ºnden Sie.\nWie hoch ist die Wahrscheinlichkeit, dass die Hypothese wahr ist (laut unserem Modell)?\nWas ist Ihr Punktsch√§tzer f√ºr den Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS?\nMit einer Wahrscheinlichkeit von 95% liegt der Unterschied im Spritverbrauch zwischen Autos mit viel und wenig PS zwischen welchen Werten (laut unserem Modell)?\nGeben Sie die Skalenniveaus der Variablen in der Regressionsformel an."
  },
  {
    "objectID": "posts/bayesbox2/index.html",
    "href": "posts/bayesbox2/index.html",
    "title": "bayesbox2",
    "section": "",
    "text": "1 Setup\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\n\n2 Aufgabe\nSie f√ºhren ein zweiwertiges (binomiales) Zufallsexperiment \\(n\\)-mal durch, dabei erzielen Sie \\(k\\) Treffer. Die Wiederholungen sind unabh√§ngig voneinander, und die Trefferwahrscheinlichkeit \\(\\pi\\) bleibt konstant.\n(Eine M√ºnze wiederholt werfen w√§re das typische Beispiel f√ºr ein solches Zufallexperiment.)\nGehen Sie von folgenden Parameterwerten aus:\n\nn &lt;- 10\nk &lt;- 10\n\nWelcher Parameterwert \\(\\pi\\) ist am wahrscheinlichsten, wenn Sie keine weiteren Informationen haben?\nSie √ºberpr√ºfen alle 11 Parameterwerte f√ºr \\(\\pi\\) von 0 bis 1 (in Schritten von 0.1.)\nUm diese Frage zu beantworten, berechnen Sie die Wahrscheinlichkeiten f√ºr alle m√∂glichen Parameterwerte \\(\\pi\\) von 0 bis 1 in Schritten von 0.1 anhand einer Bayesbox. Dabei gehen wir von einer Binomialverteilung aus:\n\\(k \\sim Bin(n, \\pi)\\).\n\n\n\n\nListing¬†1: Parameterwerte (Gitter) f√ºr Trefferwahrscheinlichkeit: 0, 0.1, 0.2, ‚Ä¶, 1\n\n\npis &lt;- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte\npis\n\n\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten gegeben jeweils eines Parameterwerts:\n\nLikelihood &lt;- dbinom(k, size = n, prob = pis)\nLikelihood\n\n [1] 0.0000000000 0.0000000001 0.0000001024 0.0000059049 0.0001048576\n [6] 0.0009765625 0.0060466176 0.0282475249 0.1073741824 0.3486784401\n[11] 1.0000000000\n\n\nAuf dieser Basis erstellen wir eine Bayes-Box, um die Posteriori-Wahrscheinlichkeiten f√ºr alle Parameterwerte zu berechnen, s. Listing¬†2.\n\n\n\n\nListing¬†2: Wir basteln uns eine Bayes-Box\n\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (die Parameterwerte, p): \n    p = pis,\n    # Lege den Priori-Wert fest:\n    Priori  = 1/11) |&gt; \n    mutate(\n      # berechne Likelihood f√ºr jeden Wasseranteil (Parameterwert):\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\n\n\n\nDie Bayes-Box (Table¬†1) zeigt, wie sich die Post-Verteilung berechnet.\nLeider sind die zentralen Spalten ausgeblendet. ü§¨\n\n\n\n\nTable¬†1: Die Bayes-Box\n\n\n\n\n\n\nid\np\nPriori\n\n\n\n\n1\n0.0\n0.01\n\n\n2\n0.1\n0.01\n\n\n3\n0.2\n0.01\n\n\n4\n0.3\n0.01\n\n\n5\n0.4\n0.01\n\n\n6\n0.5\n0.01\n\n\n7\n0.6\n0.01\n\n\n8\n0.7\n0.01\n\n\n9\n0.8\n0.01\n\n\n10\n0.9\n0.01\n\n\n11\n1.0\n0.01\n\n\n\n\n\n\n\n\nAufgabe: Welcher Parameterwert \\(\\pi\\) ist am wahrscheinlichsten laut der Bayesbox?\n  \n  \n  \n  \n\n\n3 L√∂sung\nDer wahrscheinlichste Parameterwert \\(\\pi\\) ist derjenige, der die h√∂chste Posteriori-Wahrscheinlichkeit hat.\nBei \\(k=n\\) Treffer hat \\(p=1\\) die h√∂chste Posteriori-Wahrscheinlichkeit.\n\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n\n1\n0.0\n0.01\n0.00\n0.00\n0.01\n0.00\n\n\n2\n0.1\n0.01\n0.00\n0.00\n0.01\n0.00\n\n\n3\n0.2\n0.01\n0.00\n0.00\n0.01\n0.00\n\n\n4\n0.3\n0.01\n0.00\n0.00\n0.01\n0.00\n\n\n5\n0.4\n0.01\n0.00\n0.00\n0.01\n0.00\n\n\n6\n0.5\n0.01\n0.00\n0.00\n0.01\n0.00\n\n\n7\n0.6\n0.01\n0.01\n0.00\n0.01\n0.00\n\n\n8\n0.7\n0.01\n0.03\n0.00\n0.01\n0.02\n\n\n9\n0.8\n0.01\n0.11\n0.00\n0.01\n0.07\n\n\n10\n0.9\n0.01\n0.35\n0.00\n0.01\n0.23\n\n\n11\n1.0\n0.01\n1.00\n0.01\n0.01\n0.67\n\n\n\n\n\nHier ist eine Visualisierung der Posteriori-Wahrscheinlichkeiten:\n\nggline(d, x = \"p\", y = \"Post\", \n       xlab = \"Trefferwahrscheinlichkeit\", ylab = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Posteriori-Wahrscheinlichkeiten f√ºr Trefferwahrscheinlichkeit\",\n       add = c(\"point\", \"smooth\"))"
  },
  {
    "objectID": "posts/boxplots-de1a/boxplots-de1a.html",
    "href": "posts/boxplots-de1a/boxplots-de1a.html",
    "title": "boxplots-de1a",
    "section": "",
    "text": "laut zwei Stichproben (A und B) mithilfe zweier Boxplots dargestellt. Welche der folgenden Aussagen ist korrekt?\nHinweis: Die Aussagen sind entweder eindeutig richtig oder eindeutig falsch.\n\n\n\n\n\n\n\n\n\n\n\n\nDie zentrale Tendenz der Verteilungen ist (etwa) identisch.\nBeide Verteilungen haben keine Ausrei√üer.\nDie Streuung in Stichprobe A ist deutlich gr√∂√üer als in Stichprobe B.\nDie Schiefe der beiden Stichproben ist √§hnlich.\nVerteilung A ist linksschief."
  },
  {
    "objectID": "posts/boxplots-de1a/boxplots-de1a.html#answerlist",
    "href": "posts/boxplots-de1a/boxplots-de1a.html#answerlist",
    "title": "boxplots-de1a",
    "section": "",
    "text": "Die zentrale Tendenz der Verteilungen ist (etwa) identisch.\nBeide Verteilungen haben keine Ausrei√üer.\nDie Streuung in Stichprobe A ist deutlich gr√∂√üer als in Stichprobe B.\nDie Schiefe der beiden Stichproben ist √§hnlich.\nVerteilung A ist linksschief."
  },
  {
    "objectID": "posts/boxplots-de1a/boxplots-de1a.html#answerlist-1",
    "href": "posts/boxplots-de1a/boxplots-de1a.html#answerlist-1",
    "title": "boxplots-de1a",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Verteilung B hat im Durchschnitt h√∂here Werte als Verteilung A.\nWahr. Beide Verteilungen haben keine Beobachtungen, die mehr als das 1.5-fache der Interquartilsabstands von der Box entfernt sind\nFalsch. Der Interquartilsabstand in Stichprobe A ist nicht deutlich gr√∂√üer als in B.\nFalsch. Die Schiefe der beiden Verteilungen ist unterschiedlich. Stichprobe A ist rechtsschief. Stichprobe B ist etwa symmetrisch.\nFalsch. Verteilung A ist rechtsschief.\n\n\nCategories:\n\nvis\neda\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html",
    "href": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html",
    "title": "Verteilungen-Quiz-10",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X = \\bar{x}) = 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist",
    "href": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist",
    "title": "Verteilungen-Quiz-10",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist-1",
    "title": "Verteilungen-Quiz-10",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/mtcars-post2/mtcars-post2.html",
    "href": "posts/mtcars-post2/mtcars-post2.html",
    "title": "mtcars-post2",
    "section": "",
    "text": "Im Datensatz mtcars: Wie gro√ü ist der Effekt der UV vs auf die AV mpg? Geben Sie die Breite des 95% PI an (im Bezug zur gesuchten Gr√∂√üe). Berechnen Sie das dazu passende Modell mit Methoden der Bayes-Statistik.\nHinweise\nW√§hlen Sie die am besten passende Option:\n\n\n\n0.7\n2.7\n4.7\n6.7\n8.7"
  },
  {
    "objectID": "posts/mtcars-post2/mtcars-post2.html#answerlist",
    "href": "posts/mtcars-post2/mtcars-post2.html#answerlist",
    "title": "mtcars-post2",
    "section": "",
    "text": "0.7\n2.7\n4.7\n6.7\n8.7"
  },
  {
    "objectID": "posts/mtcars-post2/mtcars-post2.html#answerlist-1",
    "href": "posts/mtcars-post2/mtcars-post2.html#answerlist-1",
    "title": "mtcars-post2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\nbayes\nregression\npost\nexam-22"
  },
  {
    "objectID": "posts/filter01/filter01.html",
    "href": "posts/filter01/filter01.html",
    "title": "filter01",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nFiltern Sie alle Spiele, die mehr als 50 Euro kosten (total_pr) erzielt haben und die Versandkosten erheben (ship_pr)!\nGeben Sie die Antwort der Zeilen zur√ºck, die nach dem Filtern im Datensatz verbleiben!\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nFiltern:\n\nmariokart2 &lt;- filter(mariokart, total_pr &gt; 50.00 & ship_pr &gt; 0)  # R bentzt Dezimalpunkt\n\nDie L√∂sung lautet: 32 Zeilen verbleiben im Datensatz nach dem Filtern.\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/targets-multiple-data-files/targets-multiple-data-files.html",
    "href": "posts/targets-multiple-data-files/targets-multiple-data-files.html",
    "title": "targets-multiple-data-files",
    "section": "",
    "text": "Aufgabe\nSchreiben Sie eine targets Pipeline, die einen Ordner mit Datendateien beobachtet und sich aktualisiert, wenn neue Daten dazukommt. Die Pipeline soll die Datendateien importieren und zu einer Tabelle zusammenf√ºgen und schlie√ülich die Zeilen z√§hlen.\n         \n\n\nL√∂sung\nDie folgende L√∂sung ist stark inspiriert von diesem SO-Post.\nWir scheiben eine _targets.R Datei mit folgendem Inhalt.\nZuerst das Setup:\n\nlibrary(targets)\nlibrary(tidyverse)\nlibrary(tarchetypes)  # f√ºr tar_files()\n\nDann definieren wir Konstanten; hier den Pfad:\n\npath &lt;- list()\npath$data &lt;- \"data/\"\n\nAus Gr√ºnden der Ordnungsfreude haben wir eine Liste erstellt, in der dann alle m√∂glichen Pfade abgelegt werden k√∂nnen.\nSchlie√ülich definieren wir die Pipeline. Hier spielt die Musik:\n\nlist(\n  tar_files(data_paths, path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\")),  # Liste der Daten-Dateien\n  tar_target(data_proc, data_paths %&gt;% read_csv(),  # Einlesen\n             pattern = map(data_paths)),  # √úber alle Elemente von data_paths iterieren, also √ºber alle Datendateien\n  tar_target(n_row, nrow(data_proc))  # Zeilen z√§hlen\n)\n\n[[1]]\n[[1]]$data_paths_files\n&lt;tar_stem&gt; \n  name: data_paths_files \n  description:  \n  command:\n    path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\") \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: worker \n  retrieval mode: auto \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: always \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[1]]$data_paths\n&lt;tar_pattern&gt; \n  name: data_paths \n  description:  \n  command:\n    data_paths_files \n  pattern:\n    map(data_paths_files) \n  format: file \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: main \n  retrieval mode: main \n  deployment mode: main \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: thorough \n  packages:\n    character(0) \n  library:\n    NULL\n\n[[2]]\n&lt;tar_pattern&gt; \n  name: data_proc \n  description:  \n  command:\n    data_paths %&gt;% read_csv() \n  pattern:\n    map(data_paths) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: worker \n  retrieval mode: auto \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: thorough \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[3]]\n&lt;tar_stem&gt; \n  name: n_row \n  description:  \n  command:\n    nrow(data_proc) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: worker \n  retrieval mode: auto \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: thorough \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n\n\nMit pattern = map(data_paths) iterieren wir nicht nur √ºber alle Elemente von data_path, sondern f√ºgen die Elemente auch zu einer Tabelle zusammen.\nHier ist die ganze Syntax noch einmal:\n\n# _targets.R file\n\nlibrary(targets)\nlibrary(tidyverse)\nlibrary(tarchetypes)\n\n\npath &lt;- list()\npath$data &lt;- \"data/\"\n\n\nlist(\n  tar_files(data_paths, path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\")),\n  tar_target(data_proc, data_paths %&gt;% read_csv(),\n             pattern = map(data_paths)),\n  tar_target(n_row, nrow(data_proc))\n)\n\n[[1]]\n[[1]]$data_paths_files\n&lt;tar_stem&gt; \n  name: data_paths_files \n  description:  \n  command:\n    path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\") \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: worker \n  retrieval mode: auto \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: always \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[1]]$data_paths\n&lt;tar_pattern&gt; \n  name: data_paths \n  description:  \n  command:\n    data_paths_files \n  pattern:\n    map(data_paths_files) \n  format: file \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: main \n  retrieval mode: main \n  deployment mode: main \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: thorough \n  packages:\n    character(0) \n  library:\n    NULL\n\n[[2]]\n&lt;tar_pattern&gt; \n  name: data_proc \n  description:  \n  command:\n    data_paths %&gt;% read_csv() \n  pattern:\n    map(data_paths) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: worker \n  retrieval mode: auto \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: thorough \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[3]]\n&lt;tar_stem&gt; \n  name: n_row \n  description:  \n  command:\n    nrow(data_proc) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: auto \n  storage mode: worker \n  retrieval mode: auto \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    seed: TRUE\n    file: TRUE\n    iteration: TRUE\n    repository: TRUE\n    format: TRUE\n    depend: TRUE\n    command: TRUE\n    mode: thorough \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n\n\n\nCategories:\n\nprojectmgt\ntargets\nrepro\nstring"
  },
  {
    "objectID": "posts/muenze-weird/index.html",
    "href": "posts/muenze-weird/index.html",
    "title": "muenze-weird",
    "section": "",
    "text": "1 Aufgabe\nEine M√ºnze wird n=5 Mal geworfen; dabei wird x=0 mal ‚ÄúZahl‚Äù geworfen. Wie hoch ist die Wahrscheinlichkeit, dass die M√ºnze fair ist?\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nDie Frage l√§sst sich ohne Vorannahme zur Trefferwahrscheinlichkeit der M√ºnze nicht beantworten."
  },
  {
    "objectID": "posts/breiman/breiman.html",
    "href": "posts/breiman/breiman.html",
    "title": "breiman",
    "section": "",
    "text": "In einem ber√ºhmten Paper mit dem Titel ‚ÄúStatistical Modeling: The Two Culture‚Äù hat Leo Breiman zwei Arten der Datenanalyse vorgestellt und kritisch diskutiert. Dieser Artikel wurde vielfach diskutiert, weil er zentrale Fragen des Fachgebiets anstie√ü bzw. intensivierte. Welche der folgenden Kontroversen zeichnen das Feld der Datenanalyse nicht?\nWelche Aussagen sind in diesem Zusammenhang falsch?\n\n\n\nZentrale Fragestellungen der Datenanalyse kann man mit den Zielen Vorhersage und Erkl√§rung (des Kausalmodells) kontrastierend vorstellen.\nMan kann zwei ‚ÄúLager‚Äù oder Fraktionen innerhalb der Datenanalyse ausmachen: Die mehr an Mathematik orientierten Statistiker und die mehr an Informatik orientierten Datenwissenschaftler.\nStatistische Modelle (bzw. die Modelle der Statistiker) basieren auf der Wahrscheinlichkeitsrechnung.\nDie Modelle der Datenwissenschaftler bezeichnet man auch als algorithmische Modelle.\nDie Modelle der Datenwissenschaftler sind zumeist ‚ÄúBlack-Box-Modelle‚Äù.\nEin Beispiel f√ºr ein Black-Box-Modell ist die klassische Regression (Methode der kleinsten Quadrate)."
  },
  {
    "objectID": "posts/breiman/breiman.html#answerlist",
    "href": "posts/breiman/breiman.html#answerlist",
    "title": "breiman",
    "section": "",
    "text": "Zentrale Fragestellungen der Datenanalyse kann man mit den Zielen Vorhersage und Erkl√§rung (des Kausalmodells) kontrastierend vorstellen.\nMan kann zwei ‚ÄúLager‚Äù oder Fraktionen innerhalb der Datenanalyse ausmachen: Die mehr an Mathematik orientierten Statistiker und die mehr an Informatik orientierten Datenwissenschaftler.\nStatistische Modelle (bzw. die Modelle der Statistiker) basieren auf der Wahrscheinlichkeitsrechnung.\nDie Modelle der Datenwissenschaftler bezeichnet man auch als algorithmische Modelle.\nDie Modelle der Datenwissenschaftler sind zumeist ‚ÄúBlack-Box-Modelle‚Äù.\nEin Beispiel f√ºr ein Black-Box-Modell ist die klassische Regression (Methode der kleinsten Quadrate)."
  },
  {
    "objectID": "posts/Typ-Fehler-R-06a/Typ-Fehler-R-06a.html",
    "href": "posts/Typ-Fehler-R-06a/Typ-Fehler-R-06a.html",
    "title": "Typ-Fehler-R-06a",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgende R-Syntax, f√ºr die R eine Fehlermeldung ausgibt:\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x) - x))\n\n[1] 2\n\n\nGeben Sie die korrekte Syntax an! √Ñndern Sie nur die notwendigen Zeichen an der Syntax oben. Gehen Sie davon aus, dass die aufgerufenen Funktionen existieren.\nGeben Sie keine Leerzeichen ein.\n         \n\n\nL√∂sung\nHinten ist eine (schlie√üende) Klammer zu viel, die muss weg:\n\nsum(abs(mean(x)-x))  # so geht's\n\n[1] 2\n\n\n\nsol &lt;- \"sum(abs(mean(x)-x))\"\n\nDie Antwort lautet: sum(abs(mean(x)-x)).\n\nCategories:\n\nR\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/mtcars-abhaengig_var2/mtcars-abhaengig_var2.html",
    "href": "posts/mtcars-abhaengig_var2/mtcars-abhaengig_var2.html",
    "title": "mtcars-abhaengig_var2",
    "section": "",
    "text": "Aufgabe\nIm Folgenden ist der Datensatz mtcars zu analysieren.\nDer Datensatz ist z.B. als CSV-Datei von dieser Webseite abrufbar.\nHilfe zum Datensatz ist via help(\"name_des_datensatzes\") oder auf dieser Webseite abrufbar.\nOb die Variable hp (UV; Ereignis \\(A\\)) und Spritverbrauch (mpg; AV; Ereignis \\(B\\)) wohl voneinander abh√§ngig sind? Was meinen Sie? Was ist Ihre Einsch√§tzung dazu? Vermutlich haben Sie ein (wenn vielleicht auch implizites) Vorab-Wissen zu dieser Frage. Lassen wir dieses Vorab-Wissen aber einmal au√üen vor und schauen uns rein Daten dazu an. Vereinfachen wir die Frage etwas, indem wir beide Variablen am Mittelwert aufteilen: Wenn eine Beobachtung (d.h. ein Auto) einen Wert in der jeweiligen Variablen h√∂chstens so gro√ü wie der Mittelwert der Variable aufweist, geben wir der Beobachtung der Wert 0, ansonsten den Wert 1. Wir nehmen die Anteile der gesuchten Gr√∂√üen als Sch√§tzwert f√ºr deren Wahrscheinlichkeit.\nDie resultierenden bin√§ren Variablen nennen wir av_high bzw. uv_high (im sch√∂nsten Denglisch).\nBerechnen Sie: \\(Pr(\\neg \\text{uvhigh} \\, | \\,  \\text{avhigh})\\)\nHinweise:\n\nDas ‚ÄúEllbogen-Zeichen‚Äù \\(\\neg\\) kennzeichnet eine logische Negierung (das Gegenteil).\nDie angegebene Wahrscheinlichkeit ist eine bedingte Wahrscheinlichkeit.\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nSchauen wir zuerst mal in den Datensatz:\n\nmtcars %&gt;% \n  select(mpg, hp) %&gt;% \n  slice_head(n = 5)\n\n                   mpg  hp\nMazda RX4         21.0 110\nMazda RX4 Wag     21.0 110\nDatsun 710        22.8  93\nHornet 4 Drive    21.4 110\nHornet Sportabout 18.7 175\n\n\nDann berechnen wir die bin√§ren Variablen.\nZuerst av_high:\n\n# split by mean:\nd2 &lt;-\n  mtcars %&gt;% \n  select(mpg, hp) %&gt;% \n  mutate(av_high = case_when(\n    mpg &lt;= mean(mpg) ~ 0,\n    mpg &gt; mean(mpg) ~ 1\n  )) %&gt;% \n  select(-mpg) \n\nglimpse(d2)\n\nRows: 32\nColumns: 2\n$ hp      &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, ‚Ä¶\n$ av_high &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,‚Ä¶\n\n\nav_high = 1 zeigt hohe Werte in mpg an, und av_high = 0 zeigt geringe Werte (im Verh√§ltnis zum Mittelwert).\nAchtung! Wenn es fehlende Werte im Datensatz g√§be, m√ºssten wir diese in geeigneter Manier vorab entfernen. Also z.B.:\n\n# split by mean:\nd2 &lt;-\n  mtcars %&gt;% \n  select(mpg, hp) %&gt;% \n  drop_na() |&gt; \n  mutate(av_high = case_when(\n    mpg &lt;= mean(mpg) ~ 0,\n    mpg &gt; mean(mpg) ~ 1\n  )) %&gt;% \n  select(-mpg) \n\nglimpse(d2)\n\nRows: 32\nColumns: 2\n$ hp      &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, ‚Ä¶\n$ av_high &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,‚Ä¶\n\n\nOder so:\n\n# split by mean:\nd2 &lt;-\n  mtcars %&gt;% \n  select(mpg, hp) %&gt;% \n  mutate(av_high = case_when(\n    mpg &lt;= mean(mpg, na.rm = TRUE) ~ 0,\n    mpg &gt; mean(mpg, na.rm = TRUE) ~ 1\n  )) %&gt;% \n  select(-mpg) \n\nglimpse(d2)\n\nRows: 32\nColumns: 2\n$ hp      &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, ‚Ä¶\n$ av_high &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,‚Ä¶\n\n\nMan beachte, dass hohe Werte in MPG einen geringen Spritverbrauch bedeuten (also eine hohe Sparsamkeit im Verbrauch).\nDann berechnen wir uv_high:\n\nd3 &lt;-\n  d2 %&gt;% \n  select(av_high, hp) %&gt;% \n  mutate(uv_high = case_when(\n    hp &lt;= mean(hp) ~ 0,\n    hp &gt; mean(hp) ~ 1\n  )) %&gt;% \n  select(-hp) \n\nglimpse(d3)\n\nRows: 32\nColumns: 2\n$ av_high &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,‚Ä¶\n$ uv_high &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,‚Ä¶\n\n\nAuch hier gilt, dass die Funktionen der deskriptiven Statistik alle Beine von sich strecken und den Dienst ‚Äúverweigern‚Äù, wenn es fehlende Werte im Vektor geben sollte. Sie meinen es nat√ºrlich nur gut mit Ihnen. ü§∑‚Äç‚ôÇÔ∏è\nDann z√§hlen wir die gesuchten Wahrscheinlichkeiten bzw. Anteile der AV: ::: {.cell hash=‚Äòmtcars-abhaengig_var2_cache/html/unnamed-chunk-3_58dd122513f901834fa26a5f30219555‚Äô}\nd3 %&gt;% \n  count(av_high)\n\n  av_high  n\n1       0 18\n2       1 14\n\n:::\nEs gibt also 14 Autos, die den oben gesuchten ‚Äúhinteren Teil‚Äù der Bedingung erf√ºllen (av_high = 1).\nFiltern wir als n√§chstes nur in diesen 14 Autos nach dem ‚Äúvorderen Teil‚Äù der gesuchten Wahrscheinlichkeit, also uv_high = 0.\n\nd3 %&gt;% \n  filter(av_high == 1) %&gt;% \n  count(uv_high) %&gt;% \n  mutate(prop = n/sum(n))\n\n  uv_high  n prop\n1       0 14    1\n\n\nEs gibt also 14 von 14 Autos, die diese Bedingung, uv_high = 0 erf√ºllen. Das sind 100%.\nIn Worten: Von den Autos mit hoher Sparsamkeit haben alle eine geringe PS-Zahl. Das macht intuitiv Sinn.\nDer gesuchte Wert betr√§gt also 1.\n\nCategories:\n\ndyn\nprobability"
  },
  {
    "objectID": "posts/movies-vis2/movies-vis2.html",
    "href": "posts/movies-vis2/movies-vis2.html",
    "title": "movies-vis2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie bitte f√ºr diese Aufgabe den Datensatz movies (aus dem R-Paket ggplot2movies). Ein Data-Dictionary findet sich hier.\nErstellen Sie folgende Visualisierung:\n\nGruppenvergleich des Budgets pro Jahr\nBer√ºcksichtigen Sie nur Actionfilme ab 2000\nVerzichten Sie auf Filme mit einer unterdurchschnittlichen Zahl an Bewertungen (votes; gemessen an allen Filmen, gerundet zur n√§chsten ganzen Zahl)\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(DataExplorer)\n\nDaten importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\"\nd &lt;- read.csv(d_path)\n\nDurchschnittliche Zahl an Bewertungen:\n\nd %&gt;% \n  summarise(votes_mean = mean(votes))\n\n\n\n\n\nvotes_mean\n\n\n\n\n632.1304\n\n\n\n\n\n\nDie durchschnittliche Zahl an Bewertungen betr√§gt also 632.\n\nd %&gt;% \n  select(budget, rating, year, votes, Action) %&gt;% \n  filter(year &gt;= 2000) %&gt;% \n  filter(Action == 1) %&gt;% \n  filter(votes &gt;= 632) %&gt;% \n  select(-Action) %&gt;% \n  mutate(year = factor(year)) %&gt;% \n  select(budget, year) %&gt;% \n  plot_boxplot(by = \"year\")\n\n\n\n\n\n\n\n\nHinweis: Die Zahl ‚Äú5.0e+07‚Äù ist eine Zahl in der Exponenzial-Schreibweise, n√§mlich \\(5\\cdot10^7\\), also \\(5 \\cdot 1000000\\).\n\nCategories:\n\nvis\neda\nstring"
  },
  {
    "objectID": "posts/qm2-quiz-wskt/index.html",
    "href": "posts/qm2-quiz-wskt/index.html",
    "title": "qm2-quiz-wskt",
    "section": "",
    "text": "1 Aufgabe\nGeben Sie jeweils an, ob die Aussage richtig oder falsch ist.\n\nBei einem Zufallsexperiment ist der Ereignisraum unbekannt.\nMeim W√ºrfelwurf ist \\(\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{‚öÄ, ‚öÅ, ‚öÇ, ‚öÉ, ‚öÑ, ‚öÖ\\}\\) ein sinnvoller Ereignisraum.\nJede einelementige Teilmenge von \\(\\Omega\\) hei√üt Elementarereignis.\nDas leere Ereignis \\(\\emptyset\\) ist ein unm√∂gliches Ereignis.\nJede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) hei√üt Elementarereignis.\nWird der Grundraum \\(\\Omega\\) vollst√§ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollst√§ndiges Ereignissystem.\nDie formallogische Konzeption von Wahrscheinlichkeit sieht Wahrscheinlichkeit als Erweiterung der formalen Logik. In der formallogischen Konzeption wird der Platz zwischen ‚Äúfalsch‚Äù (0) und ‚Äúrichtig‚Äù (1) durch die Wahrscheinlichkeit \\(0&lt;p&lt;1\\) gef√ºllt.\nDas Prinzip des unzureichenden Grundes) besagt, dass in Abwesenheit jeglicher Informationen, die bestimmte Ereignisse bevorzugen oder benachteiligen w√ºrden, alle m√∂glichen Elementarereignisse als unterschiedlich wahrscheinlich angesehen werden sollten.\nDie Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein und nicht gr√∂√üer als 1.\nMan schreibt \\(C = A \\cup B\\) und liest: ‚ÄúC ist A geschnitten mit B‚Äù.\nBeim W√ºrfelwurf ist das Komplement√§rereignis zu ‚Äú1‚Äù das Ereignis ‚Äú6‚Äù.\nDas Ereignis ‚Äú1‚Äù und das Ereignis ‚Äú6‚Äù sind disjunkt (beim W√ºrfelwurf).\nDie Ereignisse ‚ÄúZahl zwischen 1 und 3‚Äù und das Ereignis ‚Äúgerade Zahl‚Äù sind disjunkt (beim W√ºrfelwurf).\nDer allgemeine Additionssatz f√ºr Wahrscheinlichkeiten lautet: \\(P(A \\cup B) = P(A) + P(B)\\).\nDie auf B bedingte Wahrscheinlichkeit von A ist definiert als \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\).\nZwei Ereignisse sind (stochastisch) unabh√§ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abh√§ngt, ob \\(B\\) der Fall ist.\nDer allgemeine Multiplikationssatz f√ºr Wahrscheinlichkeiten lautet: \\(P(A \\cap B) = P(A) \\cdot Pr(B)\\).\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nBei einem Zufallsexperiment ist der Ereignisraum unbekannt. F\nMeim W√ºrfelwurf ist \\(\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{‚öÄ, ‚öÅ, ‚öÇ, ‚öÉ, ‚öÑ, ‚öÖ\\}\\) ein sinnvoller Ereignisraum. R\nJede einelementige Teilmenge von \\(\\Omega\\) hei√üt Elementarereignis. R\nDas leere Ereignis \\(\\emptyset\\) ist ein unm√∂gliches Ereignis. R\nJede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) hei√üt Elementarereignis. R\nWird der Grundraum \\(\\Omega\\) vollst√§ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollst√§ndiges Ereignissystem. R\nDie formallogische Konzeption von Wahrscheinlichkeit sieht Wahrscheinlichkeit als Erweiterung der formalen Logik.In der formallogischen Konzeption wird der Platz zwischen ‚Äúfalsch‚Äù (0) und ‚Äúrichtig‚Äù (1) durch die Wahrscheinlichkeit \\(0&lt;p&lt;1\\) gef√ºllt. R\nDas Prinzip des unzureichenden Grundes) besagt, dass in Abwesenheit jeglicher Informationen, die bestimmte Elementarereignisse bevorzugen oder benachteiligen w√ºrden, alle m√∂glichen ElemnteraEreignisse als unterschiedlich wahrscheinlich angesehen werden sollten. F\nDie Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein und nicht gr√∂√üer als 1. R\nMan schreibt \\(C = A \\cup B\\) und liest: ‚ÄúC ist A geschnitten mit B‚Äù. F\nBeim W√ºrfelwurf ist das Komplement√§rereignis zu ‚Äú1‚Äù das Ereignis ‚Äú6‚Äù. F\nDas Ereignis ‚Äú1‚Äù und das Ereignis ‚Äú6‚Äù sind disjunkt (beim W√ºrfelwurf). R\nDie Ereignisse ‚ÄúZahl zwischen 1 und 3‚Äù und das Ereignis ‚Äúgerade Zahl‚Äù sind disjunkt (beim W√ºrfelwurf). F\nDer allgemeine Additionssatz f√ºr Wahrscheinlichkeiten lautet: \\(P(A \\cup B) = P(A) + P(B)\\). F\nDie auf B bedingte Wahrscheinlichkeit von A ist definiert als \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\). R\nZwei Ereignisse sind (stochastisch) unabh√§ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abh√§ngt, ob \\(B\\) der Fall ist. R\nDer allgemeine Multiplikationssatz f√ºr Wahrscheinlichkeiten lautet: \\(P(A \\cap B) = P(A) \\cdot Pr(B)\\). F"
  },
  {
    "objectID": "posts/lm-mario3/lm-mario3.html",
    "href": "posts/lm-mario3/lm-mario3.html",
    "title": "lm-mario3",
    "section": "",
    "text": "Sagen Sie den Verkaufspreis vorher f√ºr Spiele mit 1, 2, bzw. 3 Euro Versandkosten (ship_pr)!\nGeben Sie den Durchschnitt der Vorhersagen als L√∂sung an!"
  },
  {
    "objectID": "posts/lm-mario3/lm-mario3.html#setup",
    "href": "posts/lm-mario3/lm-mario3.html#setup",
    "title": "lm-mario3",
    "section": "Setup",
    "text": "Setup\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nlibrary(tidyverse)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/lm-mario3/lm-mario3.html#regressionsgerade-berechnen",
    "href": "posts/lm-mario3/lm-mario3.html#regressionsgerade-berechnen",
    "title": "lm-mario3",
    "section": "Regressionsgerade berechnen",
    "text": "Regressionsgerade berechnen\n\nlm_mariokart &lt;- lm(total_pr ~ ship_pr, data = mariokart) # \"lm\" wie *l*lineares *M*odell, also eine Gerade.\nlm_mariokart\n\n\nCall:\nlm(formula = total_pr ~ ship_pr, data = mariokart)\n\nCoefficients:\n(Intercept)      ship_pr  \n     36.246        4.337"
  },
  {
    "objectID": "posts/lm-mario3/lm-mario3.html#vorhersagen",
    "href": "posts/lm-mario3/lm-mario3.html#vorhersagen",
    "title": "lm-mario3",
    "section": "Vorhersagen",
    "text": "Vorhersagen\nVorhersagen funktionieren mit dem Befehl predict.\n\nneue_spiele &lt;- tibble(ship_pr = c(1,2,3))\nneue_spiele\n\n\n\n\n\nship_pr\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\n\n\n\nAnstelle von tibble k√∂nnen Sie auch data.frame verwenden. Mit c erstellt man einen ‚ÄúVektor‚Äù, also eine ‚ÄúListe‚Äù zusammengeh√∂riger Werte.\n\nvorhersagen &lt;- predict(lm_mariokart, neue_spiele)  # predicte mir den Verkaufspreis\n\nvorhersagen\n\n       1        2        3 \n40.58276 44.91998 49.25720 \n\n\n\nloesung &lt;- mean(vorhersagen)\nloesung\n\n[1] 44.91998\n\n\nDie L√∂sung lautet: 44.9199833.\n\nCategories:\n\nR\nlm\npredict\nnum"
  },
  {
    "objectID": "posts/mtcars-post3/mtcars-post3.html",
    "href": "posts/mtcars-post3/mtcars-post3.html",
    "title": "mtcars-post3",
    "section": "",
    "text": "Im Datensatz mtcars: Wie gro√ü ist die Wahrscheinlichkeit, dass der Effekt der UV vs auf die AV mpg positiv ist? Berechnen Sie das dazu passende Modell mit Methoden der Bayes-Statistik.\nHinweise\nW√§hlen Sie die am besten passende Option:\n\n\n\n.42\n.73\n.23\n1\n0"
  },
  {
    "objectID": "posts/mtcars-post3/mtcars-post3.html#answerlist",
    "href": "posts/mtcars-post3/mtcars-post3.html#answerlist",
    "title": "mtcars-post3",
    "section": "",
    "text": ".42\n.73\n.23\n1\n0"
  },
  {
    "objectID": "posts/mtcars-post3/mtcars-post3.html#answerlist-1",
    "href": "posts/mtcars-post3/mtcars-post3.html#answerlist-1",
    "title": "mtcars-post3",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\nbayes\nregression\npost\nexam-22"
  },
  {
    "objectID": "posts/wskt-quiz03/wskt-quiz03.html",
    "href": "posts/wskt-quiz03/wskt-quiz03.html",
    "title": "wskt-quiz03",
    "section": "",
    "text": "Wirft man eine faire M√ºnze 10-fach, so gilt \\(Pr(\\text{10 mal Kopf}) = Pr(\\text{10 mal Zahl}) &gt; .01\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz03/wskt-quiz03.html#answerlist",
    "href": "posts/wskt-quiz03/wskt-quiz03.html#answerlist",
    "title": "wskt-quiz03",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz03/wskt-quiz03.html#answerlist-1",
    "href": "posts/wskt-quiz03/wskt-quiz03.html#answerlist-1",
    "title": "wskt-quiz03",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html",
    "href": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html",
    "title": "Verteilungen-Quiz-16",
    "section": "",
    "text": "F√ºr die mittlere K√∂rpergr√∂√üe des deutschen Mannes \\(X\\) gelte \\(X \\sim N(180,06)\\) (in Zentimetern).\nQuelle Mittelwert Quelle SD gesch√§tzt\n√Ñhnliche Daten finden sich bei Our World in Data.\nAufgabe: Ist folgende Aussage wahr?\nDas 50%-Quantil von \\(X\\) betr√§gt 180.\n\n  Ja    Nein \n\n\nAntworten"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html#answerlist",
    "href": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html#answerlist",
    "title": "Verteilungen-Quiz-16",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/nasa01/nasa01.html",
    "href": "posts/nasa01/nasa01.html",
    "title": "nasa01",
    "section": "",
    "text": "Viele Quellen berichten Klimadaten unserer Erde, z.B. auch National Aeronautics and Space Administration - Goddard Institute for Space Studies.\nVon dieser Quelle beziehen wir diesen Datensatz.\nDie Datensatz sind auf der Webseite wie folgt beschrieben:\nTables of Global and Hemispheric Monthly Means and Zonal Annual Means\nCombined Land-Surface Air and Sea-Surface Water Temperature Anomalies (Land-Ocean Temperature Index, L-OTI)\nThe following are plain-text files in tabular format of temperature anomalies, i.e.¬†deviations from the corresponding 1951-1980 means.\n\nGlobal-mean monthly, seasonal, and annual means, 1880-present, updated through most recent month: TXT, CSV\n\nStarten Sie zun√§chst das R-Paket tidyverse falls noch nicht geschehen.\n\nlibrary(tidyverse)\n\nImportieren Sie dann die Daten:\n\ndata_path &lt;- \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\nd &lt;- read.csv(data_path, skip = 1)\n\nWir lassen die 1. Zeile des Datensatzes aus (Argument skip), da dort Metadaten stehen, also keine Daten, sondern Informationen (Daten) zu den eigentlichen Daten.\nAufgabe\nBerechnen und visualisieren Sie die folgende Statistiken pro Dekade:\n\nMittelwert der Temperatur im Januar\nSD der Temperatur im Januar\n\nHinweise:\n\nSie m√ºssen zuerst die Dekade als neue Spalte berechnen."
  },
  {
    "objectID": "posts/nasa01/nasa01.html#setup",
    "href": "posts/nasa01/nasa01.html#setup",
    "title": "nasa01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(ggpubr)\nlibrary(DataExplorer)"
  },
  {
    "objectID": "posts/nasa01/nasa01.html#daten-aufbereiten",
    "href": "posts/nasa01/nasa01.html#daten-aufbereiten",
    "title": "nasa01",
    "section": "Daten aufbereiten",
    "text": "Daten aufbereiten\nDekade berechnen:\n\nd &lt;-\n  d %&gt;% \n  mutate(decade = round(Year/10))\n\nDas ist ein m√∂glicher Weg, um aus einer Jahreszahl die Dekade zu berechnen."
  },
  {
    "objectID": "posts/nasa01/nasa01.html#statistiken-berechnen",
    "href": "posts/nasa01/nasa01.html#statistiken-berechnen",
    "title": "nasa01",
    "section": "Statistiken berechnen",
    "text": "Statistiken berechnen\nStatistiken pro Dekade:\n\nd_summarized &lt;- \n  d %&gt;% \n  group_by(decade) %&gt;% \n  summarise(temp_mean = mean(Jan),\n            temp_sd = sd(Jan))\n\nd_summarized\n\n\n\n\n\n\n\n\n\ndecade\ntemp_mean\ntemp_sd\n\n\n\n\n188\n‚àí0.20\n0.24\n\n\n189\n‚àí0.44\n0.22\n\n\n190\n‚àí0.27\n0.16\n\n\n191\n‚àí0.40\n0.22\n\n\n192\n‚àí0.29\n0.15\n\n\n193\n‚àí0.14\n0.22\n\n\n194\n0.02\n0.21\n\n\n195\n‚àí0.05\n0.19\n\n\n196\n0.03\n0.15\n\n\n197\n‚àí0.07\n0.17\n\n\n198\n0.21\n0.19\n\n\n199\n0.35\n0.13\n\n\n200\n0.51\n0.19\n\n\n201\n0.63\n0.21\n\n\n202\n1.02\n0.19"
  },
  {
    "objectID": "posts/nasa01/nasa01.html#statistiken-visualisieren",
    "href": "posts/nasa01/nasa01.html#statistiken-visualisieren",
    "title": "nasa01",
    "section": "Statistiken visualisieren",
    "text": "Statistiken visualisieren\n\nMit DataExplorer\n\nd_summarized |&gt; \n  select(decade, temp_mean) |&gt; \n  plot_scatterplot(by = \"temp_mean\")\n\nd_summarized |&gt; \n  select(decade, temp_sd) |&gt; \n  plot_scatterplot(by = \"temp_sd\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMit ggpubr\n\nd_summarized |&gt; \n  ggline(x = \"decade\", y = \"temp_mean\")\n\nd_summarized |&gt; \n  ggline(x = \"decade\", y = \"temp_sd\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd  |&gt; \n  ggerrorplot(x = \"decade\", y = \"Jan\")\n\n\n\n\n\n\n\n\nFalls Sie Teile der R-Syntax nicht kennen: Machen Sie sich nichts daraus. üòÑ\n\nCategories:\n\ndata\neda\nlagema√üe\nvariability\nstring"
  },
  {
    "objectID": "posts/ds-quiz/ds-quiz.html",
    "href": "posts/ds-quiz/ds-quiz.html",
    "title": "ds-quiz",
    "section": "",
    "text": "Im Folgenden sind mehrere Aussagen zum Thema maschinelles Lernen dargestellt. W√§hlen Sie alle korrekten Aussagen aus!\nHinweise:\n\nAlle Aussagen sind entweder richtig oder falsch, aber nicht beides.\nBeziehen Sie sich im Zweifel auf den Stoff wie im Unterricht dargestellt.\n\n\n\n\nDecision Trees (Baummodelle) sind Overfitting (√úberanpassung) mehr ausgesetzt als lineare Modelle.\nEin Resampling-Schema mit \\(v=10\\) Faltungen und \\(r=5\\) Wiederholungen ist identisch zu einem Schema mit \\(v=50\\) Faltungen und \\(r=1\\) Wiederholungen.\n‚ÄúNormale‚Äù (nicht regularisierte) lineare Modelle sind besser interpretierbar als L1-regularisierte lineare Modelle.\n‚ÄúNormale‚Äù lineare Modelle verf√ºgen nicht √ºber Tuningparameter.\nJe gr√∂√üer die Anzahl der B√§ume in einem Random Forest, desto gr√∂√üer die Gefahr des Overfittings."
  },
  {
    "objectID": "posts/ds-quiz/ds-quiz.html#answerlist",
    "href": "posts/ds-quiz/ds-quiz.html#answerlist",
    "title": "ds-quiz",
    "section": "",
    "text": "Decision Trees (Baummodelle) sind Overfitting (√úberanpassung) mehr ausgesetzt als lineare Modelle.\nEin Resampling-Schema mit \\(v=10\\) Faltungen und \\(r=5\\) Wiederholungen ist identisch zu einem Schema mit \\(v=50\\) Faltungen und \\(r=1\\) Wiederholungen.\n‚ÄúNormale‚Äù (nicht regularisierte) lineare Modelle sind besser interpretierbar als L1-regularisierte lineare Modelle.\n‚ÄúNormale‚Äù lineare Modelle verf√ºgen nicht √ºber Tuningparameter.\nJe gr√∂√üer die Anzahl der B√§ume in einem Random Forest, desto gr√∂√üer die Gefahr des Overfittings."
  },
  {
    "objectID": "posts/ds-quiz/ds-quiz.html#answerlist-1",
    "href": "posts/ds-quiz/ds-quiz.html#answerlist-1",
    "title": "ds-quiz",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig. Decision Trees neigen zum Overfitting, sie sind sehr flexibel und haben daher viel Varianz in ihren Entscheidungen.\nFalsch. Bei 10 Faltungen beinhaltet das Test-Sample 1/10 der Beobachtungen und entsprechend bei 50 Faltungen nur 1/50 der Beobachtungen. Au√üerdem erreicht man durch die Wiederholungen eine robustere (pr√§zisere) Sch√§tzung der Vorhersageg√ºte.\nFalsch. Durch die L1-Regularisierung (Lasso) werden (oft) Pr√§diktoren entfernt (ihr Gewicht auf Null gesetzt), so dass das resultierende Modell einfacher und damit auch einfacher interpretierbarer ist.\nRichtig.\nFalsch. Normalerweise steigt die Modellg√ºte mit der Anzahl der B√§ume bis zu einem S√§ttigungsniveau, ab welchem zus√§tzliche B√§ume die Vorhersageg√ºte nicht mehr beeinflussen (allerdings die Rechenzeit schon).\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nmchoice"
  },
  {
    "objectID": "posts/globus-bin/index.html",
    "href": "posts/globus-bin/index.html",
    "title": "globus-bin1",
    "section": "",
    "text": "1 Aufgabe\nSie werfen einen Globus \\(n=9\\) Mal. (Wenn Sie nach l√§ngerem Suchen keinen Globus finden, dann nehmen Sie eine M√ºnze. Das geht genauso, macht aber weniger Spa√ü.)\nDer Versuch l√§uft so ab: Sie werfen den Globus. Hoch! Und fangen ihn wieder auf. Dann schauen Sie zur Stelle unter Ihrem Zeigefinger. Ist dort Land oder Wasser?\nGehen Sie von einer Trefferwahrscheinlichkeit (f√ºr ‚ÄúWasser‚Äù) von \\(\\pi=.7\\) aus.\nAufgabe Berechnen Sie die Wahrscheinlichkeit, dass Sie genau \\(0,1,2,\\ldots,n\\) mal ‚ÄúWasser‚Äù sehen.\n  \n  \n  \n  \n\n\n2 L√∂sung\n\ndbinom(x = 0:9, size = 9, prob = .7)\n\n [1] 0.000019683 0.000413343 0.003857868 0.021003948 0.073513818 0.171532242\n [7] 0.266827932 0.266827932 0.155649627 0.040353607"
  },
  {
    "objectID": "posts/weinhaendler/weinhaendler.html",
    "href": "posts/weinhaendler/weinhaendler.html",
    "title": "Weinhaendler",
    "section": "",
    "text": "Sie sind k√ºrzlich in ein Startup-Unternehmen eingestiegen. Das Unternehmen versucht, einen Online-Weinhandel aufzubauen. Kern des Unternehmens ist eine k√ºnstliche Intelligenz, die versucht, den Kundis den best m√∂glich passenden Wein anzudreh‚Ä¶ zu verkaufen.\nSie haben sich bei Ihrem Bewerbungsgespr√§ch pers√∂nlich von der Qualit√§t der Produkte eingehend √ºberzeugt und sind daher hoch motiviert, sich zum Wohle des Unternehmens einzusetzen.\nK√ºrzlich hat eine Beratungsfirma, die Ihre Kunden im Rahmen einer qualitativen Studie untersucht hat, herausgefunden, dass doch ein beachtlicher Teil von einem Menschen, nicht von einem Roboter (bzw. der KI) beim Wein aussuchen beraten werden m√∂chte. Diesen Anteil von Kunden (die nicht von der KI beraten werden m√∂chten) m√∂chten Sie jetzt genauer bestimmen.\nDazu haben Sie \\(N=42\\) Kundis befragt. Gut die H√§lfte (\\(n=23\\)) hat sich zugunsten der KI ausgesprochen; der Rest der Kundis m√∂chte lieber von einem Menschen beraten werden.\nGehen Sie im Folgenden davon aus, dass die Studie bzw. die erhaltenen Daten von guter Qualit√§t ist (man also keine Probleme wie mangelnde Repr√§sentativit√§t erwarten muss).\nVerwenden Sie die Gittermethode und gleichverteilte Priori-Werte.\n\nWie gro√ü ist die Wahrscheinlichkeit, dass die KI-freundlichen Kundis bei Ihnen √ºberwiegen?\nWie gro√ü ist die Wahrscheinlichkeit (laut Modell), dass k√ºnftig eine Mehrheit an KI-freundlichen Kundis zu beobachten sein wird?\nWenn Sie nur eine Zahl angeben d√ºrften: Was ist Ihr Sch√§tzwert zum Anteil der KI-Freunde (in dieser Studie)?"
  },
  {
    "objectID": "posts/weinhaendler/weinhaendler.html#a",
    "href": "posts/weinhaendler/weinhaendler.html#a",
    "title": "Weinhaendler",
    "section": "A)",
    "text": "A)\n\nWie gro√ü ist die Wahrscheinlichkeit (laut Modell), dass die KI-freundlichen Kundis bei Ihnen √ºberwiegen?\n\nDas ist eine Frage nach der kumulative Verteilungsfuntion (cumulative distribution function, cdf).\n\np_grid &lt;- seq(from=0, \n              to=1, \n              length.out=1000)  # Gitterwerte\n\nprior &lt;- rep(1, 1000)  # Priori-Gewichte\n\nset.seed(42)  # Zufallszahlen festlegen\nlikelihood &lt;- dbinom(23, size = 42, prob=p_grid ) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nZiehen wir daraus Stichproben:\n\nset.seed(42)  # Zufallszahlen festlegen\nsamples &lt;- \n  tibble(\n    p = sample(p_grid , \n               prob = posterior, \n               size=1e4, \n               replace=TRUE))  \nsamples &lt;-\n  samples %&gt;% \n  mutate(id = 1:nrow(samples))\n\n\nsamples %&gt;% \n  filter(p &gt; 0.5) %&gt;% \n  summarise(wskt_mehrheit_will_ki = n()/nrow(samples))\n\n\n\n\n\nwskt_mehrheit_will_ki\n\n\n\n\n0.7309\n\n\n\n\n\n\nVisualisieren:\nMit {ggpubr}:\n\nlibrary(ggpubr)\n\ngghistogram(samples, x = \"p\") +\n  geom_vline(xintercept = 0.5, color = \"red\", linewidth=2) \n\n\n\n\n\n\n\n\nMit {ggplot2}:\n\nsamples %&gt;% \n  ggplot() +\n  aes(x = p) +\n  geom_histogram() +\n  geom_vline(xintercept = 0.5) +\n  labs(title = \"Post-Verteilung\")"
  },
  {
    "objectID": "posts/weinhaendler/weinhaendler.html#b",
    "href": "posts/weinhaendler/weinhaendler.html#b",
    "title": "Weinhaendler",
    "section": "b)",
    "text": "b)\n\nWie gro√ü ist die Wahrscheinlichkeit (laut Modell), dass k√ºnftig eine Mehrheit an KI-freundlichen Kunfis zu beobachten sein wird?\n\n\nPPV &lt;-\n  samples %&gt;% \n  mutate(Anzahl_will_KI = rbinom(n = 1e4, size = 42, prob = p))\n\n\nPPV %&gt;% \n  ggplot() +\n  aes(x = Anzahl_will_KI) +\n  geom_histogram() +\n  labs(title = \"PPV\")\n\n\n\n\n\n\n\n\nEine Mehrheit entspricht mind. 22 von 42 Personen.\n\nPPV %&gt;% \n  filter(Anzahl_will_KI &gt;= 22) %&gt;% \n  summarise(prob_mehrheit_will_ki = n()/nrow(PPV))\n\n\n\n\n\nprob_mehrheit_will_ki\n\n\n\n\n0.6227"
  },
  {
    "objectID": "posts/weinhaendler/weinhaendler.html#c",
    "href": "posts/weinhaendler/weinhaendler.html#c",
    "title": "Weinhaendler",
    "section": "C)",
    "text": "C)\n\nWenn Sie nur eine Zahl angeben d√ºrften: Was ist Ihr Sch√§tzwert zum Anteil der KI-Freunde (in dieser Studie)?\n\nMan k√∂nnte den Mittelwert oder den Median angeben:\n\nlibrary(easystats)\ndescribe_distribution(samples)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\np\n0.5448855\n0.0736796\n0.1001001\n0.2742743\n7.887888e-01\n-0.0884649\n-0.0591925\n10000\n0\n\n\nid\n5000.5000000\n2886.8956799\n5000.5000000\n1.0000000\n1.000000e+04\n0.0000000\n-1.2000000\n10000\n0\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes-box\nbayes\nstring"
  },
  {
    "objectID": "posts/tutorium-kausal/index.html",
    "href": "posts/tutorium-kausal/index.html",
    "title": "tutorium-kausal",
    "section": "",
    "text": "Aufgabe\nSie untersuchen folgende Forschungsfrage:\n\nHat ein Tutorium (im Fach Statistik, X) einen (kausalen) Effekt auf die Note (in der Statistikklausur), Y?\n\nDabei gehen Sie von folgendem DAG aus.\n\n\n\n\n\n\n\n\nFigure¬†1: Der kausale Effekt eines Tutoriums auf die Note, konfundiert durch IQ\n\n\n\n\n\nAufgabe: Geben Sie das minimale Adjustierungsset an, um den direkten kausalen Effekt von Tutor auf Note zu identifizieren.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nMan muss IQ adjustieren.\n\nadjustmentSets(tutor_dag,\n               exposure = \"Tutor\",\n               outcome = \"Note\")\n\n{ IQ }\n\n\nAlternativ kann man Tutor randomisieren. Dadurch werden alle in Tutor eingehenden Pfeile ‚Äúgel√∂scht‚Äù. Das Resultat ist, dass es keine ‚ÄúHintert√ºr‚Äù von X zu Y mehr gibt.\n\n\n\n\n\n\n\n\nFigure¬†2: Der kausale Effekt eines Tutoriums auf die Note mit randomisiertem (R) Tutorium\n\n\n\n\n\nAlternative Visualisierung:\n\nplot(tutor_dag_rand)\n\n\n\n\n\n\n\n\nNat√ºrlich m√ºsste man ‚Äì realistischer ‚Äì davon ausgehen, dass es noch viele weitere ungemessene Ursachen f√ºr die Note gibt, z.B. Lernzeit (f√ºr die Klausur).\nGeht man aber davon aus, dass es keine gemeinsame Ursache von Lernzeit und (dem Besuch eines) Tutorium gibt, so gibt es keine Konfundierung und damit keine Verzerrung der Kausaleffekts, auch wenn man Lernzeit nicht misst.\n\n\n\n\n\n\n\n\nFigure¬†3: Der kausale Effekt eines Tutoriums auf die Note mit randomisiertem (R) Tutorium plus weitere ungemessene (u) Einfl√ºsse"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html",
    "href": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html",
    "title": "Verteilungen-Quiz-18",
    "section": "",
    "text": "Ei Forschi untersucht den Effekt eines Intelligenztraining auf den IQ.\nDabei findet sich aposteriori (also als Ergebnis der Untersuchung) \\(\\bar{x} \\sim N(3,5)\\) (in Standard-IQ-Punkten). Wir messen dabei die Erh√∂hung des Intelligenzwerts.\nDis Forschi res√ºmiert: ‚ÄúMit einer Wahrscheinlichkeit von 95% profitiert man von diesem Training‚Äù.\nIst diese Aussage korrekt (gegeben der Angaben)?\nHinweise:\n\nNutzen Sie Simulationsmethoden zur L√∂sung\nFixieren Sie die Zufallszahlen auf die Startzahl 42.\nZiehen Sie \\(10^5\\) Zufallszahlen aus der gegebenen Verteilung.\n\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist",
    "href": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist",
    "title": "Verteilungen-Quiz-18",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist-1",
    "title": "Verteilungen-Quiz-18",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Regression4/Regression4.html",
    "href": "posts/Regression4/Regression4.html",
    "title": "Regression4",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie \\(\\hat{y}\\) f√ºr das unten ausgegeben Modell!\nNutzen Sie daf√ºr folgende Werte:\n\n\\(g=0\\)\n\\(x=-8\\).\n\n\n\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\nlower_ci\nupper_ci\n\n\n\n\nintercept\n32.534\n6.533\n4.980\n0\n19.491\n45.576\n\n\nx\n-11.222\n0.648\n-17.327\n0\n-12.515\n-9.929\n\n\ng\n44.030\n9.185\n4.794\n0\n25.692\n62.367\n\n\nx:g\n-8.619\n0.967\n-8.909\n0\n-10.550\n-6.687\n\n\n\n\n\nHinweis: Ein Interaktionseffekt der Variablen \\(x\\) und \\(g\\) ist mit x:g gekennzeichnet. Runden Sie zur n√§chsten ganzen Zahl.\n         \n\n\nL√∂sung\n\\(\\hat{y}\\) betr√§gt im Fall der vorliegenden Parameter und dem vorliegenden Modell \\(122\\).\n\nCategories:\n\ndyn\nregression\nlm\nnum"
  },
  {
    "objectID": "posts/purrr-map01/purrr-map01.html",
    "href": "posts/purrr-map01/purrr-map01.html",
    "title": "purrr-map01",
    "section": "",
    "text": "library(tidyverse)\n\n\nExercise\nErstellen Sie einen Tibble mit folgenden Spalten:\n\nBuchstaben A-Z, so dass in der 1. Zeile ‚ÄúA‚Äù steht, in der 2. Zeile ‚ÄúB‚Äù etc.\nBuchstaben a-z, so dass in der 1. Zeile ‚Äúa‚Äù steht, in der 2. Zeile ‚Äúb‚Äù etc.\nBuchstabenkombination der ersten beiden Spalten, so dass in der 1. Zeile ‚ÄúA-a‚Äù steht, in der 2. Zeile ‚ÄúB-b‚Äù etc.\n\n         \n\n\nSolution\nGeht es vielleicht so?\n\nd &lt;-\n  tibble(\n    letter1 = LETTERS,\n    letter2 = letters,\n    letters = paste(letter1, letter2, collapse = \"-\")\n  )\n\nhead(d)\n\n\n\n\n\n\n\n\n\n\nletter1\nletter2\nletters\n\n\n\n\nA\na\nA a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P p-Q q-R r-S s-T t-U u-V v-W w-X x-Y y-Z z\n\n\nB\nb\nA a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P p-Q q-R r-S s-T t-U u-V v-W w-X x-Y y-Z z\n\n\nC\nc\nA a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P p-Q q-R r-S s-T t-U u-V v-W w-X x-Y y-Z z\n\n\nD\nd\nA a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P p-Q q-R r-S s-T t-U u-V v-W w-X x-Y y-Z z\n\n\nE\ne\nA a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P p-Q q-R r-S s-T t-U u-V v-W w-X x-Y y-Z z\n\n\nF\nf\nA a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P p-Q q-R r-S s-T t-U u-V v-W w-X x-Y y-Z z\n\n\n\n\n\n\nNein, leider nicht.\nOK, neuer Versuch:\n\nd &lt;-\n  tibble(\n    letter1 = LETTERS,\n    letter2 = letters) %&gt;% \n  unite(\"letters\", c(letter1, letter2), remove = FALSE)\n\n\nhead(d)\n\n\n\n\n\nletters\nletter1\nletter2\n\n\n\n\nA_a\nA\na\n\n\nB_b\nB\nb\n\n\nC_c\nC\nc\n\n\nD_d\nD\nd\n\n\nE_e\nE\ne\n\n\nF_f\nF\nf\n\n\n\n\n\n\nProbieren wir es mit purrr::map():\n\nd &lt;-\n  tibble(\n    letter1 = LETTERS,\n    letter2 = letters,\n    letters = map2_chr(letter1, letter2, ~ paste(c(.x, .y), collapse =\"-\"))\n  )\n\nhead(d)\n\n\n\n\n\nletter1\nletter2\nletters\n\n\n\n\nA\na\nA-a\n\n\nB\nb\nB-b\n\n\nC\nc\nC-c\n\n\nD\nd\nD-d\n\n\nE\ne\nE-e\n\n\nF\nf\nF-f\n\n\n\n\n\n\nInfos zur Funktion paste() findet sich z.B. hier.\n\nCategories:\n\nR\nmap\ntidyverse"
  },
  {
    "objectID": "posts/tmdb06/tmdb06.html",
    "href": "posts/tmdb06/tmdb06.html",
    "title": "tmdb06",
    "section": "",
    "text": "Aufgabe\nMelden Sie sich an f√ºr die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?.\nSie ben√∂tigen dazu ein Konto; es ist auch m√∂glich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Pr√§diktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verf√ºgung. Eine klassische ‚Äúpredictive Competition‚Äù also :-) Allerdings k√∂nnen immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Lineares Modell mit Tidymodels!\nHinweise\n\n\nVerzichten Sie auf Vorverarbeitung.\nVerzichten Sie auf Tuning.\nReichen Sie das Modell ein und berichten Sie Ihren Score.\nBegrenzen Sie sich auf folgende Pr√§diktoren.\nVerwenden Sie (langweiligerweise) nur ein lineares Modell.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\")\n\n         \n\n\nL√∂sung\n\n\nPakete starten\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(finetune)  # Anova Race\nlibrary(doParallel)  # parallele Verarbeitung\n\n\n\nDaten importieren\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nWerfen wir einen Blick in die Daten:\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1‚Ä¶\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C‚Ä¶\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00‚Ä¶\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '‚Ä¶\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht‚Ä¶\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148‚Ä¶\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", ‚Ä¶\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In‚Ä¶\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807‚Ä¶\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh‚Ä¶\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam‚Ä¶\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of‚Ä¶\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/‚Ä¶\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119‚Ä¶\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'‚Ä¶\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol‚Ä¶\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96‚Ä¶\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'‚Ä¶\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep‚Ä¶\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,‚Ä¶\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, ‚Ä¶\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pok√©mon Collection', 'p‚Ä¶\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06‚Ä¶\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n‚Ä¶\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-‚Ä¶\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595‚Ä¶\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", ‚Ä¶\n$ original_title        &lt;chr&gt; \"„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§\", \"Attack of the 50 Foot Wom‚Ä¶\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco‚Ä¶\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680‚Ä¶\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1‚Ä¶\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',‚Ä¶\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3‚Ä¶\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11‚Ä¶\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,‚Ä¶\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_‚Ä¶\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B‚Ä¶\n$ title                 &lt;chr&gt; \"Pok√©mon: The Rise of Darkrai\", \"Attack of the 5‚Ä¶\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok‚àö¬©mon'}, {'id': 1155‚Ä¶\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i‚Ä¶\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep‚Ä¶\n\n\npreds_chosen sind alle Pr√§diktoren im Datensatz, oder nicht? Das pr√ºfen wir mal kurz:\n\npreds_chosen %in% names(d_train) %&gt;% \n  all()\n\n[1] TRUE\n\n\nJa, alle Elemente von preds_chosen sind Pr√§diktoren im (Train-)Datensatz.\n\n\nCV\nWir brauchen keine CV, da wir keine Tuningparameter haben.\n\ncv_scheme &lt;- vfold_cv(d_train)\n\n\n\nRezept\n\nrec1 &lt;- \n  recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_naomit(all_predictors()) \nrec1\n\nMan beachte, dass noch 21 Pr√§diktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (‚Äúgebacken‚Äù) wurde.\n\ntidy(rec1)\n\n\n\n\n\nnumber\noperation\ntype\ntrained\nskip\nid\n\n\n\n\n1\nstep\nimpute_bag\nFALSE\nFALSE\nimpute_bag_ZD5YP\n\n\n2\nstep\nnaomit\nFALSE\nTRUE\nnaomit_NViKj\n\n\n\n\n\n\nRezept checken:\n\nprep(rec1)\n\n\nd_train_baked &lt;-\n  rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n\nRows: 3,000\nColumns: 4\n$ budget     &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00, 8.00e+06,‚Ä¶\n$ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.148070, 0.743274‚Ä¶\n$ runtime    &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119, 98, 122, ‚Ä¶\n$ revenue    &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970, 3261638, 8‚Ä¶\n\n\nFehlende Werte noch √ºbrig?\n\nlibrary(easystats)\ndescribe_distribution(d_train_baked) %&gt;% \n  select(Variable, n_Missing)\n\n\n\n\n\nVariable\nn_Missing\n\n\n\n\nbudget\n0\n\n\npopularity\n0\n\n\nruntime\n0\n\n\nrevenue\n0\n\n\n\n\n\n\n\n\nModell\n\nmodel_lm &lt;- linear_reg()\n\n\n\nWorkflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model_lm) %&gt;% \n  add_recipe(rec1)\n\n\n\nModell fitten (und tunen)\n\n#doParallel::registerDoParallel(4)\ntic()\nlm_fit1 &lt;-\n  wf1 %&gt;% \n  fit(d_train)\ntoc()\n\n0.561 sec elapsed\n\n\n\npreds &lt;-\n  lm_fit1 %&gt;% \n  predict(d_test)\n\n\n\nSubmission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n\n\n\n\nid\nrevenue\n\n\n\n\n3001\n-4147658.3\n\n\n3002\n-8808530.5\n\n\n3003\n8523919.3\n\n\n3004\n31675316.1\n\n\n3005\n-504489.9\n\n\n3006\n13531493.9\n\n\n\n\n\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\n\n\nKaggle Score\nDiese Submission erzielte einen Score von Score: 6.14787 (RMSLE).\n\nsol &lt;- 6.14787\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/penguins-vis-bodymass1/index.html",
    "href": "posts/penguins-vis-bodymass1/index.html",
    "title": "penguins-vis-bodymass1",
    "section": "",
    "text": "Aufgabe\nIm Datensatz palmerpenguins: Welche der folgenden Variablen korreliert am st√§rksten mit dem K√∂rpergewicht der Pinguine?\nBeantworten Sie diese Frage mit Hilfe einer Visualisierung!\nSie k√∂nnen den Datensatz so beziehen:\n\n#install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(\"penguins\")\nd &lt;- penguins \n\nOder so:\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nEin Codebook finden Sie hier.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\nL√∂sung\n\nlibrary(tidyverse)\nlibrary(DataExplorer)\n\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\nd |&gt; \n  select(bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g) |&gt; \n  plot_scatterplot(by = \"body_mass_g\")\n\n\n\n\n\n\n\n\nEs sieht so aus, also ob flipper_length_mm am st√§rksten mit dem K√∂rpergewicht zusammenh√§ngt.\nAlternative Art der Visualisierung:\n\nlibrary(ggpubr)\n\nd |&gt; ggscatter(x = \"bill_length_mm\", \"body_mass_g\")\n\n\n\n\n\n\n\nd |&gt; ggscatter(x = \"flipper_length_mm\", \"body_mass_g\")\n\n\n\n\n\n\n\nd |&gt; ggscatter(x = \"bill_depth_mm\", \"body_mass_g\")"
  },
  {
    "objectID": "posts/penguins-stan-03/penguins-stan-03.html",
    "href": "posts/penguins-stan-03/penguins-stan-03.html",
    "title": "penguins-stan-03",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nWie gro√ü ist der statistische Einfluss der UV auf die AV?\nGeben Sie den Punktsch√§tzer des Effekts an!\nHinweise:\n\nNutzen Sie den Datensatz zu den Palmer Penguins.\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nBeziehen Sie sich auf den Median-Sch√§tzwert.\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nZentrieren ist eigentlich immer n√ºtzlich, aber hier streng genommen nicht unbedingt n√∂tig. Der Hauptgrund daf√ºr ist, dass Stan f√ºr uns den Prior f√ºr den Intercept festlegt, und zwar auf Basis der Daten, wir uns also nicht um die komische Frage zu k√ºmmern brauchen, welchen Prior wir f√ºr den unzentrierten Achsenabschnitt vergeben wollten: Wie schwer sind Pinguins der Schnabell√§nge Null? Mit zentrierten Pr√§diktoren ist die Frage nach dem Prior viel einfacher zu beantworten: Wie schwer ist ein Pinguin mit mittelgro√üem Schnabel?\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)\n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1, ci_method = \"hdi\", ci = .9, keep = \"bill_length_mm\")  # nur f√ºr \"bill_length_mm\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\nbill_length_mm\n87.4472\n0.9\n76.99955\n98.3694\n1\n1.000491\n4123.761\nnormal\n0\n367.2233\n\n\n\n\n\n\nDie L√∂sung lautet also, wie aus der Ausgabe zu den Parametern ersichtlich, 87.45.\n\nCategories:\n\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/Regr-Bayes-interpret/Regr-Bayes-interpret.html",
    "href": "posts/Regr-Bayes-interpret/Regr-Bayes-interpret.html",
    "title": "Regr-Bayes-interpret",
    "section": "",
    "text": "Exercise\nBerechnen Sie das Modell und interpretieren Sie die Ausgabe des folgenden Regressionsmodells. Geben Sie f√ºr jeden Regressionskoeffizienten an, wie sein Wert zu verstehen ist!\nmpg ~ hp + am + hp:am\nHinweise:\n\nFixieren Sie die Zufallszahlen.\nVerwenden Sie Stan zur Berechnung.\nRunden Sie auf 2 Dezimalstellen.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Stan, komm her\nlibrary(easystats)  # Komfort\n\n\nm1 &lt;- \n  stan_glm(mpg ~ hp + am + hp:am, \n           seed = 42,\n           refresh = 0,\n           data = mtcars)\n\ncoef(m1)\n\n  (Intercept)            hp            am         hp:am \n26.5494656993 -0.0585833356  5.2229516713  0.0001431021 \n\n\n\nIntercept: Ein Auto mit 0 PS und Automatikantrieb (am=0, s. Hilfe zum Datensatz: help(mtcars)) kann laut Modell mit einer Gallone Sprit ca. 26.62 Meilen fahren.\nhp: Pro zus√§tzlichem PS kann ein Auto mit Automatikantrieb pro Gallone Sprit ca. 0.06 Meilen weniger weit fahren.\nam: Ein Auto mit 0 PS und Schaltgetriebe (am=1) kommt pro Gallone Sprit ca. 5.26 Meilen weiter als ein Auto mit Automatikantrieb.\nhp:am: Der Interaktionseffekt ist praktisch Null: Der Zusammenhang von PS-Zahl und Spritverbrauch unterscheidet sich nicht (wesentlich) zwischen Autos mit bzw. ohne Automatikantrieb.\n\n\nCategories:\n\nbayes\nregression"
  },
  {
    "objectID": "posts/twitter07/twitter07.html",
    "href": "posts/twitter07/twitter07.html",
    "title": "twitter07",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=2\\)) und zwar pro Nutzerkonto wie unten angegeben . die Tweets sollen jeweils an eine prominente Person gerichtet sein.\nBeziehen Sie sich auf diese Politikis.\n         \n         \n\n\nSolution\nWir starten die ben√∂tigten R-Pakete:\n\nlibrary(academictwitteR)\nlibrary(tidyverse)\nlibrary(askpass)\nlibrary(rio)\n\nHier ist der Datensatz mit den Twitterkonten, f√ºr die wir die Daten herunterladen sollen:\n\npoliticians_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/datascience-text/main/data/twitter-german-politicians.csv\"\npoliticians &lt;- import(politicians_path)\npoliticians\n\n\n\n\n\n\n\n\n\n\n\nname\nparty\nscreenname\ncomment\n\n\n\n\nKarl Lauterbach\nSPD\nKarl_Lauterbach\nNA\n\n\nOlaf Scholz\nSPD\nOlafScholz\nNA\n\n\nAnnalena Baerback\nGruene\nABaerbock\nNA\n\n\nBundesministerium f√ºr Wirtschaft und Klimaschutz\nGruene\nBMWK\nRobert Habeck ist der Minister im BMWK\n\n\nFriedrich Merz\nCDU\n_FriedrichMerz\nCDU-Chef\n\n\nMarkus S√∂der\nCSU\nMarkus_Soeder\nCSU-Chef\n\n\nCem √ñzdemir\nGruene\ncem_oezdemir\nBMEL\n\n\nJanine Wissler\nLinke\nJanine_Wissler\nLinke-Chefin\n\n\nMartin Schirdewan\nLinke\nschirdewan\nLinke-Chef\n\n\nChristian Lindner\nFDP\nc_lindner\nFDP-Chef\n\n\nMarie-Agnes Strack-Zimmermann\nFDP\nMAStrackZi\nVorsitzende Verteidigungsausschuss\n\n\nTino Chrupalla\nAFD\nTino_Chrupalla\nAFD-Bundessprecher\n\n\nAlice Weidel\nAFD\nAlice_Weidel\nAFD-Bundessprecherin\n\n\n\n\n\n\nWir m√ºssen noch das Passwort bereitstellen:\n\nbearer_token &lt;- askpass::askpass(\"bearer token\")\n\nUnd dann definieren wir eine Funktion, die das Gewichtheben f√ºr uns erledigt:\n\nget_all_tweets_politicians &lt;- function(screenname, n = 1e1) {\n  get_all_tweets(query = paste0(\"to:\", screenname, \" -is:retweet\"),\n                 start_tweets = \"2021-01-01T00:00:00Z\",\n                 end_tweets = \"2021-12-31T23:59:59Z\",\n                 bearer_token = bearer_token,\n                 file = glue::glue(\"~/datasets/Twitter/hate-speech/tweets_to_{screenname}_2021.rds\"),\n                 data_path = glue::glue(\"~/datasets/Twitter/hate-speech/{screenname}\"),\n                 n = n)\n}\n\nJetzt wenden wir die Funktion auf jedes Twitterkonto unserer Liste (alle Politikis) an:\n\nd &lt;- politicians$screenname %&gt;% \n  map(get_all_tweets_politicians)\n\n\nCategories:\n\ntextmining\ntwitter\nprogramming"
  },
  {
    "objectID": "posts/Bed-Post-Wskt1/Bed-Post-Wskt1.html",
    "href": "posts/Bed-Post-Wskt1/Bed-Post-Wskt1.html",
    "title": "Bed-Post-Wskt1",
    "section": "",
    "text": "Beziehen Sie sich auf das Regressionsmodell, f√ºr das die Ausgabe mit stan_glm() hier dargestellt ist:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n146.1050983\n0.95\n145.1605321\n147.075639\n1\n0.9997636\n4475.401\nnormal\n154.5971\n19.355830\n\n\nweight_c\n0.9034848\n0.95\n0.8201613\n0.984254\n1\n0.9998113\n4535.592\nnormal\n0.0000\n2.997786\n\n\n\n\n\n\nBetrachten Sie folgende Beziehung (Gleichung bzw. Ungleichung):\n\\[Pr(\\text{height}_i = 155|\\text{weightcentered}_i=10, \\alpha, \\beta, \\sigma) \\quad \\Box \\quad Pr(\\text{height}_i = 160|\\text{weightcentered}_i=10, \\alpha, \\beta, \\sigma)\\] Die in der obigen Beziehung angegebenen Parameter beziehen sich auf das oben dargestellt Modell.\nErg√§nzen Sie das korrekte Zeichen in das Rechteck \\(\\Box\\)!\n\n\n\n\\(\\lt\\)\n\\(\\le\\)\n\\(\\gt\\)\n\\(\\ge\\)\n\\(=\\)"
  },
  {
    "objectID": "posts/Bed-Post-Wskt1/Bed-Post-Wskt1.html#answerlist",
    "href": "posts/Bed-Post-Wskt1/Bed-Post-Wskt1.html#answerlist",
    "title": "Bed-Post-Wskt1",
    "section": "",
    "text": "\\(\\lt\\)\n\\(\\le\\)\n\\(\\gt\\)\n\\(\\ge\\)\n\\(=\\)"
  },
  {
    "objectID": "posts/Bed-Post-Wskt1/Bed-Post-Wskt1.html#answerlist-1",
    "href": "posts/Bed-Post-Wskt1/Bed-Post-Wskt1.html#answerlist-1",
    "title": "Bed-Post-Wskt1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nregression\nbayes\npost"
  },
  {
    "objectID": "posts/diamonds-tidymodels01/diamonds-tidymodels01.html",
    "href": "posts/diamonds-tidymodels01/diamonds-tidymodels01.html",
    "title": "diamonds-tidymodels01",
    "section": "",
    "text": "Aufgabe\nFinden Sie ein m√∂glichst ‚Äúgutes‚Äù pr√§diktives Modell zur Vorhersage des Diamantenpreises im Datensatz diamonds!\nGegenstand dieser Aufgabe ist die Modellierung; Datenvorverarbeitug (wie explorative Datenanalyse) steht nicht im Fokus.\nHinweise:\n\nVerwenden Sie die Methoden aus tidymodels.\nHohe Modellg√ºte (‚Äúgutes Modell‚Äù) sei definiert √ºber \\(R^2\\), RMSE und MAE\nVerwenden Sie verschiedene Algorithmen (lineare Modell, kNN, ‚Ä¶) und verschiedene Rezepte.\nResampling und Tuning ist hier noch nicht n√∂tig.s\n\nDer Datensatz ist hier zu beziehen. Au√üerdem ist er Teil von ggplot2 bzw. des Tidyverse und daher mit data() zu laden, wenn das entsprechende Paket vorhanden ist.\n         \n\n\nL√∂sung\n\n\nSetup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nDaten laden:\n\ndata(diamonds, package = \"ggplot2\")\n\nOder so:\n\ndiamonds &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n\n\n\nTrain- vs.¬†Testdaten:\n\nd_split &lt;- initial_split(diamonds, strata = price)\n\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n\nModelle:\n\nlin_mod &lt;-\n  linear_reg()\n\n\nknn_mod &lt;-\n  nearest_neighbor(mode = \"regression\")\n\nHilfe zu kNN findet sich z.B. hier.\n\n\nRezepte:\n\nrec1 &lt;-\n  recipe(price ~ ., data = d_train) %&gt;% \n  update_role(1, new_role = \"id\") %&gt;% \n  step_naomit() %&gt;% \n  step_log(all_outcomes())\n\n\n\nRezept pr√ºfen (preppen und backen)\n\nrec1_prepped &lt;-\n  rec1 %&gt;% \n  prep()\n\nrec1_prepped\n\n\nd_train_baked &lt;-\n  bake(rec1_prepped, new_data = d_train)\n\nEinen √úberblick zu steps findet sich z.B. hier.\nRollen-Definitionen in Tidymodels-Rezepten kann man hier nachlesen.\n\nrec2 &lt;-\n  recipe(price ~ ., data = d_train) %&gt;% \n  update_role(1, new_role = \"id\") %&gt;% \n  step_impute_knn() %&gt;% \n  step_log(all_outcomes())\n\n\n\nWorkflows:\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_recipe(rec1) %&gt;% \n  add_model(lin_mod)\n\n\nwf2 &lt;-\n  wf1 %&gt;% \n  update_model(knn_mod)\n\n\n\nFitting\n\nfit1 &lt;-\n  wf1 %&gt;% \n  fit(d_train)\nfit1\n\n\n\nFitten des Test-Samples\n\nfit1_test &lt;-\n  wf1 %&gt;% \n  last_fit(d_split)\nfit1_test\n\n\n\nModellg√ºte\n\ncollect_metrics(fit1_test)\n\nDe-logarithmieren, wenn man Vorhersagen in den Rohwerten haben m√∂chte:\n\ncollect_predictions(fit1_test) %&gt;% \n  head()\n\n\nd_test_w_preds &lt;- \ncollect_predictions(fit1_test) %&gt;% \n  mutate(pred_raw = exp(.pred)) \n\nhead(d_test_w_preds)\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nstring"
  },
  {
    "objectID": "posts/Streuung-Histogramm/Streuung-Histogramm.html",
    "href": "posts/Streuung-Histogramm/Streuung-Histogramm.html",
    "title": "Streuung-Histogramm",
    "section": "",
    "text": "W√§hlen Sie das Diagramm, in dem der vertikale gestrichelte Linie am genauesten die Position des Medians (\\(Md\\)) widerspiegelt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist",
    "href": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist",
    "title": "Streuung-Histogramm",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist-1",
    "href": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist-1",
    "title": "Streuung-Histogramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\neda\nstreuungsma√ü\nvariability\ndyn\nschoice"
  },
  {
    "objectID": "posts/Nullhyp-Beispiel/Nullhyp-Beispiel.html",
    "href": "posts/Nullhyp-Beispiel/Nullhyp-Beispiel.html",
    "title": "Nullhyp-Beispiel",
    "section": "",
    "text": "Welches der folgenden Beispiele ist kein Beispiel f√ºr eine Nullhypothese?\n\n\n\n\\(\\beta_1 &lt;= 0\\)\n\\(\\mu_1 = \\mu_2\\)\n\\(\\mu_1 = \\mu_2 = ... = \\mu_k\\)\n\\(\\rho = 0\\)\n\\(\\pi_1 = \\pi_2\\)"
  },
  {
    "objectID": "posts/Nullhyp-Beispiel/Nullhyp-Beispiel.html#answerlist",
    "href": "posts/Nullhyp-Beispiel/Nullhyp-Beispiel.html#answerlist",
    "title": "Nullhyp-Beispiel",
    "section": "",
    "text": "\\(\\beta_1 &lt;= 0\\)\n\\(\\mu_1 = \\mu_2\\)\n\\(\\mu_1 = \\mu_2 = ... = \\mu_k\\)\n\\(\\rho = 0\\)\n\\(\\pi_1 = \\pi_2\\)"
  },
  {
    "objectID": "posts/Nullhyp-Beispiel/Nullhyp-Beispiel.html#answerlist-1",
    "href": "posts/Nullhyp-Beispiel/Nullhyp-Beispiel.html#answerlist-1",
    "title": "Nullhyp-Beispiel",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nnull\ninference"
  },
  {
    "objectID": "posts/fun1/index.html",
    "href": "posts/fun1/index.html",
    "title": "fun1",
    "section": "",
    "text": "1 Aufgabe\nSchreiben Sie eine einfache Funktion.\nBeschreiben Sie dann Ihren Code.\n       \n\n\n2 L√∂sung\n\nmeine_funktion &lt;- function(x) {\n  tmp1 &lt;- x^2\n  tmp2 &lt;- sum(tmp1)\n  tmp3 &lt;- tmp2*(-1)\n  tmp4 &lt;- tmp3-1\n  return(tmp4)\n}"
  },
  {
    "objectID": "posts/corona-blutgruppe/corona-blutgruppe.html",
    "href": "posts/corona-blutgruppe/corona-blutgruppe.html",
    "title": "corona-blutgruppe",
    "section": "",
    "text": "Aufgabe\nBetrachten wir das Ereignis ‚ÄúSchwerer Coronaverlauf‚Äù (\\(S\\)); ferner betrachten wir das Ereignis ‚ÄúBlutgruppe ist A‚Äù (\\(A\\)) und das Gegenereignis von \\(A\\): ‚ÄúBlutgruppe ist nicht A‚Äù. Ein Gegenereignis wird auch als Komplement√§rereignis oder Komplement (complement) mit dem Operator \\(\\bar{A}\\) oder \\(A^C\\) bezeichnet.\nSei \\(Pr(S|A) = 0.01\\) und sei \\(Pr(S|A^C) = 0.01\\).\nWas kann man auf dieser Basis zur Abh√§ngigkeit der Ereignisse \\(S\\) und \\(A\\) sagen?\nGeben Sie ein Adjektiv an, dass diesen Sachverhalt kennzeichnet!\n         \n\n\nL√∂sung\nDie L√∂sung lautet: unabh√§ngig.\n\\(S\\) und \\(A\\) sind unabh√§ngig: Offenbar ist die Wahrscheinlichkeit eines schweren Verlaufs gleich gro√ü unabh√§ngig davon, ob die Blutgruppe A ist oder nicht. In diesem Fall spricht man von stochastischer Unabh√§ngigkeit.\n\\(Pr(S|A) = Pr(S|A^C) = Pr(S)\\)\nHinweis: \\(A^C\\) meint das Komplement von \\(A\\), auch als \\(\\neg A\\) bezeichnet.\n\nCategories:\n\nprobability\ndependent\nstring"
  },
  {
    "objectID": "posts/tidymodels-penguins02/tidymodels-penguins02.html",
    "href": "posts/tidymodels-penguins02/tidymodels-penguins02.html",
    "title": "tidymodels-penguins02",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=1 CV.\nTunen Sie nicht.\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs pr√ºfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\"\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n1 Recipe Step\n\n‚Ä¢ step_naomit()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nK-Nearest Neighbor Model Specification (regression)\n\nComputational engine: kknn \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\n34.5\n2900\n\n\n52.2\n3450\n\n\n45.4\n4800\n\n\n42.1\n4000\n\n\n50.0\n5350\n\n\n41.5\n4000\n\n\n\n\n\n\nAuf NA pr√ºfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5)\nfolds\n\n\n\n\n\n\n\n\n\nsplits\nid\n\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 8 , 9 , 10 , 11 , 12 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 55 , 57 , 58 , 61 , 62 , 63 , 64 , 65 , 66 , 68 , 70 , 71 , 72 , 73 , 75 , 76 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 87 , 88 , 89 , 90 , 91 , 93 , 94 , 96 , 97 , 98 , 99 , 100 , 101 , 103 , 105 , 107 , 108 , 109 , 111 , 112 , 115 , 116 , 117 , 118 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 131 , 132 , 133 , 135 , 136 , 138 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 151 , 152 , 155 , 156 , 157 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 186 , 187 , 190 , 191 , 192 , 193 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 214 , 215 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 227 , 228 , 229 , 230 , 232 , 234 , 235 , 236 , 238 , 239 , 240 , 242 , 243 , 244 , 245 , 246 , 247 , NA , Fold1\nFold1\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 10 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 26 , 27 , 28 , 29 , 33 , 34 , 35 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 48 , 50 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 84 , 85 , 86 , 87 , 89 , 90 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 100 , 101 , 102 , 103 , 104 , 105 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 146 , 148 , 150 , 153 , 154 , 155 , 156 , 158 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 169 , 170 , 171 , 172 , 173 , 175 , 176 , 177 , 179 , 180 , 181 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 194 , 196 , 197 , 198 , 199 , 200 , 201 , 204 , 205 , 206 , 208 , 209 , 211 , 213 , 214 , 215 , 216 , 217 , 218 , 220 , 221 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 245 , 247 , 248 , 249 , NA , Fold2\nFold2\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 5 , 7 , 8 , 9 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 28 , 29 , 30 , 31 , 32 , 33 , 36 , 41 , 42 , 43 , 44 , 47 , 49 , 50 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 62 , 63 , 64 , 66 , 67 , 69 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 85 , 86 , 88 , 89 , 91 , 92 , 93 , 94 , 95 , 97 , 99 , 100 , 101 , 102 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 121 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 156 , 157 , 158 , 160 , 161 , 163 , 164 , 165 , 166 , 168 , 169 , 171 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 199 , 202 , 203 , 204 , 205 , 206 , 207 , 209 , 210 , 211 , 212 , 213 , 215 , 216 , 217 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 231 , 232 , 233 , 234 , 235 , 237 , 238 , 241 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Fold3\nFold3\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 3 , 4 , 6 , 7 , 8 , 10 , 11 , 13 , 14 , 16 , 17 , 18 , 21 , 22 , 23 , 24 , 25 , 27 , 29 , 30 , 31 , 32 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 53 , 54 , 55 , 56 , 58 , 59 , 60 , 61 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 76 , 77 , 78 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 90 , 91 , 92 , 95 , 96 , 98 , 99 , 100 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 122 , 124 , 126 , 127 , 128 , 129 , 130 , 131 , 133 , 134 , 137 , 138 , 139 , 140 , 141 , 142 , 144 , 145 , 146 , 147 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 , 159 , 161 , 162 , 164 , 165 , 167 , 168 , 169 , 170 , 172 , 173 , 174 , 175 , 176 , 178 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 205 , 206 , 207 , 208 , 210 , 211 , 212 , 213 , 214 , 216 , 217 , 218 , 219 , 220 , 222 , 224 , 226 , 229 , 230 , 231 , 232 , 233 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 244 , 245 , 246 , 248 , 249 , NA , Fold4\nFold4\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 15 , 19 , 20 , 21 , 22 , 23 , 25 , 26 , 27 , 28 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 56 , 57 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 110 , 111 , 113 , 114 , 115 , 116 , 119 , 120 , 121 , 122 , 123 , 125 , 126 , 127 , 128 , 130 , 132 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 143 , 145 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 162 , 163 , 166 , 167 , 168 , 170 , 171 , 172 , 174 , 175 , 176 , 177 , 178 , 179 , 182 , 183 , 185 , 187 , 188 , 189 , 192 , 193 , 194 , 195 , 196 , 197 , 198 , 200 , 201 , 202 , 203 , 204 , 207 , 208 , 209 , 210 , 212 , 213 , 214 , 215 , 216 , 217 , 218 , 219 , 221 , 222 , 223 , 225 , 226 , 227 , 228 , 230 , 231 , 233 , 234 , 236 , 237 , 239 , 240 , 241 , 242 , 243 , 244 , 246 , 247 , 248 , 249 , NA , Fold5\nFold5\n\n\n\n\n\n\nResampling:\n\nd_resamples &lt;-\n  fit_resamples(\n    wflow,\n    resamples = folds\n  )\n\nd_resamples\n\n\n\n\n\n\n\n\n\n\n\nsplits\nid\n.metrics\n.notes\n\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 8 , 9 , 10 , 11 , 12 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 55 , 57 , 58 , 61 , 62 , 63 , 64 , 65 , 66 , 68 , 70 , 71 , 72 , 73 , 75 , 76 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 87 , 88 , 89 , 90 , 91 , 93 , 94 , 96 , 97 , 98 , 99 , 100 , 101 , 103 , 105 , 107 , 108 , 109 , 111 , 112 , 115 , 116 , 117 , 118 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 131 , 132 , 133 , 135 , 136 , 138 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 151 , 152 , 155 , 156 , 157 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 186 , 187 , 190 , 191 , 192 , 193 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 214 , 215 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 227 , 228 , 229 , 230 , 232 , 234 , 235 , 236 , 238 , 239 , 240 , 242 , 243 , 244 , 245 , 246 , 247 , NA , Fold1\nFold1\nrmse , rsq , standard , standard , 721.886703576122 , 0.257660401148508, pre0_mod0_post0 , pre0_mod0_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 10 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 26 , 27 , 28 , 29 , 33 , 34 , 35 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 48 , 50 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 84 , 85 , 86 , 87 , 89 , 90 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 100 , 101 , 102 , 103 , 104 , 105 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 146 , 148 , 150 , 153 , 154 , 155 , 156 , 158 , 159 , 160 , 161 , 162 , 163 , 164 , 165 , 166 , 167 , 169 , 170 , 171 , 172 , 173 , 175 , 176 , 177 , 179 , 180 , 181 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 194 , 196 , 197 , 198 , 199 , 200 , 201 , 204 , 205 , 206 , 208 , 209 , 211 , 213 , 214 , 215 , 216 , 217 , 218 , 220 , 221 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 245 , 247 , 248 , 249 , NA , Fold2\nFold2\nrmse , rsq , standard , standard , 688.48527827398 , 0.280016289181017, pre0_mod0_post0 , pre0_mod0_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 3 , 5 , 7 , 8 , 9 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 28 , 29 , 30 , 31 , 32 , 33 , 36 , 41 , 42 , 43 , 44 , 47 , 49 , 50 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 62 , 63 , 64 , 66 , 67 , 69 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 85 , 86 , 88 , 89 , 91 , 92 , 93 , 94 , 95 , 97 , 99 , 100 , 101 , 102 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 121 , 123 , 124 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 156 , 157 , 158 , 160 , 161 , 163 , 164 , 165 , 166 , 168 , 169 , 171 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 199 , 202 , 203 , 204 , 205 , 206 , 207 , 209 , 210 , 211 , 212 , 213 , 215 , 216 , 217 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 231 , 232 , 233 , 234 , 235 , 237 , 238 , 241 , 244 , 245 , 246 , 247 , 248 , 249 , NA , Fold3\nFold3\nrmse , rsq , standard , standard , 617.270559803398 , 0.329291768180258, pre0_mod0_post0 , pre0_mod0_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 3 , 4 , 6 , 7 , 8 , 10 , 11 , 13 , 14 , 16 , 17 , 18 , 21 , 22 , 23 , 24 , 25 , 27 , 29 , 30 , 31 , 32 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 53 , 54 , 55 , 56 , 58 , 59 , 60 , 61 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 76 , 77 , 78 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 90 , 91 , 92 , 95 , 96 , 98 , 99 , 100 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 122 , 124 , 126 , 127 , 128 , 129 , 130 , 131 , 133 , 134 , 137 , 138 , 139 , 140 , 141 , 142 , 144 , 145 , 146 , 147 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 , 159 , 161 , 162 , 164 , 165 , 167 , 168 , 169 , 170 , 172 , 173 , 174 , 175 , 176 , 178 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 189 , 190 , 191 , 192 , 193 , 194 , 195 , 197 , 198 , 199 , 200 , 201 , 202 , 203 , 205 , 206 , 207 , 208 , 210 , 211 , 212 , 213 , 214 , 216 , 217 , 218 , 219 , 220 , 222 , 224 , 226 , 229 , 230 , 231 , 232 , 233 , 235 , 236 , 237 , 238 , 239 , 240 , 241 , 242 , 243 , 244 , 245 , 246 , 248 , 249 , NA , Fold4\nFold4\nrmse , rsq , standard , standard , 771.604569711714 , 0.219804967991395, pre0_mod0_post0 , pre0_mod0_post0\n\n\n\n55 , 332 , 159 , 80 , 236 , 152 , 128 , 344 , 134 , 314 , 29 , 95 , 171 , 116 , 25 , 308 , 333 , 294 , 115 , 6 , 220 , 268 , 309 , 334 , 164 , 310 , 142 , 303 , 339 , 326 , 204 , 5 , 234 , 223 , 253 , 120 , 273 , 136 , 3 , 267 , 193 , 144 , 45 , 325 , 38 , 109 , 340 , 315 , 163 , 82 , 276 , 40 , 229 , 21 , 228 , 256 , 124 , 307 , 88 , 331 , 155 , 63 , 106 , 97 , 280 , 188 , 60 , 215 , 254 , 66 , 114 , 132 , 118 , 78 , 1 , 147 , 213 , 139 , 208 , 61 , 150 , 226 , 49 , 47 , 259 , 289 , 103 , 192 , 296 , 30 , 121 , 198 , 37 , 87 , 246 , 19 , 117 , 7 , 182 , 260 , 197 , 343 , 277 , 119 , 238 , 36 , 168 , 100 , 232 , 244 , 222 , 43 , 101 , 233 , 90 , 20 , 39 , 176 , 311 , 195 , 17 , 336 , 160 , 46 , 200 , 72 , 62 , 158 , 104 , 252 , 98 , 113 , 67 , 241 , 247 , 235 , 130 , 201 , 292 , 249 , 161 , 317 , 327 , 33 , 288 , 42 , 199 , 237 , 301 , 293 , 84 , 206 , 162 , 338 , 255 , 133 , 298 , 242 , 248 , 32 , 35 , 282 , 81 , 151 , 68 , 18 , 329 , 335 , 69 , 337 , 264 , 122 , 323 , 224 , 207 , 2 , 318 , 185 , 306 , 174 , 221 , 57 , 202 , 53 , 214 , 262 , 15 , 216 , 286 , 165 , 99 , 283 , 227 , 196 , 169 , 108 , 278 , 263 , 143 , 64 , 183 , 91 , 194 , 170 , 23 , 319 , 212 , 187 , 258 , 41 , 330 , 85 , 145 , 77 , 304 , 181 , 312 , 250 , 92 , 129 , 217 , 16 , 210 , 230 , 112 , 79 , 28 , 96 , 111 , 271 , 24 , 245 , 138 , 172 , 131 , 251 , 328 , 141 , 65 , 180 , 157 , 107 , 26 , 76 , 156 , 341 , 324 , 8 , 189 , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Chinstrap, Chinstrap, Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Gentoo , Chinstrap, Adelie , Chinstrap, Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Chinstrap, Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Adelie , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Chinstrap, Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Adelie , Adelie , Gentoo , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Adelie , Chinstrap, Adelie , Adelie , Adelie , Adelie , Chinstrap, Chinstrap, Adelie , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Gentoo , Chinstrap, Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Chinstrap, Gentoo , Gentoo , Gentoo , Adelie , Chinstrap, Adelie , Adelie , Adelie , Chinstrap, Gentoo , Chinstrap, Gentoo , Adelie , Adelie , Gentoo , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Adelie , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Adelie , Gentoo , Chinstrap, Adelie , Adelie , Gentoo , Gentoo , Adelie , Adelie , Adelie , Gentoo , Chinstrap, Chinstrap, Adelie , Gentoo , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Dream , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Dream , Dream , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Torgersen, Biscoe , Biscoe , Dream , Dream , Dream , Dream , Biscoe , Dream , Dream , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Dream , Dream , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Torgersen, Torgersen, Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Torgersen, Torgersen, Torgersen, Biscoe , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Torgersen, Biscoe , Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Dream , Torgersen, Dream , Biscoe , Torgersen, Dream , Biscoe , Biscoe , Torgersen, Dream , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Dream , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Biscoe , Biscoe , Dream , Dream , Dream , Dream , Torgersen, Dream , Biscoe , Dream , Biscoe , Dream , Torgersen, Biscoe , Torgersen, Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Dream , Biscoe , Torgersen, Biscoe , Dream , Dream , Biscoe , Biscoe , Biscoe , Biscoe , Biscoe , Torgersen, Biscoe , Dream , Dream , Torgersen, Biscoe , 34.5 , 52.2 , 45.4 , 42.1 , 50 , 41.5 , 41.5 , 50.2 , 37.5 , 52 , 37.9 , 36.2 , 46.2 , 42.7 , 38.8 , 54.2 , 45.2 , 58 , 39.6 , 39.3 , 49.5 , 55.1 , 42.5 , 49.3 , 49 , 51 , 40.6 , 50.5 , 45.7 , 49.8 , 48.5 , 36.7 , 52.5 , 47.7 , 48.5 , 41.1 , 46.8 , 41.1 , 40.3 , 46.2 , 42.7 , 40.7 , 37 , 51.5 , 42.2 , 38.1 , 55.8 , 46.9 , 40.9 , 42.9 , 49.9 , 39.8 , 47.5 , 37.8 , 48.6 , 49.1 , 41.4 , 40.9 , 36.9 , 42.5 , 48.7 , 37.6 , 39.7 , 38.1 , 45.4 , 48.4 , 37.6 , 45.7 , 55.9 , 41.6 , 42.2 , 43.1 , 37.3 , 37.2 , 39.1 , 39.2 , 45.3 , 37 , 45 , 35.7 , 37.8 , 46.5 , 36 , 41.1 , 41.7 , 47 , 37.7 , 48.7 , 49.2 , 40.5 , 36.2 , 43.6 , 38.8 , 36.3 , 49.5 , 34.4 , 38.6 , 38.9 , 50 , 53.4 , 50.5 , 50.8 , 46.5 , 35.7 , 50.8 , 39.2 , 49.3 , 43.2 , 45.2 , 52.2 , 50.7 , 36 , 35 , 49.1 , 38.9 , 46 , 37.6 , 46.3 , 49.7 , 45.3 , 38.7 , 45.6 , 46.7 , 39.6 , 50.5 , 39.7 , 41.3 , 46.5 , 37.8 , 51.1 , 40.3 , 39.7 , 35.5 , 47.5 , 44.5 , 47.4 , 44.1 , 44.9 , 50.5 , 49.4 , 43.3 , 49 , 48.1 , 39.5 , 51.7 , 40.8 , 45.5 , 44.9 , 46.7 , 50.3 , 35.1 , 50.1 , 46.8 , 46.8 , 47.2 , 36.8 , 48.5 , 52.1 , 50.8 , 37.2 , 36.4 , 45.2 , 34.6 , 36 , 41.1 , 42.5 , 45.7 , 50.2 , 35.9 , 51.9 , 49.8 , 37.7 , 50.1 , 46.4 , 46.5 , 39.5 , 46.2 , 45.1 , 52.8 , 45.1 , 43.5 , 39 , 45.2 , 35 , 46.2 , 48.1 , 34.6 , 54.3 , 51.3 , 45.5 , 33.1 , 46.1 , 46.4 , 49.6 , 42 , 38.2 , 50 , 50.5 , 32.1 , 41.1 , 47.3 , 35.7 , 49.6 , 49.2 , 35.9 , 50.9 , 50.4 , 49.1 , 46.8 , 36.5 , 50.7 , 37.3 , 37.3 , 40.9 , 49.5 , 48.2 , 47.5 , 46.9 , 41.1 , 39 , 45.8 , 36.6 , 45.5 , 51.1 , 45.6 , 36.2 , 40.5 , 40.8 , 38.1 , 47.2 , 38.2 , 45.5 , 40.2 , 48.7 , 38.5 , 48.4 , 51.4 , 40.2 , 36.4 , 47.8 , 47.6 , 38.6 , 35.3 , 42.8 , 50 , 43.5 , 49 , 39.2 , 42.6 , 18.1 , 18.8 , 14.6 , 19.1 , 15.9 , 18.5 , 18.3 , 18.7 , 18.5 , 20.7 , 18.6 , 17.3 , 14.5 , 18.3 , 17.2 , 20.8 , 16.6 , 17.8 , 20.7 , 20.6 , 16.2 , 16 , 16.7 , 19.9 , 16.1 , 18.8 , 17.2 , 18.4 , 17 , 17.3 , 14.1 , 19.3 , 15.6 , 15 , 15 , 18.6 , 14.3 , 17.5 , 18 , 14.1 , 13.7 , 17 , 16.9 , 18.7 , 18.5 , 17 , 19.8 , 16.6 , 13.7 , 17.6 , 16.1 , 19.1 , 14.2 , 18.3 , 16 , 15 , 18.5 , 16.6 , 18.6 , 17.3 , 14.1 , 17 , 18.9 , 18.6 , 18.7 , 16.3 , 19.1 , 13.9 , 17 , 18 , 19.5 , 19.2 , 20.5 , 19.4 , 18.7 , 18.6 , 13.8 , 16.5 , 15.4 , 16.9 , 18.1 , 14.8 , 17.9 , 19 , 14.7 , 17.3 , 16 , 15.7 , 18.2 , 18.9 , 17.2 , 13.9 , 20 , 19.5 , 16.1 , 18.4 , 17 , 17.8 , 15.3 , 15.8 , 15.9 , 19 , 17.9 , 17 , 17.3 , 21.1 , 15.7 , 18.5 , 16.4 , 17.1 , 15 , 18.5 , 17.9 , 14.5 , 18.8 , 21.5 , 19.3 , 15.8 , 18.6 , 13.7 , 19 , 19.4 , 15.3 , 18.8 , 15.9 , 18.4 , 21.1 , 13.5 , 20 , 16.5 , 18.5 , 17.7 , 16.2 , 14 , 14.7 , 14.6 , 18 , 13.3 , 19.6 , 15.8 , 13.4 , 19.5 , 16.4 , 17.8 , 20.3 , 18.4 , 13.9 , 13.8 , 17.9 , 20 , 19.4 , 15 , 15.4 , 16.5 , 15.5 , 18.5 , 17.5 , 17 , 15.7 , 18.1 , 17 , 17.8 , 17.2 , 17.1 , 19.1 , 20.7 , 17.3 , 18.8 , 16.6 , 19.5 , 15.9 , 19.8 , 17.9 , 15.6 , 14.4 , 17.4 , 17.5 , 14.5 , 20 , 14.5 , 14.2 , 17.5 , 15.8 , 17.9 , 14.9 , 15.1 , 21.1 , 15.7 , 19.9 , 13.7 , 16.1 , 18.2 , 15 , 15 , 13.5 , 20 , 19.5 , 15.2 , 15.5 , 18.2 , 15.3 , 18 , 16 , 15.2 , 19.2 , 19.1 , 15.3 , 14.8 , 16.1 , 18 , 19.7 , 17.8 , 16.8 , 16.8 , 19 , 14.3 , 16.8 , 14.6 , 18.1 , 17.1 , 14.2 , 17.8 , 15 , 16.3 , 20.3 , 16.1 , 17.9 , 18.9 , 16.5 , 13.7 , 18.1 , 14.5 , 20.1 , 15.1 , 17.9 , 14.4 , 19 , 17.1 , 17.1 , 15 , 14.5 , 17.2 , 18.9 , 18.5 , 15.2 , 18.1 , 19.6 , 19.6 , 13.7 , 187 , 197 , 211 , 195 , 224 , 201 , 195 , 198 , 199 , 210 , 172 , 187 , 209 , 196 , 180 , 201 , 191 , 181 , 191 , 190 , 229 , 230 , 187 , 203 , 216 , 203 , 187 , 200 , 195 , 198 , 220 , 193 , 221 , 216 , 219 , 189 , 215 , 190 , 195 , 217 , 208 , 190 , 185 , 187 , 180 , 181 , 207 , 192 , 214 , 196 , 213 , 184 , 209 , 174 , 230 , 228 , 202 , 187 , 189 , 187 , 210 , 185 , 184 , 190 , 188 , 220 , 194 , 214 , 228 , 192 , 197 , 197 , 199 , 184 , 181 , 190 , 208 , 185 , 220 , 185 , 193 , 217 , 190 , 182 , 210 , 185 , 183 , 208 , 195 , 180 , 187 , 217 , 190 , 190 , 224 , 184 , 188 , 181 , 220 , 219 , 222 , 210 , 192 , 189 , 228 , 196 , 217 , 192 , 223 , 228 , 223 , 186 , 192 , 212 , 190 , 194 , 181 , 215 , 195 , 210 , 195 , 194 , 219 , 190 , 225 , 190 , 195 , 210 , 190 , 225 , 196 , 193 , 195 , 212 , 214 , 212 , 210 , 213 , 201 , 216 , 209 , 210 , 199 , 188 , 194 , 195 , 210 , 212 , 195 , 197 , 193 , 225 , 215 , 189 , 215 , 193 , 191 , 230 , 226 , 178 , 195 , 198 , 189 , 187 , 188 , 197 , 193 , 202 , 190 , 206 , 229 , 198 , 190 , 221 , 217 , 186 , 187 , 207 , 205 , 215 , 220 , 186 , 215 , 190 , 221 , 209 , 198 , 231 , 198 , 214 , 178 , 178 , 216 , 216 , 210 , 190 , 196 , 216 , 188 , 192 , 222 , 202 , 225 , 221 , 189 , 196 , 224 , 220 , 215 , 182 , 203 , 191 , 192 , 191 , 200 , 210 , 199 , 222 , 205 , 191 , 219 , 185 , 220 , 220 , 191 , 187 , 187 , 208 , 198 , 214 , 185 , 212 , 200 , 222 , 190 , 203 , 201 , 193 , 184 , 215 , 215 , 199 , 187 , 195 , 218 , 202 , 212 , 195 , 213 , 2900 , 3450 , 4800 , 4000 , 5350 , 4000 , 4300 , 3775 , 4475 , 4800 , 3150 , 3300 , 4800 , 4075 , 3800 , 4300 , 3250 , 3700 , 3900 , 3650 , 5800 , 5850 , 3350 , 4050 , 5550 , 4100 , 3475 , 3400 , 3650 , 3675 , 5300 , 3450 , 5450 , 4750 , 4850 , 3325 , 4850 , 3900 , 3250 , 4375 , 3950 , 3725 , 3000 , 3250 , 3550 , 3175 , 4000 , 2700 , 4650 , 4700 , 5400 , 4650 , 4600 , 3400 , 5800 , 5500 , 3875 , 3200 , 3500 , 3350 , 4450 , 3600 , 3550 , 3700 , 3525 , 5400 , 3750 , 4400 , 5600 , 3950 , 4275 , 3500 , 3775 , 3900 , 3750 , 4250 , 4200 , 3400 , 5050 , 3150 , 3750 , 5200 , 3450 , 3425 , 4700 , 3700 , 3075 , 5350 , 4400 , 3950 , 3150 , 4900 , 3950 , 3800 , 5650 , 3325 , 2900 , 3625 , 5550 , 5500 , 5550 , 4100 , 3500 , 3350 , 5600 , 4150 , 5850 , 4100 , 5950 , 5400 , 5550 , 3100 , 3725 , 4625 , 3600 , 4200 , 3300 , 5050 , 3600 , 4300 , 3450 , 3525 , 5200 , 4600 , 5400 , 3900 , 4400 , 4550 , 4250 , 5250 , 4350 , 3200 , 3350 , 4875 , 4850 , 4725 , 4000 , 5100 , 4050 , 4925 , 4400 , 3950 , 3325 , 3300 , 3775 , 3900 , 4200 , 4750 , 3300 , 3300 , 4200 , 5000 , 5150 , 3650 , 4975 , 3500 , 3400 , 5550 , 5200 , 3900 , 3325 , 3950 , 3200 , 3700 , 4100 , 4500 , 3600 , 3800 , 3050 , 3950 , 5950 , 3500 , 3400 , 5000 , 4900 , 3800 , 3650 , 5050 , 4550 , 5000 , 4700 , 3550 , 5300 , 3450 , 5300 , 5500 , 4400 , 5650 , 3700 , 4650 , 2900 , 3250 , 4700 , 4750 , 4150 , 3900 , 3900 , 5000 , 3050 , 4050 , 5250 , 3550 , 5700 , 6300 , 3800 , 3550 , 5550 , 5150 , 5500 , 3150 , 4050 , 3350 , 3000 , 3700 , 3800 , 4600 , 3900 , 4875 , 4300 , 3050 , 4700 , 3700 , 5000 , 6000 , 4600 , 3550 , 3200 , 4300 , 3825 , 4925 , 3950 , 4750 , 3975 , 5350 , 3325 , 4625 , 3950 , 3400 , 2850 , 5650 , 5400 , 3750 , 3800 , 4250 , 5700 , 3400 , 4300 , 4675 , 4950 , female , male , female , male , male , male , male , female , male , male , female , female , female , male , male , male , female , female , female , male , male , male , female , male , male , male , male , female , female , female , male , female , male , female , female , male , female , male , female , female , female , male , female , male , female , female , male , female , female , male , male , male , female , female , male , male , male , female , female , female , female , female , male , female , female , male , male , female , male , male , male , male , male , male , male , male , female , female , male , female , male , female , female , male , female , female , female , male , male , male , female , female , male , male , male , female , female , female , male , male , male , male , female , female , male , male , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , female , male , male , male , male , male , female , male , male , male , female , female , female , female , female , male , female , male , male , female , male , female , female , male , male , female , female , female , male , male , male , male , female , female , female , male , male , male , male , female , female , female , female , male , male , female , male , female , male , male , male , female , male , female , female , female , female , male , female , female , female , male , female , male , male , male , male , male , female , female , female , female , male , female , male , male , female , female , male , male , female , male , male , female , male , male , female , male , female , male , female , female , female , male , female , female , female , male , female , female , female , male , male , male , female , female , male , female , female , male , female , male , male , female , female , male , female , female , male , male , female , female , male , male , female , male , male , female , 1 , 2 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 15 , 19 , 20 , 21 , 22 , 23 , 25 , 26 , 27 , 28 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 56 , 57 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 110 , 111 , 113 , 114 , 115 , 116 , 119 , 120 , 121 , 122 , 123 , 125 , 126 , 127 , 128 , 130 , 132 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 143 , 145 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 162 , 163 , 166 , 167 , 168 , 170 , 171 , 172 , 174 , 175 , 176 , 177 , 178 , 179 , 182 , 183 , 185 , 187 , 188 , 189 , 192 , 193 , 194 , 195 , 196 , 197 , 198 , 200 , 201 , 202 , 203 , 204 , 207 , 208 , 209 , 210 , 212 , 213 , 214 , 215 , 216 , 217 , 218 , 219 , 221 , 222 , 223 , 225 , 226 , 227 , 228 , 230 , 231 , 233 , 234 , 236 , 237 , 239 , 240 , 241 , 242 , 243 , 244 , 246 , 247 , 248 , 249 , NA , Fold5\nFold5\nrmse , rsq , standard , standard , 749.45672187204 , 0.280562727669961, pre0_mod0_post0 , pre0_mod0_post0\n\n\n\n\n\n\n\nLast Fit:\n\nfit_last &lt;- last_fit(wflow, d_split)\n\nModellg√ºte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\nrmse\nstandard\n654.4496346\npre0_mod0_post0\n\n\nrsq\nstandard\n0.2935091\npre0_mod0_post0\n\n\n\n\n\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n[1] 0.2935091\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/kausal21/kausal21.html",
    "href": "posts/kausal21/kausal21.html",
    "title": "kausal21",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x3.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x5, x6 }\n{ x6, x7 }\n{ x2, x7 }\n{ }\n{ x1, x4 }"
  },
  {
    "objectID": "posts/kausal21/kausal21.html#answerlist",
    "href": "posts/kausal21/kausal21.html#answerlist",
    "title": "kausal21",
    "section": "",
    "text": "{ x5, x6 }\n{ x6, x7 }\n{ x2, x7 }\n{ }\n{ x1, x4 }"
  },
  {
    "objectID": "posts/kausal21/kausal21.html#answerlist-1",
    "href": "posts/kausal21/kausal21.html#answerlist-1",
    "title": "kausal21",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nRichtig\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/urne2/urne2.html",
    "href": "posts/urne2/urne2.html",
    "title": "urne2",
    "section": "",
    "text": "Aufgabe\nIn einer Urne befinden sich f√ºnf Kugeln, von denen 4 rot sind und 1 wei√ü.\nAufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass bei 2 Ziehungen mit Zur√ºcklegen (ZmZ) genau 2 rote Kugeln gezogen werden?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nSei \\(R1\\) ‚Äúrote Kugel im 1. Zug gezogen‚Äù.\nSei \\(R2\\) ‚Äúrote Kugel im 2. Zug gezogen‚Äù.\nGesucht ist die gemeinsame Wahrscheinlichkeit f√ºr R1 und R2: \\(Pr(R1 \\cap R2)\\), die Wahrscheinlichkeit also, dass beide Ereignisse (R1 und R2) eintreten: \\(Pr(R1 \\cap R2)\\).\nF√ºr R1 gilt: \\(Pr(R1) = 4/5\\).\nF√ºr R2 gilt: \\(Pr(R2|R1) = 4/5\\).\nMan beachte, dass R1 und R2 unabh√§ngig sind: \\(R1 \\perp \\!\\!\\! \\perp R2\\), d.h. sie sind nicht abh√§ngig (voneinander).\n\nPr_R1 &lt;- 4/5\nPr_R2_geg_R1 &lt;- 4/5\nPr_R1_R2 &lt;- Pr_R1 * Pr_R2_geg_R1\nPr_R1_R2\n\n[1] 0.64\n\n\nDie L√∂sung lautet 0.64.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/pwert2/index.html",
    "href": "posts/pwert2/index.html",
    "title": "pwert2",
    "section": "",
    "text": "Beurteilen Sie folgende Aussagen:\n\nWenn die Stichprobe gro√ü genug ist, wird jeder Effekt statistisch signifikant (der p-Wert also beliebig klein). Jede Nullhypothese wird dann zur√ºckgewiesen.\n\n\n\n\nJa\nNein\nKommt darauf an, ob der Effekt gro√ü genug ist (und ungleich Null)\nJa, aber nur, wenn der Effekt nicht exakt Null ist\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/pwert2/index.html#antwortoptionen",
    "href": "posts/pwert2/index.html#antwortoptionen",
    "title": "pwert2",
    "section": "",
    "text": "Ja\nNein\nKommt darauf an, ob der Effekt gro√ü genug ist (und ungleich Null)\nJa, aber nur, wenn der Effekt nicht exakt Null ist\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/nerd-gelockert/nerd-gelockert.html",
    "href": "posts/nerd-gelockert/nerd-gelockert.html",
    "title": "Nerd-gelockert",
    "section": "",
    "text": "Aufgabe\nIn einer Studie werden Pers√∂nlichkeitsmerkmale von Professoren untersucht. Laut der Studie wird bei 12% extreme Nerdigkeit festgestellt, bei 8% stark gelockerte Assoziation (vulgo: Schraube locker). Bei 4% wurden beide Merkmale festgestellt.\nAufgabe: Berechnen Sie die Wahrscheinlichkeit von gelockerter Assoziation gegeben dass der Prof extremer Nerd ist.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nSei \\(N\\) ‚Äúextreme Nerdigkeit‚Äù.\nSei \\(A\\) ‚Äúgelockerte Assoziation‚Äù.\n\\(Pr(A|N) = \\frac{Pr(N \\cap A)}{Pr(N)} = \\frac{Pr(NA)}{Pr(N)}\\)\n\nPr_N &lt;- .12\nPr_A &lt;- .08\nPr_NA &lt;- .04\nPr_A_geg_N &lt;- (Pr_NA) / Pr_N\nPr_A_geg_N\n\n[1] 0.3333333\n\n\nDie L√∂sung lautet 0.3333333.\n\n\nVariante\n\nPr_N &lt;- .73\nPr_A &lt;- .23\nPr_NA &lt;- .42\nPr_A_geg_N &lt;- (Pr_NA) / Pr_N\nPr_A_geg_N\n\n[1] 0.5753425\n\n\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/anz-params/index.html",
    "href": "posts/anz-params/index.html",
    "title": "anz-params",
    "section": "",
    "text": "1 Aufgabe\nWie viele Parameter sieht die folgende Definition eines Bayes-Modells vor?\n\\[\n\\begin{aligned}\n\\text{y}_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{x1}_i + \\beta_2\\text{x2}_i \\\\\n\\beta_0, \\beta_1, \\beta_2  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\]\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\\(4: \\beta_0, \\beta_1, \\beta_2, \\sigma\\)"
  },
  {
    "objectID": "posts/kausal10/kausal10.html",
    "href": "posts/kausal10/kausal10.html",
    "title": "kausal10",
    "section": "",
    "text": "Ein Forschungsteam aus Psychologen und Medizinern untersucht die Frage, ob (h√∂here) Bereitschaft f√ºr eine OP und zu Ver√§nderung in ihrer Lebensf√ºhrung, nach einem Jahr √ºber einen (h√∂heren) Schmerzr√ºckgang f√ºhrt. Das hie√üt, Patienten geringerer Bereitschaft sollten es entsprechend zu weniger Schmerzr√ºckgang kommen. Die Bereitschaft der Patienten (ein theoretisches Konstrukt, was nicht direkt beobachtbar ist) wurde mittels eines psychometrisch validierten Fragebogen erhoben. Die Studie umfasst ausschlie√ülich Patienten, die eine OP wegen R√ºckenschmerzen durchlaufen sind (s. DAG).\nDas Studiendesign impliziert, dass nur Patienten, die eine OP durchlaufen haben, in die Studie aufgenommen wurde. Damit wird per Design diese Variable stratifiziert (kontrolliert).\n\n\n\n\n\n\n\n\n\nDurch die Stratifizierung wird ein Hintert√ºrpfad ge√∂ffnet; dieser muss geschlossen werden. Wie sollte dies geschehen (in diesem Modell)?\nIm folgenden Diagramm ist der Kollisionsbias kenntlich gemacht, der durch die Stratifizierung von Surgical Status entsteht:\n\n\n\n\n\n\n\n\n\nHinweis:\n\nWenn von ‚Äúkausaler Effekt‚Äù gesprochen wird, ist stets der (totale) kausale Effekt wie oben definiert gemeint.\nGehen Sie davon aus, dass die Daten zur Studie wie oben dargestellt erhoben und zug√§nglich sind; die Datenerhebung aber abgeschlossen ist.\n\n\n\n\nEs sollte vom Forschungsteam auf Baseline Pane kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Underlying Readiness kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Surgical Status kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Change in Pain kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Measured Readiness kontrolliert werden, um den kausalen Effekt zu identifizieren."
  },
  {
    "objectID": "posts/kausal10/kausal10.html#answerlist",
    "href": "posts/kausal10/kausal10.html#answerlist",
    "title": "kausal10",
    "section": "",
    "text": "Es sollte vom Forschungsteam auf Baseline Pane kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Underlying Readiness kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Surgical Status kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Change in Pain kontrolliert werden, um den kausalen Effekt zu identifizieren.\nEs sollte vom Forschungsteam auf Measured Readiness kontrolliert werden, um den kausalen Effekt zu identifizieren."
  },
  {
    "objectID": "posts/kausal10/kausal10.html#answerlist-1",
    "href": "posts/kausal10/kausal10.html#answerlist-1",
    "title": "kausal10",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html",
    "title": "germeval03-sent-wordvec-glm",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie eine einfache logistische Regression, d.h. ohne Tuning-Parameter.\n\n\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\n\n\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\n\n\n\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#daten",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#daten",
    "title": "germeval03-sent-wordvec-glm",
    "section": "",
    "text": "Verwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#av-und-uv",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#av-und-uv",
    "title": "germeval03-sent-wordvec-glm",
    "section": "",
    "text": "Die AV lautet c1. Die (einzige) UV lautet: text."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#hinweise",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#hinweise",
    "title": "germeval03-sent-wordvec-glm",
    "section": "",
    "text": "Orientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#setup",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#setup",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Setup",
    "text": "Setup\nTrain-Datensatz:\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\nPakete:\n\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(beepr)\nlibrary(finetune)  # anova race\n\nEine Vorlage f√ºr ein Tidymodels-Pipeline findet sich hier."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#learnermodell",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#learnermodell",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Learner/Modell",
    "text": "Learner/Modell\n\nmod &lt;-\n  logistic_reg(mode = \"classification\"\n  )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#gebackenen-datensatz-als-neue-grundlage",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#gebackenen-datensatz-als-neue-grundlage",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Gebackenen Datensatz als neue Grundlage",
    "text": "Gebackenen Datensatz als neue Grundlage\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz. Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind. Die Arbeit des Feature Engineering wurde uns schon abgenommen.\n\nd_train_raw &lt;-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\n\nd_test_baked_raw &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#keine-dummysierung-der-av",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#keine-dummysierung-der-av",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Keine Dummysierung der AV",
    "text": "Keine Dummysierung der AV\nLineare Modelle m√ºssen dummysiert sein. Rezepte wollen das nicht so gerne f√ºr die AV besorgen.\nABER: Klassifikationsmodelle in Tidymodels (parsnip) ben√∂tigen eine Variable vom Typ factor als AV, sonst werden sie nicht als Klassifikation erkannt.\n\nd_train &lt;-\n  d_train_raw |&gt; \n  mutate(c1 = as.factor(c1)) \n\nlevels(d_train$c1)\n\nTidymodels modelliert die erste Stufe, nicht die zweite, wie Base-R glm.\n\nd_test_baked &lt;-\n  d_test_baked_raw |&gt; \n  mutate(c1 = as.factor(c1)) \n\nlevels(d_test_baked$c1)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#dummy-rezept",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#dummy-rezept",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Dummy-Rezept",
    "text": "Dummy-Rezept\nPlain, aber mit Dummyisierung:\n\nrec &lt;- \n  recipe(c1 ~ ., data = d_train)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#workflow",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#workflow",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Workflow",
    "text": "Workflow\n\nwf &lt;-\n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#tuneresamplefit",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#tuneresamplefit",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Tune/Resample/Fit",
    "text": "Tune/Resample/Fit\n\nfit_train &lt;-\n  fit(wf,\n      data = d_train)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-glm/germeval-sent-wordvec-glm.html#test-set-g√ºte",
    "title": "germeval03-sent-wordvec-glm",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(fit_train, new_data = d_test_baked)\ntoc()\n\n\nd_test &lt;-\n  d_test_baked |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/kausal28/kausal28.html",
    "href": "posts/kausal28/kausal28.html",
    "title": "kausal28",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x7.\nAV: x8.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x1, x2, x3, x4, x5, x6 }\n{ x4, x7 }\n{ x2, x7 }\n{ x3, x5 }\n{ x2, x6 }"
  },
  {
    "objectID": "posts/kausal28/kausal28.html#answerlist",
    "href": "posts/kausal28/kausal28.html#answerlist",
    "title": "kausal28",
    "section": "",
    "text": "{ x1, x2, x3, x4, x5, x6 }\n{ x4, x7 }\n{ x2, x7 }\n{ x3, x5 }\n{ x2, x6 }"
  },
  {
    "objectID": "posts/kausal28/kausal28.html#answerlist-1",
    "href": "posts/kausal28/kausal28.html#answerlist-1",
    "title": "kausal28",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal\nschoice"
  },
  {
    "objectID": "posts/twitter01/twitter01.html",
    "href": "posts/twitter01/twitter01.html",
    "title": "twitter01",
    "section": "",
    "text": "Exercise\nLaden Sie die neuesten Tweets an karl_lauterbach herunter!\n         \n\n\nSolution\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nDann anmelden, z.B. als Bot:\n\nauth &lt;- rtweet_bot(api_key = API_Key,\n                   api_secret = API_Key_Secret,\n                   access_token = Access_Token,\n                   access_secret = Access_Token_Secret)\n\n‚Ä¶ Oder als App, das bringt bessere Raten mit sich:\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\nTest:\n\nsesa_test &lt;- get_timeline(user = \"sauer_sebastian\", n = 3) %&gt;% \n  select(full_text)\n\nsesa_test\n\n1 RT @fuecks: By the way: Systematic destruction of life-sustaining infrastructures ‚Ä¶\n2 RT @NoContextBrits: No shortbread for little Nazis. https://t.co/F6FUPvRz94        \n3 RT @ernst_gennat: 2 oder 3 Jahre #Tempolimit von 120 km/h. Abschlie√üend Evaluation‚Ä¶\nTweets an Karl Lauterbach suchen:\n\nkarl1 &lt;- search_tweets(\"@karl_lauterbach\")\n\nIn Ausz√ºgen:\n\"@Karl_Lauterbach Ein Minister der alle paar Stunden Zeit hat einen Mist zu verbreiten....\"   \n\"@Karl_Lauterbach @focusonline Long Covid ist nichts anderes als schwere Nebenwirkungen der Gentherapie!\"  \"@Karl_Lauterbach @focusonline Wer sch√ºtzt uns vor Long Lauterbach?\"\n\"@Karl_Lauterbach Also Karl, prim√§r fordere ich und viele andere eher erstmal dein sofortigen R√ºcktritt.\"  \"@Karl_Lauterbach Behalt deinen Senf f√ºr dich!\"                                                            \"@Karl_Lauterbach Oh Gott üò±\"     \n\"@Karl_Lauterbach Ach nein, der Clown mit Lebensangst ‚Ä¶.\\n\\nhttps://t.co/8cQZeHh6Ew\"                       \"@Karl_Lauterbach Ich kenne nur Leute mit Long Covid, die mehrfach geimpft sind! Das ist kein Witz! Scheinbar liegt‚Äôs wohl doch an den Spritzen???\"                                                            \"@Karl_Lauterbach @focusonline Interessiert keine Sau üòâ\"                      \n\"RT @Karl_Lauterbach @focusonline ‚ÄûLauterbachs Aussagen k√∂nnen fundamental nicht stimmen‚Äú\\nhttps://t.co/rfxnWAWiZX\"                                                                          \"@Karl_Lauterbach @focusonline ü§°üòÇüòÇüòÇüòÇüòÇüòÇ\"                                         \n\"@Karl_Lauterbach Jau und sie sind kein f√§higer Gesundheitsminister, sondern lediglich ein gekaufter Coronaminister\"        \nPuh, viele toxische Tweets, wie es scheint.\nUnd ohne Retweets (RT) und ohne Replies:\n\nkarl2 &lt;- search_tweets(\"@karl_lauterbach\", \n  include_rts = FALSE, `-filter` = \"replies\")\n\nTweets, die an Karl Lauterbach gerichtet sind, per API-Anweisung:\n\nkarl3 &lt;- search_tweets(\"to:karl_lauterbach\", n = 100)\n\n\"@Karl_Lauterbach Vielen Dank, dass LongCovid ein gefundenes fressen f√ºr die jenigen ist, die nicht mehr Arbeiten wollen.\"       \n \"@Karl_Lauterbach verpiss dich einfach! Immer dieser Schwachsinn\"    \n\"@Karl_Lauterbach @focusonline Das sind genau die Impfnebenwirkungen! Will man nun das wenden um die Impfnebenwirkungen zu vertuschen? \\nWof√ºr ist die Impfung gut wenn nicht mal Long-Covid verhindert wird, die Ansteckung konnte sie noch nie verhindern!\\nWarum sind 89% Covid Patienten geimpfte in den Spit√§ler?\"\n\"@Karl_Lauterbach Was spielen Sie eigentlich f√ºr ein schmutziges Spiel?\\n\\nhttps://t.co/8LJIzxyF7G\"   \n \"@Karl_Lauterbach @focusonline Bessen von Covid! St√§ndig wird das Netz durchsucht, nach Artikeln,die instrumentalisiert werden, um f√ºr Impfung zu werben. Was h√§tte nur ein vern√ºnftiger Gesundheitsminister mit so viel Zeit Vern√ºnftiges im Gesundheitswesen auf die Beine stellen k√∂nnen...\"    \n\"@Karl_Lauterbach Mit Dauerschaden wegen der Impfung üíâ bin ich Arbeitslos geworden in der Pflege ü§∑‚Äç‚ôÇÔ∏è Ist das normal Herr @Karl_Lauterbach ?\"          \nOb man mit @karl_lauterbach sucht oder `to:karl_lauterbach‚Äù, scheint keinen gro√üen Unterschied zu machen (?).\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/penguins-relationen/index.html",
    "href": "posts/penguins-relationen/index.html",
    "title": "penguins-relationen",
    "section": "",
    "text": "In dieser Aufgabe betrachten wir die Relationen einiger Ereignisse im Zusammenhang mit dem Datensatz penguins.\nSie k√∂nnen den Datensatz z.B. so importieren:\n\ndata(penguins, package = \"palmerpenguins\")  # Paket muss installiert sein\n\nSei das Ereignis \\(W\\) ein weiblicher Pinguin. Sei das Ereignis \\(S\\) ein ‚Äúschwerer‚Äù Pinguin, definiert als schwerer als der Median aller Pinguine (des Datensatzes). Sei \\(WS\\) ein weiblicher, schwerer Pinguin.\nBerechnen Sie folgende Wahrscheinlichkeiten, wobei wir den jeweiligen Anteil der Tiere als Wahrscheinlichkeit interpretieren.\n\n\n\n\n\\(Pr(W \\cup S)\\)\n\\(Pr(W \\cap S)\\)\n\\(Pr(\\neg S)\\)\n\\(Pr(\\neg W)\\)\n\\(Pr(W \\setminus WS)\\)\n\\(Pr(S \\setminus WS)\\)\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/penguins-relationen/index.html#hintergrund",
    "href": "posts/penguins-relationen/index.html#hintergrund",
    "title": "penguins-relationen",
    "section": "",
    "text": "In dieser Aufgabe betrachten wir die Relationen einiger Ereignisse im Zusammenhang mit dem Datensatz penguins.\nSie k√∂nnen den Datensatz z.B. so importieren:\n\ndata(penguins, package = \"palmerpenguins\")  # Paket muss installiert sein\n\nSei das Ereignis \\(W\\) ein weiblicher Pinguin. Sei das Ereignis \\(S\\) ein ‚Äúschwerer‚Äù Pinguin, definiert als schwerer als der Median aller Pinguine (des Datensatzes). Sei \\(WS\\) ein weiblicher, schwerer Pinguin.\nBerechnen Sie folgende Wahrscheinlichkeiten, wobei wir den jeweiligen Anteil der Tiere als Wahrscheinlichkeit interpretieren."
  },
  {
    "objectID": "posts/penguins-relationen/index.html#teilaufgaben",
    "href": "posts/penguins-relationen/index.html#teilaufgaben",
    "title": "penguins-relationen",
    "section": "",
    "text": "\\(Pr(W \\cup S)\\)\n\\(Pr(W \\cap S)\\)\n\\(Pr(\\neg S)\\)\n\\(Pr(\\neg W)\\)\n\\(Pr(W \\setminus WS)\\)\n\\(Pr(S \\setminus WS)\\)\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/penguins-relationen/index.html#a.-prw-cup-s",
    "href": "posts/penguins-relationen/index.html#a.-prw-cup-s",
    "title": "penguins-relationen",
    "section": "2.1 A. \\(Pr(W \\cup S)\\)",
    "text": "2.1 A. \\(Pr(W \\cup S)\\)\nDas logische ‚ÄúODER‚Äù wird vom |-Operator abgebildet in R:\n\npenguins |&gt; \n    filter(sex == \"female\" | body_mass_g &gt; weight_md) |&gt; \n    nrow()\n\n[1] 261\n\n\nDas sind 261 Zeilen von insgesamt 344:\n\nnrow(penguins)\n\n[1] 344\n\n\nAlso:\n\n261/344\n\n[1] 0.7587209\n\n\nDie Wahrscheinlichkeit liegt bei 76%."
  },
  {
    "objectID": "posts/penguins-relationen/index.html#b.-prw-cap-s",
    "href": "posts/penguins-relationen/index.html#b.-prw-cap-s",
    "title": "penguins-relationen",
    "section": "2.2 B. \\(Pr(W \\cap S)\\)",
    "text": "2.2 B. \\(Pr(W \\cap S)\\)\nDas logische ‚ÄúUND‚Äù wird vom &-Operator abgebildet in R:\n\nanzahl_w_und_s &lt;- \npenguins |&gt; \n    filter(sex == \"female\" & body_mass_g &gt; weight_md) |&gt; \n    nrow()\n\nanzahl_w_und_s\n\n[1] 53\n\n\nDas sind 53 Zeilen von insgesamt 344, also:\n\nanzahl_w_und_s/nrow(penguins)\n\n[1] 0.1540698"
  },
  {
    "objectID": "posts/penguins-relationen/index.html#c.-prneg-s",
    "href": "posts/penguins-relationen/index.html#c.-prneg-s",
    "title": "penguins-relationen",
    "section": "2.3 C. \\(Pr(\\neg S)\\)",
    "text": "2.3 C. \\(Pr(\\neg S)\\)\n\npenguins |&gt; \n    filter(body_mass_g &lt;= weight_md) |&gt; \n    nrow() / nrow(penguins)\n\n[1] 0.5610465"
  },
  {
    "objectID": "posts/penguins-relationen/index.html#d.-prneg-w",
    "href": "posts/penguins-relationen/index.html#d.-prneg-w",
    "title": "penguins-relationen",
    "section": "2.4 D. \\(Pr(\\neg W)\\)",
    "text": "2.4 D. \\(Pr(\\neg W)\\)\n\npenguins |&gt; \n    filter(sex != \"female\")  |&gt; \n    nrow() / nrow(penguins)\n\n[1] 0.4883721"
  },
  {
    "objectID": "posts/penguins-relationen/index.html#e.-prw-setminus-ws",
    "href": "posts/penguins-relationen/index.html#e.-prw-setminus-ws",
    "title": "penguins-relationen",
    "section": "2.5 E. \\(Pr(W \\setminus WS)\\)",
    "text": "2.5 E. \\(Pr(W \\setminus WS)\\)\nDie Logische Differenz bekommt man in R mit der Funktion setdiff.\n\nweiblich &lt;- penguins |&gt; filter(sex == \"female\")\n\nweiblich_schwer &lt;-  \n    penguins |&gt;\n    filter(sex == \"female\", body_mass_g &gt; weight_md)\n\nweiblich_minus_weiblichschwer &lt;- setdiff(weiblich, weiblich_schwer)\n\nweiblich_minus_weiblichschwer |&gt; \n    head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nfemale\n2007\n\n\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nfemale\n2007\n\n\nAdelie\nTorgersen\n36.6\n17.8\n185\n3700\nfemale\n2007\n\n\n\n\n\n\n\nweiblich_minus_weiblichschwer |&gt; \n    nrow() / nrow(penguins)\n\n[1] 0.3255814\n\n\nEs gibt mehrere Wege, die logische Differenz zu berechnen."
  },
  {
    "objectID": "posts/penguins-relationen/index.html#f.-prs-setminus-ws",
    "href": "posts/penguins-relationen/index.html#f.-prs-setminus-ws",
    "title": "penguins-relationen",
    "section": "2.6 F. \\(Pr(S \\setminus WS)\\)",
    "text": "2.6 F. \\(Pr(S \\setminus WS)\\)\n\nschwer &lt;- penguins |&gt; filter(body_mass_g &gt; weight_md)\n\nschwer_minus_weiblichschwer &lt;- setdiff(schwer, weiblich_schwer)\n\nschwer_minus_weiblichschwer |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.2\n19.6\n195\n4675\nmale\n2007\n\n\nAdelie\nTorgersen\n42.0\n20.2\n190\n4250\nNA\n2007\n\n\nAdelie\nTorgersen\n34.6\n21.1\n198\n4400\nmale\n2007\n\n\nAdelie\nTorgersen\n42.5\n20.7\n197\n4500\nmale\n2007\n\n\nAdelie\nDream\n39.8\n19.1\n184\n4650\nmale\n2007\n\n\nAdelie\nDream\n44.1\n19.7\n196\n4400\nmale\n2007\n\n\n\n\n\n\n\nschwer_minus_weiblichschwer |&gt; \n    nrow() / nrow(penguins)\n\n[1] 0.2790698"
  },
  {
    "objectID": "posts/penguins-relationen/index.html#hinweis",
    "href": "posts/penguins-relationen/index.html#hinweis",
    "title": "penguins-relationen",
    "section": "2.7 Hinweis",
    "text": "2.7 Hinweis\nDer Nenner der Wahrscheinlichkeit sollte die Anzahl aller Pinguine sein, f√ºr die alle relevanten Informationen verf√ºgbar sind. Da body_mass_g und sex f√ºr die gesamte Aufgabe relevant sind, sollten nur Tiere ohne fehlende Werte in diesen Spalten betrachtet werden.\n\npenguins_nona &lt;- penguins |&gt; drop_na(body_mass_g, sex)"
  },
  {
    "objectID": "posts/tidymodels-remove-na/tidymodels-remove-na.html",
    "href": "posts/tidymodels-remove-na/tidymodels-remove-na.html",
    "title": "tidymodels-remove-na",
    "section": "",
    "text": "Aufgabe\n\nErstellen Sie ein Rezept, dass die fehlenden Werte aus dem Datensatz penguins entfernt.\nHinweise:\n\nVerwenden Sie tidymodels.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_normalize(all_predictors()) |&gt; \n  step_naomit(all_predictors()) \n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrownames\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nyear\nbody_mass_g\nspecies_Chinstrap\nspecies_Gentoo\nisland_Dream\nisland_Torgersen\nsex_male\n\n\n\n\n-1.724511\n-0.8832047\n0.7843001\n-1.4162715\n-1.257484\n3750\n-0.4956416\n-0.7496652\n-0.7496652\n2.366233\n0.9895421\n\n\n-1.714456\n-0.8099390\n0.1260033\n-1.0606961\n-1.257484\n3800\n-0.4956416\n-0.7496652\n-0.7496652\n2.366233\n-1.0075337\n\n\n-1.704400\n-0.6634077\n0.4298326\n-0.4206603\n-1.257484\n3250\n-0.4956416\n-0.7496652\n-0.7496652\n2.366233\n-1.0075337\n\n\n-1.684289\n-1.3227986\n1.0881294\n-0.5628905\n-1.257484\n3450\n-0.4956416\n-0.7496652\n-0.7496652\n2.366233\n-1.0075337\n\n\n-1.674234\n-0.8465718\n1.7464261\n-0.7762357\n-1.257484\n3650\n-0.4956416\n-0.7496652\n-0.7496652\n2.366233\n0.9895421\n\n\n-1.664178\n-0.9198375\n0.3285561\n-1.4162715\n-1.257484\n3625\n-0.4956416\n-0.7496652\n-0.7496652\n2.366233\n-1.0075337\n\n\n\n\n\n\n\nlibrary(easystats)\ndescribe_distribution(d_train_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nrownames\n0.0183444\n0.9893218\n1.709428\n-1.7245110\n1.7245110\n0.0112758\n-1.1916974\n333\n0\n\n\nbill_length_mm\n0.0129796\n1.0016640\n1.694268\n-2.1653537\n2.8716604\n0.0453405\n-0.8834182\n333\n0\n\n\nbill_depth_mm\n0.0069350\n0.9971857\n1.569785\n-2.0514400\n2.2021701\n-0.1497203\n-0.8919598\n333\n0\n\n\nflipper_length_mm\n0.0036811\n0.9967324\n1.635647\n-2.0563073\n2.1394829\n0.3601480\n-0.9612410\n333\n0\n\n\nyear\n0.0158516\n0.9933867\n2.443924\n-1.2574843\n1.1864400\n-0.0772613\n-1.4826040\n333\n0\n\n\nbody_mass_g\n4207.0570571\n805.2158019\n1237.500000\n2700.0000000\n6300.0000000\n0.4722461\n-0.7334890\n333\n0\n\n\nspecies_Chinstrap\n0.0163725\n1.0122867\n0.000000\n-0.4956416\n2.0117218\n1.4741850\n0.1742318\n333\n0\n\n\nspecies_Gentoo\n-0.0064633\n0.9981442\n2.079716\n-0.7496652\n1.3300511\n0.5980072\n-1.6523478\n333\n0\n\n\nisland_Dream\n0.0185183\n1.0052525\n2.079716\n-0.7496652\n1.3300511\n0.5437762\n-1.7146419\n333\n0\n\n\nisland_Torgersen\n-0.0279365\n0.9720172\n0.000000\n-0.4213840\n2.3662335\n2.0707569\n2.3018230\n333\n0\n\n\nsex_male\n0.0000000\n1.0000000\n1.997076\n-1.0075337\n0.9895421\n-0.0181004\n-2.0117916\n333\n0\n\n\n\n\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/penguins-interact2/index.html",
    "href": "posts/penguins-interact2/index.html",
    "title": "penguins-interact2",
    "section": "",
    "text": "Eine Forscherin untersucht, ob das Geschlecht eines Pinguins den Einfluss der Flossenl√§nge (Flipper, mm) auf das K√∂rpergewicht (g) des Tieres moderiert.\nHinweise:\n\nNutzen Sie die folgende Analyse als Grundlage Ihrer Antworten.\nBeachten Sie die Hinweise des Datenwerks.\nUnter ‚Äúsubstanziell‚Äù sei ein Effekt von mind. 100 g verstanden.\n\n\n\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\nlibrary(ggpubr)\ndata(\"penguins\", package = \"palmerpenguins\")\n\nDaf√ºr ist folgende Analyse gegeben.\nWir entfernen zun√§chst alle fehlenden Werte:\n\npenguins_nona &lt;- \n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\")\n\npenguins_nona$sex |&gt; unique()\n\n[1] male   female\nLevels: female male\n\n\nZur besseren Interpretierbarkeit standardisieren wir die (metrische) UV und AV:\n\npenguins_nona_z &lt;- \n  penguins_nona |&gt; \n  standardise(select = c(\"flipper_length_mm\", \"body_mass_g\"),\n              append = TRUE)\n\n\nm_interaction &lt;- stan_glm(body_mass_g_z ~  sex + flipper_length_mm_z + sex:flipper_length_mm_z,  # Regressionsgleichung\n               data = penguins_nona_z, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm_interaction_params &lt;- parameters(m_interaction, ci_method = \"hdi\", ci = .9)\nm_interaction_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n-0.2162622\n0.9\n-0.2773580\n-0.1604693\n1.0000\n1.000844\n3367.317\nnormal\n0\n2.500000\n\n\nsexmale\n0.4308790\n0.9\n0.3469589\n0.5114735\n1.0000\n0.999997\n3702.528\nnormal\n0\n4.992690\n\n\nflipper_length_mm_z\n0.8210854\n0.9\n0.7553752\n0.8817705\n1.0000\n1.000643\n2564.870\nnormal\n0\n2.500000\n\n\nsexmale:flipper_length_mm_z\n-0.0059798\n0.9\n-0.0873804\n0.0805173\n0.5385\n1.001081\n2372.781\nnormal\n0\n3.346997\n\n\n\n\n\n\n\nplot(m_interaction_params)\n\n\n\n\n\n\n\n\n\nM√§nnliche Tiere sind im Schnitt leichter.\nEs liegt ein Interaktionseffekt vor; die Nullhypothese zum Interaktionseffekt kann verworfen werden.\nEs liegt kein Interaktionseffekt vor; die Nullhypothese zum Interaktionseffekt kann nicht verworfen werden.\nPro Einheit an Flossenl√§nge (flipper_lengh_mm_z) steigt das K√∂rpergewicht um ca. 0.8 Einheiten bei m√§nnlichen Tieren; bei weiblichen Tieren steigt es um ca. 0.4 + 0.8 = 1.2 Einheiten.\nPro SD-Einheit an Flossenl√§nge (flipper_lengh_mm_z) steigt das K√∂rpergewicht um ca. 0.8 SD-Einheiten bei m√§nnlichen Tieren; bei weiblichen Tieren steigt es um ca. 0.4 + 0.8 = 1.2 SD-Einheiten."
  },
  {
    "objectID": "posts/penguins-interact2/index.html#setup",
    "href": "posts/penguins-interact2/index.html#setup",
    "title": "penguins-interact2",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\nlibrary(ggpubr)\ndata(\"penguins\", package = \"palmerpenguins\")\n\nDaf√ºr ist folgende Analyse gegeben.\nWir entfernen zun√§chst alle fehlenden Werte:\n\npenguins_nona &lt;- \n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\")\n\npenguins_nona$sex |&gt; unique()\n\n[1] male   female\nLevels: female male\n\n\nZur besseren Interpretierbarkeit standardisieren wir die (metrische) UV und AV:\n\npenguins_nona_z &lt;- \n  penguins_nona |&gt; \n  standardise(select = c(\"flipper_length_mm\", \"body_mass_g\"),\n              append = TRUE)\n\n\nm_interaction &lt;- stan_glm(body_mass_g_z ~  sex + flipper_length_mm_z + sex:flipper_length_mm_z,  # Regressionsgleichung\n               data = penguins_nona_z, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm_interaction_params &lt;- parameters(m_interaction, ci_method = \"hdi\", ci = .9)\nm_interaction_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n-0.2162622\n0.9\n-0.2773580\n-0.1604693\n1.0000\n1.000844\n3367.317\nnormal\n0\n2.500000\n\n\nsexmale\n0.4308790\n0.9\n0.3469589\n0.5114735\n1.0000\n0.999997\n3702.528\nnormal\n0\n4.992690\n\n\nflipper_length_mm_z\n0.8210854\n0.9\n0.7553752\n0.8817705\n1.0000\n1.000643\n2564.870\nnormal\n0\n2.500000\n\n\nsexmale:flipper_length_mm_z\n-0.0059798\n0.9\n-0.0873804\n0.0805173\n0.5385\n1.001081\n2372.781\nnormal\n0\n3.346997\n\n\n\n\n\n\n\nplot(m_interaction_params)\n\n\n\n\n\n\n\n\n\nM√§nnliche Tiere sind im Schnitt leichter.\nEs liegt ein Interaktionseffekt vor; die Nullhypothese zum Interaktionseffekt kann verworfen werden.\nEs liegt kein Interaktionseffekt vor; die Nullhypothese zum Interaktionseffekt kann nicht verworfen werden.\nPro Einheit an Flossenl√§nge (flipper_lengh_mm_z) steigt das K√∂rpergewicht um ca. 0.8 Einheiten bei m√§nnlichen Tieren; bei weiblichen Tieren steigt es um ca. 0.4 + 0.8 = 1.2 Einheiten.\nPro SD-Einheit an Flossenl√§nge (flipper_lengh_mm_z) steigt das K√∂rpergewicht um ca. 0.8 SD-Einheiten bei m√§nnlichen Tieren; bei weiblichen Tieren steigt es um ca. 0.4 + 0.8 = 1.2 SD-Einheiten."
  },
  {
    "objectID": "posts/wrangle10/wrangle10.html",
    "href": "posts/wrangle10/wrangle10.html",
    "title": "wrangle10",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgende Tabelle:\n\ndf &lt;- tibble(\n  groesse = c(180, 190, 160, 170),\n  geschlecht = c(\"m\", \"m\", \"f\", \"f\")\n)\ndf\n\n\n\n\ngroesse\ngeschlecht\n\n\n\n\n180\nm\n\n\n190\nm\n\n\n160\nf\n\n\n170\nf\n\n\n\n\n\nHinweis: Der Befehl tibble erstellt einen Tibble (Dataframe).\nWas ist er erste Wert, den der folgende Ausdruck zur√ºckliefert?\n\ndf_grouped &lt;- group_by(df, geschlecht)\n\nsummarise(df_grouped, ergebnis = mean(groesse))\n\n         \n\n\nL√∂sung\nDie Werte werden alphabetisch (bzw. alphanumerisch) sortiert. ‚Äúf‚Äù kommt vor ‚Äúm‚Äù im Alphabet.\nAntwort: 165\n\ndf_grouped &lt;- group_by(df, geschlecht)\n\nsummarise(df_grouped, ergebnis = mean(groesse))\n\n\n\n\ngeschlecht\nergebnis\n\n\n\n\nf\n165\n\n\nm\n185\n\n\n\n\n\n\nCategories:\n\neda\nlagema√üe\nnum"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie XGB. Tunen Sie die Lernrate und die max. Tiefe (max_depth) des Modells.\n\n\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\n\n\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\n\n\n\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#daten",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#daten",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "",
    "text": "Verwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#av-und-uv",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#av-und-uv",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "",
    "text": "Die AV lautet c1. Die (einzige) UV lautet: text."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#hinweise",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#hinweise",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "",
    "text": "Orientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#setup",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#setup",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Setup",
    "text": "Setup\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\n\nlibrary(tictoc)\nlibrary(tidymodels)\n#library(syuzhet)\nlibrary(beepr)\nlibrary(finetune)  # anova race\nlibrary(lobstr)  # object size\nlibrary(visdat)  # footprint of csv\n#data(\"sentiws\", package = \"pradadata\")\n\nEine Vorlage f√ºr ein Tidymodels-Pipeline findet sich hier."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#learnermodell",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#learnermodell",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Learner/Modell",
    "text": "Learner/Modell\n\nmod &lt;-\n  boost_tree(mode = \"classification\",\n             learn_rate = tune(), \n             tree_depth = tune()\n             )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#gebackenen-datensatz-als-neue-grundlage",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#gebackenen-datensatz-als-neue-grundlage",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Gebackenen Datensatz als neue Grundlage",
    "text": "Gebackenen Datensatz als neue Grundlage\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz. Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind. Die Arbeit des Feature Engineering wurde uns schon abgenommen.\n\nd_train &lt;-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\n\nvis_dat(d_train) +\n  # remove axis labels:\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank() \n        )\n\n\nd_test_baked &lt;- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#plain-rezept",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#plain-rezept",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Plain-Rezept",
    "text": "Plain-Rezept\n\nrec &lt;- \n  recipe(c1 ~ ., data = d_train)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#neuer-workflow-mit-plainem-rezept",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#neuer-workflow-mit-plainem-rezept",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Neuer Workflow mit plainem Rezept",
    "text": "Neuer Workflow mit plainem Rezept\n\nwf &lt;-\n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#parallelisierung-√ºber-mehrere-kerne",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#parallelisierung-√ºber-mehrere-kerne",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Parallelisierung √ºber mehrere Kerne",
    "text": "Parallelisierung √ºber mehrere Kerne\n\nlibrary(parallel)\nall_cores &lt;- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl &lt;- makeCluster(3)\nplan(cluster, workers = cl)\n\nAchtung: Viele Kerne brauchen auch viel Speicher."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#tuneresamplefit",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#tuneresamplefit",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Tune/Resample/Fit",
    "text": "Tune/Resample/Fit\n\ntic()\nfit_wordvec_senti_xgb &lt;-\n  tune_race_anova(\n    wf,\n    grid = 30,\n    resamples = vfold_cv(d_train, v = 5),\n    control = control_race(verbose_elim = TRUE))\ntoc()\nbeep()\n\nObjekt-Gr√∂√üe:\n\nlobstr::obj_size(fit_wordvec_senti_xgb)\n\nGro√ü!\nWie wir gesehen haben, ist das Rezept riesig."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#get-best-performance",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#get-best-performance",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Get best performance",
    "text": "Get best performance\n\nautoplot(fit_wordvec_senti_xgb)\n\n\nshow_best(fit_wordvec_senti_xgb)\n\nbest_params &lt;- select_best(fit_wordvec_senti_xgb)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#finalisieren",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#finalisieren",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_params &lt;- select_best(fit_wordvec_senti_xgb)\ntic()\nwf_finalized &lt;- finalize_workflow(wf, best_params)\nlastfit_xgb &lt;- fit(wf_finalized, data = d_train)\ntoc()"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-xgb-tune/germeval-sent-wordvec-xgb-tune.html#test-set-g√ºte",
    "title": "germeval-sent-wordvec-xgb-tune",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\n\ntic()\npreds &lt;-\n  predict(lastfit_xgb, new_data = d_test_baked)\ntoc()\n\n\nd_test &lt;-\n  d_test_baked |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/supervisedlearning/supervisedlearning.html",
    "href": "posts/supervisedlearning/supervisedlearning.html",
    "title": "supervisedlearning",
    "section": "",
    "text": "Welches der folgenden Verfahren ist ein Vertreter des geleiteten Lernens (supervised learning)?\n\n\n\nClusteranalyse\nPCA\nAnalyse der Worth√§ufigkeit in Textmining-Analysen\nRandom Forest"
  },
  {
    "objectID": "posts/supervisedlearning/supervisedlearning.html#answerlist",
    "href": "posts/supervisedlearning/supervisedlearning.html#answerlist",
    "title": "supervisedlearning",
    "section": "",
    "text": "Clusteranalyse\nPCA\nAnalyse der Worth√§ufigkeit in Textmining-Analysen\nRandom Forest"
  },
  {
    "objectID": "posts/argumente/argumente.html",
    "href": "posts/argumente/argumente.html",
    "title": "argumente",
    "section": "",
    "text": "Welche der folgenden Syntax-Beispiele zeigt fehlerhaften Code?\nEs sei jeweils definiert:\n\nx &lt;- c(1, 2, 3)\n\n\n\n\nmean(x = x)\nmean(FALSE)\nmean(na.rm = FALSE, x = x)\nmean(x, 0, FALSE)"
  },
  {
    "objectID": "posts/argumente/argumente.html#answerlist",
    "href": "posts/argumente/argumente.html#answerlist",
    "title": "argumente",
    "section": "",
    "text": "mean(x = x)\nmean(FALSE)\nmean(na.rm = FALSE, x = x)\nmean(x, 0, FALSE)"
  },
  {
    "objectID": "posts/argumente/argumente.html#answerlist-1",
    "href": "posts/argumente/argumente.html#answerlist-1",
    "title": "argumente",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nR\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "chatgpt-sentiment-loop-all",
    "section": "",
    "text": "Fragen Sie ChatGPT via API zum Sentiment der Texte aus dem Germeval-2018-Datensatz (Test).\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab √ºber die Preise von OpenAI. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen. Sie k√∂nnen unter https://platform.openai.com/usage Ihre Kosten pr√ºfen."
  },
  {
    "objectID": "posts/index.html#achtung",
    "href": "posts/index.html#achtung",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Achtung",
    "text": "Achtung\n\nOpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî \\(\\square\\)"
  },
  {
    "objectID": "posts/index.html#setup",
    "href": "posts/index.html#setup",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Setup",
    "text": "Setup\nDie richtige venv nutzen:\n\nlibrary(reticulate)\n#virtualenv_create(\"chatgpt\")\nuse_virtualenv(\"chatgpt\")\n\nCheck zu Python:\n\nreticulate::py_config()\n\nGgf. noch Module installieren:\n\n#reticulate::py_install(\"pandas\")\n#py_install(\"tiktoken\")\n#py_install(\"datar\")\n#py_install(\"scikit-learn\")"
  },
  {
    "objectID": "posts/index.html#r-pakete-und-python-module",
    "href": "posts/index.html#r-pakete-und-python-module",
    "title": "chatgpt-sentiment-loop-all",
    "section": "R-Pakete und Python-Module",
    "text": "R-Pakete und Python-Module\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(plotly)\n\nModule importieren:\n\nfrom openai import OpenAI\nimport pandas as pd\nimport numpy as np\nimport time\nfrom datetime import datetime\n#from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nVersionen der importierten Module:\n\npd.__version__\n\n\n```{zsh openai-version-zsh}\npip list | grep openai\n```\n\nWir brauchen &gt;= 1.35.\nDer Operator | ist die ‚ÄúPfeife‚Äù der Kommandozeile, also sozusagen der ‚ÄúUND-DANN-Befehl‚Äù."
  },
  {
    "objectID": "posts/index.html#daten",
    "href": "posts/index.html#daten",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Daten",
    "text": "Daten\nDaten importieren:\n\ncsv_file_path_test = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv'\n\ngermeval_test = pd.read_csv(csv_file_path_test)\n\nDie ersten paar Texte herausziehen:\n\nstart_pos = 0\nend_pos = 3531\ntweets = germeval_test[\"text\"].iloc[start_pos:(end_pos+1)].tolist()"
  },
  {
    "objectID": "posts/index.html#prompt",
    "href": "posts/index.html#prompt",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Prompt",
    "text": "Prompt\nPrompt definieren:\n\nprompt_stem  = \"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes einzusch√§tzen. Bitte antworten Sie nur mit einem einzigen Wort, entweder 'positiv', 'neutral' oder 'negativ'. Ihre Antwort soll Ihre Insgesamt-Einsch√§tzung zum Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folgt der Text, dessen Sentiment Sie einsch√§tzen sollen: \"\n\nGute Prompts k√∂nnen helfen, gute Antworten vom Modell zu erhalten.\nMit ‚ÄúList Comprehension‚Äù k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:\n\nprompts = [prompt_stem + tweet for tweet in tweets]\nprompts[0]\n\nCheck: Wie viele Elemente hat die Liste prompts?\n\nlen(prompts)\n\nLaut OpenAI kostet 1k Token f√ºr das Modell gpt-3.5-turbo-1106 $0.001."
  },
  {
    "objectID": "posts/index.html#authentifizieren",
    "href": "posts/index.html#authentifizieren",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Authentifizieren",
    "text": "Authentifizieren\nAnmelden bei OpenAI:\n\nclient = OpenAI()\n\n\n\n\n\n\n\nNote\n\n\n\nDieses Anmeldeverfahren setzt voraus, dass in .Renviron die Variable OPENAI_API_KEY hinterlegt ist. \\(\\square\\)\n\n\nAnfrage an die API, in eine Funktion gepackt:\n\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n    model=model,\n    messages=messages,\n    max_tokens=50,\n    temperature=0,\n  )\n  return response.choices[0].message.content"
  },
  {
    "objectID": "posts/index.html#api-anfragen",
    "href": "posts/index.html#api-anfragen",
    "title": "chatgpt-sentiment-loop-all",
    "section": "API anfragen",
    "text": "API anfragen\nUnd jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:\n\npredicted_values = []\n\n\nstart_time = time.time()\n\nfor prompt in prompts:\n  result = get_completion(prompt, client) \n  predicted_values.append(result)\n\nend_time = time.time()\nend_time - start_time\n\nVoil√†:\n\nprint(predicted_values[:5])"
  },
  {
    "objectID": "posts/index.html#als-csv-speichern",
    "href": "posts/index.html#als-csv-speichern",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Als CSV speichern",
    "text": "Als CSV speichern\n\nid_seq = [i for i in range(start_pos, end_pos + 1)]\npredicted_values_df = pd.DataFrame(id_seq, columns = [\"id\"])\npredicted_values_df[\"pred\"] = predicted_values\n\nnow = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\ncsv_output_name = \"germeval_test_preds_at_\" + now\npredicted_values_df.to_csv(csv_output_name)"
  },
  {
    "objectID": "posts/index.html#oder-vorhersagen-aus-csv-importieren",
    "href": "posts/index.html#oder-vorhersagen-aus-csv-importieren",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Oder Vorhersagen aus CSV importieren",
    "text": "Oder Vorhersagen aus CSV importieren\n\npreds_path = 'https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/posts/chatgpt-sentiment-loop-all/germeval_test_preds_at_2023-12-20%2014%3A06%3A00'\n\npreds = pd.read_csv(preds_path)\n\npreds.head()\n\nMan kann eine Python-Variable an R √ºbergeben:\n\npreds_r &lt;- py$preds"
  },
  {
    "objectID": "posts/index.html#vorhersagen-predictions-betrachten",
    "href": "posts/index.html#vorhersagen-predictions-betrachten",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Vorhersagen (Predictions) betrachten",
    "text": "Vorhersagen (Predictions) betrachten\nZ√§hlen wir mal kurz aus:\n\npreds_r |&gt; \n  count(pred) |&gt; \n  slice(3:5)  # zwei komische, kaputte Zeilen, weg damit\n\nOder in Python:\n\npreds[\"pred\"].value_counts()\n\nPuh, das ist ein bisschen was kaput gegangen."
  },
  {
    "objectID": "posts/index.html#predictions-reparieren",
    "href": "posts/index.html#predictions-reparieren",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Predictions reparieren",
    "text": "Predictions reparieren\n\nallowed_preds = [\"positiv\", \"neutral\", \"negativ\"]\npreds.loc[~preds[\"pred\"].isin(allowed_preds), \"pred\"] = np.nan\n\nCheck:\n\npreds[\"pred\"].value_counts()\n\nPasst!"
  },
  {
    "objectID": "posts/index.html#scoring-vorbereiten",
    "href": "posts/index.html#scoring-vorbereiten",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Scoring vorbereiten",
    "text": "Scoring vorbereiten\nWas waren noch mal die Variablen unser Tabelle?\n\ngermeval_test.columns\n\nDie ersten paar Werte:\n\ngermeval_test.head()\n\nRescore im Test-Set:\n\ndf = germeval_test\ndf[\"c1\"] = df[\"c1\"].replace({\"OFFENSE\": \"negativ\"})\n\ndf[\"c1\"].value_counts()\n\nRescore in den Vorhersagen\n\npreds[\"pred\"] = preds[\"pred\"].replace({\"neutral\": \"OTHER\", \"positiv\": \"OTHER\"})\n\npreds[\"pred\"].value_counts()\n\n\npreds_list = preds[\"pred\"].tolist()\n\nHier ist die Liste der wahren Werte:\n\ny = df[\"c1\"].values.tolist()"
  },
  {
    "objectID": "posts/index.html#scoring",
    "href": "posts/index.html#scoring",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Scoring",
    "text": "Scoring\n\naccuracy = accuracy_score(y, preds_list)\nprint(\"Accuracy:\", accuracy)\n\nOder mit tidymodels; zuerst aufbereiten:\n\ny_truth = as.factor(py$y)\ny_pred = py$preds_list \n\n# replace NAN with NA and convert to factor:\ny_pred = as.character(y_pred) \ny_pred[is.nan(y_pred)] &lt;- NA\ny_pred[!y_pred %in% c(\"negativ\", \"OTHER\")] &lt;- NA\ny_pred &lt;- as.factor(y_pred)\n\ntable(y_pred)\n\n\naccuracy_vec(truth = y_truth,\n             estimate = y_pred)"
  },
  {
    "objectID": "posts/index.html#fun",
    "href": "posts/index.html#fun",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Fun",
    "text": "Fun\n\nfig &lt;- plot_ly(\n  domain = list(x = c(0, 1), y = c(0, 1)),\n  value = 74,\n  title = list(text = \"Accuracy\"),\n  type = \"indicator\",\n  mode = \"gauge+number\") \nfig &lt;- fig %&gt;%\n  layout(margin = list(l=20,r=30))\n\nfig"
  },
  {
    "objectID": "posts/tmdb07/tmdb07.html",
    "href": "posts/tmdb07/tmdb07.html",
    "title": "tmdb07",
    "section": "",
    "text": "Aufgabe\nMelden Sie sich an f√ºr die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?.\nSie ben√∂tigen dazu ein Konto; es ist auch m√∂glich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Pr√§diktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verf√ºgung. Eine klassische ‚Äúpredictive Competition‚Äù also :-) Allerdings k√∂nnen immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Lineares-Modell mit Regularisierung mit Tidymodels!\nHinweise\n\n\nVerzichten Sie auf Vorverarbeitung.\nTunen Sie die typischen Parameter.\nReichen Sie das Modell ein und berichten Sie Ihren Score.\nBegrenzen Sie sich auf folgende Pr√§diktoren.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\")\n\n         \n\n\nL√∂sung\n\n\nPakete starten\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(finetune)\nlibrary(doParallel)\nlibrary(tictoc)\n\n\n\nDaten importieren\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nWerfen wir einen Blick in die Daten:\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1‚Ä¶\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C‚Ä¶\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00‚Ä¶\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '‚Ä¶\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht‚Ä¶\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148‚Ä¶\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", ‚Ä¶\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In‚Ä¶\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807‚Ä¶\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh‚Ä¶\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam‚Ä¶\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of‚Ä¶\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/‚Ä¶\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119‚Ä¶\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'‚Ä¶\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol‚Ä¶\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96‚Ä¶\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'‚Ä¶\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep‚Ä¶\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,‚Ä¶\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, ‚Ä¶\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pok√©mon Collection', 'p‚Ä¶\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06‚Ä¶\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n‚Ä¶\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-‚Ä¶\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595‚Ä¶\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", ‚Ä¶\n$ original_title        &lt;chr&gt; \"„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§\", \"Attack of the 50 Foot Wom‚Ä¶\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco‚Ä¶\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680‚Ä¶\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1‚Ä¶\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',‚Ä¶\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3‚Ä¶\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11‚Ä¶\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,‚Ä¶\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_‚Ä¶\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B‚Ä¶\n$ title                 &lt;chr&gt; \"Pok√©mon: The Rise of Darkrai\", \"Attack of the 5‚Ä¶\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok‚àö¬©mon'}, {'id': 1155‚Ä¶\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i‚Ä¶\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep‚Ä¶\n\n\n\n\nResampling / Cross-Validation-Scheme\n\ncv_scheme &lt;- vfold_cv(d_train)\n\nKleine Werte f√ºr \\(v\\) wie \\(v=3\\) kann man w√§hlen, um Rechenzeit zu sparen. Das ist gerade f√ºrs Debuggen n√ºtzlich. F√ºr die ‚ÄúWirklichkeit‚Äù ist ein h√∂herer Wert besser, z.B. \\(v=10\\) (der Defaultwert)\n\n\nRezept\n\nrec1 &lt;- \n  recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_naomit(all_predictors()) \nrec1\n\n\n\nModell\n\nmodel_lm &lt;- linear_reg(penalty = tune(),\n                       engine = \"glmnet\")\n\n\n\nWorkflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model_lm) %&gt;% \n  add_recipe(rec1)\n\n\n\nModell fitten (und tunen)\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\nlm_fit1 &lt;-\n  wf1 %&gt;% \n  tune_race_anova(resamples = cv_scheme)\ntoc()\n\n23.469 sec elapsed\n\n\n\nlm_fit1 %&gt;% show_best()\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0e+00\nrmse\nstandard\n85402528\n10\n2766934\npre0_mod01_post0\n\n\n0.0e+00\nrmse\nstandard\n85402528\n10\n2766934\npre0_mod02_post0\n\n\n0.0e+00\nrmse\nstandard\n85402528\n10\n2766934\npre0_mod03_post0\n\n\n4.0e-07\nrmse\nstandard\n85402528\n10\n2766934\npre0_mod04_post0\n\n\n4.1e-06\nrmse\nstandard\n85402528\n10\n2766934\npre0_mod05_post0\n\n\n\n\n\n\n\n\nFinalisieren\n\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(lm_fit1, metric = \"rmse\"))\n\n\n\nFinal Fit\n\nfit1_final &lt;-\n  wf1_final %&gt;% \n  fit(d_train)\n\nfit1_final\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: linear_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_impute_bag()\n‚Ä¢ step_naomit()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\") \n\n   Df  %Dev    Lambda\n1   0  0.00 103500000\n2   1  9.63  94340000\n3   1 17.62  85960000\n4   1 24.25  78320000\n5   1 29.76  71370000\n6   1 34.33  65030000\n7   1 38.13  59250000\n8   1 41.28  53990000\n9   1 43.90  49190000\n10  1 46.07  44820000\n11  2 48.25  40840000\n12  2 50.48  37210000\n13  2 52.34  33900000\n14  2 53.88  30890000\n15  2 55.15  28150000\n16  2 56.21  25650000\n17  2 57.09  23370000\n18  2 57.82  21290000\n19  2 58.43  19400000\n20  2 58.93  17680000\n21  2 59.35  16110000\n22  2 59.70  14680000\n23  2 59.99  13370000\n24  2 60.23  12180000\n25  2 60.42  11100000\n26  2 60.59  10120000\n27  2 60.73   9217000\n28  2 60.84   8398000\n29  2 60.93   7652000\n30  2 61.01   6973000\n31  2 61.08   6353000\n32  2 61.13   5789000\n33  2 61.18   5274000\n34  2 61.21   4806000\n35  3 61.25   4379000\n36  3 61.29   3990000\n37  3 61.32   3635000\n38  3 61.34   3313000\n39  3 61.36   3018000\n40  3 61.38   2750000\n41  3 61.39   2506000\n42  3 61.40   2283000\n43  3 61.41   2080000\n44  3 61.42   1896000\n45  3 61.43   1727000\n46  3 61.43   1574000\n\n...\nand 12 more lines.\n\n\n\npreds &lt;-\n  fit1_final %&gt;% \n  predict(d_test)\n\n\n\nSubmission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n\n\n\n\nid\nrevenue\n\n\n\n\n3001\n-3509004.0\n\n\n3002\n-7713242.9\n\n\n3003\n8857020.3\n\n\n3004\n31400207.8\n\n\n3005\n101087.7\n\n\n3006\n13470032.2\n\n\n\n\n\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\n\n\nKaggle Score\nDiese Submission erzielte einen Score von Score: 6.14787 (RMSLE).\n\nsol &lt;- 6.14787\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nnum"
  },
  {
    "objectID": "posts/Ridges-vergleichen/Ridges-vergleichen.html",
    "href": "posts/Ridges-vergleichen/Ridges-vergleichen.html",
    "title": "Ridges-vergleichen",
    "section": "",
    "text": "Die Mittelwerte der Histogramme sind identisch.\nDie Mediane der Histogramme sind identisch.\nDie Histogramme sind (alle) linksschief.\nDie Histogramme sind (alle) rechtsschief.\nDie F√§rbung (F√ºllfarbe) kodiert die Schliffart (cut).\nEinige Histogramme sind normalverteilt."
  },
  {
    "objectID": "posts/Ridges-vergleichen/Ridges-vergleichen.html#answerlist",
    "href": "posts/Ridges-vergleichen/Ridges-vergleichen.html#answerlist",
    "title": "Ridges-vergleichen",
    "section": "",
    "text": "Die Mittelwerte der Histogramme sind identisch.\nDie Mediane der Histogramme sind identisch.\nDie Histogramme sind (alle) linksschief.\nDie Histogramme sind (alle) rechtsschief.\nDie F√§rbung (F√ºllfarbe) kodiert die Schliffart (cut).\nEinige Histogramme sind normalverteilt."
  },
  {
    "objectID": "posts/Ridges-vergleichen/Ridges-vergleichen.html#answerlist-1",
    "href": "posts/Ridges-vergleichen/Ridges-vergleichen.html#answerlist-1",
    "title": "Ridges-vergleichen",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\nvis\ndyn\nschoice"
  },
  {
    "objectID": "posts/exp1/index.html",
    "href": "posts/exp1/index.html",
    "title": "exp1",
    "section": "",
    "text": "1 Aufgabe\nDie Expontentialverteilung ist eine h√§ufig verwendete Verteilung in der Statistik. Sie kann verwendet werden, um Streuungen zu modellieren.\nWelche der folgenden Aussagen zur Exponentialverteilung sind korrekt?\nA. Die Exponentialverteilung ist eine stetige Verteilung.\nB. Die Exponentialverteilung ist nur f√ºr nicht-negative Werte definiert.\nC. Die Exponentialverteilung ist symmetrisch.\nD. Die Exponentialverteilung hat nur einen Parameter.\nE. Die Exponentialverteilung ist streng monoton fallend.\n  \n  \n  \n  \n\n\n2 L√∂sung\nA. Die Exponentialverteilung ist eine stetige Verteilung. RICHTIG\nB. Die Exponentialverteilung ist nur f√ºr nicht-negative Werte definiert. RICHTIG\nC. Die Exponentialverteilung ist symmetrisch. FALSCH\nD. Die Exponentialverteilung hat nur einen Parameter. RICHTIG\nE. Die Exponentialverteilung ist streng monoton fallend. RICHTIG\nHier ist ein Beispiel f√ºr eine Exponentialverteilung mit dem Parameterwert \\(\\lambda = 0.1\\):"
  },
  {
    "objectID": "posts/log-y-regr2/log-y-regr2.html",
    "href": "posts/log-y-regr2/log-y-regr2.html",
    "title": "log-y-regression2",
    "section": "",
    "text": "Exercise\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nIn dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zun√§chst den Datensatz und verschaffen Sie sich einen √úberblick.\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\"\n\nd &lt;- data_read(d_path)\n\nDokumentation und Quellenangaben zum Datensatz finden sich hier.\n\nglimpse(d)\n\nRows: 2,675\nColumns: 11\n$ rownames &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18‚Ä¶\n$ treat    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ age      &lt;int&gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 2‚Ä¶\n$ educ     &lt;int&gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12‚Ä¶\n$ ethn     &lt;chr&gt; \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\"‚Ä¶\n$ married  &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,‚Ä¶\n$ re74     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ re75     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ re78     &lt;dbl&gt; 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 2‚Ä¶\n$ u74      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ u75      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n\n\nModellieren Sie den Effekt der Bildungsdauer auf das Einkommen! Gehen Sie von einem exponenziellen Zusammenhang der beiden Variablen aus. Wie ver√§ndert sich die Verteilung der abh√§ngigen Variablen (Y) durch die Logarithmus-Transformation?\nHinweise:\n\nVerwenden Sie lm zur Modellierung.\nOperationalisieren Sie das Einkommen mit der Variable re74.\nF√ºgen Sie keine weiteren Variablen dem Modell hinzu.\nGehen Sie von einem kausalen Effekt des Pr√§diktors aus.\n\n         \n\n\nSolution\n\nd2 &lt;-\n  d %&gt;% \n  filter(re74 &gt; 0) %&gt;% \n  mutate(re74_log = log(re74))\n\n\nm &lt;- lm(re74_log ~ educ, data = d2)\n\n\nggplot(d2) +\n  aes(x = re74) +\n  geom_density() +\n  labs(title = \"Income raw\")\n\n\nggplot(d2) +\n  aes(x = re74_log) +\n  geom_density() +\n  labs(title = \"Income log transformed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBetrachten wir die deskriptiven Statistiken:\n\nd2 %&gt;% \n  select(re74, re74_log) %&gt;% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nre74\n20938.281236\n1.263152e+04\n1.508630e+04\n17.633400\n137149.00000\n1.621495\n6.808108\n2329\n0\n\n\nre74_log\n9.733938\n7.596623e-01\n7.985049e-01\n2.869795\n11.82882\n-1.667429\n6.009968\n2329\n0\n\n\n\n\n\n\nDie Log-Transformation hat in diesem Fall nicht wirklich zu einer Normalisierung der Variablen beigetragen. Aber das war auch nicht unser Ziel.\n\nCategories:\n\nregression\nlm\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/globus3/index.html",
    "href": "posts/globus3/index.html",
    "title": "globus3",
    "section": "",
    "text": "1 Aufgabe\nWir werfen einen Globus \\(n=9\\) Mal und erzielen \\(W=6\\) mal das Ereignis ‚ÄúWasser‚Äù.\nWas ist die Wahrscheinlichkeit dieses Ereignisses, wenn wir von einer Wasseranteil, d.h. Wahrscheinlichkeit, von \\(\\pi=1\\) ausgehen?\n  \n  \n  \n  \n\n\n2 L√∂sung\nHier sind die gegebenen Werte:\n\nW &lt;- 6\nn &lt;- 9\npi &lt;- 1\n\nWir suchen also diese Gr√∂√üe:\n\\[Pr(W=6 | \\pi=1, n=9) = ?\\]\nWir k√∂nnen R die Arbeit machen lassen:\n\n\n\n\nListing¬†1: Binomialverteilung mit R\n\n\nloesung &lt;- dbinom(x = W, size = n, prob = pi)\nloesung\n\n\n\n\n[1] 0\n\n\nOder den Taschenrechner nutzen:\n\nloesung &lt;- choose(n,W) * pi^W * (1-pi)^(n-W)\nloesung\n\n[1] 0\n\n\nDie Harten unter uns rechnen es per Hand aus.\nDaf√ºr kann man zun√§chst die Anzahl der Pfade mit dem Binomialkoeffizienten berechnen:\n\nanzahl_pfade &lt;- factorial(n) / (factorial(W) * factorial(n-W))\nanzahl_pfade\n\n[1] 84\n\n\nfactorial(W) liefert die Fakult√§t von \\(W\\) zur√ºck.\nDann berechnet man die Wahrscheinlichkeit eines einzelnen Pfades:\n\npfad_wskt &lt;-  pi^W * (1-pi)^(n-W)\npfad_wskt\n\n[1] 0\n\n\nMultipliziert man die beiden vorherigen Zwischenergebnisse, so erh√§lt man die L√∂sung:\n\nloesung &lt;-  anzahl_pfade * pfad_wskt\nloesung\n\n[1] 0"
  },
  {
    "objectID": "posts/kausal27/kausal27.html",
    "href": "posts/kausal27/kausal27.html",
    "title": "kausal27",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber 7 Variablen, die als Knoten im Graph dargestellt sind (mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet) und √ºber Kanten verbunden sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x1.\nAV: x3.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben.\n\n\n\n\n{ x2, x4 }\n/\n{ }\n{ x4, x7 }\n{ x3, x5 }"
  },
  {
    "objectID": "posts/kausal27/kausal27.html#answerlist",
    "href": "posts/kausal27/kausal27.html#answerlist",
    "title": "kausal27",
    "section": "",
    "text": "{ x2, x4 }\n/\n{ }\n{ x4, x7 }\n{ x3, x5 }"
  },
  {
    "objectID": "posts/kausal27/kausal27.html#answerlist-1",
    "href": "posts/kausal27/kausal27.html#answerlist-1",
    "title": "kausal27",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/tidymodels-penguins04/tidymodels-penguins04.html",
    "href": "posts/tidymodels-penguins04/tidymodels-penguins04.html",
    "title": "tidymodels-penguins04",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=2 CV.\nTunen Sie \\(K\\) (Default-Tuning)\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs pr√ºfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\nAuf NA pr√ºfen:\n\nsum(is.na(d_baked))\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5, repeats = 2)\nfolds\n\nTunen:\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE)\n  )\n\nd_resamples\n\nBester Kandidat:\n\nshow_best(d_resamples)\n\n\nfitbest &lt;- fit_best(d_resamples)\nfitbest\n\nLast Fit:\n\nfit_last &lt;- last_fit(fitbest, d_split)\nfit_last\n\nModellg√ºte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins03/tidymodels-penguins03.html",
    "href": "posts/tidymodels-penguins03/tidymodels-penguins03.html",
    "title": "tidymodels-penguins03",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=1 CV.\nTunen Sie \\(K\\) (Default-Tuning)\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs pr√ºfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\nAuf NA pr√ºfen:\n\nsum(is.na(d_baked))\n\nCV:\n\nset.seed(43)\nfolds &lt;- vfold_cv(d_train, v = 5)\nfolds\n\nTunen:\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE)\n  )\n\nd_resamples\n\nBester Kandidat:\n\nshow_best(d_resamples)\n\n\nfitbest &lt;- fit_best(d_resamples)\nfitbest\n\nLast Fit:\n\nfit_last &lt;- last_fit(fitbest, d_split)\nfit_last\n\nModellg√ºte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/kausal20/kausal20.html",
    "href": "posts/kausal20/kausal20.html",
    "title": "kausal20",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x3.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x2, x4 }\n{ x4 }\n{ x1, x4 }\n{ x2 }\n{ x2, x5 }"
  },
  {
    "objectID": "posts/kausal20/kausal20.html#answerlist",
    "href": "posts/kausal20/kausal20.html#answerlist",
    "title": "kausal20",
    "section": "",
    "text": "{ x2, x4 }\n{ x4 }\n{ x1, x4 }\n{ x2 }\n{ x2, x5 }"
  },
  {
    "objectID": "posts/kausal20/kausal20.html#answerlist-1",
    "href": "posts/kausal20/kausal20.html#answerlist-1",
    "title": "kausal20",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nRichtig\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/interpret-koeff-lm/interpret-koeff-lm.html",
    "href": "posts/interpret-koeff-lm/interpret-koeff-lm.html",
    "title": "interpret-koeff-lm",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie dieses Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars):\n\ndata(mtcars)\nlibrary(easystats)\nlm1 &lt;- lm(mpg ~ hp, data = mtcars)\nparameters(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\n\n\n\n\n(Intercept)\n30.0988605\n1.6339210\n0.95\n26.7619488\n33.4357723\n18.421246\n30\n0e+00\n\n\nhp\n-0.0682283\n0.0101193\n0.95\n-0.0888947\n-0.0475619\n-6.742388\n30\n2e-07\n\n\n\n\n\n\n\nWas bedeuten die Koeffizienten?\nWie ist der Effekt von \\(\\beta_1\\) zu interpretieren?\n\n         \n\n\nL√∂sung\n\nIntercept (\\(\\beta_0\\)): Der Achsenabschnitt gibt den gesch√§tzten mittleren Y-Wert (Spritverbrauch) an, wenn \\(x=0\\), also f√ºr ein Auto mit 0 PS (was nicht wirklich Sinn macht). hp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und damit die Steigung der Regressionsgeraden.\nhp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und gibt den statistischen ‚ÄúEffekt‚Äù der PS-Zahl auf den Spritverbrauch an. Vorsicht: Dieser ‚ÄúEffekt‚Äù darf nicht vorschnell als kausaler Effekt verstanden werden. Daher muss man vorsichtig sein, wenn man von einem ‚ÄúEffekt‚Äù spricht. Vorsichtiger w√§re zu sagen: ‚ÄúEin Auto mit einem PS mehr, kommt im Mittel 0,1 Meilen weniger weit mit einer Gallone Sprit, laut diesem Modell‚Äù.\n\n\nCategories:\n\nregression\nlm\nstring"
  },
  {
    "objectID": "posts/groesse04/index.html",
    "href": "posts/groesse04/index.html",
    "title": "groesse04",
    "section": "",
    "text": "Wir interessieren uns f√ºr die typische K√∂rpergr√∂√üe deutscher Studentis. Hier findet sich dazu der Datensatz wo_men.\nWir wollen die Forschungsfrage untersuchen, wie gro√ü deutsche Studentis im Schnitt sind.\nDiese Verteilung (typische K√∂rpergr√∂√üe erwachsener M√§nner) nehmen wir an mit \\(\\mu \\sim N(178.4, 7.6)\\).\n\nQuelle: K√∂rpergr√∂√üe M√§nner\nSiehe auch hier zur K√∂rpergr√∂√üe der M√§nner\nAufgabe: Wie breit ist das 95%-ETI f√ºr die K√∂rpergr√∂√üe der (m√§nnlichen) Studenten (in der Post-Verteilung)? Geben Sie die Zahl in Zentimetern an!\nHinweise:\n\nVerwenden Sie die Daten wie in dieser Aufgabe angegeben.\nGehen Sie von einer Normalverteilung aus.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n\n\n\n\nlibrary(pradadata)  # f√ºr den Datensatz `wo_men`\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n\nDaten importieren:\n\ndata(wo_men)\n\nAlternativ per URL:\n\nwo_men &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/wo_men.csv\")\n\nMittelwert in der Stichprobe:\n\nmen &lt;- \nwo_men |&gt; \n  filter(height &lt; 210, height &gt; 150) |&gt; \n  filter(sex == \"man\") |&gt; \n  drop_na()\n\nmen |&gt;  \n  summarise(height_avg = mean(height, na.rm = TRUE),\n            height_sd = sd(height, na.rm = TRUE))\n\n\n\n\n\nheight_avg\nheight_sd\n\n\n\n\n183.1111\n9.958082\n\n\n\n\n\n\n\nmen |&gt; \n  ggdensity(x = \"height\", fill = \"sex\")\n\n\n\n\n\n\n\n\nHm, ob da alle M√§nner ihre Gr√∂√üe korrekt angegeben haben?\n\n\n\n\nm1 &lt;- stan_glm(height ~ 1, data = men,\n               refresh = 0,\n               prior_intercept = normal(178.4, 7.6),\n               prior_aux = exponential(0.125))\n\nModellparameter:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n182.65\n(178.01, 187.25)\n100%\n1.002\n1972.00\nNormal (178.40 +- 7.60)\n\n\n\n\n\nVisualisierung der Post-Verteilung (HDI, 95%):\n\n\n\n\n\n\n\n\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/groesse04/index.html#hintergrund-und-forschungsfrage",
    "href": "posts/groesse04/index.html#hintergrund-und-forschungsfrage",
    "title": "groesse04",
    "section": "",
    "text": "Wir interessieren uns f√ºr die typische K√∂rpergr√∂√üe deutscher Studentis. Hier findet sich dazu der Datensatz wo_men.\nWir wollen die Forschungsfrage untersuchen, wie gro√ü deutsche Studentis im Schnitt sind.\nDiese Verteilung (typische K√∂rpergr√∂√üe erwachsener M√§nner) nehmen wir an mit \\(\\mu \\sim N(178.4, 7.6)\\).\n\nQuelle: K√∂rpergr√∂√üe M√§nner\nSiehe auch hier zur K√∂rpergr√∂√üe der M√§nner\nAufgabe: Wie breit ist das 95%-ETI f√ºr die K√∂rpergr√∂√üe der (m√§nnlichen) Studenten (in der Post-Verteilung)? Geben Sie die Zahl in Zentimetern an!\nHinweise:\n\nVerwenden Sie die Daten wie in dieser Aufgabe angegeben.\nGehen Sie von einer Normalverteilung aus.\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/groesse04/index.html#setup",
    "href": "posts/groesse04/index.html#setup",
    "title": "groesse04",
    "section": "",
    "text": "library(pradadata)  # f√ºr den Datensatz `wo_men`\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstanarm)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/groesse04/index.html#daten-der-stichprobe",
    "href": "posts/groesse04/index.html#daten-der-stichprobe",
    "title": "groesse04",
    "section": "",
    "text": "Daten importieren:\n\ndata(wo_men)\n\nAlternativ per URL:\n\nwo_men &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/wo_men.csv\")\n\nMittelwert in der Stichprobe:\n\nmen &lt;- \nwo_men |&gt; \n  filter(height &lt; 210, height &gt; 150) |&gt; \n  filter(sex == \"man\") |&gt; \n  drop_na()\n\nmen |&gt;  \n  summarise(height_avg = mean(height, na.rm = TRUE),\n            height_sd = sd(height, na.rm = TRUE))\n\n\n\n\n\nheight_avg\nheight_sd\n\n\n\n\n183.1111\n9.958082\n\n\n\n\n\n\n\nmen |&gt; \n  ggdensity(x = \"height\", fill = \"sex\")\n\n\n\n\n\n\n\n\nHm, ob da alle M√§nner ihre Gr√∂√üe korrekt angegeben haben?"
  },
  {
    "objectID": "posts/groesse04/index.html#modell",
    "href": "posts/groesse04/index.html#modell",
    "title": "groesse04",
    "section": "",
    "text": "m1 &lt;- stan_glm(height ~ 1, data = men,\n               refresh = 0,\n               prior_intercept = normal(178.4, 7.6),\n               prior_aux = exponential(0.125))\n\nModellparameter:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n182.65\n(178.01, 187.25)\n100%\n1.002\n1972.00\nNormal (178.40 +- 7.60)\n\n\n\n\n\nVisualisierung der Post-Verteilung (HDI, 95%):\n\n\n\n\n\n\n\n\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/Interaktionseffekt1/Interaktionseffekt1.html",
    "href": "posts/Interaktionseffekt1/Interaktionseffekt1.html",
    "title": "interaktionseffekt1",
    "section": "",
    "text": "W√§hlen Sie das Diagramm, in dem kein Interaktionseffekt (in der Population) vorhanden ist (bzw. w√§hlen Sie das Diagramm, dass dies am ehesten darstellt).\n\n\n\nDiagramm A\nDiagramm B\nDiagramm C\nDiagramm D\nDiagramm E"
  },
  {
    "objectID": "posts/Interaktionseffekt1/Interaktionseffekt1.html#answerlist",
    "href": "posts/Interaktionseffekt1/Interaktionseffekt1.html#answerlist",
    "title": "interaktionseffekt1",
    "section": "",
    "text": "Diagramm A\nDiagramm B\nDiagramm C\nDiagramm D\nDiagramm E"
  },
  {
    "objectID": "posts/Interaktionseffekt1/Interaktionseffekt1.html#answerlist-1",
    "href": "posts/Interaktionseffekt1/Interaktionseffekt1.html#answerlist-1",
    "title": "interaktionseffekt1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ninteraction\nregression"
  },
  {
    "objectID": "posts/euro-bayes/euro-bayes.html",
    "href": "posts/euro-bayes/euro-bayes.html",
    "title": "euro-bayes",
    "section": "",
    "text": "Exercise\nIn Information Theory, Inference, and Learning Algorithms, stellt David MacKay folgendes Problem.\n‚ÄúA statistical statement appeared in The Guardian on Friday January 4, 2002:\nWhen spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110. ‚ÄòIt looks very suspicious to me,‚Äô said Barry Blight, a statistics lecturer at the London School of Economics. ‚ÄòIf the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.‚Äô\nBut do these data give evidence that the coin is biased rather than fair?‚Äù\nWie wahrscheinlich ist es, dass die M√ºnze (exakt) fair ist, im Lichte dieser Daten?\nHinweise:\n\nUntersuchen Sie die Hypothesen \\(\\pi_0 = 0, \\pi_1 = 0.1, \\pi_2 = 0.2, ..., \\pi_{10} = 1\\) f√ºr die Trefferwahrscheinlichkeit (Kopf; heads).\nErstellen Sie ein Bayes-Gitter zur L√∂sung dieser Aufgabe.\nGehen Sie davon aus, dass Sie indifferent gegen√ºber der Hypothesen zu den Parameterwerten der M√ºnze sind.\nGeben Sie Prozentzahlen immer als Anteil an und lassen Sie die f√ºhrende Null weg (z.B. .42).\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (das \"Gitter\"): \n    p_Gitter = seq(from = 0, to = 1, by = 0.1),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %&gt;%  \n    mutate(\n      # berechne Likelihood f√ºr jeden Gitterwert:\n      Likelihood = dbinom(140, size = 250, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.00\n0.00\n0.00\n\n\n0.4\n1\n0.00\n0.00\n0.00\n\n\n0.5\n1\n0.01\n0.01\n0.27\n\n\n0.6\n1\n0.02\n0.02\n0.73\n\n\n0.7\n1\n0.00\n0.00\n0.00\n\n\n0.8\n1\n0.00\n0.00\n0.00\n\n\n0.9\n1\n0.00\n0.00\n0.00\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\nPlotten mit ggplot:\n\nd %&gt;% \n  ggplot(aes(x=p_Gitter, y = Post)) +\n  geom_line()\n\n\n\n\n\n\n\n\nOder mit ggpubr plotten:\n\nggline(d, x = \"p_Gitter\", y = \"Post\", add = \"mean_se\", \n       xlab = \"Trefferwahrscheinlichkeit\", ylab = \"Posteriori-Wahrscheinlichkeit\")\n\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit \\(Pr(\\pi = 1/2 \\, | \\, X=140)\\) wenn \\(X \\sim Bin(250, 1/2)\\) betr√§gt ca. 27% oder .27.\nAllerdings w√ºrden viele Statistiker:innen nicht (nur) fragen, wie wahrscheinlich 140 Treffer sind. Stattdessen k√∂nnte man von folgender √úberlegung ausgehen.\nZuerst: Welcher Wert w√§re am wahrscheinlichsten, wenn die M√ºnze fair w√§re?\n\ndbinom(x = 0:250, size = 250, prob = 1/2) %&gt;% which.max()\n\n[1] 126\n\n\nDer 126. Wert in der Liste 0:250 ist der wahrscheinlichste (also 125 Treffer).\nWenn die M√ºnze fair ist, dann w√§ren doch 15 Treffer mehr als 125 genauso so unwahrscheinlich wie 15 Treffer weniger als 125 Treffer. Beide Ereignisse - 110 und 140 Treffer - sind ja gleich weit entfernt von denjenigen Wert, der am wahrscheinlichsten ist, wenn die M√ºnze fair ist.\nEine Statistikerin w√ºrde also eher fragen: ‚ÄúWie wahrscheinlich ist es, dass man ein Ergebnis erh√§lt, dass mind. 15 Treffer entfernt ist von der Trefferzahl, die bei einer fairen M√ºnze zu erwarten ist?‚Äù. Aber genug davon f√ºr diese Aufgabe :-)\n\nCategories:\n\nprobability\nbayesbox"
  },
  {
    "objectID": "posts/tidymodels2/tidymodels2.html",
    "href": "posts/tidymodels2/tidymodels2.html",
    "title": "tidymodels2",
    "section": "",
    "text": "Aufgabe\nEin merkw√ºrdiger Fehler bzw. eine merkw√ºrdige Fehlermeldung in Tidymodels - das untersuchen wir hier genauer und versuchen das Ph√§nomen zu erkl√§ren.\nAufgabe\nErl√§utern Sie die Ursachen des Fehlers! Schalten Sie den Fehler an und ab, um zu zeigen, dass Sie Ihn verstehen.\n\n\nStartup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nData import\n\ndata(\"mtcars\")\n\nd_train &lt;- mtcars %&gt;% slice_head(n = 20)\nd_test &lt;- mtcars %&gt;% slice(21:n())\n\n\n\nRecipe\n\npreds_chosen &lt;- c(\"hp\", \"disp\", \"am\")\n\n\nrec1 &lt;- \n  recipe( ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %&gt;% \n  update_role(mpg, new_role = \"outcome\")\nrec1\n\n\nd_train_baked &lt;-\n  rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n\nRows: 20\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,‚Ä¶\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16‚Ä¶\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180‚Ä¶\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,‚Ä¶\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.‚Ä¶\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18‚Ä¶\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1\n\n\n\n\nModel 1\n\nmodel_lm &lt;- linear_reg()\n\n\n\nWorkflow 1\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model_lm) %&gt;% \n  add_recipe(rec1)\n\n\n\nFit\n\nlm_fit1 &lt;-\n  wf1 %&gt;% \n  fit(d_train)\n\n\npreds &lt;-\n  lm_fit1 %&gt;% \n  predict(d_test)\n\nhead(preds)\n\n\n\n\n\n.pred\n\n\n\n\n22.63594\n\n\n17.24780\n\n\n17.44343\n\n\n12.09935\n\n\n14.86481\n\n\n28.15949\n\n\n\n\n\n\nAus Gr√ºnden der Reproduzierbarkeit bietet es sich an, eine SessionInfo anzugeben:\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] yardstick_1.3.2    workflowsets_1.1.1 workflows_1.3.0    tune_2.0.0        \n [5] tailor_0.1.0       rsample_1.3.1      recipes_1.3.1      parsnip_1.3.3     \n [9] modeldata_1.5.1    infer_1.0.9        dials_1.4.2        scales_1.4.0      \n[13] broom_1.0.10       tidymodels_1.4.1   lubridate_1.9.4    forcats_1.0.0     \n[17] stringr_1.5.2      dplyr_1.1.4        purrr_1.1.0        readr_2.1.5       \n[21] tidyr_1.3.1        tibble_3.3.0       ggplot2_4.0.0      tidyverse_2.0.0   \n[25] colorout_1.3-2    \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1    timeDate_4041.110   farver_2.1.2       \n [4] S7_0.2.0            fastmap_1.2.0       digest_0.6.37      \n [7] rpart_4.1.23        timechange_0.3.0    lifecycle_1.0.4    \n[10] survival_3.6-4      magrittr_2.0.4      compiler_4.4.1     \n[13] rlang_1.1.6         tools_4.4.1         yaml_2.3.10        \n[16] data.table_1.17.8   knitr_1.50          htmlwidgets_1.6.4  \n[19] DiceDesign_1.10     RColorBrewer_1.1-3  withr_3.0.2        \n[22] nnet_7.3-19         grid_4.4.1          sparsevctrs_0.3.3  \n[25] future_1.58.0       globals_0.18.0      MASS_7.3-65        \n[28] cli_3.6.5           rmarkdown_2.28      generics_0.1.4     \n[31] rstudioapi_0.17.1   future.apply_1.20.0 tzdb_0.4.0         \n[34] splines_4.4.1       parallel_4.4.1      vctrs_0.6.5        \n[37] hardhat_1.4.2       Matrix_1.7-0        jsonlite_1.8.8     \n[40] hms_1.1.3           listenv_0.9.1       gower_1.0.2        \n[43] glue_1.8.0          parallelly_1.44.0   codetools_0.2-20   \n[46] stringi_1.8.7       gtable_0.3.6        GPfit_1.0-8        \n[49] pillar_1.11.1       furrr_0.3.1         htmltools_0.5.8.1  \n[52] ipred_0.9-15        lava_1.8.0          R6_2.5.1           \n[55] lhs_1.2.0           evaluate_1.0.3      lattice_0.22-6     \n[58] backports_1.5.0     class_7.3-22        Rcpp_1.1.0         \n[61] prodlim_2024.06.25  xfun_0.52           pkgconfig_2.0.3    \n\n\n         \n\n\nL√∂sung\nDefiniert man das Rezept so:\n\nrec2 &lt;- recipe(mpg ~ hp + disp + am, data = d_train)\n\nDann l√§uft predict() brav durch.\nAuch dieser Code funktioniert:\n\nrec3 &lt;- \n  recipe(mpg ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %&gt;% \n  update_role(mpg, new_role = \"outcome\")\n\nDas Problem von rec1 scheint darin zu legen, dass die Rollen der Variablen nicht richtig gel√∂scht werden, was predict() verwirrt:\n\nrec1 &lt;- \n  recipe(mpg ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %&gt;% \n  update_role(mpg, new_role = \"outcome\")\nrec1\n\nDaher l√§uft das Rezept rec3 durch, wenn man zun√§chst alle Pr√§diktoren in ID-Variablen umwandelt: Damit sind alle Rollen wieder sauber.\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nerror\nstring"
  },
  {
    "objectID": "posts/groesse03/index.html",
    "href": "posts/groesse03/index.html",
    "title": "groesse03",
    "section": "",
    "text": "Wir interessieren uns f√ºr die typische K√∂rpergr√∂√üe deutscher Studentis. Hier findet sich dazu der Datensatz wo_men.\nWir wollen die Forschungsfrage untersuchen, ob die K√∂rpergr√∂√üe m√§nnlicher Studenten normalverteilt ist und zwar gleich der K√∂rpergr√∂√üe des ‚Äútypischen‚Äù erwachsenen Mannes.\nDiese Verteilung (typische K√∂rpergr√∂√üe erwachsener M√§nner) nehmen wir an mit \\(\\mu \\sim N(178.4, 7.6)\\).\n\nQuelle: K√∂rpergr√∂√üe M√§nner\nSiehe auch hier zur K√∂rpergr√∂√üe der M√§nner\nAufgabe K√∂nnen Sie die Hypothese verwerfen, dass die mittlere K√∂rpergr√∂√üe der m√§nnlichen Studenten der der m√§nnlichen Allgemeinbev√∂lkerung entspricht? Begr√ºnden Sie!\n\n\n\n\nlibrary(pradadata)  # f√ºr den Datensatz `wo_men`\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n\nDaten importieren:\n\ndata(wo_men)\n\nAlternativ per URL:\n\nwo_men &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/wo_men.csv\")\n\nMittelwert in der Stichprobe:\n\nmen &lt;- \nwo_men |&gt; \n  filter(height &lt; 210, height &gt; 150) |&gt; \n  filter(sex == \"man\") |&gt; \n  drop_na()\n\nmen |&gt;  \n  summarise(height_avg = mean(height, na.rm = TRUE),\n            height_sd = sd(height, na.rm = TRUE))\n\n\n\n\n\nheight_avg\nheight_sd\n\n\n\n\n183.1111\n9.958082\n\n\n\n\n\n\n\nmen |&gt; \n  ggdensity(x = \"height\", fill = \"sex\")\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\n\n\n\n\n\nm1 &lt;- stan_glm(height ~ 1, data = men,\n               refresh = 0,\n               prior_intercept = normal(178.4, 7.6))\n\nModellparameter:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n182.66\n(177.86, 187.13)\n100%\n0.999\n2331.00\nNormal (178.40 +- 7.60)\n\n\n\n\n\nVisualisierung der Post-Verteilung (HDI, 95%):\n\n\n\n\n\n\n\n\nFigure¬†2\n\n\n\n\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/groesse03/index.html#hintergrund-und-forschungsfrage",
    "href": "posts/groesse03/index.html#hintergrund-und-forschungsfrage",
    "title": "groesse03",
    "section": "",
    "text": "Wir interessieren uns f√ºr die typische K√∂rpergr√∂√üe deutscher Studentis. Hier findet sich dazu der Datensatz wo_men.\nWir wollen die Forschungsfrage untersuchen, ob die K√∂rpergr√∂√üe m√§nnlicher Studenten normalverteilt ist und zwar gleich der K√∂rpergr√∂√üe des ‚Äútypischen‚Äù erwachsenen Mannes.\nDiese Verteilung (typische K√∂rpergr√∂√üe erwachsener M√§nner) nehmen wir an mit \\(\\mu \\sim N(178.4, 7.6)\\).\n\nQuelle: K√∂rpergr√∂√üe M√§nner\nSiehe auch hier zur K√∂rpergr√∂√üe der M√§nner\nAufgabe K√∂nnen Sie die Hypothese verwerfen, dass die mittlere K√∂rpergr√∂√üe der m√§nnlichen Studenten der der m√§nnlichen Allgemeinbev√∂lkerung entspricht? Begr√ºnden Sie!"
  },
  {
    "objectID": "posts/groesse03/index.html#setup",
    "href": "posts/groesse03/index.html#setup",
    "title": "groesse03",
    "section": "",
    "text": "library(pradadata)  # f√ºr den Datensatz `wo_men`\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstanarm)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/groesse03/index.html#daten-der-stichprobe",
    "href": "posts/groesse03/index.html#daten-der-stichprobe",
    "title": "groesse03",
    "section": "",
    "text": "Daten importieren:\n\ndata(wo_men)\n\nAlternativ per URL:\n\nwo_men &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/wo_men.csv\")\n\nMittelwert in der Stichprobe:\n\nmen &lt;- \nwo_men |&gt; \n  filter(height &lt; 210, height &gt; 150) |&gt; \n  filter(sex == \"man\") |&gt; \n  drop_na()\n\nmen |&gt;  \n  summarise(height_avg = mean(height, na.rm = TRUE),\n            height_sd = sd(height, na.rm = TRUE))\n\n\n\n\n\nheight_avg\nheight_sd\n\n\n\n\n183.1111\n9.958082\n\n\n\n\n\n\n\nmen |&gt; \n  ggdensity(x = \"height\", fill = \"sex\")\n\n\n\n\n\n\n\nFigure¬†1"
  },
  {
    "objectID": "posts/groesse03/index.html#modell",
    "href": "posts/groesse03/index.html#modell",
    "title": "groesse03",
    "section": "",
    "text": "m1 &lt;- stan_glm(height ~ 1, data = men,\n               refresh = 0,\n               prior_intercept = normal(178.4, 7.6))\n\nModellparameter:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n182.66\n(177.86, 187.13)\n100%\n0.999\n2331.00\nNormal (178.40 +- 7.60)\n\n\n\n\n\nVisualisierung der Post-Verteilung (HDI, 95%):\n\n\n\n\n\n\n\n\nFigure¬†2\n\n\n\n\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/Rethink2m1/Rethink2m1.html",
    "href": "posts/Rethink2m1/Rethink2m1.html",
    "title": "Rethink2m1",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\n2M1. Recall the globe tossing model from the chapter (also see exercise globus1).\nCompute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p.\n\nWWW\nWWWL\nLWWLWWW\n\n         \n\n\nL√∂sung\nThe solution is taken from this source.\n\nlibrary(tidyverse)\n\ndist &lt;- \n  tibble(\n    # Gridwerte bestimmen:\n    p_grid = seq(from = 0, to = 1, length.out = 20),\n    # Priori-Wskt bestimmen:\n    prior = rep(1, times = 20)) %&gt;%\n  mutate(\n    # Likelihood berechnen:\n    likelihood_1 = dbinom(3, size = 3, prob = p_grid),  # WWW\n    likelihood_2 = dbinom(3, size = 4, prob = p_grid),  # WWWL\n    likelihood_3 = dbinom(5, size = 7, prob = p_grid),  # LWWLWWW\n    # unstand. Posterior-Wskt:\n    unstand_post_1 = likelihood_1 * prior,\n    unstand_post_2 = likelihood_2 * prior,\n    unstand_post_3 = likelihood_3 * prior,\n    # stand. Post-Wskt:\n    std_post_1 = unstand_post_1 / sum(unstand_post_1),\n    std_post_2 = unstand_post_2 / sum(unstand_post_2),\n    std_post_3 = unstand_post_3 / sum(unstand_post_3)\n    ) \n\nHier ist die Bayes-Box:\n\nknitr::kable(round(dist, 2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood_1\nlikelihood_2\nlikelihood_3\nunstand_post_1\nunstand_post_2\nunstand_post_3\nstd_post_1\nstd_post_2\nstd_post_3\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.05\n1\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0.16\n1\n0.00\n0.01\n0.00\n0.00\n0.01\n0.00\n0.00\n0.00\n0.00\n\n\n0.21\n1\n0.01\n0.03\n0.01\n0.01\n0.03\n0.01\n0.00\n0.01\n0.00\n\n\n0.26\n1\n0.02\n0.05\n0.01\n0.02\n0.05\n0.01\n0.00\n0.01\n0.01\n\n\n0.32\n1\n0.03\n0.09\n0.03\n0.03\n0.09\n0.03\n0.01\n0.02\n0.01\n\n\n0.37\n1\n0.05\n0.13\n0.06\n0.05\n0.13\n0.06\n0.01\n0.03\n0.02\n\n\n0.42\n1\n0.07\n0.17\n0.09\n0.07\n0.17\n0.09\n0.01\n0.05\n0.04\n\n\n0.47\n1\n0.11\n0.22\n0.14\n0.11\n0.22\n0.14\n0.02\n0.06\n0.06\n\n\n0.53\n1\n0.15\n0.28\n0.19\n0.15\n0.28\n0.19\n0.03\n0.07\n0.08\n\n\n0.58\n1\n0.19\n0.33\n0.24\n0.19\n0.33\n0.24\n0.04\n0.09\n0.10\n\n\n0.63\n1\n0.25\n0.37\n0.29\n0.25\n0.37\n0.29\n0.05\n0.10\n0.12\n\n\n0.68\n1\n0.32\n0.40\n0.31\n0.32\n0.40\n0.31\n0.06\n0.11\n0.13\n\n\n0.74\n1\n0.40\n0.42\n0.32\n0.40\n0.42\n0.32\n0.08\n0.11\n0.13\n\n\n0.79\n1\n0.49\n0.41\n0.29\n0.49\n0.41\n0.29\n0.09\n0.11\n0.12\n\n\n0.84\n1\n0.60\n0.38\n0.22\n0.60\n0.38\n0.22\n0.11\n0.10\n0.09\n\n\n0.89\n1\n0.72\n0.30\n0.13\n0.72\n0.30\n0.13\n0.14\n0.08\n0.06\n\n\n0.95\n1\n0.85\n0.18\n0.04\n0.85\n0.18\n0.04\n0.16\n0.05\n0.02\n\n\n1.00\n1\n1.00\n0.00\n0.00\n1.00\n0.00\n0.00\n0.19\n0.00\n0.00\n\n\n\n\n\nJetzt k√∂nnen wir das jeweilige Diagramm zeichnen:\n\nlibrary(ggpubr)\nggline(dist,\n       x = \"p_grid\",\n       y = \"std_post_1\")\n\n\n\n\n\n\n\n\nOder mit ggplot2:\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_1) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWW\")\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_2) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWWL\")\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_3) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: LWWLWWW\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayesbox\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/streuung-post2/index.html",
    "href": "posts/streuung-post2/index.html",
    "title": "streuung-post2",
    "section": "",
    "text": "1 Aufgabe\nEin Fitnesstrainer behauptet, der Effekt einer Stunde Joggen l√§ge bei ‚Äúetwa 500 bis 600‚Äù kcal. Der Fitnesstrainer erkl√§rt, dass er sich auf einen erwachsenen Mann mit ca. 80 kg K√∂rpergewicht bezieht und eine mittleren Geschwindigkeit von ca. 8-9 km/h.\nUnter der Annahme, dass der Effekt existiert, normalverteilt ist und dass der oben angef√ºhrte Wertebereich dem 95%-ETI einer Posterior-Verteilung entspricht:\nWie gro√ü ist die Streuung der Posterior-Verteilung?\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nF√ºr eine Normalverteilung N(Œº, œÉ¬≤) gilt:\nDas 2,5%-Quantil liegt bei Œº - 1,96œÉ Das 97,5%-Quantil liegt bei Œº + 1,96œÉ\nDaraus folgt:\n500 = Œº - 1,96œÉ 600 = Œº + 1,96œÉ\nAus den beiden Gleichungen:\nDifferenz: 600 - 500 = 100 = 2 √ó 1,96œÉ Daher: œÉ = 100 / (2 √ó 1,96) = 100 / 3,92 ‚âà 25,5 kcal\nMittelwert:\nŒº = (500 + 600) / 2 = 550 kcal\nAntwort: Die Streuung (Standardabweichung) der Posterior-Verteilung betr√§gt etwa 25,5 kcal. Interpretation: Bei einer Normalverteilung mit Œº = 550 kcal und œÉ = 25,5 kcal liegen 95% der Werte zwischen 500 und 600 kcal, was genau dem angegebenen 95%-ETI entspricht."
  },
  {
    "objectID": "posts/Rethink2m6/Rethink2m6.html",
    "href": "posts/Rethink2m6/Rethink2m6.html",
    "title": "Rethink2m6",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\n2M6. Imagine that black ink is heavy, and so cards with black sides are heavier than cards with white sides. As a result, it‚Äôs less likely that a card with black sides is pulled from the bag. So again assume there are three cards: B/B, B/W, and W/W. After experimenting a number of times, you conclude that for every way to pull the B/B card from the bag, there are 2 ways to pull the B/W card and 3 ways to pull the W/W card. Again suppose that a card is pulled and a black side appears face up. Show that the probability the other side is black is now 0.5. Use the counting method, as before.\n         \n\n\nL√∂sung\nLet‚Äôs label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nWanted is the probability that the second side of the card is black (2b), given one side is already identified as black (1b): \\(Pr(2b|1b)\\).\nBayes-Box to the rescue:\nWhenever the probability of all paths (in a tree diagram) is the same, we do not need to write down the probability of the path for the likelihood. It is enough to write the number of paths.\n\n\n\n\n\n\n\n\nHyp\nPrior\nLikelihood\nunstand_post\nstd_post\n\n\n\n\nbb\n1\n2\n2\n0.5\n\n\nbw\n2\n1\n2\n0.5\n\n\nww\n3\n0\n0\n0.0\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes\nbayesbox\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/mtcars-abhaengig_var3a/mtcars-abhaengig_var3a.html",
    "href": "posts/mtcars-abhaengig_var3a/mtcars-abhaengig_var3a.html",
    "title": "mtcars-abhaengig_var3a",
    "section": "",
    "text": "Aufgabe\nIm Folgenden ist der Datensatz mtcars zu analysieren.\nDer Datensatz ist z.B. als CSV-Datei von dieser Webseite abrufbar.\nHilfe zum Datensatz ist via dieser Webseite abrufbar.\nOb die Variable hp (UV) und Spritverbrauch (mpg; AV) wohl voneinander abh√§ngig sind? Was meinen Sie? Was ist Ihre Einsch√§tzung dazu? Vermutlich haben Sie ein (wenn vielleicht auch implizites) Vorab-Wissen zu dieser Frage. Lassen wir dieses Vorab-Wissen aber einmal au√üen vor und schauen uns rein Daten dazu an. Vereinfachen wir die Frage etwas, indem wir beide Variablen am Mittelwert aufteilen: Wenn eine Beobachtung (d.h. ein Auto) einen Wert in der jeweiligen Variablen h√∂chstens so gro√ü wie der Mittelwert der Variable aufweist, geben wir der Beobachtung der Wert 0, ansonsten den Wert 1. Das Ereignis \\(A\\) sei ‚Äúhoher Spritverbrauch‚Äù, mpg_high == 1. Das Ereignis \\(B\\) sei ‚Äúhohe PS_Zahl‚Äù, hp_high == 1.\nBerechnen Sie: \\(Pr(\\neg \\text{uv high} \\, | \\,  \\text{av high})\\)\nHinweise:\n\nDas ‚ÄúEllbogen-Zeichen‚Äù \\(\\neg\\) kennzeichnet eine logische Negierung (das Gegenteil oder Komplement).\nDie angegebene Wahrscheinlichkeit ist eine bedingte Wahrscheinlichkeit.\nWeitere Hinweise\n\n         \n\n\nL√∂sung\nDieser Pr√§diktor wurde als UV bestimmt: hp.\nSchauen wir zuerst mal in den Datensatz:\n\ndata(mtcars)  # mtcars importieren\n\nmtcars %&gt;% \n  select(mpg, hp) %&gt;% \n  slice_head(n = 5)\n\n                   mpg  hp\nMazda RX4         21.0 110\nMazda RX4 Wag     21.0 110\nDatsun 710        22.8  93\nHornet 4 Drive    21.4 110\nHornet Sportabout 18.7 175\n\n\nDann berechnen wir die bin√§ren Variablen:\n\nmtcars2 &lt;-\n  mtcars %&gt;% \n  select(mpg, hp) %&gt;% \n  mutate(mpg_high = case_when(\n    mpg &lt;= mean(mpg) ~ 0,\n    mpg &gt; mean(mpg) ~ 1\n  )) %&gt;% \n  select(-mpg) \n\nmtcars3 &lt;-  # Jetzt analog f√ºr die UV, `hp`:\n  mtcars2 |&gt; \n  mutate(hp_high = case_when(\n    hp &lt;= mean(hp) ~ 0,\n    hp &gt; mean(hp) ~ 1\n  )) |&gt; \n  select(-hp)\n\nDann filtern wir die gesuchten Wahrscheinlichkeiten bzw. Anteile der AV: ::: {.cell hash=‚Äòmtcars-abhaengig_var3a_cache/html/unnamed-chunk-3_6c04861ad9eddfd4132aaf5ecab49672‚Äô}\nmtcars3_filtered &lt;-\n  mtcars3 %&gt;% \n  filter(mpg_high == 1)\n\nmtcars3_filtered\n\n               mpg_high hp_high\nMazda RX4             1       0\nMazda RX4 Wag         1       0\nDatsun 710            1       0\nHornet 4 Drive        1       0\nMerc 240D             1       0\nMerc 230              1       0\nFiat 128              1       0\nHonda Civic           1       0\nToyota Corolla        1       0\nToyota Corona         1       0\nFiat X1-9             1       0\nPorsche 914-2         1       0\nLotus Europa          1       0\nVolvo 142E            1       0\n\n:::\nDie Anzahl der Zeilen in mtcars3_filtered sagt uns, wie viele Autos die gesuchte Bedingung, also den ‚Äúhinteren Teil‚Äù der Wahrscheinlichkeit, erf√ºllen.\nZur Erinnerung: Bedingte Wahrscheinlichkeit berechnen ist analog zum Filtern einer Tabelle:\nEs gibt also 14 Autos, die den oben gesuchten ‚Äúhinteren Teil‚Äù der Bedingung erf√ºllen (mpg_high = 1).\nFiltern wir als n√§chstes nach dem ‚Äúvorderen Teil‚Äù der gesuchten Wahrscheinlichkeit (was das gleiche ist wie ein Anteil in diesem Fall):\n\nmtcars3_filtered %&gt;% \n  filter(hp_high == 0) \n\n               mpg_high hp_high\nMazda RX4             1       0\nMazda RX4 Wag         1       0\nDatsun 710            1       0\nHornet 4 Drive        1       0\nMerc 240D             1       0\nMerc 230              1       0\nFiat 128              1       0\nHonda Civic           1       0\nToyota Corolla        1       0\nToyota Corona         1       0\nFiat X1-9             1       0\nPorsche 914-2         1       0\nLotus Europa          1       0\nVolvo 142E            1       0\n\n\nEs gibt also 14 Autos, f√ºr die gilt hp_high == 0.\nMit count kann man sich die Werte z√§hlen lassen:\n\n\n  hp_high  n\n1       0 14\n\n\nDer gesuchte Wert betr√§gt also 14/14 = 1.\nVisualisieren wir noch die bedingten Wahrscheinlichkeiten, so k√∂nnte man die gesuchten Anteile einfach abz√§hlen:\n\n\n\n\n\n\n\n\n\nSieht man in dem Diagramm nur eine Farbe (anstelle von zweien), so hei√üt das, dass es nur eine Gruppe gibt (und nicht zwei). Die H√§ufigkeit der nicht vorhandenen Gruppe ist demnach Null.\n\nCategories:\n\nprobability\nbayes\nnum"
  },
  {
    "objectID": "posts/germeval09-tfidf/germeval09-tfidf.html",
    "href": "posts/germeval09-tfidf/germeval09-tfidf.html",
    "title": "germeval09-tfidf",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten, nutzen Sie einen Entscheidungsbaum als Modell. Erstellen Sie pro Wort tfIDF-Kennwerte im Rahmen von Feature-Engineering.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon."
  },
  {
    "objectID": "posts/germeval09-tfidf/germeval09-tfidf.html#workflow",
    "href": "posts/germeval09-tfidf/germeval09-tfidf.html#workflow",
    "title": "germeval09-tfidf",
    "section": "Workflow",
    "text": "Workflow\n\n# model:\nmod1 &lt;-\n  decision_tree(mode = \"classification\")\n\n# recipe:\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  step_tokenize(text) %&gt;%\n  step_tokenfilter(text, max_tokens = 1e3) %&gt;%\n  step_tfidf(text) %&gt;%\n  step_zv(all_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/germeval09-tfidf/germeval09-tfidf.html#fit",
    "href": "posts/germeval09-tfidf/germeval09-tfidf.html#fit",
    "title": "germeval09-tfidf",
    "section": "Fit",
    "text": "Fit\nOhne Tuning:\n\ntic()\nfit1 &lt;-\n  fit(wf1,\n      data = d_train)\ntoc()\n#beep()\n\n\nfit1"
  },
  {
    "objectID": "posts/germeval09-tfidf/germeval09-tfidf.html#test-set-g√ºte",
    "href": "posts/germeval09-tfidf/germeval09-tfidf.html#test-set-g√ºte",
    "title": "germeval09-tfidf",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval09-tfidf/germeval09-tfidf.html#prepbake",
    "href": "posts/germeval09-tfidf/germeval09-tfidf.html#prepbake",
    "title": "germeval09-tfidf",
    "section": "Prep/Bake",
    "text": "Prep/Bake\nAls Check: Das gepreppte/bebackene Rezept:\n\ntic()\nrec1_prepped &lt;- prep(rec1)\ntoc()\n\n\ntic()\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\ntoc()"
  },
  {
    "objectID": "posts/germeval09-tfidf/germeval09-tfidf.html#sehr-viele-spalten",
    "href": "posts/germeval09-tfidf/germeval09-tfidf.html#sehr-viele-spalten",
    "title": "germeval09-tfidf",
    "section": "Sehr viele Spalten",
    "text": "Sehr viele Spalten\nDas Problem ist, dass dieses Rezept sehr viele Spalten erzeugt. Das ist (sehr) rechen- und speicherintensiv.\n\ndim(d_train_baked)\n\n\nd_train_baked |&gt; \n  head()\n\n\nCategories:\n\ntextmining\ndatawrangling\ngermeval\nprediction\ntidymodels\nstring"
  },
  {
    "objectID": "posts/import-mtcars/import-mtcars.html",
    "href": "posts/import-mtcars/import-mtcars.html",
    "title": "import-mtcars",
    "section": "",
    "text": "Aufgabe\nFinden Sie den Datensatz ‚Äúmtcars‚Äù online! ‚Äúmtcars.csv‚Äù Tipp: Die Webseite ‚Äúvincentarelbundock‚Äù ist ein guter Ort zum Suchen. Importieren Sie dann den Datensatz in R.\nSagen Sie mir den Namen der letzten Spalte und dort den 1. Wert!\n         \n\n\nL√∂sung\n\nlibrary(easystats)  # in diesem Paket \"wohnt\" data_read. \nmtcars_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\"\n\nmtcars &lt;- data_read(mtcars_path)\n\nAntwort: Die letzte Spalte hei√üt carb und der 1. Wert ist 4.\nAnstelle von data_read aus easystats k√∂nnte man auch read.csv verwenden, das ist ein ‚Äúeingebauter‚Äù Befehl in R, f√ºr den man kein Paket gestartet haben muss.\n\nCategories:\n\nR\ndata\nnum"
  },
  {
    "objectID": "posts/remove-digits/index.html",
    "href": "posts/remove-digits/index.html",
    "title": "remove-digits",
    "section": "",
    "text": "1 Aufgabe\n\n\n2 Aufgabe\nSchreiben Sie einen R-Code, der aus dem folgenden String-Vektor, die Anzahl der uniquen Werte ausgibt, nachdem alle Zahlen aus dem Vektor entfernt wurden.\nHier ist der String-Vektor:\n\ncol_names &lt;- \n  c(\"key01\",\n    \"key02\",\n    \"value01\",\n    \"value02\")\n\ndie L√∂sung sollte also sein: ‚Äúkey, value‚Äù.\n  \n  \n  \n  \n\n\n3 L√∂sung\nSetup:\n\nlibrary(tidyverse)\n\nZahlen entfernen:\n\ncol_names_unique &lt;- \n  col_names %&gt;% \n  str_remove_all(\"[:digit:]\") |&gt;  # aus \"stringr\"\n  unique()\n\ncol_names_unique\n\n[1] \"key\"   \"value\"\n\n\nAlternativen, um Zahlen zu entfernen:\n\ncol_names %&gt;% \n  str_remove_all(\"[0-9]\") \n\n[1] \"key\"   \"key\"   \"value\" \"value\"\n\n\nWeitere Alternative:\n\ncol_names |&gt; \n  str_remove_all(\"\\\\d+$\") \n\n[1] \"key\"   \"key\"   \"value\" \"value\"\n\n\nAlternative mit base-R:\n\ngsub(\"[0-9]+$\",\"\", col_names) \n\n[1] \"key\"   \"key\"   \"value\" \"value\""
  },
  {
    "objectID": "posts/anim03/anim03.html",
    "href": "posts/anim03/anim03.html",
    "title": "anim03",
    "section": "",
    "text": "Visualisieren Sie in animierter Form die Temperatur in New York im Zeitverlauf der Kontinent soll in der Visualisierung ber√ºcksichtigt sein.\nHinweise:\n\nBeziehen Sie sich auf die Daten des Datensatzes airquality.\nNutzen Sie plotly zur Visualisierung.\nNutzen Sie die Monate als ‚ÄúGruppierungsvariable‚Äù.\nVerwenden Sie das Paket gganimate."
  },
  {
    "objectID": "posts/anim03/anim03.html#setup",
    "href": "posts/anim03/anim03.html#setup",
    "title": "anim03",
    "section": "Setup",
    "text": "Setup\n\nlibrary(gapminder)\nlibrary(tidyverse)\nlibrary(gganimate)\ndata(gapminder)"
  },
  {
    "objectID": "posts/anim03/anim03.html#statisches-diagramm",
    "href": "posts/anim03/anim03.html#statisches-diagramm",
    "title": "anim03",
    "section": "Statisches Diagramm",
    "text": "Statisches Diagramm\n\np &lt;- airquality %&gt;% \n  ggplot(aes(x = Day, y = Temp, color = factor(Month))) +\n  geom_line()\np"
  },
  {
    "objectID": "posts/anim03/anim03.html#animiertes-und-interaktives-diagramm",
    "href": "posts/anim03/anim03.html#animiertes-und-interaktives-diagramm",
    "title": "anim03",
    "section": "Animiertes (und interaktives) Diagramm",
    "text": "Animiertes (und interaktives) Diagramm\n\np + transition_reveal(Day)\n\nDieser Post orientiert sich an dieser Quelle; dort finden sich auch mehr Beispiele.\n\nCategories:\n\n2023\nvis\nanimation\nstring"
  },
  {
    "objectID": "posts/kekse01/kekse01.html",
    "href": "posts/kekse01/kekse01.html",
    "title": "kekse01",
    "section": "",
    "text": "Exercise\nIn Think Bayes stellt Allen Downey folgende Aufgabe:\n‚ÄúSuppose there are two bowls of cookies.\nBowl 1 contains 30 vanilla cookies and 10 chocolate cookies.\nBowl 2 contains 20 vanilla cookies and 20 chocolate cookies.\nNow suppose you choose one of the bowls at random and, without looking, choose a cookie at random.\nIf the cookie is vanilla, what is the probability that it came from Bowl 1?‚Äù\nHinweise:\n\nErstellen Sie eine Bayesbox zur L√∂sung dieser Aufgabe.\nGehen Sie davon aus, dass Sie (apriori) indifferent gegen√ºber der Hypothesen sind.\nGeben Sie Prozentzahlen immer als Anteil an und lassen Sie die f√ºhrende Null weg (z.B. .42).\n\n\n\n\n\n\nZwei Keksdosen\n\n\n\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n1\n0.5\n0.75\n0.38\n0.6\n\n\n2\n0.5\n0.50\n0.25\n0.4\n\n\n\n\n\nDie Antwort lautet: 0.6.\nEs ist √ºbrigens egal, ob Sie f√ºr die Priori-Werte .5 oder 1 (oder eine andere Zahl) w√§hlen. Das Ergebnis bleibt das gleiche. Sie m√ºssen nur f√ºr alle Hypothesen die gleiche Zahl verwenden. Probieren Sie es aus!\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n1\n1\n0.75\n0.75\n0.6\n\n\n2\n1\n0.50\n0.50\n0.4"
  },
  {
    "objectID": "posts/ds-quiz2/ds-quiz2.html",
    "href": "posts/ds-quiz2/ds-quiz2.html",
    "title": "ds-quiz2",
    "section": "",
    "text": "Im Folgenden sind mehrere Aussagen zum Thema maschinelles Lernen dargestellt. W√§hlen Sie alle korrekten Aussagen aus!\nHinweise:\n\nAlle Aussagen sind entweder richtig oder falsch, aber nicht beides.\nBeziehen Sie sich im Zweifel auf den Stoff wie im Unterricht dargestellt.\n\n\n\n\nJe gr√∂√üer der Wert von mtry in einem Random-Forest-Modell, desto besser die Modellg√ºte in der Regel.\nRandom-Forest-Modelle und Baginng-Modelle basieren auf einem Bootstrapping-Verfahren.\nBeim kNN-Modell ist ein Distanzma√ü \\(d\\) die euklidische Distanz, die sich im 2D-Fall wie folgt berechnet: \\(d = \\sqrt{a^2 + b^2}\\). Dabei sind \\(a\\) und \\(b\\) die Distanz zwischen zwei Punkten \\(x\\) und \\(y\\) in den Dimensionen \\(A\\) und \\(B\\).\nBeim Random-Forest-Modell nennt man den Teil der Train-Stichprobe, der nicht in die Berechnung des jeweiligen Baumes einflie√üt, die ‚ÄúOOB-Stichprobe‚Äù.\nOverfitting tritt bei linearen Modellen nicht auf.\nBerechnet man die Vorhersageg√ºte eines Modells in mehreren Stichproben, so kann man die Vorhersageg√ºte f√ºr ein Test-Sample pr√§ziser bestimmen.\nBei baumbasierten Klassifikationsmodellen ist es dazu Ziel, die Homogenit√§t (hinsichtlich der AV) in jedem Endknoten (‚ÄúBlatt‚Äù) zu maximieren."
  },
  {
    "objectID": "posts/ds-quiz2/ds-quiz2.html#answerlist",
    "href": "posts/ds-quiz2/ds-quiz2.html#answerlist",
    "title": "ds-quiz2",
    "section": "",
    "text": "Je gr√∂√üer der Wert von mtry in einem Random-Forest-Modell, desto besser die Modellg√ºte in der Regel.\nRandom-Forest-Modelle und Baginng-Modelle basieren auf einem Bootstrapping-Verfahren.\nBeim kNN-Modell ist ein Distanzma√ü \\(d\\) die euklidische Distanz, die sich im 2D-Fall wie folgt berechnet: \\(d = \\sqrt{a^2 + b^2}\\). Dabei sind \\(a\\) und \\(b\\) die Distanz zwischen zwei Punkten \\(x\\) und \\(y\\) in den Dimensionen \\(A\\) und \\(B\\).\nBeim Random-Forest-Modell nennt man den Teil der Train-Stichprobe, der nicht in die Berechnung des jeweiligen Baumes einflie√üt, die ‚ÄúOOB-Stichprobe‚Äù.\nOverfitting tritt bei linearen Modellen nicht auf.\nBerechnet man die Vorhersageg√ºte eines Modells in mehreren Stichproben, so kann man die Vorhersageg√ºte f√ºr ein Test-Sample pr√§ziser bestimmen.\nBei baumbasierten Klassifikationsmodellen ist es dazu Ziel, die Homogenit√§t (hinsichtlich der AV) in jedem Endknoten (‚ÄúBlatt‚Äù) zu maximieren."
  },
  {
    "objectID": "posts/ds-quiz2/ds-quiz2.html#answerlist-1",
    "href": "posts/ds-quiz2/ds-quiz2.html#answerlist-1",
    "title": "ds-quiz2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Die obige Behauptung stimmt oft nicht.\nRichtig.\nRichtig.\nRichtig.\nFalsch. Zwar tritt Overfitting bei (einfachen) linearen Modellen oft weniger auf, aber gerade bei Verwendung von Polynomen ist die Gefahr des Overfitting hoch.\nRichtig.\nRichtig\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nmchoice"
  },
  {
    "objectID": "posts/bayes-theorem1/bayes-theorem1.html",
    "href": "posts/bayes-theorem1/bayes-theorem1.html",
    "title": "Bayes-Theorem1",
    "section": "",
    "text": "Pr_Tpos_geg_Kpos &lt;- (sample(085:99, size = 1) / 100 ) %&gt;% round(2)\nPr_Tpos_geg_Kneg &lt;- (sample(1:10, size = 1) / 100) %&gt;% round(2)\nPr_Kpos &lt;- (sample(01:10, size = 1) / 1000) %&gt;% round(3)\n\n\nAufgabe\nEin Krebstest (\\(T\\)) habe die Wahrscheinlichkeit von 0.98, einen vorhandenen Krebs (\\(K\\)) zu erkennen. Diese Wahrscheinlichkeit bezeichnen wir als \\(Pr(T+|K+)\\). Der Test erkennt also die meisten Krebsf√§lle, und ein paar werden √ºbersehen.\nManchmal macht der Test auch den umgekehrten Fehler: Ein gesunder Mensch wird f√§lschlich Krebs diagnostiziert, \\(Pr(T+|K-)\\). Diese Wahrscheinlichkeit liegt bei dem Test bei 0.1, zum Gl√ºck also relativ gering.\nDie Grundrate dieser Krebsart belaufe sich in der Population auf 0.008, \\(Pr(K+)\\).\nAufgabe: Berechnen Sie die Wahrscheinlichkeit, dass ein Patient tats√§chlich Krebs hat, wenn der Test positiv ist, also Krebs diagnostiziert hat!\n         \n\n\nL√∂sung\n\nzaehler_bayes &lt;- Pr_Tpos_geg_Kpos * Pr_Kpos\nPr_Tpos &lt;- (zaehler_bayes + (1-Pr_Kpos) * Pr_Tpos_geg_Kneg)\n\nsol &lt;- Pr_Kpos_geg_Tpos &lt;- zaehler_bayes / Pr_Tpos \nsol &lt;- round(sol, 2)\nsol\n\n[1] 0.07\n\n\nDie L√∂sung betr√§gt also: 0.07.\n\nCategories:\n\nbayes\nprobability\nnum"
  },
  {
    "objectID": "posts/kausal08/kausal08.html",
    "href": "posts/kausal08/kausal08.html",
    "title": "kausal08",
    "section": "",
    "text": "Gegeben sei die Theorie (oder schlichter: das Modell), demzufolge eine Anlage zu Suchtverhalten die Ursache von sowohl Rauchen als auch Kaffeegewohnheit darstellt. Lungenkrebs wiederum hat als (alleinige) Ursache Rauchen (laut diesem Modell).\nDaten zeigen, dass Kaffeegenuss und Lungenkrebs assoziiert sind: Bei Kaffeetrinkern ist die Lungenkrebsrate h√∂her als bei Nichttrinkern (von Kaffee). Ob Kaffeegebrauch Lungenkrebs erzeugt?\nEine alternative Erkl√§rung bietet folgender DAG.\n\n\n\n\n\n\n\n\n\nWelche Variablenmenge muss mindestens kontrolliert werden, um Konfundierung auszuschlie√üen und damit den kausalen Effekt von Kaffee auf Lungenkrebs zu identifizieren?\n\n\n\n{Addictive Behavior oder aber Rauchen}\n{Rauchen}\n{Addictive Behavior}\n{Addictive Behavior und Rauchen}\n{Addictive Behavior und Lungenkrebs}"
  },
  {
    "objectID": "posts/kausal08/kausal08.html#answerlist",
    "href": "posts/kausal08/kausal08.html#answerlist",
    "title": "kausal08",
    "section": "",
    "text": "{Addictive Behavior oder aber Rauchen}\n{Rauchen}\n{Addictive Behavior}\n{Addictive Behavior und Rauchen}\n{Addictive Behavior und Lungenkrebs}"
  },
  {
    "objectID": "posts/kausal08/kausal08.html#answerlist-1",
    "href": "posts/kausal08/kausal08.html#answerlist-1",
    "title": "kausal08",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/stan_glm01/stan_glm01.html",
    "href": "posts/stan_glm01/stan_glm01.html",
    "title": "stan_glm01",
    "section": "",
    "text": "Exercise\nGegeben dem folgenden Modell, geben Sie den Befehl mit stan_glm() an, um die Posteriori-Verteilung zu berechnen.\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(0, 1)\\)\n         \n\n\nSolution\n\nlibrary(rstanarm)\n\n\nmodel &lt;-\n  stan_glm(h ~ 1,\n           prior_intercept = normal(0,1),\n           prior_aux = exponential(0.1),\n           daten = meine_Daten\n  )\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/PCA1/PCA1.html",
    "href": "posts/PCA1/PCA1.html",
    "title": "PCA1",
    "section": "",
    "text": "Principal Component Analysis (PCA) ist ein g√§ngiges Verfahren zur Dimensionsreduktion eines \\(n \\times p\\) Datensatz \\(\\boldsymbol{X}\\). Welche Aussage ist in dem Zusammenhang (am ehesten) korrekt?\n\n\n\nEine z-Transformation ist i.A. empfehlenswert.\nDie Gerade einer Hauptkomponenten und die Regressionsgeraden sind i.A. nicht identisch.\nDie PCA ist ein geleitetes (supervised) Verfahren des statistisches Lernens.\nEin Screeplot zeigt auf der \\(Y\\)-Achse die kumulierte, erkl√§rte Varianz.\nBei einem \\(n \\times p\\) Datensatz \\(\\boldsymbol{X}\\) gibt es max(\\(n-1, p\\)) Komponenten.\nKomponenten k√∂nnen (m√ºssen aber nicht) orthogonal zueinander sein.\nJe st√§rker korreliert die \\(p\\) Variablen sind, desto weniger sinnvoll ist eine PCA.\nEin Screeplot zeigt auf der \\(X\\)-Achse die kumulierte, erkl√§rte Varianz."
  },
  {
    "objectID": "posts/PCA1/PCA1.html#answerlist",
    "href": "posts/PCA1/PCA1.html#answerlist",
    "title": "PCA1",
    "section": "",
    "text": "Eine z-Transformation ist i.A. empfehlenswert.\nDie Gerade einer Hauptkomponenten und die Regressionsgeraden sind i.A. nicht identisch.\nDie PCA ist ein geleitetes (supervised) Verfahren des statistisches Lernens.\nEin Screeplot zeigt auf der \\(Y\\)-Achse die kumulierte, erkl√§rte Varianz.\nBei einem \\(n \\times p\\) Datensatz \\(\\boldsymbol{X}\\) gibt es max(\\(n-1, p\\)) Komponenten.\nKomponenten k√∂nnen (m√ºssen aber nicht) orthogonal zueinander sein.\nJe st√§rker korreliert die \\(p\\) Variablen sind, desto weniger sinnvoll ist eine PCA.\nEin Screeplot zeigt auf der \\(X\\)-Achse die kumulierte, erkl√§rte Varianz."
  },
  {
    "objectID": "posts/PCA1/PCA1.html#answerlist-1",
    "href": "posts/PCA1/PCA1.html#answerlist-1",
    "title": "PCA1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/OLS-Minimierung/OLS-Minimierung.html",
    "href": "posts/OLS-Minimierung/OLS-Minimierung.html",
    "title": "OLS-Minimierung",
    "section": "",
    "text": "Um die Parameter der Regressiongeraden zu bestimmen, wird ein Ausdruck minimiert. W√§hlen Sie den korrekten Ausdruck.\n\n\n\n\\(\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\\)\n\\(\\sum_{i=1}^{n}(y_i - \\hat{y}_i)\\)\n\\(\\sum_{i=1}^{n}(|y_i - \\hat{y}_i|)^2\\)\n\\(\\sum_{i=1}^{n}(|y_i + \\hat{y}_i|)\\)\n\\(\\sum_{i=1}^{n}(y_i + \\hat{y}_i)^2\\)"
  },
  {
    "objectID": "posts/OLS-Minimierung/OLS-Minimierung.html#answerlist",
    "href": "posts/OLS-Minimierung/OLS-Minimierung.html#answerlist",
    "title": "OLS-Minimierung",
    "section": "",
    "text": "\\(\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\\)\n\\(\\sum_{i=1}^{n}(y_i - \\hat{y}_i)\\)\n\\(\\sum_{i=1}^{n}(|y_i - \\hat{y}_i|)^2\\)\n\\(\\sum_{i=1}^{n}(|y_i + \\hat{y}_i|)\\)\n\\(\\sum_{i=1}^{n}(y_i + \\hat{y}_i)^2\\)"
  },
  {
    "objectID": "posts/OLS-Minimierung/OLS-Minimierung.html#answerlist-1",
    "href": "posts/OLS-Minimierung/OLS-Minimierung.html#answerlist-1",
    "title": "OLS-Minimierung",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/mario-compare-models/index.html",
    "href": "posts/mario-compare-models/index.html",
    "title": "mario-compare-models",
    "section": "",
    "text": "1 Aufgabe\nVariieren Sie das folgende Modell mit einer bzw. beiden UV bzw. mit Interaktionseffekt. Welches Modell ist am besten?\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\nHinweise:\n\nNutzen Sie den Datensatz mariokart.\nBonus: Visualisieren Sie das Streudiagramm!\n\nDen Datensatz k√∂nnen Sie hier beziehen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n\n2 L√∂sung\n\nlibrary(easystats)\nlibrary(tidyverse)\n\nModelle berechnen:\n\nlibrary(easystats)\n\n# Modell a\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n# Modell b\nlm_mario_start_pr &lt;- lm(total_pr ~ start_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n# Modell c\nlm_mario_ship_pr &lt;- lm(total_pr ~  ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n# Modell d\nlm_mario_2uv_interaktion &lt;- lm(total_pr ~ start_pr + ship_pr + start_pr:ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\nModellg√ºten ausgeben lassen:\n\nr2(lm_mario_2uv)\n\n# R2 for Linear Regression\n       R2: 0.107\n  adj. R2: 0.094\n\nr2(lm_mario_start_pr)\n\n# R2 for Linear Regression\n       R2: 0.107\n  adj. R2: 0.101\n\nr2(lm_mario_ship_pr)\n\n# R2 for Linear Regression\n       R2: 0.000\n  adj. R2: -0.007\n\nr2(lm_mario_2uv_interaktion)\n\n# R2 for Linear Regression\n       R2: 0.108\n  adj. R2: 0.088\n\n\n\n\n3 BONUS\nVisualisieren Sie das Streudiagramm!\n\nlibrary(DataExplorer)\n\nmariokart |&gt; \n  select(total_pr, ship_pr) |&gt; \n  filter(total_pr &lt; 100) |&gt; \n  plot_scatterplot( \"total_pr\")\n\n\n\n\n\n\n\nlibrary(ggpubr)\n\nggscatter(mariokart |&gt; filter(total_pr &lt; 100),\n          x = \"ship_pr\",\n          y = \"total_pr\",\n          add = \"reg.line\")"
  },
  {
    "objectID": "posts/Rethink2m7/Rethink2m7.html",
    "href": "posts/Rethink2m7/Rethink2m7.html",
    "title": "Rethink2m7",
    "section": "",
    "text": "Aufgabe\nThis question is taken from McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Ed.). Taylor and Francis, CRC Press.\n2M7. Assume again the original card problem, with a single card showing a black side face up. Before looking at the other side, we draw another card from the bag and lay it face up on the table. The face that is shown on the new card is white. Show that the probability that the first card, the one showing a black side, has black on its other side is now 0.75. Use the counting method, if you can. Hint: Treat this like the sequence of globe tosses, counting all the ways to see each observation, for each possiible first card.\n         \n\n\nL√∂sung\nLet‚Äôs label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nTo keep things straight, here‚Äôs a visualization of our data.\n\n\n\n\n\n\n\n\n\nWanted is the probability \\(Pr(c1=bb|1b,2w)\\), the probability of drawing (as card 1) a bb card, given that we observerd b in the first draw, denoted as 1b, and a white card in the second draw, denoted as 2w.\nLet‚Äôs draw a tree diagram for easier comprehension.\n\n\n\n\n\n\nIn the diagram, the symbol ‚Äú_b_w‚Äù means that black face of a the bw-card (one black, one white face) was drawn. Similarly, ‚Äú_b_b‚Äù means that one (of the two) black faces of the bb-card (two black faces) was drawn.\nHere, we have to consider two cards. Let‚Äôs use this notation ww-bb for the sequence ‚Äúfirst card is white on both sides, second card is black on both sides‚Äù.\nThe data observed is: first card has one black side, the second card has one white side, i.,e b-w.\nLooking at the tree, we realize that out of all 8 paths, 6 feature the bb card as first card:\n\\(Pr(1bb|b,w) = 6/8 = 3/4 = 0.75\\)\nwhere 1bb means ‚Äúcard 1 is black on both sides‚Äù, and b,w means ‚Äúfirst draw showed a black face, and second card showed a white face‚Äù.\nIn other words, there are 8 valid paths in the tree diagram, out of which 6 belong the the hypothesis that the first card is all black.\nUsing a Bayes-Grid (or ‚ÄúBayes-Box‚Äù), we can depict the situation like this:\n\n\n\n\n\nHyp\nPrior\nL\nunstand_Post\nPost\n\n\n\n\nbb\n1\n6\n6\n6/8 = 3/4\n\n\nbw\n1\n2\n2\n2/8 = 1/4\n\n\nww\n1\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOr, using probability, and not counts:\n\n\n\n\n\nHyp\nPrior\nL\nunstand_Post\nPost\n\n\n\n\nbb\n2\n3/4\n6/4\n3/4\n\n\nbw\n1\n2/4\n2/4\n1/4\n\n\n\n\n\nWhenever the probability of all paths (in a tree diagram) is the same, as it is the case in the present example, we do not need to write down the probability of the path for the likelihood. It is enough to write the number of paths (of course we can if we want).\n\nCategories:\n\nprobability\nbayes\nbayesbox\nrethink-chap2\nstring"
  },
  {
    "objectID": "posts/exp-tab2/index.html",
    "href": "posts/exp-tab2/index.html",
    "title": "exp-tab2",
    "section": "",
    "text": "1 Aufgabe\nGegeben sei\n\\(x \\sim \\text{Exp}(1)\\).\nGesucht ist folgendes ETI: 95 %.\nNutzen Sie die Tabelle der Exponentialverteilung, um das Quantil zu bestimmen.\n\n\n\n\n\n\nrate\n2.5 %\n5 %\n50 %\n95 %\n97.5 %\n\n\n\n\n1.00\n0.03\n0.05\n0.69\n3.00\n3.69\n\n\n2.00\n0.01\n0.03\n0.35\n1.50\n1.84\n\n\n4.00\n0.01\n0.01\n0.17\n0.75\n0.92\n\n\n8.00\n0.00\n0.01\n0.09\n0.37\n0.46\n\n\n0.50\n0.05\n0.10\n1.39\n5.99\n7.38\n\n\n0.25\n0.10\n0.21\n2.77\n11.98\n14.76\n\n\n0.12\n0.20\n0.41\n5.55\n23.97\n29.51\n\n\n\n\n\n\nDie gleiche Tabelle als Bild:\n\n\n\n\n\n\n\n\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nETI steht f√ºr Equal Tail Interval, eine spezielle von Konfidenzintervall bei einer Bayes-Analyse.\nUntere Grenze: 0.03\nObere Grenze: 3.69"
  },
  {
    "objectID": "posts/bike01/bike01.html",
    "href": "posts/bike01/bike01.html",
    "title": "bike01",
    "section": "",
    "text": "Kann man die Anzahl gerade verliehener Fahrr√§der eines entsprechenden Anbieters anhand der Temperatur vorhersagen?\nIn dieser √úbung untersuchen wir diese Frage.\nSie k√∂nnen die Daten von der Webseite der UCI herunterladen.\nWir beziehen uns auf den Datensatz day.\nBerechnen Sie ein lineares Modell mit der Anzahl der aktuell vermieteten R√§der als AV und der aktuellen Temperatur als UV!\nGeben Sie den MSE an!\nHinweise"
  },
  {
    "objectID": "posts/bike01/bike01.html#data-split",
    "href": "posts/bike01/bike01.html#data-split",
    "title": "bike01",
    "section": "Data split",
    "text": "Data split\n\nset.seed(42)\nsplit_vec &lt;- initial_split(d, strata = cnt)\n\nd_train &lt;- training(split_vec)\nd_test &lt;- testing(split_vec)"
  },
  {
    "objectID": "posts/bike01/bike01.html#define-recipe",
    "href": "posts/bike01/bike01.html#define-recipe",
    "title": "bike01",
    "section": "Define recipe",
    "text": "Define recipe\n\nrec1 &lt;- \n  recipe(cnt ~ temp, data = d)"
  },
  {
    "objectID": "posts/bike01/bike01.html#define-model",
    "href": "posts/bike01/bike01.html#define-model",
    "title": "bike01",
    "section": "Define model",
    "text": "Define model\n\nm1 &lt;-\n  linear_reg()"
  },
  {
    "objectID": "posts/bike01/bike01.html#workflow",
    "href": "posts/bike01/bike01.html#workflow",
    "title": "bike01",
    "section": "Workflow",
    "text": "Workflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(m1) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/bike01/bike01.html#fit",
    "href": "posts/bike01/bike01.html#fit",
    "title": "bike01",
    "section": "Fit",
    "text": "Fit\n\nfit1 &lt;- last_fit(wf1, split_vec)\nfit1"
  },
  {
    "objectID": "posts/bike01/bike01.html#model-performance-metrics-in-test-set",
    "href": "posts/bike01/bike01.html#model-performance-metrics-in-test-set",
    "title": "bike01",
    "section": "Model performance (metrics) in test set",
    "text": "Model performance (metrics) in test set\n\nfit1 %&gt;% collect_metrics()\n\n\nMSE &lt;- fit1 %&gt;% collect_metrics() %&gt;% pluck(3, 1)\nMSE\n\nSolution:\n\nCategories:\n\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/k-coins-k-hits/k-coins-k-hits.html",
    "href": "posts/k-coins-k-hits/k-coins-k-hits.html",
    "title": "k-coins-k-hits",
    "section": "",
    "text": "Aufgabe\nSie werfen eine M√ºnze \\(k = 6\\) Mal; die Trefferchance betrage \\(p = 0.9\\). Die M√ºnzw√ºrfe seien unabh√§ngig voneinander.\nWie hoch ist die Wahrscheinlichkeit f√ºr (genau) \\(k = 6\\) Treffer?\nBeachten Sie die Bearbeitungshinweise.\n         \n\n\nL√∂sung\nTrefferchance bei jedem Wurf:\n\n\n[1] 0.9\n\n\nAnzahl W√ºrfe/M√ºnzen:\n\n\n[1] 6\n\n\nAufgrund der Multiplikationsregel der Wahrscheinlichkeitsrechnung sind die Wahrscheinlichkeiten der \\(k\\) Ereignisse (Treffer) zu multiplizieren, da unabh√§ngig. Da es nur eine M√∂glichkeit gibt, bei \\(k\\) W√ºrfen \\(k\\) Treffer zu erzielen, gibt es nur einen ‚ÄúPfad‚Äù.\n\nsol &lt;- p^k  # \"sol\" wie \"solution\" (L√∂sung)\nsol\n\n[1] 0.531441\n\n\n\nAufgaben-ID: k-coins-k-hits\n\nCategories:\n\nprobability\ndyn\nbayes\nnum"
  },
  {
    "objectID": "posts/groesse02/groesse02.html",
    "href": "posts/groesse02/groesse02.html",
    "title": "groesse02",
    "section": "",
    "text": "Aufgabe\nWir interessieren uns f√ºr die typische K√∂rpergr√∂√üe deutscher Studentis. Hier findet sich dazu ein Datensatz.\nAusgehend von der Annahme, dass sich die K√∂rpergr√∂√üe normalverteilt (innerhalb eines Geschlechts) suchen wir die Parameter der Normalverteilung, also Mittelwert und Streuung.\nGehen wir von folgenden Apriori-Wahrscheinlichkeiten f√ºr die Parameter der Normalverteilung aus:\n\nMittelwert: 150cm bis 200 cm, jeder Wert gleich plausibel, alle anderen Werte unm√∂glich\nSD: 1cm bis 20cm, jeder Wert gleich plausibel, alle anderen Werte unm√∂glich\n\nJa, das sind ziemlich einf√§ltige Annahmen, aber gut, fangen wir damit an.\nErstellen Sie eine Bayes-Box!\nHinweise:\n\nUntersuchen Sie den angegebenen Parameterbereich in 1cm-Schritten.\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\n\nlibrary(pradadata)  # f√ºr den Datensatz `wo_men`\nlibrary(prada)  # f√ºr bayesbox, alternativ mit `source`\nlibrary(tidyverse)\nlibrary(ggpubr)\n\nDaten importieren:\n\ndata(wo_men)\n\nAlternativ per URL:\n\nwo_men &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/wo_men.csv\")\n\nMittelwert in der Stichprobe:\n\nwo_men |&gt; \n  group_by(sex) |&gt; \n  summarise(height_avg = mean(height, na.rm = TRUE),\n            height_sd = sd(height, na.rm = TRUE))\n\n\n\n\n\nsex\nheight_avg\nheight_sd\n\n\n\n\nman\n183.1111\n9.958082\n\n\nwoman\n161.3095\n42.782380\n\n\nNA\nNaN\nNA\n\n\n\n\n\n\nZur Berechnung der Likelihoods diskretisieren wir die stetige Variable height in Stufen von jeweils 1cm, der Einfachheit halber.\nDie Wahrscheinlichkeit f√ºr das 1cm-Intervall um unserem Stichprobenergebnis herem (182.5cm bis 183.5cm), bei z.B. einem Mittelwert von 180cm und einer SD von 10cm, entspricht dann dieser Differenz:\n\nobere_grenze &lt;- pnorm(q = 183 + 0.5, mean = 180, sd = 10)\nuntere_grenze &lt;- pnorm(q = 183 - 0.5, mean = 180, sd = 10)\n\nobere_grenze\n\n[1] 0.6368307\n\nuntere_grenze\n\n[1] 0.5987063\n\nobere_grenze - untere_grenze\n\n[1] 0.03812433\n\n\nVisualisieren wir uns kurz dieses Intervall.\n\nlibrary(mosaic)\nxpnorm(q = c(182.5, 183.5), mean = 180, sd = 10)\n\n\n\n\n\n\n\n\n[1] 0.5987063 0.6368307\n\n\nAls n√§chstes legen wir die Werte f√ºr unsere Bayes-Box fest.\n\nnorm_mean &lt;- seq(from = 150, to = 200, by = 1)\nnorm_sd &lt;- seq(from = 1, to = 20, by = 1)\n\nJetzt bauen wir unsere Bayes-Box.\nWenn wir die Wahrscheinlichkeiten der Parameter f√ºr alle Kombinationen aus 51 Mittelwerten und 20 SD-Werten pr√ºfen wollen, wird die Tabelle ganz sch√∂n lang:\n\nanzahl_kombinationen &lt;- length(norm_mean) * length(norm_sd)\nanzahl_kombinationen\n\n[1] 1020\n\n\nMit expand_grid kann man sich eine Tabelle erstellen lassen, die alle Kombinationen zweier Variablen aufschreibt:\n\nbayes_box &lt;-\n  expand_grid(norm_mean, norm_sd)\n\nhead(bayes_box)\n\n\n\n\n\nnorm_mean\nnorm_sd\n\n\n\n\n150\n1\n\n\n150\n2\n\n\n150\n3\n\n\n150\n4\n\n\n150\n5\n\n\n150\n6\n\n\n\n\n\n\nDas sind unsere Parameterwerte: Jede Kombination eines Mittelwerts und einer Streuung ist eine Hypothese. Insgesamt haben wir also 1020 Parameterwerte.\nSo, bauen wir die Bayes-Box weiter:\n\nL &lt;- pnorm(183.5, mean = bayes_box$norm_mean, sd = bayes_box$norm_sd)\n\nbayes_box2 &lt;-\n  bayes_box |&gt; \n  mutate(hyp = 1:anzahl_kombinationen,\n         lik = L,\n         post_unstand = hyp * lik,\n         post_std = post_unstand / sum(post_unstand))\n\n\nsamples &lt;-\n  bayes_box2 |&gt; \n  slice_sample(\n    n = 1e4,\n    weight_by = post_std,\n    replace = TRUE\n  )\n\nUnd jetzt visualisieren:\n\nsamples |&gt; \n  ggplot() +\n  aes(x = norm_sd,\n      y = norm_mean,\n      fill = post_std) +\n  geom_tile() +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\nDie Stichproben-Postverteilung erlaubt es auch bequem, die einzelnen Parameter der Post-Verteilung jeweils f√ºr sich zu visualisieren:\n\ngghistogram(samples,\n            x = \"norm_mean\",\n            bins = 15)\n\n\n\n\n\n\n\n\n\nggdensity(samples,\n          x = \"norm_mean\")\n\n\n\n\n\n\n\n\n\nggdensity(samples,\n          x = \"norm_sd\")\n\n\n\n\n\n\n\n\n\nCategories: Categories:\n\n2023\nbayes\nbayes-box\nstring"
  },
  {
    "objectID": "posts/Wertzuweisen/Wertzuweisen.html",
    "href": "posts/Wertzuweisen/Wertzuweisen.html",
    "title": "Wertzuweisen",
    "section": "",
    "text": "Aufgabe\nWeisen Sie dem Objekt loesung den Wert 42 zu. Geben Sie den korrekten R-Code daf√ºr ein.\nHinweis: Verzichten Sie jegliche Leerzeichen in Ihrer Eingabe, da sonst die Eingabe nicht als korrekt erkannt werden kann.\n         \n\n\nL√∂sung\nloesung&lt;-42\n\nCategories:\n\nR\n‚Äò2023‚Äô\nstring"
  },
  {
    "objectID": "posts/additionssatz1/additionssatz1.html",
    "href": "posts/additionssatz1/additionssatz1.html",
    "title": "Additionssatz1",
    "section": "",
    "text": "Aufgabe\nEin Hersteller √ºberteuerter Mobilfunkger√§te vermutet, dass 80% seiner Kunden auf der Webseite A (Schick-und-Sch√∂n) abh√§ngen, und 50% seiner Kunden auf der Webseite B (Cool-but-Useless). Au√üerdem sch√§tzt er, dass 35% der Kunden auf beiden Seiten abh√§ngen. Auf beiden Webseiten schaltet der Hersteller eine gro√üe Werbeanzeige.\nAufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass ein potenzieller Kunde die Anzeige liest?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nSei \\(A\\) ‚ÄúLeute, die auf Webseite A abh√§ngen‚Äù.\nSei \\(B\\) ‚ÄúLeute, die auf Webseite A abh√§ngen‚Äù.\n\\(Pr(A \\cup B) = Pr(A) + Pr(B) - Pr(AB)\\)\n\nAoderB &lt;- .8 + .5 - .35\nAoderB\n\n[1] 0.95\n\n\nDie L√∂sung lautet 0.95.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/MWberechnen/MWberechnen.html",
    "href": "posts/MWberechnen/MWberechnen.html",
    "title": "MWberechnen",
    "section": "",
    "text": "Question\n\nAufgabe\nBerechnen Sie den Mittelwert folgender Zahlenreihe; ignorieren sie etwaige fehlende Werte. Runden Sie auf zwei Dezimalstellen.\n\n\n[1]  1.06 -2.76 -1.71 -0.12  0.35\n\n\n         \n\n\nL√∂sung\nDer Mittelwert liegt bei -0.64.\nDie Antwort lautet -0.64.\nIn R kann man den Mittelwert z.B. so berechnen:\n\nmean(zahlenreihe, na.rm = TRUE)\n\n[1] -0.636\n\n\nDas Argument na.rm = TRUE sorgt daf√ºr, dass R auch bei Vorhandensein fehlender Werte ein Ergebnis ausgibt. Ohne dieses Argument w√ºrde R ein spr√∂des NA zur√ºckgeben, falls fehlende Werte vorliegen. Dieses Verhalten von R ist recht defensiv, getreu dem Motto: Wenn es ein Problem gibt, sollte man so fr√ºh wie m√∂glich dar√ºber deutlich informiert werden (und nicht erst, wenn die Marsrakete gestartet ist‚Ä¶).\n\nCategories:\n\neda\ndatawrangling\nnum\ndyn"
  },
  {
    "objectID": "posts/distros/index.html",
    "href": "posts/distros/index.html",
    "title": "distros",
    "section": "",
    "text": "1 Aufgabe\nOrdnen Sie die folgenden Diagrammen von Verteilungen den richtigen Namen (der Verteilung zu).\nA\n\n\n\n\n\n\n\n\n\nB\n\n\n\n\n\n\n\n\n\nC\n\n\n\n\n\n\n\n\n\nD\n\n\n\n\n\n\n\n\n\n\nExpontialverteilung\nNormalverteilung\nBinomialverteilung\nGleichverteilung\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nA - Binomialverteilung\nB - Normalverteilung\nC - Gleichverteilung\nD - Expontialverteilung\nBildquelle:\nCoded by Rasmus B√•√•th\nrasmus.baath@lucs.lu.se www.sumsar.net"
  },
  {
    "objectID": "posts/kausal09/kausal09.html",
    "href": "posts/kausal09/kausal09.html",
    "title": "kausal09",
    "section": "",
    "text": "Ein Forschungsteam aus Epidemiologen untersucht den (m√∂glicherweise kausalen) Zusammenhang von Erziehung (education) und Diabetes (diabetes). Das Team schl√§gt folgendes Modell zur Erkl√§rung des Zusammenhangs vor (s. DAG).\n\n\n\n\n\n\n\n\n\nNochmal den gleich DAG ohne ‚ÄúSchilder‚Äù, damit man die Pfeilspitzen besser sieht:\n\n\n\n\n\n\n\n\n\nSollte die Krankengeschichte der Mutter hinsichtlich Diabetes kontrolliert werden, um den kausalen Effekt von Erziehung auf Diabetes zu identifizieren?\n\n\n\nNein, Mother's Diabetes sollte nicht kontrolliert werden, da so ein Collider Bias (Kollisionsverzerrung) resultiert.\nNein, Mother's Diabetes sollte nicht kontrolliert werden, da so eine Konfundierung resultiert.\nNein, Mother's Diabetes sollte nicht kontrolliert werden, da zwar keine Verzerrung entsteht, es aber auch nicht n√∂tig ist.\nJa, Mother's Diabetes sollte kontrolliert werden, da so ein Collider Bias (Kollisionsverzerrung) vermieden wird.\nJa, Mother's Diabetes sollte kontrolliert werden, da so eine Konfundierung vermieden wird."
  },
  {
    "objectID": "posts/kausal09/kausal09.html#answerlist",
    "href": "posts/kausal09/kausal09.html#answerlist",
    "title": "kausal09",
    "section": "",
    "text": "Nein, Mother's Diabetes sollte nicht kontrolliert werden, da so ein Collider Bias (Kollisionsverzerrung) resultiert.\nNein, Mother's Diabetes sollte nicht kontrolliert werden, da so eine Konfundierung resultiert.\nNein, Mother's Diabetes sollte nicht kontrolliert werden, da zwar keine Verzerrung entsteht, es aber auch nicht n√∂tig ist.\nJa, Mother's Diabetes sollte kontrolliert werden, da so ein Collider Bias (Kollisionsverzerrung) vermieden wird.\nJa, Mother's Diabetes sollte kontrolliert werden, da so eine Konfundierung vermieden wird."
  },
  {
    "objectID": "posts/kausal09/kausal09.html#answerlist-1",
    "href": "posts/kausal09/kausal09.html#answerlist-1",
    "title": "kausal09",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/mutate01/mutate01.html",
    "href": "posts/mutate01/mutate01.html",
    "title": "mutate01",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nErzeugen Sie eine Spalte zu_teuer, die folgende Pr√ºfung durchf√ºhrt: total_pr &gt; 100.\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nmariokart &lt;- \n  mutate(mariokart, zu_teuer = total_pr &gt; 100)\n\nmariokart2 &lt;-\n  select(mariokart, total_pr, zu_teuer)\n\nhead(mariokart2)\n\n\n\n\n\ntotal_pr\nzu_teuer\n\n\n\n\n51.55\nFALSE\n\n\n37.04\nFALSE\n\n\n45.50\nFALSE\n\n\n44.00\nFALSE\n\n\n71.00\nFALSE\n\n\n45.00\nFALSE\n\n\n\n\n\n\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/Diamonds-Histogramm-Vergleich/Diamonds-Histogramm-Vergleich.html",
    "href": "posts/Diamonds-Histogramm-Vergleich/Diamonds-Histogramm-Vergleich.html",
    "title": "Diamonds-Histogramm-Vergleich",
    "section": "",
    "text": "Die Daten beziehen sich auf den Datensatz diamonds und sind hier einzusehen bzw. k√∂nnen bei Interesse dort heruntergeladen werden.\n\n\n\n\n\n\n\n\n\nHinweise:\n\nMit ‚ÄúFacette‚Äù sind ‚ÄúTeilbilder‚Äù gemeint, die jeweils eine Teilgruppe der Daten visualisieren, z.B. k√∂nnte die Variable ‚ÄúGeschlecht‚Äù zwei Facetten (Frauen, M√§nner) beinhalten.\n\n\n\n\nDer vertikale Strich passt nicht auf den Median.\nEs ist nicht sinnvoll, die Gesamtverteilung zus√§tzlich zur Verteilung pro Gruppe in jeder Facette darzustellen.\nDen globalen Median (f√ºr den gesamten Datensatz, also √ºber alle Gruppen hinweg) in jeder Facette darzustellen, ist redundant. Daher ist es besser, in jeder Facetten den Median pro Gruppe darzustellen.\nDie Verwendung einer F√ºllfarbe (Diagramm B) ist hier nicht sinnvoll."
  },
  {
    "objectID": "posts/Diamonds-Histogramm-Vergleich/Diamonds-Histogramm-Vergleich.html#answerlist",
    "href": "posts/Diamonds-Histogramm-Vergleich/Diamonds-Histogramm-Vergleich.html#answerlist",
    "title": "Diamonds-Histogramm-Vergleich",
    "section": "",
    "text": "Der vertikale Strich passt nicht auf den Median.\nEs ist nicht sinnvoll, die Gesamtverteilung zus√§tzlich zur Verteilung pro Gruppe in jeder Facette darzustellen.\nDen globalen Median (f√ºr den gesamten Datensatz, also √ºber alle Gruppen hinweg) in jeder Facette darzustellen, ist redundant. Daher ist es besser, in jeder Facetten den Median pro Gruppe darzustellen.\nDie Verwendung einer F√ºllfarbe (Diagramm B) ist hier nicht sinnvoll."
  },
  {
    "objectID": "posts/Diamonds-Histogramm-Vergleich/Diamonds-Histogramm-Vergleich.html#answerlist-1",
    "href": "posts/Diamonds-Histogramm-Vergleich/Diamonds-Histogramm-Vergleich.html#answerlist-1",
    "title": "Diamonds-Histogramm-Vergleich",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html",
    "href": "posts/wskt-df-r/wskt-df-r.html",
    "title": "wskt-df-r",
    "section": "",
    "text": "In dieser Aufgabe betrachten wir typische Relationen von Ereignissen, um typische Fragen der Wahrscheinlichkeitsrechnung zu beantworten.\nGegeben sei folgender Datensatz d:\n\n#echo: true\nd &lt;-\n  data.frame(\n    A = c(1, 1, 0, 0),\n    B = c(1, 0, 1, 0)\n  )\n\nd\n\n\n\n\n\nA\nB\n\n\n\n\n1\n1\n\n\n1\n0\n\n\n0\n1\n\n\n0\n0\n\n\n\n\n\n\nDer Datensatz d stellt alle vier Kombinationen der beiden Variablen A und B da (wir gehen davon aus, dass es sich um bin√§re Variablen, wie Ereignisse, handelt, der Einfachheit halber).\nDabei steht A == 1 f√ºr \\(A\\) (Ereignis \\(A\\) ist der Fall) und A == 0 f√ºr \\(\\neg A\\), A tritt nicht ein, ist nicht der Fall.\nGenerell wird in der Wissenschaft und Technik 0 f√ºr ‚Äúnein, falsch‚Äù und 1 f√ºr ‚Äúja, wahr, richtig‚Äù verwendet.\nAufgabe: Berechnen Sie mit R \\(Pr(A\\cap B), Pr(\\neg A\\cap B), Pr(A\\cup B), Pr(A|B), Pr(B|A)\\)!"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#setup",
    "href": "posts/wskt-df-r/wskt-df-r.html#setup",
    "title": "wskt-df-r",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\n\nHier ist unserer Datentabelle d, wie oben erstellt::\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n1\n1\n\n\n1\n0\n\n\n0\n1\n\n\n0\n0"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#pracap-b",
    "href": "posts/wskt-df-r/wskt-df-r.html#pracap-b",
    "title": "wskt-df-r",
    "section": "\\(Pr(A\\cap B)\\)",
    "text": "\\(Pr(A\\cap B)\\)\n\nd |&gt; \n  filter(A == 1 & B == 1)\n\n\n\n\n\nA\nB\n\n\n\n\n1\n1\n\n\n\n\n\n\nAlso 1 von 4 Zeilen, das hei√üt 1/4 oder .25.\nMan kann das auch mit count ausrechnen:\n\nd |&gt; \n  count(A == 1 & B == 1)\n\n\n\n\n\nA == 1 & B == 1\nn\n\n\n\n\nFALSE\n3\n\n\nTRUE\n1\n\n\n\n\n\n\nDer Operator & steht f√ºr das logische ‚ÄúUND‚Äù (Schnitt, intersect).\nUnd so kann man sich noch die Anteile ausrechnen lassen:\n\nd |&gt; \n  count(A == 1 & B == 1) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\nA == 1 & B == 1\nn\nAnteil\n\n\n\n\nFALSE\n3\n0.75\n\n\nTRUE\n1\n0.25"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#prneg-acap-b",
    "href": "posts/wskt-df-r/wskt-df-r.html#prneg-acap-b",
    "title": "wskt-df-r",
    "section": "\\(Pr(\\neg A\\cap B)\\)",
    "text": "\\(Pr(\\neg A\\cap B)\\)\n\\(Pr(\\neg A\\cap B)\\) ist im Prinzip identisch zum Schnitt ohne Negation:\n\nd |&gt; \n  count(A == 0 & B == 1) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\nA == 0 & B == 1\nn\nAnteil\n\n\n\n\nFALSE\n3\n0.75\n\n\nTRUE\n1\n0.25\n\n\n\n\n\n\nOder so:\n\nd |&gt; \n  count(!(A == 1) & B == 1) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\n!(A == 1) & B == 1\nn\nAnteil\n\n\n\n\nFALSE\n3\n0.75\n\n\nTRUE\n1\n0.25\n\n\n\n\n\n\nDer Operator ! entspricht der logischen Negation."
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#pracup-b",
    "href": "posts/wskt-df-r/wskt-df-r.html#pracup-b",
    "title": "wskt-df-r",
    "section": "\\(Pr(A\\cup B)\\)",
    "text": "\\(Pr(A\\cup B)\\)\nKommen wir zu \\(Pr(A\\cup B)\\), der logischen Vereinigung, auch logisches ‚ÄúODER‚Äù genannt.\n\nd |&gt; \n  count((A == 1) | (B == 1)) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\n(A == 1) | (B == 1)\nn\nAnteil\n\n\n\n\nFALSE\n1\n0.25\n\n\nTRUE\n3\n0.75\n\n\n\n\n\n\nDer Operator | steht in R f√ºr das logische ODER.\nWie man sieht, kann man die Klammern um (A == 1) | (B == 1) verwenden f√ºr bessere Sichtbarkeit. Es ist aber nicht n√∂tig."
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#prab",
    "href": "posts/wskt-df-r/wskt-df-r.html#prab",
    "title": "wskt-df-r",
    "section": "\\(Pr(A|B)\\)",
    "text": "\\(Pr(A|B)\\)\n\\(Pr(A|B)\\) entspricht einem Filtern, d.h. bedingen auf B entspricht einem Filtern, so dass nur noch \\(B\\) und nicht \\(\\neg B\\) √ºbrig bleibt.\n\nd |&gt; \n  filter(B == 1) |&gt; \n  count(A)\n\n\n\n\n\nA\nn\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n\n\n\n\n1 Fall von 2 erf√ºllt die Bedingung A == 1, also 50%."
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#prba",
    "href": "posts/wskt-df-r/wskt-df-r.html#prba",
    "title": "wskt-df-r",
    "section": "\\(Pr(B|A)\\)",
    "text": "\\(Pr(B|A)\\)\nDiese Aufgabe ist analog zu \\(Pr(A|B)\\):\n\nd |&gt; \n  filter(A == 1) |&gt; \n  count(B)\n\n\n\n\n\nB\nn\n\n\n\n\n0\n1\n\n\n1\n1"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#bonus-prbneg-a",
    "href": "posts/wskt-df-r/wskt-df-r.html#bonus-prbneg-a",
    "title": "wskt-df-r",
    "section": "Bonus \\(Pr(B|\\neg A)\\)",
    "text": "Bonus \\(Pr(B|\\neg A)\\)\n\\(Pr(B|\\neg A)\\) - Eigentlich nichts Neues:\n\nd |&gt; \n  filter(!(A == 1)) |&gt; \n  count(B)\n\n\n\n\n\nB\nn\n\n\n\n\n0\n1\n\n\n1\n1"
  },
  {
    "objectID": "posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html",
    "href": "posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html",
    "title": "stan_glm_parameterzahl",
    "section": "",
    "text": "Exercise\nBerechnet man eine Posteriori-Verteilung mit stan_glm(), so kann man entweder die schwach informativen Prioriwerte der Standardeinstellung verwenden, oder selber Prioriwerte definieren.\nBetrachten Sie dazu dieses Modell:\nstan_glm(price ~ cut, data = diamonds, \n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(100, 100, 100, 100)),\n                   prior_aux = exponential(1),\n                   prior_intercept = normal(3000, 500))\nWie viele Parameter gibt es in diesem Modell?\nHinweise:\n\nGeben Sie nur eine (ganze) Zahl ein.\n\n         \n\n\nSolution\nGrunds√§tzlich hat ein Regressionsmodell die folgenden Parameter:\n\neinen Parameter f√ºr den Intercept, \\(\\beta_0\\)\npro UV ein weiterer Parameter, \\(\\beta_1, \\beta_2, \\ldots\\)\nf√ºr sigma (\\(\\sigma\\)) noch ein zus√§tzlicher Parameter\n\nZu beachten ist aber, dass bei einer nominalen Variablen mit zwei Stufen nur ein Regressionsgewicht (\\(\\beta_1\\)) berechnet wird. Allgemein gilt bei nominalen also, dass bei \\(k\\) Stufen nur \\(k-1\\) Regressionsgewichte berechnet werden.\nIm vorliegenden Fall hat die Variable cut 5 Stufen, also werden 4 Regressiongewichte berechnet.\nFazit: In Summe werden also 6 Parameter berechnet.\n\nlibrary(tidyverse)\nlibrary(rstanarm)\n\nBerechnet man das Modell, so kann man sich auch Infos √ºber die Prioris ausgeben lassen:\n\nm1 &lt;- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100)),\n               prior_intercept = normal(3000, 500),\n               prior_aux = exponential(1),\n               refresh = 0)\n\nprior_summary(m1)\n\nPriors for model 'm1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 3000, scale = 500)\n\nCoefficients\n ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nWie man sieht, wird f√ºr die Streuung im Standard eine Exponentialverteilung verwendet von stan_glm(). Gibt man also nicht an - wie im Beispiel m1 oben, so wird stan_glm() f√ºr die Streuung, d.h. prior_aux eine Exponentialverteilung verwenden. Zu beachten ist, dass stan_glm() ein automatische Skalierung vornimmt.\nS. hier f√ºr weitere Erl√§uterung.\nM√∂chte man den Prior f√ºr die Streuung direkt ansprechen, so kann man das so formulieren:\n\nm2 &lt;- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100)),\n               prior_intercept = normal(3000, 500),\n               prior_aux = exponential(1),\n               refresh = 0)\n\nprior_summary(m1)\n\nPriors for model 'm1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 3000, scale = 500)\n\nCoefficients\n ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nZu beachten ist beim selber definieren der Prioris, dass dann keine Auto-Skalierung von stan_glm() vorgenommen wird, es sei denn, man weist es explizit an:\n\nm3 &lt;- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100),\n                              autoscale = TRUE),\n               prior_intercept = normal(3000, 500, autoscale = TRUE),\n               prior_aux = exponential(1, autoscale = TRUE),\n               chain = 1,  # nur 1 mal Stichproben ziehen, um Zeit zu sparen\n               refresh = 0)\n\nprior_summary(m3)\n\nPriors for model 'm3' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 3000, scale = 500)\n  Adjusted prior:\n    ~ normal(location = 3000, scale = 2e+06)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n  Adjusted prior:\n    ~ normal(location = [100,100,100,...], scale = [1129833.17, 868199.02, 936606.47,...])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.00025)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nGrunds√§tzlich ist es n√ºtzlich f√ºr die numerische Stabilit√§t, dass die Zahlen (hier die Parameterwerte) etwa die gleiche Gr√∂√üenordnung haben, am besten um die 0-1 herum. Daher bietet sich oft eine z-Standardisierung an.\nUnabh√§ngig von der der Art der Parameter ist die Anzahl immer gleich.\nDie Anzahl der gesch√§tzten Parameter werden im Modell-Summary unter Estimates gezeigt:\n\nsummary(m1)\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      price ~ cut\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 53940\n predictors:   5\n\nEstimates:\n              mean   sd     10%    50%    90% \n(Intercept) 4027.5   21.7 4000.1 4027.7 4055.3\ncut.L       -249.1   51.5 -315.9 -249.4 -182.0\ncut.Q       -283.4   45.5 -340.8 -283.8 -223.7\ncut.C       -581.1   43.7 -637.0 -582.1 -523.9\ncut^4       -265.7   37.6 -313.3 -265.6 -217.4\nsigma       3830.2   11.3 3815.7 3830.1 3844.6\n\nFit Diagnostics:\n           mean   sd     10%    50%    90% \nmean_PPD 3931.8   23.1 3902.7 3932.1 3961.4\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.4  1.0  2750 \ncut.L         1.0  1.0  2604 \ncut.Q         1.0  1.0  2246 \ncut.C         0.9  1.0  2536 \ncut^4         0.7  1.0  3024 \nsigma         0.1  1.0  6932 \nmean_PPD      0.4  1.0  3604 \nlog-posterior 0.0  1.0  1701 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\n\nDas sind:\n\n1 Intercept (Achsenabschnitt) - prior_intercept\n4 Gruppen (zus√§tzlich zur Referenzgruppe, die mit dem Achsenabschnitt dargestellt ist) - prior_normal\n1 Sigma (Ungewissheit ‚Äúinnerhalb des Modells‚Äù) - prior_aux\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/maschinendesaster/index.html",
    "href": "posts/maschinendesaster/index.html",
    "title": "maschinendesaster",
    "section": "",
    "text": "1 Aufgabe\n\nEine Maschine bestehe aus n=100 Teilen. Jedes Teil habe eine Zuverl√§ssigkeit (f√ºr Funktionsf√§higkeit) von r=.99 (f√ºr ein bestimmtes Zeitintervall t). Nur solange alle Teile arbeiten, arbeitet die Maschine, ansonsten f√§llt sie aus.\nWie gro√ü ist die Wahrscheinlichkeit, dass die Maschine im Zeitintervall t ausf√§llt?\nHinweise:\n\nGehen Sie von Unabh√§ngigkeit (der Zuverl√§ssigkeit) der Teile aus.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nNun zur Berechnung der Wahrscheinlichkeit, dass die Maschine im Zeitintervall t ausf√§llt:\nGegeben sind:\nAnzahl der Teile (n): = 100\nZuverl√§ssigkeit jedes Teils (r): = 0,99\n\nn &lt;- 100\nr &lt;- 0.99\n\nDie Maschine funktioniert nur, wenn alle 100 Teile funktionieren. D a die Zuverl√§ssigkeiten der Teile unabh√§ngig voneinander sind, ist die Wahrscheinlichkeit, dass die Maschine funktioniert (P(Maschine funktioniert)):\nP(Maschine funktioniert) = r^n = (0,99)^100\n\nP_maschine_funzt &lt;- r^n\nP_maschine_funzt\n\n[1] 0.3660323\n\n\nDie Wahrscheinlichkeit, dass die Maschine im Zeitintervall t ausf√§llt, ist das Komplement√§rereignis dazu, dass die Maschine funktioniert:\nP(Maschine f√§llt aus) = 1 - P(Maschine funktioniert)\nBerechnung:\n\nP_maschine_faellt_aus &lt;- 1 - P_maschine_funzt\nP_maschine_faellt_aus\n\n[1] 0.6339677\n\n\nDie Wahrscheinlichkeit, dass die Maschine im Zeitintervall t ausf√§llt, betr√§gt ungef√§hr 63,40%.\n\n\n3 Variante\n\nn &lt;- 1000\nr &lt;- .99\nP_maschine_funzt &lt;- r^n\nP_maschine_faellt_aus &lt;- 1 - P_maschine_funzt\nP_maschine_faellt_aus\n\n[1] 0.9999568\n\n\n\n\n4 Ausfallwahrscheinlichkeit in Abh√§ngigkeit der Anzahl der Teile\n\nn_min &lt;- 10\nn_max &lt;- 1000\nn_teile &lt;- seq(n_min, n_max, by = 10)\nP_maschine_faellt_aus &lt;- 1 - r^n_teile\n\nErgebnisse in einem Data Frame speichern:\n\n ergebnisse &lt;- data.frame(\n  Teile = n_teile,\n  Ausfallwahrscheinlichkeit = P_maschine_faellt_aus,\n  Ausfallwahrscheinlichkeit_Prozent = P_maschine_faellt_aus * 100\n)\n\n\n ggplot(ergebnisse, aes(x = Teile, y = Ausfallwahrscheinlichkeit)) +\n  geom_line(color = \"red\", size = 1) +\n  geom_point(color = \"darkred\", size = 0.5) +\n  labs(\n    title = \"Ausfallwahrscheinlichkeit vs. Anzahl der Teile\",\n    subtitle = paste(\"Zuverl√§ssigkeit pro Teil: r =\", r),\n    x = \"Anzahl der Teile\",\n    y = \"Ausfallwahrscheinlichkeit\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = scales::percent_format()) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"blue\", alpha = 0.7) +\n  annotate(\"text\", x = 500, y = 0.52, label = \"50% Ausfallrisiko\", color = \"blue\")"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html",
    "title": "tidymodels-tree2",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nEntscheidungsbaum\n\nModellformel: am ~ . (Datensatz mtcars)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nVerwenden mehrerer Prozesskerne\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nF√ºhren Sie eine \\(v=2\\)-fache Kreuzvalidierung durch (weil die Stichprobe so klein ist).\nBeachten Sie die √ºblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#setup",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#setup",
    "title": "tidymodels-tree2",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\nlibrary(doParallel)  # Nutzen mehrerer Kerne\n\nF√ºr Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#daten-teilen",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#daten-teilen",
    "title": "tidymodels-tree2",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#modelle",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#modelle",
    "title": "tidymodels-tree2",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#rezepte",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#rezepte",
    "title": "tidymodels-tree2",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#resampling",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#resampling",
    "title": "tidymodels-tree2",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#workflows",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#workflows",
    "title": "tidymodels-tree2",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#tuningfitting",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#tuningfitting",
    "title": "tidymodels-tree2",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\ntune_grid\n\n\n\n\n\ncost_complexity\ntree_depth\nmin_n\n\n\n\n\n0.0000000\n1\n2\n\n\n0.0000000\n1\n2\n\n\n0.0000032\n1\n2\n\n\n0.0005623\n1\n2\n\n\n0.1000000\n1\n2\n\n\n0.0000000\n4\n2\n\n\n0.0000000\n4\n2\n\n\n0.0000032\n4\n2\n\n\n0.0005623\n4\n2\n\n\n0.1000000\n4\n2\n\n\n0.0000000\n8\n2\n\n\n0.0000000\n8\n2\n\n\n0.0000032\n8\n2\n\n\n0.0005623\n8\n2\n\n\n0.1000000\n8\n2\n\n\n0.0000000\n11\n2\n\n\n0.0000000\n11\n2\n\n\n0.0000032\n11\n2\n\n\n0.0005623\n11\n2\n\n\n0.1000000\n11\n2\n\n\n0.0000000\n15\n2\n\n\n0.0000000\n15\n2\n\n\n0.0000032\n15\n2\n\n\n0.0005623\n15\n2\n\n\n0.1000000\n15\n2\n\n\n0.0000000\n1\n11\n\n\n0.0000000\n1\n11\n\n\n0.0000032\n1\n11\n\n\n0.0005623\n1\n11\n\n\n0.1000000\n1\n11\n\n\n0.0000000\n4\n11\n\n\n0.0000000\n4\n11\n\n\n0.0000032\n4\n11\n\n\n0.0005623\n4\n11\n\n\n0.1000000\n4\n11\n\n\n0.0000000\n8\n11\n\n\n0.0000000\n8\n11\n\n\n0.0000032\n8\n11\n\n\n0.0005623\n8\n11\n\n\n0.1000000\n8\n11\n\n\n0.0000000\n11\n11\n\n\n0.0000000\n11\n11\n\n\n0.0000032\n11\n11\n\n\n0.0005623\n11\n11\n\n\n0.1000000\n11\n11\n\n\n0.0000000\n15\n11\n\n\n0.0000000\n15\n11\n\n\n0.0000032\n15\n11\n\n\n0.0005623\n15\n11\n\n\n0.1000000\n15\n11\n\n\n0.0000000\n1\n21\n\n\n0.0000000\n1\n21\n\n\n0.0000032\n1\n21\n\n\n0.0005623\n1\n21\n\n\n0.1000000\n1\n21\n\n\n0.0000000\n4\n21\n\n\n0.0000000\n4\n21\n\n\n0.0000032\n4\n21\n\n\n0.0005623\n4\n21\n\n\n0.1000000\n4\n21\n\n\n0.0000000\n8\n21\n\n\n0.0000000\n8\n21\n\n\n0.0000032\n8\n21\n\n\n0.0005623\n8\n21\n\n\n0.1000000\n8\n21\n\n\n0.0000000\n11\n21\n\n\n0.0000000\n11\n21\n\n\n0.0000032\n11\n21\n\n\n0.0005623\n11\n21\n\n\n0.1000000\n11\n21\n\n\n0.0000000\n15\n21\n\n\n0.0000000\n15\n21\n\n\n0.0000032\n15\n21\n\n\n0.0005623\n15\n21\n\n\n0.1000000\n15\n21\n\n\n0.0000000\n1\n30\n\n\n0.0000000\n1\n30\n\n\n0.0000032\n1\n30\n\n\n0.0005623\n1\n30\n\n\n0.1000000\n1\n30\n\n\n0.0000000\n4\n30\n\n\n0.0000000\n4\n30\n\n\n0.0000032\n4\n30\n\n\n0.0005623\n4\n30\n\n\n0.1000000\n4\n30\n\n\n0.0000000\n8\n30\n\n\n0.0000000\n8\n30\n\n\n0.0000032\n8\n30\n\n\n0.0005623\n8\n30\n\n\n0.1000000\n8\n30\n\n\n0.0000000\n11\n30\n\n\n0.0000000\n11\n30\n\n\n0.0000032\n11\n30\n\n\n0.0005623\n11\n30\n\n\n0.1000000\n11\n30\n\n\n0.0000000\n15\n30\n\n\n0.0000000\n15\n30\n\n\n0.0000032\n15\n30\n\n\n0.0005623\n15\n30\n\n\n0.1000000\n15\n30\n\n\n0.0000000\n1\n40\n\n\n0.0000000\n1\n40\n\n\n0.0000032\n1\n40\n\n\n0.0005623\n1\n40\n\n\n0.1000000\n1\n40\n\n\n0.0000000\n4\n40\n\n\n0.0000000\n4\n40\n\n\n0.0000032\n4\n40\n\n\n0.0005623\n4\n40\n\n\n0.1000000\n4\n40\n\n\n0.0000000\n8\n40\n\n\n0.0000000\n8\n40\n\n\n0.0000032\n8\n40\n\n\n0.0005623\n8\n40\n\n\n0.1000000\n8\n40\n\n\n0.0000000\n11\n40\n\n\n0.0000000\n11\n40\n\n\n0.0000032\n11\n40\n\n\n0.0005623\n11\n40\n\n\n0.1000000\n11\n40\n\n\n0.0000000\n15\n40\n\n\n0.0000000\n15\n40\n\n\n0.0000032\n15\n40\n\n\n0.0005623\n15\n40\n\n\n0.1000000\n15\n40"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#ohne-parallelisierung",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#ohne-parallelisierung",
    "title": "tidymodels-tree2",
    "section": "Ohne Parallelisierung",
    "text": "Ohne Parallelisierung\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\n28.681 sec elapsed\n\n\nca. 45 sec.¬†auf meinem Rechner (4-Kerne-MacBook Pro 2020)."
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#mit-parallelisierung",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#mit-parallelisierung",
    "title": "tidymodels-tree2",
    "section": "Mit Parallelisierung",
    "text": "Mit Parallelisierung\nWie viele CPUs hat mein Computer?\n\nparallel::detectCores(logical = FALSE)\n\n[1] 4\n\n\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\nfit_tree2 &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\n27.109 sec elapsed\n\n\nca. 17 Sekunden - deutlich schneller!\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/iq09/iq09.html",
    "href": "posts/iq09/iq09.html",
    "title": "iq09",
    "section": "",
    "text": "Aufgabe\nZwei Forscherinnen, Prof.¬†Weiss-Ois und Prof.¬†Blitz-Chegga, streiten sich √ºber den Effekt von Cannabis auf die Intelligenz.\nDazu untersuchen Sie die Intelligenz langj√§hriger Konsumentis.\nProf.¬†Weiss-Ois hat (apriori) folgende Hypothese: \\(IQ \\sim N(90, 10)\\). Prof.¬†Blitz-Chegga hat (apriori) folgende Hypothese: \\(IQ \\sim N(95, 5)\\).\nMit gro√üer Spannung wurden die Messdaten zur Intelligenz erwartet (die erst nach langem Streit √ºber die zu verwendenden Intelligenztests erhoben werden konnten). Insgesamt wurden \\(N=541\\) Personen untersucht.\nTats√§chlich sei die wahre IQ-Verteilung jener Cannabis-Konsumentis wie folgt: \\(IQ \\sim N(92.5, 7.5)\\). Nat√ºrlich kennen die Forschis diese Verteilung nicht.\nWessen Hypothese unterst√ºtzen die Daten mehr? Die von Prof.¬†Weiss-Ois oder von Prof.¬†Blitz-Chegga?\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^4\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html",
    "title": "tidymodels-tree5",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nRandom Forest mit trees=50\n\nModellformel: body_mass_g ~ . (Datensatz palmerpenguins::penguins)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nAuslassen gering performanter Tuningparameterwerte\nVerwenden Sie ein Anova-Grid-Search!\nParallelisieren Sie auf mehrere Kerne (wenn m√∂glich).\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nBeachten Sie die √ºblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#setup",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#setup",
    "title": "tidymodels-tree5",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(\"penguins\", package = \"palmerpenguins\")\nlibrary(tictoc)  # Zeitmessung\nlibrary(finetune)  # tune_race_anova\nlibrary(doParallel)  # mehrere CPUs nutzen \nset.seed(42)\n\nEntfernen wir F√§lle mit fehlenden Werten:\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#daten-teilen",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#daten-teilen",
    "title": "tidymodels-tree5",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#modelle",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#modelle",
    "title": "tidymodels-tree5",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_rf &lt;-\n  rand_forest(mode = \"regression\",\n              mtry = tune())\nmod_rf\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n\nComputational engine: ranger"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#rezepte",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#rezepte",
    "title": "tidymodels-tree5",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(body_mass_g ~ ., data = d_train) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_knn(all_predictors())\n\n\nd_train_baked &lt;-\n  bake(prep(rec_plain, d_train), new_data = NULL)\n\nhead(d_train_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nyear\nbody_mass_g\nspecies_Chinstrap\nspecies_Gentoo\nisland_Dream\nisland_Torgersen\nsex_male\n\n\n\n\n34.5\n18.1\n187\n2008\n2900\n0\n0\n0\n0\n0\n\n\n52.2\n18.8\n197\n2009\n3450\n1\n0\n1\n0\n1\n\n\n45.4\n14.6\n211\n2007\n4800\n0\n1\n0\n0\n0\n\n\n42.1\n19.1\n195\n2008\n4000\n0\n0\n0\n1\n1\n\n\n50.0\n15.9\n224\n2009\n5350\n0\n1\n0\n0\n1\n\n\n41.5\n18.5\n201\n2009\n4000\n0\n0\n1\n0\n1\n\n\n\n\n\n\nKeine fehlenden Werte mehr?\n\nsum(is.na(d_train_baked))\n\n[1] 0"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#resampling",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#resampling",
    "title": "tidymodels-tree5",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#workflows",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#workflows",
    "title": "tidymodels-tree5",
    "section": "Workflows",
    "text": "Workflows\n\nwf_rf &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_rf)\n\nwf_rf\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: rand_forest()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_dummy()\n‚Ä¢ step_impute_knn()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n\nComputational engine: ranger"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#ohne-speed-up",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#ohne-speed-up",
    "title": "tidymodels-tree5",
    "section": "Ohne Speed-up",
    "text": "Ohne Speed-up\n\ntic()\nfit_rf &lt;-\n  tune_grid(\n    object = wf_rf,\n    resamples = rsmpl)\ntoc()\n\n16.801 sec elapsed\n\n\nDie angegebene Rechenzeit bezieht sich auf einen 4-Kerne-MacBook Pro (2020)."
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-1",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-1",
    "title": "tidymodels-tree5",
    "section": "Mit Speeed-up 1",
    "text": "Mit Speeed-up 1\n\ntic()\nfit_rf2 &lt;-\n  tune_race_anova(\n    object = wf_rf,\n    resamples = rsmpl)\ntoc()\n\n27.433 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-2",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-2",
    "title": "tidymodels-tree5",
    "section": "Mit Speeed-up 2",
    "text": "Mit Speeed-up 2\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(\n    object = wf_rf,\n    metrics = metric_set(rmse),\n    control = control_race(verbose = FALSE,\n                           pkgs = c(\"tidymodels\"),\n                           save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n25.795 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-3",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-3",
    "title": "tidymodels-tree5",
    "section": "Mit Speeed-up 3",
    "text": "Mit Speeed-up 3\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_grid(object = wf_rf,\n            metrics = metric_set(rmse),\n            control = control_grid(verbose = FALSE,\n                                   save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n15.888 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#fazit",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#fazit",
    "title": "tidymodels-tree5",
    "section": "Fazit",
    "text": "Fazit\nMit Speed-up ist schneller also ohne. Ein Random-Forest ist ein Modelltyp, der von Parallelisierung gut profitiert.\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/mse/mse.html",
    "href": "posts/mse/mse.html",
    "title": "mse",
    "section": "",
    "text": "Wie ist der MSE definiert? Entscheiden Sie sich f√ºr eine der folgenden Definitionen:\n\n\n\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(y_i -\\hat{f}(x_i))^2\\)\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(y_i -\\hat{f}(x_i))\\)\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(|y_i -\\hat{f}(x_i)|)\\)\n\\(MSE= \\sum^n_{i=1}(y_i -\\hat{f}(x_i))^2\\)\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(y_i + \\hat{f}(x_i))^2\\)"
  },
  {
    "objectID": "posts/mse/mse.html#answerlist",
    "href": "posts/mse/mse.html#answerlist",
    "title": "mse",
    "section": "",
    "text": "\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(y_i -\\hat{f}(x_i))^2\\)\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(y_i -\\hat{f}(x_i))\\)\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(|y_i -\\hat{f}(x_i)|)\\)\n\\(MSE= \\sum^n_{i=1}(y_i -\\hat{f}(x_i))^2\\)\n\\(MSE= \\frac{1}{n}\\sum^n_{i=1}(y_i + \\hat{f}(x_i))^2\\)"
  },
  {
    "objectID": "posts/mse/mse.html#answerlist-1",
    "href": "posts/mse/mse.html#answerlist-1",
    "title": "mse",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/lm-standardfehler/lm-standardfehler.html",
    "href": "posts/lm-standardfehler/lm-standardfehler.html",
    "title": "lm-standardfehler",
    "section": "",
    "text": "Man kann angeben, wie genau eine Sch√§tzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser √úbung untersuchen wir, wie sich der SE als Funktion der Stichprobengr√∂√üe, \\(n\\), verh√§lt.\nErstellen Sie dazu folgenden Datensatz:\n\nlibrary(tidyverse)\n\nn &lt;- 2^4\n\nd &lt;-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nHier ist das Ergebnis. Uns interessiert v.a. Std. Error f√ºr den Pr√§diktor x:\n\nlm(y ~ x, data = d) %&gt;% \nsummary()\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8758 -0.3004 -0.1946  0.2529  1.3000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.1422     0.1561  -0.911    0.378    \nx             0.9546     0.1317   7.251 4.22e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5976 on 14 degrees of freedom\nMultiple R-squared:  0.7897,    Adjusted R-squared:  0.7747 \nF-statistic: 52.58 on 1 and 14 DF,  p-value: 4.216e-06\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\nVerdoppeln Sie die Stichprobengr√∂√üe 5 Mal und betrachten Sie, wie sich die Sch√§tzgenauigkeit, gemessen √ºber den SE, ver√§ndert. Berechnen Sie dazu f√ºr jedes n eine Regression mit x als Pr√§diktor und y als AV!\nBei welcher Stichprobengr√∂√üe ist SE am kleinsten?\n\n\n\n\\(2^5\\)\n\\(2^6\\)\n\\(2^7\\)\n\\(2^8\\)\n\\(2^9\\)"
  },
  {
    "objectID": "posts/lm-standardfehler/lm-standardfehler.html#answerlist",
    "href": "posts/lm-standardfehler/lm-standardfehler.html#answerlist",
    "title": "lm-standardfehler",
    "section": "",
    "text": "\\(2^5\\)\n\\(2^6\\)\n\\(2^7\\)\n\\(2^8\\)\n\\(2^9\\)"
  },
  {
    "objectID": "posts/lm-standardfehler/lm-standardfehler.html#answerlist-1",
    "href": "posts/lm-standardfehler/lm-standardfehler.html#answerlist-1",
    "title": "lm-standardfehler",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr. Die gr√∂√üte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\nCategories:\n\ninference\nlm\nqm2"
  },
  {
    "objectID": "posts/regression1b/regression1b.html",
    "href": "posts/regression1b/regression1b.html",
    "title": "regression1b",
    "section": "",
    "text": "Die folgende Frage bezieht sich auf dieses Ergebnis einer Regressionsanalyse:\n\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.95512 -0.66937  0.04638  0.57000  2.47071 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -0.08826    0.13368  -0.660    0.512\nx           -0.22014    0.13605  -1.618    0.112\n\nResidual standard error: 0.9621 on 51 degrees of freedom\nMultiple R-squared:  0.04883,   Adjusted R-squared:  0.03018 \nF-statistic: 2.618 on 1 and 51 DF,  p-value: 0.1118\n\n\nZusammengefasst sind die Koeffizienten (beta0 und beta1) also:\n\ncoef(m)\n\n(Intercept)           x \n-0.08826225 -0.22013983 \n\n\nWelche der folgenden Aussagen ist korrekt?\n\n\n\nWenn x um 1 Einheit steigt, dann kann eine Ver√§nderung um etwa -0.22 Einheiten in y erwartet werden.\nWenn x=0, dann ist ein Mittelwert von y in H√∂he von etwa -0.31 zu erwarten.\nWenn x=1, dann ist ein Mittelwert von y in H√∂he von ca. -0.09 zu erwarten.\nWenn x=2, dann ist ein Mittelwert von y in H√∂he von ca. -0.31 zu erwarten.\nDas (nicht-adjustierte) \\(R^2\\) liegt im Modell bei -0.22."
  },
  {
    "objectID": "posts/regression1b/regression1b.html#answerlist",
    "href": "posts/regression1b/regression1b.html#answerlist",
    "title": "regression1b",
    "section": "",
    "text": "Wenn x um 1 Einheit steigt, dann kann eine Ver√§nderung um etwa -0.22 Einheiten in y erwartet werden.\nWenn x=0, dann ist ein Mittelwert von y in H√∂he von etwa -0.31 zu erwarten.\nWenn x=1, dann ist ein Mittelwert von y in H√∂he von ca. -0.09 zu erwarten.\nWenn x=2, dann ist ein Mittelwert von y in H√∂he von ca. -0.31 zu erwarten.\nDas (nicht-adjustierte) \\(R^2\\) liegt im Modell bei -0.22."
  },
  {
    "objectID": "posts/regression1b/regression1b.html#answerlist-1",
    "href": "posts/regression1b/regression1b.html#answerlist-1",
    "title": "regression1b",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nregression\nR\nlm\nschoice"
  },
  {
    "objectID": "posts/mariokart-max1/mariokart-max1.html",
    "href": "posts/mariokart-max1/mariokart-max1.html",
    "title": "mariokart-max1",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die maximale Verkaufspreise (total_pr) f√ºr Spiele, die mit 0, 1, 2, ‚Ä¶ Lenkr√§der (wheels) gekauft werden. Bilden Sie davon den Mittelwert und geben Sie diesen an.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_max = max(total_pr)) %&gt;% \n  summarise(pr_max_mean = mean(pr_max))\n\nsolution\n\n\n\n\n\npr_max_mean\n\n\n\n\n127.946\n\n\n\n\n\n\nL√∂sung:\n\n\n\n\npr_max_mean\n\n\n\n\n127.95\n\n\n\n\n.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nnum"
  },
  {
    "objectID": "posts/verteilungen-quiz-01/verteilungen-quiz-01.html",
    "href": "posts/verteilungen-quiz-01/verteilungen-quiz-01.html",
    "title": "verteilungen-quiz-01",
    "section": "",
    "text": "Beziehen Sie sich auf den Standard-Globusversuch mit \\(N=9\\) W√ºrfen und \\(W=6\\) Wassertreffern (binomialverteilt), vgl. hier.\nDie Postverteilung sieht so aus:\n\nIst sich das Modell auf Basis dieser Post-Verteilung sicher sein, dass der Wasseranteil \\(\\pi=.7\\) betr√§gt?\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/verteilungen-quiz-01/verteilungen-quiz-01.html#answerlist",
    "href": "posts/verteilungen-quiz-01/verteilungen-quiz-01.html#answerlist",
    "title": "verteilungen-quiz-01",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/verteilungen-quiz-01/verteilungen-quiz-01.html#answerlist-1",
    "href": "posts/verteilungen-quiz-01/verteilungen-quiz-01.html#answerlist-1",
    "title": "verteilungen-quiz-01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/scikit-llm-zeroshot/scikit-llm-zeroshot.html",
    "href": "posts/scikit-llm-zeroshot/scikit-llm-zeroshot.html",
    "title": "Scikit-Learn-LLM Zero Shot Learners",
    "section": "",
    "text": "Aufgabe\nFragen Sie ChatGPT via Scikit-Learn-LLM zum Sentiment der ersten 7 Texte (=Tweets) aus dem Germeval-2018-Datensatz (Test). Nutzen Sie die gleiche Zahl an Tweets aus dem Train-Datensatz zum Finetuning Ihres Modells. Nutzen Sie den Endpoint ZeroShotGPTClassifier.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen. Werfen Sie hin und wieder einen Blick auf Ihr OpenAI-Guthaben-Konto.\n\n\n\n\n\n\n\nCaution\n\n\n\nAktuell sind scikit-llm und openai in den aktuellsten Versionen inkompatibel.\n\nERROR: pip‚Äôs dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scikit-llm 0.4.2 requires openai&lt;1.0,&gt;=0.27.9, but you have openai 1.3.5 which is incompatible.\n\nDie einfachste L√∂sung ist, beide Pakete in verschiedenen venvs zu lagern. \\(\\square\\)\n\n\n\n\n\nsci-llm\n\n\n         \n\n\nL√∂sung\nWir legen ggf. eine neue venv an:\n\nlibrary(reticulate)\n\n\n#virtualenv_create(\"scikit-llm\")\n\nUnd nutzen diese:\n\nuse_virtualenv(\"scikit-llm\")\n\nCheck:\n\npy_config()\n\npython:         /Users/sebastiansaueruser/.virtualenvs/scikit-llm/bin/python\nlibpython:      /Users/sebastiansaueruser/.pyenv/versions/3.11.1/lib/libpython3.11.dylib\npythonhome:     /Users/sebastiansaueruser/.virtualenvs/scikit-llm:/Users/sebastiansaueruser/.virtualenvs/scikit-llm\nversion:        3.11.1 (main, Oct  4 2023, 18:12:06) [Clang 15.0.0 (clang-1500.0.40.1)]\nnumpy:          /Users/sebastiansaueruser/.virtualenvs/scikit-llm/lib/python3.11/site-packages/numpy\nnumpy_version:  1.26.2\n\nNOTE: Python version was forced by use_python() function\n\n\n\npy_list_packages() |&gt; head()\n\n\n\n\n\npackage\nversion\nrequirement\n\n\n\n\naiohttp\n3.9.0\naiohttp==3.9.0\n\n\naiosignal\n1.3.1\naiosignal==1.3.1\n\n\nannotated-types\n0.6.0\nannotated-types==0.6.0\n\n\nanyio\n3.7.1\nanyio==3.7.1\n\n\nattrs\n23.1.0\nattrs==23.1.0\n\n\ncachetools\n5.3.2\ncachetools==5.3.2\n\n\n\n\n\n\nGgf. m√ºssen Sie zun√§chst die n√∂tigen Module installieren, z.B. so: reticulate::py_install(\"scikit-llm\").\n\n#py_install(\"scikit-llm\")\n\nModule importieren:\n\nfrom skllm import ZeroShotGPTClassifier   \nfrom skllm.config import SKLLMConfig  # Anmeldung\nimport pandas as pd\nimport time \nimport os\n\nTrain-Daten importieren:\n\ncsv_file_path_train = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv'\ngermeval_train = pd.read_csv(csv_file_path_train)\n\nTest-Daten importieren:\n\ncsv_file_path_test = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv'\ngermeval_test = pd.read_csv(csv_file_path_test)\n\nDie ersten paar Texte aus dem Train-Datensatz herausziehen:\n\nn_tweets = 7\nX_train = germeval_train[\"text\"].head(n_tweets).tolist()\nX_train\n\n['@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.', '@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è', '@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!', '@spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.', '@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.', '@milenahanm 33 bis 45 habe ich noch gar nicht gelebt und es geht mir am Arsch vorbei was in dieser Zeit geschehen ist. Ich lebe im heute und jetzt und nicht in der Vergangenheit.']\n\n\nUnd hier sind die Labels dazu:\n\ny_train = germeval_train[\"c1\"].head(n_tweets).tolist()\ny_train\n\n['OTHER', 'OTHER', 'OTHER', 'OTHER', 'OFFENSE', 'OTHER', 'OFFENSE']\n\n\nUnd analog f√ºr den Test-Datensatz:\n\nX_test = germeval_test[\"text\"].head(n_tweets).tolist()\n\nAnmelden bei OpenAI:\n\nOPENAI_SECRET_KEY = os.environ.get(\"OPENAI_API_KEY\")\nOPENAI_ORG_ID = os.environ.get(\"OPENAI_ORG_ID\")\n\nSKLLMConfig.set_openai_key(OPENAI_SECRET_KEY)\nSKLLMConfig.set_openai_org(OPENAI_ORG_ID)\n\nModel definieren:\n\nclf = ZeroShotGPTClassifier(openai_model=\"gpt-3.5-turbo\")\n\nModel fitten:\n\nclf.fit(X = X_train, y = y_train)  \n\nZeroShotGPTClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ZeroShotGPTClassifierZeroShotGPTClassifier()\n\n\nVorhersagen:\n\ny_pred = clf.predict(X = X_test)  \n\n  0%|          | 0/7 [00:00&lt;?, ?it/s]\n 14%|‚ñà‚ñç        | 1/7 [00:38&lt;03:48, 38.03s/it]\n 29%|‚ñà‚ñà‚ñä       | 2/7 [00:48&lt;01:48, 21.62s/it]\n 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [01:16&lt;01:38, 24.65s/it]\n 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [01:18&lt;00:47, 15.81s/it]\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [01:28&lt;00:27, 13.69s/it]\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [01:31&lt;00:09,  9.87s/it]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [01:33&lt;00:00, 13.32s/it]\nVoil√†:\n\nfor tweet, sentiment in zip(X_test, y_pred):\n    print(f\"Review: {tweet}\\nPredicted Sentiment: {sentiment}\\n\\n\")\n\nReview: Meine Mutter hat mir erz√§hlt, dass mein Vater einen Wahlkreiskandidaten nicht gew√§hlt hat, weil der gegen die Homo-Ehe ist ‚ò∫\nPredicted Sentiment: OFFENSE\n\n\nReview: @Tom174_ @davidbest95 Meine Reaktion; |LBR| Nicht jeder Moslem ist ein Terrorist. Aber jeder Moslem glaubt an √úberlieferungen, die Gewalt und Terror beg√ºnstigen.\nPredicted Sentiment: OFFENSE\n\n\nReview: #Merkel rollt dem Emir von #Katar, der islamistischen Terror unterst√ºtzt, den roten Teppich aus.Wir brauchen einen sofortigen #Waffenstopp!\nPredicted Sentiment: OFFENSE\n\n\nReview: ‚ÄûMerle ist kein junges unschuldiges M√§dchen‚Äú Kch....... üò± #tatort\nPredicted Sentiment: OFFENSE\n\n\nReview: @umweltundaktiv Asylantenflut bringt eben nur negatives f√ºr Deutschland. Drum Asylanenstop und R√ºckf√ºhrung der Mehrzahl.\nPredicted Sentiment: OFFENSE\n\n\nReview: @_StultaMundi Die Bibel enth√§lt ebenfalls Gesetze des Zivil- und Strafrechts.\nPredicted Sentiment: OTHER\n\n\nReview: @Thueringen_ @Miquwarchar @Pontifex_de Man munkelt, Franziskus ist gro√üer \"Kiss\"- und \"Black Sabbath\"-Fan! #RockOn\nPredicted Sentiment: OTHER"
  },
  {
    "objectID": "posts/lose-nieten-binomial-grid/lose-nieten-binomial-grid.html",
    "href": "posts/lose-nieten-binomial-grid/lose-nieten-binomial-grid.html",
    "title": "lose-nieten-binomial-grid",
    "section": "",
    "text": "Exercise\nIn einer Lostrommel befinden sich ‚Äúsehr viele‚Äù Lose, davon ein Anteil \\(p\\) Treffer (und \\(1-p\\) Nieten), mit zun√§chst \\(p=0.01\\).\nSie kaufen \\(n=10\\) Lose.\n\nWie gro√ü ist die Wahrscheinlichkeit f√ºr genau \\(k=0,1,...,10\\) Treffer?\nSagen wir, Sie haben 3 Treffer in den 10 Losen. Yeah! Jetzt sei \\(p\\) unbekannt und Sie sind indifferent zu den einzelnen Werten von \\(p\\). Visualisieren Sie die Posteriori-Wahrscheinlichkeitsverteilung mit ca. 100 Gridwerten. Was beobachten Sie?\nVariieren Sie \\(n\\), aber halten Sie die Trefferquote bei 1/3. Was beobachten Sie?\n\nNutzen Sie die Gittermethode. Treffen Sie Annahmen, wo n√∂tig.\n         \n\n\nSolution\n\nWie gro√ü ist die Wahrscheinlichkeit f√ºr genau \\(k=0,1,...,10\\) Treffer?\n\n\nd_a &lt;- \n  tibble(\n    k = 0:10,\n    wskt = dbinom(k, size = 10, prob = .01))\n\nd_a %&gt;% \n  ggplot() +\n  aes(x = k, y = wskt) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nk\nwskt\n\n\n\n\n0\n9.04¬†√ó¬†10‚àí1\n\n\n1\n9.14¬†√ó¬†10‚àí2\n\n\n2\n4.15¬†√ó¬†10‚àí3\n\n\n3\n1.12¬†√ó¬†10‚àí4\n\n\n4\n1.98¬†√ó¬†10‚àí6\n\n\n5\n2.40¬†√ó¬†10‚àí8\n\n\n6\n2.02¬†√ó¬†10‚àí10\n\n\n7\n1.16¬†√ó¬†10‚àí12\n\n\n8\n4.41¬†√ó¬†10‚àí15\n\n\n9\n9.90¬†√ó¬†10‚àí18\n\n\n10\n1.00¬†√ó¬†10‚àí20\n\n\n\n\n\n\n\n\nSagen wir, Sie haben 3 Treffer in den 10 Losen. Yeah! Jetzt sei \\(p\\) unbekannt und Sie sind indifferent zu den einzelnen Werten von \\(p\\). Visualisieren Sie die Posteriori-Wahrscheinlichkeitsverteilung mit ca. 100 Gridwerten. Was beobachten Sie?\n\n\nd2 &lt;-\n  tibble(\n    p_grid = seq(0, 1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 3, size = 10, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd2 %&gt;% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\nDer Modus liegt bei ca 1/3. Der Bereich plausibler Werte f√ºr \\(p\\) liegt ca. zwischen 0.1 und und 0.7, grob visuell gesch√§tzt. Mehr dazu sp√§ter.\n\nVariieren Sie \\(n\\), aber halten Sie die Trefferquote bei 1/3. Was beobachten Sie?\n\n\n# n = 2\nd3 &lt;-\n  tibble(\n    p_grid = seq(0,1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 2, size = 6, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd3 %&gt;% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"n=20\")\n\n\n\n\n\n\n\n# n = 20\nd4 &lt;-\n  tibble(\n    p_grid = seq(0,1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 20, size = 60, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd4 %&gt;% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"n = 20\")\n\n\n\n\n\n\n\n# n = 200\nd5 &lt;-\n  tibble(\n    p_grid = seq(0,1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 200, size = 600, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd5 %&gt;% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"n = 20\")\n\n\n\n\n\n\n\n\nDer Modus und andere Ma√üe der zentralen Tendenz bleiben gleich; die Streuung wird geringer.\n\nCategories:\n\nprobability\nbinomial"
  },
  {
    "objectID": "posts/prob-ereignisraum/index.html",
    "href": "posts/prob-ereignisraum/index.html",
    "title": "prob-ereignisraum",
    "section": "",
    "text": "1 Aufgabe\nBeim einmaligen Wurf eines gew√∂hnlichen, sechsseitigen Spielw√ºrfels ist der Ereignisraum Œ©={1,2,3,4,5,6}. Was ist die M√§chtigkeit des Ereignisraumes, ‚à£Œ©‚à£?\n\n1\n2\n6\n36\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\n6"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html",
    "href": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html",
    "title": "Verteilungen-Quiz-06",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\ge 100) \\ne 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist",
    "href": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist",
    "title": "Verteilungen-Quiz-06",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist-1",
    "title": "Verteilungen-Quiz-06",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/wskt-quiz13/wskt-quiz13.html",
    "href": "posts/wskt-quiz13/wskt-quiz13.html",
    "title": "wskt-quiz13",
    "section": "",
    "text": "Behauptung: Die Post-Verteilung gibt die Wahrscheinlichkeit der Hypothese an, gegeben der Daten (und des Modells).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz13/wskt-quiz13.html#answerlist",
    "href": "posts/wskt-quiz13/wskt-quiz13.html#answerlist",
    "title": "wskt-quiz13",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz13/wskt-quiz13.html#answerlist-1",
    "href": "posts/wskt-quiz13/wskt-quiz13.html#answerlist-1",
    "title": "wskt-quiz13",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html",
    "href": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html",
    "title": "Typ-Fehler-R-02",
    "section": "",
    "text": "R gibt folgende Fehlermeldung aus:\n(Fehler in library(XXX): es gibt kein Paket namens 'XXX'),\nwobei f√ºr XXX ein Paketname wie tidyverse angef√ºhrt wird.\nW√§hlen Sie die plausibelste Ursache aus!\n\n\n\nDas Paket XXX ist nicht installiert auf dem aktuellen Rechner.\nDas Paket XXX ist nicht verf√ºgbar genau f√ºr dieses Betriebssystem.\nEs existiert kein Paket mit Namen XXX.\nDas Paket XXX ist nicht geladen.\nDas Paket XXX ist defekt."
  },
  {
    "objectID": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist",
    "href": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist",
    "title": "Typ-Fehler-R-02",
    "section": "",
    "text": "Das Paket XXX ist nicht installiert auf dem aktuellen Rechner.\nDas Paket XXX ist nicht verf√ºgbar genau f√ºr dieses Betriebssystem.\nEs existiert kein Paket mit Namen XXX.\nDas Paket XXX ist nicht geladen.\nDas Paket XXX ist defekt."
  },
  {
    "objectID": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist-1",
    "href": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist-1",
    "title": "Typ-Fehler-R-02",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig.\nFalsch.\nFalsch.\nFalsch.\nFalsch.\n\n\nCategories:\n\nR\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/wuerfel04/wuerfel04.html",
    "href": "posts/wuerfel04/wuerfel04.html",
    "title": "wuerfel04",
    "section": "",
    "text": "Exercise\nWas ist die Wahrscheinlichkeit, mit zwei fairen W√ºrfeln genau 10 Augen zu werfen?\nHinweise:\n\nNutzen Sie Simulationsmnethoden der Wahrscheinlichkeitsrechnung, keine exakten Rechnung auf Basis der Wahrscheinlichkeitsrechnung.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSetzen Sie bei Simulationsaufgaben immer die Zufallszahlen mit set.seed(). Sofern kein anderer Wert f√ºr set.seed() genannt, verwenden Sie die Zahl 42.\nDa es bei dieser Aufgabe n√∂tig ist, zwei Mal Zufallszahlen zu berechnen (f√ºr zwei W√ºrfel n√§mlich), verwenden Sie beim ersten W√ºrfel die Zahl 42 und beim zweiten W√ºrfel die Zahl 43.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nEinen W√ºrfelwurf in R kann man so simulieren:\n\nwuerfel &lt;- sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))\nwuerfel\n\n[1] 1\n\n\nBei sample gibt x den Ereignisraum, \\(\\Omega\\), an, size die Stichprobengr√∂√üe und prob gibt f√ºr jedes Element von x die Wahrscheinlichkeit an.\nDas machen wir jetzt 1000 Mal. Viel Spa√ü beim Tippen‚Ä¶\n‚Ä¶ ‚Ä¶ ‚Ä¶\nOkay, das sollten wir einfacher hinkriegen. Man kann R sagen, dass sie eine Funktion (wie sample) oft ausf√ºhren soll. Damit k√∂nnen wir viele W√ºrfelw√ºrfe simulieren. Diese ‚ÄúWiederholungsfunktion‚Äù hei√üt replicate(n, expr); dabei gibt n an, wie oft die Funktion wiederholt werden soll, und expr ist der Ausdruck (die Funktion), die wiederholt werden soll, das ist bei uns die Funktion sample, wie oben dargestellt.\n\nzehn_wuerfel &lt;- replicate(n = 10, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\nzehn_wuerfel\n\n [1] 5 6 3 3 5 6 4 4 6 2\n\n\nK√∂nnen wir nat√ºrlich auch zich Mal wiederholen, nicht nur 10 Mal, sagen wir \\(10^4\\) Mal:\n\nset.seed(42)\nwuerfel1_oft &lt;- replicate(n = 10^4, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\n\nmean(wuerfel1_oft)\n\n[1] 3.4968\n\n\nAh, interessant: Der Mittelwert ist etwa 3.5‚Ä¶\nJetzt werfen wir noch einen zweiten W√ºrfel genau so oft:\n\nset.seed(43)\nwuerfel2_oft &lt;- replicate(n = 10^4, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\n\nmean(wuerfel2_oft)\n\n[1] 3.4983\n\n\nDas packen wir jetzt in eine Tabelle und erg√§nzen die Augensumme f√ºr jede Wiederholung des Doppelwurfes:\n\nd &lt;-\n  tibble(w1 = wuerfel1_oft,\n         w2 = wuerfel2_oft,\n         w_sum = w1+w2)\n\nhead(d)\n\n\n\n\n\nw1\nw2\nw_sum\n\n\n\n\n1\n4\n5\n\n\n1\n1\n2\n\n\n3\n2\n5\n\n\n6\n6\n12\n\n\n5\n3\n8\n\n\n5\n5\n10\n\n\n\n\n\n\nJetzt ist es einfach:\nWir z√§hlen einfach, wie oft das Ergebnis 10 vorkommt in der Tabelle.\n\nd %&gt;% \n  count(w_sum == 10)\n\n\n\n\n\nw_sum == 10\nn\n\n\n\n\nFALSE\n9148\n\n\nTRUE\n852\n\n\n\n\n\n\nErg√§nzen wir die Anteile dieser Anzahl:\n\nd %&gt;% \n  count(w_sum == 10) %&gt;% \n  mutate(Anteil = n/sum(n))\n\n\n\n\n\nw_sum == 10\nn\nAnteil\n\n\n\n\nFALSE\n9148\n0.9148\n\n\nTRUE\n852\n0.0852\n\n\n\n\n\n\nDie L√∂sung lautet also: 0.08 (gerundet auf zwei Dezimalen)\nAuf einfache Weise k√∂nnen wir entsprechend die Wahrscheinlichkeit f√ºr mindestens \\(k\\) Augen (bei zwei W√ºrfelw√ºrfen) ermitteln, mit \\(k\\) ist die gesuchte Augensumme, hier 10.\n\nd %&gt;% \n  count(w_sum &gt;= 10) %&gt;% \n  mutate(Anteil = n/sum(n))\n\n\n\n\n\nw_sum &gt;= 10\nn\nAnteil\n\n\n\n\nFALSE\n8316\n0.8316\n\n\nTRUE\n1684\n0.1684\n\n\n\n\n\n\nOder h√∂chstens 10, ganz analog:\n\nd %&gt;% \n  count(w_sum &lt;= 10) %&gt;% \n  mutate(Anteil = n/sum(n))\n\n\n\n\n\nw_sum &lt;= 10\nn\nAnteil\n\n\n\n\nFALSE\n832\n0.0832\n\n\nTRUE\n9168\n0.9168\n\n\n\n\n\n\n\nCategories:\n\nprobability\ndice\nsimulation"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html",
    "title": "wskt-mtcars-1l",
    "section": "",
    "text": "Pr√ºfen Sie folgende Hypothese:\n\nEin Auto mit manueller Schaltung hat pro Gallone Sprit mind. 5 Meilen mehr Reichweite als ein Auto mit Automatikschaltung (ceteris paribus).\n\nQuantifizieren Sie die Wahrscheinlichkeit dieser Hypothese!\nHinweise:\n\nNutzen Sie die Bayes-Statistik mit Stan.\nBeachten Sie die Standardhinweise des Datenwerks.\nVerwenden Sie den Datensatz mtcars."
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#setup",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#setup",
    "title": "wskt-mtcars-1l",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell",
    "title": "wskt-mtcars-1l",
    "section": "Modell",
    "text": "Modell\nDie Hypothese kann man wie folgt formalisieren:\n\nDie Wahrscheinlichkeit, dass Manuellschalter eine h√∂here Reichweite haben, ist gr√∂√üer als die Wahrscheinlichkeit, dass Automatikschalter eine h√∂here Reichweite haben:\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; Pr(mpg_M &lt;= mpg_A)\\]\n\nOder anders gesagt: Die Wahrscheinlichkeit, dass Automatikschalter eine h√∂here Reichweite haben (pro Gallone Sprit und im Vergleich zu Automatikschalter) ist gr√∂√üer als 50%.\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; 1/2\\] 3. M√∂chte man noch hinzuf√ºgen, dass sich diese Behauptung auf ein bestimmtes, n√§mlich unser Regressionsmodell bezieht, kann man schreiben:\n\\[Pr(mpg_M &gt; mpg_A \\quad | \\beta_0, \\beta_1, \\sigma)\\]"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell-berechnen",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell-berechnen",
    "title": "wskt-mtcars-1l",
    "section": "Modell berechnen",
    "text": "Modell berechnen\n\nm &lt;- stan_glm(mpg ~ am,\n              data = mtcars,\n              refresh = 0,\n              seed = 42)\n\n\nparameters(m)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n17.135995\n0.95\n14.85310\n19.50922\n1.0000\n0.9992095\n3739.117\nnormal\n20.09062\n15.06737\n\n\nam\n7.210857\n0.95\n3.72452\n10.69610\n0.9995\n0.9994221\n3754.841\nnormal\n0.00000\n30.19568"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#post-verteilung-auslesen",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#post-verteilung-auslesen",
    "title": "wskt-mtcars-1l",
    "section": "Post-Verteilung auslesen",
    "text": "Post-Verteilung auslesen\n\nm_post &lt;-\n  m |&gt;\n  as_tibble()\n\nprop &lt;- \nm_post |&gt; \n  count(am &gt;= 5) |&gt; \n  mutate(prop = n/sum(n))\n\nprop\n\n\n\n\n\nam &gt;= 5\nn\nprop\n\n\n\n\nFALSE\n431\n0.10775\n\n\nTRUE\n3569\n0.89225"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#antwort",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#antwort",
    "title": "wskt-mtcars-1l",
    "section": "Antwort",
    "text": "Antwort\nLaut unserem Modell betr√§gt die Wahrscheinlichkeit f√ºr obige Hypothese 0.89."
  },
  {
    "objectID": "posts/wuerfel03/wuerfel03.html",
    "href": "posts/wuerfel03/wuerfel03.html",
    "title": "wuerfel03",
    "section": "",
    "text": "Exercise\nWas ist die Wahrscheinlichkeit, mit zwei fairen W√ºrfeln h√∂chstens 10 Augen zu werfen?\nHinweise:\n\nNutzen Sie exakte Methoden der Wahrscheinlichkeitsrechnung, keine Simulation.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\n\n         \n\n\nSolution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden W√ºrfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), ‚Ä¶, (1,6), ‚Ä¶, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd &lt;- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\n\nd\n\n\n\n\n\nwuerfel1\nwuerfel2\n\n\n\n\n1\n1\n\n\n1\n2\n\n\n1\n3\n\n\n1\n4\n\n\n1\n5\n\n\n1\n6\n\n\n2\n1\n\n\n2\n2\n\n\n2\n3\n\n\n2\n4\n\n\n2\n5\n\n\n2\n6\n\n\n3\n1\n\n\n3\n2\n\n\n3\n3\n\n\n3\n4\n\n\n3\n5\n\n\n3\n6\n\n\n4\n1\n\n\n4\n2\n\n\n4\n3\n\n\n4\n4\n\n\n4\n5\n\n\n4\n6\n\n\n5\n1\n\n\n5\n2\n\n\n5\n3\n\n\n5\n4\n\n\n5\n5\n\n\n5\n6\n\n\n6\n1\n\n\n6\n2\n\n\n6\n3\n\n\n6\n4\n\n\n6\n5\n\n\n6\n6\n\n\n\n\n\n\nJetzt erg√§nzen wir eine Spalte f√ºr die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 &lt;-\n  d %&gt;% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\n\n\n\n\n1\n1\n0.0277778\n\n\n1\n2\n0.0277778\n\n\n1\n3\n0.0277778\n\n\n1\n4\n0.0277778\n\n\n1\n5\n0.0277778\n\n\n1\n6\n0.0277778\n\n\n\n\n\n\nAu√üerdem erg√§nzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\naugensumme\n\n\n\n\n1\n1\n0.0277778\n2\n\n\n1\n2\n0.0277778\n3\n\n\n1\n3\n0.0277778\n4\n\n\n1\n4\n0.0277778\n5\n\n\n1\n5\n0.0277778\n6\n\n\n1\n6\n0.0277778\n7\n\n\n\n\n\n\nF√ºr manche Augensummen gibt es mehrere M√∂glichkeiten:\n\nd3 %&gt;% \n  filter(augensumme == 7)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\naugensumme\n\n\n\n\n1\n6\n0.0277778\n7\n\n\n2\n5\n0.0277778\n7\n\n\n3\n4\n0.0277778\n7\n\n\n4\n3\n0.0277778\n7\n\n\n5\n2\n0.0277778\n7\n\n\n6\n1\n0.0277778\n7\n\n\n\n\n\n\n‚Ä¶ f√ºr andere weniger:\n\nd3 %&gt;% \n  filter(augensumme == 12)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\naugensumme\n\n\n\n\n6\n6\n0.0277778\n12\n\n\n\n\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 &lt;- \n  d3 %&gt;% \n  group_by(augensumme) %&gt;% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n\n\n\n\naugensumme\ntotale_w_pro_augenzahl\n\n\n\n\n2\n0.0277778\n\n\n3\n0.0555556\n\n\n4\n0.0833333\n\n\n5\n0.1111111\n\n\n6\n0.1388889\n\n\n7\n0.1666667\n\n\n8\n0.1388889\n\n\n9\n0.1111111\n\n\n10\n0.0833333\n\n\n11\n0.0555556\n\n\n12\n0.0277778\n\n\n\n\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %&gt;% \n  summarise(sum(totale_w_pro_augenzahl))\n\n\n\n\n\nsum(totale_w_pro_augenzahl)\n\n\n\n\n1\n\n\n\n\n\n\nUnd:\n\nd2 %&gt;% \n  summarise(sum(prob))\n\n\n\n\n\nsum(prob)\n\n\n\n\n1\n\n\n\n\n\n\nPasst!\nDie Wahrscheinlichkeit f√ºr die Augensumme von h√∂chstens 10 betr√§gt also:\n\nloesung &lt;-\n  d4 %&gt;% \n  filter(augensumme &lt;= 10) %&gt;% \n  summarise(prob_sum = sum(totale_w_pro_augenzahl)) %&gt;% \n  pull(prob_sum)\n\nloesung\n\n[1] 0.9166667\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/mariokart-korr1/mariokart-korr1.html",
    "href": "posts/mariokart-korr1/mariokart-korr1.html",
    "title": "mariokart-korr1",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie die Korrelation von Verkaufspreis (total_pr) und Startgebot (start_pr)!\nHinweise:\n\nRunden Sie auf 2 Dezimalstellen.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;- \nd  %&gt;% \n  summarise(pr_cor = cor(total_pr, start_pr))\nsolution\n\n\n\n\n\npr_cor\n\n\n\n\n0.073406\n\n\n\n\n\n\nAlternativ kann man (komfortabel) die Korrelation z.B. so berechnen:\n\nd %&gt;% \n  select(start_pr, total_pr) %&gt;% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nstart_pr\ntotal_pr\n0.073406\n0.95\n-0.0918493\n0.2347263\n0.8740063\n141\n0.383601\nPearson correlation\n143\n\n\n\n\n\n\nMan kann das Ergebnis von correlation auch einfach in ein Diagramm √ºberf√ºhren:\n\nmariokart_corr1 &lt;- \nd %&gt;% \n  select(start_pr, total_pr) %&gt;% \n  correlation()\n\nmariokart_corr1 %&gt;% plot()\n\n\n\n\n\n\n\n\nL√∂sung: 0.07.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nassociation\nnum"
  },
  {
    "objectID": "posts/smartphone1/index.html",
    "href": "posts/smartphone1/index.html",
    "title": "smartphone1",
    "section": "",
    "text": "In dieser Fallstudie analysieren Sie die Ergebnisse einer Umfrage zum Thema Smartphone-Nutzung. \nKernst√ºck der Umfrage ist die Smartphone-Sucht-Skala (kwon_smartphone_2013?). Eine Studie fand, dass ca. ein Siebtel der Studierenden s√ºchtig nach ihrem Smartphone sind (haug_smartphone_2015?); demnach k√∂nnte dem Thema eine hohe Bedeutsamkeit zukommen.\n\nImportieren Sie den Datensatz zur Handynutzung von Google-Docs.\nBenennen Sie die Spalten um und zwar nach folgendem Muster: itemXY, wobei XY die Nummer der Spalte ist. Sichern Sie die urspr√ºnglichen Spaltennamen in einem Vektor. Tipp: Der Funktion names(meine_tabelle) k√∂nnen Sie einen Vektor mit neuen Spaltennamen √ºbergeben.\nBerechnen Sie f√ºr die Items der Smartphone-Addiction-Scale den Mittelwert pro Person. Tipp: Erstellen Sie einen Dataframe mit den entsprechenden Items und nutzen Sie dann die Funktion rowMeans(mein_dataframe), um den Mittelwert √ºber mehrere Spalten f√ºr jede Zeile zu berechnen (‚ÄúScore‚Äù).\nVisualisieren Sie die Verteilung des Scores getrennt f√ºr die Geschlechter.\nNach einer Quelle (kwon_smartphone_2013?) liegt der Cutoff-Wert f√ºr Sucht bei 3.1 (M√§nner) bzw. 3.3 (Frauen). Bestimmen Sie den Anteil abh√§ngiger Personen (pro Geschlecht).\nDas Item i13 ist ein Versuch, mit einem einzelnen Item zu messen, ob jemand s√ºchtig nach seinem Smartphone ist (Item-Label: ‚ÄúIch.w√ºrde.sagen..dass.ich.smartphone.s√ºchtig.bin.‚Äù). Visualisieren Sie den Zusammenhang dieses Items mit dem Score.\nVisualsieren Sie den Anteil abh√§ngiger Personen.\nBerechnen Sie, wie viel Geld f√ºr das zuletzt gekaufte Handy im Schnitt ausgegeben wurde. Gruppieren Sie dabei nach dem Betriebsystem.\nWer gibt mehr Geld f√ºr das Handy aus: Frauen oder M√§nner? Beantworten Sie die Frage anhand des Medians.\nVisualisieren Sie den Median des Geldausgebens f√ºr das Handy, getrennt nach Geschlechtern\n\n\n\n\n\n\n\nTip\n\n\n\nNutzen Sie ChatGPT oder einen anderen Bot, um sich Hilfe mit dem R-Code zu holen. \\(\\square\\)\n\n\n\n\n\n\n\n\nTip\n\n\n\nEs wird (fast) nie von Ihnen verlangt, dass Sie eine Aufgabe mit einem bestimmten R-Befehl l√∂sen. Wenn Ihnen ein bestimmter R-Befehl nicht zusagt (oder Sie ihn nicht kennen oder verstehen) ‚Äì dann nehmen Sie einfach einen anderen R-Befehl, der Ihnen mehr zusagt. \\(\\square\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeachten Sie die Hinweise des Datenwerks. \\(\\square\\)"
  },
  {
    "objectID": "posts/smartphone1/index.html#daten-importieren",
    "href": "posts/smartphone1/index.html#daten-importieren",
    "title": "smartphone1",
    "section": "2.1 Daten importieren",
    "text": "2.1 Daten importieren\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/Smartphone-Nutzung%20(Responses)%20-%20Form%20responses%201.csv\"\nsmartphone_raw &lt;- read.csv(data_path)\n\nDie Anzahl der Spalten einer Tabelle kann man sich √ºbrigens z.B. mit ncol ausgeben lassen:\n\nanz_spalten &lt;- ncol(smartphone_raw)\nanz_spalten\n\n[1] 18\n\n\nUnsere Datentabelle hat also 18 Spalten."
  },
  {
    "objectID": "posts/smartphone1/index.html#spalten-umbenennen",
    "href": "posts/smartphone1/index.html#spalten-umbenennen",
    "title": "smartphone1",
    "section": "2.2 Spalten umbenennen",
    "text": "2.2 Spalten umbenennen\nZun√§chst sichern wir die alten Spaltennamen in einen Vektor:\n\nitem_labels_old &lt;- names(smartphone_raw)\nitem_labels_old\n\n [1] \"Timestamp\"                                                                                                        \n [2] \"Wann.haben.Sie.heute.zum.letzten.Mal.Ihr.Handy.benutzt..Bitte.geben.Sie.die.Uhrzeit.an.\"                          \n [3] \"Aufgrund.meiner.Smartphone.Nutzung.erledige.ich.geplante.Aufgaben.nicht.\"                                         \n [4] \"Aufgrund.meiner.Smartphone.Nutzung.f√§llt.es.mir.schwer..mich.in.der.Schule.oder.Arbeit.zu.konzentrieren.\"         \n [5] \"Bei.der.Nutzung.des.Smartphones.bekomme.ich.Schmerzen.in.Handgelenk.oder.Nacken.\"                                 \n [6] \"Ich.w√ºrde.es.nicht.aushalten..kein.Smartphone.zu.haben.\"                                                          \n [7] \"Wenn.ich.mein.Smartphone.nicht.in.der.Hand.habe..f√ºhle.ich.mich.unruhig.und.gereizt.\"                             \n [8] \"Ich.denke.st√§ndig.an.mein.Smartphone..auch.wenn.ich.es.nicht.benutze.\"                                            \n [9] \"Ich.werde.nie.aufh√∂ren..mein.Smartphone.zu.benutzen..selbst.wenn.mein.Alltag.bereits.stark.davon.beeinflusst.ist.\"\n[10] \"Ich.schaue.st√§ndig.auf.mein.Smartphone..um.keine.Neuigkeiten.zu.verpassen.\"                                       \n[11] \"Ich.benutze.mein.Smartphone.l√§nger.als.ich.es.vorhabe.\"                                                           \n[12] \"Die.Menschen.in.meinem.Umfeld.sagen.mir..dass.ich.mein.Smartphone.zu.h√§ufig.nutze.\"                               \n[13] \"Ich.w√ºrde.sagen..dass.ich.smartphone.s√ºchtig.bin.\"                                                                \n[14] \"Hier.ist.Platz.f√ºr.Ihre.Kommentare\"                                                                               \n[15] \"Bitte.geben.Sie.Ihr.Geschlecht.an.\"                                                                               \n[16] \"Bitte.geben.Sie.Ihr.Alter.an.\"                                                                                    \n[17] \"Bitte.geben.Sie.das.Betriebssystem.Ihres..am.meisten.genutzten..Handies.an.\"                                      \n[18] \"Wie.viel.Geld.haben.Sie.f√ºr.Ihr.zuletzt.gekauftes.Handy.gezahlt.\"                                                 \n\n\nVariablen aus psychologischen Frageb√∂gen nennt man √ºbrigens oft items.\nUnd dann nennen wir die Spaltennamen um. Das geht mit der Funktion names(smartphone_raw) &lt;-, der wir einen Vektor mit neuen Spaltennamen √ºbergeben, z.B. so:\n\nitem_labels_new &lt;- c( \"item1\",  \"item2\", \"item3\", \"item4\",\n                      \"item5\", \"item6\",  \"item7\", \"item8\",\n                      \"item9\",  \"item10\", \"item11\", \"item12\",\n                      \"item13\", \"item14\", \"item15\", \"item16\",\n                      \"item17\", \"item18\")\n\nWichtig ist, dass ihr Vektor item_labels_new genau so viele Elemente hat, wie die Datentabelle Spalten hat.\nJetzt k√∂nnen Sie der Funktion names() den neuen Vektor item_labels_new zuweisen und haben damit die Spaltenanmen ge√§ndert:\n\nnames(smartphone_raw) &lt;- item_labels_new\n\nDen Vektor item_labels_new zu erstellen, war Ihnen zu viel Tipperei? Ja, mir auch. Schneller geht‚Äôs mit der Funktion paste0. Das erkl√§rt sich am einfachsten mit einem Beispiel:\n\npaste0(\"item\", 1:3)\n\n[1] \"item1\" \"item2\" \"item3\"\n\n\nSehen Sie, was paste0 macht? Es f√ºgt zwei Vektoreneinen Rei√üverschluss zusammen. Da item nur aus einem Element besteht, wird es item einfach auf die richtige L√§nge erh√∂ht.\nDer Doppelpunkt in 1:3 bedeutet ‚Äúvon 1 bis 3‚Äù.\nAlso:\n\nnames(smartphone_raw) &lt;- paste0(\"item\",1:anz_spalten)\n\nSie m√∂chten lieber zweistellige Nummern f√ºr die Spalten, also 01, 02, ‚Ä¶, 09, 10, ‚Ä¶? Gute Idee. Aber wie macht man das? Eine einfache L√∂sung: Fragen Sie ChatGPT!\n\nüë©‚Äçüéì: I want a string of the type ‚ÄúitemXY‚Äù, where XY is a number between 0 and 18. Make sure to use two digits. Use the R function paste0.\n\n\nü§ñ: üò∏"
  },
  {
    "objectID": "posts/smartphone1/index.html#vertiefung-fingerabdruck-der-datentabelle",
    "href": "posts/smartphone1/index.html#vertiefung-fingerabdruck-der-datentabelle",
    "title": "smartphone1",
    "section": "2.3 Vertiefung: Fingerabdruck der Datentabelle",
    "text": "2.3 Vertiefung: Fingerabdruck der Datentabelle\nMit dem R-Paket visdat bekommt man einen ‚ÄúFingerabdruck‚Äù der Datentabelle.\nAm einfachsten erkl√§rt sich das an einem Beispiel. Schauen Sie sich das folgende Diagramm mal an. Es zeigt Ihnen den Datentyp pro Spalte und au√üerdem fehlende Werte.\n\nlibrary(visdat)\n\nvis_dat(smartphone_raw)\n\n\n\n\n\n\n\n\nDas ist deutlich √ºbersichtlicher als eine Excel-Tabelle, wenn es darum geht, die Datenstruktur grob zu verstehen."
  },
  {
    "objectID": "posts/smartphone1/index.html#mittelwert-der-smartphone-addiction-scale",
    "href": "posts/smartphone1/index.html#mittelwert-der-smartphone-addiction-scale",
    "title": "smartphone1",
    "section": "2.4 Mittelwert der Smartphone-Addiction-Scale",
    "text": "2.4 Mittelwert der Smartphone-Addiction-Scale\n\nsmartphone_addiction_mittelwert &lt;- \nsmartphone_raw |&gt; \n  select(item3:item12) |&gt; \n  rowMeans()\n\nWir erhalten einen Vektor mit den Mittwerten (Score) pro Person f√ºr die Skala Smartphone-Abh√§ngigkeit:\n\nhead(smartphone_addiction_mittelwert)\n\n[1] 3.0 3.8 2.7 3.2 4.2 3.3\n\n\nDiesen Vektor f√ºgen wir dann unseren Daten hinzu. Au√üerdem benennen wir die Spalte item15 in sex um, damit wir uns merken k√∂nnen, in welcher Spalte das Geschlecht codiert ist.\n\nsmartphone &lt;-\n  smartphone_raw |&gt; \n  mutate(smartphone_addiction_mean = smartphone_addiction_mittelwert) |&gt; \n  rename(sex = item15) |&gt;   \n  filter(sex == \"Frau\" | sex == \"Mann\") \n\nMit rename(neuer_name = alter_name) k√∂nnen Sie die Namen von Spalten Ihrer Datentabelle √§ndern.\n\nüßë‚Äçüéì Also das mit rename h√§tte ich jetzt nicht gewusst.\n\n\nüë©‚Äçüè´ Dann frag mal ChatGPT.\n\n\nü§ñ Ja, bitte!!\n\nAlternativ k√∂nnen Sie die folgende, etwas fortgeschrittenere Syntax nutzen:\n\nsmartphone2 &lt;- \nsmartphone_raw |&gt; \n  rowwise() |&gt; \n  mutate(smartphone_addiction_mean = mean(c_across(item3:item12)))"
  },
  {
    "objectID": "posts/smartphone1/index.html#score-visualisieren",
    "href": "posts/smartphone1/index.html#score-visualisieren",
    "title": "smartphone1",
    "section": "2.5 Score visualisieren",
    "text": "2.5 Score visualisieren\nLeider kann DataExplorer nicht mehrere Gruppen in einem Dichtediagramm anzeigen. Wir m√ºssten also mit DataExplorer zwei Diagramme erstellen, eines f√ºr Frauen und eines f√ºr M√§nner. Eleganter geht es mit dem Paket ggpubr\n\nsmartphone |&gt; \n  ggdensity(x = \"smartphone_addiction_mean\", \n            color = \"sex\")"
  },
  {
    "objectID": "posts/smartphone1/index.html#anteil-smartphone-abh√§ngigkeit",
    "href": "posts/smartphone1/index.html#anteil-smartphone-abh√§ngigkeit",
    "title": "smartphone1",
    "section": "2.6 Anteil Smartphone-Abh√§ngigkeit",
    "text": "2.6 Anteil Smartphone-Abh√§ngigkeit\nMit case_when erstellen wir folgende Regel:\n\n‚Äúaddicted‚Äù: wenn der Score &gt; 3.1 und das Geschlecht ‚ÄúMann‚Äù ist bzw.\n‚Äúaddicted‚Äù: wenn der Score &gt; 3.3 und das Geschlecht ‚ÄúFrau‚Äù ist bzw.\n‚Äúnicht addicted‚Äù: ansonsten\n\n\nsmartphone &lt;-\n  smartphone |&gt; \n  mutate(is_addicted =\n           case_when(smartphone_addiction_mean &gt; 3.1 & sex == \"Mann\" ~ \"addicted\",\n                     smartphone_addiction_mean &gt; 3.3 & sex == \"Frau\" ~ \"addicted\",\n                     TRUE ~ \"not-addicted\"))\n\nJetzt haben wir die Spalte is_addicted, die f√ºr jede Person (Zeile) angibt, ob die Person addicted ist. Nun z√§hlen wir die Anzahl (n) aus, und zwar pro Geschlechtsgruppe. Weil es praktisch ist, rechen wir die Anzahl noch in einen Anteil (proportion) um.\n\nsmartphone_count &lt;- \nsmartphone |&gt; \n  group_by(sex) |&gt; \n  count(is_addicted) |&gt; \n  mutate(is_addicted_proportion = n / sum(n))\n\nsmartphone_count\n\n# A tibble: 4 √ó 4\n# Groups:   sex [2]\n  sex   is_addicted      n is_addicted_proportion\n  &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;                  &lt;dbl&gt;\n1 Frau  addicted        18                  0.462\n2 Frau  not-addicted    21                  0.538\n3 Mann  addicted         2                  0.333\n4 Mann  not-addicted     4                  0.667"
  },
  {
    "objectID": "posts/smartphone1/index.html#smartphone-sucht-mit-einzelnen-item-gemessen",
    "href": "posts/smartphone1/index.html#smartphone-sucht-mit-einzelnen-item-gemessen",
    "title": "smartphone1",
    "section": "2.7 Smartphone-Sucht, mit einzelnen Item gemessen",
    "text": "2.7 Smartphone-Sucht, mit einzelnen Item gemessen\n\nsmartphone |&gt; \n  select(smartphone_addiction_mean, item13) |&gt; \n  drop_na() |&gt; \n  plot_scatterplot(by = \"smartphone_addiction_mean\")\n\n\n\n\n\n\n\n\nEs scheint einen Zusammenhang zwischen item13 und smartphone_addiction_mean zu geben."
  },
  {
    "objectID": "posts/smartphone1/index.html#anteil-der-abh√§ngigen-visualisieren",
    "href": "posts/smartphone1/index.html#anteil-der-abh√§ngigen-visualisieren",
    "title": "smartphone1",
    "section": "2.8 Anteil der Abh√§ngigen visualisieren",
    "text": "2.8 Anteil der Abh√§ngigen visualisieren\nDer Anteil der abh√§ngigen Personen ist in beiden Geschlechtern gleich hoch:\n\nsmartphone_count |&gt; \n  plot_bar(by = \"sex\")\n\n\n\n\n\n\n\n\nHier noch eine alternative Visualisierung mit dem Paket ggpubr:\n\nsmartphone_count |&gt; \n  ggbarplot(x = \"sex\", y = \"n\", fill = \"is_addicted\")"
  },
  {
    "objectID": "posts/smartphone1/index.html#kosten-nach-betriebssystem",
    "href": "posts/smartphone1/index.html#kosten-nach-betriebssystem",
    "title": "smartphone1",
    "section": "2.9 Kosten nach Betriebssystem",
    "text": "2.9 Kosten nach Betriebssystem\n\nsmartphone |&gt; \n  group_by(item17) |&gt; \n  summarise(price_mean = mean(item18, na.rm = TRUE))\n\n# A tibble: 2 √ó 2\n  item17  price_mean\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Android       412 \n2 iOS           742."
  },
  {
    "objectID": "posts/smartphone1/index.html#kosten-nach-geschlecht",
    "href": "posts/smartphone1/index.html#kosten-nach-geschlecht",
    "title": "smartphone1",
    "section": "2.10 Kosten nach Geschlecht",
    "text": "2.10 Kosten nach Geschlecht\n\nsmartphone |&gt; \n  group_by(sex) |&gt; \n  summarise(price_median = median(item18, na.rm = TRUE))\n\n# A tibble: 2 √ó 2\n  sex   price_median\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Frau           700\n2 Mann          1000\n\n\nM√§nner geben im Median 300 Euro mehr aus.\n\n\n\n\n\n\nTip\n\n\n\nWenn Sie nicht mehr wissen, was z.B. na.rm = TRUE bedeutet, dann einfach googeln oder einen ChatBot fragen. In der Regel ist die Frage dann in zwei Minuten beantwortet. \\(\\square\\)"
  },
  {
    "objectID": "posts/smartphone1/index.html#kosten-nach-geschlecht-visualisieren",
    "href": "posts/smartphone1/index.html#kosten-nach-geschlecht-visualisieren",
    "title": "smartphone1",
    "section": "2.11 Kosten nach Geschlecht visualisieren",
    "text": "2.11 Kosten nach Geschlecht visualisieren\n\nsmartphone |&gt; \n  select(sex, item18) |&gt; \n  plot_boxplot(by = \"sex\")\n\n\n\n\n\n\n\n\nWie man sieht ist der Median bei den M√§nnern h√∂her als bei den Frauen. Allerdings f√§llt der Median der M√§nner aus das dritte Quartil, was vermuten l√§sst, dass da irgendwas nicht stimmt. Schauen wir uns die Daten n√§her an:\n\nsmartphone |&gt; \n  filter(sex == \"Mann\")\n\n                item1    item2 item3 item4 item5 item6 item7 item8 item9 item10\n1 02/05/2024 16:29:51              4     4     3    NA     1    NA     1      4\n2 02/05/2024 16:30:37 16:20:00     2     5     2     4     3     3     3      3\n3 02/05/2024 16:30:42 16:20:00     1     2     2     4     1     1     6      5\n4 02/05/2024 16:30:48 16:30:00     5     5     2     6     2     2     5      4\n5 02/05/2024 16:30:58 16:00:00     4     2     3     5     2     2     3      4\n6 02/05/2024 16:31:28 16:28:00     6     6     1     6     3     2     6      3\n  item11 item12 item13 item14  sex item16  item17 item18\n1      4     NA      2        Mann     21 Android    400\n2      4      2      4        Mann     19     iOS   1000\n3      3      1      5        Mann     22     iOS   1200\n4      5      4      4        Mann     19 Android    300\n5      5      1      2        Mann     29     iOS   1000\n6      6      2      5        Mann     19     iOS   1000\n  smartphone_addiction_mean  is_addicted\n1                        NA not-addicted\n2                       3.1 not-addicted\n3                       2.6 not-addicted\n4                       4.0     addicted\n5                       3.1 not-addicted\n6                       4.1     addicted\n\n\nAh, es sind einfach sehr wenig M√§nner in diesem Datensatz enthalten."
  },
  {
    "objectID": "posts/germeval01-textfeatures/germeval01-textfeatures.html",
    "href": "posts/germeval01-textfeatures/germeval01-textfeatures.html",
    "title": "germeval01-textfeatures",
    "section": "",
    "text": "Aufgabe\nExtrahieren Sie typisches Text-Features aus einem Text.\nNutzen Sie das Paket textfeatures.\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\nlibrary(easystats)\ndata(\"germeval_train\", package = \"pradadata\")\n\nNutzen Sie diesen Text-Datensatz, bevor Sie den gr√∂√üeren germeval-Datensatz verwenden:\n\n\nDaten\nTeststring:\n\ntext &lt;- c(\"Abbau, Abbruch ist jetzt\", \n          \"Test   üßë‚Äçüéì üòÑ heute!!\", \n          \"Abbruch #morgen #perfekt\", \n          \"Abmachung... LORE IPSUM\", \n          \"boese ja\", \"b√∂se nein\", \n          \"hallo ?! www.google.de\", \n          \"gut schlecht I am you are he she it is\")\n\nn_emo &lt;- c(2, 0, 2, 1, 1, 1, 0, 2)\n\ntest_text &lt;-\n  data.frame(id = 1:length(text),\n         text = text,\n         n_emo = n_emo)\n\ntest_text\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nDas Paket textfeatures ist aktuelle nicht auf CRAN, aber √ºber Github zu bekommen (oder im CRAN-Archiv).\n\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(textfeatures)\n\n\n\nTest 1\nHier ein Test vom Autor des Pakets:\n\nx &lt;- c(\n  \"this is A!\\t sEntence https://github.com about #rstats @github\",\n  \"and another sentence here\", \"THe following list:\\n- one\\n- two\\n- three\\nOkay!?!\"\n)\n\n## get text features\ntextfeatures::textfeatures(x, verbose = FALSE)\n\n\n\nTest 2\n\ntextfeatures::textfeatures(test_text$text,\n                           sentiment = FALSE,\n                           word_dims = FALSE)\n\n\nCategories:\n\n2023\ntextmining\ndatawrangling\ngermeval\nstring"
  },
  {
    "objectID": "posts/iq01/iq01.html",
    "href": "posts/iq01/iq01.html",
    "title": "iq01",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt. Ab einem Testwert von 130 Punkten nennt man die getestete Person hochbegabt.\nWie gro√ü ist die Wahrscheinlichkeit, dass die n√§chste Person, die Sie treffen, hochbetagthochbegabt ist? Geben Sie die Wahrscheinlichkeit (als Anteil) an.\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^3\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten).\nWir wollen hier keine Post-Verteilung berechnen, sondern lediglich Werte simulieren.\nGeben Sie keine Prozentzahlen, sondern stets Anteile an.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)  # Reproduzierbarkeit\nd &lt;- tibble(\n  id = 1:10^3,  # Der Doppelpunkt hei√üt \"bis\", also \"von 1 bis 10 hoch 3\". Diese Spalte ist nicht so wichtig.\n  iq = rnorm(n = 10^3, mean = 100, sd = 15))\n\nhead(d)  # Die ersten paar Zeilen\n\n\n\n\n\nid\niq\n\n\n\n\n1\n120.56438\n\n\n2\n91.52953\n\n\n3\n105.44693\n\n\n4\n109.49294\n\n\n5\n106.06402\n\n\n6\n98.40813\n\n\n\n\n\n\nWir filtern wie in der Angabe gew√ºnscht:\n\nd %&gt;% \n  count(iq &gt;= 130)\n\n\n\n\n\niq &gt;= 130\nn\n\n\n\n\nFALSE\n979\n\n\nTRUE\n21\n\n\n\n\n\n\nCa. 20 von 1000 Personen erf√ºllen diese Bedingung (IQ &gt;= 130).\nGenau genommen:\n\n21/1000\n\n[1] 0.021\n\n\nL√∂sung: Die gesuchte Wahrscheinlichkeit betr√§gt ca. 2% bzw. 0.02.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nexam-22\nnum"
  },
  {
    "objectID": "posts/tidymodels-error1/tidymodels-error1.html",
    "href": "posts/tidymodels-error1/tidymodels-error1.html",
    "title": "tidymodels-error1introd",
    "section": "",
    "text": "Aufgabe\n\nlibrary(tidymodels)\nlibrary(tictoc)\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read.csv(d_path)\n\nDie folgende Pipeline hat einen Fehler. Welcher ist das?\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"regression\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d_train) |&gt; \n  #step_unknown(all_nominal_predictors(), new_level = \"NA\") |&gt; \n  #step_novel(all_nominal_predictors()) |&gt; \n  step_naomit(all_predictors()) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_nzv(all_predictors()) |&gt; \n  step_normalize(all_predictors()) \n\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# fitting:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit(data = d_train)\ntoc()\n\npreds &lt;- predict(wf1_fit, new_data = d_test) \n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n\nd_train_baked |&gt; \n  map_int(~ sum(is.na(.)))\n\n         \n\n\nL√∂sung\nDer Fehler liegt darin, dass das Rezept keine √Ñnderungen an der AV ausf√ºhrt. In der AV gibt es aber fehlende Werte (NA) im Test-Set.\n\ncolSums(is.na(d_test))\n\nEinen fehlenden Wert, um genau zu sein. Dieser eine fehlende Wert versalzt uns die Suppe:\n\nd_test_nona &lt;-\n  d_test |&gt; \n  na.omit()\n\nUnd schon geht‚Äôs.\n\npreds &lt;- predict(wf1_fit, new_data = d_test_nona) \npreds |&gt; \n  head()\n\nDieser SO-Post handelt von einem vergleichbarem Problem.\n\nCategories:\n\ntidymodels\nstatlearning\nerror\nNA\nstring"
  },
  {
    "objectID": "posts/iq06/iq06.html",
    "href": "posts/iq06/iq06.html",
    "title": "iq06",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nWie wahrscheinlich ist es, zur Gruppe der ‚Äúdurchschnittlich intelligenten‚Äù Menschen geh√∂ren?\nDabei sei ‚Äúdurchschnittlich intelligent‚Äù definiert als der Intelligenzwert \\(X\\), f√ºr den gilt \\(x-\\sigma &lt; x &lt; x + \\sigma\\).\nHinweise:\n\nNutzen Sie Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\)\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSimulieren Sie \\(n=10^3\\) Stichproben.\nNutzen Sie die Zahl 42 als Startwert f√ºr Ihre Zufallszahlen (um die Reproduzierbarkeit zu gew√§hrleisten)\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nk &lt;- 3\nd &lt;- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd = 15))\n\nWir filtern die schlauesten 0,1 Prozent:\n\nd %&gt;% \n  count(iq &gt; 85 & iq &lt; 115) \n\n\n\n\n\niq &gt; 85 & iq &lt; 115\nn\n\n\n\n\nFALSE\n327\n\n\nTRUE\n673\n\n\n\n\n\n\nDie Antwort auf die Frage\nWie wahrscheinlich ist es, zur Gruppe der ‚Äúdurchschnittlich intelligenten‚Äù Menschen geh√∂ren?,\nlautet also 0.673.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html",
    "title": "tidymodels-tree4",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nEntscheidungsbaum\n\nModellformel: body_mass_g ~ . (Datensatz palmerpenguins::penguins)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nAuslassen gering performanter Tuningparameterwerte\nVerwenden Sie ein Anova-Grid-Search!\nParallelisieren Sie auf mehrere Kerne (wenn m√∂glich).\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nBeachten Sie die √ºblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#setup",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#setup",
    "title": "tidymodels-tree4",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(\"penguins\", package = \"palmerpenguins\")\nlibrary(tictoc)  # Zeitmessung\nlibrary(finetune)  # tune_race_anova\nlibrary(doParallel)  # mehrere CPUs nutzen \nset.seed(42)\n\nEntfernen wir F√§lle ohne y-Wert:\n\nd &lt;-\n  penguins %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#daten-teilen",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#daten-teilen",
    "title": "tidymodels-tree4",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#modelle",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#modelle",
    "title": "tidymodels-tree4",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"regression\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#rezepte",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#rezepte",
    "title": "tidymodels-tree4",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(body_mass_g ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#resampling",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#resampling",
    "title": "tidymodels-tree4",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#workflows",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#workflows",
    "title": "tidymodels-tree4",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#tuning-grid",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#tuning-grid",
    "title": "tidymodels-tree4",
    "section": "Tuning-Grid",
    "text": "Tuning-Grid\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\n\nHinweis: Andere Arten von Tuning-Grids sind sinnvoller, hier ist nur zum Vergleich mit anderen Aufgaben diese Form des Tuning-Grids gew√§hlt.\nDie Zeilen im Tuninggrid zeigen uns, f√ºr wie viele Modellparameter ein Modell berechnet wird. Nat√ºrlich √ºblicherweise jedes Modell mit Resampling. Da kommt in Summe ein mitunter sehr gro√üe Menge an Modellberechnungen zusammen."
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#ohne-speed-up",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#ohne-speed-up",
    "title": "tidymodels-tree4",
    "section": "Ohne Speed-up",
    "text": "Ohne Speed-up\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            resamples = rsmpl)\ntoc()\n\n111.597 sec elapsed\n\n\nDie angegebene Rechenzeit bezieht sich auf einen 4-Kerne-MacBook Pro (2020)."
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-1",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-1",
    "title": "tidymodels-tree4",
    "section": "Mit Speeed-up 1",
    "text": "Mit Speeed-up 1\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            control = control_race(verbose = FALSE,\n                                   pkgs = c(\"tidymodels\"),\n                                   save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n140.425 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-2",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-2",
    "title": "tidymodels-tree4",
    "section": "Mit Speeed-up 2",
    "text": "Mit Speeed-up 2\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(\n    object = wf_tree,\n    grid = tune_grid,\n    metrics = metric_set(rmse),\n    control = control_race(verbose = FALSE,\n                           pkgs = c(\"tidymodels\"),\n                           save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n129.935 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-3",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-3",
    "title": "tidymodels-tree4",
    "section": "Mit Speeed-up 3",
    "text": "Mit Speeed-up 3\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            control = control_grid(verbose = FALSE,\n                                   save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n92.329 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#fazit",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#fazit",
    "title": "tidymodels-tree4",
    "section": "Fazit",
    "text": "Fazit\nMit Speed-up ist schneller also ohne. Hier haben wir einen Entscheidungsbaum berechnet, der ist nicht so sehr parallelisierbar. Bei einem ‚ÄúWald-Modell‚Äù, wie Random Forests, sollte der Vorteil der Parallisierung viel deutlich sein.\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html",
    "title": "tidymodels-tree3",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nEntscheidungsbaum\n\nModellformel: body_mass_g ~ . (Datensatz palmerpenguins::penguins)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nAuslassen gering performanter Tuningparameterwerte\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nBeachten Sie die √ºblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#setup",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#setup",
    "title": "tidymodels-tree3",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(\"penguins\", package = \"palmerpenguins\")\nlibrary(tictoc)  # Zeitmessung\nlibrary(finetune)  # tune_race_anova\nset.seed(42)\n\nEntfernen wir F√§lle ohne y-Wert:\n\nd &lt;-\n  penguins %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#daten-teilen",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#daten-teilen",
    "title": "tidymodels-tree3",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#modelle",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#modelle",
    "title": "tidymodels-tree3",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"regression\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#rezepte",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#rezepte",
    "title": "tidymodels-tree3",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(body_mass_g ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#resampling",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#resampling",
    "title": "tidymodels-tree3",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#workflows",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#workflows",
    "title": "tidymodels-tree3",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#tuning-grid",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#tuning-grid",
    "title": "tidymodels-tree3",
    "section": "Tuning-Grid",
    "text": "Tuning-Grid\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\n\nDie Zeilen im Tuninggrid zeigen uns, f√ºr wie viele Modellparameter ein Modell berechnet wird. Nat√ºrlich √ºblicherweise jedes Modell mit Resampling. Da kommt in Summe ein mitunter sehr gro√üe Menge an Modellberechnungen zusammen."
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#ohne-speed-up",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#ohne-speed-up",
    "title": "tidymodels-tree3",
    "section": "Ohne Speed-up",
    "text": "Ohne Speed-up\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            resamples = rsmpl)\ntoc()\n\n102.337 sec elapsed\n\n\nca. auf meinem Rechner (4-Kerne-MacBook Pro 2020)."
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#mit-geschicktem-weglassen-von-tuningparametern",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#mit-geschicktem-weglassen-von-tuningparametern",
    "title": "tidymodels-tree3",
    "section": "Mit geschicktem Weglassen von Tuningparametern",
    "text": "Mit geschicktem Weglassen von Tuningparametern\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            resamples = rsmpl)\ntoc()\n\n128.856 sec elapsed\n\n\nca. - schneller!\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/pigs2/pigs2.html",
    "href": "posts/pigs2/pigs2.html",
    "title": "pigs2",
    "section": "",
    "text": "Aufgabe\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Inferenz\nlibrary(easystats)  # Komfort\n\nLaden Sie den Datensatz toothgrowth, z.B. von dieser Quelle. In dem Datensatz sind die Daten eines einfaches Experiments berichtet.\nIn dem Experiment wird der (kausale) Effekt verschiedener Darreichungsformen und Konzentrationen von Vitamin C auf das Zahnwachstum von Meerschweinchen untersucht.\nForschungsfrage:\nHat die Dosis (dose) einen (kausalen) Effekt auf die AV, Zahnl√§nge (len)?\nWir gehen mal einfach davon aus, dass der Faktor experimentell (also randomisiert und auf St√∂reffekte hin kontrollliert) veraeicht wurde. Sonst w√§re eine Kausalinterpretation nicht (ohne Weiteres) m√∂glich.\nAufgabe: Berechnen Sie die Breite eines 95%-HDI f√ºr den Effekt!\nHinweise\n         \n\n\nL√∂sung\n\nSchritt: Modell berechnen\n\n\nlm2 &lt;- stan_glm(len ~ dose, data = d,\n                seed = 42,\n                refresh = 0)\n\nZur Erinnerung: Bei der Regressionsformel gilt immer av ~  uv.\n\nSchritt: Posteriori-Verteilung betrachten\n\nMit parameters() kriegt man einen guten √úberblick √ºber die Modellparameter:\n\nparameters(lm2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n7.404367\n0.95\n4.841285\n9.957746\n1\n0.9994476\n3881.400\nnormal\n18.81333\n19.12329\n\n\ndose\n9.759631\n0.95\n7.808405\n11.758601\n1\n0.9994879\n4144.048\nnormal\n0.00000\n30.40886\n\n\n\n\n\n\nDas Modell zeigt einen positiven Effekt f√ºr dose:\nPro Einheit von dose steigt die Zahnl√§nge (len) um ca. 8-12 mm im Schnitt (laut unserem Modell).\nNull ist nicht im Intervall enthalten; die Nullhypothese ist demnach auszuschlie√üen (falls das jemanden interessiert). Man sagt, man verwirft die Nullhypothese (oder weist sie zur√ºck).\nDas k√∂nnen wir auch plotten:\n\nplot(parameters(lm2))\n\n\n\n\n\n\n\n\nMan kann sich auch ein HDI direkt ausgeben, ohne die sonstigen Informationen, die parameters() ausgibt:\n\nhdi(lm2, ci = .95)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n4.959402\n10.06051\nfixed\nconditional\n\n\ndose\n0.95\n7.769051\n11.70019\nfixed\nconditional\n\n\n\n\n\n\nWie wir sehen, wird im Standard ein 95%-Intervall berichtet, wie in der Aufgabenstellung verlangt.\nWieder sehen wir, die Null ist nicht im Intervall enthalten. Null ist also kein plausibler Wert f√ºr den gesuchten Effekt (laut unserem Modell).\nSchauen wir uns mal zum Vergleich die Stichproben-Daten an:\n\nd %&gt;% \n  ggplot(aes(y = len, x = dose)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nMan sieht deutlich einen positiven Effekt: Die Regressionsgerade steigt.\nDie Breite des Sch√§tzintervalls f√ºr den Effekt betr√§gt also:\n\nsol &lt;- 11.70 - 7.77\nsol\n\n[1] 3.93\n\n\n\nCategories:\n\nbayes\n~\nregression\nexam-22"
  },
  {
    "objectID": "posts/iq03a/index.html",
    "href": "posts/iq03a/index.html",
    "title": "iq03a",
    "section": "",
    "text": "Aufgabe\nIntelligenz wird h√§ufig mittels einem IQ-Test ermittelt.\nPersonen mit einem Testwert von h√∂chstens 100 Punkten kann man als ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù bezeichnen.\nDefinieren wir also das Ereignis ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù als ‚Äúdie n√§chste Person, die Sie treffen, hat einen IQ von h√∂chstens 100 Punkten‚Äù.\nWie gro√ü ist die Wahrscheinlichkeit, dass die n√§chste Person, die Sie treffen, nicht √ºberdurchschnittlich intelligent ist?\nHinweise:\n\nNutzen Sie keine Simulationsmethoden.\nGehen Sie von folgender IQ-Verteilung aus: \\(IQ \\sim N(100,15)\\).\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nGeben Sie keine Prozentzahlen, sondern stets Anteile an.\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nL√∂sung: Die Wahrscheinlichkeit f√ºr ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù betr√§gt 50%.\n\npnorm(100, mean = 100, sd = 15)\n\n[1] 0.5\n\n\nDas Ereignis ‚Äúnicht √ºberdurchschnittlich intelligent‚Äù kann man vielleicht einfacher - und auf jeden Fall pr√§ziser benennen mit \\(iq \\le 100\\).\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nnum"
  },
  {
    "objectID": "posts/wuerfel02/wuerfel02.html",
    "href": "posts/wuerfel02/wuerfel02.html",
    "title": "wuerfel02",
    "section": "",
    "text": "Exercise\nWas ist die Wahrscheinlichkeit, mit zwei fairen W√ºrfeln mindestens 10 Augen zu werfen?\nHinweise:\n\nNutzen Sie exakte Methoden der Wahrscheinlichkeitsrechnung, keine Simulation.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\n\n         \n\n\nSolution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden W√ºrfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), ‚Ä¶, (1,6), ‚Ä¶, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd &lt;- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\n\nd\n\n\n\n\n\nwuerfel1\nwuerfel2\n\n\n\n\n1\n1\n\n\n1\n2\n\n\n1\n3\n\n\n1\n4\n\n\n1\n5\n\n\n1\n6\n\n\n2\n1\n\n\n2\n2\n\n\n2\n3\n\n\n2\n4\n\n\n2\n5\n\n\n2\n6\n\n\n3\n1\n\n\n3\n2\n\n\n3\n3\n\n\n3\n4\n\n\n3\n5\n\n\n3\n6\n\n\n4\n1\n\n\n4\n2\n\n\n4\n3\n\n\n4\n4\n\n\n4\n5\n\n\n4\n6\n\n\n5\n1\n\n\n5\n2\n\n\n5\n3\n\n\n5\n4\n\n\n5\n5\n\n\n5\n6\n\n\n6\n1\n\n\n6\n2\n\n\n6\n3\n\n\n6\n4\n\n\n6\n5\n\n\n6\n6\n\n\n\n\n\n\nJetzt erg√§nzen wir eine Spalte f√ºr die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 &lt;-\n  d %&gt;% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\n\n\n\n\n1\n1\n0.0277778\n\n\n1\n2\n0.0277778\n\n\n1\n3\n0.0277778\n\n\n1\n4\n0.0277778\n\n\n1\n5\n0.0277778\n\n\n1\n6\n0.0277778\n\n\n\n\n\n\nAu√üerdem erg√§nzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\naugensumme\n\n\n\n\n1\n1\n0.0277778\n2\n\n\n1\n2\n0.0277778\n3\n\n\n1\n3\n0.0277778\n4\n\n\n1\n4\n0.0277778\n5\n\n\n1\n5\n0.0277778\n6\n\n\n1\n6\n0.0277778\n7\n\n\n\n\n\n\nF√ºr manche Augensummen gibt es mehrere M√∂glichkeiten:\n\nd3 %&gt;% \n  filter(augensumme == 7)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\naugensumme\n\n\n\n\n1\n6\n0.0277778\n7\n\n\n2\n5\n0.0277778\n7\n\n\n3\n4\n0.0277778\n7\n\n\n4\n3\n0.0277778\n7\n\n\n5\n2\n0.0277778\n7\n\n\n6\n1\n0.0277778\n7\n\n\n\n\n\n\n‚Ä¶ f√ºr andere weniger:\n\nd3 %&gt;% \n  filter(augensumme == 12)\n\n\n\n\n\nwuerfel1\nwuerfel2\nprob\naugensumme\n\n\n\n\n6\n6\n0.0277778\n12\n\n\n\n\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 &lt;- \n  d3 %&gt;% \n  group_by(augensumme) %&gt;% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n\n\n\n\naugensumme\ntotale_w_pro_augenzahl\n\n\n\n\n2\n0.0277778\n\n\n3\n0.0555556\n\n\n4\n0.0833333\n\n\n5\n0.1111111\n\n\n6\n0.1388889\n\n\n7\n0.1666667\n\n\n8\n0.1388889\n\n\n9\n0.1111111\n\n\n10\n0.0833333\n\n\n11\n0.0555556\n\n\n12\n0.0277778\n\n\n\n\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %&gt;% \n  summarise(sum(totale_w_pro_augenzahl))\n\n\n\n\n\nsum(totale_w_pro_augenzahl)\n\n\n\n\n1\n\n\n\n\n\n\nUnd:\n\nd2 %&gt;% \n  summarise(sum(prob))\n\n\n\n\n\nsum(prob)\n\n\n\n\n1\n\n\n\n\n\n\nPasst!\nDie Wahrscheinlichkeit f√ºr die Augensumme von mind. 10 betr√§gt also:\n\nloesung &lt;-\n  d4 %&gt;% \n  filter(augensumme &gt;= 10) %&gt;% \n  summarise(prob_sum = sum(totale_w_pro_augenzahl)) %&gt;% \n  pull(prob_sum)\n\nloesung\n\n[1] 0.1666667\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/CV1/CV1.html",
    "href": "posts/CV1/CV1.html",
    "title": "CV1",
    "section": "",
    "text": "Kreuzvalidierung (CV) ist ein g√§ngiges Verfahren, um die Vorhersageg√ºte in einem Testdatensatz einzusch√§tzen und um Parameterwerte (Tuningparameter) auszuw√§hlen. Welche der folgenden Aussagen zur Kreuzvalidierung ist richtig?\n\n\n\nBei der Kreuzvalidierung k√∂nnen unterschiedliche Fehlerwerte (z.B. \\(MSE\\)) resultieren in Abh√§ngigkeit von der (zuf√§lligen) Aufteilung in die jeweiligen Train- und Validierungsstichprobe.\nBei der Anzahl der Faltungen (folds) sollte stets \\(k=10\\) gew√§hlt werden.\nBei der Anzahl der Faltungen (folds) sollte stets \\(k=5\\) gew√§hlt werden.\nDie \\(k\\)-fache Kreuzvalidierung ist rechenintensiver als die LOOCV-Methode.\nDie wiederholte \\(k\\)-fache Kreuzvalidierung erh√∂ht die Gefahr des Overfittings und sollte daher vermieden werden."
  },
  {
    "objectID": "posts/CV1/CV1.html#answerlist",
    "href": "posts/CV1/CV1.html#answerlist",
    "title": "CV1",
    "section": "",
    "text": "Bei der Kreuzvalidierung k√∂nnen unterschiedliche Fehlerwerte (z.B. \\(MSE\\)) resultieren in Abh√§ngigkeit von der (zuf√§lligen) Aufteilung in die jeweiligen Train- und Validierungsstichprobe.\nBei der Anzahl der Faltungen (folds) sollte stets \\(k=10\\) gew√§hlt werden.\nBei der Anzahl der Faltungen (folds) sollte stets \\(k=5\\) gew√§hlt werden.\nDie \\(k\\)-fache Kreuzvalidierung ist rechenintensiver als die LOOCV-Methode.\nDie wiederholte \\(k\\)-fache Kreuzvalidierung erh√∂ht die Gefahr des Overfittings und sollte daher vermieden werden."
  },
  {
    "objectID": "posts/CV1/CV1.html#answerlist-1",
    "href": "posts/CV1/CV1.html#answerlist-1",
    "title": "CV1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nstatlearning\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/wuerfel05/wuerfel05.html",
    "href": "posts/wuerfel05/wuerfel05.html",
    "title": "wuerfel05",
    "section": "",
    "text": "Aufgabe\nWas ist die Wahrscheinlichkeit, mit zwei fairen W√ºrfeln genau 12 Augen zu werfen?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nDie Ereignisse A=‚ÄúWurf des 1. W√ºrfels‚Äù und B=‚ÄúWurf des 2. W√ºrfels‚Äù sind unabh√§ngig voneinander.\nDaher gilt: \\(Pr(A\\cap B) = Pr(AB) = Pr(A) \\cdot Pr(B)\\).\n\nPr_AB &lt;- 1/6 * 1/6\nPr_AB\n\n[1] 0.02777778\n\n\nAufgrund der Unabh√§ngigkeit gilt au√üerdem: \\(Pr(A|B) = Pr(A) = Pr(A|\\neg B).\\)\nDie L√∂sung lautet 0.0277778.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/Typ-Fehler-R-03/Typ-Fehler-R-03.html",
    "href": "posts/Typ-Fehler-R-03/Typ-Fehler-R-03.html",
    "title": "Typ-Fehler-R-03",
    "section": "",
    "text": "Aufgabe\nGegeben sei diese Syntax:\n\nx &lt;- 42\nY &lt;- 1\n\nL√§sst man folgende Syntax laufen, so kommt eine Fehlermeldung:\n\nX + Y\n\nError: object 'X' not found\n\n\nGeben Sie die korrekte Syntax ein (zur Berechnung der Summe), die nicht zu einer Fehlermeldung f√ºhrt!\nBitte verwenden Sie keine Leerzeichen bei Ihrer Eingabe.\n         \n\n\nL√∂sung\n\nx+Y\n\n[1] 43\n\n\nDie Antwort lautet: x+Y.\n\nCategories:\nstring"
  },
  {
    "objectID": "posts/mtcars-rope1/mtcars-rope1.html",
    "href": "posts/mtcars-rope1/mtcars-rope1.html",
    "title": "mtcars-rope1",
    "section": "",
    "text": "Exercise\nIm Datensatz mtcars: Ist der (mittlere) Unterschied im Spritverbrauch zwischen den beiden Stufen von vs vernachl√§ssigbar klein?\nDefinieren Sie ‚Äúvernachl√§ssigbar klein‚Äù mit ‚Äúh√∂chstens eine Meile‚Äù.\n\nGeben Sie die Breite des 95% PI an (im Bezug zur gesuchten Gr√∂√üe).\nGeben Sie das 95% HDI an (im Bezug zur gesuchten Gr√∂√üe).\nIm Hinblick auf die Rope-Methode: Ist der Unterschied vernachl√§ssigbar klein? (ja/nein/unentschieden)\n\nHinweise:\n\nVerwenden Sie ansonsten die Standardwerte (Defaults) der typischen (im Unterricht verwendeten) R-Funktionen.\nRunden Sie auf 2 Dezimalstellen.\nVerwenden Sie Methoden der Bayes-Statistik.\n\n         \n\n\nSolution\nSetup:\n\ndata(mtcars)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(bayesplot)  # Histogramm-Plots f√ºr Post-Vert.\nlibrary(bayestestR)  # rope\n\nModell berechnen:\n\nm1 &lt;- stan_glm(mpg ~ vs, data = mtcars,\n               refresh = 0)\n\n\ncoef(m1)\n\n(Intercept)          vs \n  16.604674    7.926746 \n\n\nzu a)\n95%-PI:\n\npost_m1_vs &lt;- posterior_interval(m1, prob = .95,\n                   pars = \"vs\")\npost_m1_vs[1]\n\n[1] 4.49118\n\npost_m1_vs[2]\n\n[1] 11.28616\n\n\nBreite des Intervalls:\n\nbreite &lt;- post_m1_vs[2] - post_m1_vs[1]\nbreite &lt;- breite %&gt;% round(2)\nbreite\n\n[1] 6.79\n\n\nDie Antwort f√ºr a) lautet also 6.79.\n\nmcmc_areas(m1)\n\n\n\n\n\n\n\n\nzu b)\nWir nutzen den Befehl hdi() aus {bayestestR}.\n\nhdi(m1)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n14.53580\n18.93290\nfixed\nconditional\n\n\nvs\n0.95\n4.65166\n11.38565\nfixed\nconditional\n\n\n\n\n\n\nMit dem Schalter ci = .89 bek√§me man bspw. ein 89%-Intervall (s. Hilfe f√ºr den Befehl).\n‚Äúhdi‚Äù und ‚Äúhdpi‚Äù und ‚Äúhpdi‚Äù sind synonym.\n\nggplot(mtcars) +\n  aes(x = vs, y = mpg) +\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nzu c)\n\nrope(m1,range = c(-1,1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-1\n1\n0\nfixed\nconditional\n\n\nvs\n0.95\n-1\n1\n0\nfixed\nconditional\n\n\n\n\n\n\n\nplot(rope(m1, range = c(-1,1)))\n\n\n\n\n\n\n\n\nWir verwerfen also die H0-Rope.\n\nCategories:\n\nbayes\nlm"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html",
    "href": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html",
    "title": "Verteilungen-Quiz-07",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\le 100) \\ne 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist",
    "href": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist",
    "title": "Verteilungen-Quiz-07",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist-1",
    "title": "Verteilungen-Quiz-07",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/movie-sentiment1/movie-sentiment1.html",
    "href": "posts/movie-sentiment1/movie-sentiment1.html",
    "title": "movie-sentiment1",
    "section": "",
    "text": "Eine typische Aufgabe des Textminings ist die Sentimentanalyse. Betrachten wir dazu einen Datensatz des Filmbewertungsportal IMDB. Das Portal ver√∂ffentlicht Bewertungen (quantitativ und qualitativ, d.h. als Score oder Bewertung/Review) zu Filmen der Nutzerinnen und Nutzer. Der Datensatz kann √ºber Kaggle bezogen werden.\nIm Rahmen einer Fallstudie soll eine Sentimentanalyse wie folgt abgearbeitet werden:\n\nDaten in R importieren\nRelevante Spalten ausw√§hlen (die die Reviews der Nutzer enthalten)\nDaten in das ‚ÄúTidytext-Format‚Äù √ºberf√ºhren\nNicht-W√∂rter (z.B. Zahlen) entfernen\nStopw√∂rter entfernen\nSentimentanalyse durchf√ºhren zur Identifikation der Grundemotionen\nVisualisierung der Intensit√§t der Emotionen der 10 h√§ufigsten W√∂rter (sortierte Balken)\n\nHinweise:\n\nHier ist nur ein Teil des Datensatzes dargestellt (aus Gr√ºnden der Einfachheit).\nGehen Sie davon aus, dass die Daten unter dem Pfad verf√ºgbar sind, der in dieser Variable gespeichert ist: path_to_data. Die relevanten Spalten sind dort schon ausgew√§hlt.\n\nWelcher der folgenden R-Syntaxen f√ºhrt diese Analyse korrekt aus? W√§hlen Sie die am besten passende Antwort!\nOption A\n\n\n\nlibrary(tidytext)\nlibrary(tidyverse)\n\nd &lt;- read_csv(path_to_data)\n\nstopwords &lt;- get_stopwords()\nemo &lt;- get_sentiments('loughran')\n\nwordcount_plot1 &lt;- \nd %&gt;% \n  select(review) %&gt;% \n  unnest_tokens(word, review) %&gt;% \n  filter(str_detect(word, '\\w.')) %&gt;% \n  anti_join(stopwords) %&gt;% \n  inner_join(emo) %&gt;% \n  count(word, sort = TRUE) %&gt;% \n  slice_head(n = 10) %&gt;% \n  mutate(word = fct_reorder(word, n)) %&gt;% \n  ggplot(aes(n, word)) +\n  geom_col()\n\n\nOption B\n\n\n\nlibrary(tidytext) \nlibrary(tidyverse)\n\nd &lt;- read_csv(path_to_data)\n\nstopwords &lt;- get_stopwords()\nemo &lt;- get_sentiments('nrc')\n\nwordcount_plot1 &lt;- \nd %&gt;% \n  select(review) %&gt;% \n  unnest_tokens(word, review) %&gt;% \n  filter(str_detect(word, '[a-z]+')) %&gt;% \n  anti_join(stopwords) %&gt;% \n  inner_join(emo) %&gt;% \n  count(word, sort = TRUE) %&gt;% \n  slice_head(n = 10) %&gt;% \n  mutate(word = fct_reorder(word, n)) %&gt;% \n  ggplot(aes(n, word)) +\n  geom_col()\n\n\nOption C\n\n\n\nlibrary(tidytext)\nlibrary(tidyverse)\n\nd &lt;- read_csv(path_to_data)\n\nstopwords &lt;- get_stopwords()\nemo &lt;- get_sentiments('nrc')\n\nwordcount_plot1 &lt;- \nd %&gt;% \n  select(review) %&gt;% \n  unnest_tokens(word, review) %&gt;% \n  filter(str_detect(word, '[a-z]+')) %&gt;% \n  left_join(stopwords) %&gt;% \n  inner_join(emo) %&gt;% \n  count(word, sort = TRUE) %&gt;% \n  slice(n = 10) %&gt;% \n  ggplot(aes(x = n, y = word)) +\n  geom_bar()\n  \n\n\nOption D\n\n\nkeine der genannten\n\n\nOption E\n\n\n\nlibrary(tidytext)\nlibrary(tidyverse)\n\nd &lt;- read_csv(path_to_data)\n\nstopwords &lt;- get_stopwords()\nemo &lt;- get_sentiments()\n\nd %&gt;% \n  select(review) %&gt;% \n  unnest_tokens(word, review) %&gt;% \n  filter(str_detect(word, '[a-z]+')) %&gt;% \n  anti_join(stopwords) %&gt;% \n  inner_join(emo) %&gt;% \n  count(word) %&gt;% \n  slice_head(n = 10) %&gt;% \n  mutate(word = fct_reorder(word, n)) %&gt;% \n  ggplot(aes(n, word)) +\n  geom_bar()\n\n\n\n\n\nSyntax A\nSyntax B\nSyntax C\nSyntax D\nSyntax E"
  },
  {
    "objectID": "posts/movie-sentiment1/movie-sentiment1.html#answerlist",
    "href": "posts/movie-sentiment1/movie-sentiment1.html#answerlist",
    "title": "movie-sentiment1",
    "section": "",
    "text": "Syntax A\nSyntax B\nSyntax C\nSyntax D\nSyntax E"
  },
  {
    "objectID": "posts/movie-sentiment1/movie-sentiment1.html#answerlist-1",
    "href": "posts/movie-sentiment1/movie-sentiment1.html#answerlist-1",
    "title": "movie-sentiment1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ntextmining\nimdb\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz15/wskt-quiz15.html",
    "href": "posts/wskt-quiz15/wskt-quiz15.html",
    "title": "wskt-quiz15",
    "section": "",
    "text": "Behauptung:\n\\(Pr(BA) = Pr(B|A) \\cdot Pr(A)\\).\nHinweise:\n\n‚ÄúAB‚Äù meint das gemeinsame Auftreten der Eregnisse ‚ÄúA‚Äù und ‚ÄúB‚Äù.\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz15/wskt-quiz15.html#answerlist",
    "href": "posts/wskt-quiz15/wskt-quiz15.html#answerlist",
    "title": "wskt-quiz15",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz15/wskt-quiz15.html#answerlist-1",
    "href": "posts/wskt-quiz15/wskt-quiz15.html#answerlist-1",
    "title": "wskt-quiz15",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/fofrage-regrformel/index.html",
    "href": "posts/fofrage-regrformel/index.html",
    "title": "fofrage-regrformel",
    "section": "",
    "text": "1 Aufgabe\n√úbersetzen Sie folgende Forschungsfrage in die korrekte Regressionsformel!\n\nGibt es einen Interaktionseffekt zwischen Geschlecht und Schnabell√§nge auf das Gewicht eines Pinguins? Liegen auch Haupteffekte vor?\n\nHinweise:\n\nUnter ‚ÄúHaupteffekt‚Äù versteht man den Effekt einer UV auf die AV (im Gegensatz zu einem Interaktionseffekt, der ja der gemeinsame Effekt mehrerer UV auf die AV ist).\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\nBeziehen Sie sich auf den Datensatz penguins.\n\n\nlibrary(palmerpenguins)\ndata(penguins)\n\n\nlibrary(tidyverse)\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nDie Regressionsformel lautet: body_mass_g ~ sex + bill_length_mm + sex:bill_length_mm."
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html",
    "href": "posts/step-dummy/step-dummy.html",
    "title": "step-dummy",
    "section": "",
    "text": "Viele Lernalgorithmen k√∂nnen nicht mit nominalen Variablen umgehen; daher muss man sie dummifizieren, um sie einer Verarbeitung zug√§nglich zu machen. In Tidymodels gibt es daf√ºr step_dummy().\nAber bezieht step_dummy() nur Variablen vom Typ factor ein oder auch Variablen vom Typ character? Oder vielleicht weder noch?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nNur Variablen vom Typ factor\nNur Variablen vom Typ character\nSowohl Variablen vom Typ factor als auch vom Typ character\nWeder Variablen vom Typ factor noch vom Typ character"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#answerlist",
    "href": "posts/step-dummy/step-dummy.html#answerlist",
    "title": "step-dummy",
    "section": "",
    "text": "Nur Variablen vom Typ factor\nNur Variablen vom Typ character\nSowohl Variablen vom Typ factor als auch vom Typ character\nWeder Variablen vom Typ factor noch vom Typ character"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#setup",
    "href": "posts/step-dummy/step-dummy.html#setup",
    "title": "step-dummy",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\nDaten:\n\nd &lt;-\n  data.frame(\n    y = c(1,2,3,4,5),\n    x = c(\"A\", \"B\", \"B\", \"C\", \"A\")\n  )\n\nstr(d)\n\n'data.frame':   5 obs. of  2 variables:\n $ y: num  1 2 3 4 5\n $ x: chr  \"A\" \"B\" \"B\" \"C\" ..."
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#rezept-1",
    "href": "posts/step-dummy/step-dummy.html#rezept-1",
    "title": "step-dummy",
    "section": "Rezept 1",
    "text": "Rezept 1\nRezept 1, mit Variable vom Typ character:\n\nrec &lt;-\n  recipe(y ~ x, data = d) %&gt;% \n  step_dummy(x)\n\nd_baked &lt;- rec %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nstr(d_baked)\n\ntibble [5 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ y  : num [1:5] 1 2 3 4 5\n $ x_B: num [1:5] 0 1 1 0 0\n $ x_C: num [1:5] 0 0 0 1 0"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#rezept-2",
    "href": "posts/step-dummy/step-dummy.html#rezept-2",
    "title": "step-dummy",
    "section": "Rezept 2",
    "text": "Rezept 2\nRezept 2, mit Variable vom Typ factor:\nDaten:\n\nd2 &lt;-\n  data.frame(\n    y = c(1,2,3,4,5),\n    x = factor(c(\"A\", \"B\", \"B\", \"C\", \"A\"))\n  )\n\nstr(d2)\n\n'data.frame':   5 obs. of  2 variables:\n $ y: num  1 2 3 4 5\n $ x: Factor w/ 3 levels \"A\",\"B\",\"C\": 1 2 2 3 1\n\n\n\nrec2 &lt;-\n  recipe(y ~ x, data = d2) %&gt;% \n  step_dummy(x)\n\nd_baked2 &lt;- rec2 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nstr(d_baked2)\n\ntibble [5 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ y  : num [1:5] 1 2 3 4 5\n $ x_B: num [1:5] 0 1 1 0 0\n $ x_C: num [1:5] 0 0 0 1 0"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#answerlist-1",
    "href": "posts/step-dummy/step-dummy.html#answerlist-1",
    "title": "step-dummy",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr. step_dummy transformiert beide Arten von Variablen\nFalsch\n\n\nCategories:\n\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/Pfad/Pfad.html",
    "href": "posts/Pfad/Pfad.html",
    "title": "Pfad",
    "section": "",
    "text": "Aufgabe\nRecherchieren Sie den Datensatz ‚ÄúPalmer Penguins‚Äù als CSV-Datei im Internet.\n\nImportieren Sie die Datendatei in R von einer geeigneten Online-Quelle.\nLaden Sie die Datendatei herunter, speichern Sie Sie in den Ordner Ihres aktuellen RStudio-Projekts. Dann importieren Sie die Datendatei in R von diesem Ort.\n\n         \n\n\nL√∂sung\n\nlibrary(tidyverse)\n\nAd 1)\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\nd &lt;- read_csv(penguins_url)\n\n\n\n\n\n\n\n\n\nrownames\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n1\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\n2\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\n5\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\n6\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\n\nAlternativ (hier aber nicht verlangt) k√∂nnen Sie den Datensatz penguins auch √ºber ein R-Paket beziehen:\n\ndata(penguins, package = \"palmerpenguins\")\n\nhead(penguins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\nSynonym:\n\nlibrary(palmerpenguins)\ndata(penguins)\nhead(penguins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\nAchtung:\nWenn Sie das Paket palmerpenguins nicht mit library() gestartet haben, dann wird data(penguins) nicht funktionieren.\nAd 2)\nWenn Sie die Datei heruntergeladen haben und in Ihrem (aktuellen) RStudio-Projektordner abgespeichert haben, dann (und nur dann) k√∂nnen Sie sie ohne Angabe eines Pfades in R importieren:\n\nd &lt;- read_csv(\"penguins.csv\")  # die Datei muss im aktuellen Verzeichnis liegen\n\n\nCategories:\n\nR\npath\ndatawrangling\nqm1\nqm2\nstring"
  },
  {
    "objectID": "posts/wskt-quiz08/wskt-quiz08.html",
    "href": "posts/wskt-quiz08/wskt-quiz08.html",
    "title": "wskt-quiz08",
    "section": "",
    "text": "Mehrere Proben werden zu einem unbekannten Planeten geschossen. Die Forschungsfrage lautet: Ist es die Erde (70% Wasseranteil) oder der Planet ‚ÄúBath42‚Äù mit 90% Wasseranteil?\nWir sind indifferent (apriori) zu den Parameterwerten.\nDaten: 6 Treffer (Wasser) von 9 Versuchen (Proben).\nBehauptung: ‚ÄúDas ist fast sicher Bath42!‚Äù.\nIst die Wahrscheinlichkeit h√∂her f√ºr Bath42 (als f√ºr die Erde)?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz08/wskt-quiz08.html#answerlist",
    "href": "posts/wskt-quiz08/wskt-quiz08.html#answerlist",
    "title": "wskt-quiz08",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz08/wskt-quiz08.html#answerlist-1",
    "href": "posts/wskt-quiz08/wskt-quiz08.html#answerlist-1",
    "title": "wskt-quiz08",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/penguins-lm/index.html",
    "href": "posts/penguins-lm/index.html",
    "title": "penguins-lm",
    "section": "",
    "text": "Consider the dataset penguins. Compute a linear model with body mass as output variable (DV) and flipper length as input (IV).\n\nReport the coefficients and interpret them.\nPlot the model and the coefficients.\nReport the model fit (R squared).\nBONUS: predict() the weight of an average flipper-sized animal. Check out the internet for examples of how to do so in case you need support."
  },
  {
    "objectID": "posts/penguins-lm/index.html#setup",
    "href": "posts/penguins-lm/index.html#setup",
    "title": "penguins-lm",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)\n\n# import data:\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")"
  },
  {
    "objectID": "posts/penguins-lm/index.html#lets-go",
    "href": "posts/penguins-lm/index.html#lets-go",
    "title": "penguins-lm",
    "section": "2.2 Let‚Äôs go",
    "text": "2.2 Let‚Äôs go\n\nlm1 &lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins)\n\nPlot the model:\n\nplot(estimate_relation(lm1))\n\n\n\n\n\n\n\n\nAlternative plotting method:\n\nggscatter(penguins,\n          x = \"flipper_length_mm\",\n          y = \"body_mass_g\",\n          add =\"reg.line\")\n\n\n\n\n\n\n\n\nCoefficients (parameters):\n\nparameters(lm1)\n\nParameter         | Coefficient |     SE |               95% CI | t(340) |      p\n---------------------------------------------------------------------------------\n(Intercept)       |    -5780.83 | 305.81 | [-6382.36, -5179.30] | -18.90 | &lt; .001\nflipper length mm |       49.69 |   1.52 | [   46.70,    52.67] |  32.72 | &lt; .001\n\n\nPlot the coefficients:\n\nplot(parameters(lm1))\n\n\n\n\n\n\n\n\nModel fit (explained variance by model):\n\nr2(lm1)\n\n# R2 for Linear Regression\n       R2: 0.759\n  adj. R2: 0.758\n\n\nPredict weight of average animal:\n\npenguins |&gt; \n  summarise(flipper_length_mm_avg = \n              mean(flipper_length_mm, na.rm = TRUE))\n\n  flipper_length_mm_avg\n1                   201"
  },
  {
    "objectID": "posts/penguins-lm/index.html#for-average-flipper-length-whats-the-expected-weight",
    "href": "posts/penguins-lm/index.html#for-average-flipper-length-whats-the-expected-weight",
    "title": "penguins-lm",
    "section": "2.3 For average flipper length, what‚Äôs the expected weight?",
    "text": "2.3 For average flipper length, what‚Äôs the expected weight?\n\npredict(lm1, newdata = data.frame(flipper_length_mm = 200))\n\n   1 \n4156 \n\n\nAround 4 kgs."
  },
  {
    "objectID": "posts/penguins-lm/index.html#centering-the-data",
    "href": "posts/penguins-lm/index.html#centering-the-data",
    "title": "penguins-lm",
    "section": "2.4 Centering the data",
    "text": "2.4 Centering the data\nCenter the data:\n\npenguins_c &lt;-\n  penguins |&gt; \n  mutate(flipper_length_mm_c = center(flipper_length_mm))\n\nNow the mean value is (nearly) zero:\n\nmean(penguins_c$flipper_length_mm_c, na.rm = TRUE)\n\n[1] -1.2e-14\n\n\nRun the model again:\n\nlm2 &lt;- lm(body_mass_g ~ flipper_length_mm_c, data = penguins_c)\n\nparameters(lm2)\n\nParameter           | Coefficient |    SE |             95% CI | t(340) |      p\n--------------------------------------------------------------------------------\n(Intercept)         |     4201.75 | 21.32 | [4159.82, 4243.69] | 197.08 | &lt; .001\nflipper length mm c |       49.69 |  1.52 | [  46.70,   52.67] |  32.72 | &lt; .001"
  },
  {
    "objectID": "posts/Histogramm-in-Boxplot/Histogramm-in-Boxplot.html",
    "href": "posts/Histogramm-in-Boxplot/Histogramm-in-Boxplot.html",
    "title": "Histogramm-in-Boxplot",
    "section": "",
    "text": "Histogramm:\n\n\n\n\n\n\n\n\n\nBoxplots:\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\nBoxplot A\nBoxplot B\nBoxplot C\nBoxplot D\nBoxplot E"
  },
  {
    "objectID": "posts/Histogramm-in-Boxplot/Histogramm-in-Boxplot.html#answerlist",
    "href": "posts/Histogramm-in-Boxplot/Histogramm-in-Boxplot.html#answerlist",
    "title": "Histogramm-in-Boxplot",
    "section": "",
    "text": "Boxplot A\nBoxplot B\nBoxplot C\nBoxplot D\nBoxplot E"
  },
  {
    "objectID": "posts/Histogramm-in-Boxplot/Histogramm-in-Boxplot.html#answerlist-1",
    "href": "posts/Histogramm-in-Boxplot/Histogramm-in-Boxplot.html#answerlist-1",
    "title": "Histogramm-in-Boxplot",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/bed-wskt1/bed-wskt1.html",
    "href": "posts/bed-wskt1/bed-wskt1.html",
    "title": "Bed-Wskt1",
    "section": "",
    "text": "Aufgabe\nProf.¬†Bitter-S√º√ü untersucht eine seiner Lieblingsfragen: Wie viel bringt das Lernen auf eine Klausur? Dabei konzentriert er sich auf das Fach Statistik (es gef√§llt ihm gut). In einer aktuellen Untersuchung hat er \\(n=90\\) Studierende untersucht (s. Tabelle und Diagramm) und jeweils erfasst, ob die Person die Klausur bestanden (b) hat oder durchgefallen (d) ist. Dabei hat er zwei Gruppen unterschieden: Die ‚ÄúViel-Lerner‚Äù (VL) und die ‚ÄúWenig-Lerner‚Äù (WL).\nBerechnen Sie die folgende bedingte Wahrscheinlichkeit: p(Durchfallen|Weniglerner).\nBeispiel: Wenn Sie ausrechnen, dass die Wahrscheinlichkeit bei 42 Prozentpunkten liegt, so geben Sie ein: 0,42 bzw. 0.42 (das Dezimalzeichen ist abh√§ngig von Ihren Spracheinstellungen).\nHinweise:\n\nGeben Sie nur eine Zahl ein (ohne Prozentzeichen o.√Ñ.), z.B. 0,42.\nAndere Angaben k√∂nnen u.U. nicht gewertet werden.\nRunden Sie auf zwei Dezimalstellen.\nAchten Sie darauf, das korrekte Dezimaltrennzeichen einzugeben; auf Ger√§ten mit deutscher Spracheinstellung ist dies oft ein Komma.\n\n\nd &lt;-\n  tibble(Lerntyp = c(rep(\"Weniglerner\", times = n_weniglerner),\n                     rep(\"Viellerner\", times = n_viellerner))) %&gt;% \n  mutate(Lerntyp = factor(Lerntyp)) %&gt;% \n  mutate(Erfolg_p = case_when(\n    Lerntyp == \"Weniglerner\" ~ erfolgsquote_viellerner,\n    Lerntyp == \"Viellerner\" ~ erfolgsquote_viellerner,\n    TRUE ~ NA_real_\n  )) %&gt;% \n  mutate(Klausurergebnis = map_chr(.x = Erfolg_p,\n                                   .f = ~(sample(Klausurergebnis,\n                                                 size = 1,\n                                                 prob = c(.x, 1-.x)))))\n\n\nggplot(d) +\n  aes(x = Lerntyp, fill = factor(Klausurergebnis)) +\n  geom_bar() +\n  labs(fill = \"\")\n\n\n\n\n\n\n\n\nmosaic::tally(Klausurergebnis ~ Lerntyp, data = d) %&gt;% \n  kbl(caption = \"Ergebnisse der Studie\") %&gt;% \n  kable_classic(full_width = F, html_font = \"Cambria\")\n\nErgebnisse der Studie\n\n\n\nViellerner\nWeniglerner\n\n\n\n\nBestehen\n51\n33\n\n\nDurchfallen\n3\n3\n\n\n\n         \n\n\nL√∂sung\n\nprob_conditional %&gt;% \n  filter(Lerntyp == Lerntyp_selected, \n         Klausurergebnis == Klausurergebnis_selected) %&gt;% \n  gt()\n\n\n\n\n\n\n\nLerntyp\nKlausurergebnis\nn\nn_group\nprop_conditional_group\nN_gesamt\n\n\n\n\nWeniglerner\nDurchfallen\n3\n36\n0.08333333\n90\n\n\n\n\n\n\n\n\nn &lt;- \n prob_conditional %&gt;% \n  filter(Lerntyp == Lerntyp_selected, \n         Klausurergebnis == Klausurergebnis_selected) |&gt; \n  pull(n)\n\n\nn_group &lt;- \n  prob_conditional %&gt;% \n  filter(Lerntyp == Lerntyp_selected, \n         Klausurergebnis == Klausurergebnis_selected) |&gt; \n  pull(n_group)\n\nAntwort: Der gesuchte Wert liegt bei \\(3 / 36 =  0.08\\).\n\nCategories:\n\nprobability\nbayes\nnum"
  },
  {
    "objectID": "posts/dplyr-uebersetzen/dplyr-uebersetzen.html",
    "href": "posts/dplyr-uebersetzen/dplyr-uebersetzen.html",
    "title": "dplyr-uebersetzen",
    "section": "",
    "text": "library(tidyverse)\n\n\nAufgabe\nImportieren Sie den folgenden Datensatz in R:\n\nmtcars &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\")\n\n√úbersetzen Sie dann die folgende R-Sequenz ins Deutsche:\n\nmtcars %&gt;% \n  drop_na() %&gt;% \n  select(mpg, hp, cyl) %&gt;% \n  filter(hp &gt; 100, cyl &gt;= 6) %&gt;% \n  group_by(cyl) %&gt;% \n  summarise(mpg_mean = mean(mpg))\n\n\n\n\n\ncyl\nmpg_mean\n\n\n\n\n6\n19.74286\n\n\n8\n15.10000\n\n\n\n\n\n\n         \n\n\nL√∂sung\nHey R:\n\nNimm den Datensatz mtcars UND DANN\nhau alle Zeilen raus, in denen es fehlende Werte gibt UND DANN\nw√§hle (selektiere) die folgenden Spalten: Spritverbrauch, PS, Zylinder UND DANN\nfilter Autos mit mehr als 100 PS und mit mindestens 6 Zylindern UND DANN\ngruppiere nach der Zahl der Zylinder UND DANN\nfasse den Verbrauch zum Mittelwert zusammen.\n\n\nCategories:\n\ndatawrangling\ntidyverse\nstring"
  },
  {
    "objectID": "posts/rope3/rope3.html",
    "href": "posts/rope3/rope3.html",
    "title": "rope3",
    "section": "",
    "text": "Einer der (bisher) gr√∂√üten Studien der Untersuchung psychologischer Konsequenzen (oder Korrelate) der Covid-Zeit ist die Studie COVIDiStress.\nIm Folgenden sollen Sie folgende Forschungsfrage untersuchen:\nIst der Zusammenhang von Stress (PSS10_avg, AV) und Neurotizismus (neu, UV) vernachl√§ssigbar klein?\nDen Datensatz k√∂nnen Sie so herunterladen (Achtung, gro√ü):\n\nosf_d_path &lt;- \"https://osf.io/cjxua/?action=download\"\n\nd &lt;- read_csv(osf_d_path)\n\nHinweise:\n\nSie ben√∂tigen einen Computer, um diese Aufgabe zu l√∂sen.\nVerwenden Sie die statistischen Methoden, die im Unterricht behandelt wurden.\nVerwenden Sie Ans√§tze aus der Bayes-Statistik zur L√∂sung dieser Aufgabe.\nBei der Variable f√ºr Geschlecht k√∂nnen Sie sich auf F√§lle begrenzen, die M√§nner und Frauen umfassen.\nWandeln Sie die die Variable f√ºr Geschlecht in eine bin√§re Variable - also Werte mit 0 und 1 - um.\nAlle Daten (und weitere Informationen) zum Projekt sind hier abgelegt.\nEine Beschreibung der Variablen der Studie finden Sie hier.\nDas Codebook findet sich hier.\nDer Datensatz ist recht gro√ü (ca. 150 MB).\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nBerechnen Sie 89%-PIs, wenn Sie Ungewissheit quantifizieren.\n\nAntwortoptionen\n\n\n\nJa\nNein\nDie Daten sind nicht konkludent; es ist keine Entscheidung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Entscheidung m√∂glich."
  },
  {
    "objectID": "posts/rope3/rope3.html#answerlist",
    "href": "posts/rope3/rope3.html#answerlist",
    "title": "rope3",
    "section": "",
    "text": "Ja\nNein\nDie Daten sind nicht konkludent; es ist keine Entscheidung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Entscheidung m√∂glich."
  },
  {
    "objectID": "posts/rope3/rope3.html#answerlist-1",
    "href": "posts/rope3/rope3.html#answerlist-1",
    "title": "rope3",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr. ROPE ist zu verwerfen, damit sind Werte um die Null herum nicht wahrscheinlich.\nFalsch\nFalsch\n\n\nCategories:\n\nrope\nbayes"
  },
  {
    "objectID": "posts/tidymodels-lasso/tidymodels-lasso.html",
    "href": "posts/tidymodels-lasso/tidymodels-lasso.html",
    "title": "tidymodels-lasso",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse f√ºr ein Vorhersagemodell mit dem Lasso.\nHinweise:\n\nTunen Sie die Penalisierung.\nVerwenden Sie Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ .\n\n         \n\n\nL√∂sung\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellg√ºte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\nMan beachte: F√ºr regulierte Modelle sind Zentrierung und Skalierung n√∂tig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nstring\ntemplate"
  },
  {
    "objectID": "posts/Schiefe-erkennen/Schiefe-erkennen.html",
    "href": "posts/Schiefe-erkennen/Schiefe-erkennen.html",
    "title": "Schiefe-erkennen",
    "section": "",
    "text": "W√§hlen Sie das Histogramm, welches am deutlichsten die Eigenschaft ‚Äúlinksschief‚Äù aufweist!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE"
  },
  {
    "objectID": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist",
    "href": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist",
    "title": "Schiefe-erkennen",
    "section": "",
    "text": "A\nB\nC\nD\nE"
  },
  {
    "objectID": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist-1",
    "href": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist-1",
    "title": "Schiefe-erkennen",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\neda\ndistributions\nschoice"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html",
    "href": "posts/saratoga-cor2/saratoga-cor2.html",
    "title": "saratoga-cor2",
    "section": "",
    "text": "Importieren Sie den Datensatz saratoga.\nBerechnen Sie dann den Zusammenhang zwischen price und livingArea pro Stufe von bedrooms.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks."
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#setup",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#setup",
    "title": "saratoga-cor2",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#gruppieren",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#gruppieren",
    "title": "saratoga-cor2",
    "section": "Gruppieren",
    "text": "Gruppieren\n\nd2 &lt;-\n  SaratogaHouses |&gt; \n  group_by(bedrooms)"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#statistiken",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#statistiken",
    "title": "saratoga-cor2",
    "section": "Statistiken",
    "text": "Statistiken\n\nd2 |&gt; \n  summarise(korrelation = cor(livingArea, price))\n\n\n\n\n\nbedrooms\nkorrelation\n\n\n\n\n1\n0.1145486\n\n\n2\n0.5097218\n\n\n3\n0.6358629\n\n\n4\n0.6872350\n\n\n5\n0.7214769\n\n\n6\n0.8818375\n\n\n7\n0.7905541"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#visualisierung",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#visualisierung",
    "title": "saratoga-cor2",
    "section": "Visualisierung",
    "text": "Visualisierung\n\nggscatter(d2, \n          x = \"livingArea\",\n          y = \"price\",\n          facet.by = \"bedrooms\",\n          add = \"reg.line\")"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html",
    "href": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html",
    "title": "Verteilungen-Quiz-14",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nBeim Perzentilintervall (PI) werden ‚Äúlinks‚Äù und ‚Äúrechts‚Äù die gleiche Wahrscheinlichkeitsmasse von einer Verteilung ‚Äúabgeschnitten‚Äù.\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist",
    "href": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist",
    "title": "Verteilungen-Quiz-14",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist-1",
    "title": "Verteilungen-Quiz-14",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/rethink3m2/rethink3m2.html",
    "href": "posts/rethink3m2/rethink3m2.html",
    "title": "rethink3m2",
    "section": "",
    "text": "Exercise\nNehmen wir an, wir haben 8 (Wasser-)‚ÄúTreffer‚Äù (\\(W=8\\)) bei 15 W√ºrfen (\\(N=15\\)) erhalten (wieder im Globusversuch).\n\nZiehen Sie \\(10^4\\) Stichproben aus der Posteriori-Verteilung basierend auf der Bayesbox-Methode. Gehen Sie von einer gleichverteilung Priori-Wahrscheinlichkeit aus.\nVisualisieren Sie die Verteilung der Stichproben.\nBerechnen Sie ds 90%-HDI.\n\nHinweise:\n\nBerechnen Sie eine Bayes-Box (Gittermethode).\nVerwenden Sie 1000 Gitterwerte.\nFixieren Sie die Zufallszahlen mit dem Startwert 42, d.h. set.seed(42).\nGehen Sie von einem gleichverteilten Prior aus.\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\n\n\n\nPost-Verteilung berechnen:\n\np_grid &lt;- seq(from = 0, to = 1, length.out = 1000)\nprior &lt;- rep(1, 1000)\nlikelihood &lt;- dbinom(8, size = 15, prob = p_grid)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\nStichproben-Postverteilung erstellen:\n\nsamples &lt;- \n  tibble(anteil_wasser = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE))\n\nhead(samples)\n\n\n\n\n\nanteil_wasser\n\n\n\n\n0.6666667\n\n\n0.5135135\n\n\n0.4034034\n\n\n0.6656657\n\n\n0.4694695\n\n\n0.6086086\n\n\n\n\n\n\n\n\n\n\nsamples %&gt;% \n  ggplot() +\n  aes(x = anteil_wasser) +\n  geom_histogram() + \n  labs(title = \"Stichproben aus der Posteriori-Verteilung\")\n\n\n\n\n\n\n\n\nOder so:\n\nlibrary(ggpubr)\n\ngghistogram(samples, x = \"anteil_wasser\", bins = 30, \n            title = \"Stichproben aus der Posteriori-Verteilung\")\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(easystats)\nhdi(samples, prob = 0.9)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\nanteil_wasser\n0.95\n0.3043043\n0.7557558\n\n\n\n\n\n\n\nCategories:\n\nbayes\npost\nprobability"
  },
  {
    "objectID": "posts/regex01/regex01.html",
    "href": "posts/regex01/regex01.html",
    "title": "regex01",
    "section": "",
    "text": "Aufgabe\nErstellen Sie einen Vektor mit den Namen aller CSV-Dateien eines beliebigen Ordners Ihres Computers.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nEinen Order ausw√§hlen:\nDateien als Strings einlesen:\n\n\ncharacter(0)\n\n\nDateien als Strings einlesen:\n\n\ncharacter(0)\n\n\nNur CSV-Dateien einlesen:\n\n\ncharacter(0)\n\n\n\nCategories:\n\ntextmining\nregex\nstring"
  },
  {
    "objectID": "posts/ReThink3m5/ReThink3m5.html",
    "href": "posts/ReThink3m5/ReThink3m5.html",
    "title": "ReThink3m5",
    "section": "",
    "text": "Aufgabe\nNehmen wir an, wir haben 8 (Wasser-)‚ÄúTreffer‚Äù (\\(W=8\\)) bei 15 W√ºrfen (\\(N=15\\)) erhalten (wieder im Globusversuch).\nNehmen Sie dieses Mal keine gleichverteilte Priori-Verteilung an. Stattdessen verwenden Sie einen Priori-Wert von Null solange \\(p &lt; 0.5\\) und einen konstanten Wert f√ºr \\(p \\ge 0.5\\). Diese Priori-Verteilung kodiert die Information, dass mindestens die H√§lfte der Erdoberfl√§che mit Sicherheit aus Wasser besteht.\nF√ºr alle folgenden Berechnungen, vergleichen Sie Ihre Ergebnisse zu der analogen Analyse mit einem konstanten (gleichverteilten) Priori-Wert!\n\nBerechnen Sie die Posteriori-Verteilung und visualisieren Sie sie. Nutzen Sie die Gittermethode.\nZiehen Sie \\(10^4\\) Stichproben aus der Posteriori-Verteilung, die Sie mit der Gittermethode erhalten haben. Berechnen Sie auf dieser Grundlage das 90%-HDI.\nBerechnen Sie die PPV f√ºr dieses Modell. Was ist die Wahrscheinlichkeit 8 von 15 Treffer zu erzielen laut dieser PPV?\nAuf Basis der aktuellen Posteriori-Wahrscheinlichkeit: Was ist die Wahrscheinlichkeit f√ºr 6 Wasser bei 9 W√ºrfen?\n\nHinweise:\n\nBerechnen Sie eine Bayes-Box (Gittermethode).\nVerwenden Sie 1000 Gitterwerte.\nFixieren Sie die Zufallszahlen mit dem Startwert 42, d.h. set.seed(42).\nGehen Sie von einem gleichverteilten Prior aus.\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n         \n\n\nL√∂sung\n\nBerechnen Sie die Posteriori-Verteilung und visualisieren Sie sie. Nutzen Sie die Gittermethode.\n\n\nset.seed(42)\np_grid &lt;- seq(from = 0, to = 1, length.out = 1000)\nprior &lt;- case_when(\n  p_grid &lt;  0.5 ~ 0,\n  p_grid &gt;= 0.5 ~ 1)\nlikelihood &lt;- dbinom(8, size = 15, prob = p_grid)\nunstand_posterior &lt;- likelihood * prior\nposterior &lt;- unstand_posterior / sum(unstand_posterior)\n\n\ntibble(p = p_grid, \n       posterior = posterior) %&gt;%\n  ggplot(aes(x = p, y = posterior)) +\n # geom_point() +\n  geom_line() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\n\n\n\n\n\n\n\n\nAlternativ k√∂nnen Sie mit ggpubr::ggline() visualisieren.\n\nZiehen Sie \\(10^4\\) Stichproben aus der Posteriori-Verteilung, die Sie mit der Gittermethode erhalten haben. Berechnen Sie auf dieser Grundlage das 90%-HDI.\n\n\nlibrary(easystats)\n# Stichproben (samples) aus der Posteriori-Verteilung:\nsamples &lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\nhdi(samples, prob = 0.9)\n\n\n\n\n\nCI\nCI_low\nCI_high\n\n\n\n\n0.95\n0.5005005\n0.7467467\n\n\n\n\n\n\n\nBerechnen Sie die PPV f√ºr dieses Modell. Was ist die Wahrscheinlichkeit 8 von 15 Treffer zu erzielen laut dieser PPV?\n\n\nPPV &lt;-\n  tibble(w = rbinom(1e4, size = 15, prob = samples))  # w wie Wasser\n\nPPV %&gt;% \n  count(w == 8) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n\n\nw == 8\nn\nprop\n\n\n\n\nFALSE\n8508\n0.8508\n\n\nTRUE\n1492\n0.1492\n\n\n\n\n\n\n\nAuf Basis der aktuellen Posteriori-Wahrscheinlichkeit: Was ist die Wahrscheinlichkeit f√ºr 6 Wasser bei 9 W√ºrfen?\n\n\nPPV &lt;-\n  PPV %&gt;% \n  mutate(w2 = rbinom(1e4, size = 9, prob = samples))\n\nPPV %&gt;% \n  count(w2 == 6) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n\n\nw2 == 6\nn\nprop\n\n\n\n\nFALSE\n7738\n0.7738\n\n\nTRUE\n2262\n0.2262\n\n\n\n\n\n\n\nCategories:\n\nbayes\nppv\nprobability\nstring"
  },
  {
    "objectID": "posts/korr-ungewiss/index.html",
    "href": "posts/korr-ungewiss/index.html",
    "title": "korr-ungewiss",
    "section": "",
    "text": "Aufgabe\n\nDas Berechnen der Korrelation zweier Variablen in einer Stichprobe erfolgt unter Ungewissheit.\nDas Berechnen des Mittelwerts in einer Stichprobe erfolgt unter Ungewissheit.\nDas Berechnen des Mittelwerts in einer Population erfolgt unter Ungewissheit.\nAlle obigen Aussagen erfolgen unter Ungewissheit.\nKeine Aussage zur Ungewissheit m√∂glich.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\nL√∂sung\n\nDas Berechnen des Mittelwerts in einer Population erfolgt unter Ungewissheit."
  },
  {
    "objectID": "posts/penguins-weight/index.html",
    "href": "posts/penguins-weight/index.html",
    "title": "penguins-weight",
    "section": "",
    "text": "Aufgabe\nIm Datensatz penguins: Berichten Sie die Breite eines Sch√§tzintervalls (89%, HDI) zum mittleren K√∂rpergewicht! Nutzen Sie Methoden der Bayes-Statistik.\nHinweise\nDazu sei folgendes Modell gegeben.\nSetup:\n\ndata(penguins, package = \"palmerpenguins\")\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(ggpubr)\n\nModell berechnen:\n\nm1 &lt;- stan_glm(body_mass_g ~ 1, \n               data = penguins,\n               seed = 42,\n               refresh = 0)\n\nDann gibt es verschiedene Einstellungen f√ºr die Funktion parameters():\n\nparameters(m1, ci = .89, ci_method = \"hdi\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n4200.435\n0.89\n4132.086\n4267.711\n1\n0.9998942\n2730.613\nnormal\n4201.754\n2004.886\n\n\n\n\n\n\nIm Standard wird ein 95%-ETI berichtet:\n\nparameters(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n4200.435\n0.95\n4117.553\n4287.093\n1\n0.9998942\n2730.613\nnormal\n4201.754\n2004.886\n\n\n\n\n\n\n\nplot(parameters(m1), show_intercept = TRUE)\n\n\n\n\n\n\n\n\n         \n\n\nL√∂sung\nIm Standard wird ein 95%-Perzentilintervall berechnet, s. die Dokumentation zur Funktion hier.\nDaher m√ºssen wir explizit das 89%-HDI anfordern.\nDie L√∂sung ist also aus der Tabelle oben ablesbar als Differenz der Gr√∂√üen des Sch√§tzbereichs (Konfidenzintervalls, CI).\n\n\n[1] 135.6241\n\n\n\nCategories:\n\nbayes\npost\nestimation\nexam-22"
  },
  {
    "objectID": "posts/korr01/korr01.html",
    "href": "posts/korr01/korr01.html",
    "title": "korr01",
    "section": "",
    "text": "Welcher Korrelationswert (Pearson) beschreibt die Korrelation in den Daten am besten?\n\n\n\n\\(r = 1\\)\n\\(r = -1\\)\n\\(r = 0\\)\n\\(r = .8\\)\n\\(r = -.8\\)"
  },
  {
    "objectID": "posts/korr01/korr01.html#answerlist",
    "href": "posts/korr01/korr01.html#answerlist",
    "title": "korr01",
    "section": "",
    "text": "\\(r = 1\\)\n\\(r = -1\\)\n\\(r = 0\\)\n\\(r = .8\\)\n\\(r = -.8\\)"
  },
  {
    "objectID": "posts/korr01/korr01.html#answerlist-1",
    "href": "posts/korr01/korr01.html#answerlist-1",
    "title": "korr01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\ndyn\neda\nassociation\nschoice"
  },
  {
    "objectID": "posts/hintertuer/hintertuer.html",
    "href": "posts/hintertuer/hintertuer.html",
    "title": "hintertuer",
    "section": "",
    "text": "Aufgabe\nWir wollen hier den (kausalen) Einfluss der Eltern E und Gro√üeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von Gro√üeltern auf ihre Enkel, s. Figure¬†1, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\n\nFigure¬†1: Der kausale Effekt von Gro√üeltern auf Enkel hinsichtlich Bildung.\n\n\n\n\n\nAufgabe: Geben Sie das minimale Adjustierungsset an, um den direkten kausalen Effekt von G auf K zu identifizieren.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\n\n         \n\n\nL√∂sung\nEs ist keine Adjustierung n√∂tig, um nicht-kausale Pfade zu schlie√üen. Alle nicht-kausalen Pfade sind bereits geschlossen.\nIst man am direkten Effekt von G auf K interessiert, so muss man folgende Variablen kontrollieren:\n\nE und U (beide)\n\nFalls man U nicht kontrollieren kann (was der Namen U andeutet), so ist der gesuchte kausale Effekt nicht idenfizierbar."
  },
  {
    "objectID": "posts/kung-height2/index.html",
    "href": "posts/kung-height2/index.html",
    "title": "kung-height2",
    "section": "",
    "text": "Exercise\nBetrachten Sie den Datensatz zur Gr√∂√üe der !Kung:\n\nlibrary(tidyverse)\nurl_kung &lt;- \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv\"\nd &lt;-\n  read_delim(url_kung, delim = \";\")  # Strichpunkt als Trennzeichen in der CSV-Datei\n\nDie Verteilung der Gr√∂√üe von Frauen und M√§nner in der Gruppe der Erwachsenen ist wie folgt:\n\n#|echo: false\n#|\nd2 &lt;- d %&gt;% \n  filter(age &gt;= 18)\n\n# d3 &lt;- d2 %&gt;% \n#   select(-male)\n\nggplot(d2, aes(x = height)) +\n  geom_density()\n\n\n\n\n\n\n\nggplot(d2, aes(x = height )) +\n  facet_wrap(~ male) +\n    geom_density()\n\n\n\n\n\n\n\n# ggplot(d2, aes(x = height)) +\n#   facet_wrap(~ male) +\n#   geom_histogram(data = d3, fill = \"grey60\", alpha = .6) +\n#     geom_histogram() +\n#   labs(caption = \"Grau hinterlegt ist das Histogramm f√ºr die Daten √ºber beide Geschlechter\")\n\nAufgabe\n\nIst die Gr√∂√üe der erwachsenen Personen normalverteilt?\nWelche Schiefe und welche Kurtosis weist die Normalverteilung auf?\nDiskutieren Sie, inwieweit man aus biologisch fundierten Sachverhalten (also ontologisch) eine Normalverteilung der K√∂rpergr√∂√üe annehmen kann.\n\n         \n\n\nSolution\n\nNormalverteilung\n\nJa, die Verteilungen sind beide einigerma√üen normalverteilt.\n\nSchiefe und Kurtosis\n\nEine Normalverteilung hat eine Schiefe von 0 und eine Kurtosis von 3.\n\nNormalverteilung, Begr√ºndung\n\nEs ist plausibel anzunehmen, dass der Ph√§notyp K√∂rpergr√∂√üe das Resultat des (kausalen) Einflusses vieler Gene ist, vieler Gene, die √ºber einen vergleichbar starken Einfluss verf√ºgen.\nEine besondere Situation stellt das X- bzw. Y-Chromosom dar, das Gene zum Geschlecht bereitstellt. Das Geschlecht ist ein einzelner Faktor, der (erfahrungsgem√§√ü) einen relativ gro√üen Einfluss auf die K√∂rpergr√∂√üe hat (in Anbetracht, dass vielleicht Tausende Gene additiv die Gr√∂√üe bestimmen). Insofern ist eine klarere Ann√§herung an die Normalverteilung zu erwarten, wenn man die Geschlechter einzeln betrachtet."
  },
  {
    "objectID": "posts/wrangle3/wrangle3.html",
    "href": "posts/wrangle3/wrangle3.html",
    "title": "wrangle3",
    "section": "",
    "text": "Welche Aussage zu der Funktionsweise folgender Funktionen im R-Paket dplyr ist richtig?\n\nfilter\nselect\nsummarise\ncount\ngroup_by\n\n\n\n\nDas erste Argument darf nie ein Dataframe sein.\nDas erste Argument ist immer die zu analysierende Variable.\nSpaltennamen m√ºssen mit Anf√ºhrungsstrichen benannt werden.\nEs wird immer eine Tabelle ausgegeben.\nFunktionsnamen sind (zumeist) nicht als Verben formuliert."
  },
  {
    "objectID": "posts/wrangle3/wrangle3.html#answerlist",
    "href": "posts/wrangle3/wrangle3.html#answerlist",
    "title": "wrangle3",
    "section": "",
    "text": "Das erste Argument darf nie ein Dataframe sein.\nDas erste Argument ist immer die zu analysierende Variable.\nSpaltennamen m√ºssen mit Anf√ºhrungsstrichen benannt werden.\nEs wird immer eine Tabelle ausgegeben.\nFunktionsnamen sind (zumeist) nicht als Verben formuliert."
  },
  {
    "objectID": "posts/wrangle3/wrangle3.html#answerlist-1",
    "href": "posts/wrangle3/wrangle3.html#answerlist-1",
    "title": "wrangle3",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\ndatawrangling\neda\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html",
    "href": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html",
    "title": "Verteilungen-Quiz-15",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nDas HDI (Highest-Density-Intervall) schneidet auf beiden Seiten des Intervalls die gleiche Wahrscheinlichkeitsmasse ab.\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist",
    "href": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist",
    "title": "Verteilungen-Quiz-15",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist-1",
    "title": "Verteilungen-Quiz-15",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/randomdag1/randomdag1.html",
    "href": "posts/randomdag1/randomdag1.html",
    "title": "randomdag1",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber \\(n = 6\\) Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x4.\nAV: x6.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x1, x2} meint die Menge mit den zwei Elementen x1 und x2.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äú/‚Äù.\nEs ist m√∂glich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben. Diese Variablen sind dann kausal unabh√§ngig von den √ºbrigen Variablen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x4, x5 }\n{ x2, x3 }\n{ x6 }\n/\n{ x1 }"
  },
  {
    "objectID": "posts/randomdag1/randomdag1.html#answerlist",
    "href": "posts/randomdag1/randomdag1.html#answerlist",
    "title": "randomdag1",
    "section": "",
    "text": "{ x4, x5 }\n{ x2, x3 }\n{ x6 }\n/\n{ x1 }"
  },
  {
    "objectID": "posts/randomdag1/randomdag1.html#answerlist-1",
    "href": "posts/randomdag1/randomdag1.html#answerlist-1",
    "title": "randomdag1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ncausal\ndag"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html",
    "href": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html",
    "title": "Verteilungen-Quiz-12",
    "section": "",
    "text": "Ist folgende Aussage \\(A\\) wahr?\nBei einer symmetrischen unimodalen Verteilung gilt: \\(\\bar{x} = Md = \\text{Modus}\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html#answerlist",
    "href": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html#answerlist",
    "title": "Verteilungen-Quiz-12",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/wskt-quiz07/wskt-quiz07.html",
    "href": "posts/wskt-quiz07/wskt-quiz07.html",
    "title": "wskt-quiz07",
    "section": "",
    "text": "Folgende Formel ist korrekt: \\(Pr(H|D) = Pr(D|H) \\cdot Pr(H)\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz07/wskt-quiz07.html#answerlist",
    "href": "posts/wskt-quiz07/wskt-quiz07.html#answerlist",
    "title": "wskt-quiz07",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz07/wskt-quiz07.html#answerlist-1",
    "href": "posts/wskt-quiz07/wskt-quiz07.html#answerlist-1",
    "title": "wskt-quiz07",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/mariokart-desk01/mariokart-desk01.html",
    "href": "posts/mariokart-desk01/mariokart-desk01.html",
    "title": "mariokart-desk01",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nNutzen Sie describe_distribution um deskriptive Statistiken (Lagema√üe, Streuungsma√üe) f√ºr die Variable total_pr zu berechnen.\nWie viele Statistiken werden (im Default) berichtet?\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nDaten zusammenfassen zu deskriptiven Statistiken:\nMit dataExplorer:\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\ntotal_pr\n49.88049\n25.68856\n12.99\n28.98\n326.51\n9.035897\n96.14414\n143\n0\n\n\n\n\n\n\nFalls Sie Teile der R-Syntax nicht kennen: Im Zweifel einfach ignorieren :-)\nAntwort: Es werden 8 Statistiken berichtet (im Default).\n\nCategories:\n\ndatawrangling\neda\ntidyverse\nvis\nvariability\nnum"
  },
  {
    "objectID": "posts/rf-finalize3/rf-finalize3.html",
    "href": "posts/rf-finalize3/rf-finalize3.html",
    "title": "rf-finalize3",
    "section": "",
    "text": "Berechnen Sie ein pr√§diktives Modell (Random Forest) mit dieser Modellgleichung:\nbody_mass_g ~ . (Datensatz: palmerpenguins::penguins).\nZeigen Sie, welche Werte f√ºr mtry im Default von Tidymodels gesetzt werden!\nHinweise: - Tunen Sie alle Tuningparameter mit jeweils 3 Werten. - Verwenden Sie Kreuzvalidierung - Verwenden Sie Standardwerte, wo nicht anders angegeben. - Fixieren Sie Zufallszahlen auf den Startwert 42."
  },
  {
    "objectID": "posts/rf-finalize3/rf-finalize3.html#standard-start",
    "href": "posts/rf-finalize3/rf-finalize3.html#standard-start",
    "title": "rf-finalize3",
    "section": "Standard-Start",
    "text": "Standard-Start\nZuererst der Standardablauf:\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nset.seed(42)\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# rm NA in the dependent variable:\nd &lt;- d %&gt;% \n  drop_na(body_mass_g)\n\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_rf &lt;-\n  rand_forest(mode = \"regression\",\n           mtry = tune(),\n           min_n = tune(),\n           trees = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_rf) %&gt;% \n  add_recipe(rec_plain)"
  },
  {
    "objectID": "posts/rf-finalize3/rf-finalize3.html#tuninggrid",
    "href": "posts/rf-finalize3/rf-finalize3.html#tuninggrid",
    "title": "rf-finalize3",
    "section": "Tuninggrid",
    "text": "Tuninggrid\nWelche Tuningparameter hat unser Workflow?\n\nwf1_params_unclear &lt;- \n  extract_parameter_set_dials(wf1)\nwf1_params_unclear\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nid\nsource\ncomponent\ncomponent_id\nobject\n\n\n\n\nmtry\nmtry\nmodel_spec\nrand_forest\nmain\ninteger, 1, unknown(), TRUE, TRUE, # Randomly Selected Predictors, function (object, x, log_vals = FALSE, ‚Ä¶) , {, check_param(object), rngs &lt;- range_get(object, original = FALSE), if (!is_unknown(rngs\\(upper)) {,         return(object),     },     x_dims &lt;- dim(x),     if (is.null(x_dims)) {,         cli::cli_abort(\"Cannot determine number of columns. Is {.arg x} a 2D data object?\"),     },     if (log_vals) {,         rngs[2] &lt;- log10(x_dims[2]),     },     else {,         rngs[2] &lt;- x_dims[2],     },     if (object\\)type == ‚Äúinteger‚Äù & is.null(object\\(trans)) {,         rngs &lt;- as.integer(rngs),     },     range_set(object, rngs), }                                      |\n|trees |trees |model_spec |rand_forest |main         |integer, 1      , 2000   , TRUE   , TRUE   , # Trees                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|min_n |min_n |model_spec |rand_forest |main         |integer, 2, 40, TRUE, TRUE, Minimal Node Size, function (object, x, log_vals = FALSE, frac = 1/3, ...) , {,     check_param(object),     rngs &lt;- range_get(object, original = FALSE),     if (!is_unknown(rngs\\)upper)) {, return(object), }, x_dims &lt;- dim(x), if (is.null(x_dims)) {, cli::cli_abort(‚ÄúCannot determine number of columns. Is {.arg x} a 2D data object?‚Äù), }, n_frac &lt;- floor(x_dims[1] * frac), if (log_vals) {, rngs[2] &lt;- log10(n_frac), }, else {, rngs[2] &lt;- n_frac, }, if (object\\(type == \"integer\" & is.null(object\\)trans) & !log_vals) {, rngs &lt;- as.integer(rngs), }, range_set(object, rngs), }\n\n\n\n\n\n\nVerlangt waren 3 Tuningparameterwerte pro Parameter:\n\nmy_grid &lt;- grid_latin_hypercube(wf1_params_unclear, levels = 3)\n\nError in `grid_latin_hypercube()`:\n! `levels` is not an argument to `grid_latin_hypercube()`.\n‚Ñπ Did you mean `size`?\n\nmy_grid\n\nError: object 'my_grid' not found\n\n\nTidymodels wei√ü nicht, welche Werte f√ºr mtry benutzt werden sollen, da dieser Wert abh√§ngig ist von der Anzahl der Spalten des Datensatzes, und damit unabh√§ngig vom Modell.\nDie Ausgabe nparam[?] oben sagt uns, dass Tidymodels den Wertebereich des Tuningparameter nicht kl√§ren k√∂nnte, da er Daten abh√§ngig ist.\nInformieren wir also Tidymodels zu diesem Wertebereich:\n\nwf1_params &lt;- \n  wf1 %&gt;% \n  extract_parameter_set_dials() %&gt;% \n  update(mtry = finalize(mtry(), d_train))\n\nwf1_params\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nid\nsource\ncomponent\ncomponent_id\nobject\n\n\n\n\nmtry\nmtry\nmodel_spec\nrand_forest\nmain\ninteger , 1 , 9 , TRUE , TRUE , # Randomly Selected Predictors\n\n\ntrees\ntrees\nmodel_spec\nrand_forest\nmain\ninteger, 1 , 2000 , TRUE , TRUE , # Trees\n\n\nmin_n\nmin_n\nmodel_spec\nrand_forest\nmain\ninteger, 2, 40, TRUE, TRUE, Minimal Node Size, function (object, x, log_vals = FALSE, frac = 1/3, ‚Ä¶) , {, check_param(object), rngs &lt;- range_get(object, original = FALSE), if (!is_unknown(rngs\\(upper)) {,         return(object),     },     x_dims &lt;- dim(x),     if (is.null(x_dims)) {,         cli::cli_abort(\"Cannot determine number of columns. Is {.arg x} a 2D data object?\"),     },     n_frac &lt;- floor(x_dims[1] * frac),     if (log_vals) {,         rngs[2] &lt;- log10(n_frac),     },     else {,         rngs[2] &lt;- n_frac,     },     if (object\\)type == ‚Äúinteger‚Äù & is.null(object$trans) & !log_vals) {, rngs &lt;- as.integer(rngs), }, range_set(object, rngs), }\n\n\n\n\n\n\nSo, jetzt wei√ü Tidymodels, wie viele Werte f√ºr mtry benutzt werden k√∂nnen.\nWir k√∂nnen jetzt das Tuninggitter erstellen (das macht das Paket dials):\n\nmy_grid &lt;- grid_latin_hypercube(wf1_params, size = 125)\nmy_grid %&gt;% head()\n\n\n\n\n\nmtry\ntrees\nmin_n\n\n\n\n\n1\n105\n11\n\n\n5\n1036\n21\n\n\n3\n325\n16\n\n\n4\n1375\n28\n\n\n6\n1405\n21\n\n\n7\n304\n15\n\n\n\n\n\n\nWie viele verschiedene Werte gibt es in dem Tuningitter?\nSchauen wir es uns mal an.\n\nmy_grid %&gt;% \n  ggplot(aes(x = trees, y = mtry)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWir k√∂nnen das Tuninggitter auch selber erstellen:\n\nmy_grid &lt;-\n  grid_latin_hypercube(mtry(range = c(1, ncol(d_train)-1)),\n                       trees(),\n                       min_n(),\n                       size = 60)\ndim(my_grid)\n\n[1] 60  3"
  },
  {
    "objectID": "posts/rf-finalize3/rf-finalize3.html#tuningfitting",
    "href": "posts/rf-finalize3/rf-finalize3.html#tuningfitting",
    "title": "rf-finalize3",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    grid = my_grid,\n    resamples = rsmpl)\ntoc()\n\n135.811 sec elapsed\n\n\nDann schauen wir uns das Ergebnisobjekt vom Tuning an.\n\nwf1_fit %&gt;% \n  collect_metrics() %&gt;% \n  filter(.metric == \"rmse\") %&gt;% \n  arrange(mtry)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmtry\ntrees\nmin_n\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n1\n510\n29\nrmse\nstandard\n327.0506\n10\n14.102972\npre0_mod01_post0\n\n\n1\n826\n3\nrmse\nstandard\n310.0977\n10\n13.017354\npre0_mod02_post0\n\n\n1\n1742\n14\nrmse\nstandard\n315.6416\n10\n13.105640\npre0_mod03_post0\n\n\n1\n1835\n33\nrmse\nstandard\n332.4336\n10\n13.724682\npre0_mod04_post0\n\n\n2\n51\n37\nrmse\nstandard\n298.2026\n10\n11.349008\npre0_mod05_post0\n\n\n2\n81\n29\nrmse\nstandard\n292.0088\n10\n12.269233\npre0_mod06_post0\n\n\n2\n147\n22\nrmse\nstandard\n287.0004\n10\n10.698344\npre0_mod07_post0\n\n\n2\n359\n6\nrmse\nstandard\n282.6882\n10\n11.064381\npre0_mod08_post0\n\n\n2\n386\n23\nrmse\nstandard\n288.0263\n10\n11.926175\npre0_mod09_post0\n\n\n2\n672\n15\nrmse\nstandard\n283.0290\n10\n11.154272\npre0_mod10_post0\n\n\n2\n782\n9\nrmse\nstandard\n282.1710\n10\n10.670844\npre0_mod11_post0\n\n\n2\n1590\n35\nrmse\nstandard\n295.8688\n10\n12.409382\npre0_mod12_post0\n\n\n2\n1927\n7\nrmse\nstandard\n282.5915\n10\n11.442756\npre0_mod13_post0\n\n\n3\n641\n8\nrmse\nstandard\n281.3474\n10\n10.738309\npre0_mod14_post0\n\n\n3\n747\n24\nrmse\nstandard\n282.9493\n10\n11.059727\npre0_mod15_post0\n\n\n3\n1093\n36\nrmse\nstandard\n289.0472\n10\n11.810703\npre0_mod16_post0\n\n\n3\n1219\n3\nrmse\nstandard\n282.7862\n10\n11.065238\npre0_mod17_post0\n\n\n3\n1408\n13\nrmse\nstandard\n280.9360\n10\n10.869681\npre0_mod18_post0\n\n\n3\n1697\n36\nrmse\nstandard\n288.2570\n10\n11.634923\npre0_mod19_post0\n\n\n3\n1889\n4\nrmse\nstandard\n282.0771\n10\n10.655292\npre0_mod20_post0\n\n\n3\n1967\n39\nrmse\nstandard\n290.0862\n10\n11.890039\npre0_mod21_post0\n\n\n4\n261\n31\nrmse\nstandard\n285.9761\n10\n10.342291\npre0_mod22_post0\n\n\n4\n292\n24\nrmse\nstandard\n283.3860\n10\n10.744992\npre0_mod23_post0\n\n\n4\n330\n21\nrmse\nstandard\n282.0808\n10\n10.291713\npre0_mod24_post0\n\n\n4\n458\n18\nrmse\nstandard\n281.6246\n10\n9.928690\npre0_mod25_post0\n\n\n4\n709\n14\nrmse\nstandard\n280.7476\n10\n9.676739\npre0_mod26_post0\n\n\n4\n1062\n35\nrmse\nstandard\n286.0341\n10\n11.135346\npre0_mod27_post0\n\n\n4\n1360\n8\nrmse\nstandard\n282.1273\n10\n10.147874\npre0_mod28_post0\n\n\n4\n1543\n25\nrmse\nstandard\n281.9846\n10\n10.757734\npre0_mod29_post0\n\n\n4\n1617\n12\nrmse\nstandard\n280.4863\n10\n10.414125\npre0_mod30_post0\n\n\n5\n588\n34\nrmse\nstandard\n284.0172\n10\n10.505647\npre0_mod31_post0\n\n\n5\n900\n38\nrmse\nstandard\n285.5616\n10\n10.776293\npre0_mod32_post0\n\n\n5\n909\n12\nrmse\nstandard\n281.1531\n10\n10.183557\npre0_mod33_post0\n\n\n5\n1029\n30\nrmse\nstandard\n283.3368\n10\n10.506628\npre0_mod34_post0\n\n\n5\n1274\n19\nrmse\nstandard\n280.4960\n10\n10.069676\npre0_mod35_post0\n\n\n5\n1322\n16\nrmse\nstandard\n280.5548\n10\n10.308200\npre0_mod36_post0\n\n\n5\n1444\n39\nrmse\nstandard\n285.4752\n10\n10.843783\npre0_mod37_post0\n\n\n5\n1655\n26\nrmse\nstandard\n281.1615\n10\n10.492565\npre0_mod38_post0\n\n\n5\n1994\n11\nrmse\nstandard\n281.3936\n10\n10.143697\npre0_mod39_post0\n\n\n6\n481\n2\nrmse\nstandard\n284.1143\n10\n10.174460\npre0_mod40_post0\n\n\n6\n629\n27\nrmse\nstandard\n281.5415\n10\n10.115595\npre0_mod41_post0\n\n\n6\n858\n32\nrmse\nstandard\n282.5570\n10\n10.631752\npre0_mod42_post0\n\n\n6\n996\n17\nrmse\nstandard\n280.9367\n10\n9.847399\npre0_mod43_post0\n\n\n6\n1155\n31\nrmse\nstandard\n282.1929\n10\n10.186091\npre0_mod44_post0\n\n\n6\n1178\n39\nrmse\nstandard\n284.8779\n10\n10.436088\npre0_mod45_post0\n\n\n6\n1375\n10\nrmse\nstandard\n282.1038\n10\n10.032399\npre0_mod46_post0\n\n\n6\n1532\n20\nrmse\nstandard\n280.5911\n10\n10.113653\npre0_mod47_post0\n\n\n7\n7\n20\nrmse\nstandard\n295.2057\n10\n7.571570\npre0_mod48_post0\n\n\n7\n104\n17\nrmse\nstandard\n280.6154\n10\n10.137987\npre0_mod49_post0\n\n\n7\n422\n27\nrmse\nstandard\n280.7607\n10\n10.022320\npre0_mod50_post0\n\n\n7\n546\n11\nrmse\nstandard\n280.1788\n10\n10.373537\npre0_mod51_post0\n\n\n7\n953\n23\nrmse\nstandard\n280.3642\n10\n9.769144\npre0_mod52_post0\n\n\n7\n1111\n29\nrmse\nstandard\n280.3470\n10\n10.131759\npre0_mod53_post0\n\n\n7\n1254\n26\nrmse\nstandard\n280.9250\n10\n9.864827\npre0_mod54_post0\n\n\n7\n1713\n6\nrmse\nstandard\n283.5527\n10\n10.192602\npre0_mod55_post0\n\n\n7\n1787\n33\nrmse\nstandard\n281.5877\n10\n10.133599\npre0_mod56_post0\n\n\n8\n185\n20\nrmse\nstandard\n279.5526\n10\n9.209935\npre0_mod57_post0\n\n\n8\n213\n9\nrmse\nstandard\n281.9499\n10\n10.313192\npre0_mod58_post0\n\n\n8\n1479\n5\nrmse\nstandard\n283.1197\n10\n10.354868\npre0_mod59_post0\n\n\n8\n1821\n16\nrmse\nstandard\n279.8859\n10\n9.900455\npre0_mod60_post0\n\n\n\n\n\n\nIn der Hilfe ist zu lesen:\n\nIn some cases, the tuning parameter values depend on the dimensions of the data. For example, mtry in random forest models depends on the number of predictors. In this case, the default tuning parameter object requires an upper range. dials::finalize() can be used to derive the data-dependent parameters. Otherwise, a parameter set can be created (via dials::parameters()) and the dials update() function can be used to change the values. This updated parameter set can be passed to the function via the param_info argument.\n\nAchtung: step_impute_knn scheint Probleme zu haben, wenn es Charakter-Variablen gibt.\nPraktischerweise findet Tidymodels die Begrenzung von mtry selber heraus, wenn Sie kein Tuninggrid definieren. Das erkennen Sie daran, dass Tidymodels beim Tuning/Fitten die folgende Ausgabe zeigt:\ni Creating pre-processing data to finalize unknown parameter: mtry.\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/rope2/rope2.html",
    "href": "posts/rope2/rope2.html",
    "title": "rope2",
    "section": "",
    "text": "Im Datensatz mtcars: Ist der (mittlere) Unterschied im Spritverbrauch (mpg) zwischen den beiden Gruppen Automatik vs.¬†Schaltgetriebe vernachl√§ssigbar?\nWir definieren ‚Äúvernachl√§ssigbar klein‚Äù als ‚Äúh√∂chstens eine Meile‚Äù.\nPr√ºfen Sie rechnerisch, anhand des angegebenen Datensatzes, folgende Behauptung:\nBehauptung: ‚ÄúDer Unterschied ist vernachl√§ssigbar klein!‚Äù\nNutzen Sie das ROPE-Konzept mit den Standardwerten im Befehl rope aus {easystats}.\nW√§hlen Sie die Antwortoption, die am besten zu der obigen Behauptung passt!\nHinweise\nAntwortoptionen:\n\n\n\nJa, die Behauptung ist korrekt.\nNein, die Behauptung ist falsch.\nDie Daten sind bzw. das Modell nicht konkludent; es ist keine Entscheidung √ºber die Behauptung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Antwort m√∂glich."
  },
  {
    "objectID": "posts/rope2/rope2.html#answerlist",
    "href": "posts/rope2/rope2.html#answerlist",
    "title": "rope2",
    "section": "",
    "text": "Ja, die Behauptung ist korrekt.\nNein, die Behauptung ist falsch.\nDie Daten sind bzw. das Modell nicht konkludent; es ist keine Entscheidung √ºber die Behauptung m√∂glich.\nAuf Basis der bereitgestellten Informationen ist keine Antwort m√∂glich."
  },
  {
    "objectID": "posts/rope2/rope2.html#answerlist-1",
    "href": "posts/rope2/rope2.html#answerlist-1",
    "title": "rope2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\nrope\nbayes\nregression\nexam-22"
  },
  {
    "objectID": "posts/wskt-quiz09/wskt-quiz09.html",
    "href": "posts/wskt-quiz09/wskt-quiz09.html",
    "title": "wskt-quiz09",
    "section": "",
    "text": "Sei \\(X \\sim U(0, 1)\\).\nBehauptung: Es gilt: \\(f(X=1) = .1\\).\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz09/wskt-quiz09.html#answerlist",
    "href": "posts/wskt-quiz09/wskt-quiz09.html#answerlist",
    "title": "wskt-quiz09",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz09/wskt-quiz09.html#answerlist-1",
    "href": "posts/wskt-quiz09/wskt-quiz09.html#answerlist-1",
    "title": "wskt-quiz09",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/aussagen-infstat/index.html",
    "href": "posts/aussagen-infstat/index.html",
    "title": "aussagen-infstat",
    "section": "",
    "text": "1 Aufgabe\nDie Inferenzstatistik erg√§nzt die deskriptive Statistik.\n\nWelche Aussage zur Inferenzstatistik ist FALSCH?\n\nMan kann die Zielarten der Statistik in drei Gruppen fassen: Beschreiben, Vorhersagen und Zusammenfassen.\nKennzahlen einer Population nennt man auch Parameter.\nDie Ungewissheit eines wissenschaftlichen Modells kann man in zwei Arten aufteilen: Ungewissheit zu den Koeffizienten und Ungewissheit zur Modellspezifikation.\nGrund f√ºr die Schwankungen der Modellparameter zwischen den (zuf√§llig gezogenen) Stichproben ist die Zuf√§lligkeit des Stichprobenziehens.\nDie Inferenzstatistik fasst Stichprobendaten zu einer Statistik zusammen.\nEin (statistisch) signifikantes Ergebnis zeigt nicht unbedigt (praktische) Bedeutsamkeit an.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nA"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html",
    "href": "posts/germeval-senti01/germeval-senti01.html",
    "title": "germeval-senti01",
    "section": "",
    "text": "F√ºhren Sie eine Sentiment-Analyse als Teils eines Tidymodels-Rezept durch. Modellieren Sie dann mit einem einfachen linearen Modell die abh√§ngige Variable.\nVerwenden Sie diesen Datensatz:\n\n# Analyse-Daten:\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n# Sentiment-Daten\ndata(\"sentiws\", package = \"pradadata\")\n\nDie AV ist c1.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#setup",
    "href": "posts/germeval-senti01/germeval-senti01.html#setup",
    "title": "germeval-senti01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(syuzhet)  # get_sentiment\nlibrary(tidymodels)\nlibrary(tictoc)"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#daten",
    "href": "posts/germeval-senti01/germeval-senti01.html#daten",
    "title": "germeval-senti01",
    "section": "Daten",
    "text": "Daten\nc2 brauchen wir hier nicht:\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(-c2) |&gt; \n  as_tibble()"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#rezept",
    "href": "posts/germeval-senti01/germeval-senti01.html#rezept",
    "title": "germeval-senti01",
    "section": "Rezept",
    "text": "Rezept\nRezept definieren:\n\nrec &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  #update_role(c2, new_role = \"ignore\") |&gt; \n  update_role(text, new_role = \"ignore\") |&gt; \n  step_mutate(n_emo = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = sentiws))  |&gt; \n  step_rm(text)  # Datensatz verschlanken\n\nstep_mutate erg√§nzt f√ºr die erzeugte (mutierte) Variable automatisch eine Rolle im Rezept, nimmt sie also als Pr√§diktor auf.\nMal schauen:\n\nrec\n\n\ntidy(rec)\n\nPreppen und backen:\n\ntic()\nrec_prepped &lt;- prep(rec)\ntoc()\n\n\nrec_prepped\n\n\nrec_baked &lt;- bake(rec_prepped, new_data = NULL)\nhead(rec_baked)"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#model",
    "href": "posts/germeval-senti01/germeval-senti01.html#model",
    "title": "germeval-senti01",
    "section": "Model",
    "text": "Model\n\nmod &lt;-\n  logistic_reg()"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#workflow",
    "href": "posts/germeval-senti01/germeval-senti01.html#workflow",
    "title": "germeval-senti01",
    "section": "Workflow",
    "text": "Workflow\n\nwf &lt;- workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(mod)"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#fit",
    "href": "posts/germeval-senti01/germeval-senti01.html#fit",
    "title": "germeval-senti01",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit1 &lt;-\n  fit(wf,\n      data = d_train)\ntoc()\n\n\nfit1"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#test-set-g√ºte",
    "href": "posts/germeval-senti01/germeval-senti01.html#test-set-g√ºte",
    "title": "germeval-senti01",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmetrics(d_test,\n        truth = c1,\n        estimate = .pred_class)"
  },
  {
    "objectID": "posts/germeval-senti01/germeval-senti01.html#baseline",
    "href": "posts/germeval-senti01/germeval-senti01.html#baseline",
    "title": "germeval-senti01",
    "section": "Baseline",
    "text": "Baseline\nEin einfaches Referenzmodell ist, einfach die h√§ufigste Kategorie vorherzusagen:\n\nd_train |&gt; \n  count(c1)\n\n\nCategories:\n\ntidymodels\ntextmining\nprediction\nsentimentanalysis\ngermeval\nstring"
  },
  {
    "objectID": "posts/prob-disjunkt2/index.html",
    "href": "posts/prob-disjunkt2/index.html",
    "title": "prob-disjunkt2",
    "section": "",
    "text": "1 Aufgabe\nSie ziehen eine Karte aus einem standardm√§√üigen 52er-Kartendeck. Betrachten Sie die Ereignisse:\nK: Die gezogene Karte ist ein K√∂nig.\nD: Die gezogene Karte ist eine Dame.\nSind die Ereignisse K und D disjunkt?\n\nNein, weil beide zur Kategorie der Bildkarten geh√∂ren.\nNein, weil die Wahrscheinlichkeit f√ºr beide gr√∂√üer als Null ist.\nJa, da eine Karte nicht gleichzeitig ein K√∂nig und eine Dame sein kann.\nJa, aber nur, wenn Sie die Karten vor dem Ziehen nicht gemischt haben.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nJa, da eine Karte nicht gleichzeitig ein K√∂nig und eine Dame sein kann."
  },
  {
    "objectID": "posts/wrangle5/wrangle5.html",
    "href": "posts/wrangle5/wrangle5.html",
    "title": "wrangle5",
    "section": "",
    "text": "Wie pr√ºft man in R auf Gleichheit zweier Ausdr√ºcke?\nW√§hlen Sie die korrekte Aussage.\n\n\n\n!= ‚Äì ‚Äúdefiniert als‚Äù\n== Pr√ºfung auf Gleichheit\n= ‚Äì Pr√ºfung auf Gleichheit\n&lt;- ‚Äì Pr√ºfung auf Gleichheit\n!= ‚Äì Pr√ºfung auf Gleichheit"
  },
  {
    "objectID": "posts/wrangle5/wrangle5.html#answerlist",
    "href": "posts/wrangle5/wrangle5.html#answerlist",
    "title": "wrangle5",
    "section": "",
    "text": "!= ‚Äì ‚Äúdefiniert als‚Äù\n== Pr√ºfung auf Gleichheit\n= ‚Äì Pr√ºfung auf Gleichheit\n&lt;- ‚Äì Pr√ºfung auf Gleichheit\n!= ‚Äì Pr√ºfung auf Gleichheit"
  },
  {
    "objectID": "posts/wrangle5/wrangle5.html#answerlist-1",
    "href": "posts/wrangle5/wrangle5.html#answerlist-1",
    "title": "wrangle5",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\neda\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/qm2-quiz-globus/index.html",
    "href": "posts/qm2-quiz-globus/index.html",
    "title": "qm2-quiz-globus",
    "section": "",
    "text": "1 Aufgabe\nGeben Sie jeweils an, ob die Aussage richtig oder falsch ist.\n\nDer Prozess des Bayes-Updates hat folgende drei Teile: Priori-Verteilung -&gt; Likelihood -&gt; Posteriori-Verteilung.\nDie Likelihood-Funktion ist die Wahrscheinlichkeit der Daten unter der Annahme einer bestimmten Hypothese bzw. bestimmter Parameterwerte.\nDie Likelihood kann nie Null sein.\nDie Posteriori-Wahrscheinlichkeit (einer bestimmten Hypothese) kann nie Null sein.\nDie Priori-Wahrscheinlichkeit (einer bestimmten Hypothese) kann nie Null sein.\nDie Posteriori-Wahrscheinlichkeit misst die Wahrscheinlichkeit einer Hypothese, gegeben der Daten und der Priori-Verteilung und des Modells.\nBei einer Gleichverteilung ist jede Wert gleich wahrscheinlich.\nBayes‚Äô Theorem kann man so darstellen: \\(Pr(H|D) = \\frac{ Pr(H) \\cdot Pr(D|H) }{Pr(D)}\\).\nDas Produkt von Likelihood und Priori-Wahrscheinlichkeit nennt man Evidenz.\nDie standardisierte Posteriori-Wahrscheinlichkeit ist gleich dem Produkt von Priori-Wahrscheinlichkeit und Likelihood.\nSei die Priori-Wahrscheinlichkeit \\(Pr(H) = .1\\) und die Likelihood \\(Pr(D|H) = .25\\). Dann ist die Posteriori-Wahrscheinlichkeit \\(Pr(H|D) = .25\\).\nDie Posteriori-Verteilung (Kurz: ‚ÄúPost-Verteilung‚Äù, oder ‚ÄúPost‚Äù) zeigt, wie plausibel wir jeden Wert von halten, nachdem wir die Daten des Versuchs kennen.\n\\(Pr(H|D)\\) nennt man auch die Likelihood.\nWenn ein Krebstest eine Sicherheit von 90% hat (d.h. \\(Pr(+|K) = .9\\)), dann ist die Wahrscheinlichkeit, wirklich Krebs zu haben, wenn der Test positiv ist, gleich 90%.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nDer Prozess des Bayes-Updates hat folgende drei Teile: Priori-Verteilung -&gt; Likelihood -&gt; Posteriori-Verteilung. R\nDie Likelihood-Funktion ist die Wahrscheinlichkeit der Daten unter der Annahme einer bestimmten Hypothese bzw. bestimmter Parameterwerte. R\nDie Likelihood kann nie Null sein. F\nDie Posteriori-Wahrscheinlichkeit (einer bestimmten Hypothese) kann nie Null sein. F\nDie Priori-Wahrscheinlichkeit (einer bestimmten Hypothese) kann nie Null sein. F\nDie Posteriori-Wahrscheinlichkeit misst die Wahrscheinlichkeit einer Hypothese, gegeben der Daten und der Priori-Verteilung und des Modells. R\nBei einer Gleichverteilung ist jede Wert gleich wahrscheinlich. R\nBayes‚Äô Theorem kann man so darstellen: \\(Pr(H|D) = \\frac{ Pr(H) \\cdot Pr(D|H) }{Pr(D)}\\). R\nDas Produkt von Likelihood und Priori-Wahrscheinlichkeit nennt man Evidenz. F\nDie standardisierte Posteriori-Wahrscheinlichkeit ist gleich dem Produkt von Priori-Wahrscheinlichkeit und Likelihood. F\nSei die Priori-Wahrscheinlichkeit \\(Pr(H) = .1\\) und die Likelihood \\(Pr(D|H) = .25\\). Dann ist die Posteriori-Wahrscheinlichkeit \\(Pr(H|D) = .25\\). F\nDie Posteriori-Verteilung (Kurz: ‚ÄúPost-Verteilung‚Äù, oder ‚ÄúPost‚Äù) zeigt, wie plausibel wir jeden Wert von halten, nachdem wir die Daten des Versuchs kennen. R\n\\(Pr(H|D)\\) nennt man auch die Likelihood. F\nWenn ein Krebstest eine Sicherheit von 90% hat (d.h. \\(Pr(+|K) = .9\\)), dann ist die Wahrscheinlichkeit, wirklich Krebs zu haben, wenn der Test positiv ist, gleich 90%. F"
  },
  {
    "objectID": "posts/kung-height/kung-height.html",
    "href": "posts/kung-height/kung-height.html",
    "title": "Kung-height",
    "section": "",
    "text": "Exercise\nBetrachten Sie den Datensatz zur Gr√∂√üe der !Kung:\n\nlibrary(tidyverse)\nurl_kung &lt;- \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv\"\nd &lt;-\n  read_delim(url_kung, delim = \";\")  # Strichpunkt als Trennzeichen in der CSV-Datei\n\n\nUntersuchen Sie mit Hilfe eines Diagramms, ob bzw. inwieweit sich die Gr√∂√üe der erwachsenen Personen normalverteilt.\nKennzahlen, die angegeben, inwieweit sich eine Gr√∂√üe normalverteilt, sind Schiefe und Kurtosis. Die Schiefe gibt an, wie symmetrische eine Verteilung ist.\n\nNormalverteilungen sind symmetrisch und haben daher einen Wert von 0 f√ºr Schiefe. Kurtosis gibt die ‚ÄúW√∂lbung‚Äù, also wie ‚Äúspitz‚Äù oder ‚Äúplattgedr√ºckt‚Äù eine Verteilung ist. Eine Normalverteilung hat eine Wert von 3 f√ºr Kurtosis.\nEntsprechende R-Funktionen finden Sie z.B. im Paket moments. Berechnen Sie die beiden Kennzahlen f√ºr die Gruppe der Erwachsenen sowie aufgeteilt nach dem Geschlecht. Interpretieren Sie das Ergebnis.\n\nDiskutieren Sie, inwieweit man aus biologisch fundierten Sachverhalten (also ontologisch) eine Normalverteilung der K√∂rpergr√∂√üe annehmen kann.\n\n         \n\n\nSolution\n\nVisuelle Pr√ºfung der Normalverteilung\n\n\nd2 &lt;- d %&gt;% \n  filter(age &gt;= 18)\n\nd3 &lt;- d2 %&gt;% \n  select(-male)\n\nggplot(d2, aes(x = height)) +\n  geom_density()\n\n\n\n\n\n\n\nggplot(d2, aes(x = height )) +\n  facet_wrap(~ male) +\n    geom_density()\n\n\n\n\n\n\n\nggplot(d2, aes(x = height)) +\n  facet_wrap(~ male) +\n  geom_histogram(data = d3, fill = \"grey60\", alpha = .6) +\n    geom_histogram() +\n  labs(caption = \"Grau hinterlegt ist das Histogramm f√ºr die Daten √ºber beide Geschlechter\")\n\n\n\n\n\n\n\n\nMan kann auch so visualisieren:\n\nlibrary(ggpubr)\n\nd2$male &lt;- as.factor(d2$male)\n\ngghistogram(d2, x = \"height\", fill = \"male\")\n\n\n\n\n\n\n\n\n\nSchiefe und Kurtosis\n\n\nlibrary(easystats)\nd2 %&gt;%  skewness()\n\n\n\n\n\n\nParameter\nSkewness\nSE\n\n\n\n\nheight\nheight\n0.1512388\n0.1294518\n\n\nweight\nweight\n0.1321602\n0.1294518\n\n\nage\nage\n0.6654057\n0.1294518\n\n\nmale\nmale\n0.1257815\n0.1294518\n\n\n\n\n\nd2 %&gt;% kurtosis()\n\n\n\n\n\n\nParameter\nKurtosis\nSE\n\n\n\n\nheight\nheight\n-0.4834334\n0.2556235\n\n\nweight\nweight\n-0.5063574\n0.2556235\n\n\nage\nage\n-0.2128048\n0.2556235\n\n\nmale\nmale\n-1.9955499\n0.2556235\n\n\n\n\n\n\n\nNormalverteilung, Begr√ºndung\n\nEs ist plausibel anzunehmen, dass der Ph√§notyp K√∂rpergr√∂√üe das Resultat des (kausalen) Einflusses vieler Gene ist, vieler Gene, die √ºber einen vergleichbar starken Einfluss verf√ºgen.\nEine besondere Situation stellt das X- bzw. Y-Chromosom dar, das Gene zum Geschlecht bereitstellt. Das Geschlecht ist ein einzelner Faktor, der (erfahrungsgem√§√ü) einen relativ gro√üen Einfluss auf die K√∂rpergr√∂√üe hat (in Anbetracht, dass vielleicht Tausende Gene additiv die Gr√∂√üe bestimmen). Insofern ist eine klarere Ann√§herung an die Normalverteilung zu erwarten, wenn man die Geschlechter einzeln betrachtet.\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/penguins-interact/index.html",
    "href": "posts/penguins-interact/index.html",
    "title": "penguins-interact",
    "section": "",
    "text": "Eine Forscherin untersucht, ob das Geschlecht eines Pinguins den Einfluss der Flossenl√§nge (Flipper, mm) auf das K√∂rpergewicht (g) des Tieres moderiert.\nAuf Basis der Daten: Liegt ein (substanzieller) Interaktionseffekt vor?\nHinweise:\n\nNutzen Sie die folgende Analyse als Grundlage Ihrer Antworten.\nBeachten Sie die Hinweise des Datenwerks.\nUnter ‚Äúsubstanziell‚Äù sei ein Effekt von mind. 100 g verstanden.\n\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nDaf√ºr ist folgende Analyse gegeben.\n\n\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\n\n\nDie Forschungsfrage kann man wie folgt als Hypothese formalisieren:\n\\[\\beta_{m} \\ne 0\\]\n‚ÄúDer Regressionskoeffizient der Moderation (\\(m\\), d.h. Interaktion) ist ungleich Null.‚Äù\nTestet man nicht eine exakte, sondern einen Mindestwert (ROPE), so kann man die Hypothese so formulieren:\n\\[\\beta_{m} &gt; 100\\]\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!\n\nWir k√∂nnten den Datensatz auch als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)  # oder z.B. mit read_csv \n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nWir entfernen noch alle fehlenden Werte:\n\npenguins_nona &lt;- \n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\")\n\npenguins_nona$sex |&gt; unique()\n\n[1] male   female\nLevels: female male\n\n\nZur besseren Interpretierbarkeit standardisieren wir die (metrische) UV:\n\npenguins_nona_z &lt;- \n  penguins_nona |&gt; \n  standardise(select = \"flipper_length_mm\",\n              append = TRUE)\n\n\nm_interaction &lt;- stan_glm(body_mass_g ~  sex + flipper_length_mm_z + sex:flipper_length_mm_z,  # Regressionsgleichung\n               data = penguins_nona_z, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm_interaction_params &lt;- parameters(m_interaction, ci_method = \"hdi\", ci = .9)\nm_interaction_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n4031.156606\n0.9\n3985.09735\n4078.37091\n1.0000\n1.0002909\n3191.696\nnormal\n4207.057\n2013.040\n\n\nsexmale\n348.800992\n0.9\n277.55234\n410.74168\n1.0000\n1.0000000\n3417.024\nnormal\n0.000\n4020.192\n\n\nflipper_length_mm_z\n660.203105\n0.9\n610.01272\n712.85777\n1.0000\n0.9993882\n2487.696\nnormal\n0.000\n2013.040\n\n\nsexmale:flipper_length_mm_z\n-3.144666\n0.9\n-70.02727\n68.50731\n0.5285\n0.9994223\n2651.322\nnormal\n0.000\n2695.055"
  },
  {
    "objectID": "posts/penguins-interact/index.html#setup",
    "href": "posts/penguins-interact/index.html#setup",
    "title": "penguins-interact",
    "section": "",
    "text": "library(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)"
  },
  {
    "objectID": "posts/penguins-interact/index.html#modell-und-hypothese",
    "href": "posts/penguins-interact/index.html#modell-und-hypothese",
    "title": "penguins-interact",
    "section": "",
    "text": "Die Forschungsfrage kann man wie folgt als Hypothese formalisieren:\n\\[\\beta_{m} \\ne 0\\]\n‚ÄúDer Regressionskoeffizient der Moderation (\\(m\\), d.h. Interaktion) ist ungleich Null.‚Äù\nTestet man nicht eine exakte, sondern einen Mindestwert (ROPE), so kann man die Hypothese so formulieren:\n\\[\\beta_{m} &gt; 100\\]\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!\n\nWir k√∂nnten den Datensatz auch als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)  # oder z.B. mit read_csv \n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nWir entfernen noch alle fehlenden Werte:\n\npenguins_nona &lt;- \n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\")\n\npenguins_nona$sex |&gt; unique()\n\n[1] male   female\nLevels: female male\n\n\nZur besseren Interpretierbarkeit standardisieren wir die (metrische) UV:\n\npenguins_nona_z &lt;- \n  penguins_nona |&gt; \n  standardise(select = \"flipper_length_mm\",\n              append = TRUE)\n\n\nm_interaction &lt;- stan_glm(body_mass_g ~  sex + flipper_length_mm_z + sex:flipper_length_mm_z,  # Regressionsgleichung\n               data = penguins_nona_z, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm_interaction_params &lt;- parameters(m_interaction, ci_method = \"hdi\", ci = .9)\nm_interaction_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n4031.156606\n0.9\n3985.09735\n4078.37091\n1.0000\n1.0002909\n3191.696\nnormal\n4207.057\n2013.040\n\n\nsexmale\n348.800992\n0.9\n277.55234\n410.74168\n1.0000\n1.0000000\n3417.024\nnormal\n0.000\n4020.192\n\n\nflipper_length_mm_z\n660.203105\n0.9\n610.01272\n712.85777\n1.0000\n0.9993882\n2487.696\nnormal\n0.000\n2013.040\n\n\nsexmale:flipper_length_mm_z\n-3.144666\n0.9\n-70.02727\n68.50731\n0.5285\n0.9994223\n2651.322\nnormal\n0.000\n2695.055"
  },
  {
    "objectID": "posts/penguins-interact/index.html#punktsch√§tzer",
    "href": "posts/penguins-interact/index.html#punktsch√§tzer",
    "title": "penguins-interact",
    "section": "Punktsch√§tzer",
    "text": "Punktsch√§tzer\nDer Punktsch√§tzer ist in der Spalte Median in der Tabelle parameters zu finden. Sein Wert ist:\n\n\n[1] -3.144666\n\n\nHier ist die Post-Verteilung des Effekts:\n\nm_interaction_params |&gt; plot()\n\n\n\n\n\n\n\n\nAlternative Visualisierung:\n\nhdi(m_interaction, ci = .9) |&gt; plot()"
  },
  {
    "objectID": "posts/penguins-interact/index.html#breite-des-intervalls",
    "href": "posts/penguins-interact/index.html#breite-des-intervalls",
    "title": "penguins-interact",
    "section": "Breite des Intervalls",
    "text": "Breite des Intervalls\nDazu liest man die Intervallgrenzen (90% CI) in der richtigen Zeile ab (Tabelle parameters).\nObere Grenze: 68.5073138.\nUntere Grenze: -70.0272668.\nDifferenz = Obere_Grenze - Untere_Grenze:\n\n\n[1] 138.5346\n\n\nEinheit: mm"
  },
  {
    "objectID": "posts/penguins-interact/index.html#effektwahrscheinlichkeit",
    "href": "posts/penguins-interact/index.html#effektwahrscheinlichkeit",
    "title": "penguins-interact",
    "section": "Effektwahrscheinlichkeit",
    "text": "Effektwahrscheinlichkeit\nMan erkennt schon im Diagramm zum Konfidenzintervall, dass 100% des Intervalls positiv ist. Daher ist die Effektwahrscheinlichkeit auch positiv.\nMan kann diesen Wert aus der Tabelle oben (Ausgabe von parameters()) einfach in der Spalte pd ablesen. pd steht f√ºr probability of direction, s. Details hier.\nOder so, ist auch einfach:\n\npd_m_interaction_params &lt;- p_direction(m_interaction) # aus Paket easystats\npd_m_interaction_params\n\n\n\n\n\n\nParameter\npd\nEffects\nComponent\n\n\n\n\n1\n(Intercept)\n1.0000\nfixed\nconditional\n\n\n3\nsexmale\n1.0000\nfixed\nconditional\n\n\n2\nflipper_length_mm_z\n1.0000\nfixed\nconditional\n\n\n4\nsexmale:flipper_length_mm_z\n0.5285\nfixed\nconditional\n\n\n\n\n\n\nUnd plotten ist meist hilfreich: plot(pd_m_interaction_params).\n\nplot(pd_m_interaction_params)"
  },
  {
    "objectID": "posts/penguins-interact/index.html#substanzielle-effektwahrscheinlichkeit",
    "href": "posts/penguins-interact/index.html#substanzielle-effektwahrscheinlichkeit",
    "title": "penguins-interact",
    "section": "Substanzielle Effektwahrscheinlichkeit",
    "text": "Substanzielle Effektwahrscheinlichkeit\nDie Frage ist nichts anderes als nach ROPE zu fragen.\n\nrope_m_interact &lt;- rope(m_interaction, range = c(-100,+100))\nrope_m_interact\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n1\n(Intercept)\n0.95\n-100\n100\n0\nfixed\nconditional\n\n\n3\nsexmale\n0.95\n-100\n100\n0\nfixed\nconditional\n\n\n2\nflipper_length_mm_z\n0.95\n-100\n100\n0\nfixed\nconditional\n\n\n4\nsexmale:flipper_length_mm_z\n0.95\n-100\n100\n1\nfixed\nconditional\n\n\n\n\n\n\n\nplot(rope_m_interact)\n\n\n\n\n\n\n\n\nDas 95%-Post-Intervall ist komplett innerhalb des ROPE.\nWir k√∂nnen die ROPE-Hypothese daher best√§tigen."
  },
  {
    "objectID": "posts/tidytext/tidytext.html",
    "href": "posts/tidytext/tidytext.html",
    "title": "tidytext",
    "section": "",
    "text": "library(tidytext)\nlibrary(tidyverse)\ntext_df %&gt;%\n  unnest_tokens(word, text) %&gt;% \n  filter(str_detect(word, \"[a-z]\"))\n\nWelche Aussage zu dieser Syntax ist korrekt?\n\n\n\nDer Text wird so ‚Äúentschachtelt‚Äù, dass in jeder Zelle nur noch ein Wort steht. Dabei werden so viele Spalten angeh√§ngt, wie W√∂rter in der betreffenden Zelle standen.\nDurch filter() in Verbindung mit str_detect() werden alle Buchstaben von a bis z entfernt.\nEin Token bedeutet hier so viel wie eine numerische Analyseeinheit.\nDer Text wird in das lange Format umwandelt, so dass nur noch ein Wort pro Zeile steht."
  },
  {
    "objectID": "posts/tidytext/tidytext.html#answerlist",
    "href": "posts/tidytext/tidytext.html#answerlist",
    "title": "tidytext",
    "section": "",
    "text": "Der Text wird so ‚Äúentschachtelt‚Äù, dass in jeder Zelle nur noch ein Wort steht. Dabei werden so viele Spalten angeh√§ngt, wie W√∂rter in der betreffenden Zelle standen.\nDurch filter() in Verbindung mit str_detect() werden alle Buchstaben von a bis z entfernt.\nEin Token bedeutet hier so viel wie eine numerische Analyseeinheit.\nDer Text wird in das lange Format umwandelt, so dass nur noch ein Wort pro Zeile steht."
  },
  {
    "objectID": "posts/kausal_corona_glatze/kausal_corona_glatze.html",
    "href": "posts/kausal_corona_glatze/kausal_corona_glatze.html",
    "title": "kausal_corona_glatze",
    "section": "",
    "text": "Exercise\nVor einiger Zeit war in der Presse Folgendes zu lesen:\n\nRecent studies linking male sex hormones to severe coronavirus infections point to a potential predictor of disease severity: baldness. International researchers studying global data on COVID-19 patients have found that in general, the more male hormones called androgens someone has, the easier it is for SARS-CoV-2 to enter and take over their immune systems. And bald men have more of these hormones than men with full manes, and women.\n\nQuelle\nAllerdings vers√§umten es einige (viele) der Pressemeldungen, eine belastbare Quelle, also den Forschungsartikel, auf dem dieses Befund beruhen muss, zu zitieren.\nEine m√∂gliche Kausalhypothese f√ºr die obige Pressemitteilung ist, dass m√§nnliche Sexualhormone eine gemeinsame Ursache f√ºr Haarausfall und auch die Schwere eine Covid19-Infektion darstellen.\nAllerdings sind auch andere, skeptischere, Hypothesen denkbar. Skeptisch meint dabei, dass auf komplexere Erkl√§rungen zugunsten einfachere verzichtet werden kann.\nSo ben√∂tigt etwa die Hypothese ‚ÄúSt√∂rche bringen Babies‚Äù komplexe Erk√§rungsmodelle; eine skeptischere (einfachere) Erkl√§rung w√§re, dass die (geringe) Urbanisierung eines Landstrichs die gemeinsame Ursache f√ºr sowohl die H√§ufigkeit von St√∂rchen als auch von Babies darstellt.\nGeben Sie eine skeptische Kausalerk√§rung an f√ºr den Befund, dass Haarausfall und Schwere eines Coronaverlaufs assoziiert sind!.\n         \n\n\nSolution\nAlter ist sowohl die Ursache von Haarausfall (bei M√§nnern) als auch von der Schwere eines Corona-Verlaufs. Daher sind Haarausfall (bei M√§nnern) und die Schwerer eines Corona-Verlaufs durch das Alter konfundiert. Ohne Ber√ºcksichtigung der gemeinsamen Ursache erscheint Haarausfall mit Corona-Schwere korreliert zu sein. Nach Kontrolle der konfundierenden Variablen verschwindet die Korrelation.\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/simu-unif3/index.html",
    "href": "posts/simu-unif3/index.html",
    "title": "simu-unif3",
    "section": "",
    "text": "1 Aufgabe\nSie warten an einer Bushaltestelle auf einen Bus. Der Bus f√§hrt alle 10 Minuten ab. Allerdings wissen Sie nicht, wann der Bus das letzte Mal abgefahren ist.\nAufgabe: Wie hoch ist die Wahrscheinlichkeit, dass Sie l√§nger als 1 Minute, aber nicht l√§nger als 9 Minuten, warten m√ºssen?\n  \n  \n  \n  \n\n\n2 L√∂sung\n80%"
  },
  {
    "objectID": "posts/urne1/urne1.html",
    "href": "posts/urne1/urne1.html",
    "title": "urne1",
    "section": "",
    "text": "Aufgabe\nIn einer Urne befinden sich f√ºnf Kugeln, von denen 4 rot sind und 1 wei√ü.\nAufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass bei 2 Ziehungen ohne Zur√ºcklegen (ZoZ) genau 2 rote Kugeln gezogen werden?\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nSei \\(R1\\) ‚Äúrote Kugel im 1. Zug gezogen‚Äù.\nSei \\(R2\\) ‚Äúrote Kugel im 2. Zug gezogen‚Äù.\nGesucht ist die gemeinsame Wahrscheinlichkeit f√ºr R1 und R2: \\(Pr(R1 \\cap R2)\\), die Wahrscheinlichkeit also, dass beide Ereignisse (R1 und R2) eintreten.\nF√ºr R1 gilt: \\(Pr(R1) = 4/5\\).\nF√ºr R2 gilt: \\(Pr(R2|R1) = 3/4\\).\nMan beachte, dass R1 und R2 nicht unabh√§ngig sind, d.h. sie sind abh√§ngig (voneinander).\n\nPr_R1 &lt;- 4/5\nPr_R2_geg_R1 &lt;- 3/4\nPr_R1_R2 &lt;- Pr_R1 * Pr_R2_geg_R1\nPr_R1_R2\n\n[1] 0.6\n\n\nDie L√∂sung lautet 0.6.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html",
    "title": "tidymodels-penguins06",
    "section": "",
    "text": "Berechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm.\nVergleichen Sie die Testfehlerh√∂he im Test-Sample in folgenden zwei Szenarien:\n\nTrain-Test-Aufspaltung, 10 Mal wiederholt\n10-fache Kreuzvalidierung (im Train-Sample) (\\(v=10, r= 1\\))\n\nHinweise:\n\nTuning Sie - nur im 2. Szenario - \\(k\\) mit den Werten 5, 10, 15.\nL√∂schen Sie alle Zeilen mit fehlenden Werten in den Pr√§diktoren.\nBeachten Sie die √ºblichen Hinweise.\nNat√ºrlich gilt: Ceteris paribus. Halten Sie also die Modelle im √úbrigen vergleichbar bzw. identisch.\n\n\n\n\nSzenario 1 hat den geringeren Vorhersagefehler.\nSzenario 2 hat den geringeren Vorhersagefehler.\nDer Vorhersagefehler ist in beiden Szenarien gleich.\nKeine Antwort m√∂glich."
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#answerlist",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#answerlist",
    "title": "tidymodels-penguins06",
    "section": "",
    "text": "Szenario 1 hat den geringeren Vorhersagefehler.\nSzenario 2 hat den geringeren Vorhersagefehler.\nDer Vorhersagefehler ist in beiden Szenarien gleich.\nKeine Antwort m√∂glich."
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#setup",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#setup",
    "title": "tidymodels-penguins06",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nWir d√ºrfen keine fehlenden Werte in der Y-Variable haben (im Train-Set), sonst meckert Tidymodels:\n\nd2 &lt;- \n  d %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#daten-aufteilen",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#daten-aufteilen",
    "title": "tidymodels-penguins06",
    "section": "Daten aufteilen:",
    "text": "Daten aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-1",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-1",
    "title": "tidymodels-penguins06",
    "section": "CV",
    "text": "CV\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 10, repeats = 1)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#workflow",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#workflow",
    "title": "tidymodels-penguins06",
    "section": "Workflow",
    "text": "Workflow\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric_predictors())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten",
    "title": "tidymodels-penguins06",
    "section": "Fitten",
    "text": "Fitten\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellg√ºte",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellg√ºte",
    "title": "tidymodels-penguins06",
    "section": "Modellg√ºte",
    "text": "Modellg√ºte\n\nbestfit1 &lt;- fit_best(x = d_resamples)\nlastfit1 &lt;- last_fit(bestfit1, d_split)\n\nError in `last_fit()`:\n! `last_fit()` is not well-defined for a fitted workflow.\n\ncollect_metrics(lastfit1)\n\nError: object 'lastfit1' not found"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-2",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-2",
    "title": "tidymodels-penguins06",
    "section": "CV",
    "text": "CV\nWir resamplen nicht √ºber das Train-Sample, sondern √ºber die ganze Stichprobe:\n\nset.seed(42)\nfolds2 &lt;- vfold_cv(d2, v = 2, repeats = 10)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten-1",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten-1",
    "title": "tidymodels-penguins06",
    "section": "Fitten",
    "text": "Fitten\n\nd_resamples2 &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds2,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellg√ºte-1",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellg√ºte-1",
    "title": "tidymodels-penguins06",
    "section": "Modellg√ºte",
    "text": "Modellg√ºte\n\nbestfit2 &lt;- fit_best(x = d_resamples2)\nlastfit2 &lt;- last_fit(bestfit2, d_split)\n\nError in `last_fit()`:\n! `last_fit()` is not well-defined for a fitted workflow.\n\ncollect_metrics(lastfit2)\n\nError: object 'lastfit2' not found\n\n\n\nCategories:\n\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/zwert-berechnen/zwert-berechnen.html",
    "href": "posts/zwert-berechnen/zwert-berechnen.html",
    "title": "zwert-berechnen",
    "section": "",
    "text": "Exercise\nSei \\(X \\sim \\mathcal{N}(42, 7)\\) und \\(x_1 = 28\\).\nBerechnen Sie den z-Wert f√ºr \\(x_1\\)!\nHinweis:\n\nRunden Sie ggf. auf die n√§chste ganze Zahl.\n\n         \n\n\nSolution\n\nx1_z = (x1 - x_mw) / x_sd\n\n-2\n\nCategories:\n\nz-value\nR\nmath"
  },
  {
    "objectID": "posts/tidymodels-penguins01/tidymodels-penguins01.html",
    "href": "posts/tidymodels-penguins01/tidymodels-penguins01.html",
    "title": "tidymodels-penguins01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Ma√ü f√ºr die Modellg√ºte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=1 CV.\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read.csv(d_path)\n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(penguins)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nlm_mod &lt;-\n  linear_reg()\n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(lm_mod)\n\nwflow\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\nAuf NA pr√ºfen:\n\nsum(is.na(d_baked))\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5)\nfolds\n\nResampling:\n\npenguins_resamples &lt;-\n  fit_resamples(\n    wflow,\n    resamples = folds\n  )\npenguins_resamples\n\nLast Fit:\n\npenguins_last &lt;- last_fit(wflow, d_split)\n\nModellg√ºte im Test-Sample:\n\npenguins_last %&gt;% collect_metrics()\n\nR-Quadrat:\n\nsol &lt;-  collect_metrics(penguins_last)[[\".estimate\"]][2]\nsol\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/kausal22/kausal22.html",
    "href": "posts/kausal22/kausal22.html",
    "title": "kausal22",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x3.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x6, x7 }\n{ x1, x7 }\n{ x2 }\n{ x1, x3 }\n{ x2, x6 }"
  },
  {
    "objectID": "posts/kausal22/kausal22.html#answerlist",
    "href": "posts/kausal22/kausal22.html#answerlist",
    "title": "kausal22",
    "section": "",
    "text": "{ x6, x7 }\n{ x1, x7 }\n{ x2 }\n{ x1, x3 }\n{ x2, x6 }"
  },
  {
    "objectID": "posts/kausal22/kausal22.html#answerlist-1",
    "href": "posts/kausal22/kausal22.html#answerlist-1",
    "title": "kausal22",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/Boxplot-Aussagen/Boxplot-Aussagen.html",
    "href": "posts/Boxplot-Aussagen/Boxplot-Aussagen.html",
    "title": "Boxplot-Aussagen",
    "section": "",
    "text": "Hinweis: Female steht f√ºr Frauen; Male f√ºr M√§nner.\nDiese Aufgabe bezieht sich auf den Datensatz tips (aus dem R-Paket reshape2), den Sie ggf. hier herunterladen k√∂nnen. Ein Data-Dictionary findet sich hier.\n\ndata(tips, package = \"reshape2\")\nlibrary(tidyverse)\n\nggplot(tips) +\n  aes(x = sex, y = total_bill) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nDer IQR der M√§nner ist gr√∂√üer als der der Frauen.\nDer Boxplot ist schlecht geeignet, um die Verteilung mehrerer Gruppen pr√§gnant und √ºbersichtlich zu visualisieren.\nDer Mittelwert der M√§nner ist kleiner als der der Frauen.\nDie Streuung in den RANDbereichen der Frauen ist gr√∂√üer als die der M√§nner.\nBei den M√§nnern gibt es mehr Ausrei√üer als bei den Frauen.\nDie Streuung in den beiden √§u√üeren Quartilen ist bei den Frauen gr√∂√üer als bei den M√§nnern.\nDie Verteilungen sind beide nicht schief.\nDie Verteilungen sind beide symmetrisch.\nAuf der X-Achse steht eine metrische (quantitative) Variable.\nAuf der Y-Achse steht eine nominale (qualitative) Variable.\nAuf der Y-Achse steht eine metrische (quantitative) Variable.\nAuf der X-Achse steht eine nominale (qualitative) Variable."
  },
  {
    "objectID": "posts/Boxplot-Aussagen/Boxplot-Aussagen.html#answerlist",
    "href": "posts/Boxplot-Aussagen/Boxplot-Aussagen.html#answerlist",
    "title": "Boxplot-Aussagen",
    "section": "",
    "text": "Der IQR der M√§nner ist gr√∂√üer als der der Frauen.\nDer Boxplot ist schlecht geeignet, um die Verteilung mehrerer Gruppen pr√§gnant und √ºbersichtlich zu visualisieren.\nDer Mittelwert der M√§nner ist kleiner als der der Frauen.\nDie Streuung in den RANDbereichen der Frauen ist gr√∂√üer als die der M√§nner.\nBei den M√§nnern gibt es mehr Ausrei√üer als bei den Frauen.\nDie Streuung in den beiden √§u√üeren Quartilen ist bei den Frauen gr√∂√üer als bei den M√§nnern.\nDie Verteilungen sind beide nicht schief.\nDie Verteilungen sind beide symmetrisch.\nAuf der X-Achse steht eine metrische (quantitative) Variable.\nAuf der Y-Achse steht eine nominale (qualitative) Variable.\nAuf der Y-Achse steht eine metrische (quantitative) Variable.\nAuf der X-Achse steht eine nominale (qualitative) Variable."
  },
  {
    "objectID": "posts/Boxplot-Aussagen/Boxplot-Aussagen.html#answerlist-1",
    "href": "posts/Boxplot-Aussagen/Boxplot-Aussagen.html#answerlist-1",
    "title": "Boxplot-Aussagen",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\nWahr\n\n\nCategories:\n\nvis\neda\ndyn\nschoice"
  },
  {
    "objectID": "posts/Boosting2/Boosting2.html",
    "href": "posts/Boosting2/Boosting2.html",
    "title": "Boosting2",
    "section": "",
    "text": "Boosting ist eine beliebte Methode des statistischen Lernens, da sie sich in vielen pr√§diktiven Fragestellungen als hoch pr√§diktiv herausgestellt hat. Die Modellfunktion von Boosting kann man so darstellen:\n\\[\\hat{f}(x)=\\sum_{b=1}^B \\lambda \\hat{f}^b(x)\\]\n(Dabei stellt \\(B\\) die Anzahl der B√§ume im Modell dar und \\(\\lambda\\) einen Tuningparamter zur Penalisierung/Regularisierung bzw. die Lernrate des Modells.)\nWelche Aussage ist in diesem Zusammenhang korrekt?\n\n\n\nBoosting gleicht einem Random-Forest-Modell, nur dass die B√§ume sequenzielle Modelle darstellen und nicht parallel (gleichzeitig) in ein Modell einflie√üen.\nBoosting-Modelle bestehen aus einer Sequenz von B√§umen mit jeweils nur einer Inputvariablen (Gabelung/Split; internal nodes).\nAlle Boosting-Modelle erf√ºllen obige Funktionsgleichung und sind daher immer linear.\nBoosting-Modelle analysieren im Allgemeinen in jedem der \\(B\\) Durchl√§ufe einen anderen Datensatz.\nDer Parameter \\(B\\) sollte nicht √ºber Kreuzvalidierungsmethoden bestimmt werden."
  },
  {
    "objectID": "posts/Boosting2/Boosting2.html#answerlist",
    "href": "posts/Boosting2/Boosting2.html#answerlist",
    "title": "Boosting2",
    "section": "",
    "text": "Boosting gleicht einem Random-Forest-Modell, nur dass die B√§ume sequenzielle Modelle darstellen und nicht parallel (gleichzeitig) in ein Modell einflie√üen.\nBoosting-Modelle bestehen aus einer Sequenz von B√§umen mit jeweils nur einer Inputvariablen (Gabelung/Split; internal nodes).\nAlle Boosting-Modelle erf√ºllen obige Funktionsgleichung und sind daher immer linear.\nBoosting-Modelle analysieren im Allgemeinen in jedem der \\(B\\) Durchl√§ufe einen anderen Datensatz.\nDer Parameter \\(B\\) sollte nicht √ºber Kreuzvalidierungsmethoden bestimmt werden."
  },
  {
    "objectID": "posts/Boosting2/Boosting2.html#answerlist-1",
    "href": "posts/Boosting2/Boosting2.html#answerlist-1",
    "title": "Boosting2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Im Gegensatz zu Random-Forest-Modellen wird im Boosting u.a. kein Resampling verwendet.\nFalsch. Boosting-Modelle k√∂nnen mehr als eine Gabelung enthalten.\nFalsch. Boosting-Modelle sind nur dann linear, wenn Sie nur eine Gabelung enthalten.\nRichtig. In jedem Durchlauf wird der analysierte Datensatz ver√§ndert, insofern als das jeweils die Residuen des vorherigen Durchlaufs den Datensatz des n√§chsten Durchlaufs bilden.\nFalsch. Es macht Sinn, den Paramter \\(B\\) √ºber Kreuzvalidierungsmethoden zu bestimmen. Allerdings ist die √úberfittingsgefahr relativ gering.\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html",
    "href": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html",
    "title": "Szenario-charakterisieren1",
    "section": "",
    "text": "Angenommen, Sie arbeiten als Analyst mit folgender Aufgabe:\nEs liegt ein Datensatz mit 600 Besch√§ftigten (als Beobachtungseinheit) vor. F√ºr jede Person sind folgende Informationen bekannt: Dauer der Betriebszugeh√∂rigkeit, Alter, Ausbildung und Ergebnis der letzten Leistungsbeurteilung. Ziel ist es, die H√∂he des zu erwartenden Gehalts vorherzusagen.\n\n\n\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erkl√§rung (inference) \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine un√ºberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist",
    "href": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist",
    "title": "Szenario-charakterisieren1",
    "section": "",
    "text": "Es handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erkl√§rung (inference) \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine un√ºberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist-1",
    "href": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist-1",
    "title": "Szenario-charakterisieren1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/wozu-streudiagramm/wozu-streudiagramm.html",
    "href": "posts/wozu-streudiagramm/wozu-streudiagramm.html",
    "title": "wozu-streudiagramm",
    "section": "",
    "text": "Zu welchem Zweck ist ein Streudiagramm am besten geeignet?\n\n\n\nUm Verteilungen einer nominalen Variablen darzustellen.\nUm Verteilungen einer metrischen Variablen darzustellen.\nUm Verteilungen einer stetigen, metrischen Variablen darzustellen.\nUm Zusammenh√§nge zwischen zwei nominalen Variablen darzustellen.\nUm Zusammenh√§nge zwischen zwei metrischen Variablen darzustellen."
  },
  {
    "objectID": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist",
    "href": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist",
    "title": "wozu-streudiagramm",
    "section": "",
    "text": "Um Verteilungen einer nominalen Variablen darzustellen.\nUm Verteilungen einer metrischen Variablen darzustellen.\nUm Verteilungen einer stetigen, metrischen Variablen darzustellen.\nUm Zusammenh√§nge zwischen zwei nominalen Variablen darzustellen.\nUm Zusammenh√§nge zwischen zwei metrischen Variablen darzustellen."
  },
  {
    "objectID": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist-1",
    "href": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist-1",
    "title": "wozu-streudiagramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/griech-buchstaben/griech-buchstaben.html",
    "href": "posts/griech-buchstaben/griech-buchstaben.html",
    "title": "Griech-Buchstaben-Inferenz",
    "section": "",
    "text": "Exercise\nF√ºr Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; f√ºr Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollst√§ndigen Sie folgende Tabelle entsprechend!\n\n\n\n\n\nKennwert\nStatistik\nParameter\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\nNA\n\n\nMittelwertsdifferenz\n\\(\\bar{X}_1-\\bar{X}_2\\)\nNA\n\n\nStreuung\nsd\nNA\n\n\nAnteil\np\nNA\n\n\nKorrelation\nr\nNA\n\n\nRegressionsgewicht\nb\nNA\n\n\n\n\n\n         \n\n\nSolution\n\n\n\n\n\nKennwert\nStatistik\nParameter\n\n\n\n\nMittelwert\n\\[\\bar{X}\\]\n\\[\\mu\\]\n\n\nMittelwertsdifferenz\n\\[d=\\bar{X}_1-\\bar{X}_2\\]\n\\[\\mu_1\\]- \\[\\mu_2\\]\n\n\nStreuung\nsd\n\\[\\sigma\\]\n\n\nAnteil\np\n\\[\\pi\\]\n\n\nKorrelation\nr\n\\[\\rho\\]\n\n\nRegressionsgewicht\nb\n\\[\\beta\\]\n\n\n\n\n\n\nCategories:\n\nqm2\ninference"
  },
  {
    "objectID": "posts/zwielichter-dozent-bayes/zwielichter-dozent-bayes.html",
    "href": "posts/zwielichter-dozent-bayes/zwielichter-dozent-bayes.html",
    "title": "zwielichter-dozent-bayes",
    "section": "",
    "text": "options(digits = 2)\n\n\nExercise\nNach einem langen Unitag machen Sie sich auf den Weg nach Hause; ihr Weg fuÃàhrt Sie durch eine dunkle Ecke. Just dort regt sich auf einmal eine Gestalt in den Schatten . Die Person spricht Sie an: ‚ÄûNa, Lust auf ein Spielchen?‚Äú. Sie willigen sofort ein. Die Person stellt sich als ein Statistiker vor, dessen Namen nichts zur Sache tue; das Gesicht kommt Ihnen vage bekannt vor. ‚ÄûPass auf‚Äú, erkl√§rt der Statistiker, ‚Äûwir werfen eine MuÃànze, ich setze auf Zahl‚Äú. Dass er auf Zahl setzt, uÃàberrascht Sie nicht . ‚ÄûWenn ich gewinne‚Äú, f√§hrt der Statistiker fort, ‚Äûbekomme ich 10 Euro von Dir, wenn Du gewinnst, bekommst Du 11 Euro von mir. Gutes Spiel, oder?‚Äú. Sie einigen sich auf 10 Durchg√§nge, in denen der Statistiker jedes Mal eine MuÃànze wirft, f√§ngt und dann die oben liegende Seite pruÃàft. Erster Wurf: Zahl! Der Statistiker gewinnt. Pech fuÃàr Sie. Zweiter Wurf: Zahl! Schon wieder 10 Euro fuÃàr den Statistiker. Hm. Dritter Wurf: . . . Zahl! Schon wieder. Aber kann ja passieren, bei einer fairen MuÃànze, oder? Vierter Wurf: Zahl! Langsam regen sich Zweifel bei Ihnen. Kann das noch mit rechten Dingen zugehen? Ist die MuÃànzewirklich fair? Insgesamt gewinnt der zwielichte Statistiker 8 von 10 Durchg√§ngen.\nUnter leisem Gel√§chter des Statistikers (und mit leeren Taschen) machen Sie sich von dannen. Hat er falsch gespielt? Wie plausibel ist es, bei 10 W√ºrfen 8 Treffer zu erhalten, wenn die M√ºnze fair ist? Ist das ein h√§ufiges, ein typisches Ereignis oder ein seltenes, untypisches Ereignis bei einer fairen M√ºnze? Wenn es ein einigerma√üen h√§ufiges Ereignis sein sollte, dann spricht das f√ºr die Fairness der M√ºnze. Zumindest spricht ein Ereignis, welches von einer Hypothese als h√§ufig vorausgesagt wird und schlie√ülich eintritt, nicht gegen eine Hypothese. Zuhause angekommen, denken Sie sich, jetzt m√ºssen Sie erstmal in Ruhe die Posteriori-Verteilung und die PPV ausrechnen!\n\nBerechnen Sie die Posteriori-Verteilung mit der Gittermethode! Gehen Sie von einer gleichverteilten Priori-Wahrscheinlichkeit aus. Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\nWie gro√ü ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die M√ºnze zugunsten des Dozenten gezinkt ist?\nGeben Sie das 50%-PI und 50%-HDPI zum Parameterwert (\\(p\\) der M√ºnze) an!\nMit welcher Wahrscheinlichkeit liegt die Trefferchance der M√ºnze zwischen \\(p=.45\\) und \\(p=.55\\), ist also nicht ‚Äúnennenswert‚Äù gezinkt?\nWas ist der wahrscheinlichste Parameterwert (Trefferchance der M√ºnze)?\nGeben Sie das 90%-PI und 90%-HDI zu Parameterwert (\\(p\\) der M√ºnze) an!\nBerechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\nDiskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von \\(p\\)!\n\n         \n\n\nSolution\n\nBerechnen Sie die Posteriori-Verteilung mit der Gittermethode! Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\n\n\np_grid &lt;- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior &lt;- rep( 1 , 1000 )  # Priori-Gewichte\n\nlikelihood &lt;- dbinom(8, size = 10, prob=p_grid) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples &lt;- \n  tibble(\n    gewinnchance_muenze = sample(p_grid , prob=posterior, size=1e4, replace=TRUE))\n\nVisualisierung:\n\nsamples %&gt;% \n  ggplot() +\n  aes(x = gewinnchance_muenze) +\n  geom_histogram() +\n  labs(title = \"Posterior-Verteilung\",\n       x = \"Gewinnchance der M√ºnze (50%: faire M√ºnze)\")\n\n\n\n\n\n\n\n\n\nWie gro√ü ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die M√ºnze zugunsten des Dozenten gezinkt ist?\n\n\nsamples %&gt;% \n  count(gewinnchance_muenze &gt; .5) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n\n\ngewinnchance_muenze &gt; 0.5\nn\nprop\n\n\n\n\nFALSE\n310\n0.03\n\n\nTRUE\n9690\n0.97\n\n\n\n\n\n\n\nGeben Sie das 50%-PI (Perzentilintervall) und 50%-HDI zum Parameterwert (\\(p\\) der M√ºnze) an!\n\n\nlibrary(easystats)\neti(samples, ci = .5)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\ngewinnchance_muenze\n0.5\n0.67\n0.84\n\n\n\n\n\nhdi(samples, ci = .5)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\ngewinnchance_muenze\n0.5\n0.72\n0.88\n\n\n\n\n\n\nEin PI wird auch equal tail interval genannt, weil die beiden ‚Äúabgeschnitten Randbereiche‚Äù links und rechts die gleichen Fl√§chenanteil (Wahrscheinlichkeitsmasse) aufweisen.\nInteresant ist, dass das PI und das HDI zu unterschiedlichen Ergebnissen kommen. Das l√§sst auf eine schiefe Verteilung schlie√üen. Au√üerdem er√∂ffnet es den Raum zur Diskussion, welches Intervall man berichtet. Um diese Frage besser zu verstehen, k√∂nnen wir die Intervalle visualisieren.\nBonus: Visualisieren wir die Intervalle:\nPI:\n\neti(samples, ci = .5) %&gt;% plot()\n\n\n\n\n\n\n\n\nHDI:\n\nhdi(samples, ci = .5) %&gt;% plot()\n\n\n\n\n\n\n\n\nDas HDI ist schm√§ler und liegt n√§her am Modus. Vermutlich ist das HDI zu bevorzugen.\n\nMit welcher Wahrscheinlichkeit liegt die Trefferchance der M√ºnze zwischen \\(p=.45\\) und \\(p=.55\\), ist also nicht ‚Äúnennenswert‚Äù gezinkt (auf Basis unserer Modellannahmen)?\n\n\nsamples %&gt;% \n  count(gewinnchance_muenze &gt;= 0.45 & gewinnchance_muenze &lt;= .55) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n\n\ngewinnchance_muenze &gt;= 0.45 & gewinnchance_muenze &lt;= 0.55\nn\nprop\n\n\n\n\nFALSE\n9522\n0.95\n\n\nTRUE\n478\n0.05\n\n\n\n\n\n\nDie Wahrscheinlichkeit, dass die M√ºnze nicht nennenswert gezinkt ist (nach unserer Definition), ist gering. Man sollte vielleicht erw√§hnen, dass unsere Definition von ‚Äúnicht nennenswert gezinkt‚Äù plausibel ist, und andere (vern√ºnftige) Definitionen zu einem sehr √§hnlichen Ergebnis k√§men.\n\nWas ist der wahrscheinlichste Parameterwert (Trefferchance der M√ºnze)?\n\n\nsamples %&gt;% \n   map_estimate()\n\n\n\n\n\nParameter\nMAP_Estimate\n\n\n\n\ngewinnchance_muenze\n0.8\n\n\n\n\n\n\nmap_estimate steht f√ºr ‚Ä¶\n\nFind the Highest Maximum A Posteriori probability estimate (MAP) of a posterior, i.e., the value associated with the highest probability density (the ‚Äúpeak‚Äù of the posterior distribution). In other words, it is an estimation of the mode for continuous parameters.\n\n(aus der Hilfeseite der Funktion)\n\nGeben Sie das 90%-PI und 90%-HDI zum Parameterwert (\\(p\\) der M√ºnze) an!\n\n\nlibrary(easystats)\neti(samples, ci = .9)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\ngewinnchance_muenze\n0.9\n0.53\n0.92\n\n\n\n\n\nhdi(samples, ci = .9)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\ngewinnchance_muenze\n0.9\n0.57\n0.95\n\n\n\n\n\n\n\nBerechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\n\n\nPPV &lt;-\n  samples %&gt;% \n  mutate(anzahl_kopf = rbinom(n = 1e4, size = 10, prob = gewinnchance_muenze))\n\nVisualisierung:\n\nPPV %&gt;% \n  ggplot() +\n  aes(x = anzahl_kopf) +\n  labs(title = \"PPV\") +\n  geom_bar()  # geom_bar() ginge auch, sieht aber bei wenig Balken nicht so gut aus.\n\n\n\n\n\n\n\n\nLaut der PPV sind 8 von 10 Treffern der Wert, der mit der h√∂chsten Wahrscheinlichkeit zu beobachten sein wird. Allerdings sind 7 oder 9 Treffer fast genauso wahrscheinlich. Etwas genauer:\n\nPPV %&gt;% \n  count(between(anzahl_kopf, 7,9))   # \"z√§hle mir, wie oft ein Wert ZWISCHEN (between) 7 und 9 vorkommt\"\n\n\n\n\n\nbetween(anzahl_kopf, 7, 9)\nn\n\n\n\n\nFALSE\n3902\n\n\nTRUE\n6098\n\n\n\n\n\n\nMit dieser Wahrscheinlichkeit ist ein Wert zwischen 7 und 9 zu beobachten, wenn man den Versuch wiederholt, laut dem Modell.\n\nPPV %&gt;% \n  eti(anzahl_kopf, ci = .9)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\ngewinnchance_muenze\n0.9\n0.53\n0.92\n\n\nanzahl_kopf\n0.9\n4.00\n10.00\n\n\n\n\n\n\nUnser Modell sieht einen ‚ÄúPassungsbereich‚Äù (ein Perzentilintervall) von 4 bis 10 Treffern als mit 90% Wahrscheinlichkeit passend an.\n\nDiskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von \\(p\\)!\n\nZwar hat eine Gleichverteilung der Priori-Werte den Vorteil, dass sie ‚Äúobjektiv‚Äù ist in dem Sinne, dass kein Wert ‚Äúbevorteilt‚Äù wird; alle gelten als gleich wahrscheinlich. Aber das ist hochgradig unplausibel: So ist z.B. der Wert \\(p=1\\) logisch unm√∂glich, da wir nicht nur Treffer beobachtet haben. Ein Wert von z.B. \\(p=0.999\\) erscheint uns ebenfalls sehr unwahrscheinlich. N√ºtzlicher erscheint daher vielleicht doch eine Priori-Verteilung, die extreme Werte von \\(p\\) als unwahrscheinlich bemisst.\n\nCategories:\n\nbayes\nprobability\nppv"
  },
  {
    "objectID": "posts/Streudiagramm/Streudiagramm.html",
    "href": "posts/Streudiagramm/Streudiagramm.html",
    "title": "Streudiagramm",
    "section": "",
    "text": "-.90\n0\n+.90\n1\n-1"
  },
  {
    "objectID": "posts/Streudiagramm/Streudiagramm.html#answerlist",
    "href": "posts/Streudiagramm/Streudiagramm.html#answerlist",
    "title": "Streudiagramm",
    "section": "",
    "text": "-.90\n0\n+.90\n1\n-1"
  },
  {
    "objectID": "posts/Streudiagramm/Streudiagramm.html#answerlist-1",
    "href": "posts/Streudiagramm/Streudiagramm.html#answerlist-1",
    "title": "Streudiagramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/penguins-vis-bodymass2/index.html",
    "href": "posts/penguins-vis-bodymass2/index.html",
    "title": "penguins-vis-bodymass2",
    "section": "",
    "text": "Aufgabe\nIm Datensatz palmerpenguins: Ist der Zusammenhang zwischen K√∂rpergewicht und Schnabelh√∂he (bill depth) (vgl. Schemazeichnung hier) gr√∂√üer, wenn man den Zusammenhang getrennt f√ºr jede Spezies betrachtet?\nBeantworten Sie diese Frage mit Hilfe einer Visualisierung!\nSie k√∂nnen den Datensatz so beziehen:\n\n#install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(\"penguins\")\nd &lt;- penguins \n\nOder so:\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nEin Codebook finden Sie hier.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie das R-Paket ggpubr zur Visualisierung. Dort finden Sie einen Befehl namens ggscatter(datensatz, x-variable, y_variable, facet_by), mit dem Sie Streudiagramme aufgeteilt nach (‚Äúfacettiert nach‚Äù) einer (nominal skalierten) Gruppierungsvariablen erstellen k√∂nnen.\n\n\n\nL√∂sung\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\nd |&gt; \n  ggscatter(x = \"bill_depth_mm\", y = \"body_mass_g\", facet.by = \"species\")\n\n\n\n\n\n\n\n\nUnd jetzt erstellen wir das Streudiagramm ohne Aufteilung in die Gruppen von species:\n\nggscatter(d, x = \"bill_depth_mm\", y = \"body_mass_g\")\n\n\n\n\n\n\n\n\nWie man sieht, tritt der Zusammenhang klarer hervor, wenn man die Daten in die von species definierten Gruppen aufteilt."
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html",
    "href": "posts/filter-na5/filter-na5.html",
    "title": "filter-na5",
    "section": "",
    "text": "Z√§hlen Sie fehlende Werte im Datensatz penguins zeilenweise."
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html#setup",
    "href": "posts/filter-na5/filter-na5.html#setup",
    "title": "filter-na5",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\nnrow(d)\n\n[1] 344"
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html#weg-1",
    "href": "posts/filter-na5/filter-na5.html#weg-1",
    "title": "filter-na5",
    "section": "Weg 1",
    "text": "Weg 1\n\napply(d, 1, function(x) sum(is.na(x)))\n\n  [1] 0 0 0 5 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n[186] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n[223] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n[260] 0 0 0 0 0 0 0 0 0 1 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[297] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[334] 0 0 0 0 0 0 0 0 0 0 0"
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html#weg-2",
    "href": "posts/filter-na5/filter-na5.html#weg-2",
    "title": "filter-na5",
    "section": "Weg 2",
    "text": "Weg 2\n\nd_na_only &lt;- \n  d %&gt;% \n  rowwise() %&gt;% \n  mutate(na_n = sum(is.na(cur_data()))) %&gt;%  # \"na_n\" f√ºr \"Anzahl (n) NA\"\n  ungroup()\n\nd_na_only %&gt;% \n  pull(na_n)\n\n  [1] 0 0 0 5 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n[186] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n[223] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n[260] 0 0 0 0 0 0 0 0 0 1 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[297] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[334] 0 0 0 0 0 0 0 0 0 0 0"
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html#weg-3",
    "href": "posts/filter-na5/filter-na5.html#weg-3",
    "title": "filter-na5",
    "section": "Weg 3",
    "text": "Weg 3\n\nrowSums(is.na(d))\n\n  [1] 0 0 0 5 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n[186] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n[223] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n[260] 0 0 0 0 0 0 0 0 0 1 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[297] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[334] 0 0 0 0 0 0 0 0 0 0 0"
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html#weg-4",
    "href": "posts/filter-na5/filter-na5.html#weg-4",
    "title": "filter-na5",
    "section": "Weg 4",
    "text": "Weg 4\nDer folgende Weg funktioniert nur, wenn alle Variablen vom Typ numeric sind.\n\nd %&gt;% \n  rowwise() %&gt;% \n  mutate(na_n = sum(is.na(c_across(everything()))))\n\nError in `mutate()`:\n‚Ñπ In argument: `na_n = sum(is.na(c_across(everything())))`.\n‚Ñπ In row 1.\nCaused by error in `vec_c()`:\n! Can't combine `rownames` &lt;double&gt; and `species` &lt;character&gt;."
  },
  {
    "objectID": "posts/filter-na5/filter-na5.html#weg-5",
    "href": "posts/filter-na5/filter-na5.html#weg-5",
    "title": "filter-na5",
    "section": "Weg 5",
    "text": "Weg 5\nWir definieren eine Funktion, die die NAs des Vektors x z√§hlt:\n\nsum_na &lt;- function(x) {sum(is.na(x))}\n\nDiese Funktion ‚Äúmappen‚Äù wir wir auf jede Spalte (und lassen uns einen numerischen Vektor dbl (‚Äúdouble‚Äù) zur√ºckgeben):\n\nd |&gt; \n  map_dbl(sum_na)\n\n         rownames           species            island    bill_length_mm \n                0                 0                 0                 2 \n    bill_depth_mm flipper_length_mm       body_mass_g               sex \n                2                 2                 2                11 \n             year \n                0 \n\n\n\nCategories:\n\n2023\neda\nna\nstring"
  },
  {
    "objectID": "posts/anova-skalenniveau/anova-skalenniveau.html",
    "href": "posts/anova-skalenniveau/anova-skalenniveau.html",
    "title": "anova-skalenniveau",
    "section": "",
    "text": "Die Varianzanalyse (ANOVA) ist ein inferenzstatistisches Verfahren des Frequentismus. Welches Skalenniveau passt zu diesem Verfahren?\n\n\n\nUV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/anova-skalenniveau/anova-skalenniveau.html#answerlist",
    "href": "posts/anova-skalenniveau/anova-skalenniveau.html#answerlist",
    "title": "anova-skalenniveau",
    "section": "",
    "text": "UV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/anova-skalenniveau/anova-skalenniveau.html#answerlist-1",
    "href": "posts/anova-skalenniveau/anova-skalenniveau.html#answerlist-1",
    "title": "anova-skalenniveau",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nvariable-levels\nanova"
  },
  {
    "objectID": "posts/purrr-map02/purrr-map02.html",
    "href": "posts/purrr-map02/purrr-map02.html",
    "title": "purrr-map02",
    "section": "",
    "text": "Exercise\nBestimmen Sie die h√§ufigsten Worte im Grundatzprogramm der Partei AfD (in der aktuellsten Version).\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nText aus PDF-Dateien kann man mit dem Paket pdftools einlesen:\n\nlibrary(pdftools)\nd_path &lt;- \"~/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf\"\n\nd &lt;- tibble(text = pdf_text(d_path))\n\nDann erstellen wir eine Tidy-Version und tokenisieren nach W√∂rtern:\n\nlibrary(tidytext)\nd2 &lt;-\n  d %&gt;% \n  unnest_tokens(output = word, input = text)\n\nhead(d2)\n\n\n\n\n\nword\n\n\n\n\nprogramm\n\n\nf√ºr\n\n\ndeutschland\n\n\ndas\n\n\ngrundsatzprogramm\n\n\nder\n\n\n\n\n\n\nDann z√§hlen wir die W√∂rter:\n\nd2 %&gt;% \n  count(word, sort = TRUE) %&gt;% \n  head(20)\n\n\n\n\n\nword\nn\n\n\n\n\ndie\n1151\n\n\nund\n1147\n\n\nder\n870\n\n\nzu\n435\n\n\nf√ºr\n392\n\n\nin\n392\n\n\nden\n271\n\n\nvon\n257\n\n\nist\n251\n\n\ndas\n225\n\n\nwerden\n214\n\n\neine\n211\n\n\nnicht\n196\n\n\nein\n191\n\n\ndeutschland\n190\n\n\nsind\n187\n\n\nwir\n176\n\n\nafd\n171\n\n\ndes\n169\n\n\nsich\n158\n\n\n\n\n\n\n\nCategories:\n\nR\nmap\ntidyverse"
  },
  {
    "objectID": "posts/diamonds-histogram/diamonds-histogram.html",
    "href": "posts/diamonds-histogram/diamonds-histogram.html",
    "title": "diamonds-histogram",
    "section": "",
    "text": "Die Daten beziehen sich auf den Datensatz diamonds und sind hier einzusehen bzw. k√∂nnen bei Interesse dort heruntergeladen werden.\n\n\n\n\n\n\n\n\n\nAuf der X-Achse ist eine nominalskalierte Variable abgetragen.\nDer vertikale Strich in jedem Bild passt gut zur Position des insgesamten Medians.\nDie Variable cut ist eine intervallskalierte Variable.\nAuf der x-Achse werden H√§ufigkeiten abgetragen.\nDie Gruppierungsvariable cut wird hier als ordinale Variable, also mit Ordnungsstruktur, verwendet."
  },
  {
    "objectID": "posts/diamonds-histogram/diamonds-histogram.html#answerlist",
    "href": "posts/diamonds-histogram/diamonds-histogram.html#answerlist",
    "title": "diamonds-histogram",
    "section": "",
    "text": "Auf der X-Achse ist eine nominalskalierte Variable abgetragen.\nDer vertikale Strich in jedem Bild passt gut zur Position des insgesamten Medians.\nDie Variable cut ist eine intervallskalierte Variable.\nAuf der x-Achse werden H√§ufigkeiten abgetragen.\nDie Gruppierungsvariable cut wird hier als ordinale Variable, also mit Ordnungsstruktur, verwendet."
  },
  {
    "objectID": "posts/diamonds-histogram/diamonds-histogram.html#answerlist-1",
    "href": "posts/diamonds-histogram/diamonds-histogram.html#answerlist-1",
    "title": "diamonds-histogram",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nschoice"
  },
  {
    "objectID": "posts/tmdb05/tmdb05.html",
    "href": "posts/tmdb05/tmdb05.html",
    "title": "tmdb05",
    "section": "",
    "text": "Melden Sie sich an f√ºr die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?.\nSie ben√∂tigen dazu ein Konto; es ist auch m√∂glich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Pr√§diktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verf√ºgung. Eine klassische ‚Äúpredictive Competition‚Äù also :-) Allerdings k√∂nnen immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Boosting-Modell mit Tidymodels!\nHinweise\n\n\nF√ºr den Start empfehle ich, etwaige Vorverarbeitung erstmal klein zu halten. Nach dem Motto: Erstmal das Modell zum Laufen kriegen, dann erst verbessern.\nTunen Sie die typischen Parameter.\nReichen Sie das Modell bei Kaggle ein und berichten Sie Ihren Score.\nIm √úbrigen sind Sie frei in Ihrem Vorgehen."
  },
  {
    "objectID": "posts/tmdb05/tmdb05.html#rezept-checken",
    "href": "posts/tmdb05/tmdb05.html#rezept-checken",
    "title": "tmdb05",
    "section": "Rezept checken",
    "text": "Rezept checken\n\nd_train_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_train_baked\n\nViele Modelle k√∂nnen nicht arbeiten mit nominalen Pr√§diktoren oder mit fehlenden Werten. Daher sollte man im Rezept diese Fehler vorab abfangen.\nEin letzter Blick:\n\ndescribe_distribution(d_train_baked)\n\nSieht ok aus."
  },
  {
    "objectID": "posts/rope3a/index.html",
    "href": "posts/rope3a/index.html",
    "title": "rope3a",
    "section": "",
    "text": "Einer der (bisher) gr√∂√üten Studien der Untersuchung psychologischer Konsequenzen (oder Korrelate) der Covid-Zeit ist die Studie COVIDiStress.\nIm Folgenden sollen Sie folgende Forschungsfrage untersuchen:\nIst der Zusammenhang von Stress (PSS10_avg, AV) und Neurotizismus (neu, UV) vernachl√§ssigbar klein?\nDen Datensatz k√∂nnen Sie so herunterladen (Achtung, gro√ü):\n\nosf_d_path &lt;- \"https://osf.io/cjxua/?action=download\"\n\nd &lt;- read_csv(osf_d_path)\n\nPakete laden:\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\nRelevante Spalten ausw√§hlen:\n\nd2 &lt;-\n  d %&gt;% \n  select(PSS10_avg, neu)\n\nDatensatz aufbereiten:\n\nd3 &lt;-\n  d2 %&gt;% \n  drop_na()\n\nModell berechnen:\n\nm1 &lt;-\n  stan_glm(PSS10_avg ~ neu, \n           refresh = 0,\n           seed = 42,\n           data = d3)\n\nModellkoeffizienten auslesen:\n\ncoef(m1)\n\n(Intercept)         neu \n  1.4533911   0.3509393 \n\n\nPosteriori-Verteilung auslesen:\n\nparameters(m1, ci = .89)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n1.4533911\n0.89\n1.4428916\n1.463608\n1\n0.9999767\n4301.909\nnormal\n2.625455\n1.841433\n\n\nneu\n0.3509393\n0.89\n0.3480155\n0.353949\n1\n0.9997235\n4475.252\nnormal\n0.000000\n1.747465\n\n\n\n\n\n\nWarum 89%? Kein besonderer Grund. Aber ich mag Primzahlen :-)\nPosteriori-Verteilung plotten:\n\nplot(parameters(m1, ci = .89), show_intercept = TRUE)\n\n\n\n\n\n\n\n\nRope berechnen:\n\nrope_m1 &lt;- rope(m1)\nrope_m1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-0.0736573\n0.0736573\n0\nfixed\nconditional\n\n\nneu\n0.95\n-0.0736573\n0.0736573\n0\nfixed\nconditional\n\n\n\n\n\n\nRope visualisieren:\n\nplot(rope_m1)\n\n\n\n\n\n\n\n\nAufgabe: W√§hlen Sie die am besten passende Antwortoption!\nAntwortoptionen\n\n\n\nJa\nNein\nDie Daten sind inkonkludent; es ist eine unklare Befundlage.\nAuf Basis der bereitgestellten Informationen ist keine Antwort m√∂glich."
  },
  {
    "objectID": "posts/rope3a/index.html#answerlist",
    "href": "posts/rope3a/index.html#answerlist",
    "title": "rope3a",
    "section": "",
    "text": "Ja\nNein\nDie Daten sind inkonkludent; es ist eine unklare Befundlage.\nAuf Basis der bereitgestellten Informationen ist keine Antwort m√∂glich."
  },
  {
    "objectID": "posts/rope3a/index.html#answerlist-1",
    "href": "posts/rope3a/index.html#answerlist-1",
    "title": "rope3a",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr. ROPE ist zu verwerfen, damit sind Werte um die Null herum nicht wahrscheinlich.\nFalsch\nFalsch\n\n\nCategories:\n\nrope\nbayes"
  },
  {
    "objectID": "posts/dplyr-mtcars01/index.html",
    "href": "posts/dplyr-mtcars01/index.html",
    "title": "dplyr-mtcars1",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mtcars:\nGruppieren Sie den Datensatz in Autos mit bzw. ohne Automatikgetriebe.\nGeben Sie dann an, wieviel PS das Automatik-Auto mit der h√∂chsten PS-Zahl hat.\nGeben Sie diese Zahl als Antwort zur√ºck!\nHinweise:\n\nDer Datensatz mtcars ist in R ‚Äúfest eingebaut‚Äù. Sie k√∂nnen ihn mit dem Befehl data(mtcars) verf√ºgbar machen. Ein Herunterladen ist nicht n√∂tig.\nHilfe zu einem Datensatz (oder einem anderen Objekt) bekommen Sie in R mit dem Befehl help(name_des_objekts).\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\ndata(mtcars)\n\nZusammenfassen:\n\nmtcars |&gt; \n  group_by(am) |&gt; \n  summarise(max_ps = max(hp))\n\n# A tibble: 2 √ó 2\n     am max_ps\n  &lt;dbl&gt;  &lt;dbl&gt;\n1     0    245\n2     1    335\n\n\nDie L√∂sung lautet: 245 PS.\nAus der Hilfeseite k√∂nnen wir ablesen:\n\n[, 9] am Transmission (0 = automatic, 1 = manual)"
  },
  {
    "objectID": "posts/tidymodels-remove-na2/tidymodels-remove-na2.html",
    "href": "posts/tidymodels-remove-na2/tidymodels-remove-na2.html",
    "title": "tidymodels-remove-na2",
    "section": "",
    "text": "Aufgabe\n\nDas folgende Rezept ist gedacht, fehlende Werte aus dem Datensatz penguins zu entfernen. Allerdings erf√ºllt es diese Aufgabe nicht.\nFinden Sie den Fehler und korrigieren Sie das Rezept.\nHinweise:\n\nVerwenden Sie tidymodels.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nL√∂sung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d) |&gt; \n  step_naomit() \n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n\ndescribe_distribution(d_train_baked)\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/twitter04/twitter04.html",
    "href": "posts/twitter04/twitter04.html",
    "title": "twitter04",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=2\\)) via der Twitter API; Suchterm soll sein ‚Äú(karl_lauterbach?)‚Äù. Bereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopw√∂rter entfernen, Zahlen entfernen, ‚Ä¶). Berichten Sie dann die 10 h√§ufigsten W√∂rter als Sch√§tzer f√ºr die Dinge, die an Karl Lauterbach getweetet werden.\n         \n\n\nSolution\n\nlibrary(rtweet)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(lsa)  # Stopw√∂rter\nlibrary(SnowballC)  # Stemming\n\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\n\nkarl1 &lt;- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(karl1, file = \"karl1.rds\", compress = \"gz\")\n\n\nkarl2 &lt;- \n  karl1 %&gt;% \n  select(full_text)\n\n\nkarl3 &lt;- \n  karl2 %&gt;% \n  unnest_tokens(output = word, input = full_text)\n\n\nkarl4 &lt;- \nkarl3 %&gt;% \n  anti_join(tibble(word = lsa::stopwords_de)) \n\n\nkarl5 &lt;- \n  karl4 %&gt;% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %&gt;% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %&gt;% \n  mutate(word = str_replace_na(word, \" +\")) %&gt;% \n  drop_na()\n\n\nkarl6 &lt;-\n  karl5 %&gt;% \n  mutate(word = wordStem(word))\n\n\nkarl6 %&gt;% \n  count(word, sort = TRUE) %&gt;% \n  slice_head(n=10)\n\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/n-vars-diagram/n-vars-diagram.html",
    "href": "posts/n-vars-diagram/n-vars-diagram.html",
    "title": "n-vars-diagram",
    "section": "",
    "text": "Aufgabe\nWie viele Variablen sind in folgendem Diagramm dargestellt?\nDie Daten beziehen sich au den Datensatz mtcars; hier finden Sie Informationen zu dem Datensatz. Er ist in R ‚Äúfest eingebaut‚Äù, also direkt verf√ºgbar und muss daher nicht explizit geladen werden.\n\n\n\n\n\n\n\n\n\n         \n\n\nL√∂sung\nEs sind 5 Variablen abgebildet:\n\nhp\nmpg\nam\ncyl\nvs\n\n\nCategories:\n\nvis\n‚Äò2023‚Äô\nnum"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html",
    "href": "posts/ttest-als-regr/ttest-als-regr.html",
    "title": "ttest-als-regression",
    "section": "",
    "text": "Der t-Test kann als Spezialfall der Regressionsanalyse gedeutet werden. Der t-Test ist ein Verfahren, der die Mittelwerte zweier Gruppen miteinander vergleicht.\nHierbei ist es wichtig, sich das Skalenniveau der Variablen, die ein t-Test verarbeitet, vor Augen zu f√ºhren.\nHinweisse:\n\nDie folgende Abbildung gibt Tipps.\nInformationen, die zur L√∂sung einer Aufgabe nicht n√∂tig sind, sollte man ignorieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenennen Sie die Skalenniveaus der UV eines t-Tests (X-Achse im Diagramm)! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nBenennen Sie die Skalenniveaus der AV eines t-Tests (Y-Achse im Diagramm)! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nNennen Sie eine beispielhafte Forschungsfrage f√ºr einen t-Test.\nSkizzieren Sie ein Diagramm einer Regression, die analytisch identisch (oder sehr √§hnlich) zu einem t-Test ist!"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html#answerlist",
    "href": "posts/ttest-als-regr/ttest-als-regr.html#answerlist",
    "title": "ttest-als-regression",
    "section": "",
    "text": "Benennen Sie die Skalenniveaus der UV eines t-Tests (X-Achse im Diagramm)! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nBenennen Sie die Skalenniveaus der AV eines t-Tests (Y-Achse im Diagramm)! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nNennen Sie eine beispielhafte Forschungsfrage f√ºr einen t-Test.\nSkizzieren Sie ein Diagramm einer Regression, die analytisch identisch (oder sehr √§hnlich) zu einem t-Test ist!"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html#answerlist-1",
    "href": "posts/ttest-als-regr/ttest-als-regr.html#answerlist-1",
    "title": "ttest-als-regression",
    "section": "Answerlist",
    "text": "Answerlist\n\nUV: bin√§r\nAV: metrisch\nUnterscheiden sich die mittleren Einparkzeiten von Frauen und M√§nnern?\nAus dem Datensatz mtcars:\n\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nregression\nttest\nvariable-levels"
  },
  {
    "objectID": "posts/prob-sicher-unmoÃàglich/index.html",
    "href": "posts/prob-sicher-unmoÃàglich/index.html",
    "title": "prob-sicher-unm√∂glich",
    "section": "",
    "text": "1 Aufgabe\nBeim Werfen eines W√ºrfels betrachten wir die folgenden Ereignisse:\nEreignis A: Es f√§llt eine Zahl kleiner als 7.\nEreignis B: Es f√§llt eine Zahl gr√∂√üer als 6.\nWelche Begriffe beschreiben A und B in dieser Reihenfolge?\n\nUnm√∂gliches Ereignis; Sicheres Ereignis\nElementarereignis; Sicheres Ereignis\nSicheres Ereignis; Unm√∂gliches Ereignis\nSicheres Ereignis; Disjunktes Ereignis\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\nSicheres Ereignis; Unm√∂gliches Ereignis"
  },
  {
    "objectID": "posts/exp2/index.html",
    "href": "posts/exp2/index.html",
    "title": "exp2",
    "section": "",
    "text": "1 Aufgabe\nSei \\(X \\sim \\text{Exp}(1)\\).\nWelche der Aussagen ist richtig?\n\nJe gr√∂√üer lambda, desto gr√∂√üer der Mittelwert der Verteilung.\nlambda ist unabh√§ngig vom Mittelwert der Verteilung.\nJe gr√∂√üer lambda, desto kleiner der Mittelwert der Verteilung.\nDie Verteilung hat keinen Mittelwert.\nKeine der genannten Antworten ist richtig.\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nC"
  },
  {
    "objectID": "posts/einhoerner-fliegen/index.html",
    "href": "posts/einhoerner-fliegen/index.html",
    "title": "einhoerner-fliegen",
    "section": "",
    "text": "1 Aufgabe\nSei \\(A\\): ‚ÄúSophia ist ein Einhorn‚Äù. Und sei \\(B\\): ‚ÄúEinh√∂rner k√∂nnen (alle) fliegen‚Äù.\nWas ist \\(Pr(B|A)\\) ?\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\nDarauf ist keine Antwort im Sinne einer Wahrscheinlichkeitsaussage m√∂glich:\nWie hoch die Wahrscheinlichkeit ist, dass Einh√∂rner fliegen k√∂nnen gegeben, dass Sophia ein Einhorn ist. Tja, nur die Tatsache allein, dass Sophie ein Einhorn ist, belegt keineswegs, dass Einh√∂rner fliegen k√∂nnen."
  },
  {
    "objectID": "posts/subjektiv-Bayes/subjektiv-Bayes.html",
    "href": "posts/subjektiv-Bayes/subjektiv-Bayes.html",
    "title": "subjektiv-Bayes",
    "section": "",
    "text": "Exercise\nNennen Sie einen Aspekte der bayesianischen Analyse, der (in Teilen) subjektiv ist - abgesehen von der Wahl der Priori-Verteilung.\n         \n\n\nSolution\n\nLinearit√§tsannahme in (linearen) Modellen\nWahl des Likelihoods\nWahl der Daten\nMethoden der Modellpr√ºfung\nGeneralisierung des Modells auf andere Situationen\nWahl der Pr√§diktoren\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/Tengku-Hanis01/Tengku-Hanis01.html",
    "href": "posts/Tengku-Hanis01/Tengku-Hanis01.html",
    "title": "Tengku-Hanis01",
    "section": "",
    "text": "Aufgabe\nBearbeiten Sie diese Fallstudie von Tengku Hanis!\n         \n\n\nL√∂sung\nDie folgende L√∂sung basiert auf der oben angegebenen Fallstudie.\nPakete laden:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(finetune)\n\nDaten importieren:\n\ndata(income, package = \"kernlab\")\n\nDatensatz vereinfachen:\n\nset.seed(2021)\nincome2 &lt;- \n  income %&gt;% \n  filter(INCOME == \"[75.000-\" | INCOME == \"[50.000-75.000)\") %&gt;% \n  slice_sample(n = 600) %&gt;% \n  mutate(INCOME = fct_drop(INCOME), \n         INCOME = fct_recode(INCOME, \n                             rich = \"[75.000-\",\n                             less_rich = \"[50.000-75.000)\"), \n         INCOME = factor(INCOME, ordered = F)) %&gt;% \n  mutate(across(-INCOME, fct_drop))\n\nCheck:\n\nDataExplorer::plot_missing(income)\n\n\n\n\n\n\n\n\n{DataExplorer} sieht nach einem n√ºtzlichen Paket aus. Check it out hier!\nDaten aufteilen (‚ÄúSpending our data budget‚Äù):\n\nset.seed(2021)\ndat_index &lt;- initial_split(income2, strata = INCOME)\ndat_train &lt;- training(dat_index)\ndat_test &lt;- testing(dat_index)\n\nKreuzvalidierung:\n\nset.seed(2021)\ndat_cv &lt;- vfold_cv(dat_train, v = 10, repeats = 1, strata = INCOME)\n\nRezept:\n\ndat_rec &lt;- \n  recipe(INCOME ~ ., data = dat_train) %&gt;% \n  step_impute_mode(all_predictors()) %&gt;% \n  step_ordinalscore(AGE, EDUCATION, AREA, HOUSEHOLD.SIZE, UNDER18)\n\nAls Modell (im engeren Sinne) nutzen wir ein Random-Forest-Modell:\n\nrf_mod &lt;- \n  rand_forest(mtry = tune(),\n              trees = tune(),\n              min_n = tune()) %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"ranger\")\n\nWie man sieht, geben wir 3 Tuningparameter an.\nModell und Rezept zum Workflow zusammenfassen:\n\nrf_wf &lt;- \n  workflow() %&gt;% \n  add_recipe(dat_rec) %&gt;% \n  add_model(rf_mod)\n\nTuning Grids definieren:\nWichtig ist, dass wir genau die Parameter angeben im Grid, die wir auch zum Tunen getaggt haben. Das kann man h√§ndisch erledigen:\n\n# Regular grid:\nreg_grid &lt;- grid_regular(mtry(c(1, 13)), \n                         trees(), \n                         min_n(), \n                         levels = 3)\n\n# Random grid mit 100 Kandidaten:\nrand_grid &lt;- grid_random(mtry(c(1, 13)), \n                         trees(), \n                         min_n(), \n                         size = 100)\n\nWir speichern die Vorhersagen aller Folds im Train-Sample, um die Modellg√ºte im Train- bzw. Validierungssample anschauen zu k√∂nnen:\n\nctrl &lt;- control_grid(save_pred = T,\n                     extract = extract_model)\n\nError: object 'extract_model' not found\n\nmeasure &lt;- metric_set(roc_auc)\n\nAu√üerdem haben wir als G√ºtema√ü roc_auc definiert.\nIn der Fallstudie wurde noch extract = extract_model bei control_grid() erg√§nzt. Das lassen wir der Einfachheit halber mal weg.\nParallelisieren auf mehreren Kernen, um Rechenzeit zu sparen:\n\nlibrary(doParallel)\n\n# Create a cluster object and then register: \ncl &lt;- makePSOCKcluster(4)\nregisterDoParallel(cl)\n\nWie viele CPUs hat mein Computer?\n\ndetectCores(logical = FALSE)\n\n[1] 4\n\n\nJetzt geht‚Äôs ab: Tuning und Fitting!\nHier das ‚Äúregul√§re Gitter‚Äù an Tuningkandidaten:\n\nset.seed(2021)\ntune_regular &lt;- \n  rf_wf %&gt;% \n  tune_grid(\n    resamples = dat_cv, \n    grid = reg_grid,         \n    control = ctrl, \n    metrics = measure)\n\nError: object 'ctrl' not found\n\nstopCluster(cl)\n\nDie Modellg√ºte im Vergleich zwischen den Tuning-Kandidaten kann man sich sch√∂n ausgeben lassen:\n\nautoplot(tune_regular)\n\nError: object 'tune_regular' not found\n\n\nGeht aber nur, wenn man oben gesagt hat, dass man die Predictions speichern m√∂chte.\nWelche Kandidatin war am besten:\n\nshow_best(tune_regular)\n\nError: object 'tune_regular' not found\n\n\nSo kann man sich die beste Kandidatin anschauen:\n\nshow_best(tune_regular) %&gt;% \n  arrange(-mean) %&gt;% \n  slice(1)\n\nError: object 'tune_regular' not found\n\n\nAber man kann sich auch von Tidymodels einfach die beste Kandidatin sagen lassen:\n\nbest_rf &lt;-\n  select_best(tune_regular, \"roc_auc\")\n\nError: object 'tune_regular' not found\n\n\nAuf dieser Basis k√∂nnen wir jetzt den Workflow finalisieren, also die Tuningparameter einf√ºllen:\n\nfinal_wf &lt;- \n  rf_wf %&gt;% \n  finalize_workflow(best_rf)\n\nError: object 'best_rf' not found\n\nfinal_wf\n\nError: object 'final_wf' not found\n\n\nUnd mit diesen Werten den ganzen Train-Datensatz fitten:\n\ntest_fit &lt;- \n  final_wf %&gt;%\n  last_fit(dat_index) \n\nError: object 'final_wf' not found\n\n\nWie gut ist das jetzt?\n\ntest_fit %&gt;%\n  collect_metrics()\n\nError: object 'test_fit' not found\n\n\n\nCategories:\n\ntidymodels\nprediction\nyacsda\nstatlearning\ntrees\nspeed\nstring"
  },
  {
    "objectID": "posts/kausal23/kausal23.html",
    "href": "posts/kausal23/kausal23.html",
    "title": "kausal23",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x6.\nAV: x5.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äú/‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n/\n{ x3, x4 }\n{ x1, x4 }\n{ x2, x6 }\n{ x5 }"
  },
  {
    "objectID": "posts/kausal23/kausal23.html#answerlist",
    "href": "posts/kausal23/kausal23.html#answerlist",
    "title": "kausal23",
    "section": "",
    "text": "/\n{ x3, x4 }\n{ x1, x4 }\n{ x2, x6 }\n{ x5 }"
  },
  {
    "objectID": "posts/kausal23/kausal23.html#answerlist-1",
    "href": "posts/kausal23/kausal23.html#answerlist-1",
    "title": "kausal23",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\nFalsch\n\nDieser DAG ist nicht ganz ein Gespenster-DAG. Es stimmt fast, dass man alle nicht-kausalen Pfade zumachen (blockieren) kann. Aber nicht ganz: Der Pfad von AV zu UV muss offen bleiben. Und dieser Pfad ist NICHT kausal in diesem DAG, da er in die falsche Richtung zeigt (von AV zu UV, was die falsche Richtung ist). Darum ist es ein ‚Äúbiasing path‚Äù, ein ‚Äúb√∂ser Pfad‚Äù. Aber man kann ihn nicht zumachen, da man keine Pfade mit UV oder AV zumachen kann. Insofern ist dieser DAG ein verlorener Fall. üëª\nEs ist also ein bisschen ein Spezialfall. Wie gesagt, der entscheidende Punkt ist, dass der Pfad ‚Äúx5 (AV) -&gt; x6 (UV)‚Äù nicht kausal ist.\nNat√ºrlich ist das Beispiel extrem; niemand w√ºrde so einen DAG spezifizieren (normalerweise). Es macht keinen Sinn, eine Theorie, die sagt ‚ÄúIch glaube, dass meine Ursache eigentliche die Wirkung ist‚Äù. ü§™\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz.html",
    "href": "posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz.html",
    "title": "griech-buchstaben-inferenz",
    "section": "",
    "text": "Exercise\nF√ºr Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; f√ºr Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollst√§ndigen Sie folgende Tabelle entsprechend!\n\n\n\n\n\nKennwert\nStatistik\nParameter\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\nNA\n\n\nMittelwertsdifferenz\n\\(\\bar{X}_1-\\bar{X}_2\\)\nNA\n\n\nStreuung\nsd\nNA\n\n\nAnteil\np\nNA\n\n\nKorrelation\nr\nNA\n\n\nRegressionsgewicht\nb\nNA\n\n\n\n\n\n         \n\n\nSolution\n\n\n\n\n\nKennwert\nStatistik\nParameter\n\n\n\n\nMittelwert\n\\[\\bar{X}\\]\n\\[\\mu\\]\n\n\nMittelwertsdifferenz\n\\[d=\\bar{X}_1-\\bar{X}_2\\]\n\\[\\mu_1\\]- \\[\\mu_2\\]\n\n\nStreuung\nsd\n\\[\\sigma\\]\n\n\nAnteil\np\n\\[\\pi\\]\n\n\nKorrelation\nr\n\\[\\rho\\]\n\n\nRegressionsgewicht\nb\n\\[\\beta\\]\n\n\n\n\n\n\nCategories:\n\nqm2\ninference\nparameters"
  },
  {
    "objectID": "posts/kausal24/kausal28.html",
    "href": "posts/kausal24/kausal28.html",
    "title": "kausal28",
    "section": "",
    "text": "library(dagitty)\nlibrary(ggdag)\nlibrary(ggplot2)\n\nGegeben sei der DAG (Graph) g (s. u.). Der DAG verf√ºgt √ºber mehrere Variablen, die als Knoten im Graph dargestellt sind.\n\ng &lt;-\n  dagify(\n    y ~ z + m,\n    m ~ x + z,\n    exposure = \"x\",\n    outcome = \"y\"\n  )\n\nHier ist die Definition des DAGs:\n\ncat(g)\n\ndag {\nm\nx [exposure]\ny [outcome]\nz\nm -&gt; y\nx -&gt; m\nz -&gt; m\nz -&gt; y\n}\n\n\nUnd so sieht er aus:\n\nggdag(g) + theme_dag_blank()\n\n\n\n\n\n\n\n\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x\nAV: y\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x8, x9} meint die Menge mit den zwei Elementen x8 und x9.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist m√∂glich, dass es keine L√∂sung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, w√§hlen Sie ‚Äúkeine L√∂sung‚Äù.\n\n\n\n\n{m}\n{z}\n{m, z}\n{ }\nkeine L√∂sung"
  },
  {
    "objectID": "posts/kausal24/kausal28.html#answerlist",
    "href": "posts/kausal24/kausal28.html#answerlist",
    "title": "kausal28",
    "section": "",
    "text": "{m}\n{z}\n{m, z}\n{ }\nkeine L√∂sung"
  },
  {
    "objectID": "posts/kausal24/kausal28.html#answerlist-1",
    "href": "posts/kausal24/kausal28.html#answerlist-1",
    "title": "kausal28",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nRichtig\nFalsch\n\n\nCategories:\n\ndag\ncausal"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "",
    "text": "Erstellen Sie ein pr√§diktives Modell f√ºr Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering. Nutzen Sie au√üerdem deutsche Word-Vektoren f√ºr das Feature-Engineering.\nAls Lernalgorithmus verwenden Sie XGB.\nVerwenden Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n\nDie AV lautet c1. Die (einzige) UV lautet: text.\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks.\nNutzen Sie Tidymodels.\nNutzen Sie das sentiws Lexikon.\n‚ùó Achten Sie darauf, die Variable c2 zu entfernen bzw. nicht zu verwenden."
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#learnermodell",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#learnermodell",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "Learner/Modell",
    "text": "Learner/Modell\n\nmod &lt;-\n  boost_tree(mode = \"classification\",\n             learn_rate = .01, \n             tree_depth = 5\n             )"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#rezept",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#rezept",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "Rezept",
    "text": "Rezept\nPfad zu den Wordvecktoren:\n\npath_wordvec &lt;- \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/part-0.arrow\"\n\n\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_recipe_wordvec_senti.R\")\n\nrec &lt;- def_recipe_wordvec_senti(data_train = d_train,\n                                path_wordvec = path_wordvec)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#workflow",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#workflow",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "Workflow",
    "text": "Workflow\n\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_df.R\")\nwf &lt;- def_wf()\n\nwf"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#check",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#check",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "Check",
    "text": "Check\n\ntic()\nrec_prepped &lt;- prep(rec)\ntoc()\n\nrec_prepped\n\n\nobj_size(rec_prepped)\n\nGro√ü!\n\ntidy(rec_prepped)\n\n\nd_rec_baked &lt;- bake(rec_prepped, new_data = NULL)\n\nhead(d_rec_baked)\n\n\nsum(is.na(d_rec_baked))\n\n\nobj_size(d_rec_baked)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#fit",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#fit",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "Fit",
    "text": "Fit\n\ntic()\nfit_wordvec_senti_xgb &lt;-\n  fit(wf,\n      data = d_train)\ntoc()\nbeep()\n\n\nfit_wordvec_senti_xgb\n\nObjekt-Gr√∂√üe:\n\nlobstr::obj_size(fit_wordvec_senti_xgb)\n\nGro√ü!\nWie wir gesehen haben, ist das Rezept riesig.\n\nlibrary(butcher)\nout &lt;- butcher(fit_wordvec_senti_xgb)\nlobstr::obj_size(out)"
  },
  {
    "objectID": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#test-set-g√ºte",
    "href": "posts/germeval-sent-wordvec-xgb/germeval-sent-wordvec-xgb.html#test-set-g√ºte",
    "title": "germeval03-sent-wordvec-xgb",
    "section": "Test-Set-G√ºte",
    "text": "Test-Set-G√ºte\nVorhersagen im Test-Set:\n\ntic()\npreds &lt;-\n  predict(fit_wordvec_senti_xgb, new_data = germeval_test)\ntoc()\n\nUnd die Vorhersagen zum Test-Set hinzuf√ºgen, damit man TRUTH und ESTIMATE vergleichen kann:\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/Wertberechnen/Wertberechnen.html",
    "href": "posts/Wertberechnen/Wertberechnen.html",
    "title": "Wertberechnen",
    "section": "",
    "text": "Aufgabe\nWelchen Wert bzw. welches Ergebnis liefert folgende R-Syntax f√ºr ergebnis zur√ºck?\nx hat zu Beginn den Wert 0.\nHinweis: sqrt(x) liefert die (positive) Quadratwurzel von x zur√ºck.\n         \n\n\nL√∂sung\nEs wird 1 zur√ºckgeliefert.\n\nCategories:\n\nR\ndyn\nnum"
  },
  {
    "objectID": "posts/twitter05/twitter05.html",
    "href": "posts/twitter05/twitter05.html",
    "title": "twitter05",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=2\\)) via der Twitter API; Suchterm soll sein ‚Äú(karl_lauterbach?)‚Äù. Bereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopw√∂rter entfernen, Zahlen entfernen, ‚Ä¶).\nNutzen Sie die Daten, um eine Sentimentanalyse zu erstellen.\n         \n\n\nSolution\nNutzen Sie die Daten der letzten Aufgabe, um eine Sentimentanalyse zu erstellen.\nZuerst muss man sich anmelden und die Tweets herunterladen; dieser Teil ist hier nicht aufgef√ºhrt (s. andere Aufgaben).\n\nlibrary(rtweet)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(lsa)  # Stopw√∂rter\nlibrary(SnowballC)  # Stemming\n\nBeachten Sie, dass die Spalten je nach Funktion, die Sie zum Herunterladen der Tweets verwenden, unterschiedlich hei√üen k√∂nnen.\n\nkarl2 &lt;- \n  karl1 %&gt;% \n  select(contains(\"text\"))\n\n\nkarl3 &lt;- \n  karl2 %&gt;% \n  unnest_tokens(output = word, input = text)\n\n\nkarl4 &lt;- \nkarl3 %&gt;% \n  anti_join(tibble(word = lsa::stopwords_de)) \n\n\nkarl5 &lt;- \n  karl4 %&gt;% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %&gt;% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %&gt;% \n  mutate(word = str_replace_na(word, \" +\")) %&gt;% \n  drop_na()\n\n\ndata(sentiws, package = \"pradadata\")\n\n\nkarl7 &lt;-\n  karl5 %&gt;% \n  inner_join(sentiws)\n\n\nkarl7 %&gt;% \n  group_by(neg_pos) %&gt;% \n  summarise(senti_avg = mean(value, na.rm = TRUE),\n            senti_sd = sd(value, na.rm = TRUE),\n            senti_n = n())\n\nAchtung, Sentimentanalyse sollte vor dem Stemming kommen.\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/mariokart-mean4/mariokart-mean4.html",
    "href": "posts/mariokart-mean4/mariokart-mean4.html",
    "title": "mariokart-mean4",
    "section": "",
    "text": "Aufgabe\nImportieren Sie den Datensatz mariokart in R. Berechnen Sie den mittleren Verkaufspreis (total_pr) f√ºr Spiele, die neu sind oder (auch) √ºber Lenkr√§der (wheels) verf√ºgen.\nHinweise:\n\nRunden Sie auf 1 Dezimalstelle.\n\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nDaten importieren:\n\nd_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nd &lt;- data_read(d_url)\n\n\nsolution &lt;-\nd  %&gt;% \n  filter(cond == \"new\" | wheels &gt; 0) %&gt;% \n  summarise(pr_mean = mean(total_pr))\n\nsolution\n\n\n\n\n\npr_mean\n\n\n\n\n52.73218\n\n\n\n\n\n\nL√∂sung: 52.73.\n\nCategories:\n\ndatawrangling\ndplyr\neda\nnum"
  },
  {
    "objectID": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html",
    "href": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html",
    "title": "germeval08-extract-spacy",
    "section": "",
    "text": "Extrahieren Sie deutsche Worembedding aus SpaCy f√ºr den GermEval-Datensatz (Train).\nNutzen Sie die GermEval-2018-Daten.\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\nDie Daten sind auch √ºber das R-Paket PradaData zu beziehen.\n\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\n\nHinweise:\n\nOrientieren Sie sich im √úbrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#setup",
    "href": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#setup",
    "title": "germeval08-extract-spacy",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\n\n\nimport spacy\nimport de_core_news_sm\nimport pandas as pd\nnlp = de_core_news_sm.load()"
  },
  {
    "objectID": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#daten-in-python-importieren",
    "href": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#daten-in-python-importieren",
    "title": "germeval08-extract-spacy",
    "section": "Daten in Python importieren",
    "text": "Daten in Python importieren\n\ncsv_file_path = '/home/sebastian/git-repos/pradadata/data-raw/germeval_train.csv'\n\ngermeval_train = pd.read_csv(csv_file_path)"
  },
  {
    "objectID": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#vorbereiten",
    "href": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#vorbereiten",
    "title": "germeval08-extract-spacy",
    "section": "Vorbereiten",
    "text": "Vorbereiten\nAls String konvertieren:\n\ntweets = germeval_train['text']\ntweets2 = tweets.astype(str)\ntweets3 = tweets2.to_string()\n\nNLP-Features berechnen:\n\ndoc = nlp(tweets3)"
  },
  {
    "objectID": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#wortvektoren-berechnen",
    "href": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#wortvektoren-berechnen",
    "title": "germeval08-extract-spacy",
    "section": "Wortvektoren berechnen",
    "text": "Wortvektoren berechnen\n\nwordvec = [token.vector for token in doc]\nlen(wordvec)"
  },
  {
    "objectID": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#export",
    "href": "posts/germeval08-extract-spacy/germeval08-extract-spacy.html#export",
    "title": "germeval08-extract-spacy",
    "section": "Export",
    "text": "Export\nals Pandas DF:\n\ndf = pd.DataFrame(wordvec)\n\ndimensions = df.shape\ndimensions\n\nIn CSV schreiben:\n\ndf.to_csv(\"germeval_spacy_embed.csv\")\n\n\nCategories:\n\nwordembedding\ntextmining\npython\nstring"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html",
    "href": "posts/vis-mtcars/vis-mtcars.html",
    "title": "vis-mtcars",
    "section": "",
    "text": "In dieser Fallstudie (YACSDA: Yet another Case Study on Data Analysis) untersuchen wir den Datensatz mtcars.\nSie k√∂nnen den Datensatz so beziehen:\n\ndata(\"mtcars\")\nd &lt;- mtcars \n\nEin Codebook finden Sie hier.\nDie Forschungsfrage lautet:\nWas ist der Einfluss der Schaltung und der PS-Zahl auf den Spritverbrauch?\n\nAbh√§ngige Variable (metrisch), y: Spritverbrauch (mpg)\nUnabh√§ngige Variable 1 (nominal), x1: Schaltung (am)\nUnabh√§ngige Variable 2 (metrisch), x2: PS-Zahl (hp)\n\nVisualisieren Sie dazu folgende Aspekte der Forschungsfrage!"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#umbenennen",
    "href": "posts/vis-mtcars/vis-mtcars.html#umbenennen",
    "title": "vis-mtcars",
    "section": "Umbenennen",
    "text": "Umbenennen\nZur einfacheren Verarbeitung nenne ich die Variablen um:\n\nd &lt;-\n  d |&gt; \n  rename(y = mpg, x1 = am, x2 = hp)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.",
    "text": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.\nDas R-Paket ggpubr erstellt sch√∂ne Diagramme (basierend auf ggplot) auf einfache Art. Nehmen wir ein Dichtediagramm; die Variable y soll auf der X-Achse stehen:\n\nggdensity(d, x = \"y\")\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable in Anf√ºhrungsstriche gesetzt werden muss: x = \"y\".\nOder ein Histogramm:\n\ngghistogram(d, x = \"y\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "href": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "title": "vis-mtcars",
    "section": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.",
    "text": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.\nUm Diagramme mit Statistiken anzureichen, bietet sich das Paket ggstatsplot an:\n\ngghistostats(d, x = y)\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable nicht in Anf√ºhrungsstriche gesetzt werden darf: x = y."
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie die Verteilung von x1 und x2.",
    "text": "Visualisieren Sie die Verteilung von x1 und x2.\n\nx1\n\nd_counted &lt;- \n  d |&gt; \n  count(x1) \n\n\nggbarplot(data = d_counted, y = \"n\", x = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\n\n\nx2\n\ngghistostats(d, x = x2)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie die Verteilung von y bedingt auf x1",
    "text": "Visualisieren Sie die Verteilung von y bedingt auf x1\n\ngghistogram(d, x = \"y\", fill = \"x1\")\n\n\n\n\n\n\n\n\nOder so:\n\ngghistogram(d, x = \"y\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "href": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "title": "vis-mtcars",
    "section": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu",
    "text": "F√ºgen Sie relevante Kennzahlen zur letzten Visualisierung hinzu\n\ngrouped_gghistostats(d, x = y, grouping.var = x1)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie den Zusammenhang von y und x2",
    "text": "Visualisieren Sie den Zusammenhang von y und x2\n\nggscatter(d, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#verbessern-sie-das-letzte-diagramm-so-dass-es-√ºbersichtlicher-wird",
    "href": "posts/vis-mtcars/vis-mtcars.html#verbessern-sie-das-letzte-diagramm-so-dass-es-√ºbersichtlicher-wird",
    "title": "vis-mtcars",
    "section": "Verbessern Sie das letzte Diagramm, so dass es √ºbersichtlicher wird",
    "text": "Verbessern Sie das letzte Diagramm, so dass es √ºbersichtlicher wird\nEs gibt mehrere Wege, das Diagramm √ºbersichtlicher zu machen. Logarithmieren ist ein Weg.\n\nd |&gt; \n  mutate(x2 = log(x2)) |&gt; \n  ggscatter(x = \"x2\", y = \"y\")\n\n\n\n\n\n\n\n\nSynonym k√∂nnten wir schreiben:\n\nd_logged &lt;- \n  d |&gt; \n  mutate(x2 = log(x2))\n  \n\nggscatter(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "href": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "title": "vis-mtcars",
    "section": "F√ºgen Sie dem letzten Diagramm relevante Kennzahlen hinzu",
    "text": "F√ºgen Sie dem letzten Diagramm relevante Kennzahlen hinzu\n\nggscatterstats(d_logged, x = x2, y = y)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "href": "posts/vis-mtcars/vis-mtcars.html#f√ºgen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "title": "vis-mtcars",
    "section": "F√ºgen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu",
    "text": "F√ºgen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"reg.line\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "href": "posts/vis-mtcars/vis-mtcars.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "title": "vis-mtcars",
    "section": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade",
    "text": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "href": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "title": "vis-mtcars",
    "section": "Gruppieren Sie das letzte Diagramm nach x1",
    "text": "Gruppieren Sie das letzte Diagramm nach x1\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"),\n          facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#dichotomisieren-sie-y-und-z√§hlen-sie-die-h√§ufigkeiten",
    "href": "posts/vis-mtcars/vis-mtcars.html#dichotomisieren-sie-y-und-z√§hlen-sie-die-h√§ufigkeiten",
    "title": "vis-mtcars",
    "section": "Dichotomisieren Sie y und z√§hlen Sie die H√§ufigkeiten",
    "text": "Dichotomisieren Sie y und z√§hlen Sie die H√§ufigkeiten\nNehmen wir einen Mediansplit, um zu dichotomisieren.\n\nd &lt;-\n  d |&gt; \n  mutate(y_dicho = ifelse(y &gt; median(y), \"high\", \"low\"))\n\n\nd |&gt; \n  count(y_dicho) |&gt; \n  ggbarplot(x = \"y_dicho\", y = \"n\")\n\n\n\n\n\n\n\n\nGleich viele! Das sollte nicht verwundern."
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "href": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "title": "vis-mtcars",
    "section": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1",
    "text": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1\n\nd_count &lt;- \nd |&gt; \n  count(y_dicho, x1) \n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\n\n\n\n\nhigh\n0\n4\n\n\nhigh\n1\n11\n\n\nlow\n0\n15\n\n\nlow\n1\n2\n\n\n\n\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"n\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-h√§ufigkeiten-statt-absoluter-h√§ufigkeiten-gezeigt-werden",
    "href": "posts/vis-mtcars/vis-mtcars.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-h√§ufigkeiten-statt-absoluter-h√§ufigkeiten-gezeigt-werden",
    "title": "vis-mtcars",
    "section": "Variieren Sie das letzte Diagramm so, dass Anteile (relative H√§ufigkeiten) statt absoluter H√§ufigkeiten gezeigt werden",
    "text": "Variieren Sie das letzte Diagramm so, dass Anteile (relative H√§ufigkeiten) statt absoluter H√§ufigkeiten gezeigt werden\n\nd_count &lt;-\n  d_count |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n\n\n\n\ny_dicho\nx1\nn\nprop\n\n\n\n\nhigh\n0\n4\n0.12\n\n\nhigh\n1\n11\n0.34\n\n\nlow\n0\n15\n0.47\n\n\nlow\n1\n2\n0.06\n\n\n\n\n\n\nCheck:\n\nd_count |&gt; \n  summarise(sum(prop))\n\n\n\n\n\nsum(prop)\n\n\n\n\n0.99\n\n\n\n\n\n\nGut! Die Anteile summieren sich zu ca. 1 (100 Prozent).\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMan beachten, dass sich die Anteile auf das ‚ÄúGesamt-N‚Äù beziehen.\n\nCategories:\n\nvis\nyacsda\nggquick\nmtcars\nstring"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html",
    "href": "posts/einsamkeit-modellierung/index.html",
    "title": "einsamkeit-modellierung",
    "section": "",
    "text": "In dieser Fallstudie wird eine studentische Studie vorgestellt, die untersucht, inwieweit Einsamkeit induziert werden kann und welche Effekte die Einsamkeitsinduktion auf das aktuelle Befinden hat.\nDas Design ist reichhaltig und l√§sst viele Analysen zu. Bei diesem Post liegt der Fokus auf der Modellierung der Forschungsfrage.\n\n\nHat die Induktion (ind) von Einsamkeit einen Effekt auf die wahrgenommenen Einsamkeit (lonely) ?\nInsgesamt wird zwei Mal Einsamkeit induziert:\nH1: Die Induktion 1 (ind1) verringert die Einsamkeit (Geschichte √ºber Einsamkeit oder neutral)\nH2: Die Induktion 2 (ind2) verringert die Einsamkeit (‚Äúeinsame‚Äù Musik oder neutral)\n\n\n\nEs handelt sich um eine Kausalanalyse, da man am Effekt der Intervention auf die Einsamkeit interessiert ist.\n\n\n\n\n\ngraph LR\n  ind1 --&gt; lonely\n  ind2 --&gt; lonely\n  u --&gt; lonely\n\n\n\n\n\n\n\n\n\n\nUV1: Einsamkeitsinduktion 1 (Geschichte)\nUV2: Einsamkeitsinduktion 2 (Musik)\nAV: Einsamkeit"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#forschungsfrage-und-hypothesen",
    "href": "posts/einsamkeit-modellierung/index.html#forschungsfrage-und-hypothesen",
    "title": "einsamkeit-modellierung",
    "section": "",
    "text": "Hat die Induktion (ind) von Einsamkeit einen Effekt auf die wahrgenommenen Einsamkeit (lonely) ?\nInsgesamt wird zwei Mal Einsamkeit induziert:\nH1: Die Induktion 1 (ind1) verringert die Einsamkeit (Geschichte √ºber Einsamkeit oder neutral)\nH2: Die Induktion 2 (ind2) verringert die Einsamkeit (‚Äúeinsame‚Äù Musik oder neutral)"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#dag-kausalgraph",
    "href": "posts/einsamkeit-modellierung/index.html#dag-kausalgraph",
    "title": "einsamkeit-modellierung",
    "section": "",
    "text": "Es handelt sich um eine Kausalanalyse, da man am Effekt der Intervention auf die Einsamkeit interessiert ist.\n\n\n\n\n\ngraph LR\n  ind1 --&gt; lonely\n  ind2 --&gt; lonely\n  u --&gt; lonely"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#forschungsdesign",
    "href": "posts/einsamkeit-modellierung/index.html#forschungsdesign",
    "title": "einsamkeit-modellierung",
    "section": "",
    "text": "UV1: Einsamkeitsinduktion 1 (Geschichte)\nUV2: Einsamkeitsinduktion 2 (Musik)\nAV: Einsamkeit"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#delta-1",
    "href": "posts/einsamkeit-modellierung/index.html#delta-1",
    "title": "einsamkeit-modellierung",
    "section": "7.1 Delta 1",
    "text": "7.1 Delta 1\n\n7.1.1 Modell\n\nmod_delta1 &lt;- stan_glm(loneliness_delta1 ~ Geschichte, data = d_delta)\n\nMit lm w√ºrde das genau so funktionieren. Nur ohne die Ergebnisse einfach probabilistisch interpretieren zu k√∂nnen.\nErgebnisse:\n\nparameters(mod_delta1) |&gt; \n  print_md()\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n0.07\n(-0.03, 0.18)\n90.53%\n1.000\n3590.00\nNormal (0.02 +- 0.63)\n\n\nGeschichteneutrale\n-0.10\n(-0.24, 0.05)\n90.33%\n1.000\n3766.00\nNormal (0.00 +- 1.25)\n\n\n\n\n\nDie Nullhypothese kann nicht verworfen werden.\n\n\n7.1.2 Visualisierung\n\nplot(parameters(mod_delta1))\n\n\n\n\n\n\n\n\n\n\n7.1.3 Modellg√ºte\n\nr2(mod_delta1)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.037 (95% CI [8.275e-09, 0.164])\n\n\nTja, die Intervention war leider nicht so stark. Aber so ist es nun Mal im harten Forscherleben ‚Ä¶\n\nmod_delta1_rope &lt;- rope(mod_delta1)\n\nplot(mod_delta1_rope)"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#delta-2-und-3",
    "href": "posts/einsamkeit-modellierung/index.html#delta-2-und-3",
    "title": "einsamkeit-modellierung",
    "section": "7.2 Delta 2 und 3",
    "text": "7.2 Delta 2 und 3\n‚Ä¶ analog"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#visualisierung-1",
    "href": "posts/einsamkeit-modellierung/index.html#visualisierung-1",
    "title": "einsamkeit-modellierung",
    "section": "8.1 Visualisierung",
    "text": "8.1 Visualisierung\n\n8.1.1 Delta 1\nHier ist die Ver√§nderung der Einsamkeit von Messung t1 zu Messung t2, aufgeteilt nach den beiden Gruppen.\n\nggboxplot(d_delta, x = \"Geschichte\", y = \"loneliness_delta1\",\n          add = \"jitter\")\n\n\n\n\n\n\n\n\nTja, leider kein starker Effekt zu erkennen.\n\nd_long &lt;- \nd |&gt; \n  select(Proband_ID, Geschichte, starts_with(\"Loneliness\")) |&gt; \n  pivot_longer(cols = starts_with(\"Loneliness\"),\n               names_to = \"Messzeitpunkt\",\n               values_to = \"Einsamkeit\") |&gt; \n  mutate(t = as.integer(str_extract(Messzeitpunkt, \"\\\\d\")))  # Messzeitpunkt als Zahl: 1,2,3\n\n\nd_long |&gt; \n  head() |&gt; \n  kable(digits = 2)\n\n\n\n\nProband_ID\nGeschichte\nMesszeitpunkt\nEinsamkeit\nt\n\n\n\n\n1\nneutrale\nLoneliness_mean_f1\n1.4\n1\n\n\n1\nneutrale\nLoneliness_mean_f2\n1.2\n2\n\n\n1\nneutrale\nLoneliness_mean_f3\n1.0\n3\n\n\n2\neinsame\nLoneliness_mean_f1\n1.2\n1\n\n\n2\neinsame\nLoneliness_mean_f2\n1.8\n2\n\n\n2\neinsame\nLoneliness_mean_f3\n1.8\n3\n\n\n\n\n\n\nd_long |&gt;\n  ggboxplot(x = \"t\", y = \"Einsamkeit\", add = \"jitter\",\n            color = \"Geschichte\")\n\n\n\n\n\n\n\n\nEs ist wenig Effekt zu erkennen. Interessanterweise hat die Gruppe der Einsamkeits-Intervention von vornherein einen h√∂heren Wert in Einsamkeit. Das ist psychologisch interessant und sollte n√§her untersucht werden.\nAndere Visualisierung:\n\nd_long |&gt; \n  ggsummarystats(x = \"t\",\n                 y = \"Einsamkeit\",\n                 ggfunc = ggline,\n                 add = \"median_iqr\",\n                 color = \"Geschichte\",\n                 position = position_dodge(width = 0.1),\n                 heights  = c(0.6, 0.4),\n                 caption = \"Error bars show median and IQR\")\n\n\n\n\n\n\n\n\n\n\n8.1.2 Delta 2 und 3\n‚Ä¶ analog"
  },
  {
    "objectID": "posts/einsamkeit-modellierung/index.html#statistiken-pro-gruppe",
    "href": "posts/einsamkeit-modellierung/index.html#statistiken-pro-gruppe",
    "title": "einsamkeit-modellierung",
    "section": "8.2 Statistiken pro Gruppe",
    "text": "8.2 Statistiken pro Gruppe\n\nd_delta |&gt; \n  select(Geschichte, loneliness_delta1) |&gt; \n  group_by(Geschichte) |&gt; \n  summarise(delta1_mean = mean(loneliness_delta1),\n            delta1_sd = sd(loneliness_delta1))\n\n\n\n\n\nGeschichte\ndelta1_mean\ndelta1_sd\n\n\n\n\neinsame\n0.0727273\n0.2930656\n\n\nneutrale\n-0.0272727\n0.1980424"
  },
  {
    "objectID": "posts/purrr-map03/purrr-map03.html",
    "href": "posts/purrr-map03/purrr-map03.html",
    "title": "purrr-map03",
    "section": "",
    "text": "Exercise\nImportieren Sie das Grundatzprogramm der Partei AfD (in der aktuellsten Version). Tokenisieren Sie nach S√§tzen. Dann entfernen Sie alle Zahlen. Dann z√§hlen Sie die Anzahl der W√∂rter pro Satz und berichten g√§ngige deskriptive Statistiken dazu.\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nText aus PDF-Dateien kann man mit dem Paket pdftools einlesen:\n\nlibrary(pdftools)\nd_path &lt;- \"~/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf\"\n\nd &lt;- tibble(text = pdf_text(d_path))\n\nDann erstellen wir eine Tidy-Version und tokenisieren nach S√§tzen:\n\nlibrary(tidytext)\nd2 &lt;-\n  d %&gt;% \n  unnest_sentences(output = word, input = text)\n\nhead(d2)\n\n\n\n\n\n\n\n\nword\n\n\n\n\nprogramm f√ºr deutschland.\n\n\ndas grundsatzprogramm der alternative f√ºr deutschland.\n\n\n2 programm f√ºr deutschland | inhalt pr√§ambel 06 4 | au√üen- und sicherheitspolitik 28 1 | demokratie und grundwerte 07 4.1 vereinte nationen reformieren 30 4.2 nato als verteidigungsb√ºndnis 30 1.1 volksabstimmungen nach schweizer vorbild 09 4.3 osze und europ√§ische sicherheitsstruktur 31 1.2 schlanker staat f√ºr freie b√ºrger 09 4.4 bundeswehr st√§rken 31 1.3 die gewaltenteilung gew√§hrleisten 10 4.4.1 keine europ√§ische armee 31 1.4 trennung von amt und mandat 10 4.4.2 wehrpflicht wieder einsetzen 32 1.5 macht der parteien beschr√§nken 11 4.5 entwicklungshilfe 32 1.5.1 parteienfinanzierung dem verfassungsrecht anpassen 11 1.5.2 freie listenwahl und freies mandat 12 5 | arbeitsmarkt und sozialpolitik 34 1.5.3 verkleinerung des bundestages 13 1.5.4 wider das berufspolitikertum: amtszeit begrenzen 13 5.1 arbeitsmarkt von unn√∂tiger b√ºrokratie befreien 36 1.5.5 direktwahl des bundespr√§sidenten durch das volk 13 5.2 bundesagentur f√ºr arbeit aufl√∂sen und kommunale 1.6 lobbyismus eind√§mmen 13 jobcenter aufwerten 36 1.6.1 private rentenvorsorge f√ºr parlamentarier 14 5.3 mindestlohn beibehalten 36 1.6.2 einf√ºhrung eines straftatbestandes der 5.4 reform der sozialen sicherungssysteme 36 steuerverschwendung 14 5.4.1 finanzielle benachteiligung von familien beseitigen 37 5.4.2 ‚Äúaktivierende grundsicherung‚Äù - arbeit, die sich lohnt 37 2 | europa und euro 15 5.4.3 kinder und erziehungsleistung bei der rente ber√ºcksichtigen 37 2.1 ein europa der vaterl√§nder 17 5.4.4 pflege durch angeh√∂rige aufwerten 37 2.2 kompetenzen an die nationalstaaten zur√ºckgeben 17 2.3 b√ºndelung gemeinsamer europ√§ischer interessen 18 6 | familien und kinder 39 2.4 volksabstimmung √ºber den euro 18 2.5 keine deutsche haftung f√ºr ausl√§ndische banken 21 6.1 bekenntnis zur traditionellen familie als leitbild 41 6.2 mehr kinder statt masseneinwanderung 41 3 | innere sicherheit und justiz 23 6.3 mehr unterst√ºtzung f√ºr familien 42 6.4 wirtschaftliche zukunft trotz demografiekrise 42 3.1 polizei st√§rken und strafjustiz verbessern 25 6.5 diskriminierung der vollzeit-m√ºtter stoppen 43 3.2 weisungsfreie staatsanw√§lte, unabh√§ngige richter 6.6 alleinerziehende unterst√ºtzen.\n\n\nfamilien st√§rken 43 und parteiferne rechnungsh√∂fe 25 6.7 willkommenskultur f√ºr neu- und ungeborene 44 3.3 angriffe auf amtspersonen h√§rter bestrafen 26 3.4 opferschutz statt t√§terschutz 26 3.5 waffenrecht muss nicht versch√§rft werden 26 3.6 kein datenschutz f√ºr t√§ter 27 3.7 organisierte kriminalit√§t nachhaltig bek√§mpfen 27 3.8 zivil- und fachgerichte sind ein standortfaktor 27 3.9 deutsche grenzen sch√ºtzen 27\n\n\n3 programm f√ºr deutschland | inhalt 7 | kultur, sprache und identit√§t 45 9 | einwanderung, integration und asyl 57 7.1 deutsche kultur, sprache und identit√§t erhalten 47 9.1 keine irregul√§re einwanderung √ºber das asylrecht 59 7.2 deutsche leitkultur statt multikulturalismus 47 9.1.1 asylzuwanderung - f√ºr einen paradigmenwechsel 59 7.3 die deutsche sprache als zentrum unserer identit√§t 47 9.1.2 r√ºckf√ºhrung - schluss mit fehlanreizen und 7.4 kultur und kunst von einflussnahme der parteien befreien 48 falscher nachsicht 60 7.5 f√ºr eine zeitgem√§√üe medienpolitik: rundfunkbeitrag abschaffen 48 9.2 einwanderung aus eu-staaten 61 7.6 der islam im spannungsverh√§ltnis zu unserer werteordnung 48 9.3 gesteuerte einwanderung aus drittstaaten 62 7.6.1 der islam geh√∂rt nicht zu deutschland 49 9.4 integration - mehr als nur deutsch lernen 63 7.6.2 kritik am islam muss erlaubt sein 49 9.5 kosten der einwanderung - transparenz herstellen 63 7.6.3 auslandsfinanzierung von moscheen beenden 49 9.6 einwandererkriminalit√§t - nichts verschleiern, 7.6.4 keine √∂ffentlich-rechtliche k√∂rperschaft f√ºr nichts verschweigen 64 islamische organisationen 50 9.7 einb√ºrgerung - abschluss gelungener integration 65 7.6.5 keine vollverschleierung im √∂ffentlichen raum 50 10 | wirtschaft, digitale welt und verbraucherschutz 66 8 | schule, hochschule und forschung 51 10.1 freier wettbewerb sichert unseren wohlstand 67 8.1 forschung und lehre: in freiheit und als einheit 52 10.2 soziale marktwirtschaft statt planwirtschaft 67 8.1.1 autonomie durch grundfinanzierung st√§rken 52 10.3 internationale wirtschaftspolitik neu ausrichten 67 8.1.2 f√∂rderung der ‚Äúgender-forschung‚Äù beenden 52 10.4 hohe standards f√ºr handelsabkommen 68 8.1.3 diplom, magister und staatsexamen wieder einf√ºhren 52 10.5 b√ºrokratie abbauen 68 8.1.4 studienanforderungen erh√∂hen 53 10.6 den technologiestandort deutschland voranbringen 68 8.2 unser schulsystem: stark durch differenzierung 53 10.7 staatliche subventionen reduzieren und befristen 69 8.2.1 die einheitsschule f√ºhrt zu qualit√§tsverlust 53 10.8 keine privatisierung gegen den willen der b√ºrger 69 8.2.2 wissensvermittlung muss zentrales anliegen bleiben 53 10.9 der mittelstand als herz unserer wirtschaftskraft 69 8.2.3 leistungsbereitschaft und disziplin st√§rken 54 10.10 digitalisierung als chance und herausforderung 69 8.2.4 politisch-ideologische indoktrination darf es an 10.10.1 quelloffene software und sichere hardware 69 der schule nicht geben 54 10.10.2 sichere kommunikation als standortvorteil 8.2.5 duale berufliche bildung st√§rken und erhalten 54 und b√ºrgerrecht 70 8.2.6 keine inklusion ‚Äúum jeden preis‚Äù.\n\n\nf√∂rder- und 10.10.3 deutsche literatur im inland digitalisieren 70 sonderschulen erhalten 54 10.11 verbraucherschutz modernisieren und st√§rken 70 8.2.7 koranschulen schlie√üen.\n\n\n\n\n\n\nDann entfernen wir die Zahlen:\n\nd3 &lt;- \n  d2 %&gt;% \n  mutate(word = str_remove_all(word, pattern = \"[:digit:]+\"))\n\nPr√ºfen wir, ob es geklappt hat:\n\nd2$word[10]\n\n[1] \"weniger subventionen    88      13.7 fischerei, forst und jagd: im einklang mit der natur     88      13.8 fl√§chenkonkurrenz:           nicht zu lasten der land- und forstwirtschaft            88\"\n\nd3$word[10]\n\n[1] \"weniger subventionen          . fischerei, forst und jagd: im einklang mit der natur           . fl√§chenkonkurrenz:           nicht zu lasten der land- und forstwirtschaft            \"\n\n\nOk.\nDann z√§hlen wir die W√∂rter pro Satz:\n\nd4 &lt;- \n  d3 %&gt;% \n  summarise(word_count_per_sentence = str_count(word, \"\\\\w+\"))\n\nhead(d4)\n\n\n\n\n\nword_count_per_sentence\n\n\n\n\n3\n\n\n6\n\n\n196\n\n\n40\n\n\n254\n\n\n15\n\n\n\n\n\n\nVisualisierung:\n\nd4 %&gt;% \n  ggplot(aes(x = word_count_per_sentence)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nlibrary(easystats)\ndescribe_distribution(d4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nword_count_per_sentence\n21.86093\n17.23801\n19\n0\n254\n3.843274\n37.5212\n1208\n0\n\n\n\n\n\n\n\nCategories:\n\nR\nmap\ntidyverse"
  },
  {
    "objectID": "posts/xlsx-online-import/index.html",
    "href": "posts/xlsx-online-import/index.html",
    "title": "xls-online-import",
    "section": "",
    "text": "Importieren Sie eine XLSX-Datei aus dem Internet in R (als Dataframe).\nHier ist ein Pfad: https://github.com/sebastiansauer/Lehre/raw/refs/heads/main/25-SoSe/FAU-2025-09/penguins.xlsx.\n\ndata_url &lt;- \"https://github.com/sebastiansauer/Lehre/raw/refs/heads/main/25-SoSe/FAU-2025-09/penguins.xlsx\"\n\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks."
  },
  {
    "objectID": "posts/xlsx-online-import/index.html#weg-1",
    "href": "posts/xlsx-online-import/index.html#weg-1",
    "title": "xls-online-import",
    "section": "2.1 Weg 1",
    "text": "2.1 Weg 1\n\nlibrary(rio)\npenguins &lt;- import(data_url)"
  },
  {
    "objectID": "posts/xlsx-online-import/index.html#weg-2",
    "href": "posts/xlsx-online-import/index.html#weg-2",
    "title": "xls-online-import",
    "section": "2.2 Weg 2",
    "text": "2.2 Weg 2\n\ndest_file &lt;- \"penguins.xlsx\"\n\ndownload.file(url = data_url, destfile = dest_file, mode = \"wb\")\n\nlibrary(readxl)\n\nmy_data &lt;- read_excel(dest_file)"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html",
    "href": "posts/penguins-stan-06/index.html",
    "title": "penguins-stan-06",
    "section": "",
    "text": "Wir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir in dem Zusammenhang den Zusammenhang des Geschlechts (als UV) und K√∂rpergewicht (als AV).\nAufgabe:\nWie gro√ü ist der statistische Einfluss der UV auf die AV?\n\nGeben Sie den Punktsch√§tzer des Effekts an!\nGeben Sie die Breite eines 90%-HDI an (zum Effekt)!\nWie gro√ü ist die Wahrscheinlichkeit, dass der Effekt vorhanden ist (also gr√∂√üer als Null ist), die ‚ÄúEffektwahrscheinlichkeit‚Äù?\nWie gro√ü ist die Wahrscheinlichkeit, dass der Effekt substanziell vorhanden ist (also gr√∂√üer als 0.5 ist), die ‚ÄúSubstantielle Effektwahrscheinlichkeit‚Äù?\n\nHinweise:\n\nNutzen Sie die folgende Analyse als Grundlage Ihrer Antworten.\nBeachten Sie die Hinweise des Datenwerks.\n\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nDaf√ºr ist folgende Analyse gegeben.\n\n\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\n\n\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{weight}_{m} &gt; \\text{weight}_{f},\\]\n‚ÄúDer Mittelwert des Gewichts der m√§nnliche Tiere ist gr√∂√üer als das der weiblichen (female) Tiere‚Äù.\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!\n\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)  # oder z.B. mit read_csv \n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nWir entfernen noch alle fehlenden Werte:\n\npenguins_nona &lt;- \n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\")\n\npenguins_nona$sex |&gt; unique()\n\n[1] male   female\nLevels: female male\n\n\n\nm1 &lt;- stan_glm(body_mass_g ~  sex,  # Regressionsgleichung\n               data = penguins_nona, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm1_params &lt;- parameters(m1, ci_method = \"hdi\", ci = .9)\nm1_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n3862.7923\n0.9\n3769.5656\n3956.3636\n1\n1.000089\n3572.529\nnormal\n4207.057\n2013.040\n\n\nsexmale\n682.2466\n0.9\n547.2974\n816.9999\n1\n1.000397\n3652.939\nnormal\n0.000\n4020.192"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html#setup",
    "href": "posts/penguins-stan-06/index.html#setup",
    "title": "penguins-stan-06",
    "section": "",
    "text": "library(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\nlibrary(ggpubr)"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html#modell-und-hypothese",
    "href": "posts/penguins-stan-06/index.html#modell-und-hypothese",
    "title": "penguins-stan-06",
    "section": "",
    "text": "Die Hypothese kann man wie folgt formalisieren:\n\\[\\text{weight}_{m} &gt; \\text{weight}_{f},\\]\n‚ÄúDer Mittelwert des Gewichts der m√§nnliche Tiere ist gr√∂√üer als das der weiblichen (female) Tiere‚Äù.\nDie Prioris √ºbernehmen wir vom Stan-Golem.ü§ñ\n\nü§ñ Beep, beep!\n\n\nüë©‚Äçüè´ An die Arbeit, Stan-Golem!\n\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)  # oder z.B. mit read_csv \n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nWir entfernen noch alle fehlenden Werte:\n\npenguins_nona &lt;- \n  penguins |&gt; \n  filter(sex == \"female\" | sex == \"male\")\n\npenguins_nona$sex |&gt; unique()\n\n[1] male   female\nLevels: female male\n\n\n\nm1 &lt;- stan_glm(body_mass_g ~  sex,  # Regressionsgleichung\n               data = penguins_nona, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nm1_params &lt;- parameters(m1, ci_method = \"hdi\", ci = .9)\nm1_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n3862.7923\n0.9\n3769.5656\n3956.3636\n1\n1.000089\n3572.529\nnormal\n4207.057\n2013.040\n\n\nsexmale\n682.2466\n0.9\n547.2974\n816.9999\n1\n1.000397\n3652.939\nnormal\n0.000\n4020.192"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html#punktsch√§tzer",
    "href": "posts/penguins-stan-06/index.html#punktsch√§tzer",
    "title": "penguins-stan-06",
    "section": "Punktsch√§tzer",
    "text": "Punktsch√§tzer\nDer Punktsch√§tzer ist in der Spalte Median in der Tabelle parameters zu finden. Sein Wert ist:\n\n\n[1] 682.2466\n\n\nHier ist die Post-Verteilung des Effekts:\n\nm1_params |&gt; plot()\n\n\n\n\n\n\n\n\nAlternative Visualisierung:\n\nhdi(m1, ci = .9) |&gt; plot()"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html#breite-des-intervalls",
    "href": "posts/penguins-stan-06/index.html#breite-des-intervalls",
    "title": "penguins-stan-06",
    "section": "Breite des Intervalls",
    "text": "Breite des Intervalls\nDazu liest man die Intervallgrenzen (90% CI) in der richtigen Zeile ab (Tabelle parameters).\nObere Grenze: 816.9999226.\nUntere Grenze: 547.2974274.\nDifferenz = Obere_Grenze - Untere_Grenze:\n\n\n[1] 269.7025\n\n\nEinheit: mm"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html#effektwahrscheinlichkeit",
    "href": "posts/penguins-stan-06/index.html#effektwahrscheinlichkeit",
    "title": "penguins-stan-06",
    "section": "Effektwahrscheinlichkeit",
    "text": "Effektwahrscheinlichkeit\nMan erkennt schon im Diagramm zum Konfidenzintervall, dass 100% des Intervalls positiv ist. Daher ist die Effektwahrscheinlichkeit auch positiv.\nMan kann diesen Wert aus der Tabelle oben (Ausgabe von parameters()) einfach in der Spalte pd ablesen. pd steht f√ºr probability of direction, s. Details hier.\nOder so, ist auch einfach:\n\npd_m1 &lt;- p_direction(m1) # aus Paket easystats\npd_m1\n\n\n\n\n\nParameter\npd\nEffects\nComponent\n\n\n\n\n(Intercept)\n1\nfixed\nconditional\n\n\nsexmale\n1\nfixed\nconditional\n\n\n\n\n\n\nUnd plotten ist meist hilfreich: plot(pd_m1).\n\nplot(pd_m1)"
  },
  {
    "objectID": "posts/penguins-stan-06/index.html#substanzielle-effektwahrscheinlichkeit",
    "href": "posts/penguins-stan-06/index.html#substanzielle-effektwahrscheinlichkeit",
    "title": "penguins-stan-06",
    "section": "Substanzielle Effektwahrscheinlichkeit",
    "text": "Substanzielle Effektwahrscheinlichkeit\nDie Frage ist nichts anderes als nach ROPE zu fragen.\n\nrope_m1 &lt;- rope(m1, range = c(-500,+500))\nrope_m1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-500\n500\n0\nfixed\nconditional\n\n\nsexmale\n0.95\n-500\n500\n0\nfixed\nconditional\n\n\n\n\n\n\n\nplot(rope_m1)\n\n\n\n\n\n\n\n\nDas 90%-Intervall ist knapp au√üerhalb des ROPE.\nWir k√∂nnen die ROPE-Hypothese daher zur√ºckweisen."
  },
  {
    "objectID": "posts/filter-na3/filter-na3.html",
    "href": "posts/filter-na3/filter-na3.html",
    "title": "filter-na3",
    "section": "",
    "text": "Filtern Sie alle Zeilen mit fehlende Werte im Datensatz penguins!\nLiefern Sie die Spalten zur√ºck, die fehlende Werte aufweisen."
  },
  {
    "objectID": "posts/filter-na3/filter-na3.html#setup",
    "href": "posts/filter-na3/filter-na3.html#setup",
    "title": "filter-na3",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\nnrow(d)\n\n[1] 344"
  },
  {
    "objectID": "posts/filter-na3/filter-na3.html#weg-1",
    "href": "posts/filter-na3/filter-na3.html#weg-1",
    "title": "filter-na3",
    "section": "Weg 1",
    "text": "Weg 1\n\nd_na_only &lt;-\n  d %&gt;% \n  filter(!complete.cases(.)) \n\nd_na_only %&gt;% \n  names()\n\n[1] \"rownames\"          \"species\"           \"island\"           \n[4] \"bill_length_mm\"    \"bill_depth_mm\"     \"flipper_length_mm\"\n[7] \"body_mass_g\"       \"sex\"               \"year\""
  },
  {
    "objectID": "posts/filter-na3/filter-na3.html#weg-2",
    "href": "posts/filter-na3/filter-na3.html#weg-2",
    "title": "filter-na3",
    "section": "Weg 2",
    "text": "Weg 2\n\nd %&gt;% \n  filter(if_any(everything(), ~ is.na(.))) %&gt;% \n  names()\n\n[1] \"rownames\"          \"species\"           \"island\"           \n[4] \"bill_length_mm\"    \"bill_depth_mm\"     \"flipper_length_mm\"\n[7] \"body_mass_g\"       \"sex\"               \"year\"             \n\n\n\nCategories:\n\n2023\neda\nna\nstring"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html",
    "href": "posts/tmdb04/tmdb04.html",
    "title": "tmdb04",
    "section": "",
    "text": "Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme.\nDie Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\""
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#train-set-verschlanken",
    "href": "posts/tmdb04/tmdb04.html#train-set-verschlanken",
    "title": "tmdb04",
    "section": "Train-Set verschlanken",
    "text": "Train-Set verschlanken\n\nd_train_raw_reduced &lt;-\n  d_train_raw %&gt;% \n  select(id, popularity, runtime, revenue, budget)"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#test-set-verschlanken",
    "href": "posts/tmdb04/tmdb04.html#test-set-verschlanken",
    "title": "tmdb04",
    "section": "Test-Set verschlanken",
    "text": "Test-Set verschlanken\n\nd_test &lt;-\n  d_test_raw %&gt;% \n  select(id,popularity, runtime, budget)"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#outcome-logarithmieren",
    "href": "posts/tmdb04/tmdb04.html#outcome-logarithmieren",
    "title": "tmdb04",
    "section": "Outcome logarithmieren",
    "text": "Outcome logarithmieren\nDer Outcome sollte nicht im Rezept transformiert werden (vgl. Part 3, S. 30, in dieser Unterlage).\n\nd_train &lt;-\n  d_train_raw_reduced %&gt;% \n  mutate(revenue = if_else(revenue &lt; 10, 10, revenue)) %&gt;% \n  mutate(revenue = log(revenue)) \n\nPr√ºfen, ob das funktioniert hat:\n\nd_train$revenue %&gt;% is.infinite() %&gt;% any()\n\nKeine unendlichen Werte mehr, auf dieser Basis k√∂nnen wir weitermachen."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#rezept-definieren",
    "href": "posts/tmdb04/tmdb04.html#rezept-definieren",
    "title": "tmdb04",
    "section": "Rezept definieren",
    "text": "Rezept definieren\n\nrec2 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  step_mutate(budget = ifelse(budget == 0, NA, budget)) %&gt;%  # log mag keine 0\n  step_log(budget) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())  %&gt;% \n  update_role(id, new_role = \"id\")\n\nrec2\n\nSchauen Sie mal, der Log mag keine Nullen:\n\nx &lt;- c(1,2, NA, 0)\n\nlog(x)\n\nDa \\(log(0) = -\\infty\\). Aus dem Grund wandeln wir 0 lieber in NA um.\n\ntidy(rec2)"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#check-das-rezept",
    "href": "posts/tmdb04/tmdb04.html#check-das-rezept",
    "title": "tmdb04",
    "section": "Check das Rezept",
    "text": "Check das Rezept\nWir berechnen das Rezept:\n\nrec2_prepped &lt;-\n  prep(rec2, verbose = TRUE)\n\nrec2_prepped\n\nDas ist noch nicht auf einen Datensatz angewendet! Lediglich die steps wurden vorbereitet, ‚Äúpr√§pariert‚Äù: z.B. ‚ÄúDiese Dummy-Variablen impliziert das Rezept‚Äù.\nSo sieht das dann aus, wenn man das pr√§parierte Rezept auf das Train-Sample anwendet:\n\nd_train_baked2 &lt;-\n  rec2_prepped %&gt;% \n  bake(new_data = NULL) \n\nhead(d_train_baked2)\n\n\nd_train_baked2 %&gt;% \n  map_df(sum_isna)\n\nKeine fehlenden Werte mehr in den Pr√§diktoren.\nNach fehlenden Werten k√∂nnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train_baked2)\n\nSo bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#check-test-sample",
    "href": "posts/tmdb04/tmdb04.html#check-test-sample",
    "title": "tmdb04",
    "section": "Check Test-Sample",
    "text": "Check Test-Sample\nDas Test-Sample backen wir auch mal, um zu pr√ºfen, das alles l√§uft:\n\nd_test_baked2 &lt;-\n  bake(rec2_prepped, new_data = d_test)\n\nd_test_baked2 %&gt;% \n  head()\n\nSieht soweit gut aus."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#lm",
    "href": "posts/tmdb04/tmdb04.html#lm",
    "title": "tmdb04",
    "section": "LM",
    "text": "LM\n\nmod_lm &lt;-\n  linear_reg()"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#finalisieren-1",
    "href": "posts/tmdb04/tmdb04.html#finalisieren-1",
    "title": "tmdb04",
    "section": "Finalisieren",
    "text": "Finalisieren\nFinalisieren bedeutet:\n\nBesten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell)\nDen besten Workflow mit den optimalen Modell-Parametern ausstatten\nDamit dann den ganzen Train-Datensatz fitten\nAuf dieser Basis das Test-Sample vorhersagen\n\n\nbest_wf2 &lt;- \nall_workflows2 %&gt;% \n  extract_workflow(\"rec1_lm1\")\n\nbest_wf2\n\n\nbest_wf_finalized2 &lt;- \n  best_wf2 %&gt;% \n  finalize_workflow(best_model_params2)\n\nbest_wf_finalized2"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#final-fit",
    "href": "posts/tmdb04/tmdb04.html#final-fit",
    "title": "tmdb04",
    "section": "Final Fit",
    "text": "Final Fit\n\nfit_final2 &lt;-\n  best_wf_finalized2 %&gt;% \n  fit(d_train)\n\nfit_final2\n\n\npreds &lt;- \nfit_final2 %&gt;% \n  predict(new_data = d_test)\n\nhead(preds)\n\nAchtung, wenn die Outcome-Variable im Rezept ver√§ndert wurde, dann w√ºrde obiger Code nicht durchlaufen.\nGrund ist hier beschrieben:\n\nWhen predict() is used, it only has access to the predictors (mirroring how this would work with new samples). Even if the outcome column is present, it is not exposed to the recipe. This is generally a good idea so that we can avoid information leakage.\n\n\nOne approach is the use the skip = TRUE option in step_log() so that it will avoid that step during predict() and/or bake(). However, if you are using this recipe with the tune package, there will still be an issue because the metric function(s) would get the predictions in log units and the observed outcome in the original units.\n\n\nThe better approach is, for simple transformations like yours, to log the outcome outside of the recipe (before data analysis and the initial split)."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#submission-df",
    "href": "posts/tmdb04/tmdb04.html#submission-df",
    "title": "tmdb04",
    "section": "Submission df",
    "text": "Submission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#zur√ºcktransformieren",
    "href": "posts/tmdb04/tmdb04.html#zur√ºcktransformieren",
    "title": "tmdb04",
    "section": "Zur√ºcktransformieren",
    "text": "Zur√ºcktransformieren\n\nsubmission_df &lt;-\n  submission_df %&gt;% \n  mutate(revenue = exp(revenue)-1)\n\nhead(submission_df)\n\nHier ein Beispiel, warum \\(e^x-1\\) genauer ist f√ºr kleine Zahlen als \\(e^x\\).\nAbspeichern und einreichen:\n\nwrite_csv(submission_df, file = \"submission.csv\")"
  },
  {
    "objectID": "posts/penguins-stan-01/penguins-stan-01.html",
    "href": "posts/penguins-stan-01/penguins-stan-01.html",
    "title": "penguins-stan-01",
    "section": "",
    "text": "Aufgabe\nWir untersuchen Einflussfaktoren bzw. Pr√§diktoren auf das K√∂rpergewicht von Pinguinen. In dieser Aufgabe untersuchen wir in dem Zusammenhang den Zusammenhang von Schnabell√§nge (als UV) und K√∂rpergewicht (als AV).\nWie gro√ü ist der statistische Einfluss der UV auf die AV?\n\nBerechnen Sie den Punktsch√§tzer des Effekts!\nWie viele Parameter hat das Modell?\nGeben Sie die Breite eines 90%-HDI an (zum Effekt)!\nWie gro√ü ist die Wahrscheinlichkeit, dass der Effekt vorhanden ist (also gr√∂√üer als Null ist), die ‚ÄúEffektwahrscheinlichkeit‚Äù?\nWie gro√ü ist das 95%-HDI, wenn Sie nur die Spezies Adelie untersuchen?\nGeben Sie die Prioris an f√ºr m1 f√ºr die Regressionskoeffizienten!\n\nHinweise:\n\nNutzen Sie den Datensatz zu den Palmer Penguins.\nVerwenden Sie Methoden der Bayes-Statistik und die Software Stan.\nFixieren Sie die Zufallszahlen auf den Startwert 42!\nSie k√∂nnen den Datensatz z.B. hier beziehen oder √ºber das R-Paket palmerpenguins.\nGeben Sie keine Prozentzahlen, sondern stets Anteile an.\nBeachten Sie die √ºbrigen Hinweise.\n\n         \n\n\nL√∂sung\nZentrieren ist eigentlich immer n√ºtzlich, aber hier streng genommen nicht unbedingt n√∂tig. Der Hauptgrund ist, dass Stan f√ºr uns den Prior f√ºr den Intercept festlegt, und zwar auf Basis der Daten, wir uns also nicht um die komische Frage zu k√ºmmern brauchen, welchen Prior wir f√ºr den unzentrierten Achsenabschnitt vergeben wollten: Wie schwer sind Pinguins der Schnabell√§nge Null? Mit zentrierten Pr√§diktoren ist die Frage nach dem Prior viel einfacher zu beantworten: Wie schwer ist ein Pinguin mit mittelgro√üem Schnabel?\nSetup:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nEs wird in dieser Aufgabe vorausgesetzt, dass Sie den Datensatz selbst√§ndig importieren k√∂nnen. Tipp: Kurzes Googeln hilft ggf., den Datensatz zu finden.\nAlternativ k√∂nnten Sie den Datensatz als CSV-Datei importieren:\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\npenguins &lt;- data_read(d_path)  # oder z.B. mit read_csv \n\nEin Blick in die Daten zur Kontrolle, ob das Importieren richtig funktioniert hat:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nVertrauen ist gut, aber - was Golems betrifft - ist Kontrolle eindeutig besser ;-)\n\nPunktsch√§tzer\n\n\nm1 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Reproduzierbarkeit\n               refresh = 0)  # nicht so viel Output\n\n\nparameters(m1, ci_method = \"hdi\", ci = .9)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n359.9393\n0.9\n-112.36003\n834.8034\n0.89575\n1.000485\n4117.553\nnormal\n4201.754\n2004.8863\n\n\nbill_length_mm\n87.4472\n0.9\n76.99955\n98.3694\n1.00000\n1.000491\n4123.761\nnormal\n0.000\n367.2233\n\n\n\n\n\n\n\nAnzahl Parameter\n\nDas Modell hat 3 Paramter:\n\n\\(\\beta_0\\) (oder \\(\\alpha\\))\n\\(\\beta_01\\)\n\\(\\sigma\\)\n\n\nBreite des Intervalls\n\nDazu liest man die Intervallgrenzen (90% CI) in der richtigen Zeile ab (Tabelle parameters):\n\n 97.70  - 76.24\n\n[1] 21.46\n\n\nEinheit: mm\n\nEffektwahrscheinlichkeit\n\n\nm1_post &lt;-\n  m1 %&gt;% \n  as_tibble()\n\nm1_post %&gt;% \n  count(bill_length_mm &gt; 0)\n\n\n\n\n\nbill_length_mm &gt; 0\nn\n\n\n\n\nTRUE\n4000\n\n\n\n\n\n\nAlso: 100% oder 1 (4000 von 4000 Stichproben finden dieses Ergebnis in unserem Modell).\nMan kann diesen Wert aus der Tabelle oben (Ausgabe von parameters()) einfach in der Spalte pd ablesen. pd steht f√ºr probability of direction, s. Details hier.\nOder so, ist auch einfach:\n\npd_m1 &lt;- p_direction(m1) # aus Paket easystats\npd_m1\n\n\n\n\n\nParameter\npd\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.89575\nfixed\nconditional\n\n\nbill_length_mm\n1.00000\nfixed\nconditional\n\n\n\n\n\n\nUnd plotten ist meist hilfreich: plot(pd_m1).\nMan kann sich auch ein ‚ÄúDashboard‚Äù mit allen Ergebnissen des Modells ausgeben lassen:\n\nmodel_dashboard(m1)\n\n\nNur Adelie:\n\nWelche Spezies gibt es im Datensatz?\n\npenguins %&gt;% \n  count(species)\n\n\n\n\n\nspecies\nn\n\n\n\n\nAdelie\n152\n\n\nChinstrap\n68\n\n\nGentoo\n124\n\n\n\n\n\n\nFiltern:\n\npenguins_adelie &lt;-\n  penguins %&gt;% \n  filter(species == \"Adelie\")\n\nModell berechnen:\n\nm2 &lt;- stan_glm(body_mass_g ~  bill_length_mm,  # Regressionsgleichung\n               data = penguins_adelie, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\nDas Modell ist - bis auf die Daten - identisch zu m1.\n\nparameters(m2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n22.53919\n0.95\n-879.18205\n913.4400\n0.5185\n1.000466\n3934.802\nnormal\n3700.662\n1146.4153\n\n\nbill_length_mm\n94.71685\n0.95\n71.89291\n118.0511\n1.0000\n1.000492\n3910.510\nnormal\n0.000\n430.4322\n\n\n\n\n\n\n\nhdi(m2, parameters = \"bill_length_mm\")\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\nbill_length_mm\n0.95\n71.57412\n117.4872\nfixed\nconditional\n\n\n\n\n\n\nS. auch Tabelle oben.\n\n118.09 - 71.86\n\n[1] 46.23\n\n\n\nPrioris\n\n\ndescribe_prior(m1, component = \"auxiliary\")\n\n\n\n\n\nParameter\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\nnormal\n4201.754\n2004.8863\n\n\nbill_length_mm\nnormal\n0.000\n367.2233\n\n\n\n\n\n\nSteht auch in der Tabelle, die von parameters ausgegeben wird.\n\nCategories:\n\nbayes\nregression\nstring"
  },
  {
    "objectID": "posts/finde-prior/index.html",
    "href": "posts/finde-prior/index.html",
    "title": "finde-prior",
    "section": "",
    "text": "1 Aufgabe\nBetrachten Sie das folgende Bayes-Modell.\nAufgaben:\n\nIn welcher Zeile wird der Likelihood definiert?\nIn welcher Zeile wird der Prior f√ºr das Regressionsgewicht definiert?\nIn welcher Zeile wird der Prior f√ºr das die Vorhersageg√ºte des Modells definiert?\n\n\\[\\begin{align*}\n1. \\qquad \\text{y}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{???} \\\\\n2.  \\qquad \\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{???} \\\\\n3.  \\qquad \\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{???} \\\\\n4. \\qquad  \\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{???} \\\\\n5.  \\qquad \\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{???}\n\\end{align*}\\]\nHinweise:\n\nBeachten Sie die √ºblichen Hinweise des Datenwerks.\n\n  \n  \n  \n  \n\n\n2 L√∂sung\n\\[\\begin{align*}\n1. \\qquad \\text{y}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{Likelihood} \\\\\n2.  \\qquad \\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{Lineares Modell} \\\\\n3.  \\qquad \\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{Prior Achsenabschnitt} \\\\\n4. \\qquad  \\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{Prior Regressionsgewicht} \\\\\n5.  \\qquad \\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{Prior Vorhersageg√ºte}\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/tmdb03/tmdb03.html",
    "href": "posts/tmdb03/tmdb03.html",
    "title": "tmdb03",
    "section": "",
    "text": "Aufgabe\nWir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme.\nDie Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\n\n\nAufgabe\nReichen Sie bei Kaggle eine Submission f√ºr die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n\nSie m√ºssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym m√∂glich); alternativ k√∂nnen Sie sich mit einem Google-Konto anmelden.\nVerwenden Sie mehrere, und zwar folgende Algorithmen: Random Forest, Boosting, lineare Regression. Tipp: Ein Workflow-Set ist hilfreich.\nLogarithmieren Sie budget.\nBetreiben Sie Feature Engineering, zumindest etwas. Insbesondere sollten Sie den Monat und das Jahr aus dem Datum extrahieren und als Features (Pr√§diktoren) nutzen.\nVerwenden Sie tidymodels.\nDie Zielgr√∂√üe ist revenue in Dollars; nicht in ‚ÄúLog-Dollars‚Äù. Sie m√ºssen also r√ºcktransformieren, falls Sie revenue logarithmiert haben.\n\n         \n\n\nL√∂sung\nVorbereitung\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen\n#library(Metrics)\nlibrary(lubridate)  # Datumsangaben\nlibrary(VIM)  # fehlende Werte\nlibrary(visdat)  # Datensatz visualisieren\nlibrary(lubridate)  # Datum/Uhrzeit verarbeiten\nlibrary(doParallel)  # mehrere CPUs nutzen\n\n\nd_train_raw &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nMal einen Blick werfen:\n\nglimpse(d_train_raw)\nglimpse(d_test)\n\nTrain-Set verschlanken\n\nd_train &lt;-\n  d_train_raw %&gt;% \n  select(popularity, runtime, revenue, budget, release_date) \n\nDatensatz kennenlernen\n\nlibrary(visdat)\nvis_dat(d_train)\n\nFehlende Werte pr√ºfen\nWelche Spalten haben viele fehlende Werte?\n\nvis_miss(d_train)\n\nMit {VIM} kann man einen Datensatz gut auf fehlende Werte hin untersuchen:\n\naggr(d_train)\n\nRezept definieren\n\nrec1 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  #update_role(all_predictors(), new_role = \"id\") %&gt;% \n  #update_role(popularity, runtime, revenue, budget, original_language) %&gt;% \n  #update_role(revenue, new_role = \"outcome\") %&gt;% \n  step_mutate(budget = if_else(budget &lt; 10, 10, budget)) %&gt;% \n  step_log(budget) %&gt;% \n  step_mutate(release_date = mdy(release_date)) %&gt;% \n  step_date(release_date, features = c(\"year\"), keep_original_cols = FALSE) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_dummy(all_nominal())\n\nrec1\n\n\ntidy(rec1)\n\nCheck das Rezept \n\nprep(rec1, verbose = TRUE)\n\n\nd_train_baked &lt;- \nprep(rec1) %&gt;% \n  bake(new_data = NULL) \n\nd_train_baked\n\n\nd_train_baked %&gt;% \n  map_df(~ sum(is.na(.)))\n\nKeine fehlenden Werte mehr in den Pr√§diktoren.\nNach fehlenden Werten k√∂nnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train_baked)\n\nSo bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache.\nCheck Test-Sample\nDas Test-Sample backen wir auch mal. Das hat nur den Zwecke, zu pr√ºfen, ob unser Rezept auch richtig funktioniert. Das Preppen und Backen des Test-Samples wir automatisch von predict() bzw. last_fit() erledigt.\nWichtig: Wir preppen den Datensatz mit dem Train-Sample, auch wenn wir das Test-Sample backen wollen.\n\nrec1_prepped &lt;- prep(rec1)\n\nd_test_baked &lt;-\n  bake(rec1_prepped, new_data = d_test)\n\nd_test_baked %&gt;% \n  head()\n\n\n\nKreuzvalidierung\nNur aus Zeitgr√ºnden ist hier \\(v=5\\) eingestellt; besser w√§re z.B. \\(v=10\\) und \\(r=3\\).\n\ncv_scheme &lt;- vfold_cv(d_train,\n                      v = 5, \n                      repeats = 1)\n\n\n\nModelle\nBaum\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                mode = \"regression\")\n\nRandom Forest\n\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000,\n              mode = \"regression\") \n\nXGBoost\n\nmod_boost &lt;- boost_tree(mtry = tune(),\n                        min_n = tune(),\n                        trees = tune()) %&gt;% \n  set_mode(\"regression\")\n\nLM\n\nmod_lm &lt;-\n  linear_reg()\n\nWorkflow-Set\n\npreproc &lt;- list(rec1 = rec1)\nmodels &lt;- list(tree1 = mod_tree, \n               rf1 = mod_rf, \n               boost1 = mod_boost, \n               lm1 = mod_lm)\n \nall_workflows &lt;- workflow_set(preproc, models)\n\nFitten und tunen\n\n\nFitten/Tunen\nWenn man das Ergebnis-Objekt abgespeichert hat, dann kann man es einfach laden, spart Rechenzeit (der Tag ist kurz):\n\nresult_obj_file &lt;- \"tmdb_model_set.rds\"\n\n(Davon ausgehend, dass die Datei im Arbeitsverzeichnis liegt.)\nDann k√∂nnte man Folgendes machen:\n\nif (file.exists(result_obj_file)) {\n  tmdb_model_set &lt;- read_rds(result_obj_file)\n} else {\n  \n  &lt;computer_workflow_set_and_be_happy&gt;\n  \n}\n\nAchtung Gef√§hrlich! Zwischenspeichern auf der Festplatte birgt die Gefahr, dass man vergisst, das Objekt auf der Festplatte zu aktualisieren und Sie noch in einem Jahr und nach 100 Updates Ihres Rezepts immer noch das uralte Objekt von der Festplatte laden ‚Ä¶\nUm Rechenzeit zu sparen, kann man das Ergebnisobjekt abspeichern, dann muss man beim n√§chsten Mal nicht wieder von Neuem berechnen:\n\n#write_rds(tmdb_model_set, \"objects/tmdb_model_set.rds\")\n\nHier berechnen wir aber lieber das Modell neu:\n\ntic()\ntmdb_model_set &lt;-\n  all_workflows %&gt;% \n  workflow_map(\n    resamples = cv_scheme,\n    #grid = 10,\n    metrics = metric_set(rmse),\n    seed = 42,  # reproducibility\n    control = control_grid(verbose = FALSE))\ntoc()\n\nOhne Parallelisierung dauerte die Berechnung bei mir knapp 4 Minuten (225 Sec). Ich habe hier auf Parallelisierung verzichtet, da Tidymodels einen Fehler aufwarf mit der Begr√ºndung, dass das Paket lubridate in den parallel laufenden Instanzen nicht verf√ºgbar sei (und der parameter pckgs = 'lubridate keine Linderung brachte).\nCheck:\n\ntmdb_model_set[[\"result\"]][[1]]\n\nFinalisieren\nWelcher Algorithmus schneidet am besten ab?\nGenauer gesagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz.\n\ntune::autoplot(tmdb_model_set)\n\nR-Quadrat ist nicht so entscheidend; rmse ist wichtiger.\nDie Ergebnislage ist nicht ganz klar, aber einiges spricht f√ºr das Random-Forest-Modell.\n\ntmdb_model_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(mean) %&gt;% \n  slice_head(n = 10)\n\n\nbest_model_params &lt;-\nextract_workflow_set_result(tmdb_model_set, \"rec1_rf1\") %&gt;% \n  select_best()\n\nbest_model_params\n\nFinalisieren\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_rf1\")\n\nbest_wf\n\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n\nFinal Fit\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  fit(d_train)\n\nfit_final\n\n\nd_test$revenue &lt;- NA\n\nfinal_preds &lt;- \n  fit_final %&gt;% \n  predict(new_data = d_test) %&gt;% \n  bind_cols(d_test)\n\nSubmission\n\nsubmission_df &lt;-\n  final_preds %&gt;% \n  select(id, revenue = .pred)\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\nKaggle Score\nDiese Submission erzielte einen Score von 4.79227 (RMSLE).\n\nsol &lt;- 4.79227\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/summarise05/summarise05.html",
    "href": "posts/summarise05/summarise05.html",
    "title": "summarise05",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, wie viele Lenkr√§der bei der Auktion dabei waren.\nFassen Sie die Spalte total_pr zusammen und zwar zur MAA und zum IQR - pro Gruppe!\n\nGeben Sie den erste Wert des IQR als Antwort zur√ºck!\n         \n\n\nL√∂sung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nZusammenfassen:\n\nlibrary(DescTools)\nmariokart_gruppiert &lt;- group_by(mariokart, wheels)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, \n                             pr_iqr = IQR(total_pr),\n                             pr_maa = mean(abs(total_pr - mean(total_pr))),\n                             pr_maa2 = MeanAD(total_pr)\n                             )  # zusammenfassen\nmariokart_klein\n\n\n\n\n\nwheels\npr_iqr\npr_maa\npr_maa2\n\n\n\n\n0\n7.00\n7.046676\n7.046676\n\n\n1\n5.32\n3.250858\n3.250858\n\n\n2\n7.18\n11.907374\n11.907374\n\n\n3\n5.25\n5.250000\n5.250000\n\n\n4\n0.00\n0.000000\n0.000000\n\n\n\n\n\n\nM√∂chte man den MAA nicht von Hand ausrechnen, so kann man die Funktion MeanAD aus dem Paket DescTools nutzen (Denken Sie daran, dass Sie das Paket einmalig installiert haben m√ºssen.)\nDie L√∂sung lautet: 7.00\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nvariability\nnum"
  },
  {
    "objectID": "posts/tidymodels-poly02/tidymodels-poly02.html",
    "href": "posts/tidymodels-poly02/tidymodels-poly02.html",
    "title": "tidymodels-poly02",
    "section": "",
    "text": "Aufgabe\nFitten Sie ein Polynomial-Modell f√ºr folgende Modellgleichung:\nbody_mass_g ~ bill_length_mm.\nGesucht ist der RMSE im Test-Set (optimal hinsichtlich minimalem Prognosefehler).\nHinweise:\n\nDatensatz penguins (palmerpenguins)\nVerwenden Sie Tidymodels\nFitten Sie Polynome des Grades 1 bis 10.\nDefinieren Sie die Polynomegrade als Tuningparameter.\nEntfernen Sie fehlende Werte in den Pr√§diktoren.\nWie immer gilt: Verwenden Sie die Standardeinstellungen der Funktionen, soweit nicht anders angegeben.\n\n         \n\n\nL√∂sung\nSetup:\n\nlibrary(tidymodels)\ndata(penguins, package = \"palmerpenguins\")\n\nDatenaufteilung:\n\nd_split &lt;- initial_split(penguins)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nRezept:\n\nrec1 &lt;- \n  recipe(body_mass_g ~ bill_length_mm, data = penguins) %&gt;% \n  step_naomit(all_predictors()) %&gt;% \n  step_poly(all_predictors(), degree = tune()) %&gt;% \n  update_role(contains(\"_poly_\"), new_role = \"predictor\")\n\nCheck:\n\nd_baked &lt;- bake(prep(rec1), new_data = NULL)\n\nRezepte mit Tuningparametern kann man nicht preppen/backen.\nWorkflow:\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(linear_reg()) %&gt;% \n  add_recipe(rec1)\n\nTuning:\n\nset.seed(42)\ntune1 &lt;-\n  tune_grid(\n    wf1,\n    resamples = vfold_cv(data = penguins),\n    metrics = metric_set(rmse),\n    grid = grid_regular(degree(range = c(1, 10)),\n                               levels = 10),\n    control = control_grid(save_workflow = TRUE)\n  )\n\n\nautoplot(tune1)\n\n\n\n\n\n\n\n\n\nshow_best(tune1)\n\n\n\n\n\ndegree\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n2\nrmse\nstandard\n638.2267\n10\n22.70394\npre02_mod0_post0\n\n\n4\nrmse\nstandard\n641.2418\n10\n23.69291\npre04_mod0_post0\n\n\n1\nrmse\nstandard\n642.9314\n10\n21.83462\npre01_mod0_post0\n\n\n5\nrmse\nstandard\n643.0979\n10\n23.48819\npre05_mod0_post0\n\n\n3\nrmse\nstandard\n643.1772\n10\n24.16118\npre03_mod0_post0\n\n\n\n\n\n\nFinalisieren:\n\nbest1 &lt;- fit_best(tune1)\nbest1\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: linear_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_naomit()\n‚Ä¢ step_poly()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n          (Intercept)  bill_length_mm_poly_1  bill_length_mm_poly_2  \n                 4202                   8813                  -1708  \n\n\nPredicten:\n\nfinal1 &lt;- last_fit(best1, d_split)\n\nError in `last_fit()`:\n! `last_fit()` is not well-defined for a fitted workflow.\n\ncollect_metrics(final1)\n\nError: object 'final1' not found\n\n\nOder so:\n\nsol &lt;- \npredict(best1, new_data = d_test) %&gt;% \n  bind_cols(d_test) %&gt;% \n  rmse(truth = body_mass_g, estimate = .pred) %&gt;% \n  pull(.estimate) %&gt;% \n  pluck(1)\n\nsol\n\n[1] 662.8083\n\n\nDie Antwort lautet: 662.8083105.\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Many shiny pieces",
    "section": "",
    "text": "verteilungsfunktion-penguins\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nprob-voll-esystem\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nprob-disjunkt\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-relationen\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nsophie-kann-fliegen\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nlikelihood-nv\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nziel-bayes\n\n\n\nbayes\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\ninterpret-ci2\n\n\n\ninference\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\ngruppenvergleich-regression\n\n\n\ninference\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\ninterpret-ci\n\n\n\ninference\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-postbreite\n\n\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nJun 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nschmalste-post\n\n\n\nprobability\n\ndistributions\n\nexam24\n\n\n\n\n\n\n\n\n\nJun 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nstreuung-post\n\n\n\nbayes\n\n\n\n\n\n\n\n\n\nJun 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nconfounder-example\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nMay 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nfofrage-regrformel2\n\n\n\nbayes\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nmodelldef-regrformel\n\n\n\nbayes\n\npaper\n\nregression\n\n\n\n\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nqm2-quiz-inferenz\n\n\n\nqm2\n\n2024\n\ninference\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nrope2a\n\n\n\nrope\n\nbayes\n\nregression\n\nexam-22\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-regr02a\n\n\n\nbayes\n\nrope\n\nregression\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-02a\n\n\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-rope\n\n\n\nregression\n\nbayes\n\nrope\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-01a\n\n\n\nbayes\n\nregression\n\nstring\n\nqm2\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-05a\n\n\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npupil-size2\n\n\n\nprobability\n\nbayes\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3e1-7-paper\n\n\n\nbayes\n\nprobability\n\npost\n\nbayesbox\n\npaper\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post3a\n\n\n\nbayes\n\nregression\n\npost\n\nexam-22\n\nqm2\n\npaper\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post_paper\n\n\n\nbayes\n\npost\n\nestimation\n\nexam-22\n\nqm2\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWskt-Schluckspecht2\n\n\n\npost\n\nbayes\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nkekse03\n\n\n\nprobability\n\nbayesbox\n\nbayes\n\npaper\n\n\n\n\n\n\n\n\n\nNov 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nglobus-bin2\n\n\n\nprobability\n\nbayes\n\ndistributions\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nbayesbox2\n\n\n\nbayes\n\nprobability\n\npaper\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsimu-uniform\n\n\n\nprobability\n\nsimulation\n\npaper\n\ndistributions\n\n\n\n\n\n\n\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\niq02a\n\n\n\nprobability\n\npaper\n\nnormal-distribution\n\nVerteilungen-Quiz24\n\nnum\n\n\n\n\n\n\n\n\n\nOct 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ngem-wskt4\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nOct 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nimport-mtcars\n\n\n\nmtcars\n\nR\n\ndata\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nbertie-bott3\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-simpson\n\n\n\nlm\n\nbayes\n\nregression\n\ncausal\n\n\n\n\n\n\n\n\n\nOct 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nprob-vereinigung\n\n\n\ndistributions\n\n\n\n\n\n\n\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsamples-nyc2\n\n\n\ninference\n\nstory\n\nyacsda\n\n\n\n\n\n\n\n\n\nSep 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nwikipedia\n\n\n\nsimulation\n\nprobability\n\nstory\n\nnullhypothesis\n\n\n\n\n\n\n\n\n\nAug 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nflights-delay\n\n\n\nlm\n\nregression\n\ninteraction\n\nyacsda\n\n\n\n\n\n\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nflights-yacsda-eda\n\n\n\neda\n\nyacsda\n\nvariability\n\nassociation\n\n\n\n\n\n\n\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\noecd-yacsda\n\n\n\neda\n\ndatawrangling\n\nvis\n\nyacsda\n\nR\n\n\n\n\n\n\n\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmutate03\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm_parameterzahl_simple\n\n\n\nbayes\n\nregression\n\nparameters\n\n\n\n\n\n\n\n\n\nJan 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nkollision-eignung\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsaratoga-cor1\n\n\n\nR\n\nvis\n\ncausal\n\neda\n\n\n\n\n\n\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWskt-Schluckspecht\n\n\n\npost\n\nbayes\n\nregression\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nchatgpt-sentiment-simple\n\n\n\ntextmining\n\nnlp\n\ntransformer\n\nchatgpt\n\nsentiment\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-emojis\n\n\n\ntextmining\n\ntidymodels\n\ncount\n\ngermeval\n\nemoji\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval04\n\n\n\n2023\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-textfeatures-rand-for\n\n\n\n2023\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval02\n\n\n\ntextmining\n\ntidymodels\n\ngermeval\n\nsentiment\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval05\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nwordvec\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-08-name-clash\n\n\n\nR\n\nerror\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-07\n\n\n\nR\n\nerror\n\nmchoice\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkekse02\n\n\n\nprobability\n\nbayesbox\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npostvert-vis-zwielicht\n\n\n\n2023\n\nvis\n\nbayes\n\npost\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m5\n\n\n\nprobability\n\nbayes\n\nbayesbox\n\nrethink-chap2\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbath42\n\n\n\nquiz\n\nprobability\n\nbayes\n\nnum\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m2\n\n\n\nprobability\n\nbayesbox\n\nbayes\n\nrethink-chap2\n\nstring\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m3\n\n\n\nprobability\n\nbayes\n\nrethink-chap2\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m4\n\n\n\nprobability\n\nbayes\n\nbayesbox\n\nrethink-chap2\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntotale-Wskt1\n\n\n\nR\n\nprobability\n\nbayes\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngroesse01\n\n\n\n2023\n\nbayes\n\nbayesbox\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGem-Wskt2\n\n\n\nprobability\n\nbayes\n\ncloze\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz10\n\n\n\nquiz\n\nprobability\n\nbayes\n\ndistributions\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz17\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\noptions-print\n\n\n\n2023\n\nR\n\ntidyverse\n\nmarkdown\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nalphafehler-inflation3\n\n\n\nprobability\n\nR\n\ninference\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz19\n\n\n\nquiz\n\nprobability\n\nbayes\n\ndistributions\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nalphafehler-inflation4\n\n\n\nprobability\n\nR\n\ninference\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkaefer2\n\n\n\nR\n\nbayes\n\nbayesbox\n\nnum\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree1\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndag-graph\n\n\n\nfopro\n\nresearchdesign\n\ncausal\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsentiws2\n\n\n\ntextmining\n\ntokenizer\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq03\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq04\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nabh-ereignisse2\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel06\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz18\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nalphafehler-inflation2\n\n\n\nprobability\n\nR\n\ninference\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz20\n\n\n\nquiz\n\nprobability\n\ninference\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz16\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGem-Wskt3\n\n\n\nprobability\n\ndyn\n\nbayes\n\nnum\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz11\n\n\n\nquiz\n\nprobability\n\nbayes\n\ndistributions\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq05\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq02\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKlausuren-bestehen\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmodellguete-testset\n\n\n\nregression\n\nperformance\n\nrmse\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrethink3m1\n\n\n\nbayes\n\nppv\n\nprobability\n\nstring\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex02\n\n\n\ntextmining\n\nregex\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwithin-design-analysis1\n\n\n\nregression\n\nwithin-design\n\nresearchdesign\n\nfopro\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren1a\n\n\n\nregression\n\n2023\n\nstring\n\nqm2\n\nqm2-pruefung2023\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Wskt2\n\n\n\nprobability\n\nbayes\n\nnum\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-lexicon\n\n\n\ntextmining\n\nnlp\n\nregex\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz02\n\n\n\nquiz\n\nprobability\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz05\n\n\n\nquiz\n\nprobability\n\ndistributions\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-05\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex03\n\n\n\nregex\n\ntextmining\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig_var3\n\n\n\ndyn\n\nprobability\n\nnum\n\nmtcars\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nppv-dyn1\n\n\n\nbayes\n\nppv\n\nregression\n\nnum\n\nmtcars\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\names-kaggle1\n\n\n\nregression\n\ndata\n\nkaggle\n\nstring\n\nkaggle\n\n\n\n\n\n\n\n\n\nJun 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntargets-multiple-data-files\n\n\n\nprojectmgt\n\ntargets\n\nrepro\n\nstring\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npca\n\n\n\neda\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-lasso2\n\n\n\ntidymodels\n\nstatlearning\n\nlasso\n\nlm\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap1\n\n\n\nstatlearning\n\nds1\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels1\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\ndyn\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike04\n\n\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike03\n\n\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTest-MSE2\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-lasso3\n\n\n\ntidymodels\n\nstatlearning\n\nlasso\n\nlm\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-finalize\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike02\n\n\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-vorlage\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntitanic_casestudy\n\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCluster02\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlex-vs-nichtflex-Methode3\n\n\n\nstatlearning\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbootstrap\n\n\n\nstatlearning\n\ninference\n\nschoice\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwfsets_penguins02\n\n\n\nR\n\nstatlearning\n\ntidymodels\n\nnum\n\nwfsets\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnyc_casestudy\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlex-vs-nichtflex-Methode2\n\n\n\nstatlearning\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlex-vs-nichtflex-Methode\n\n\n\nstatlearning\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsmape\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nShrinkage1\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm-mario2\n\n\n\nR\n\nlm\n\npredict\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-03\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-04\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-02\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbreiman\n\n\n\nds1\n\nprediction\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr2\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nassociation\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-regr01\n\n\n\nlm\n\nmtcars\n\nassociation\n\nregression\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkorr-als-regr\n\n\n\nlm\n\nregression\n\nstring\n\nassociation\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregression1a\n\n\n\nregression\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr4\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nassociation\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr3\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nassociation\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm1\n\n\n\nregression\n\nlm\n\nstats-nutshell\n\nschoice\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkorr02\n\n\n\ndyn\n\neda\n\nassociation\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression5\n\n\n\ndyn\n\nregression\n\nlm\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nanim01\n\n\n\n2023\n\nvis\n\nanimation\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKennwert-robust\n\n\n\neda\n\nlagema√üe\n\nvariability\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa07\n\n\n\ndata\n\neda\n\nlagema√üe\n\nvariability\n\nstring\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-mariokart-variab\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\nvis\n\nvariability\n\nstring\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsd-vergleich\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\nvis\n\nvariability\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmw-berechnen\n\n\n\neda\n\ndatawrangling\n\ndyn\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmw-berechnen2\n\n\n\neda\n\ndatawrangling\n\ndyn\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-max2\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmutate02\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidydata1\n\n\n\ndatawrangling\n\ntidy\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle9\n\n\n\neda\n\n2023\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle7\n\n\n\neda\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter01\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle1\n\n\n\neda\n\ndatawrangling\n\ntidyverse\n\ndplyr\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLogikpruefung2\n\n\n\nR\n\n2023\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-01\n\n\n\nR\n\n2023\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nthere-is-no-package\n\n\n\nR\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertberechnen2\n\n\n\nR\n\ndyn\n\nnum\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertzuweisen_mc\n\n\n\nR\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-06a\n\n\n\nR\n\n2023\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nboxhist\n\n\n\nvis\n\neda\n\nen\n\ncloze\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmax-corr1\n\n\n\nvis\n\n2023\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDiamonds-Histogramm-Vergleich2\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nboxplots-de1a\n\n\n\nvis\n\neda\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvariability01\n\n\n\nvariability\n\nbasics\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDef-Statistik01\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKausale-Verben\n\n\n\ncausal\n\nresearch-question\n\nmchoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidy1\n\n\n\ntidy\n\ndatawrangling\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal02\n\n\n\ndag\n\ncausal\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal03\n\n\n\ndag\n\ncausal\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel01\n\n\n\nprobability\n\ndice\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post2\n\n\n\nbayes\n\nregression\n\npost\n\nexam-22\n\nqm2\n\nmtcars\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal05\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal04\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal-bedrooms1\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal-einfach\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nttest-skalenniveau\n\n\n\nttest\n\nregression\n\nvariable-levels\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegression2\n\n\n\nregression\n\ndyn\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBayes-Ziel1\n\n\n\nregression\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nLikelihood2\n\n\n\nregression\n\nbayes\n\nlikelihood\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBayesmod-bestimmen01\n\n\n\nregression\n\nbayes\n\nprior\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPost-befragen1\n\n\n\nregression\n\nbayes\n\npost\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPostvert-Regr-01\n\n\n\nregression\n\nbayes\n\npost\n\npaper\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nfattails02\n\n\n\nprobability\n\nbayes\n\nbayesbox\n\nsimulation\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-05\n\n\n\ndistributions\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz\n\nVerteilungen-Quiz24\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-02\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\nsimulation\n\nquiz\n\nqm2\n\ncomputer\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-03\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nVerteilungen-Quiz24\n\nprobability\n\nbayes\n\npaper\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-04\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nVerteilungen-Quiz\n\nVerteilungen-Quiz24\n\nprobability\n\nbayes\n\npaper\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-17\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\nsimulation\n\ncomputer\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-10\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nAnteil-Apple\n\n\n\nbayes\n\nbayesbox\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\niq-studentis\n\n\n\nprobability\n\nbayes\n\nsimulation\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWarum-Bayes\n\n\n\nqm2\n\nbayes\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSim-Prior\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ninferenz-fuer-alle\n\n\n\nqm2\n\ninference\n\nuncertainty\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmuenze-weird\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\nbestehen_ohne_lernen\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nOct 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nprob-ereignisraum\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nparameter-genau\n\n\n\ninference\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nboxplot_with_points\n\n\n\nvis\n\ntidyverse\n\n\n\n\n\n\n\n\n\nSep 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nstreuung-post2\n\n\n\nbayes\n\n\n\n\n\n\n\n\n\nJun 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nmaschinendesaster\n\n\n\nprobability\n\nR\n\nnum\n\nexam24\n\n\n\n\n\n\n\n\n\nJun 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nrowmeans-groupby-summarise\n\n\n\ntidyverse\n\ndatawrangling\n\n\n\n\n\n\n\n\n\nJun 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nfofrage-regrformel\n\n\n\nbayes\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWskt-Schluckspecht2a\n\n\n\npost\n\nbayes\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nrope-luecke\n\n\n\nregression\n\nrope\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-regr02b\n\n\n\nbayes\n\nrope\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm01a\n\n\n\nprobability\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-04a\n\n\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nexp-tab2\n\n\n\ndistributions\n\nprobability\n\npaper\n\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nnorm-sd\n\n\n\ndistributions\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nkekse01\n\n\n\nprobability\n\nbayesbox\n\nbayes\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ndistros\n\n\n\nprobability\n\ndistributions\n\npaper\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nremove-digits\n\n\n\ntextmining\n\nstring\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-lm\n\n\n\nlm\n\nen\n\nregression\n\npenguins\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-easystats\n\n\n\ndatawrangling\n\ntidyverse\n\neda\n\nen\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nflights-delay-simplified\n\n\n\nlm\n\nregression\n\ninteraction\n\nyacsda\n\n\n\n\n\n\n\n\n\nJun 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmario-compare-models\n\n\n\nlm\n\nregression\n\ninteraction\n\n\n\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsmartphone1\n\n\n\nR\n\neda\n\ndatawrangling\n\nvis\n\nyacsda\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nimport-xls\n\n\n\nR\n\ndata\n\n\n\n\n\n\n\n\n\nApr 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nr-quiz\n\n\n\nR\n\nen\n\nquiz\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-df-r\n\n\n\nprobability\n\nR\n\ncomputer\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKausal\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nJan 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsaratoga-cor2\n\n\n\nR\n\nvis\n\ncausal\n\neda\n\n\n\n\n\n\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nScikit-Learn-LLM Zero Shot Learners\n\n\n\ntextmining\n\nnlp\n\ntransformer\n\nchatgpt\n\nsentiment\n\nscikit\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwfsets1\n\n\n\nR\n\nstatlearning\n\ntidymodels\n\nwfsets\n\ntemplate\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval10-wordvec-rf\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nstring\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npupil-size\n\n\n\nprobability\n\nbayes\n\nregression\n\nstring\n\ncomputer\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval09-tfidf\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval01-textfeatures\n\n\n\n2023\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval06\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nwordvec\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmovie-sentiment1\n\n\n\ntextmining\n\nimdb\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval-textfeatures01\n\n\n\ntidymodels\n\ntextmining\n\nprediction\n\nsentiment\n\ngermeval\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nna-per-col\n\n\n\nR\n\ndatawrangling\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval07\n\n\n\n2023\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-error1introd\n\n\n\ntidymodels\n\nstatlearning\n\nerror\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m1\n\n\n\nprobability\n\nbayesbox\n\nrethink-chap2\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsicherheit2\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m6\n\n\n\nprobability\n\nbayes\n\nbayesbox\n\nrethink-chap2\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig_var3a\n\n\n\nprobability\n\nbayes\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBayes-Theorem1\n\n\n\nbayes\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbayes2\n\n\n\nR\n\nbayes\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m7\n\n\n\nprobability\n\nbayes\n\nbayesbox\n\nrethink-chap2\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nk-coins-k-hits\n\n\n\nprobability\n\ndyn\n\nbayes\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nabh-ereignisse\n\n\n\nR\n\nprobability\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngroesse02\n\n\n\n2023\n\nbayes\n\nbayesbox\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAdditionssatz1\n\n\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree2\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nspeed\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkaefer1\n\n\n\nR\n\nbayes\n\nbayesbox\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq09\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree5\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nspeed\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq07\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz14\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz13\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\npaper\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nVar-vs-Stufe\n\n\n\nfopro\n\nresearchdesign\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq01\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nexam-22\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq06\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree4\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nspeed\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree3\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nspeed\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq08\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel05\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz12\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz15\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKrebs1\n\n\n\nbayes\n\nprobability\n\nnum\n\nbayesbox\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz08\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Wskt1\n\n\n\nprobability\n\nbayes\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz06\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz01\n\n\n\nquiz\n\nprobability\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq03a\n\n\n\nprobability\n\npaper\n\nnormal-distribution\n\nnum\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nOct 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nstep-dummy\n\n\n\ntidymodels\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-emoji\n\n\n\ntextmining\n\nnlp\n\nstring\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nds-quiz2\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nmchoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npredictioncontest1\n\n\n\nR\n\nds1\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPCA1\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nOLS-Minimierung\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike01\n\n\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels3\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nlm\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTest-MSE1\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwfsets_penguins01\n\n\n\nR\n\nstatlearning\n\ntidymodels\n\nnum\n\nwfsets\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmse\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCluster01\n\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCV1\n\n\n\nstatlearning\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-finalize2\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-lasso\n\n\n\ntidymodels\n\nstatlearning\n\nlasso\n\nlm\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnichtlineare-regr1\n\n\n\nlm\n\nvis\n\nqm2\n\nregression\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregression1b\n\n\n\nregression\n\nR\n\nlm\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr1\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nassociation\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa03\n\n\n\ndata\n\neda\n\nassociation\n\nstring\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregression1\n\n\n\nregression\n\ndyn\n\nlm\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression6\n\n\n\ndyn\n\nregression\n\nexam-22\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nanim03\n\n\n\n2023\n\nvis\n\nanimation\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nanim02\n\n\n\n2023\n\nvis\n\nanimation\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa04\n\n\n\ndata\n\neda\n\nlagema√üe\n\nvis\n\nanimation\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKennwert-robust2\n\n\n\neda\n\nvariability\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-max1\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSchiefe1\n\n\n\nschoice\n\neda\n\ndistributions\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSchiefe-erkennen\n\n\n\neda\n\ndistributions\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMWberechnen\n\n\n\neda\n\ndatawrangling\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmutate01\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr-uebersetzen\n\n\n\ndatawrangling\n\ntidyverse\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLogikpruefung1\n\n\n\nR\n\n2023\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nimport-mtcars\n\n\n\nR\n\ndata\n\nmtcars\n\nnum\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertzuweisen\n\n\n\nR\n\n2023\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertpruefen\n\n\n\nR\n\n2023\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-02\n\n\n\nR\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-04\n\n\n\nR\n\n2023\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-03\n\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPfad\n\n\n\nR\n\ndatawrangling\n\nqm1\n\nqm2\n\nstring\n\ndata\n\nimport\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDiamonds-Histogramm-Vergleich\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmax-corr2\n\n\n\nvis\n\n2023\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHistogramm-in-Boxplot\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nZiele-Statistik\n\n\n\nbasics\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvariability02\n\n\n\nvariability\n\nbasics\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal01\n\n\n\ndag\n\ncausal\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npigs2\n\n\n\nbayes\n\nqm2\n\nqm2-pruefung2023\n\nregression\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-mtcars-1l\n\n\n\npost\n\nbayes\n\nregression\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal06\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal08\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal09\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal07\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret03\n\n\n\nbayes\n\nregression\n\nqm2\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope-regr\n\n\n\nbayes\n\nregression\n\nrope\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret02\n\n\n\nbayes\n\nregression\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nposterior_interval\n\n\n\nbayes\n\nregression\n\npost\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-rope1\n\n\n\nbayes\n\nregression\n\npost\n\nexam-22\n\nqm2\n\nmtcars\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm_prioriwerte\n\n\n\nbayes\n\nregression\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope4\n\n\n\nrope\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope3\n\n\n\nrope\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm_parameterzahl\n\n\n\nbayes\n\nregression\n\nparameters\n\n\n\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBayesmod-bestimmen02\n\n\n\nregression\n\nbayes\n\nprior\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nfattails01\n\n\n\nprobability\n\nsimulation\n\nfat-tails\n\nbayes\n\nbayesbox\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nverteilungen-quiz-01\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-06\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nqm2-pruefung2023\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-08\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-09\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-07\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\nqm2\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-13\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-14\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm01\n\n\n\nprobability\n\nbayes\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrethink3m2\n\n\n\nbayes\n\npost\n\nprobability\n\ncomputer\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlose-nieten-binomial-grid\n\n\n\nprobability\n\nbinomial\n\ndistributions\n\ncomputer\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel04\n\n\n\nprobability\n\ndice\n\nsimulation\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nvoll-normal\n\n\n\nprobability\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nGem-Wskt1\n\n\n\nprobability\n\nqm2\n\nqm2-pruefung2023\n\ndyn\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nungewiss-arten-regression\n\n\n\nqm2\n\ninference\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ninterpret-koeff\n\n\n\nregression\n\nlm\n\nbayes\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nvorhersageintervall1\n\n\n\nlm\n\ninference\n\nqm2\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlm-standardfehler\n\n\n\ninference\n\nlm\n\nqm2\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\neti-hdi\n\n\n\npaper\n\nbayes\n\nbayesbox\n\nprobability\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\naussagen-infstat\n\n\n\ninference\n\nexam24\n\n\n\n\n\n\n\n\n\nJun 27, 2026\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-relationen2\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nprob-elementarereignis\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nprob-disjunkt2\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nprob-sicher-unm√∂glich\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\neinhoerner-fliegen\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nrope3a\n\n\n\nrope\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr-mtcars1\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\nmtcars\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-xgb-plain\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\nxgb\n\ntune\n\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-vorlage3\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-remove-na2\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren2_var1\n\n\n\nlm\n\nregression\n\nbayes\n\nadjust\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-penguins\n\n\n\nvis\n\nyacsda\n\nggquick\n\npenguins\n\nstring\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb02\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\ntrees\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb05\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nrandom-forest\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregr-tree02\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nmtcars\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTengku-Hanis01\n\n\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\ntrees\n\nspeed\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins07\n\n\n\ntidymodels\n\nstatlearning\n\ntrees\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na5\n\n\n\n2023\n\neda\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na2\n\n\n\n2023\n\neda\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise04\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-sd3\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise03\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean2\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndiamonds-histogram\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nn-vars-diagram\n\n\n\nvis\n\n2023\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPPV1a-mtcars\n\n\n\nbayes\n\nregression\n\nexam-22\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post\n\n\n\nbayes\n\npost\n\nestimation\n\nexam-22\n\nqm2\n\nmtcars\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMediterran-Alk\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal23\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal24\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal28\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nanova-skalenniveau\n\n\n\nvariable-levels\n\nanova\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ngriech-buchstaben-inferenz\n\n\n\nqm2\n\ninference\n\nparameters\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nsubjektiv-Bayes\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter03\n\n\n\ntextmining\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter04\n\n\n\ntextmining\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map02\n\n\n\nR\n\nmap\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-simple3\n\n\n\nregression\n\nen\n\nbayes\n\nfrequentist\n\nqm1\n\nstats-nutshell\n\nqm2\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nttest-als-regression\n\n\n\nregression\n\nttest\n\nvariable-levels\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nexp2\n\n\n\ndistributions\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\nxls-online-import\n\n\n\ndata\n\ndatawrangling\n\n\n\n\n\n\n\n\n\nOct 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nindifferenz-p\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\npwert2\n\n\n\ninference\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nkorr-ungewiss\n\n\n\ninference\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\neinsamkeit-modellierung\n\n\n\nbayes\n\nregression\n\nfopro\n\nyacsda\n\n\n\n\n\n\n\n\n\nJun 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\ntutorium-kausal\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nMay 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart_desk-inf-mod\n\n\n\nR\n\nbayes\n\nlagema√üe\n\nregression\n\ntidyverse\n\nvis\n\nyacsda\n\n\n\n\n\n\n\n\n\nFeb 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nanz-params\n\n\n\nbayes\n\npaper\n\nregression\n\n\n\n\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret02a\n\n\n\nbayes\n\nregression\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nfinde-prior\n\n\n\nbayes\n\nregression\n\n\n\n\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nqm2-quiz-wskt\n\n\n\nqm2\n\n2024\n\nprobability\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nqm2-quiz-verteilungen\n\n\n\nqm2\n\n2024\n\ndistributions\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nqm2-quiz-globus\n\n\n\nqm2\n\n2024\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-interact2\n\n\n\nbayes\n\nregression\n\npaper\n\nqm2\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-interact\n\n\n\nbayes\n\nregression\n\npaper\n\nqm2\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-06\n\n\n\nbayes\n\nregression\n\nstring\n\nqm2\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-mtcars-5meilen\n\n\n\npost\n\nbayes\n\nregression\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ngenial\n\n\n\nbayes\n\nprobability\n\nnum\n\nbayesbox\n\n\n\n\n\n\n\n\n\nDec 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nexp-tab\n\n\n\ndistributions\n\nprobability\n\npaper\n\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ngroesse04\n\n\n\nbayes\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsmall-wide-normal\n\n\n\nnormal-distribution\n\ndistributions\n\nposterior\n\nbayes\n\npencil\n\n\n\n\n\n\n\n\n\nNov 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nexp1\n\n\n\nprobability\n\ndistributions\n\npaper\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post2a\n\n\n\nbayes\n\nregression\n\npost\n\nexam-22\n\nqm2\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-weight\n\n\n\nbayes\n\npost\n\npaper\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ngroesse03\n\n\n\nbayes\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nbfi10\n\n\n\nbayes\n\nnormal-distribution\n\ndistributions\n\nbayesbox\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nbayesbox3\n\n\n\nbayes\n\nprobability\n\npaper\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nglobus-bin1\n\n\n\nprobability\n\nbayes\n\ndistributions\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nglobus2\n\n\n\nbayes\n\nprobability\n\ndistributions\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nglobus3\n\n\n\nbayes\n\nprobability\n\ndistributions\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nglobus1\n\n\n\nbayes\n\nprobability\n\ndistributions\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nbayesbox\n\n\n\nbayes\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsimu-unif2\n\n\n\nprobability\n\nsimulation\n\npaper\n\ndistributions\n\n\n\n\n\n\n\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsimu-unif3\n\n\n\nprobability\n\nsimulation\n\npaper\n\ndistributions\n\n\n\n\n\n\n\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\niq01a\n\n\n\nprobability\n\npaper\n\nnormal-distribution\n\nVerteilungen-Quiz24\n\nnum\n\n\n\n\n\n\n\n\n\nOct 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nfun1\n\n\n\nR\n\nprogramming\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-lm2\n\n\n\nlm\n\nen\n\nregression\n\npenguins\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsamples-nyc\n\n\n\ninference\n\nstory\n\nyacsda\n\n\n\n\n\n\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npd1\n\n\n\ninference\n\nbayes\n\n\n\n\n\n\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-vis-bodymass1\n\n\n\nvis\n\n\n\n\n\n\n\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-vis-bodymass2\n\n\n\nvis\n\n\n\n\n\n\n\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nchatgpt-sentiment-loop-all\n\n\n\ntextmining\n\nnlp\n\ntransformer\n\nchatgpt\n\nsentiment\n\n\n\n\n\n\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nhintertuer\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-glm\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\ntune\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-elasticnet\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\nelasticnet\n\ntune\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nchatgpt-sentiment-loop\n\n\n\ntextmining\n\nnlp\n\ntransformer\n\nchatgpt\n\nsentiment\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-rf-tune\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\nrandom-forest\n\ntune\n\n\n\n\n\n\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval-sent-wordvec-xgb-tune\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\nxgb\n\ntune\n\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-rf-plain\n\n\n\ntextmining\n\ndatawrangling\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\nrandom-forest\n\ntune\n\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-xgb\n\n\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nsentiment\n\nstring\n\nxgb\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nemojis1\n\n\n\nemoji\n\ntextmining\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval08-schimpf\n\n\n\n2023\n\ntextmining\n\ndatawrangling\n\ngermeval\n\nprediction\n\ntidymodels\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-words01\n\n\n\ntextmining\n\ntidymodels\n\ncount\n\ngermeval\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-emoji-emo\n\n\n\ntextmining\n\nnlp\n\nemoji\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval-senti01\n\n\n\ntidymodels\n\ntextmining\n\nprediction\n\nsentiment\n\ngermeval\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval08-extract-spacy\n\n\n\nwordvec\n\ntextmining\n\npython\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrethink4e1\n\n\n\nprobability\n\nbayes\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-remove-na\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkung-height2\n\n\n\nbayes\n\npaper\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq10\n\n\n\nprobability\n\nsimulation\n\nnormal-distribution\n\nbayes\n\nbayesbox\n\nnum\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren2a\n\n\n\nregression\n\n2023\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz04\n\n\n\nquiz\n\nprobability\n\ndistributions\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz03\n\n\n\nquiz\n\nprobability\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nausreisser1\n\n\n\neda\n\ndatawrangling\n\ntidyverse\n\nausreisser\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWeinhaendler\n\n\n\nprobability\n\nbayesbox\n\nbayes\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Wskt3\n\n\n\nprobability\n\nbayes\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncorona-blutgruppe\n\n\n\nprobability\n\ndependent\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nurne2\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNerd-gelockert\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex01\n\n\n\ntextmining\n\nregex\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m5\n\n\n\nbayes\n\nppv\n\nprobability\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBsp-Binomial\n\n\n\nprobability\n\nbinomial\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz07\n\n\n\nquiz\n\nprobability\n\nbayes\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz09\n\n\n\nquiz\n\nprobability\n\nbayes\n\ndistributions\n\nquiz1-qm2-ws23\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m4\n\n\n\nbayes\n\nppv\n\nprobability\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nurne1\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKlausur-raten\n\n\n\nprobability\n\ndyn\n\nbayes\n\nnum\n\nqm2-pruefung2023\n\nqm2\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsicherheit\n\n\n\nR\n\nprobability\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrepro1-sessioninfo\n\n\n\nR\n\nrepro\n\nstring\n\n\n\n\n\n\n\n\n\nOct 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-gapminder\n\n\n\nvis\n\nyacsda\n\nggquick\n\ngapminder\n\nstring\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-mtcars\n\n\n\nvis\n\nyacsda\n\nggquick\n\nmtcars\n\nstring\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-01\n\n\n\nbayes\n\nregression\n\nstring\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal28\n\n\n\ndag\n\ncausal\n\nschoice\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal29\n\n\n\ndag\n\ncausal\n\nschoice\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nppv-mtcars1\n\n\n\nbayes\n\nppv\n\nregression\n\nnum\n\nmtcars\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndurch3-durch5\n\n\n\nR\n\nchallenge\n\nstring\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex-insert-char\n\n\n\ntextmining\n\nregex\n\nstring\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm-mario3\n\n\n\nR\n\nlm\n\npredict\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nds-quiz\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nmchoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb06\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nrandom-forest\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels_workflowset01\n\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb01\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nrandom-forest\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb08\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nrandom-forest\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndiamonds-tidymodels01\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins02\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins05\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting1\n\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsupervisedlearning\n\n\n\nstatlearning\n\nds1\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-poly01\n\n\n\nR\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb07\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregr-tree01\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nn-se\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins04\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins03\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels2\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nerror\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-usemodels\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm-mario1\n\n\n\nR\n\nlm\n\npredict\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngini-plot\n\n\n\n2023\n\nvis\n\nstatlearning\n\ntrees\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-finalize3\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-01\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidytext\n\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins06\n\n\n\ntidymodels\n\nstatlearning\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins01\n\n\n\nds1\n\ntidymodels\n\nprediction\n\nyacsda\n\nstatlearning\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nknn-ames01\n\n\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting2\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSzenario-charakterisieren1\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregr-tree03\n\n\n\nstatlearning\n\ntrees\n\ntidymodels\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-vorlage2\n\n\n\ntidymodels\n\nstatlearning\n\ntemplate\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb04\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nrandom-forest\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb03\n\n\n\nds1\n\ntidymodels\n\nstatlearning\n\ntmdb\n\nrandom-forest\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-poly02\n\n\n\nR\n\nstatlearning\n\ntidymodels\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na1\n\n\n\n2023\n\neda\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na3\n\n\n\n2023\n\neda\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na4\n\n\n\n2023\n\neda\n\nna\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa06\n\n\n\ndata\n\neda\n\nlagema√üe\n\nstring\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression3\n\n\n\ndyn\n\nregression\n\nlm\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLinearitaet1a\n\n\n\nlm\n\nregression\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression4\n\n\n\ndyn\n\nregression\n\nlm\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ninterpret-koeff-lm\n\n\n\nregression\n\nlm\n\nstring\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkorr01\n\n\n\ndyn\n\neda\n\nassociation\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-regr02\n\n\n\nlm\n\nbayes\n\nrope\n\nstring\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa05\n\n\n\ndata\n\neda\n\nlagema√üe\n\nvis\n\nanimation\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa01\n\n\n\ndata\n\neda\n\nlagema√üe\n\nvariability\n\nstring\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nStreuung-Histogramm\n\n\n\neda\n\nvariability\n\ndyn\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-sd1\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise06\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-desk01\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\nvis\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-sd2\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise05\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nvariability\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean1\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle10\n\n\n\neda\n\nlagema√üe\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise01\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa02\n\n\n\ndata\n\neda\n\nlagema√üe\n\nstring\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean4\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean3\n\n\n\ndatawrangling\n\ndplyr\n\neda\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise02\n\n\n\ndatawrangling\n\neda\n\ntidyverse\n\ndplyr\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\naffairs-dplyr\n\n\n\ndatawrangling\n\neda\n\nstring\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle4\n\n\n\neda\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle3\n\n\n\ndatawrangling\n\neda\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle5\n\n\n\neda\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nhaeufigkeit01\n\n\n\ndatawrangling\n\neda\n\ncount\n\nstring\n\nmtcars\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nargumente\n\n\n\nR\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertberechnen\n\n\n\nR\n\ndyn\n\nnum\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmovies-vis2\n\n\n\nvis\n\neda\n\nstring\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRidges-vergleichen\n\n\n\nvis\n\ndyn\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmin-corr1\n\n\n\nvis\n\n2023\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwozu-balkendiagramm\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmovies-vis1\n\n\n\nvis\n\neda\n\nstring\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBoxplot-Aussagen\n\n\n\nvis\n\neda\n\ndyn\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwozu-streudiagramm\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nStreudiagramm\n\n\n\nvis\n\n2023\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSkalenniveau1a\n\n\n\ndyn\n\nvariable-levels\n\nvariable-levels\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSkalenniveau1b\n\n\n\ndyn\n\nvariable-levels\n\nvariable-levels\n\nmchoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig_var2\n\n\n\ndyn\n\nprobability\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post3\n\n\n\nbayes\n\nregression\n\npost\n\nexam-22\n\nqm2\n\nqm2-pruefung2023\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-04\n\n\n\nbayes\n\nregression\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-03\n\n\n\nbayes\n\nregression\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-02\n\n\n\nbayes\n\nregression\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-05\n\n\n\nbayes\n\nregression\n\nexam-22\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrope2\n\n\n\nrope\n\nbayes\n\nregression\n\nexam-22\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal21\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal26\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal10\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal27\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal20\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrandomdag1\n\n\n\ncausal\n\ndag\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal_corona_glatze\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal25\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal22\n\n\n\ndag\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret\n\n\n\nbayes\n\nregression\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nNullhyp-Beispiel\n\n\n\nnullhypothesis\n\ninference\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ninteraktionseffekt1\n\n\n\ninteraction\n\nregression\n\npaper\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ndiamonds-nullhyp-mws\n\n\n\nbayes\n\nregression\n\nnullhypothesis\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nzwert-berechnen\n\n\n\nz-value\n\nR\n\nmath\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope1\n\n\n\nrope\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Post-Wskt1\n\n\n\nregression\n\nbayes\n\npost\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPriorwahl1\n\n\n\nfat-tails\n\ndistributions\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nLikelihood-identifizieren\n\n\n\nregression\n\nbayes\n\nlikelihood\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPriorwahl2\n\n\n\nregression\n\nbayes\n\ndistributions\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrethink3e1-7\n\n\n\nbayes\n\nprobability\n\npost\n\nbayesbox\n\ncomputer\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-11\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-16\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-18\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-15\n\n\n\ndistributions\n\nprobability\n\nbayes\n\npaper\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-12\n\n\n\ndistributions\n\nVerteilungen-Quiz\n\nprobability\n\nbayes\n\npaper\n\nVerteilungen-Quiz24\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter07\n\n\n\ntextmining\n\ntwitter\n\nprogramming\n\n\n\n\n\n\n\n\n\nNov 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npriori-streuung\n\n\n\nprobability\n\nsimulation\n\ndistributions\n\nbayes\n\nqm2\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrethink4e3\n\n\n\nbayes\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrethink4e2\n\n\n\nprobability\n\nbayes\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nfat-tails-Artikel\n\n\n\nprobability\n\ndistributions\n\nfat-tails\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nKung-height\n\n\n\nbayes\n\nppv\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrethink3m3\n\n\n\nbayes\n\nppv\n\nprobability\n\ncomputer\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nzwielichter-dozent-bayes\n\n\n\nbayes\n\nprobability\n\nppv\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter01\n\n\n\ntextmining\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter06\n\n\n\ntextmining\n\ntwitter\n\nprogramming\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel03\n\n\n\nprobability\n\ndice\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel02\n\n\n\nprobability\n\ndice\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter05\n\n\n\ntextmining\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter02\n\n\n\ntextmining\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\neuro-bayes\n\n\n\nprobability\n\nbayesbox\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map01\n\n\n\nR\n\nmap\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map06\n\n\n\nprogramming\n\nloop\n\nmtcars\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig\n\n\n\nprobability\n\ndependent\n\nmtcars\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map05\n\n\n\nprogramming\n\nloop\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map03\n\n\n\nR\n\nmap\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map04\n\n\n\nR\n\nmap\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-simple1\n\n\n\nregression\n\nen\n\nbayes\n\nfrequentist\n\nqm1\n\nstats-nutshell\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlog-y-regression3\n\n\n\nstats-nutshell\n\nqm2\n\nregression\n\nlog\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlog-y-regression2\n\n\n\nregression\n\nlm\n\nqm2\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren1\n\n\n\nqm2\n\nlm\n\nbayes\n\nstats-nutshell\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npunktschaetzer-reicht-nicht\n\n\n\nregression\n\nen\n\nbayes\n\nfrequentist\n\nqm1\n\nstats-nutshell\n\nqm2\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-simple2\n\n\n\nregression\n\nen\n\nbayes\n\nfrequentist\n\nqm1\n\nstats-nutshell\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlog-y-regression1\n\n\n\nregression\n\nlm\n\nqm2\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren2\n\n\n\nregression\n\nlm\n\nqm2\n\nbayes\n\nadjust\n\nqm2-pruefung2023\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nStichprobenziehen1\n\n\n\nlm\n\ninference\n\nqm2\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nGriech-Buchstaben-Inferenz\n\n\n\nqm2\n\ninference\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret03a\n\n\n\nbayes\n\nregression\n\nqm2\n\nmtcars\n\npaper\n\n\n\n\n\n\n\n\n\nJan 3, 2022\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "English.html",
    "href": "English.html",
    "title": "English",
    "section": "",
    "text": "Note\n\n\n\n\nThis book is written in German. However, your browser will easily translate the text to your favorite language. Please check your browser‚Äôs documentation for details. Translation should be achieved with one or two clicks. Have fun!\\(\\square\\)"
  },
  {
    "objectID": "English.html#translation-to-english",
    "href": "English.html#translation-to-english",
    "title": "English",
    "section": "",
    "text": "Note\n\n\n\n\nThis book is written in German. However, your browser will easily translate the text to your favorite language. Please check your browser‚Äôs documentation for details. Translation should be achieved with one or two clicks. Have fun!\\(\\square\\)"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Untitled",
    "section": "",
    "text": "√úberschrift\nsjdfk\nsdjklf\n\ndfsjk\nsdfjlk\n\n\n \nThis is a form spacer\n\nA text field (1)\n  \n\n\nAnother text field (2)"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html#a-welche-variable-entspricht-der-zufallsvariable-gewicht-des-tieres",
    "href": "posts/verteilungsfunktion-penguins/index.html#a-welche-variable-entspricht-der-zufallsvariable-gewicht-des-tieres",
    "title": "verteilungsfunktion-penguins",
    "section": "2.1 A) Welche Variable entspricht der Zufallsvariable Gewicht des Tieres?",
    "text": "2.1 A) Welche Variable entspricht der Zufallsvariable Gewicht des Tieres?\n\nnames(penguins)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\n\n`‚Äúbody_mass_g‚Äù ``"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html#b-was-ist-die-wahrscheinlichkeit-dass-ein-pinguin-weiblich-ist",
    "href": "posts/verteilungsfunktion-penguins/index.html#b-was-ist-die-wahrscheinlichkeit-dass-ein-pinguin-weiblich-ist",
    "title": "verteilungsfunktion-penguins",
    "section": "2.2 B) Was ist die Wahrscheinlichkeit, dass ein Pinguin weiblich ist?",
    "text": "2.2 B) Was ist die Wahrscheinlichkeit, dass ein Pinguin weiblich ist?\n\npenguins |&gt; \n  filter(sex == \"female\") |&gt; \n  nrow() / nrow(penguins)\n\n[1] 0.4796512"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html#c-visualisieren-sie-die-wahrscheinlichkeitsverteilung-des-gewichts.",
    "href": "posts/verteilungsfunktion-penguins/index.html#c-visualisieren-sie-die-wahrscheinlichkeitsverteilung-des-gewichts.",
    "title": "verteilungsfunktion-penguins",
    "section": "2.3 C) Visualisieren Sie die Wahrscheinlichkeitsverteilung des Gewichts.",
    "text": "2.3 C) Visualisieren Sie die Wahrscheinlichkeitsverteilung des Gewichts.\n\ngghistogram(penguins, x = \"body_mass_g\")\n\n\n\n\n\n\n\n\n\nggdensity(penguins, x = \"body_mass_g\")"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html#d-visualisieren-sie-die-verteilungsfunktion-des-gewichts.",
    "href": "posts/verteilungsfunktion-penguins/index.html#d-visualisieren-sie-die-verteilungsfunktion-des-gewichts.",
    "title": "verteilungsfunktion-penguins",
    "section": "2.4 D) Visualisieren Sie die Verteilungsfunktion des Gewichts.",
    "text": "2.4 D) Visualisieren Sie die Verteilungsfunktion des Gewichts.\nDie empirische kumulative Verteilungsfunktion nennt man auf Englisch: empirical cumulative distribution function, kurz ECDF.\nDaf√ºr gibt es eine Funktion in ggpubrund in ggplot2.\n\nggecdf(penguins, x = \"body_mass_g\")\n\n\n\n\n\n\n\n\nEin bisschen cooler:\n\npenguins_clean &lt;- penguins %&gt;%\n  filter(!is.na(body_mass_g))\n\n# ECDF plot with ggpubr\nggecdf(\n  data = penguins_clean,\n  x = \"body_mass_g\",\n  color = \"species\",   # optional: color by species\n  add = \"mean\",        # optional: add mean line\n  xlab = \"Body Mass (g)\",\n  ylab = \"ECDF\",\n  title = \"Empirical CDF of Penguin Body Mass\"\n)"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html#e-visualisieren-sie-den-erwartungswert-des-gewichts.",
    "href": "posts/verteilungsfunktion-penguins/index.html#e-visualisieren-sie-den-erwartungswert-des-gewichts.",
    "title": "verteilungsfunktion-penguins",
    "section": "2.5 E) Visualisieren Sie den Erwartungswert des Gewichts.",
    "text": "2.5 E) Visualisieren Sie den Erwartungswert des Gewichts.\n\nggdensity(penguins, x = \"body_mass_g\", add = \"mean\")"
  },
  {
    "objectID": "posts/verteilungsfunktion-penguins/index.html#f-visualisieren-sie-die-varianz-des-gewichts.",
    "href": "posts/verteilungsfunktion-penguins/index.html#f-visualisieren-sie-die-varianz-des-gewichts.",
    "title": "verteilungsfunktion-penguins",
    "section": "2.6 F) Visualisieren Sie die Varianz des Gewichts.",
    "text": "2.6 F) Visualisieren Sie die Varianz des Gewichts.\nDie Breite der Verteilung zeigt die Varinaz.\n\nggdensity(penguins, x = \"body_mass_g\", add = \"mean\")"
  }
]