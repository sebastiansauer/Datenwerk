{
  "hash": "017f5e288c6bbfdcd4e8de4391f6a204",
  "result": {
    "markdown": "---\nexname: lm-Standardfehler\nextype: schoice\nexsolution: 1\nexshuffle: no\ncategories:\n- inference\n- lm\n- qm2\ndate: '2022-09-04'\nslug: lm-Standardfehler\ntitle: lm-Standardfehler\n\n---\n\n\n\n\n\n\n\n\n# Exercise\n\nMan kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt.\nZumeist wird dazu der *Standardfehler* (engl. standard error, SE) verwendet.\n\nIn dieser Übung untersuchen wir,\nwie sich der SE als Funktion der Stichprobengröße, $n$, verhält.\n\n\nErstellen Sie dazu folgenden Datensatz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nn <- 2^4\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n```\n:::\n\n\n\nHier ist das Ergebnis. Uns interessiert v.a. `Std. Error` für den Prädiktor `x`: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y ~ x, data = d) %>% \nsummary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.60191 -0.42922  0.09198  0.32313  0.59878 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.1226     0.1061  -1.156    0.267    \nx             1.0385     0.0888  11.694  1.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4223 on 14 degrees of freedom\nMultiple R-squared:  0.9071,\tAdjusted R-squared:  0.9005 \nF-statistic: 136.8 on 1 and 14 DF,  p-value: 1.302e-08\n```\n:::\n:::\n\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\n\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie,\nwie sich die Schätzgenauigkeit, gemessen über den SE, verändert.\nBerechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\n\nBei welcher Stichprobengröße ist SE am kleinsten?\n\nAnswerlist\n----------\n* $2^5$\n* $2^6$\n* $2^7$\n* $2^8$\n* $2^9$\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\nProbieren wir es aus!\n\nErste Verdopplung, $n=2^5$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^5\n\nd5 <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nlm5 <- lm(y ~ x, data = d5)\n\nlm5 %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x, data = d5)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.65187 -0.29109 -0.07686  0.31015  0.69899 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.04455    0.07604   0.586    0.562    \nx            1.02917    0.07532  13.664 2.04e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4162 on 30 degrees of freedom\nMultiple R-squared:  0.8616,\tAdjusted R-squared:  0.857 \nF-statistic: 186.7 on 1 and 30 DF,  p-value: 2.036e-14\n```\n:::\n:::\n\n\n\n\nMan kann sich den Standardfehler komfortabler ausgeben lassen,\nwenn man das Paket `broom` verwendet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nlm5 %>% \n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   0.0446    0.0760     0.586 5.62e- 1\n2 x             1.03      0.0753    13.7   2.04e-14\n```\n:::\n:::\n\n\nDann könnte man z.B. die Spalte `std.error` selektieren und nach `term==x` filtern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm5 %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0753\n```\n:::\n:::\n\n\nJetzt mit den anderen Stichprobengrößen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^6\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0687\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^7\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0408\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^8\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0297\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^9\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0205\n```\n:::\n:::\n\n\nAnswerlist\n----------\n\n\n* Falsch\n* Falsch\n* Falsch\n* Falsch\n* Wahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\n\n\n\n---\n\nCategories: \n\n- inference\n- lm\n- qm2\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}