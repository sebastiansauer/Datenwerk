{
  "hash": "017f5e288c6bbfdcd4e8de4391f6a204",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: lm-Standardfehler\nextype: schoice\nexsolution: 1\nexshuffle: no\ncategories:\n- inference\n- lm\n- qm2\ndate: '2022-09-04'\nslug: lm-Standardfehler\ntitle: lm-Standardfehler\n\n---\n\n\n\n\n\n\n\n\n# Exercise\n\nMan kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt.\nZumeist wird dazu der *Standardfehler* (engl. standard error, SE) verwendet.\n\nIn dieser Übung untersuchen wir,\nwie sich der SE als Funktion der Stichprobengröße, $n$, verhält.\n\n\nErstellen Sie dazu folgenden Datensatz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nn <- 2^4\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n```\n:::\n\n\n\nHier ist das Ergebnis. Uns interessiert v.a. `Std. Error` für den Prädiktor `x`: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y ~ x, data = d) %>% \nsummary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8039 -0.3986 -0.1500  0.6939  0.8013 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.1610     0.1446   1.114    0.284    \nx             1.1144     0.1660   6.711 9.92e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5777 on 14 degrees of freedom\nMultiple R-squared:  0.7629,\tAdjusted R-squared:  0.746 \nF-statistic: 45.04 on 1 and 14 DF,  p-value: 9.919e-06\n```\n\n\n:::\n:::\n\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\n\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie,\nwie sich die Schätzgenauigkeit, gemessen über den SE, verändert.\nBerechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\n\nBei welcher Stichprobengröße ist SE am kleinsten?\n\nAnswerlist\n----------\n* $2^5$\n* $2^6$\n* $2^7$\n* $2^8$\n* $2^9$\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\nProbieren wir es aus!\n\nErste Verdopplung, $n=2^5$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^5\n\nd5 <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nlm5 <- lm(y ~ x, data = d5)\n\nlm5 %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = d5)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.06790 -0.28655 -0.06282  0.25958  1.18567 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.08955    0.10349  -0.865    0.394    \nx            1.01855    0.08561  11.898 6.91e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5155 on 30 degrees of freedom\nMultiple R-squared:  0.8251,\tAdjusted R-squared:  0.8193 \nF-statistic: 141.6 on 1 and 30 DF,  p-value: 6.91e-13\n```\n\n\n:::\n:::\n\n\n\n\nMan kann sich den Standardfehler komfortabler ausgeben lassen,\nwenn man das Paket `broom` verwendet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nlm5 %>% \n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -0.0896    0.103     -0.865 3.94e- 1\n2 x             1.02      0.0856    11.9   6.91e-13\n```\n\n\n:::\n:::\n\n\nDann könnte man z.B. die Spalte `std.error` selektieren und nach `term==x` filtern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm5 %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0856\n```\n\n\n:::\n:::\n\n\nJetzt mit den anderen Stichprobengrößen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^6\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0580\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^7\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0388\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^8\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0325\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^9\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  tidy() %>% \n  filter(term == \"x\")  %>% \n  select(std.error) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  std.error\n      <dbl>\n1    0.0216\n```\n\n\n:::\n:::\n\n\nAnswerlist\n----------\n\n\n* Falsch\n* Falsch\n* Falsch\n* Falsch\n* Wahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\n\n\n\n---\n\nCategories: \n\n- inference\n- lm\n- qm2\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}