---
extype: string
exsolution: NA
exname: purrr-map04
expoints: 1
categories:
- r
- map
- tidyverse
date: '2022-10-10'
slug: purrr-map04
title: purrr-map04

---




```{r}
library(tidyverse)
```


# Exercise

Importieren Sie das Grundatzprogramm der Partei AfD (in der aktuellen Version). 
Tokenisieren Sie nach Seiten. 
Dann verschachteln Sie die Spalte, in denen der Text der Seite steht, zu einer Listenspalte.
Schließlich zählen Sie die Anzahl der Wörter pro Seite und berichten gängige deskriptive Statistiken dazu.








</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Solution

Text aus PDF-Dateien kann man mit dem Paket [`pdftools`](https://docs.ropensci.org/pdftools/) einlesen:

```{r}
library(pdftools)
d_path <- "/Users/sebastiansaueruser/Google Drive/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf"

d <- tibble(text = pdf_text(d_path),
            page = 1:length(text))
```


Zu Seiten tokenisieren brauchen wir nicht; das Datenmaterial ist bereits nach Seiten organisiert.

Jetzt "verschachteln" (to nest) wir die Spalte mit dem Text:

```{r}
d2 <-
  d %>% 
  nest(data = text)

head(d2)
```



Dann zählen wir die Wörter pro Seite:


```{r}
d3 <-
  d2 %>% 
  mutate(word_count_per_page = map(data, ~ str_count(.x$text, "\\w+")))

head(d3)
```
Wie sieht eine Zelle aus `data` aus?


```{r}
d3$data[[1]]
```

Wie sieht eine Zelle aus `word_count_per_page` aus?

```{r}
d3$data[[1]]
```

Ah! Darin steckt nur eine einzelne Zahl!

```{r}
d3$data[[1]] %>% str()
```


Das heißt, wir können vereinfachen, entschacheln:

```{r}
d4 <-
  d3 %>% 
  unnest(word_count_per_page)

head(d4)
```

Visualisierung:

```{r}
d4 %>% 
  ggplot(aes(x = word_count_per_page)) +
  geom_histogram()
```


```{r}
library(easystats)
describe_distribution(d4$word_count_per_page)
```





---

Categories: 

- r
- map
- tidyverse

