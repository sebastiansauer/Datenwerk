---
date: 2023-12-06 
draft: FALSE   
title: chatgpt-sentiment-simple
extype: string
exsolution: ""
categories:
- textmining
- nlp
- transformer
- chatgpt
- sentiment
execute:
  error: true
  eval: false
---








```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      fig.align = "center",
                      echo = TRUE, 
                      message = FALSE,
                      fig.show = "hold")
```







# Aufgabe


Fragen Sie ChatGPT via API zum Sentiment des ersten Texts aus dem Germeval-2018-Datensatz (Train).


![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/1200px-ChatGPT_logo.svg.png){width=25% fig-align="center"}



Hinweise:

- Beachten Sie die [Standardhinweise des Datenwerks](https://datenwerk.netlify.app/hinweise).
- Nutzen Sie Python, nicht R.
- Das Verwenden der OpenAI-API kostet Geld. ðŸ’¸ Informieren Sie sich vorab. Um auf die API zugreifen zu kÃ¶nnen, mÃ¼ssen Sie sich ein Konto angelegt haben und Ã¼ber ein Guthaben verfÃ¼gen.



</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# LÃ¶sung


::: {.callout-attention}
OpenAI hat eine neue API (Stand: 2023-11-23). Der Code der alten API bricht. ðŸ’” $\square$
:::


Module importieren:

```{python}
from openai import OpenAI
```


Anmelden bei OpenAI:

```{python}
client = OpenAI()
```


::: {.callout-note}
Dieses Verfahren setzt voraus, dass in `.Renviron` die Variable `OPENAI_API_KEY` hinterlegt ist. $\square$
:::


Textschnipsel, das zu klassifizieren ist:

```{python}
text = "@corinnamilborn Liebe Corinna, wir wÃ¼rden dich gerne als Moderatorin fÃ¼r uns gewinnen! WÃ¤rst du begeisterbar?"
```


Prompt definieren:

```{python}
my_prompt  = f"Analysieren Sie das Sentiment des folgenden Texts:\n{text}"
```


Anfrage an die API, in eine Funktion gepackt:

```{python}
def get_completion(prompt, client_instance, model="gpt-3.5-turbo"):
  messages = [{"role": "user", "content": prompt}]
  response = client_instance.chat.completions.create(
  model=model,
  messages=messages,
  max_tokens=50,
  temperature=0,
  )
  return response.choices[0].message.content
```


Und los:

```{python ask-api}
get_completion(my_prompt, client) 
```

