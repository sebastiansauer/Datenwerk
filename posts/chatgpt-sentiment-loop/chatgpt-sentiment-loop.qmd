---
date: today
draft: FALSE   # ACHTUNG DRAFT STEHT AUF TRUE!
title: chatgpt-sentiment-loop
execute: 
  eval: true 
  
highlight-style: arrow 
cache: true

extype: string
exsolution: ""
categories:
- textmining
- nlp
- transformer
- chatgpt
- sentiment
---








```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      echo = TRUE, 
                      message = FALSE,
                      fig.show = "hold")
```








# Aufgabe


Fragen Sie ChatGPT via API zum Sentiment der ersten zwei Texte aus dem Germeval-2018-Datensatz (Train).


Hinweise:

- Beachten Sie die [Standardhinweise des Datenwerks](https://datenwerk.netlify.app/hinweise).
- Nutzen Sie Python, nicht R.
- Das Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen.



</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# L√∂sung


::: {.callout-attention}
OpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî $\square$
:::


Die richtige venv nutzen:

```{r}
library(reticulate)
#virtualenv_create("chatgpt")
use_virtualenv("chatgpt")
```


Check zu Python:

```{r}
reticulate::py_config()
```

Ggf. noch Module installieren:

```{r}
#reticulate::py_install("pandas")
```


Module importieren:

```{python}
from openai import OpenAI
import pandas as pd
import time 
```

Versionen der importierten Module:

```{python}
pd.__version__
```


```{zsh}
#| echo: fenced
pip list | grep openai
```


Wir brauchen `>= 1.35`.

Daten importieren:

```{python import-data}
csv_file_path_train = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv'

germeval_train = pd.read_csv(csv_file_path_train)
```


Die ersten paar Texte herausziehen:

```{python tweets-first-few}
n_tweets = 2
tweets_first_few = germeval_train["text"].head(n_tweets).tolist()
tweets_first_few
```


Prompt definieren:

```{python}
prompt_stem  = "Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes zu erkennen. Bitte antworten Sie nur mit einem Wort, entweder 'positiv', 'neutral' oder 'negativ'. Dieses Wort soll die Insgesamt-Einsch√§tzung des Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folt der Text, dessen Sentiment Sie einsch√§tzen sollen: \n"
```


Mit "List Comprehension" k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:

```{python}
prompts = [prompt_stem + tweet for tweet in tweets_first_few]
prompts[0]
```

Check: Wie viele Elemente hat die Liste `prompts`?

```{python}
len(prompts)
```



Anmelden bei OpenAI:

```{python}
client = OpenAI()
```


::: {.callout-note}
Dieses Anmeldeverfahren setzt voraus, dass in `.Renviron` die Variable `OPENAI_API_KEY` hinterlegt ist. $\square$
:::






Anfrage an die API, in eine Funktion gepackt:

```{python}
def get_completion(prompt, client_instance, model="gpt-3.5-turbo"):
  messages = [{"role": "user", "content": prompt}]
  response = client_instance.chat.completions.create(
    model=model,
    messages=messages,
    max_tokens=50,
    temperature=0,
  )
  return response.choices[0].message.content
```


Und jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:

```{python}
results = []
```


```{python ask-api}
start_time = time.time()

for prompt in prompts:
  result = get_completion(prompt, client) 
  results.append(result)

end_time = time.time()
end_time - start_time
```

Voil√†:


```{python}
print(results)
```

