---
exname: tidymodels-penguins07
extype: schoice
exsolution: r fmt(sol)
exshuffle: no
expoints: 1
categories:
- tidymodels
- statlearning
- trees
- schoice
date: '2023-05-17'
slug: tidymodels-penguins07
title: tidymodels-penguins07
execute:
  error: true
---






```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      cache = TRUE,
                      echo = TRUE,
                      message = FALSE,
                      fig.show = "hold")

library(tidyverse)
library(exams)
```






# Aufgabe

Berechnen Sie ein Entscheidungsbaum-Modell mit tidymodels und zwar anhand des penguins Datensatzes.

Modellgleichung: `body_mass_g ~ bill_length_mm`.

Berichten Sie die RMSE!



Hinweise:

- Tuning Sie $Cp$ mit 20 verschiedenen den Werten.
- Löschen Sie alle Zeilen mit fehlenden Werten in den Prädiktoren.
- Beachten Sie die [üblichen Hinweise](https://datenwerk.netlify.app/hinweise).
- Natürlich gilt: Ceteris paribus. Halten Sie also die Modelle im Übrigen vergleichbar bzw. identisch.






</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Lösung

## Setup

```{r}
library(tidymodels)
library(tidyverse)
library(tictoc)  # Rechenzeit messen, optional
# data(penguins, package = "palmerpenguins")
d_path <- "https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv"
d <- read_csv(d_path)
```


Wir dürfen keine fehlenden Werte in der Y-Variable haben (im Train-Set),
sonst meckert Tidymodels:


```{r}
d2 <- 
  d %>% 
  drop_na(body_mass_g)
```

# CV

## Daten aufteilen:

```{r}
set.seed(42)
d_split <- initial_split(d2)
d_train <- training(d_split)
d_test <- testing(d_split)
```



## CV

```{r}
set.seed(42)
folds <- vfold_cv(d_train, v = 10)
```




## Workflow



```{r}
rec1 <-
  recipe(body_mass_g ~ bill_length_mm, data = d_train) %>% 
  step_naomit(all_numeric_predictors())

mod_tree <- 
decision_tree(
  mode = "regression",
  cost_complexity = tune()
)

wflow <-
  workflow() %>%
  add_recipe(rec1) %>%
  add_model(mod_tree)
```




## Fitten

```{r}
tic()
wflow_fit <-
  tune_grid(
    wflow,
    resamples = folds,
    control = control_grid(save_workflow = TRUE),
    grid = 20,
    metrics = metric_set(rmse)
    )
toc()
```




## Modellgüte


```{r}
bestfit1 <- fit_best(x = wflow_fit)
lastfit1 <- last_fit(bestfit1, d_split)
collect_metrics(lastfit1)
```





---

Categories: 

- tidymodels
- statlearning
- trees
- schoice

