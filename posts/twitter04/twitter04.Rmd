---
extype: string
exsolution: NA
exname: twitter04
expoints: 1
categories:
- textmining
- twitter
date: '2022-10-28'
slug: twitter04
title: twitter04

---








# Exercise


Laden Sie $n=10^k$ Tweets von Twitter herunter (mit $k=2$) via der Twitter API; Suchterm soll sein "@karl_lauterbach".
Bereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopwörter entfernen, Zahlen entfernen, ...).
Berichten Sie dann die 10 häufigsten Wörter als Schätzer für die Dinge, die an Karl Lauterbach getweetet werden.





</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Solution





```{r}
library(rtweet)
library(tidyverse)
library(tidytext)
library(lsa)  # Stopwörter
library(SnowballC)  # Stemming
```

```{r eval=FALSE}
source("/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R")
```

```{r eval=FALSE}
auth <- rtweet_app(bearer_token = Bearer_Token)
```





```{r eval=FALSE}
karl1 <- search_tweets("@karl_lauterbach", n = 1e2, include_rts = FALSE)
#write_rds(karl1, file = "karl1.rds", compress = "gz")
```



```{r echo=FALSE}
karl_raw <- 
  read_rds(file = "/Users/sebastiansaueruser/datasets/tweets_to_karl_lauterbach.rds")

karl1 <-
  karl_raw %>% 
  slice_head(n = 100)
```


```{r}
karl2 <- 
  karl1 %>% 
  select(full_text)
```


```{r}
karl3 <- 
  karl2 %>% 
  unnest_tokens(output = word, input = full_text)
```


```{r}
karl4 <- 
karl3 %>% 
  anti_join(tibble(word = lsa::stopwords_de)) 
```


```{r}
karl5 <- 
  karl4 %>% 
  mutate(word = str_replace_na(word, "^[:digit:]+$")) %>% 
  mutate(word = str_replace_na(word, "hptts?://\\w+")) %>% 
  mutate(word = str_replace_na(word, " +")) %>% 
  drop_na()
```


```{r}
karl6 <-
  karl5 %>% 
  mutate(word = wordStem(word))
```



```{r}
karl6 %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n=10)
```






---

Categories: 

- textmining
- twitter

