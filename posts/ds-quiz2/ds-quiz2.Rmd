---
exname: ds-quiz2
extype: mchoice
exsolution: 37385
exshuffle: yes
categories:
- ds1
- tidymodels
- statlearning
- mchoice
date: '2023-05-17'
slug: ds-quiz2
title: ds-quiz2

---





```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      echo = FALSE,
                      message = FALSE,
                      fig.show = "hold")
```






# Aufgabe

Im Folgenden sind mehrere Aussagen zum Thema maschinelles Lernen dargestellt.
Wählen Sie alle korrekten Aussagen aus!

Hinweise:

- Alle Aussagen sind entweder richtig oder falsch, aber nicht beides.
- Beziehen Sie sich im Zweifel auf den Stoff wie im Unterricht dargestellt.



Answerlist
----------

* Je größer der Wert von `mtry` in einem Random-Forest-Modell, desto besser die Modellgüte in der Regel.
* Random-Forest-Modelle und Baginng-Modelle basieren auf einem Bootstrapping-Verfahren.
* Beim kNN-Modell ist ein Distanzmaß $d$ die euklidische Distanz, die sich im 2D-Fall wie folgt berechnet: $d = \sqrt{a^2 + b^2}$. Dabei sind $a$ und $b$ die Distanz zwischen zwei Punkten $x$ und $y$ in den Dimensionen $A$ und $B$.
* Beim Random-Forest-Modell nennt man den Teil der Train-Stichprobe, der nicht in die Berechnung des jeweiligen Baumes einfließt, die "OOB-Stichprobe".
* Overfitting tritt bei linearen Modellen nicht auf.
* Berechnet man die Vorhersagegüte eines Modells in mehreren Stichproben, so kann man die Vorhersagegüte für ein Test-Sample präziser bestimmen.
* Bei baumbasierten Klassifikationsmodellen ist es dazu Ziel, die Homogenität (hinsichtlich der AV) in jedem Endknoten ("Blatt") zu maximieren.


</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Lösung


Answerlist
----------


* Falsch. Die obige Behauptung stimmt oft nicht.
* Richtig.
* Richtig.
* Richtig.
* Falsch. Zwar tritt Overfitting bei (einfachen) linearen Modellen oft weniger auf, aber gerade bei Verwendung von Polynomen ist die Gefahr des Overfitting hoch.
* Richtig.
* Richtig




---

Categories: 

- ds1
- tidymodels
- statlearning
- mchoice

