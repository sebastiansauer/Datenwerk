---
exname: tmdb07
extype: num
exsolution: r sol
extol: 0.5
expoints: 1
categories:
- ds1
- tidymodels
- statlearning
- tmdb
- num
date: '2023-05-17'
slug: tmdb07
title: tmdb07

---




```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      echo = TRUE,
                      message = FALSE,
                      fig.show = "hold")
```






# Aufgabe

Melden Sie sich an für die Kaggle Competition [TMDB Box Office Prediction -
Can you predict a movie's worldwide box office revenue?](https://www.kaggle.com/competitions/tmdb-box-office-prediction/overview).

Sie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.

Bei diesem Prognosewettbewerb geht es darum, vorherzusagen,
wieviel Umsatz wohl einige Filme machen werden. 
Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung.
Eine klassische "predictive Competition" also :-)
Allerdings können immer ein paar Schwierigkeiten auftreten ;-)


*Aufgabe*

Erstellen Sie ein *Lineares-Modell* mit *Regularisierung* mit Tidymodels!


*Hinweise*

<!-- - Nehmen Sie folgende Prädiktoren auf: `budget` und `popularity` -->
- Verzichten Sie auf Vorverarbeitung. 
- Tunen Sie die typischen Parameter. 
- Reichen Sie das Modell ein und berichten Sie Ihren Score.
- Begrenzen Sie sich auf folgende Prädiktoren.


```{r}
preds_chosen <- 
  c("id", "budget", "popularity", "runtime")
```




</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Lösung


# Pakete starten

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
library(finetune)
library(doParallel)
library(tictoc)
```



# Daten importieren

```{r}
d_train_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv"
d_test_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv"

d_train <- read_csv(d_train_path)
d_test <- read_csv(d_test_path)
```

Werfen wir einen Blick in die Daten:

```{r}
glimpse(d_train)
glimpse(d_test)
```



# Resampling / Cross-Validation-Scheme

```{r}
cv_scheme <- vfold_cv(d_train)
```



Kleine Werte für $v$ wie $v=3$ kann man wählen, um Rechenzeit zu sparen.
Das ist gerade fürs Debuggen nützlich.
Für die "Wirklichkeit" ist ein höherer Wert besser,
z.B. $v=10$ (der Defaultwert)



# Rezept



```{r rec1}
rec1 <- 
  recipe(revenue ~ budget + popularity + runtime, data = d_train) %>% 
  step_impute_bag(all_predictors()) %>% 
  step_naomit(all_predictors()) 
rec1
```


# Modell



```{r}
model_lm <- linear_reg(penalty = tune(),
                       engine = "glmnet")
```


# Workflow

```{r wf1}
wf1 <-
  workflow() %>% 
  add_model(model_lm) %>% 
  add_recipe(rec1)
```




#  Modell fitten (und tunen)



Parallele Verarbeitung starten:

```{r}
cl <- makePSOCKcluster(4)  # Create 4 clusters
registerDoParallel(cl)
```



```{r fit-resamples-no-tune}
tic()
lm_fit1 <-
  wf1 %>% 
  tune_race_anova(resamples = cv_scheme)
toc()
```



```{r}
lm_fit1 %>% show_best()
```

# Finalisieren


```{r}
wf1_final <-
  wf1 %>% 
  finalize_workflow(select_best(lm_fit1, metric = "rmse"))
```




# Final Fit


```{r}
fit1_final <-
  wf1_final %>% 
  fit(d_train)

fit1_final
```



```{r}
preds <-
  fit1_final %>% 
  predict(d_test)
```




# Submission df


```{r}
submission_df <-
  d_test %>% 
  select(id) %>% 
  bind_cols(preds) %>% 
  rename(revenue = .pred)

head(submission_df)
```



Abspeichern und einreichen:

```{r eval = FALSE}
#write_csv(submission_df, file = "submission.csv")
```


# Kaggle Score

Diese Submission erzielte einen Score von **Score: 6.14787** (RMSLE).

```{r}
sol <- 6.14787
```






---

Categories: 

- ds1
- tidymodels
- statlearning
- tmdb
- num

