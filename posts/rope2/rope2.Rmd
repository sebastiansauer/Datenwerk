---
extype: schoice
exsolution: 64
exname: rope2
expoints: 1
categories:
- rope
- bayes
date: '2022-12-15'
slug: rope2
title: rope2

---




```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      # out.width = "100%",
                      cache = TRUE)
```








# Exercise

Im Datensatz `mtcars`: Ist der (mittlere) Unterschied im Spritverbrauch zwischen den beiden Gruppen 
*Automatik* vs. *Schaltgetriebe* vernachlässigbar?

Definieren Sie selber, was "vernachlässigbar klein" bedeutet.
Oder greifen Sie auf die Definition "höchstens eine Meile" zurück.

Prüfen Sie rechnerisch, anhand des angegebenen Datensatzes, folgende Behauptung:


*Behauptung: "Der Unterschied ist vernachlässigbar klein!"*


Wählen Sie die Antwortoption, die am besten zu der obigen Behauptung passt!


Hinweise:

- Sie benötigen einen Computer, um diese Aufgabe zu lösen.
- Verwenden Sie die statistischen Methoden, die im Unterricht behandelt wurden.
- Verwenden Sie Ansätze aus der Bayes-Statistik zur Lösung dieser Aufgabe.


*Antwortoptionen*:

Answerlist
----------
* Ja, die Behauptung ist korrekt.
* Nein, die Behauptung ist falsch.
* Die Daten sind bzw. das Modell nicht konkludent; es ist keine Entscheidung über die Behauptung möglich.
* Auf Basis der bereitgestellten Informationen ist keine Entscheidung möglich über die Behauptung.




</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Solution

```{r message=FALSE}
library(easystats)
library(tidyverse)
library(rstanarm)
```


Zur ersten Orientierung erstellen wir uns, rein deskriptiv, 
eine Darstellung des Spritverbrauchs beider Gruppen, z.B. so:

```{r}
mtcars %>% 
  mutate(am = factor(am)) %>% 
  ggplot() +
  aes(x = mpg, color = am, fill = am) +
  geom_density(alpha = .5)
```

Man sieht direkt, 
dass es substanzielle Unterschiede zwischen den beiden Gruppen gibt.
Vermutlich wird das Modell, das wir gleich berechnen,
uns wenig überraschen,
sondern den deskriptiven Befund widerspiegeln.




Modell berechnen:

```{r}
library(rstanarm)
library(tidyverse)
data(mtcars)

m1_mtcars <- stan_glm(mpg ~ am, data = mtcars, refresh = 0)
```

Posteriori-Verteilung betrachten:


```{r}
parameters(m1_mtcars)
```

Spuckt ein PI (ETI) aus, kein HDI.



Visualisieren der Posteriori-Verteilung:

```{r}
plot(parameters(m1_mtcars), show_intercept = TRUE)
```

[Hilfe zum Plot-Befehl von `parameters](https://easystats.github.io/see/reference/plot.see_parameters_model.html)



Rope berechnen:

```{r}
library(bayestestR)
rope_m1 <- rope(m1_mtcars, range = c(-1, 1)) #  ±1 Meile Unterschied
```

Rope visualisieren:

```{r}
plot(rope_m1)
```


Man sieht, dass der "Berg" 
- die Posteriori-Verteilung bzw. der Bereich plausibler Werte - 
außerhalb des Rope-Bereichs liegt. 

Wir können also die Hypothese,
dass der Unterschied zwischen beiden Gruppen praktisch Null ist,
verwerfen.

Natürlich ist das nur ein deskriptiver Befund,
wir können nichts dazu sagen,
ob der Unterschied auch ein kausaler Effekt ist.



Alternative Rope-Definition: Z-Standardisieren.

Ein kleiner Effekt ist, laut Kruschke 2018, 
ein Unterschied der nicht größer ist als ±0.1 SD.



```{r}
m2_mtcars <- 
  mtcars %>% 
  mutate(mpg_z = scale(mpg)) %>% 
  stan_glm(mpg_z ~ am, data = ., refresh = 0)
```


```{r}
rope(m2_mtcars)
```


```{r}
plot(rope(m2_mtcars))
```



Answerlist
----------


* Falsch
* Richtig
* Falsch
* Falsch






---

Categories: 

- rope
- bayes

