---
date: 2023-12-20
draft: TRUE   # ACHTUNG DRAFT STEHT AUF TRUE!
title: chatgpt-sentiment-loop-all
execute: 
  eval: true 
  
highlight-style: arrow 
cache: true

extype: string
exsolution: ""
categories:
- textmining
- nlp
- transformer
- chatgpt
- sentiment
---








```{r global-knitr-options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      echo = TRUE, 
                      message = FALSE,
                      fig.show = "hold")
```








# Aufgabe


Fragen Sie ChatGPT via API zum Sentiment der Texte aus dem Germeval-2018-Datensatz (Test).


Hinweise:

- Beachten Sie die [Standardhinweise des Datenwerks](https://datenwerk.netlify.app/hinweise).
- Nutzen Sie Python, nicht R.
- Das Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab √ºber die [Preise von OpenAI](https://openai.com/pricing). Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen. Sie k√∂nnen unter <https://platform.openai.com/usage> Ihre Kosten pr√ºfen.



</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# L√∂sung


## Achtung

::: {.callout-attention}
OpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî $\square$
:::

## Setup


Die richtige venv nutzen:

```{r venv}
library(reticulate)
#virtualenv_create("chatgpt")
use_virtualenv("chatgpt")
```


Check zu Python:

```{r}
reticulate::py_config()
```

Ggf. noch Module installieren:

```{r}
#reticulate::py_install("pandas")
#py_install("tiktoken")
#py_install("datar")
#py_install("scikit-learn")
```


## R-Pakete und Python-Module



```{r}
library(tidyverse)
library(tidymodels)
```


Module importieren:

```{python libs}
from openai import OpenAI
import pandas as pd
import numpy as np
import time
from datetime import datetime
#from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
```

Versionen der importierten Module:

```{python py-version}
pd.__version__
```




```{zsh openai-version-zsh}
#| echo: fenced
pip list | grep openai
```

Wir brauchen `>= 1.35`.

Der Operator `|` ist die "Pfeife" der Kommandozeile, also sozusagen der "UND-DANN-Befehl".





## Daten

Daten importieren:

```{python import-data}
csv_file_path_test = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv'

germeval_test = pd.read_csv(csv_file_path_test)
```


Die ersten paar Texte herausziehen:

```{python tweets-tolist}
start_pos = 0
end_pos = 3531
tweets = germeval_test["text"].iloc[start_pos:(end_pos+1)].tolist()
```


## Prompt

Prompt definieren:

```{python}
prompt_stem  = "Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes einzusch√§tzen. Bitte antworten Sie nur mit einem einzigen Wort, entweder 'positiv', 'neutral' oder 'negativ'. Ihre Antwort soll Ihre Insgesamt-Einsch√§tzung zum Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folgt der Text, dessen Sentiment Sie einsch√§tzen sollen: "
```

Gute Prompts k√∂nnen helfen, gute Antworten vom Modell zu erhalten.



Mit "List Comprehension" k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:

```{python prompt-list}
prompts = [prompt_stem + tweet for tweet in tweets]
prompts[0]
```

Check: Wie viele Elemente hat die Liste `prompts`?

```{python}
len(prompts)
```



Laut OpenAI kostet 1k Token f√ºr das Modell `gpt-3.5-turbo-1106` $0.001.


## Authentifizieren

Anmelden bei OpenAI:

```{python openai-auth}
client = OpenAI()
```


::: {.callout-note}
Dieses Anmeldeverfahren setzt voraus, dass in `.Renviron` die Variable `OPENAI_API_KEY` hinterlegt ist. $\square$
:::






Anfrage an die API, in eine Funktion gepackt:

```{python fun-ask-chatgpt}
def get_completion(prompt, client_instance, model="gpt-3.5-turbo"):
  messages = [{"role": "user", "content": prompt}]
  response = client_instance.chat.completions.create(
    model=model,
    messages=messages,
    max_tokens=50,
    temperature=0,
  )
  return response.choices[0].message.content
```


## API anfragen

Und jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:

```{python}
predicted_values = []
```


```{python ask-api}
#| eval: false
start_time = time.time()

for prompt in prompts:
  result = get_completion(prompt, client) 
  predicted_values.append(result)

end_time = time.time()
end_time - start_time
```



Voil√†:


```{python}
print(predicted_values[:5])
```

## Als CSV speichern

```{python save-csv}
#| eval: false
id_seq = [i for i in range(start_pos, end_pos + 1)]
predicted_values_df = pd.DataFrame(id_seq, columns = ["id"])
predicted_values_df["pred"] = predicted_values

now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
csv_output_name = "germeval_test_preds_at_" + now
predicted_values_df.to_csv(csv_output_name)
```


## Oder Vorhersagen aus CSV importieren


```{python}
preds_path = 'https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/posts/chatgpt-sentiment-loop-all/germeval_test_preds_at_2023-12-20%2014%3A06%3A00'

preds = pd.read_csv(preds_path)

preds.head()
```

Man kann eine Python-Variable an R √ºbergeben:

```{r}
preds_r <- py$preds
```

## Vorhersagen (Predictions) betrachten


Z√§hlen wir mal kurz aus:

```{r}
preds_r |> 
  count(pred) |> 
  slice(3:5)  # zwei komische, kaputte Zeilen, weg damit
```

Oder in Python:

```{python}
preds["pred"].value_counts()
```
Puh, das ist ein bisschen was kaput gegangen.

## Predictions reparieren

```{python}
allowed_preds = ["positiv", "neutral", "negativ"]
preds.loc[~preds["pred"].isin(allowed_preds), "pred"] = np.nan
```

Check:

```{python}
preds["pred"].value_counts()
```



Passt!



## Scoring vorbereiten

Was waren noch mal die Variablen unser Tabelle?

```{python}
germeval_test.columns
```

Die ersten paar Werte:

```{python}
germeval_test.head()
```


Rescore im Test-Set:

```{python rescore-test}
df = germeval_test
df["c1"] = df["c1"].replace({"OFFENSE": "negativ"})

df["c1"].value_counts()
```

Rescore in den Vorhersagen

```{python rescore-preds}
preds["pred"] = preds["pred"].replace({"neutral": "OTHER", "positiv": "OTHER"})

preds["pred"].value_counts()
```

```{python preds-list}
preds_list = preds["pred"].tolist()
```

Hier ist die *Liste* der wahren Werte:

```{python def-y-list}
y = df["c1"].values.tolist()
```

## Scoring

```{python py-score}
accuracy = accuracy_score(y, preds_list)
print("Accuracy:", accuracy)
```





Oder  mit `tidymodels`; zuerst aufbereiten:

```{r prepare-for-tidymodels}
y_truth = as.factor(py$y)
y_pred = py$preds_list 

# replace NAN with NA and convert to factor:
y_pred = as.character(y_pred) 
y_pred[is.nan(y_pred)] <- NA
y_pred[!y_pred %in% c("negativ", "OTHER")] <- NA
y_pred <- as.factor(y_pred)

table(y_pred)
```



```{r tidymodels-score}
accuracy_vec(truth = y_truth,
             estimate = y_pred)
```

