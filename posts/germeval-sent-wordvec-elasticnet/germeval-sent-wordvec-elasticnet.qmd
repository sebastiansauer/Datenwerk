---
expoints: 1
extype: string
exsolution: NA
categories:
- textmining
- datawrangling
- germeval
- prediction
- tidymodels
- sentiment
- string
- elasticnet 
- tune
date: '2023-12-05'
title: germeval03-sent-wordvec-elasticnet
draft: false  
eval: true
execute: 
  eval: false
  cache: true
---



```{r global-knitr-options, include=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.pos = 'H',
                      fig.asp = 0.618,
                      fig.width = 4,
                      fig.cap = "", 
                      fig.path = "",
                      echo = TRUE,  # ECHO IS FALSE!!!
                      message = FALSE,
                      warning = FALSE,
                      # cache = TRUE,
                      fig.show = "hold")

options(max.print = 10)
options(rstudio.help.showDataPreview = FALSE)
```



# Aufgabe

Erstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.
Nutzen Sie außerdem *deutsche Word-Vektoren* für das Feature-Engineering.

Als Lernalgorithmus verwenden Sie ein Elasticnet. Tunen Sie alle Parameter mit insgesamt 100 Kandidaten.



## Daten

Verwenden Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).

Die Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),

Die Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.


```{r}
library(tidyverse)
data("germeval_train", package = "pradadata")
data("germeval_test", package = "pradadata")
```

## AV und UV

Die AV lautet `c1`. Die (einzige) UV lautet: `text`.


## Hinweise

- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).
- Nutzen Sie Tidymodels.
- Nutzen Sie das `sentiws` Lexikon.
- ❗ Achten Sie darauf, die Variable `c2` zu entfernen bzw. nicht zu verwenden.





</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

# Lösung


## Setup

Train-Datensatz:

```{r d-train}
d_train <-
  germeval_train |> 
  select(id, c1, text)
```

Pakete:

```{r libs}
library(tictoc)
library(tidymodels)
library(beepr)
library(finetune)  # anova race
```


Eine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).



## Learner/Modell

```{r}
mod <-
  logistic_reg(mode = "classification",
               penalty = tune(), 
               mixture = tune(),
               engine = "glmnet"
             )
```



## Gebackenen Datensatz als neue Grundlage

Wir importieren den schon an anderer Stelle aufbereiteten Datensatz.
Das hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind.
Die Arbeit des Feature Engineering wurde uns schon abgenommen.

```{r import-train-data}
d_train_raw <-
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv")
```




```{r}
d_test_baked_raw <- read_csv("https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv")
```


## Keine Dummysierung der AV

Lineare Modelle müssen dummysiert sein. Rezepte wollen das nicht so gerne für die AV besorgen. 

ABER: Klassifikationsmodelle in Tiymodels (parsnip) benötigen eine *factor* Variable als AV, sonst werden sie nicht als Klassifikation erkannt.

```{r}
d_train <-
  d_train_raw |> 
  mutate(c1 = as.factor(c1)) 

levels(d_train$c1)
```

Tidymodels modelliert die *erste* Stufe.



```{r}
d_test_baked <-
  d_test_baked_raw |> 
  mutate(c1 = as.factor(c1)) 

levels(d_test_baked$c1)
```




## Dummy-Rezept

Plain, aber mit Dummyisierung:

```{r}
rec <- 
  recipe(c1 ~ ., data = d_train) 
```




##  Workflow

```{r wf-new}
wf <-
  workflow() |> 
  add_recipe(rec) |> 
  add_model(mod)
```





## Parallelisierung über mehrere Kerne

```{r}
library(parallel)
all_cores <- detectCores(logical = FALSE)

library(doFuture)
registerDoFuture()
cl <- makeCluster(3)
plan(cluster, workers = cl)
```


Achtung: Viele Kerne brauchen auch viel Speicher.

## Tune/Resample/Fit




```{r fit}
tic()
fit_wordvec_senti_elasticnet <-
  tune_race_anova(
    wf,
    grid = 100,
    resamples = vfold_cv(d_train, v = 5),
    control = control_race(verbose_elim = TRUE))
toc()
beep()
```




## Beste Performance

```{r}
autoplot(fit_wordvec_senti_elasticnet)
```


```{r best-params}
show_best(fit_wordvec_senti_elasticnet)

best_params <- select_best(fit_wordvec_senti_elasticnet)
```


## Finalisieren


```{r finalize-wf}
tic()
wf_finalized <- finalize_workflow(wf, best_params)
lastfit <- fit(wf_finalized, data = d_train)
toc()
```


## Test-Set-Güte

```{r predict}
tic()
preds <-
  predict(lastfit, new_data = d_test_baked)
toc()
```


```{r bind-cols}
d_test <-
  d_test_baked |> 
  bind_cols(preds) |> 
  mutate(c1 = as.factor(c1))
```


```{r metrics}
my_metrics <- metric_set(accuracy, f_meas)
my_metrics(d_test,
           truth = c1,
           estimate = .pred_class)
```











