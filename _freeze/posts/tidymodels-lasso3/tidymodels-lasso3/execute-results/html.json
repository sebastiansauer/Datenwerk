{
  "hash": "66f9b5a5c041a27b4e9292eadcd49244",
  "result": {
    "markdown": "---\nexname: tidymodels-lasso3\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- tidymodels\n- statlearning\n- lasso\n- lm\n- string\ndate: '2023-05-17'\nslug: tidymodels-lasso3\ntitle: tidymodels-lasso3\n\n---\n\n\n\n\n\n# Aufgabe\n\n<!-- Schreiben Sie eine Vorlage für eine prädiktive Analyse mit Tidymodels! -->\n\nSchreiben Sie eine prototypische Analyse für ein Vorhersagemodell mit dem *Lasso*.\n\nBerichten Sie, welche Prädiktoren nach dem Lasso im Modell verbleiben.\n\nHinweise:\n\n- Tunen Sie die Penalisierung.\n- Verwenden Sie Kreuzvalidierung.\n- Verwenden Sie Standardwerte, wo nicht anders angegeben.\n- Fixieren Sie Zufallszahlen auf den Startwert 42.\n- Verwenden Sie den Datensatz `penguins`.\n- Modellformel: `body_mass_g ~ .`\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Standardvorgehen\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variablenbedeutung\n\n# Data:\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd <- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd <-\n  d %>% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split <- initial_split(d)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n# model:\nmod_lasso <-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl <- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain <- \n  recipe(body_mass_g ~  ., data = d_train) %>% \n  update_role(\"...1\", new_role = \"id\") %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked <- \n  prep(rec1_plain) %>% bake(new_data = NULL)\n\nna_n <- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod_lasso) %>% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit <-\n  wf1 %>% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n14.01 sec elapsed\n```\n:::\n\n```{.r .cell-code}\n# best candidate:\nshow_best(wf1_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 7\n   penalty .metric .estimator  mean     n std_err .config              \n     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 1.97e-10 rmse    standard    281.    10    12.0 Preprocessor1_Model01\n2 4.54e- 9 rmse    standard    281.    10    12.0 Preprocessor1_Model02\n3 8.93e- 8 rmse    standard    281.    10    12.0 Preprocessor1_Model03\n4 1.75e- 7 rmse    standard    281.    10    12.0 Preprocessor1_Model04\n5 1.65e- 6 rmse    standard    281.    10    12.0 Preprocessor1_Model05\n```\n:::\n\n```{.r .cell-code}\n# finalize wf:\nwf1_final <-\n  wf1 %>% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final <-\n  wf1_final %>% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     326.    Preprocessor1_Model1\n2 rsq     standard       0.819 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Inspektion der Tuningparameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(wf1_fit)\n```\n\n::: {.cell-output-display}\n![](tidymodels-lasso3_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\nDie Standard-Wahl der Tuningparameter-Werte war offenbar nicht so ideal,\nzumindest sieht man kaum Unterschiede zwischen der Modellgüte in Abhängigkeit von den Werten der Tuningparameter.\n\n\n## Variablenbedeutung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n\nvi_preds <- \nwf1_fit_final %>% \n  extract_fit_engine() %>% \n  vi()\n\nvi_preds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 3\n  Variable          Importance Sign \n  <chr>                  <dbl> <chr>\n1 species_Gentoo         763.  POS  \n2 sex_male               389.  POS  \n3 species_Chinstrap      284.  NEG  \n4 flipper_length_mm      268.  POS  \n5 bill_length_mm         128.  POS  \n6 bill_depth_mm           70.6 POS  \n7 island_Dream            63.8 NEG  \n8 year                    30.7 NEG  \n9 island_Torgersen         0   NEG  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvi_preds %>% \n  ggplot(aes(x = Importance, y = reorder(Variable, Importance), fill = Sign)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](tidymodels-lasso3_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nMan beachte: Für regulierte Modelle sind Zentrierung und Skalierung nötig.\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- statlearning\n- lasso\n- lm\n- string\n\n",
    "supporting": [
      "tidymodels-lasso3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}