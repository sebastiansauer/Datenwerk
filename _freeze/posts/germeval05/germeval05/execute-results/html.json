{
  "hash": "551b9e8de73514b9a1fda4b2c1021cfe",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval05-glove6b\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- wordvec\n- string\ndate: '2023-11-16'\nslug: germeval05\ntitle: germeval05\n\n---\n\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. \nNutzen Sie Word-Vektoren für das Feature-Engineering.\n\nNutzen Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(textrecipes)\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n## Textvektoren importieren\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(textdata)\n\nglove_embedding <- embedding_glove6b(\n  dir = \"/Users/sebastiansaueruser/datasets\",\n  return_path = TRUE,\n  manual_download = TRUE\n)\n\nhead(glove_embedding)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|token |       d1|        d2|       d3|        d4|      d5|        d6|       d7|       d8|         d9|       d10|      d11|       d12|      d13|      d14|        d15|       d16|       d17|       d18|      d19|       d20|       d21|       d22|       d23|       d24|       d25|     d26|      d27|       d28|       d29|      d30|    d31|        d32|       d33|      d34|       d35|        d36|      d37|       d38|      d39|       d40|        d41|       d42|       d43|       d44|      d45|      d46|        d47|       d48|       d49|      d50|\n|:-----|--------:|---------:|--------:|---------:|-------:|---------:|--------:|--------:|----------:|---------:|--------:|---------:|--------:|--------:|----------:|---------:|---------:|---------:|--------:|---------:|---------:|---------:|---------:|---------:|---------:|-------:|--------:|---------:|---------:|--------:|------:|----------:|---------:|--------:|---------:|----------:|--------:|---------:|--------:|---------:|----------:|---------:|---------:|---------:|--------:|--------:|----------:|---------:|---------:|--------:|\n|the   | 0.418000|  0.249680| -0.41242|  0.121700| 0.34527| -0.044457| -0.49688| -0.17862| -0.0006602| -0.656600| 0.278430| -0.147670| -0.55677|  0.14658| -0.0095095|  0.011658|  0.102040| -0.127920| -0.84430| -0.121810| -0.016801| -0.332790| -0.155200| -0.231310| -0.191810| -1.8823| -0.76746|  0.099051| -0.421250| -0.19526| 4.0071| -0.1859400| -0.522870| -0.31681| 0.0005921|  0.0074449|  0.17778| -0.158970| 0.012041| -0.054223| -0.2987100| -0.157490| -0.347580| -0.045637| -0.44251| 0.187850|  0.0027849| -0.184110| -0.115140| -0.78581|\n|,     | 0.013441|  0.236820| -0.16899|  0.409510| 0.63812|  0.477090| -0.42852| -0.55641| -0.3640000| -0.239380| 0.130010| -0.063734| -0.39575| -0.48162|  0.2329100|  0.090201| -0.133240|  0.078639| -0.41634| -0.154280|  0.100680|  0.488910|  0.312260| -0.125200| -0.037512| -1.5179|  0.12612| -0.024420| -0.042961| -0.28351| 3.5416| -0.1195600| -0.014533| -0.14990| 0.2186400| -0.3341200| -0.13872|  0.318060| 0.703580|  0.448580| -0.0802620|  0.630030|  0.321110| -0.467650|  0.22786| 0.360340| -0.3781800| -0.566570|  0.044691|  0.30392|\n|.     | 0.151640|  0.301770| -0.16763|  0.176840| 0.31719|  0.339730| -0.43478| -0.31086| -0.4499900| -0.294860| 0.166080|  0.119630| -0.41328| -0.42353|  0.5986800|  0.288250| -0.115470| -0.041848| -0.67989| -0.250630|  0.184720|  0.086876|  0.465820|  0.015035|  0.043474| -1.4671| -0.30384| -0.023441|  0.305890| -0.21785| 3.7460|  0.0042284| -0.184360| -0.46209| 0.0983290| -0.1190700|  0.23919|  0.116100| 0.417050|  0.056763| -0.0000637|  0.068987|  0.087939| -0.102850| -0.13931| 0.223140| -0.0808030| -0.356520|  0.016413|  0.10216|\n|of    | 0.708530|  0.570880| -0.47160|  0.180480| 0.54449|  0.726030|  0.18157| -0.52393|  0.1038100| -0.175660| 0.078852| -0.362160| -0.11829| -0.83336|  0.1191700| -0.166050|  0.061555| -0.012719| -0.56623|  0.013616|  0.228510| -0.143960| -0.067549| -0.381570| -0.236980| -1.7037| -0.86692| -0.267040| -0.258900|  0.17670| 3.8676| -0.1613000| -0.132730| -0.68881| 0.1844400|  0.0052464| -0.33874| -0.078956| 0.241850|  0.365760| -0.3472700|  0.284830|  0.075693| -0.062178| -0.38988| 0.229020| -0.2161700| -0.225620| -0.093918| -0.80375|\n|to    | 0.680470| -0.039263|  0.30186| -0.177920| 0.42962|  0.032246| -0.41376|  0.13228| -0.2984700| -0.085253| 0.171180|  0.224190| -0.10046| -0.43653|  0.3341800|  0.678460|  0.057204| -0.344480| -0.42785| -0.432750|  0.559630|  0.100320|  0.186770| -0.268540|  0.037334| -2.0932|  0.22171| -0.398680|  0.209120| -0.55725| 3.8826|  0.4746600| -0.956580| -0.37788| 0.2086900| -0.3275200|  0.12751|  0.088359| 0.163510| -0.216340| -0.0943750|  0.018324|  0.210480| -0.030880| -0.19722| 0.082279| -0.0943400| -0.073297| -0.064699| -0.26044|\n|and   | 0.268180|  0.143460| -0.27877|  0.016257| 0.11384|  0.699230| -0.51332| -0.47368| -0.3307500| -0.138340| 0.270200|  0.309380| -0.45012| -0.41270| -0.0993200|  0.038085|  0.029749|  0.100760| -0.25058| -0.518180|  0.345580|  0.449220|  0.487910| -0.080866| -0.101210| -1.3777| -0.10866| -0.232010|  0.012839| -0.46508| 3.8463|  0.3136200|  0.136430| -0.52244| 0.3302000|  0.3370700| -0.35601|  0.324310| 0.120410|  0.351200| -0.0690430|  0.368850|  0.251680| -0.245170|  0.25381| 0.136700| -0.3117800| -0.632100| -0.250280| -0.38097|\n\n</div>\n:::\n:::\n\n\n\n## Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model:\nmod1 <-\n  logistic_reg()\n\n\n# cv:\nset.seed(42)\nrsmpl <- vfold_cv(d_train, v = 5)\n\n\n# recipe:\nrec1 <-\n  recipe(c1 ~ ., data = d_train) |> \n  update_role(id, new_role = \"id\")  |> \n  #update_role(c2, new_role = \"ignore\") |> \n  step_tokenize(text) %>%\n  step_stopwords(text, keep = FALSE) %>%\n  step_word_embeddings(text,\n                       embeddings = glove_embedding,\n                       aggregation = \"mean\") |> \n  step_normalize(all_numeric_predictors()) \n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod1) %>% \n  add_recipe(rec1)\n```\n:::\n\n\n\n## Tuining/Fitting\n\n::: {.cell hash='germeval05_cache/html/tuning_e6a42598cf3c5cf12d6395df534a5831'}\n\n```{.r .cell-code}\ntic()\nwf1_fit <-\n  wf1 %>% \n  fit_resamples(\n    resamples = rsmpl,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n26.374 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nbeep()\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_fit |> collect_metrics()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.metric  |.estimator |      mean|  n|   std_err|.config              |\n|:--------|:----------|---------:|--:|---------:|:--------------------|\n|accuracy |binary     | 0.6560196|  5| 0.0072639|Preprocessor1_Model1 |\n|f_meas   |binary     | 0.1285935|  5| 0.0155600|Preprocessor1_Model1 |\n|roc_auc  |binary     | 0.5933467|  5| 0.0094711|Preprocessor1_Model1 |\n\n</div>\n:::\n:::\n\n\nBester Fold:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(wf1_fit)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.metric  |.estimator |      mean|  n|   std_err|.config              |\n|:--------|:----------|---------:|--:|---------:|:--------------------|\n|accuracy |binary     | 0.6560196|  5| 0.0072639|Preprocessor1_Model1 |\n\n</div>\n:::\n:::\n\n\n\n\n\n\n## Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- \n  wf1 |> \n  fit(data = d_train)\n```\n:::\n\n\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(fit1, new_data = germeval_test)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1.766 sec elapsed\n```\n\n\n:::\n:::\n\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.metric  |.estimator | .estimate|\n|:--------|:----------|---------:|\n|accuracy |binary     | 0.6523216|\n|f_meas   |binary     | 0.1376404|\n\n</div>\n:::\n:::\n\n\n\n## Fazit\n\n\n\n\n`glove6b` ist für die englische Sprache vorgekocht. \nDas macht wenig Sinn für einen deutschsprachigen Corpus.\n\n\n\n\n\n---\n\nCategories: \n\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- wordvec\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}