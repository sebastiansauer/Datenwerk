{
  "hash": "28d37047039b86ae0dc2587761c7ae3f",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: tmdb03\nextype: num\nexsolution: r sol\nextol: 0.2\nexpoints: 1\ncategories:\n- ds1\n- tidymodels\n- statlearning\n- tmdb\n- random-forest\n- num\ndate: '2023-05-17'\nslug: tmdb03\ntitle: tmdb03\n\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n# Aufgabe\n\nWir bearbeiten hier die Fallstudie [TMDB Box Office Prediction - \nCan you predict a movie's worldwide box office revenue?](https://www.kaggle.com/competitions/tmdb-box-office-prediction/overview),\nein [Kaggle](https://www.kaggle.com/)-Prognosewettbewerb.\n\nZiel ist es, genaue Vorhersagen zu machen,\nin diesem Fall für Filme.\n\n\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n```\n:::\n\n\n\n\n# Aufgabe\n\nReichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\n\n\nHinweise:\n\n- Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.\n- Verwenden Sie *mehrere, und zwar folgende Algorithmen*: Random Forest, Boosting, lineare Regression. Tipp: Ein Workflow-Set ist hilfreich.\n- Logarithmieren Sie `budget`.\n- Betreiben Sie Feature Engineering, zumindest etwas. Insbesondere sollten Sie den Monat und das Jahr aus dem Datum extrahieren und als Features (Prädiktoren) nutzen.\n- Verwenden Sie `tidymodels`.\n- Die Zielgröße ist `revenue` in Dollars; nicht in \"Log-Dollars\". Sie müssen also rücktransformieren,\nfalls Sie `revenue` logarithmiert haben.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n*Vorbereitung*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen\n#library(Metrics)\nlibrary(lubridate)  # Datumsangaben\nlibrary(VIM)  # fehlende Werte\nlibrary(visdat)  # Datensatz visualisieren\nlibrary(lubridate)  # Datum/Uhrzeit verarbeiten\nlibrary(doParallel)  # mehrere CPUs nutzen\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_raw <- read_csv(d_train_path)\nd_test <- read_csv(d_test_path)\n```\n:::\n\n\n\nMal einen Blick werfen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(d_train_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,000\nColumns: 23\n$ id                    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection <chr> \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                <dbl> 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                <chr> \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              <chr> NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               <chr> \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     <chr> \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        <chr> \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              <chr> \"When Lou, who has become the \\\"father of the In…\n$ popularity            <dbl> 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           <chr> \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  <chr> \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  <chr> \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          <chr> \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               <dbl> 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      <chr> \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                <chr> \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               <chr> \"The Laws of Space and Time are About to be Viol…\n$ title                 <chr> \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              <chr> \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  <chr> \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  <chr> \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               <dbl> 12314651, 95149435, 13092000, 16000000, 3923970,…\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(d_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 4,398\nColumns: 22\n$ id                    <dbl> 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection <chr> \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                <dbl> 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                <chr> \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              <chr> \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               <chr> \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     <chr> \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        <chr> \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              <chr> \"Ash and friends (this time accompanied by newco…\n$ popularity            <dbl> 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           <chr> \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  <chr> NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  <chr> \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          <chr> \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               <dbl> 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      <chr> \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                <chr> \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               <chr> \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 <chr> \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              <chr> \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  <chr> \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  <chr> \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…\n```\n\n\n:::\n:::\n\n\n\n*Train-Set verschlanken*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  d_train_raw %>% \n  select(popularity, runtime, revenue, budget, release_date) \n```\n:::\n\n\n\n\n\n\n\n\n\n*Datensatz kennenlernen*\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(visdat)\nvis_dat(d_train)\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-5-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\n*Fehlende Werte prüfen*\n\nWelche Spalten haben viele fehlende Werte?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvis_miss(d_train)\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-6-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\nMit `{VIM}` kann man einen Datensatz gut auf fehlende Werte hin untersuchen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggr(d_train)\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-7-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\n\n\n*Rezept definieren*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <-\n  recipe(revenue ~ ., data = d_train) %>% \n  #update_role(all_predictors(), new_role = \"id\") %>% \n  #update_role(popularity, runtime, revenue, budget, original_language) %>% \n  #update_role(revenue, new_role = \"outcome\") %>% \n  step_mutate(budget = if_else(budget < 10, 10, budget)) %>% \n  step_log(budget) %>% \n  step_mutate(release_date = mdy(release_date)) %>% \n  step_date(release_date, features = c(\"year\"), keep_original_cols = FALSE) %>% \n  step_impute_bag(all_predictors()) %>% \n  step_dummy(all_nominal())\n\nrec1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rec1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  number operation type       trained skip  id              \n   <int> <chr>     <chr>      <lgl>   <lgl> <chr>           \n1      1 step      mutate     FALSE   FALSE mutate_7GZRr    \n2      2 step      log        FALSE   FALSE log_9bqVu       \n3      3 step      mutate     FALSE   FALSE mutate_bGMkA    \n4      4 step      date       FALSE   FALSE date_mHs3V      \n5      5 step      impute_bag FALSE   FALSE impute_bag_57NLQ\n6      6 step      dummy      FALSE   FALSE dummy_l6So6     \n```\n\n\n:::\n:::\n\n\n\n\n*Check das Rezept *\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep(rec1, verbose = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\noper 1 step mutate [training] \noper 2 step log [training] \noper 3 step mutate [training] \noper 4 step date [training] \noper 5 step impute bag [training] \noper 6 step dummy [training] \nThe retained training set is ~ 0.1 Mb  in memory.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked <- \nprep(rec1) %>% \n  bake(new_data = NULL) \n\nd_train_baked\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,000 × 5\n   popularity runtime budget  revenue release_date_year\n        <dbl>   <dbl>  <dbl>    <dbl>             <int>\n 1      6.58       93  16.5  12314651              2015\n 2      8.25      113  17.5  95149435              2004\n 3     64.3       105  15.0  13092000              2014\n 4      3.17      122  14.0  16000000              2012\n 5      1.15      118   2.30  3923970              2009\n 6      0.743      83  15.9   3261638              1987\n 7      7.29       92  16.5  85446075              2012\n 8      1.95       84   2.30  2586511              2004\n 9      6.90      100   2.30 34327391              1996\n10      4.67       91  15.6  18750246              2003\n# ℹ 2,990 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked %>% \n  map_df(~ sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  popularity runtime budget revenue release_date_year\n       <int>   <int>  <int>   <int>             <int>\n1          0       0      0       0                 0\n```\n\n\n:::\n:::\n\n\n\nKeine fehlenden Werte mehr *in den Prädiktoren*.\n\nNach fehlenden Werten könnte man z.B. auch so suchen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatawizard::describe_distribution(d_train_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariable          |     Mean |       SD |      IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n----------------------------------------------------------------------------------------------------------------\npopularity        |     8.46 |    12.10 |     6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime           |   107.85 |    22.08 |    24.00 |     [0.00, 338.00] |     1.02 |     8.20 | 3000 |         0\nbudget            |    12.51 |     6.44 |    14.88 |      [2.30, 19.76] |    -0.87 |    -1.09 | 3000 |         0\nrevenue           | 6.67e+07 | 1.38e+08 | 6.66e+07 |   [1.00, 1.52e+09] |     4.54 |    27.78 | 3000 |         0\nrelease_date_year |  2004.58 |    15.48 |    17.00 | [1969.00, 2068.00] |     1.22 |     3.94 | 3000 |         0\n```\n\n\n:::\n:::\n\n\n\nSo bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\n\n*Check Test-Sample*\n\nDas Test-Sample backen wir auch mal. Das hat *nur* den Zwecke,\nzu prüfen, ob unser Rezept auch richtig funktioniert.\nDas Preppen und Backen des Test-Samples wir *automatisch* von `predict()` bzw. `last_fit()` erledigt.\n\nWichtig: Wir preppen den Datensatz mit dem *Train-Sample*, auch\nwenn wir das Test-Sample backen wollen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1_prepped <- prep(rec1)\n\nd_test_baked <-\n  bake(rec1_prepped, new_data = d_test)\n\nd_test_baked %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  popularity runtime budget release_date_year\n       <dbl>   <dbl>  <dbl>             <int>\n1       3.85      90   2.30              2007\n2       3.56      65  11.4               2058\n3       8.09     100   2.30              1997\n4       8.60     130  15.7               2010\n5       3.22      92  14.5               2005\n6       8.68     121   2.30              1996\n```\n\n\n:::\n:::\n\n\n\n\n\n# Kreuzvalidierung\n\nNur aus Zeitgründen ist hier $v=5$ eingestellt;\nbesser wäre z.B. $v=10$ und $r=3$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_scheme <- vfold_cv(d_train,\n                      v = 5, \n                      repeats = 1)\n```\n:::\n\n\n\n# Modelle\n\n*Baum*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_tree <-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                mode = \"regression\")\n```\n:::\n\n\n\n\n*Random Forest*\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_rf <-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000,\n              mode = \"regression\") \n```\n:::\n\n\n\n\n*XGBoost*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_boost <- boost_tree(mtry = tune(),\n                        min_n = tune(),\n                        trees = tune()) %>% \n  set_mode(\"regression\")\n```\n:::\n\n\n\n*LM*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_lm <-\n  linear_reg()\n```\n:::\n\n\n\n\n*Workflow-Set*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreproc <- list(rec1 = rec1)\nmodels <- list(tree1 = mod_tree, \n               rf1 = mod_rf, \n               boost1 = mod_boost, \n               lm1 = mod_lm)\n \nall_workflows <- workflow_set(preproc, models)\n```\n:::\n\n\n\n*Fitten und tunen*\n\n# Fitten/Tunen\n\n\n\n\nWenn man das Ergebnis-Objekt abgespeichert hat,\ndann kann man es einfach laden,\nspart Rechenzeit (der Tag ist kurz):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult_obj_file <- \"tmdb_model_set.rds\"\n```\n:::\n\n\n(Davon ausgehend, dass die Datei im Arbeitsverzeichnis liegt.)\n\nDann *könnte* man Folgendes machen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (file.exists(result_obj_file)) {\n  tmdb_model_set <- read_rds(result_obj_file)\n} else {\n  \n  <computer_workflow_set_and_be_happy>\n  \n}\n```\n:::\n\n\n\n*Achtung* Gefährlich! Zwischenspeichern auf der Festplatte birgt die Gefahr,\ndass man vergisst, das Objekt auf der Festplatte zu aktualisieren und Sie noch in einem Jahr und nach 100 Updates \nIhres Rezepts immer noch das uralte Objekt von der Festplatte laden ...\n\n\n\nUm Rechenzeit zu sparen,\nkann man das Ergebnisobjekt abspeichern,\ndann muss man beim nächsten Mal nicht wieder von Neuem berechnen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(tmdb_model_set, \"objects/tmdb_model_set.rds\")\n```\n:::\n\n\nHier berechnen wir aber lieber das Modell neu:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\ntmdb_model_set <-\n  all_workflows %>% \n  workflow_map(\n    resamples = cv_scheme,\n    #grid = 10,\n    metrics = metric_set(rmse),\n    seed = 42,  # reproducibility\n    control = control_grid(verbose = FALSE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n225.039 sec elapsed\n```\n\n\n:::\n:::\n\n\nOhne Parallelisierung dauerte die Berechnung bei mir knapp 4 Minuten (225 Sec).\nIch habe hier auf Parallelisierung verzichtet,\nda Tidymodels einen Fehler aufwarf mit der Begründung,\ndass das Paket `lubridate` in den parallel laufenden Instanzen nicht verfügbar sei (und der parameter `pckgs = 'lubridate` keine Linderung brachte).\n\nCheck:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmdb_model_set[[\"result\"]][[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits             id    .metrics          .notes          \n  <list>             <chr> <list>            <list>          \n1 <split [2400/600]> Fold1 <tibble [10 × 6]> <tibble [0 × 3]>\n2 <split [2400/600]> Fold2 <tibble [10 × 6]> <tibble [0 × 3]>\n3 <split [2400/600]> Fold3 <tibble [10 × 6]> <tibble [0 × 3]>\n4 <split [2400/600]> Fold4 <tibble [10 × 6]> <tibble [0 × 3]>\n5 <split [2400/600]> Fold5 <tibble [10 × 6]> <tibble [0 × 3]>\n```\n\n\n:::\n:::\n\n\n\n*Finalisieren*\n\n\n**Welcher Algorithmus schneidet am besten ab?**\n\nGenauer gesagt, welches Modell, denn es ist ja nicht nur ein Algorithmus,\nsondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus\nein spezifischer Datensatz.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune::autoplot(tmdb_model_set)\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-23-1.png){fig-pos='H' width=50%}\n:::\n:::\n\n\nR-Quadrat ist nicht so entscheidend; `rmse` ist wichtiger.\n\nDie Ergebnislage ist nicht ganz klar, aber\neiniges spricht für das Random-Forest-Modell.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmdb_model_set %>% \n  collect_metrics() %>% \n  arrange(mean) %>% \n  slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 9\n   wflow_id .config        preproc model .metric .estimator   mean     n std_err\n   <chr>    <chr>          <chr>   <chr> <chr>   <chr>       <dbl> <int>   <dbl>\n 1 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.10e7     5  3.37e6\n 2 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.12e7     5  3.37e6\n 3 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.14e7     5  3.29e6\n 4 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.14e7     5  3.56e6\n 5 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.14e7     5  3.42e6\n 6 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.15e7     5  3.43e6\n 7 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.19e7     5  3.55e6\n 8 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.23e7     5  3.67e6\n 9 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.28e7     5  3.66e6\n10 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.30e7     5  3.55e6\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model_params <-\nextract_workflow_set_result(tmdb_model_set, \"rec1_rf1\") %>% \n  select_best()\n\nbest_model_params\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1     2    24 Preprocessor1_Model06\n```\n\n\n:::\n:::\n\n\n\n\n*Finalisieren*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_wf <- \nall_workflows %>% \n  extract_workflow(\"rec1_rf1\")\n\nbest_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_mutate()\n• step_date()\n• step_impute_bag()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_wf_finalized <- \n  best_wf %>% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_mutate()\n• step_date()\n• step_impute_bag()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = 2\n  trees = 1000\n  min_n = 24\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n*Final Fit*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_final <-\n  best_wf_finalized %>% \n  fit(d_train)\n\nfit_final\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_mutate()\n• step_date()\n• step_impute_bag()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~2L,      x), num.trees = ~1000, min.node.size = min_rows(~24L, x),      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  1000 \nSample size:                      3000 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 24 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       6.58465e+15 \nR squared (OOB):                  0.6518847 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test$revenue <- NA\n\nfinal_preds <- \n  fit_final %>% \n  predict(new_data = d_test) %>% \n  bind_cols(d_test)\n```\n:::\n\n\n\n*Submission*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubmission_df <-\n  final_preds %>% \n  select(id, revenue = .pred)\n```\n:::\n\n\n\nAbspeichern und einreichen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_csv(submission_df, file = \"submission.csv\")\n```\n:::\n\n\n\n*Kaggle Score*\n\nDiese Submission erzielte einen Score von **4.79227** (RMSLE).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsol <- 4.79227\n```\n:::\n\n\n\n\n\n\n---\n\nCategories: \n\n- ds1\n- tidymodels\n- statlearning\n- tmdb\n- random-forest\n- num\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}