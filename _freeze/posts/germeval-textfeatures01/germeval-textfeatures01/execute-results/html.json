{
  "hash": "8d9969c7bbc87e369ecc1fa6c45c38a1",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval-textfeatures01\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- tidymodels\n- textmining\n- prediction\n- sentiment\n- germeval\n- string\ndate: '2023-11-16'\nslug: germeval-textfeatures01\ntitle: germeval-textfeatures01\n\n---\n\n\n\n\n\n\n# Aufgabe\n\nExtrahieren Sie gängige Textfeatures - mit Hilfe des gleichnamigen R-Pakets - als Teil des Feature Engineering im Rahmen eines Tidymodels-Klassifikationsmodells.\n\nModellieren Sie dann mit einem einfachen linearen Modell die abhängige Variable. \n\nVerwenden Sie diesen Datensatz:\n\n\n\n::: {.cell}\n\n:::\n\n\n\nDie AV ist `c1`. \n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Setup\n\n\n::: {.cell}\n\n:::\n\n\n\n## Daten\n\n`c2` brauchen wir hier nicht:\n\n\n::: {.cell}\n\n:::\n\n\n\n## Rezept\n\nRezept definieren:\n\n\n::: {.cell}\n\n:::\n\n\n\n`step_mutate` ergänzt für die erzeugte (mutierte) Variable automatisch eine Rolle im Rezept, nimmt sie also als Prädiktor auf.\n\n\nMal schauen:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  number operation type        trained skip  id               \n   <int> <chr>     <chr>       <lgl>   <lgl> <chr>            \n1      1 step      textfeature FALSE   FALSE textfeature_OUeIy\n```\n\n\n:::\n:::\n\n\n\nPreppen und backen:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n6.321 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 29\n     id c1      textfeature_text_n_words textfeature_text_n_uq_words\n  <int> <fct>                      <int>                       <int>\n1     1 OTHER                         15                          15\n2     2 OTHER                         19                          19\n3     3 OTHER                         11                          10\n4     4 OTHER                         19                          18\n5     5 OFFENSE                       16                          16\n6     6 OTHER                         44                          39\n# ℹ 25 more variables: textfeature_text_n_charS <int>,\n#   textfeature_text_n_uq_charS <int>, textfeature_text_n_digits <int>,\n#   textfeature_text_n_hashtags <int>, textfeature_text_n_uq_hashtags <int>,\n#   textfeature_text_n_mentions <int>, textfeature_text_n_uq_mentions <int>,\n#   textfeature_text_n_commas <int>, textfeature_text_n_periods <int>,\n#   textfeature_text_n_exclaims <int>, textfeature_text_n_extraspaces <int>,\n#   textfeature_text_n_caps <int>, textfeature_text_n_lowers <int>, …\n```\n\n\n:::\n:::\n\n\nFolgende Spalten/Features hat `step_textfeatures` extrahiert:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"id\"                              \"c1\"                             \n [3] \"textfeature_text_n_words\"        \"textfeature_text_n_uq_words\"    \n [5] \"textfeature_text_n_charS\"        \"textfeature_text_n_uq_charS\"    \n [7] \"textfeature_text_n_digits\"       \"textfeature_text_n_hashtags\"    \n [9] \"textfeature_text_n_uq_hashtags\"  \"textfeature_text_n_mentions\"    \n[11] \"textfeature_text_n_uq_mentions\"  \"textfeature_text_n_commas\"      \n[13] \"textfeature_text_n_periods\"      \"textfeature_text_n_exclaims\"    \n[15] \"textfeature_text_n_extraspaces\"  \"textfeature_text_n_caps\"        \n[17] \"textfeature_text_n_lowers\"       \"textfeature_text_n_urls\"        \n[19] \"textfeature_text_n_uq_urls\"      \"textfeature_text_n_nonasciis\"   \n[21] \"textfeature_text_n_puncts\"       \"textfeature_text_politeness\"    \n[23] \"textfeature_text_first_person\"   \"textfeature_text_first_personp\" \n[25] \"textfeature_text_second_person\"  \"textfeature_text_second_personp\"\n[27] \"textfeature_text_third_person\"   \"textfeature_text_to_be\"         \n[29] \"textfeature_text_prepositions\"  \n```\n\n\n:::\n:::\n\n\n\n## Model\n\n\n::: {.cell}\n\n:::\n\n\n\n## Workflow\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n5.78 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_textfeature()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n                    (Intercept)         textfeature_text_n_words  \n                        1.50724                          0.05024  \n    textfeature_text_n_uq_words         textfeature_text_n_charS  \n                       -0.05456                         -1.08311  \n    textfeature_text_n_uq_charS        textfeature_text_n_digits  \n                       -0.01885                          1.12019  \n    textfeature_text_n_hashtags   textfeature_text_n_uq_hashtags  \n                        0.43821                         -0.30226  \n    textfeature_text_n_mentions   textfeature_text_n_uq_mentions  \n                       -0.08228                          0.14038  \n      textfeature_text_n_commas       textfeature_text_n_periods  \n                        1.23295                          1.07770  \n    textfeature_text_n_exclaims   textfeature_text_n_extraspaces  \n                        0.79465                         -0.20735  \n        textfeature_text_n_caps        textfeature_text_n_lowers  \n                        1.04501                          1.08349  \n        textfeature_text_n_urls       textfeature_text_n_uq_urls  \n                             NA                               NA  \n   textfeature_text_n_nonasciis        textfeature_text_n_puncts  \n                             NA                          1.09470  \n    textfeature_text_politeness    textfeature_text_first_person  \n                             NA                               NA  \n textfeature_text_first_personp   textfeature_text_second_person  \n                             NA                               NA  \ntextfeature_text_second_personp    textfeature_text_third_person  \n                             NA                               NA  \n         textfeature_text_to_be    textfeature_text_prepositions  \n                             NA                               NA  \n\nDegrees of Freedom: 5008 Total (i.e. Null);  4992 Residual\nNull Deviance:\t    6402 \nResidual Deviance: 6100 \tAIC: 6134\n```\n\n\n:::\n:::\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n2.28 sec elapsed\n```\n\n\n:::\n:::\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary        0.673 \n2 kap      binary        0.0800\n```\n\n\n:::\n:::\n\n\n\n## Baseline\n\nEin einfaches Referenzmodell ist, einfach die häufigste Kategorie vorherzusagen:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  c1          n\n  <chr>   <int>\n1 OFFENSE  1688\n2 OTHER    3321\n```\n\n\n:::\n:::\n\n\n\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- textmining\n- prediction\n- sentimentanalysis\n- germeval\n- string\n\n",
    "supporting": [
      "germeval-textfeatures01_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}