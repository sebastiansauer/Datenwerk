{
  "hash": "6a9e8755bf06231057b4d204d226ffc4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: 2023-12-20\ndraft: FALSE   # ACHTUNG DRAFT STEHT AUF TRUE!\ntitle: chatgpt-sentiment-loop-all\nexecute: \n  eval: false \n  \nhighlight-style: arrow \ncache: true\n\nextype: string\nexsolution: \"\"\ncategories:\n- textmining\n- nlp\n- transformer\n- chatgpt\n- sentiment\n---\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\n\nFragen Sie ChatGPT via API zum Sentiment der Texte aus dem Germeval-2018-Datensatz (Test).\n\n\nHinweise:\n\n- Beachten Sie die [Standardhinweise des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Python, nicht R.\n- Das Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab √ºber die [Preise von OpenAI](https://openai.com/pricing). Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen. Sie k√∂nnen unter <https://platform.openai.com/usage> Ihre Kosten pr√ºfen.\n\n\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/1200px-ChatGPT_logo.svg.png){width=25% fig-align=\"center\"}\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# L√∂sung\n\n\n## Achtung\n\n::: {.callout-attention}\nOpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî $\\square$\n:::\n\n## Setup\n\n\nDie richtige venv nutzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n#virtualenv_create(\"chatgpt\")\nuse_virtualenv(\"chatgpt\")\n```\n:::\n\n\n\nCheck zu Python:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::py_config()\n```\n:::\n\n\nGgf. noch Module installieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#reticulate::py_install(\"pandas\")\n#py_install(\"tiktoken\")\n#py_install(\"datar\")\n#py_install(\"scikit-learn\")\n```\n:::\n\n\n\n## R-Pakete und Python-Module\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(plotly)\n```\n:::\n\n\n\nModule importieren:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom openai import OpenAI\nimport pandas as pd\nimport numpy as np\nimport time\nfrom datetime import datetime\n#from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n```\n:::\n\n\nVersionen der importierten Module:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.__version__\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{zsh openai-version-zsh}}\npip list | grep openai\n```\n````\n:::\n\n\nWir brauchen `>= 1.35`.\n\nDer Operator `|` ist die \"Pfeife\" der Kommandozeile, also sozusagen der \"UND-DANN-Befehl\".\n\n\n\n\n\n## Daten\n\nDaten importieren:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncsv_file_path_test = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv'\n\ngermeval_test = pd.read_csv(csv_file_path_test)\n```\n:::\n\n\n\nDie ersten paar Texte herausziehen:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstart_pos = 0\nend_pos = 3531\ntweets = germeval_test[\"text\"].iloc[start_pos:(end_pos+1)].tolist()\n```\n:::\n\n\n\n## Prompt\n\nPrompt definieren:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompt_stem  = \"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes einzusch√§tzen. Bitte antworten Sie nur mit einem einzigen Wort, entweder 'positiv', 'neutral' oder 'negativ'. Ihre Antwort soll Ihre Insgesamt-Einsch√§tzung zum Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folgt der Text, dessen Sentiment Sie einsch√§tzen sollen: \"\n```\n:::\n\n\nGute Prompts k√∂nnen helfen, gute Antworten vom Modell zu erhalten.\n\n\n\nMit \"List Comprehension\" k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompts = [prompt_stem + tweet for tweet in tweets]\nprompts[0]\n```\n:::\n\n\nCheck: Wie viele Elemente hat die Liste `prompts`?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlen(prompts)\n```\n:::\n\n\n\n\nLaut OpenAI kostet 1k Token f√ºr das Modell `gpt-3.5-turbo-1106` $0.001.\n\n\n## Authentifizieren\n\nAnmelden bei OpenAI:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nclient = OpenAI()\n```\n:::\n\n\n\n::: {.callout-note}\nDieses Anmeldeverfahren setzt voraus, dass in `.Renviron` die Variable `OPENAI_API_KEY` hinterlegt ist. $\\square$\n:::\n\n\n\n\n\n\nAnfrage an die API, in eine Funktion gepackt:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n    model=model,\n    messages=messages,\n    max_tokens=50,\n    temperature=0,\n  )\n  return response.choices[0].message.content\n```\n:::\n\n\n\n## API anfragen\n\nUnd jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npredicted_values = []\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nstart_time = time.time()\n\nfor prompt in prompts:\n  result = get_completion(prompt, client) \n  predicted_values.append(result)\n\nend_time = time.time()\nend_time - start_time\n```\n:::\n\n\n\n\nVoil√†:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(predicted_values[:5])\n```\n:::\n\n\n## Als CSV speichern\n\n\n::: {.cell}\n\n```{.python .cell-code}\nid_seq = [i for i in range(start_pos, end_pos + 1)]\npredicted_values_df = pd.DataFrame(id_seq, columns = [\"id\"])\npredicted_values_df[\"pred\"] = predicted_values\n\nnow = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\ncsv_output_name = \"germeval_test_preds_at_\" + now\npredicted_values_df.to_csv(csv_output_name)\n```\n:::\n\n\n\n## Oder Vorhersagen aus CSV importieren\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\npreds_path = 'https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/posts/chatgpt-sentiment-loop-all/germeval_test_preds_at_2023-12-20%2014%3A06%3A00'\n\npreds = pd.read_csv(preds_path)\n\npreds.head()\n```\n:::\n\n\nMan kann eine Python-Variable an R √ºbergeben:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_r <- py$preds\n```\n:::\n\n\n## Vorhersagen (Predictions) betrachten\n\n\nZ√§hlen wir mal kurz aus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_r |> \n  count(pred) |> \n  slice(3:5)  # zwei komische, kaputte Zeilen, weg damit\n```\n:::\n\n\nOder in Python:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npreds[\"pred\"].value_counts()\n```\n:::\n\nPuh, das ist ein bisschen was kaput gegangen.\n\n## Predictions reparieren\n\n\n::: {.cell}\n\n```{.python .cell-code}\nallowed_preds = [\"positiv\", \"neutral\", \"negativ\"]\npreds.loc[~preds[\"pred\"].isin(allowed_preds), \"pred\"] = np.nan\n```\n:::\n\n\nCheck:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npreds[\"pred\"].value_counts()\n```\n:::\n\n\n\n\nPasst!\n\n\n\n## Scoring vorbereiten\n\nWas waren noch mal die Variablen unser Tabelle?\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngermeval_test.columns\n```\n:::\n\n\nDie ersten paar Werte:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngermeval_test.head()\n```\n:::\n\n\n\nRescore im Test-Set:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = germeval_test\ndf[\"c1\"] = df[\"c1\"].replace({\"OFFENSE\": \"negativ\"})\n\ndf[\"c1\"].value_counts()\n```\n:::\n\n\nRescore in den Vorhersagen\n\n\n::: {.cell}\n\n```{.python .cell-code}\npreds[\"pred\"] = preds[\"pred\"].replace({\"neutral\": \"OTHER\", \"positiv\": \"OTHER\"})\n\npreds[\"pred\"].value_counts()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npreds_list = preds[\"pred\"].tolist()\n```\n:::\n\n\nHier ist die *Liste* der wahren Werte:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny = df[\"c1\"].values.tolist()\n```\n:::\n\n\n## Scoring\n\n\n::: {.cell}\n\n```{.python .cell-code}\naccuracy = accuracy_score(y, preds_list)\nprint(\"Accuracy:\", accuracy)\n```\n:::\n\n\n\n\n\n\nOder  mit `tidymodels`; zuerst aufbereiten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_truth = as.factor(py$y)\ny_pred = py$preds_list \n\n# replace NAN with NA and convert to factor:\ny_pred = as.character(y_pred) \ny_pred[is.nan(y_pred)] <- NA\ny_pred[!y_pred %in% c(\"negativ\", \"OTHER\")] <- NA\ny_pred <- as.factor(y_pred)\n\ntable(y_pred)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_vec(truth = y_truth,\n             estimate = y_pred)\n```\n:::\n\n## Fun\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfig <- plot_ly(\n  domain = list(x = c(0, 1), y = c(0, 1)),\n  value = 74,\n  title = list(text = \"Accuracy\"),\n  type = \"indicator\",\n  mode = \"gauge+number\") \nfig <- fig %>%\n  layout(margin = list(l=20,r=30))\n\nfig\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}