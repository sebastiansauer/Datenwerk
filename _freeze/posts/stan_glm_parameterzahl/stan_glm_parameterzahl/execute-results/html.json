{
  "hash": "0ba6af8d2af410589fd64dcc3e13f586",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: stan-glm-parameterzahl\nextype: num\nexsolution: r sol\nexshuffle: no\nextol: 0\nexpoints: 1\ndate: '2022-12-13'\nslug: stan_glm_parameterzahl\ntitle: stan_glm_parameterzahl\ncategories:\n- bayes\n- regression\n- parameters\n---\n\n\n\n\n\n\n\n\n\n# Exercise\n\n\nBerechnet man eine Posteriori-Verteilung mit `stan_glm()`, \nso kann man entweder die schwach informativen Prioriwerte der Standardeinstellung verwenden, \noder selber Prioriwerte definieren.\n\nBetrachten Sie dazu dieses Modell:\n\n```\nstan_glm(price ~ cut, data = diamonds, \n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(100, 100, 100, 100)),\n                   prior_aux = exponential(1),\n                   prior_intercept = normal(3000, 500))\n```\n\nWie viele Parameter gibt es in diesem Modell?\n\nHinweise:\n\n- Geben Sie nur eine (ganze) Zahl ein.\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\nGrundsätzlich hat ein Regressionsmodell die folgenden Parameter:\n\n1. einen Parameter für den Intercept, $\\beta_0$\n2. pro UV ein weiterer Parameter, $\\beta_1, \\beta_2, \\ldots$\n3. für sigma ($\\sigma$) noch ein zusätzlicher Parameter\n\nZu beachten ist aber, dass bei einer *nominalen* Variablen mit zwei Stufen nur *ein* Regressionsgewicht ($\\beta_1$) berechnet wird. Allgemein gilt bei nominalen also, dass bei $k$ Stufen nur $k-1$ Regressionsgewichte berechnet werden.\n\nIm vorliegenden Fall hat die Variable `cut` 5 Stufen, also werden 4 Regressiongewiche berechnet.\n\nIn Summe werden also *6* Parameter berechnet.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\nBerechnet man das Modell, \nso kann man sich auch Infos über die Prioris ausgeben lassen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100)),\n               prior_intercept = normal(3000, 500),\n               prior_aux = exponential(1),\n               refresh = 0)\n\nprior_summary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPriors for model 'm1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 3000, scale = 500)\n\nCoefficients\n ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n```\n\n\n:::\n:::\n\n\nWie man sieht, \nwird für die Streuung im Standard eine Exponentialverteilung verwendet von `stan_glm()`. \nGibt man also nicht an - wie im Beispiel `m1` oben, \nso wird `stan_glm()` für die Streuung, d.h. `prior_aux` eine Exponentialverteilung verwenden.\nZu beachten ist, dass `stan_glm()` ein automatische Skalierung vornimmt.\n\nS. [hier](http://mc-stan.org/rstanarm/articles/priors.html#auxiliary-parameters) für weitere Erläuterung.\n\nMöchte man den Prior für die Streuung direkt ansprechen, so kann man das so formulieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100)),\n               prior_intercept = normal(3000, 500),\n               prior_aux = exponential(1),\n               refresh = 0)\n\nprior_summary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPriors for model 'm1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 3000, scale = 500)\n\nCoefficients\n ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n```\n\n\n:::\n:::\n\n\nZu beachten ist beim selber definieren der Prioris,\ndass dann keine Auto-Skalierung von `stan_glm()` vorgenommen wird,\nes sei denn, man weist es explizit an:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100),\n                              autoscale = TRUE),\n               prior_intercept = normal(3000, 500, autoscale = TRUE),\n               prior_aux = exponential(1, autoscale = TRUE),\n               chain = 1,  # nur 1 mal Stichproben ziehen, um Zeit zu sparen\n               refresh = 0)\n\nprior_summary(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPriors for model 'm3' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 3000, scale = 500)\n  Adjusted prior:\n    ~ normal(location = 3000, scale = 2e+06)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n  Adjusted prior:\n    ~ normal(location = [100,100,100,...], scale = [1129833.17, 868199.02, 936606.47,...])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.00025)\n------\nSee help('prior_summary.stanreg') for more details\n```\n\n\n:::\n:::\n\n\nGrundsätzlich ist es nützlich für die numerische Stabilität,\ndass die Zahlen (hier die Parameterwerte) etwa die gleiche Größenordnung haben,\nam besten um die 0-1 herum.\nDaher bietet sich oft eine z-Standardisierung an.\n\n\nUnabhängig von der der Art der Parameter ist die Anzahl immer gleich.\n\nDie Anzahl der *geschätzten Parameter* werden im Modell-Summary \nunter `Estimates` gezeigt:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      price ~ cut\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 53940\n predictors:   5\n\nEstimates:\n              mean   sd     10%    50%    90% \n(Intercept) 4027.0   22.1 3998.3 4026.8 4055.8\ncut.L       -248.8   52.7 -316.9 -249.5 -180.9\ncut.Q       -283.6   46.9 -342.3 -283.4 -223.2\ncut.C       -580.5   41.8 -633.6 -580.1 -527.2\ncut^4       -266.4   36.8 -314.6 -266.5 -218.6\nsigma       3830.6   11.1 3816.4 3830.4 3845.4\n\nFit Diagnostics:\n           mean   sd     10%    50%    90% \nmean_PPD 3931.9   23.1 3902.3 3931.8 3962.0\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.4  1.0  3025 \ncut.L         1.1  1.0  2393 \ncut.Q         1.0  1.0  2135 \ncut.C         0.8  1.0  2550 \ncut^4         0.7  1.0  3132 \nsigma         0.1  1.0  7241 \nmean_PPD      0.4  1.0  3673 \nlog-posterior 0.0  1.0  1883 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n```\n\n\n:::\n:::\n\n\n\nDas sind:\n\n- 1 Intercept (Achsenabschnitt) - `prior_intercept`\n- 4 Gruppen (zusätzlich zur Referenzgruppe, die mit dem Achsenabschnitt dargestellt ist) - `prior_normal`\n- 1 Sigma (Ungewissheit \"innerhalb des Modells\") - `prior_aux`\n\n\n\n\n\n---\n\nCategories: \n\n~\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}