{
  "hash": "2fdac3b2d8ff9b25ef0d093f8fed9872",
  "result": {
    "engine": "knitr",
    "markdown": "---\nextype: string\nexsolution: NA\nexname: diamonds-tidymodels01\nexpoints: 1\ncategories:\n- ds1\n- tidymodels\n- statlearning\n- string\ndate: '2023-05-17'\nslug: diamonds-tidymodels01\ntitle: diamonds-tidymodels01\n\n---\n\n\n\n\n\n\n\n# Aufgabe\n\nFinden Sie ein möglichst \"gutes\" prädiktives Modell zur Vorhersage des Diamantenpreises im Datensatz `diamonds`!\n\nGegenstand dieser Aufgabe ist die Modellierung; \nDatenvorverarbeitug (wie explorative Datenanalyse) steht nicht im Fokus.\n\nHinweise:\n\n- Verwenden Sie die Methoden aus `tidymodels`.\n- Hohe Modellgüte (\"gutes Modell\") sei definiert über $R^2$, RMSE und MAE\n- Verwenden Sie verschiedene Algorithmen (lineare Modell, kNN, ...) und verschiedene Rezepte.\n- Resampling und Tuning ist hier noch nicht nötig.s\n\n\nDer Datensatz ist [hier](https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv) zu beziehen.\nAußerdem ist er Teil von ggplot2 bzw. des Tidyverse und daher mit `data()` zu laden,\nwenn das entsprechende Paket vorhanden ist.\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n:::\n\n\nDaten laden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(diamonds, package = \"ggplot2\")\n```\n:::\n\n\n\nOder so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds <- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 53940 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): cut, color, clarity\ndbl (8): rownames, carat, depth, table, price, x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n# Train- vs. Testdaten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(diamonds, strata = price)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n\n# Modelle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlin_mod <-\n  linear_reg()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_mod <-\n  nearest_neighbor(mode = \"regression\")\n```\n:::\n\n\nHilfe zu kNN findet sich z.B. [hier](https://parsnip.tidymodels.org/reference/nearest_neighbor.html).\n\n# Rezepte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <-\n  recipe(price ~ ., data = d_train) %>% \n  update_role(1, new_role = \"id\") %>% \n  step_naomit() %>% \n  step_log(all_outcomes())\n```\n:::\n\n\n\n# Rezept prüfen (preppen und backen)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1_prepped <-\n  rec1 %>% \n  prep()\n\nrec1_prepped\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:   1\npredictor: 9\nid:        1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Training information \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTraining data contained 40453 data points and no incomplete rows.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Removing rows with NA values in: <none> | Trained\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Log transformation on: price | Trained\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked <-\n  bake(rec1_prepped, new_data = d_train)\n```\n:::\n\n\n\n\nEinen Überblick zu `steps` findet sich z.B. [hier](https://recipes.tidymodels.org/reference/).\n\nRollen-Definitionen in Tidymodels-Rezepten kann man [hier](https://recipes.tidymodels.org/reference/has_role.html) nachlesen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2 <-\n  recipe(price ~ ., data = d_train) %>% \n  update_role(1, new_role = \"id\") %>% \n  step_impute_knn() %>% \n  step_log(all_outcomes())\n```\n:::\n\n\n\n# Workflows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(lin_mod)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf2 <-\n  wf1 %>% \n  update_model(knn_mod)\n```\n:::\n\n\n\n\n# Fitting\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <-\n  wf1 %>% \n  fit(d_train)\nfit1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_naomit()\n• step_log()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)         carat       cutGood      cutIdeal    cutPremium  \n   -2.913222     -0.540689      0.091189      0.155213      0.108878  \ncutVery Good        colorE        colorF        colorG        colorH  \n    0.124711     -0.061150     -0.091230     -0.157784     -0.259018  \n      colorI        colorJ     clarityIF    claritySI1    claritySI2  \n   -0.386879     -0.528595      1.093164      0.607816      0.440536  \n  clarityVS1    clarityVS2   clarityVVS1   clarityVVS2         depth  \n    0.817124      0.751466      1.000923      0.935170      0.050243  \n       table             x             y             z  \n    0.009026      1.156195      0.012648      0.040728  \n```\n\n\n:::\n:::\n\n\n# Fitten des Test-Samples\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1_test <-\n  wf1 %>% \n  last_fit(d_split)\nfit1_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                id             .metrics .notes   .predictions .workflow \n  <list>                <chr>          <list>   <list>   <list>       <list>    \n1 <split [40453/13487]> train/test sp… <tibble> <tibble> <tibble>     <workflow>\n```\n\n\n:::\n:::\n\n\n\n# Modellgüte\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(fit1_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       0.159 Preprocessor1_Model1\n2 rsq     standard       0.976 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\nDe-logarithmieren, wenn man Vorhersagen in den Rohwerten haben möchte:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(fit1_test) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  id               .pred  .row price .config             \n  <chr>            <dbl> <int> <dbl> <chr>               \n1 train/test split  5.81     5  5.81 Preprocessor1_Model1\n2 train/test split  5.86     6  5.82 Preprocessor1_Model1\n3 train/test split  5.89     8  5.82 Preprocessor1_Model1\n4 train/test split  6.10     9  5.82 Preprocessor1_Model1\n5 train/test split  5.85    21  5.86 Preprocessor1_Model1\n6 train/test split  5.90    25  5.87 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test_w_preds <- \ncollect_predictions(fit1_test) %>% \n  mutate(pred_raw = exp(.pred)) \n\nhead(d_test_w_preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  id               .pred  .row price .config              pred_raw\n  <chr>            <dbl> <int> <dbl> <chr>                   <dbl>\n1 train/test split  5.81     5  5.81 Preprocessor1_Model1     334.\n2 train/test split  5.86     6  5.82 Preprocessor1_Model1     352.\n3 train/test split  5.89     8  5.82 Preprocessor1_Model1     360.\n4 train/test split  6.10     9  5.82 Preprocessor1_Model1     447.\n5 train/test split  5.85    21  5.86 Preprocessor1_Model1     346.\n6 train/test split  5.90    25  5.87 Preprocessor1_Model1     364.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- ds1\n- tidymodels\n- statlearning\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}