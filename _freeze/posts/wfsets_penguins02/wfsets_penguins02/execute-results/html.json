{
  "hash": "d4a158c1677d39400994908c5258a4d0",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: wfsets_penguins02\nextype: num\nexsolution: r fmt(sol)\nexshuffle: no\nexpoints: 1\ncategories:\n- R\n- statlearning\n- tidymodels\n- num\n- wfsets\ndate: '2023-05-17'\nslug: wfsets_penguins02\ntitle: wfsets_penguins02\nexecute: \n  output: false\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nBerechnen Sie die Vorhersagegüte (RMSE) für folgende Lernalgorithmen:\n\n- lineares Modell\n- knn (neighbors: tune)\n\nModellgleichung: `body_mass_g ~ bill_length_mm, data = d_train`.\n\nTunen Sie bei `neighbors` folgende Werte: 5, 10, 15, 20, 35, 30 und betrachten Sie deren Modellgüte.\n\nNutzen Sie minimale Vorverarbeitung.\n\nBerichten Sie die den RSME.\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(tidyverse)\ndata(penguins, package = \"palmerpenguins\")\n```\n:::\n\n\n## Daten\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <-\n  penguins %>% \n  drop_na()\n```\n:::\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(d)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n## Modelle\n\n\nLineares Modell:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_lin <- linear_reg()\n\nmod_knn <- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())\n```\n:::\n\n\n\n## Rezepte\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_basic <- recipe(body_mass_g ~ bill_length_mm, data = d_train) %>% \n         step_normalize(all_predictors())\n```\n:::\n\n\n\n## Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsmpls <- vfold_cv(d_train)\n```\n:::\n\n\n\n## Workflow Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set <-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic),\n    models = list(mod_lm = mod_lin,\n                  mod_nn = mod_knn)\n  )\n```\n:::\n\n\n## Tuningparameter-Werte bestimmen\n\nWelche Tuningparameter hatten wir noch mal ausgewiesen?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_knn %>% \n  extract_parameter_set_dials()\n```\n:::\n\n\nUpdaten wir die Parameter mit unseren Werten, also min. 5 Nachbarn und max. 20 Nachbarn.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparams_knn <- \nmod_knn %>% \n  extract_parameter_set_dials() %>% \n  update(neighbors = neighbors(c(5, 20)))\n```\n:::\n\n\nDiese Infos ergänzen wir jetzt in das Workflow-Set-Objekt für den Workflow mit der ID \"rec_simple_mod_nn\" unter der Spalte \"Options\":\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set <- \nwf_set %>% \n  option_add(param_info = params_knn, id = \"rec_simple_mod_nn\")  \n```\n:::\n\n\n\n\n## Fitten\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set_fit <-\n  wf_set %>% \n  workflow_map(resamples = rsmpls)\n```\n:::\n\n\n\nCheck:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set_fit %>% pluck(\"result\")\n```\n:::\n\n\n\n## Bester Kandidat\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(wf_set_fit)\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-13-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_results(wf_set_fit, rank_metric = \"rmse\") %>% \n  filter(.metric == \"rmse\")\n```\n:::\n\n\n\nAm besten war das lineare Modell, aber schauen wir uns auch mal das knn-Modell an, v.a. um zu wissen, wie man den besten Tuningparameter-Wert sieht:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_knn <- \n  extract_workflow_set_result(wf_set_fit, \"rec_simple_mod_nn\")\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_knn %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-16-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_knn %>% select_best()\n```\n:::\n\n\n\n## Last Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_wf <-\n  wf_set_fit %>% \n  extract_workflow(\"rec_simple_mod_lm\")\n```\n:::\n\n\n\nFinalisieren müssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_final <-\n  best_wf %>% \n  last_fit(d_split)\n```\n:::\n\n\n\n## Modellgüte im Test-Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(fit_final)\n```\n:::\n\n\n\n\n\n\n---\n\nCategories: \n\n- R\n- statlearning\n- tidymodels\n- num\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}