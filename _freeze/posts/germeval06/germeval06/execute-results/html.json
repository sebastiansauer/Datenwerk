{
  "hash": "8503fa64be988d3fe86925b9bc1f3983",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval06-de-wordvec-resamples\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- wordvec\n- string\ndate: '2023-11-16'\nslug: germeval06\ntitle: germeval06\n\n---\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. \nNutzen Sie *Glove6b Word-Vektoren* für das Feature-Engineering.\n\nNutzen Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(textrecipes)\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n## Textvektoren importieren\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(textdata)\n\nglove_embedding <- embedding_glove6b(\n  dir = \"/Users/sebastiansaueruser/datasets\",\n  return_path = TRUE,\n  manual_download = TRUE\n)\n\nhead(glove_embedding)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 51\n  token     d1      d2     d3      d4    d5      d6     d7     d8        d9\n  <chr>  <dbl>   <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>     <dbl>\n1 the   0.418   0.250  -0.412  0.122  0.345 -0.0445 -0.497 -0.179 -0.000660\n2 ,     0.0134  0.237  -0.169  0.410  0.638  0.477  -0.429 -0.556 -0.364   \n3 .     0.152   0.302  -0.168  0.177  0.317  0.340  -0.435 -0.311 -0.450   \n4 of    0.709   0.571  -0.472  0.180  0.544  0.726   0.182 -0.524  0.104   \n5 to    0.680  -0.0393  0.302 -0.178  0.430  0.0322 -0.414  0.132 -0.298   \n6 and   0.268   0.143  -0.279  0.0163 0.114  0.699  -0.513 -0.474 -0.331   \n# ℹ 41 more variables: d10 <dbl>, d11 <dbl>, d12 <dbl>, d13 <dbl>, d14 <dbl>,\n#   d15 <dbl>, d16 <dbl>, d17 <dbl>, d18 <dbl>, d19 <dbl>, d20 <dbl>,\n#   d21 <dbl>, d22 <dbl>, d23 <dbl>, d24 <dbl>, d25 <dbl>, d26 <dbl>,\n#   d27 <dbl>, d28 <dbl>, d29 <dbl>, d30 <dbl>, d31 <dbl>, d32 <dbl>,\n#   d33 <dbl>, d34 <dbl>, d35 <dbl>, d36 <dbl>, d37 <dbl>, d38 <dbl>,\n#   d39 <dbl>, d40 <dbl>, d41 <dbl>, d42 <dbl>, d43 <dbl>, d44 <dbl>,\n#   d45 <dbl>, d46 <dbl>, d47 <dbl>, d48 <dbl>, d49 <dbl>, d50 <dbl>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# model:\nmod1 <-\n  logistic_reg()\n\n\n# cv:\nset.seed(42)\nrsmpl <- vfold_cv(d_train, v = 5)\n\n\n# recipe:\nrec1 <-\n  recipe(c1 ~ ., data = d_train) |> \n  update_role(id, new_role = \"id\")  |> \n  #update_role(c2, new_role = \"ignore\") |> \n  step_tokenize(text) %>%\n  step_stopwords(text, keep = FALSE) %>%\n  step_word_embeddings(text,\n                       embeddings = glove_embedding,\n                       aggregation = \"mean\") |> \n  step_normalize(all_numeric_predictors()) \n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod1) %>% \n  add_recipe(rec1)\n```\n:::\n\n\n\n## Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nwf1_fit <-\n  wf1 %>% \n  fit_resamples(\n    resamples = rsmpl,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n25.238 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nbeep()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_fit |> collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.656     5 0.00726 Preprocessor1_Model1\n2 f_meas   binary     0.129     5 0.0156  Preprocessor1_Model1\n3 roc_auc  binary     0.593     5 0.00947 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\nBester Fold:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(wf1_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.656     5 0.00726 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit1 <- \n  wf1 |> \n  fit(data = d_train)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5.413 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(fit1, new_data = germeval_test)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.356 sec elapsed\n```\n\n\n:::\n:::\n\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.652\n2 f_meas   binary         0.138\n```\n\n\n:::\n:::\n\n\n\n## Fazit\n\n\n\n\n`glove6b` ist für die englische Sprache vorgekocht. \nDas macht wenig Sinn für einen deutschsprachigen Corpus.\n\n\n\n\n\n\n---\n\nCategories: \n\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- wordvec\n- string\n\n",
    "supporting": [
      "germeval06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}