{
  "hash": "66a71b780a39a451829c3de0d4df9d95",
  "result": {
    "engine": "knitr",
    "markdown": "---\nextype: string\nexsolution: NA\nexname: zwielichter-dozent\nexpoints: 1\ncategories:\n- bayes\n- probability\n- ppv\ndate: '2022-11-05'\ntitle: zwielichter-dozent-bayes\n\n\n---\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(digits = 2)\n```\n:::\n\n\n\n\n\n\n\n\n\n# Exercise\n\n\nNach einem langen Unitag machen Sie sich auf den Weg nach Hause; \nihr Weg führt Sie durch eine dunkle Ecke. \nJust dort regt sich auf einmal eine Gestalt in den Schatten\n. Die Person spricht Sie an: „Na, Lust auf ein Spielchen?“. \nSie willigen sofort ein. Die Person stellt sich als ein Statistiker vor,\ndessen Namen nichts zur Sache tue; \ndas Gesicht kommt Ihnen vage bekannt vor. „Pass auf“, erklärt der Statistiker, \n„wir werfen eine Münze, ich setze auf Zahl“. Dass er auf Zahl setzt, überrascht Sie nicht\n. „Wenn ich gewinne“, fährt der Statistiker fort, \n„bekomme ich 10 Euro von Dir, wenn Du gewinnst, bekommst Du 11 Euro von mir. Gutes Spiel, oder?“. \nSie einigen sich auf 10 Durchgänge, in denen der Statistiker jedes Mal eine Münze wirft,\nfängt und dann die oben liegende Seite prüft.\nErster Wurf: Zahl! Der Statistiker gewinnt. Pech für Sie.\nZweiter Wurf: Zahl! Schon wieder 10 Euro für den Statistiker. Hm.\nDritter Wurf: . . . Zahl! Schon wieder. Aber kann ja passieren, bei einer fairen Münze, oder?\nVierter Wurf: Zahl! Langsam regen sich Zweifel bei Ihnen. Kann das noch mit rechten Dingen zugehen? \nIst die Münzewirklich  fair? Insgesamt gewinnt der zwielichte Statistiker 8 von 10 Durchgängen. \n\nUnter leisem Gelächter des Statistikers (und mit leeren Taschen) machen Sie sich von dannen. \nHat er falsch gespielt? Wie plausibel ist es, bei 10 Würfen 8 Treffer zu erhalten, \nwenn die Münze fair ist? Ist das ein häufiges, ein typisches Ereignis oder ein seltenes, \nuntypisches Ereignis bei einer fairen Münze? Wenn es ein einigermaßen häufiges Ereignis sein sollte, \ndann spricht das für die Fairness der Münze. Zumindest spricht ein Ereignis, \nwelches von einer Hypothese als häufig vorausgesagt wird und schließlich eintritt, \nnicht gegen eine Hypothese. Zuhause angekommen, denken Sie sich, jetzt müssen Sie erstmal in Ruhe die Posteriori-Verteilung und die PPV ausrechnen!\n\n\na) Berechnen Sie die Posteriori-Verteilung mit der Gittermethode! Gehen Sie von einer gleichverteilten Priori-Wahrscheinlichkeit aus. Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\n\nb) Wie groß ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die Münze zugunsten des Dozenten gezinkt ist?\n\nc) Geben Sie das 50%-PI und 50%-HDPI zum Parameterwert ($p$ der Münze) an!\n\nd) Mit welcher Wahrscheinlichkeit liegt die Trefferchance der Münze zwischen $p=.45$ und $p=.55$, ist also nicht \"nennenswert\" gezinkt?\n\ne) Was ist der wahrscheinlichste Parameterwert (Trefferchance der Münze)?\n\nf) Geben Sie das 90%-PI und 90%-HDI zu Parameterwert ($p$ der Münze) an!\n\ng) Berechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\n\nh) Diskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von $p$!\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\na) Berechnen Sie die Posteriori-Verteilung mit der Gittermethode! Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_grid <- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior <- rep( 1 , 1000 )  # Priori-Gewichte\n\nlikelihood <- dbinom(8, size = 10, prob=p_grid) \n\nunstandardisierte_posterior <- likelihood * prior \n\nposterior <- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples <- \n  tibble(\n    gewinnchance_muenze = sample(p_grid , prob=posterior, size=1e4, replace=TRUE))\n```\n:::\n\n\n\n\nVisualisierung:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples %>% \n  ggplot() +\n  aes(x = gewinnchance_muenze) +\n  geom_histogram() +\n  labs(title = \"Posterior-Verteilung\",\n       x = \"Gewinnchance der Münze (50%: faire Münze)\")\n```\n\n::: {.cell-output-display}\n![](zwielichter-dozent-bayes_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\nb) Wie groß ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die Münze zugunsten des Dozenten gezinkt ist?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples %>% \n  count(gewinnchance_muenze > .5) %>% \n  mutate(prop = n / sum(n))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gewinnchance_muenze > 0.5 |    n| prop|\n|:-------------------------|----:|----:|\n|FALSE                     |  310| 0.03|\n|TRUE                      | 9690| 0.97|\n\n</div>\n:::\n:::\n\n\n\n\n\n\n\n\n\nc) Geben Sie das 50%-PI (Perzentilintervall) und 50%-HDI zum Parameterwert ($p$ der Münze) an!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easystats)\neti(samples, ci = .5)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter           |  CI| CI_low| CI_high|\n|:-------------------|---:|------:|-------:|\n|gewinnchance_muenze | 0.5|   0.67|    0.84|\n\n</div>\n:::\n\n```{.r .cell-code}\nhdi(samples, ci = .5)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter           |  CI| CI_low| CI_high|\n|:-------------------|---:|------:|-------:|\n|gewinnchance_muenze | 0.5|   0.72|    0.88|\n\n</div>\n:::\n:::\n\n\n\n\nEin PI wird auch *equal tail interval* genannt, weil die beiden \"abgeschnitten Randbereiche\" links und rechts die gleichen Flächenanteil (Wahrscheinlichkeitsmasse) aufweisen.\n\n\nInteresant ist, dass das PI und das HDI zu unterschiedlichen Ergebnissen kommen.\nDas lässt auf eine schiefe Verteilung schließen.\nAußerdem eröffnet es den Raum zur Diskussion, welches Intervall man berichtet.\nUm diese Frage besser zu verstehen, können wir die Intervalle visualisieren.\n\n\nBonus: Visualisieren wir die Intervalle:\n\nPI:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neti(samples, ci = .5) %>% plot()\n```\n\n::: {.cell-output-display}\n![](zwielichter-dozent-bayes_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\nHDI:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhdi(samples, ci = .5) %>% plot()\n```\n\n::: {.cell-output-display}\n![](zwielichter-dozent-bayes_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\nDas HDI ist schmäler und liegt näher am Modus. Vermutlich ist das HDI zu bevorzugen.\n\n\nd) Mit welcher Wahrscheinlichkeit liegt die Trefferchance der Münze zwischen $p=.45$ und $p=.55$, ist also nicht \"nennenswert\" gezinkt (auf Basis unserer Modellannahmen)?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples %>% \n  count(gewinnchance_muenze >= 0.45 & gewinnchance_muenze <= .55) %>% \n  mutate(prop = n/sum(n))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gewinnchance_muenze >= 0.45 & gewinnchance_muenze <= 0.55 |    n| prop|\n|:---------------------------------------------------------|----:|----:|\n|FALSE                                                     | 9522| 0.95|\n|TRUE                                                      |  478| 0.05|\n\n</div>\n:::\n:::\n\n\n\n\nDie Wahrscheinlichkeit, dass die Münze nicht nennenswert gezinkt ist (nach unserer Definition), ist gering.\nMan sollte vielleicht erwähnen, dass unsere Definition von \"nicht nennenswert gezinkt\" plausibel ist,\nund andere (vernünftige) Definitionen zu einem sehr ähnlichen Ergebnis kämen.\n\ne) Was ist der wahrscheinlichste Parameterwert (Trefferchance der Münze)?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples %>% \n   map_estimate()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter           | MAP_Estimate|\n|:-------------------|------------:|\n|gewinnchance_muenze |          0.8|\n\n</div>\n:::\n:::\n\n\n\n\n\n`map_estimate` steht für ...\n\n>   Find the Highest Maximum A Posteriori probability estimate (MAP) of a posterior, i.e., the value associated with the highest probability density (the \"peak\" of the posterior distribution). In other words, it is an estimation of the mode for continuous parameters. \n\n(aus der Hilfeseite der Funktion)\n\nf) Geben Sie das 90%-PI und 90%-HDI zum Parameterwert ($p$ der Münze) an!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easystats)\neti(samples, ci = .9)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter           |  CI| CI_low| CI_high|\n|:-------------------|---:|------:|-------:|\n|gewinnchance_muenze | 0.9|   0.53|    0.92|\n\n</div>\n:::\n\n```{.r .cell-code}\nhdi(samples, ci = .9)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter           |  CI| CI_low| CI_high|\n|:-------------------|---:|------:|-------:|\n|gewinnchance_muenze | 0.9|   0.57|    0.95|\n\n</div>\n:::\n:::\n\n\n\n\n\n\ng) Berechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPPV <-\n  samples %>% \n  mutate(anzahl_kopf = rbinom(n = 1e4, size = 10, prob = gewinnchance_muenze))\n```\n:::\n\n\n\n\nVisualisierung:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPPV %>% \n  ggplot() +\n  aes(x = anzahl_kopf) +\n  labs(title = \"PPV\") +\n  geom_bar()  # geom_bar() ginge auch, sieht aber bei wenig Balken nicht so gut aus.\n```\n\n::: {.cell-output-display}\n![](zwielichter-dozent-bayes_files/figure-html/ppv-p-1.png){width=672}\n:::\n:::\n\n\n\n\n\nLaut der PPV sind 8 von 10 Treffern der Wert, der mit der höchsten Wahrscheinlichkeit zu beobachten sein wird. Allerdings sind 7 oder 9 Treffer fast genauso wahrscheinlich. Etwas genauer:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPPV %>% \n  count(between(anzahl_kopf, 7,9))   # \"zähle mir, wie oft ein Wert ZWISCHEN (between) 7 und 9 vorkommt\"\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|between(anzahl_kopf, 7, 9) |    n|\n|:--------------------------|----:|\n|FALSE                      | 3902|\n|TRUE                       | 6098|\n\n</div>\n:::\n:::\n\n\n\n\nMit dieser Wahrscheinlichkeit ist ein Wert zwischen 7 und 9 zu beobachten, wenn man den Versuch wiederholt, laut dem Modell.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPPV %>% \n  eti(anzahl_kopf, ci = .9)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter           |  CI| CI_low| CI_high|\n|:-------------------|---:|------:|-------:|\n|gewinnchance_muenze | 0.9|   0.53|    0.92|\n|anzahl_kopf         | 0.9|   4.00|   10.00|\n\n</div>\n:::\n:::\n\n\n\n\n\nUnser Modell sieht einen \"Passungsbereich\" (ein Perzentilintervall) von 4 bis 10 Treffern als mit 90% Wahrscheinlichkeit passend an.\n\n\nh) Diskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von $p$!\n\nZwar hat eine Gleichverteilung der Priori-Werte den Vorteil, dass sie \"objektiv\" ist in dem Sinne, dass kein Wert \"bevorteilt\" wird; alle gelten als gleich wahrscheinlich. \nAber das ist hochgradig unplausibel: So ist z.B. der Wert $p=1$ logisch unmöglich, da wir nicht nur Treffer beobachtet haben. Ein Wert von z.B. $p=0.999$ erscheint uns ebenfalls sehr unwahrscheinlich. \nNützlicher erscheint daher vielleicht doch eine Priori-Verteilung, die extreme Werte von $p$ als unwahrscheinlich bemisst. \n\n\n\n\n---\n\nCategories: \n\n- bayes\n- probability\n- ppv\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}