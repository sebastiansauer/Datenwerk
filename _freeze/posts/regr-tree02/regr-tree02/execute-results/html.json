{
  "hash": "1ad7ef86e0ab6b261072a3344e2c8bab",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: regression-tree02\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- statlearning\n- trees\n- tidymodels\n- string\ndate: '2023-05-17'\nslug: regr-tree02\ntitle: regr-tree02\n\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n```\n\n\n:::\n:::\n\n\n\n\n# Aufgabe\n\n\nBerechnen Sie einfaches Prognosemodell auf Basis eines Entscheidungsbaums!\n\nModellformel: `am ~ .` (Datensatz `mtcars`)\n\nBerichten Sie die Modellgüte (ROC-AUC).\n\nHinweise:\n\n- Tunen Sie alle Parameter (die der Engine anbietet). \n- Führen Sie eine $v=2$-fache Kreuzvalidierung durch (weil die Stichprobe so klein ist).\n- Beachten Sie die [üblichen Hinweise](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\n```\n:::\n\n\n\nFür Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars <-\n  mtcars %>% \n  mutate(am = factor(am))\n```\n:::\n\n\n\n\n## Daten teilen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(mtcars)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n## Modell(e)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_tree <-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())\n```\n:::\n\n\n\n\n\n## Rezept(e)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <- \n  recipe(am ~ ., data = d_train)\n```\n:::\n\n\n\n\n## Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsmpl <- vfold_cv(d_train, v = 2)\n```\n:::\n\n\n\n## Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1 <-\n  workflow() %>%  \n  add_recipe(rec1) %>% \n  add_model(mod_tree)\n```\n:::\n\n\n## Tuning/Fitting\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <-\n  tune_grid(object = wf1,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n→ A | warning: 30 samples were requested but there were 12 rows in the data. 12 will be used.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThere were issues with some computations   A: x1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n→ B | warning: 18 samples were requested but there were 12 rows in the data. 12 will be used.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThere were issues with some computations   A: x1\n→ C | warning: 27 samples were requested but there were 12 rows in the data. 12 will be used.\nThere were issues with some computations   A: x1\n→ D | warning: 17 samples were requested but there were 12 rows in the data. 12 will be used.\nThere were issues with some computations   A: x1\n→ E | warning: 33 samples were requested but there were 12 rows in the data. 12 will be used.\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ F | warning: 22 samples were requested but there were 12 rows in the data. 12 will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\n→ G | warning: 37 samples were requested but there were 12 rows in the data. 12 will be used.\nThere were issues with some computations   A: x1   B: x1   C: x1   D: x1   E: x1\nThere were issues with some computations   A: x2   B: x2   C: x2   D: x2   E: x…\n```\n\n\n:::\n:::\n\n\n\n## Bester Kandidat\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(fit1)\n```\n\n::: {.cell-output-display}\n![](regr-tree02_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            <dbl>      <int> <int> <chr>   <chr>      <dbl> <int>   <dbl>\n1        5.46e- 2          8     3 roc_auc binary     0.879     2  0.121 \n2        4.23e- 5         13    30 roc_auc binary     0.816     2  0.0589\n3        1.06e- 7          2    18 roc_auc binary     0.816     2  0.0589\n4        2.41e- 5         15     8 roc_auc binary     0.816     2  0.0589\n5        9.18e-10         10    11 roc_auc binary     0.816     2  0.0589\n# ℹ 1 more variable: .config <chr>\n```\n\n\n:::\n:::\n\n\n\n## Finalisieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_finalized <-\n  wf1 %>% \n  finalize_workflow(select_best(fit1))\n```\n:::\n\n\n\n## Last Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- \n  last_fit(object = wf1_finalized, d_split)\n\ncollect_metrics(final_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary             1 Preprocessor1_Model1\n2 roc_auc  binary             1 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n\n---\n\nCategories: \n\n- statlearning\n- trees\n- tidymodels\n- string\n\n",
    "supporting": [
      "regr-tree02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}