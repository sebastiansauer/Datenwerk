{
  "hash": "810ba5e49ff0f258ae8121027563b5e7",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- sentiment\n- string\n- tune\ndate: '2023-12-05'\ntitle: germeval03-sent-wordvec-glm\ndraft: false  \neval: true\nexecute:\n  cache: true\n---\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie außerdem *deutsche Word-Vektoren* für das Feature-Engineering.\n\nAls Lernalgorithmus verwenden Sie eine einfache logistische Regression, d.h. ohne Tuning-Parameter. \n\n\n## Daten\n\nVerwenden Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\n## AV und UV\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\n## Hinweise\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n- Nutzen Sie das `sentiws` Lexikon.\n- ❗ Achten Sie darauf, die Variable `c2` zu entfernen bzw. nicht zu verwenden.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Setup\n\nTrain-Datensatz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n\nPakete:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(beepr)\nlibrary(finetune)  # anova race\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n\n## Learner/Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <-\n  logistic_reg(mode = \"classification\"\n  )\n```\n:::\n\n\n\n\n## Gebackenen Datensatz als neue Grundlage\n\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz.\nDas hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind.\nDie Arbeit des Feature Engineering wurde uns schon abgenommen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_raw <-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 5009 Columns: 121\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (1): c1\ndbl (120): id, emo_count, schimpf_count, emoji_count, textfeature_text_copy_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test_baked_raw <- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 3532 Columns: 121\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (1): c1\ndbl (120): id, emo_count, schimpf_count, emoji_count, textfeature_text_copy_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n## Keine Dummysierung der AV\n\nLineare Modelle müssen dummysiert sein. Rezepte wollen das nicht so gerne für die AV besorgen. \n\nABER: Klassifikationsmodelle in Tidymodels (parsnip) benötigen eine Variable vom Typ *factor*  als AV, sonst werden sie nicht als Klassifikation erkannt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  d_train_raw |> \n  mutate(c1 = as.factor(c1)) \n\nlevels(d_train$c1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"OFFENSE\" \"OTHER\"  \n```\n\n\n:::\n:::\n\n\nTidymodels modelliert die *erste* Stufe, nicht die zweite, wie Base-R `glm`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test_baked <-\n  d_test_baked_raw |> \n  mutate(c1 = as.factor(c1)) \n\nlevels(d_test_baked$c1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"OFFENSE\" \"OTHER\"  \n```\n\n\n:::\n:::\n\n\n\n\n\n## Dummy-Rezept\n\nPlain, aber mit Dummyisierung:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- \n  recipe(c1 ~ ., data = d_train) \n```\n:::\n\n\n\n\n\n##  Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf <-\n  workflow() |> \n  add_recipe(rec) |> \n  add_model(mod)\n```\n:::\n\n\n\n\n\n\n## Tune/Resample/Fit\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_train <-\n  fit(wf,\n      data = d_train)\n```\n:::\n\n\n\n\n\n## Test-Set-Güte\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(fit_train, new_data = d_test_baked)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.036 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  d_test_baked |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.716\n2 f_meas   binary         0.509\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}