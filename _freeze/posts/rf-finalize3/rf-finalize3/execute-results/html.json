{
  "hash": "1fe5065c980078242439a9a9e827139c",
  "result": {
    "markdown": "---\nexname: rf-finalize3\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- tidymodels\n- statlearning\n- template\n- string\ndate: '2023-05-09'\nslug: rf-finalize3\ntitle: rf-finalize3\n\n---\n\n\n\n\n\n# Aufgabe\n\n<!-- Schreiben Sie eine Vorlage für eine prädiktive Analyse mit Tidymodels! -->\n\nBerechnen Sie ein prädiktives Modell (Random Forest) mit dieser Modellgleichung:\n\n`body_mass_g ~ .` (Datensatz: palmerpenguins::penguins).\n\n\nZeigen Sie, welche Werte für mtry im Default von Tidymodels gesetzt werden!\n\nHinweise:\n- Tunen Sie alle Tuningparameter mit jeweils 3 Werten.\n- Verwenden Sie Kreuzvalidierung\n- Verwenden Sie Standardwerte, wo nicht anders angegeben.\n- Fixieren Sie Zufallszahlen auf den Startwert 42.\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Standard-Start\n\nZuererst der Standardablauf:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Setup:\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ broom        1.0.4     ✔ recipes      1.0.5\n✔ dials        1.2.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.1     ✔ tibble       3.2.1\n✔ ggplot2      3.4.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.0\n✔ modeldata    1.1.0     ✔ workflows    1.1.3\n✔ parsnip      1.0.4     ✔ workflowsets 1.0.0\n✔ purrr        1.0.1     ✔ yardstick    1.1.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.2     ✔ stringr   1.5.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tictoc)  # Zeitmessung\nset.seed(42)\n\n\n# Data:\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd <- read_csv(d_path)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 344 Columns: 9\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): species, island, sex dbl (6): ...1, bill_length_mm, bill_depth_mm,\nflipper_length_mm, body_mass_g...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n\n```{.r .cell-code}\n# rm NA in the dependent variable:\nd <- d %>% \n  drop_na(body_mass_g)\n\n\nset.seed(42)\nd_split <- initial_split(d)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n# model:\nmod_rf <-\n  rand_forest(mode = \"regression\",\n           mtry = tune(),\n           min_n = tune(),\n           trees = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl <- vfold_cv(d_train)\n\n\n# recipe:\nrec_plain <- \n  recipe(body_mass_g ~  ., data = d_train) %>% \n  step_impute_bag(all_predictors())\n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod_rf) %>% \n  add_recipe(rec_plain)\n```\n:::\n\n\n## Tuninggrid\n\nWelche Tuningparameter hat unser Workflow? \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_params_unclear <- \n  extract_parameter_set_dials(wf1)\nwf1_params_unclear\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCollection of 3 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      trees trees nparam[+]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n```\n:::\n:::\n\n\n\n\nVerlangt waren 3 Tuningparameterwerte pro Parameter:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_grid <- grid_latin_hypercube(wf1_params_unclear, levels = 3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `levels` is not an argument to `grid_latin_hypercube()`. Did you mean\n`size`?\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in `grid_latin_hypercube()`:\n! These arguments contain unknowns: `mtry`.\nℹ See the `finalize()` function.\n```\n:::\n\n```{.r .cell-code}\nmy_grid\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'my_grid' not found\n```\n:::\n:::\n\n\nTidymodels weiß nicht, welche Werte für `mtry` benutzt werden sollen,\nda dieser Wert abhängig ist von der Anzahl der Spalten des Datensatzes,\nund damit unabhängig vom Modell.\n\nDie Ausgabe `nparam[?]` oben sagt uns, dass Tidymodels den Wertebereich des Tuningparameter nicht klären könnte, da er Daten abhängig ist.\n\nInformieren wir also Tidymodels zu diesem Wertebereich:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_params <- \n  wf1 %>% \n  extract_parameter_set_dials() %>% \n  update(mtry = finalize(mtry(), d_train))\n\nwf1_params\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCollection of 3 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[+]\n      trees trees nparam[+]\n      min_n min_n nparam[+]\n```\n:::\n:::\n\n\nSo, jetzt weiß Tidymodels, wie viele Werte für `mtry` benutzt werden können.\n\nWir können jetzt das Tuninggitter erstellen (das macht das Paket `dials`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_grid <- grid_latin_hypercube(wf1_params, size = 125)\nmy_grid %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n   mtry trees min_n\n  <int> <int> <int>\n1     1   105    11\n2     5  1036    21\n3     3   325    16\n4     4  1375    28\n5     6  1405    21\n6     7   304    15\n```\n:::\n:::\n\n\nWie viele verschiedene Werte gibt es in dem Tuningitter?\n\nSchauen wir es uns mal an.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_grid %>% \n  ggplot(aes(x = trees, y = mtry)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](rf-finalize3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nWir können das Tuninggitter auch selber erstellen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_grid <-\n  grid_latin_hypercube(mtry(range = c(1, ncol(d_train)-1)),\n                       trees(),\n                       min_n(),\n                       size = 60)\ndim(my_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60  3\n```\n:::\n:::\n\n\n\n## Tuning/Fitting\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tuning:\ntic()\nwf1_fit <-\n  wf1 %>% \n  tune_grid(\n    grid = my_grid,\n    resamples = rsmpl)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n137.507 sec elapsed\n```\n:::\n:::\n\n\nDann schauen wir uns das Ergebnisobjekt vom Tuning an.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_fit %>% \n  collect_metrics() %>% \n  filter(.metric == \"rmse\") %>% \n  arrange(mtry)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 9\n    mtry trees min_n .metric .estimator  mean     n std_err .config             \n   <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n 1     1  1835    33 rmse    standard    332.    10    13.7 Preprocessor1_Model…\n 2     1  1742    14 rmse    standard    316.    10    13.1 Preprocessor1_Model…\n 3     1   510    29 rmse    standard    327.    10    14.1 Preprocessor1_Model…\n 4     1   826     3 rmse    standard    310.    10    13.0 Preprocessor1_Model…\n 5     2   672    15 rmse    standard    283.    10    11.2 Preprocessor1_Model…\n 6     2   147    22 rmse    standard    287.    10    10.7 Preprocessor1_Model…\n 7     2  1927     7 rmse    standard    283.    10    11.4 Preprocessor1_Model…\n 8     2   386    23 rmse    standard    288.    10    11.9 Preprocessor1_Model…\n 9     2    81    29 rmse    standard    292.    10    12.3 Preprocessor1_Model…\n10     2   359     6 rmse    standard    283.    10    11.1 Preprocessor1_Model…\n# ℹ 50 more rows\n```\n:::\n:::\n\n\n\nIn der Hilfe ist zu lesen:\n\n\n>    In some cases, the tuning parameter values depend on the dimensions of the data. For example, mtry in random forest models depends on the number of predictors. In this case, the default tuning parameter object requires an upper range. dials::finalize() can be used to derive the data-dependent parameters. Otherwise, a parameter set can be created (via dials::parameters()) and the dials update() function can be used to change the values. This updated parameter set can be passed to the function via the param_info argument.\n\n\nAchtung: `step_impute_knn` scheint Probleme zu haben, wenn es Charakter-Variablen gibt.\n\n\n\nPraktischerweise findet Tidymodels die Begrenzung von `mtry` selber heraus, wenn Sie kein Tuninggrid definieren.\nDas erkennen Sie daran, dass Tidymodels beim Tuning/Fitten die folgende Ausgabe zeigt:\n\n`i Creating pre-processing data to finalize unknown parameter: mtry`.\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- statlearning\n- template\n- string\n\n",
    "supporting": [
      "rf-finalize3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}