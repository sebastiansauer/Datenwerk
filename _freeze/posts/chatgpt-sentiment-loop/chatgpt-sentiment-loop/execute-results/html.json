{
  "hash": "87f4ba945c4cc012f03f7976b78e52ce",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: today\ndraft: FALSE   # ACHTUNG DRAFT STEHT AUF TRUE!\ntitle: chatgpt-sentiment-loop\nexecute: \n  eval: true \n  \nhighlight-style: arrow \ncache: true\n\nextype: string\nexsolution: \"\"\ncategories:\n- textmining\n- nlp\n- transformer\n- chatgpt\n- sentiment\n---\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\n\nFragen Sie ChatGPT via API zum Sentiment der ersten zwei Texte aus dem Germeval-2018-Datensatz (Train).\n\n\nHinweise:\n\n- Beachten Sie die [Standardhinweise des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Python, nicht R.\n- Das Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen.\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# L√∂sung\n\n\n::: {.callout-attention}\nOpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî $\\square$\n:::\n\n\nDie richtige venv nutzen:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-1_5005f4ce8d51e0877787abfe089c375e'}\n\n```{.r .cell-code}\nlibrary(reticulate)\n#virtualenv_create(\"chatgpt\")\nuse_virtualenv(\"chatgpt\")\n```\n:::\n\n\n\nCheck zu Python:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-2_becd603f868e5071c258b0d15bcbfb14'}\n\n```{.r .cell-code}\nreticulate::py_config()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npython:         /Users/sebastiansaueruser/.virtualenvs/chatgpt/bin/python\nlibpython:      /Users/sebastiansaueruser/.pyenv/versions/3.11.1/lib/libpython3.11.dylib\npythonhome:     /Users/sebastiansaueruser/.virtualenvs/chatgpt:/Users/sebastiansaueruser/.virtualenvs/chatgpt\nversion:        3.11.1 (main, Oct  4 2023, 18:12:06) [Clang 15.0.0 (clang-1500.0.40.1)]\nnumpy:          /Users/sebastiansaueruser/.virtualenvs/chatgpt/lib/python3.11/site-packages/numpy\nnumpy_version:  1.26.2\n\nNOTE: Python version was forced by use_python() function\n```\n\n\n:::\n:::\n\n\nGgf. noch Module installieren:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-3_bdeb3383ba8a3feb3c390d9c179f0134'}\n\n```{.r .cell-code}\n#reticulate::py_install(\"pandas\")\n```\n:::\n\n\n\nModule importieren:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-4_870505338b2f04de636240ceb0493296'}\n\n```{.python .cell-code}\nfrom openai import OpenAI\nimport pandas as pd\nimport time \n```\n:::\n\n\nVersionen der importierten Module:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-5_5f6f3f02c643305e6ffb669828ce4994'}\n\n```{.python .cell-code}\npd.__version__\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'2.1.3'\n```\n\n\n:::\n:::\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-6_f5eae1c7802952339446792fd04a475d'}\n\n````{.cell-code}\n```{{zsh}}\npip list | grep openai\n```\n````\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nopenai            1.3.5\n```\n\n\n:::\n:::\n\n\n\nWir brauchen `>= 1.35`.\n\nDaten importieren:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/import-data_49b2aae2b4a2f99fbaef4377836d7c46'}\n\n```{.python .cell-code}\ncsv_file_path_train = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv'\n\ngermeval_train = pd.read_csv(csv_file_path_train)\n```\n:::\n\n\n\nDie ersten paar Texte herausziehen:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/tweets-first-few_7c6e405a63296724d4655b805fb34e48'}\n\n```{.python .cell-code}\nn_tweets = 2\ntweets_first_few = germeval_train[\"text\"].head(n_tweets).tolist()\ntweets_first_few\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.']\n```\n\n\n:::\n:::\n\n\n\nPrompt definieren:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-7_981be00049c499619a6d95570e47d004'}\n\n```{.python .cell-code}\nprompt_stem  = \"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes zu erkennen. Bitte antworten Sie nur mit einem Wort, entweder 'positiv', 'neutral' oder 'negativ'. Dieses Wort soll die Insgesamt-Einsch√§tzung des Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folt der Text, dessen Sentiment Sie einsch√§tzen sollen: \\n\"\n```\n:::\n\n\n\nMit \"List Comprehension\" k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-8_2a1e1c6053d0d894cc8ccbddc97c534a'}\n\n```{.python .cell-code}\nprompts = [prompt_stem + tweet for tweet in tweets_first_few]\nprompts[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes zu erkennen. Bitte antworten Sie nur mit einem Wort, entweder 'positiv', 'neutral' oder 'negativ'. Dieses Wort soll die Insgesamt-Einsch√§tzung des Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folt der Text, dessen Sentiment Sie einsch√§tzen sollen: \\n@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"\n```\n\n\n:::\n:::\n\n\nCheck: Wie viele Elemente hat die Liste `prompts`?\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-9_3febcf656fdaa6b982cc87c171afab63'}\n\n```{.python .cell-code}\nlen(prompts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2\n```\n\n\n:::\n:::\n\n\n\n\nAnmelden bei OpenAI:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-10_2e15fb2f3e26ea191649ef69d1c485a9'}\n\n```{.python .cell-code}\nclient = OpenAI()\n```\n:::\n\n\n\n::: {.callout-note}\nDieses Anmeldeverfahren setzt voraus, dass in `.Renviron` die Variable `OPENAI_API_KEY` hinterlegt ist. $\\square$\n:::\n\n\n\n\n\n\nAnfrage an die API, in eine Funktion gepackt:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-11_6d1eecfa6d43532246fa7b13b96f42a9'}\n\n```{.python .cell-code}\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n    model=model,\n    messages=messages,\n    max_tokens=50,\n    temperature=0,\n  )\n  return response.choices[0].message.content\n```\n:::\n\n\n\nUnd jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-12_2e740bf937e23c97f872dd10cc7f89fc'}\n\n```{.python .cell-code}\nresults = []\n```\n:::\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/ask-api_0290eae442dfa20daf3dc2e41e8b3488'}\n\n```{.python .cell-code}\nstart_time = time.time()\n\nfor prompt in prompts:\n  result = get_completion(prompt, client) \n  results.append(result)\n\nend_time = time.time()\nend_time - start_time\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n4.484155893325806\n```\n\n\n:::\n:::\n\n\nVoil√†:\n\n\n\n::: {.cell hash='chatgpt-sentiment-loop_cache/html/unnamed-chunk-13_338b3f7e934cedabb74996033fa4e4fe'}\n\n```{.python .cell-code}\nprint(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['positiv', 'neutral']\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}