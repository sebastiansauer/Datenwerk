{
  "hash": "c02cb56b6cf75b379d1a741aa69386d5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: 2023-12-05 \ndraft: FALSE   # ACHTUNG DRAFT STEHT AUF TRUE!\ntitle: chatgpt-sentiment-loop\nexecute: \n  eval: true \n  \nhighlight-style: arrow \ncache: true\n\nextype: string\nexsolution: \"\"\ncategories:\n- textmining\n- nlp\n- transformer\n- chatgpt\n- sentiment\n---\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\n\nFragen Sie ChatGPT via API zum Sentiment der ersten zwei Texte aus dem Germeval-2018-Datensatz (Train).\n\n\nHinweise:\n\n- Beachten Sie die [Standardhinweise des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Python, nicht R.\n- Das Verwenden der OpenAI-API kostet Geld. üí∏ Informieren Sie sich vorab. Um auf die API zugreifen zu k√∂nnen, m√ºssen Sie sich ein Konto angelegt haben und √ºber ein Guthaben verf√ºgen.\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# L√∂sung\n\n\n::: {.callout-attention}\nOpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. üíî $\\square$\n:::\n\n\nDie richtige venv nutzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n#virtualenv_create(\"chatgpt\")\nuse_virtualenv(\"chatgpt\")\n```\n:::\n\n\n\nCheck zu Python:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::py_config()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npython:         /Users/sebastiansaueruser/.virtualenvs/chatgpt/bin/python\nlibpython:      /Users/sebastiansaueruser/.pyenv/versions/3.11.1/lib/libpython3.11.dylib\npythonhome:     /Users/sebastiansaueruser/.virtualenvs/chatgpt:/Users/sebastiansaueruser/.virtualenvs/chatgpt\nversion:        3.11.1 (main, Oct  4 2023, 18:12:06) [Clang 15.0.0 (clang-1500.0.40.1)]\nnumpy:          /Users/sebastiansaueruser/.virtualenvs/chatgpt/lib/python3.11/site-packages/numpy\nnumpy_version:  1.26.2\n\nNOTE: Python version was forced by use_python() function\n```\n\n\n:::\n:::\n\n\nGgf. noch Module installieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#reticulate::py_install(\"pandas\")\n```\n:::\n\n\n\nModule importieren:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom openai import OpenAI\nimport pandas as pd\nimport time \nimport tiktoken  # Token z√§hlen\n```\n:::\n\n\nVersionen der importierten Module:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.__version__\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'2.1.3'\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{zsh}}\npip list | grep openai\n```\n````\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n[notice] To update, run: pip install --upgrade pip\nopenai             1.3.5\n```\n\n\n:::\n:::\n\n\n\nWir brauchen `>= 1.35`.\n\nDaten importieren:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncsv_file_path_train = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv'\n\ngermeval_train = pd.read_csv(csv_file_path_train)\n```\n:::\n\n\n\nDie ersten paar Texte herausziehen:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nn_tweets = 2\ntweets_first_few = germeval_train[\"text\"].head(n_tweets).tolist()\ntweets_first_few\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.']\n```\n\n\n:::\n:::\n\n\n\nPrompt definieren:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompt_stem  = \"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes zu erkennen. Bitte antworten Sie nur mit einem Wort, entweder 'positiv', 'neutral' oder 'negativ'. Dieses Wort soll die Insgesamt-Einsch√§tzung des Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folt der Text, dessen Sentiment Sie einsch√§tzen sollen: \\n\"\n```\n:::\n\n\n\nMit \"List Comprehension\" k√∂nnen wir die Tweets jeweils mit dem Prompt verkn√ºpfen:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompts = [prompt_stem + tweet for tweet in tweets_first_few]\nprompts[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\"Als KI mit Exertise in nat√ºrlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes zu erkennen. Bitte antworten Sie nur mit einem Wort, entweder 'positiv', 'neutral' oder 'negativ'. Dieses Wort soll die Insgesamt-Einsch√§tzung des Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folt der Text, dessen Sentiment Sie einsch√§tzen sollen: \\n@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"\n```\n\n\n:::\n:::\n\n\nCheck: Wie viele Elemente hat die Liste `prompts`?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlen(prompts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2\n```\n\n\n:::\n:::\n\n\n\n\n\nCheck: Wie viele Tokens hat jeder String (jeder Prompt)?\n\nWir definieren eine Helper-Funktion:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef count_tokens(string: str, encoding_name: str) -> int:\n    encoding = tiktoken.get_encoding(encoding_name)\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n```\n:::\n\n\n\nUnd z√§hlen:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nencoding_name = \"cl100k_base\"\n\nnum_tokens_list = [count_tokens(prompt, encoding_name) for prompt in prompts]\n\nfor i, num_tokens in enumerate(num_tokens_list):\n    print(f\"The number of tokens in Prompt {[i]} is {num_tokens}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe number of tokens in Prompt [0] is 142.\nThe number of tokens in Prompt [1] is 153.\n```\n\n\n:::\n:::\n\n\n\nMehr Infos zum Encoding bei ChatGPT finden sich [hier](https://stackoverflow.com/questions/75804599/openai-api-how-do-i-count-tokens-before-i-send-an-api-request).\n\nLaut OpenAI kostet 1k Token f√ºr das Modell `gpt-3.5-turbo-1106` `$0.001`.\n\n\n\n\n\nAnmelden bei OpenAI:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nclient = OpenAI()\n```\n:::\n\n\n\n::: {.callout-note}\nDieses Anmeldeverfahren setzt voraus, dass in `.Renviron` die Variable `OPENAI_API_KEY` hinterlegt ist. $\\square$\n:::\n\n\n\n\n\n\nAnfrage an die API, in eine Funktion gepackt:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n    model=model,\n    messages=messages,\n    max_tokens=50,\n    temperature=0,\n  )\n  return response.choices[0].message.content\n```\n:::\n\n\n\nUnd jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresults = []\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nstart_time = time.time()\n\nfor prompt in prompts:\n  result = get_completion(prompt, client) \n  results.append(result)\n\nend_time = time.time()\nend_time - start_time\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1.5950350761413574\n```\n\n\n:::\n:::\n\n\nVoil√†:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['positiv', 'neutral']\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}