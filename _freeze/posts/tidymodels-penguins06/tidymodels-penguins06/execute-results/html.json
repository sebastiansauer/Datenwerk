{
  "hash": "5358b8ee7db218c019d006d308d822c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: tidymodels-penguins06\nextype: schoice\nexsolution: r fmt(sol)\nexshuffle: no\nexpoints: 1\ncategories:\n- tidymodels\n- statlearning\n- schoice\ndate: '2023-05-17'\nslug: tidymodels-penguins06\ntitle: tidymodels-penguins06\n\n---\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\n\nModellgleichung: `body_mass_g ~ bill_length_mm`.\n\n\n\nVergleichen Sie die Testfehlerhöhe im Test-Sample in folgenden zwei Szenarien:\n\n1. Train-Test-Aufspaltung, 10 Mal wiederholt\n2. 10-fache Kreuzvalidierung (im Train-Sample) ($v=10, r= 1$)\n\n\nHinweise:\n\n- Tuning Sie - nur im 2. Szenario - $k$ mit den Werten 5, 10, 15.\n- Löschen Sie alle Zeilen mit fehlenden Werten in den Prädiktoren.\n- Beachten Sie die [üblichen Hinweise](https://datenwerk.netlify.app/hinweise).\n- Natürlich gilt: Ceteris paribus. Halten Sie also die Modelle im Übrigen vergleichbar bzw. identisch.\n\nAnswerlist\n----------\n\n* Szenario 1 hat den geringeren Vorhersagefehler.\n* Szenario 2 hat den geringeren Vorhersagefehler.\n* Der Vorhersagefehler ist in beiden Szenarien gleich.\n* Keine Antwort möglich.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Setup\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-1_3a974392ffb77c3f38c3dc422c763d4e'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd <- read_csv(d_path)\n```\n:::\n\n\n\nWir dürfen keine fehlenden Werte in der Y-Variable haben (im Train-Set),\nsonst meckert Tidymodels:\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-2_84c645afced1632c6115f6914b280e3e'}\n\n```{.r .cell-code}\nd2 <- \n  d %>% \n  drop_na(body_mass_g)\n```\n:::\n\n\n# CV\n\n## Daten aufteilen:\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-3_ada6954f82046fdff80f4d6dfb3031fc'}\n\n```{.r .cell-code}\nset.seed(42)\nd_split <- initial_split(d2)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n## CV\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-4_651c5dcfe0df3a76599341657c829c3a'}\n\n```{.r .cell-code}\nset.seed(42)\nfolds <- vfold_cv(d_train, v = 10, repeats = 1)\n```\n:::\n\n\n\n\n\n## Workflow\n\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-5_53d6849665302ae069ef931c979a7c14'}\n\n```{.r .cell-code}\nrec1 <-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %>% \n  step_naomit(all_numeric_predictors())\n\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow <-\n  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(knn_model)\n```\n:::\n\n\n\n\n\n## Fitten\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-6_6511de62c45bd465a9c377f9099d5dfd'}\n\n```{.r .cell-code}\nd_resamples <-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )\n```\n:::\n\n\n\n\n\n## Modellgüte\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-7_43d171648fd8d36727200fec6e350261'}\n\n```{.r .cell-code}\nbestfit1 <- fit_best(x = d_resamples)\nlastfit1 <- last_fit(bestfit1, d_split)\ncollect_metrics(lastfit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     586.    Preprocessor1_Model1\n2 rsq     standard       0.410 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n# Train-Test-Aufteilung wiederholt\n\n\n\n\n## CV\n\nWir resamplen nicht über das Train-Sample, sondern über die ganze Stichprobe:\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-8_171807ad031a846ecff2c37e7f8c6788'}\n\n```{.r .cell-code}\nset.seed(42)\nfolds2 <- vfold_cv(d2, v = 2, repeats = 10)\n```\n:::\n\n\n\n## Fitten\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-9_22807420b7537cb3fdb40cecc8f79b1d'}\n\n```{.r .cell-code}\nd_resamples2 <-\n  tune_grid(\n    wflow,\n    resamples = folds2,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )\n```\n:::\n\n\n## Modellgüte\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-10_be1f32f3e5aae517b75b3e590e5e89c8'}\n\n```{.r .cell-code}\nbestfit2 <- fit_best(x = d_resamples2)\nlastfit2 <- last_fit(bestfit2, d_split)\ncollect_metrics(lastfit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     586.    Preprocessor1_Model1\n2 rsq     standard       0.410 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- statlearning\n- schoice\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}