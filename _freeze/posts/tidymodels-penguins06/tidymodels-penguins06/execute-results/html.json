{
  "hash": "5358b8ee7db218c019d006d308d822c0",
  "result": {
    "markdown": "---\nexname: tidymodels-penguins06\nextype: schoice\nexsolution: r fmt(sol)\nexshuffle: no\nexpoints: 1\ncategories:\n- tidymodels\n- statlearning\n- schoice\ndate: '2023-05-17'\nslug: tidymodels-penguins06\ntitle: tidymodels-penguins06\n\n---\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\n\nModellgleichung: `body_mass_g ~ bill_length_mm`.\n\n\n\nVergleichen Sie die Testfehlerhöhe im Test-Sample in folgenden zwei Szenarien:\n\n1. Train-Test-Aufspaltung, 10 Mal wiederholt\n2. 10-fache Kreuzvalidierung (im Train-Sample) ($v=10, r= 1$)\n\n\nHinweise:\n\n- Tuning Sie - nur im 2. Szenario - $k$ mit den Werten 5, 10, 15.\n- Löschen Sie alle Zeilen mit fehlenden Werten in den Prädiktoren.\n- Beachten Sie die [üblichen Hinweise](https://datenwerk.netlify.app/hinweise).\n- Natürlich gilt: Ceteris paribus. Halten Sie also die Modelle im Übrigen vergleichbar bzw. identisch.\n\nAnswerlist\n----------\n\n* Szenario 1 hat den geringeren Vorhersagefehler.\n* Szenario 2 hat den geringeren Vorhersagefehler.\n* Der Vorhersagefehler ist in beiden Szenarien gleich.\n* Keine Antwort möglich.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Setup\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-1_a018d3b8dfa84d23a2a97df14b0ed519'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd <- read_csv(d_path)\n```\n:::\n\n\n\nWir dürfen keine fehlenden Werte in der Y-Variable haben (im Train-Set),\nsonst meckert Tidymodels:\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-2_0c0de69e03d12efcdfc995a6bd9e0edb'}\n\n```{.r .cell-code}\nd2 <- \n  d %>% \n  drop_na(body_mass_g)\n```\n:::\n\n\n# CV\n\n## Daten aufteilen:\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-3_d123f308c49882335e73a59411de0e62'}\n\n```{.r .cell-code}\nset.seed(42)\nd_split <- initial_split(d2)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n## CV\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-4_b590fc9fedfb4cc81949cb6abf8912c6'}\n\n```{.r .cell-code}\nset.seed(42)\nfolds <- vfold_cv(d_train, v = 10, repeats = 1)\n```\n:::\n\n\n\n\n\n## Workflow\n\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-5_10b89f10c44fe15dc323c5aecffc509b'}\n\n```{.r .cell-code}\nrec1 <-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %>% \n  step_naomit(all_numeric_predictors())\n\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow <-\n  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(knn_model)\n```\n:::\n\n\n\n\n\n## Fitten\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-6_5d3973b7ba0d14004bd8cb88400042b4'}\n\n```{.r .cell-code}\nd_resamples <-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )\n```\n:::\n\n\n\n\n\n## Modellgüte\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-7_9e4f6a0a8f1628fb40dde74639779a49'}\n\n```{.r .cell-code}\nbestfit1 <- fit_best(x = d_resamples)\nlastfit1 <- last_fit(bestfit1, d_split)\ncollect_metrics(lastfit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     586.    Preprocessor1_Model1\n2 rsq     standard       0.410 Preprocessor1_Model1\n```\n:::\n:::\n\n\n# Train-Test-Aufteilung wiederholt\n\n\n\n\n## CV\n\nWir resamplen nicht über das Train-Sample, sondern über die ganze Stichprobe:\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-8_f5401c79f7a7d904e2615db21bd48b0c'}\n\n```{.r .cell-code}\nset.seed(42)\nfolds2 <- vfold_cv(d2, v = 2, repeats = 10)\n```\n:::\n\n\n\n## Fitten\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-9_f2ab0df716e6c0e778f857214829eee8'}\n\n```{.r .cell-code}\nd_resamples2 <-\n  tune_grid(\n    wflow,\n    resamples = folds2,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )\n```\n:::\n\n\n## Modellgüte\n\n\n\n::: {.cell hash='tidymodels-penguins06_cache/html/unnamed-chunk-10_77a39cb2c26b337e9dff84eb30fd02f5'}\n\n```{.r .cell-code}\nbestfit2 <- fit_best(x = d_resamples2)\nlastfit2 <- last_fit(bestfit2, d_split)\ncollect_metrics(lastfit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     586.    Preprocessor1_Model1\n2 rsq     standard       0.410 Preprocessor1_Model1\n```\n:::\n:::\n\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- statlearning\n- schoice\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}