{
  "hash": "7d887cf28a1356ba04473bd9cb06df34",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval02-sentiment\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- tidymodels\n- germeval\n- sentiment\n- string\ndate: '2023-11-16'\nslug: germeval02\ntitle: germeval02\nexecute:\n  cache: true\n  eval: false\n---\n\n\n\n\n\n\n\n# Aufgabe\n\nFühren Sie eine Sentiment-Analyse durch. Verwenden Sie verschiedene Verfahren.\n\nNutzen Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n\n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(tictoc)  # Zeitmessung\nlibrary(syuzhet)  # Sentimentanalyse\n```\n:::\n\n\n\n\n\n# Daten\n\nNutzen Sie diesen Text-Datensatz, bevor Sie den größeren `germeval`-Datensatz verwenden:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntext <- c(\"Abbau, Abbruch ist jetzt\", \"Test heute\", \"Abbruch morgen perfekt\", \"Abmachung lore ipsum\", \"boese ja\", \"böse nein\", \"hallo ?! hallo.\", \"gut schlecht\")\n\nn_emo <- c(2, 0, 2, 1, 1, 1, 0, 2)\n\ntest_text <-\n  tibble(id = 1:length(text),\n             text = text,\n             n_emo = n_emo)\n\ntest_text\n```\n:::\n\n\n\n\nWörterbücher laden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(sentiws, package = \"pradadata\")\n#data(schimpfwoerter, package = \"pradadata\")\n\nsentiws$word <- tolower(sentiws$word)  # wichtig!\n```\n:::\n\n\n\nGermEval-Datensatz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(germeval_train, package = \"pradadata\")\ngermeval_train <- as_tibble(germeval_train)  # schöneres Print am Bildschirm\n```\n:::\n\n\n\n\n# Sentimentanalyse im Test-Datensatz\n\n\n\n\n## Sentimentanalyse mit Regex\n\nDie Funktion `count_lexicon` stammt aus `{prada}`.\n\nTipp: Mit `?count_lexicon` sehen Sie den Quelltext (jeder Funktion).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_text  |> \n  mutate(n_emowords = map_int(text, prada::count_lexicon, sentiws$word))\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\ngermeval_train |> \n  mutate(n_emowords = map_int(text, ~ prada::count_lexicon(.x, sentiws$word))) |> \n  head()\ntoc()\n```\n:::\n\n\n\nPuh! *Viel* zu langsam. \n\n\n## Sentimentanalyse mit `unnest_tokens`\n\nProbieren wir es mit `unnest_tokens`:\n\n\nJaa,... aber die Strings *ohne Treffer* werden ignoriert.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_text |> \n  unnest_tokens(word, text) |> \n  right_join(sentiws |> select(word)) |> \n  count(id)\n```\n:::\n\n\n\nProbieren wir es so:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Count words in a lexicon\n#' \n#' Counts how many of the words of the character vector `text` are\n#' found in a lexicon `lex` \n#' `text` is transformed via tolower.\n#'\n#' @param text corpus, character vector\n#'\n#' @return number of hits per element of the corpus\n#' @export\n#'\n#' @examples\n#' count_lex(my_text, my_lex)\ncount_lex <- function(text) {\n  \n  stopifnot(class(text) == \"character\")\n  \n  doc <- tibble(text = tolower(text),\n                id = 1:length(text))\n  \n  doc1 <- \n    doc |> \n    tidytext::unnest_tokens(word, text) |> \n    dplyr::inner_join(sentiws |> dplyr::select(word), by = \"word\") |> \n    count(id)\n  \n  doc2 <-\n    doc1 |> \n    dplyr::full_join(doc |> select(id), by = \"id\")\n  \n  doc2$n <- ifelse(is.na(doc2$n), 0,doc2$n)\n  \n  doc2 <- doc2 |> dplyr::arrange(id)\n  \n  doc2 |> pull(n)\n}\n```\n:::\n\n\n\nMit dem Paket [`box`](https://klmr.me/box/) kann man Funktionen, die nicht in Paketen stehen, importieren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount_lex(test_text$text)\n```\n:::\n\n\n\nAls neue Spalte im Datensatz:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_text |> \n  mutate(n_emowords = count_lex(text))\n```\n:::\n\n\n\n\n## Sentimentanalyse mit `{syuzhet}`\n\n\n### Mit dem Lexicon `nrc`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_nrc_sentiment(test_text$text, language = \"german\")\n```\n:::\n\n\nTja, nicht so viele Treffer ...\n\nIn der Zusammenfassung:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_nrc_values(text, language = \"german\")\n```\n:::\n\n\nTja, leider keine Treffer. Merkwürdig.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_sentiment(text,\n              method = \"nrc\",\n              language = \"german\")\n```\n:::\n\n\nNaja, ok.\n\n### Mit einem eigenen Lexikon\n\n\n[Beispiel vom Autor des Pakets](https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_text <- \"I love when I see something beautiful.  I hate it when ugly feelings creep into my head.\"\nchar_v <- get_sentences(my_text)\nmethod <- \"custom\"\ncustom_lexicon <- data.frame(word=c(\"love\", \"hate\", \"beautiful\", \"ugly\"), value=c(1,-1,1, -1))\nmy_custom_values <- get_sentiment(char_v, method = method, lexicon = custom_lexicon)\nmy_custom_values\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_sentiment(text,\n              method = \"custom\",\n              lexicon = sentiws)\n```\n:::\n\n\n\n\n# Sentimentanalyse im GermEval-Datensatz\n\n## Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nsentiments <-\n  get_sentiment(germeval_train$text,\n              method = \"custom\",\n              lexicon = sentiws)\ntoc()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlength(sentiments)\nhead(sentiments)\n```\n:::\n\n\n\nDie Geschwindigkeit scheint deutlich besser zu sein, als bei den Regex-Ansätzen.\n\n\n## Als Spalte in die Tabelle\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nd <-\n  germeval_train |> \n  mutate(n_emo = get_sentiment(germeval_train$text,\n              method = \"custom\",\n              lexicon = sentiws))\ntoc()\n\nhead(d)\n```\n:::\n\n\n\n\n\n\n# Fazit\n\n[syuzhet](https://github.com/mjockers/syuzhet) bietet den besten Ansatz unterm Strich (von den hier vorgestellten Methoden) für eine Sentimentanalyse in deutscher Sprache.\n\nInsgesamt ist die Sentimentanalyse relativ rechenintensiv.\n\n\n\n---\n\nCategories: \n\n- textmining\n- tidymodels\n- germeval\n- sentiment\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}