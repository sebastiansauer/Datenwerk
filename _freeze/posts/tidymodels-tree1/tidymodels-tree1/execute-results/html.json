{
  "hash": "a940096cfe2014f00f1acb76dd8a43bd",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: tidymodels-tree1\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- statlearning\n- trees\n- tidymodels\n- string\n- mtcars\ndate: '2023-11-08'\nslug: tidymodels-tree1\ntitle: tidymodels-tree1\nexecute:\n  output: false\n  eval: false\n---\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n:::\n\n\n\n\n# Aufgabe\n\n\nBerechnen Sie folgende prädiktiven Modelle und vergleichen Sie die Modellgüte:\n\n1. Entscheidungsbaum\n2. Bagging (Bootstrap-Bäume)\n\n\nModellformel: `am ~ .` (Datensatz `mtcars`)\n\nBerichten Sie die Modellgüte (ROC-AUC).\n\nHinweise:\n\n- Tunen Sie alle Parameter (die der Engine anbietet). \n- Verwenden Sie Defaults, wo nicht anders angegeben.\n- Führen Sie eine $v=2$-fache Kreuzvalidierung durch (weil die Stichprobe so klein ist).\n- Beachten Sie die [üblichen Hinweise](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\nlibrary(baguette)\n```\n:::\n\n\n\nFür Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars <-\n  mtcars %>% \n  mutate(am = factor(am))\n```\n:::\n\n\n\n\n## Daten teilen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(mtcars)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n## Modell(e)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_tree <-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())\n\nmod_bag <-\n  bag_tree(mode = \"classification\",\n           cost_complexity = tune(),\n           tree_depth = tune(),\n           min_n = tune())\n```\n:::\n\n\n\n\n\n## Rezept(e)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_plain <- \n  recipe(am ~ ., data = d_train)\n```\n:::\n\n\n\n\n## Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsmpl <- vfold_cv(d_train, v = 2)\n```\n:::\n\n\n\n## Workflows\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_tree <-\n  workflow() %>%  \n  add_recipe(rec_plain) %>% \n  add_model(mod_tree)\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_bag <-\n  workflow() %>%  \n  add_recipe(rec_plain) %>% \n  add_model(mod_bag)\n```\n:::\n\n\n\n\n\n\n## Tuning/Fitting\n\nTuninggrid:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_grid <- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\ntune_grid\n```\n:::\n\n\nDa beide Modelle die gleichen Tuningparameter aufweisen,\nbrauchen wir nur ein Grid zu erstellen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit_tree <-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\nfit_tree\n```\n:::\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit_bag <-\n  tune_grid(object = wf_bag,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n```\n:::\n\n\n## Bester Kandidat\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(fit_tree)\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(fit_bag)\n```\n:::\n\n\n\nBagging erzielte eine klar bessere Modellgüte (in den Validierungssamples) als das Entscheidungsbaum-Modell.\n\n\n## Finalisieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_best_finalized <-\n  wf_bag %>% \n  finalize_workflow(select_best(fit_bag))\n```\n:::\n\n\n\n## Last Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- \n  last_fit(object = wf_best_finalized, d_split)\n\ncollect_metrics(final_fit)\n```\n:::\n\n\nWie man sieht, ist die Modellgüte im Test-Sample schlechter als in den Train- bzw. Validierungssamples; ein typischer Befund.\n\n\n\n\n\n---\n\nCategories: \n\n- statlearning\n- trees\n- tidymodels\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}