{
  "hash": "2f08039871f62c4bbcd53752ff49a2b1",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval04sent-textfeatures-nn\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- 2023\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- string\ndate: '2023-11-15'\nslug: germeval04\ntitle: germeval04\n\n---\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\n\nNutzen Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n- Nutzen Sie das `sentiws` Lexikon.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(textrecipes)\ndata(\"sentiws\", package = \"pradadata\")\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model:\nmod1 <-\n  nearest_neighbor(mode = \"classification\",\n                   neighbors = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl <- vfold_cv(d_train, v = 5)\n\n\n# recipe:\nrec1 <-\n  recipe(c1 ~ ., data = d_train) |> \n  update_role(id, new_role = \"id\")  |> \n  #update_role(c2, new_role = \"ignore\") |> \n  update_role(text, new_role = \"ignore\") |> \n  step_mutate(n_emo = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = sentiws))  |>\n  step_textfeature(text)  |> \n  step_zv(all_predictors())   |>  # der vorherige Step erzeugt Features ohne Varianz\n  step_normalize(all_numeric_predictors()) \n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod1) %>% \n  add_recipe(rec1)\n```\n:::\n\n\n\nTuning:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nwf1_fit <-\n  wf1 %>% \n  tune_grid(\n    resamples = rsmpl,\n    grid = 2,  # Zeit sparen\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n76.704 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nbeep()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits              id    .metrics         .notes          \n  <list>              <chr> <list>           <list>          \n1 <split [4007/1002]> Fold1 <tibble [6 × 5]> <tibble [0 × 3]>\n2 <split [4007/1002]> Fold2 <tibble [6 × 5]> <tibble [0 × 3]>\n3 <split [4007/1002]> Fold3 <tibble [6 × 5]> <tibble [0 × 3]>\n4 <split [4007/1002]> Fold4 <tibble [6 × 5]> <tibble [0 × 3]>\n5 <split [4008/1001]> Fold5 <tibble [6 × 5]> <tibble [0 × 3]>\n```\n\n\n:::\n:::\n\n\n## Finalisieren\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1_best <- select_best(wf1_fit)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_final <- finalize_workflow(wf1, fit1_best)\nwf1_final_fit <- fit(wf1_final, data = d_train)\n```\n:::\n\n\n\nVorhersagen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- predict(wf1_final_fit, germeval_test)\n```\n:::\n\n\n\n## Test-Set-Güte\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.639\n2 f_meas   binary         0.286\n```\n\n\n:::\n:::\n\n\n\n## Fazit\n\nEine Reihe der Text-Features passen nicht gut auf nicht-englische Texte.\n\n\n\n\n---\n\nCategories: \n\n- 2023\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- string\n\n",
    "supporting": [
      "germeval04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}