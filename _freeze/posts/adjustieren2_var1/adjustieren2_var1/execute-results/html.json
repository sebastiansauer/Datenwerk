{
  "hash": "440ea83cb7ed389714aa0e78660203f6",
  "result": {
    "engine": "knitr",
    "markdown": "---\nextype: string\nexsolution: r regression_formel\nexname: adjustieren2_var1\nexpoints: 1\ncategories:\n- lm\n- regression\n- bayes\n- adjust\n- string\ndate: '2023-11-08'\nslug: adjustieren2_var1\ntitle: adjustieren2_var1\n\n---\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\n\nBetrachten Sie folgendes Modell, das den Zusammenhang des Preises (`price`) \nund dem Gewicht (`carat`) von Diamanten untersucht (Datensatz `diamonds`).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\ndiamonds <- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n```\n:::\n\n\n\n\n\nAber zuerst zentrieren wir den metrischen Prädiktor `carat`, \num den Achsenabschnitt besser interpretieren zu können. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds2 <-\n  diamonds %>% \n  mutate(carat_z = carat - mean(carat, na.rm = TRUE))\n```\n:::\n\n\n\nDann berechnen wir ein (bayesianisches) Regressionsmodell, \nwobei wir auf die Standardwerte der Prior zurückgreifen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstanarm)\nlm1 <- stan_glm(price ~ carat_z, data = diamonds2,\n                refresh = 0)\nparameters(lm1)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   |   Median|   CI|   CI_low|  CI_high| pd|      Rhat|      ESS|Prior_Distribution | Prior_Location| Prior_Scale|\n|:-----------|--------:|----:|--------:|--------:|--:|---------:|--------:|:------------------|--------------:|-----------:|\n|(Intercept) | 3933.103| 0.95| 3919.932| 3945.329|  1| 1.0007236| 1337.926|normal             |         3932.8|    9973.599|\n|carat_z     | 7756.757| 0.95| 7728.920| 7784.542|  1| 0.9999506| 4482.262|normal             |            0.0|   21040.850|\n\n</div>\n:::\n:::\n\n\n\n\n\nZur Verdeutlichung ein Diagramm zum Modell:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds2 %>% \n  ggplot() +\n  aes(x = carat_z, y = price) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-4-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\n\nOder so:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_relation(lm1) |> plot()\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-5-1.png){fig-pos='H' width=384}\n:::\n:::\n\n\n\n\n\n*Aufgabe*:\n\nGeben Sie eine Regressionsformel an, die `lm1` ergänzt, so dass die Schliffart (`cut`) des Diamanten kontrolliert (adjustiert) wird. \nAnders gesagt: Das Modell soll die mittleren Preise für jede der fünf Schliffarten angeben. \n\n\n\n\n\n\n\n\n*Hinweis*: \n\n- Geben Sie nur die Regressionsformel an. \n- Lassen Sie zwischen Termen der Regressionsformel jeweils ein Leerzeichen Abstand.\n- Beziehen Sie sich auf das Modell bzw. die Angaben oben.\n- Es gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>% \n  distinct(cut)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|cut       |\n|:---------|\n|Ideal     |\n|Premium   |\n|Good      |\n|Very Good |\n|Fair      |\n\n</div>\n:::\n:::\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\nDie richtige Antwort lautet: `price ~ carat_z + cut` \n\nDas Modell könnten wir so berechnen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm2 <- stan_glm(price ~ carat_z + cut, data = diamonds2,\n                refresh = 0)  # verhindert einen Haufen unnötigen Output\nparameters(lm2)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter    |   Median|   CI|   CI_low|  CI_high| pd|     Rhat|      ESS|Prior_Distribution | Prior_Location| Prior_Scale|\n|:------------|--------:|----:|--------:|--------:|--:|--------:|--------:|:------------------|--------------:|-----------:|\n|(Intercept)  | 2403.533| 0.95| 2328.352| 2474.815|  1| 1.001242| 1766.022|normal             |         3932.8|    9973.599|\n|carat_z      | 7870.523| 0.95| 7843.157| 7897.570|  1| 1.000339| 4271.289|normal             |            0.0|   21040.850|\n|cutGood      | 1122.273| 0.95| 1040.951| 1206.763|  1| 1.000233| 2115.490|normal             |            0.0|   34685.376|\n|cutIdeal     | 1802.437| 0.95| 1727.233| 1878.867|  1| 1.000457| 1845.860|normal             |            0.0|   20362.277|\n|cutPremium   | 1440.937| 0.95| 1362.846| 1519.823|  1| 1.000445| 1875.457|normal             |            0.0|   22862.493|\n|cutVery Good | 1511.725| 0.95| 1433.968| 1589.377|  1| 1.000600| 1886.521|normal             |            0.0|   23922.148|\n\n</div>\n:::\n:::\n\n\n\n\nOder auch so, mit der klassischen Regression:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(price ~ carat_z + cut, data = diamonds2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = price ~ carat_z + cut, data = diamonds2)\n\nCoefficients:\n (Intercept)       carat_z       cutGood      cutIdeal    cutPremium  \n        2405          7871          1120          1801          1439  \ncutVery Good  \n        1510  \n```\n\n\n:::\n:::\n\n\n\n\nDas führt zu ähnlichen Ergebnissen.\n\n\nMan könnte hier noch einen Interaktionseffekt ergänzen.\n\n\n\n---\n\nCategories: \n\n- lm\n- regression\n- bayes\n- adjust\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}