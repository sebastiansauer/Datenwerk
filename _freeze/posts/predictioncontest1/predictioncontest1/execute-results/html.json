{
  "hash": "fab168e8af136045eed16c57ccc445e4",
  "result": {
    "engine": "knitr",
    "markdown": "---\nextype: string\nexsolution: NA\nexname: predictioncontest1\nexpoints: 1\ntags:\n- prediction\n- tidymodels\ncategories:\n- R\n- ds1\n- string\ndate: '2023-05-17'\nslug: predictioncontest1\ntitle: predictioncontest1\n\n---\n\n\n\nQuestion\n\n# Aufgabe\n\n\nErstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\n\nNutzen Sie den Datensatz `penguins`!\n\nSagen Sie die Variable `body_mass_g` vorher.\n\nHinweise:\n\n- Halten Sie die Analyse einfach.\n- Teilen Sie Test- vs. Train-Set hälftig auf.\n- Teilen Sie Analysis vs. Assessment-Set 3:1 auf.\n- Den Datensatz `penguins` können Sie entweder aus dem Paket `palmerpenguins` beziehen oder z.B. von [hier](https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv) via `read_csv()` importieren.\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\nPakete laden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.0     ✔ tidyr        1.3.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.3.0     ✔ workflows    1.1.3\n✔ parsnip      1.2.0     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.3.0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(easystats)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n# Attaching packages: easystats 0.7.0 (red = needs update)\n✔ bayestestR  0.13.2   ✔ correlation 0.8.4 \n✖ datawizard  0.9.1    ✖ effectsize  0.8.6 \n✖ insight     0.19.8   ✔ modelbased  0.8.7 \n✖ performance 0.10.9   ✖ parameters  0.21.5\n✔ report      0.5.8    ✖ see         0.8.2 \n\nRestart the R-Session and update packages with `easystats::easystats_update()`.\n```\n\n\n:::\n\n```{.r .cell-code}\ndata(\"penguins\", package = \"palmerpenguins\")\n```\n:::\n\n\n\n\nMan erinnere sich, dass ein R-Paket erst (einmalig) installiert sein muss,\nbevor Sie darauf zugreifen können, etwa um Daten - wie den Datensatz `penguins` - \ndaraus zu beziehen.\n\n\n\nZeilen mischen und Train- vs. Testset aufteilen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins2 <-\n  penguins %>% \n  sample_n(size = nrow(.))\n\nd_train <- penguins2 %>% slice(1:(344/2))\nd_test <- penguins2 %>% slice(173:nrow(penguins))\n```\n:::\n\n\n\n\nDas Trainset weiter aufteilen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(d_train)\n\nd_analysis <- training(d_split)\nd_assessment <- testing(d_split)\n```\n:::\n\n\n\nRezept definieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <-\n  recipe(body_mass_g ~ ., data = d_analysis) %>% \n  step_impute_knn(all_predictors()) %>% \n  step_normalize(all_numeric(), -all_outcomes())\n```\n:::\n\n\n\nRezept prüfen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_analysis_baked <- \nrec1 %>% \n  prep() %>% \n  bake(new_data = NULL)\n\ndescribe_distribution(d_analysis_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariable          |      Mean |     SD |     IQR |              Range | Skewness | Kurtosis |   n | n_Missing\n-------------------------------------------------------------------------------------------------------------\nbill_length_mm    | -5.75e-16 |   1.00 |    1.63 |      [-2.06, 2.72] |     0.10 |    -0.76 | 129 |         0\nbill_depth_mm     | -1.12e-16 |   1.00 |    1.52 |      [-2.12, 2.30] |    -0.24 |    -0.70 | 129 |         0\nflipper_length_mm |  1.06e-16 |   1.00 |    1.76 |      [-1.62, 2.12] |     0.42 |    -1.15 | 129 |         0\nyear              |  2.18e-15 |   1.00 |    2.51 |      [-1.27, 1.25] |    -0.01 |    -1.42 | 129 |         0\nbody_mass_g       |   4187.30 | 812.31 | 1200.00 | [2700.00, 6050.00] |     0.55 |    -0.56 | 128 |         1\n```\n\n\n:::\n:::\n\n\n\n\nWorkflow und CV definieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- \n  linear_reg()\n\nwf1 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(m1)\n\ncv_scheme <- vfold_cv(d_analysis, v = 2)\n```\n:::\n\n\n\n\nFitten (hier kein Tuning):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <-\n  wf1 %>% \n  tune_grid(resamples = cv_scheme)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n```\n\n\n:::\n:::\n\n\n\nFinalisieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(fit1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard    316.     2    6.86 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code}\nwf1_final <-\n  wf1 %>% \n  finalize_workflow(show_best(fit1))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n\n\n:::\n\n```{.r .cell-code}\nwf1_final\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_knn()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n\n\n:::\n:::\n\n\n\nModellgüte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1_final <-\n  wf1_final %>% \n  last_fit(d_split)\n\n\ncollect_metrics(fit1_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     271.    Preprocessor1_Model1\n2 rsq     standard       0.896 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code}\nfit1_train <-\n  wf1_final %>% \n  fit(d_train)\n\n\nfit1_test <-\n  fit1_train %>% \n  predict(d_test)\n\nhead(fit1_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred\n  <dbl>\n1 4366.\n2 5444.\n3 4154.\n4 3277.\n5 4164.\n6 4905.\n```\n\n\n:::\n:::\n\n\n\n\n\nVgl <https://workflows.tidymodels.org/reference/predict-workflow.html>\n\n\nSubmitten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubm_df <-\n  d_test %>% \n  mutate(id = 173:344) %>% \n  bind_cols(fit1_test) %>% \n  select(id, .pred) %>% \n  rename(pred = .pred)\n```\n:::\n\n\n\n\nUnd als CSV-Datei speichern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_csv(subm_df, file = \"submission_blabla.csv\")\n```\n:::\n\n\n\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- R\n- ds1\n- sose22\n- string\n\n",
    "supporting": [
      "predictioncontest1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}