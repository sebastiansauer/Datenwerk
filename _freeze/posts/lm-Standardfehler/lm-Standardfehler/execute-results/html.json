{
  "hash": "2b6cae63fd9e82e36bc48c0e8bc8baad",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: lm-Standardfehler\nextype: schoice\nexsolution: 1\nexshuffle: no\ncategories:\n- inference\n- lm\n- qm2\ndate: '2022-09-04'\nslug: lm-Standardfehler\ntitle: lm-Standardfehler\n\n---\n\n\n\n\n\n\n\n\n\n# Exercise\n\nMan kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt.\nZumeist wird dazu der *Standardfehler* (engl. standard error, SE) verwendet.\n\nIn dieser Übung untersuchen wir,\nwie sich der SE als Funktion der Stichprobengröße, $n$, verhält.\n\n\nErstellen Sie dazu folgenden Datensatz:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nn <- 2^4\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n```\n:::\n\n\n\n\nHier ist das Ergebnis. Uns interessiert v.a. `Std. Error` für den Prädiktor `x`: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y ~ x, data = d) %>% \nsummary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.07923 -0.30544 -0.03081  0.36343  0.84712 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.2339     0.1398  -1.673    0.117    \nx             0.8345     0.1360   6.134 2.59e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5403 on 14 degrees of freedom\nMultiple R-squared:  0.7288,\tAdjusted R-squared:  0.7095 \nF-statistic: 37.63 on 1 and 14 DF,  p-value: 2.588e-05\n```\n\n\n:::\n:::\n\n\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\n\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie,\nwie sich die Schätzgenauigkeit, gemessen über den SE, verändert.\nBerechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\n\nBei welcher Stichprobengröße ist SE am kleinsten?\n\nAnswerlist\n----------\n* $2^5$\n* $2^6$\n* $2^7$\n* $2^8$\n* $2^9$\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\nProbieren wir es aus!\n\nErste Verdopplung, $n=2^5$:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^5\n\nd5 <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nlm5 <- lm(y ~ x, data = d5)\n\nlm5 %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = d5)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8316 -0.1946 -0.0425  0.3256  0.6255 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.01046    0.06642  -0.157    0.876    \nx            1.04145    0.05963  17.464   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3757 on 30 degrees of freedom\nMultiple R-squared:  0.9104,\tAdjusted R-squared:  0.9075 \nF-statistic:   305 on 1 and 30 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\nMan kann sich den Standardfehler komfortabler ausgeben lassen,\nwenn man das Paket `easystats` verwendet:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easystats)\nlm5 %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|          t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|----------:|--------:|---------:|\n|(Intercept) |  -0.0104562| 0.0664176| 0.95| -0.1460991| 0.1251866| -0.1574316|       30| 0.8759596|\n|x           |   1.0414489| 0.0596325| 0.95|  0.9196630| 1.1632348| 17.4644417|       30| 0.0000000|\n\n</div>\n:::\n:::\n\n\n\nJetzt mit den anderen Stichprobengrößen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^6\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|          t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|----------:|--------:|---------:|\n|(Intercept) |  -0.0213003| 0.0594411| 0.95| -0.1401213| 0.0975207| -0.3583437|       62| 0.7213034|\n|x           |   1.0476647| 0.0563846| 0.95|  0.9349535| 1.1603759| 18.5806847|       62| 0.0000000|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^7\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|         t| df_error|        p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|---------:|--------:|--------:|\n|(Intercept) |   0.0066524| 0.0429842| 0.95| -0.0784121| 0.0917169|  0.154764|      126| 0.877255|\n|x           |   0.9692920| 0.0449156| 0.95|  0.8804053| 1.0581787| 21.580293|      126| 0.000000|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^8\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|    CI_high|        t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|----------:|--------:|--------:|---------:|\n|(Intercept) |  -0.0692029| 0.0308774| 0.95| -0.1300112| -0.0083947| -2.24122|      254| 0.0258761|\n|x           |   1.0541751| 0.0308630| 0.95|  0.9933951|  1.1149551| 34.15660|      254| 0.0000000|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^9\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|          t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|----------:|--------:|---------:|\n|(Intercept) |  -0.0112189| 0.0217875| 0.95| -0.0540232| 0.0315854| -0.5149226|      510| 0.6068302|\n|x           |   1.0121220| 0.0215441| 0.95|  0.9697959| 1.0544482| 46.9790437|      510| 0.0000000|\n\n</div>\n:::\n:::\n\n\n\nAnswerlist\n----------\n\n\n* Falsch\n* Falsch\n* Falsch\n* Falsch\n* Wahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\n\n\n\n---\n\nCategories: \n\n- inference\n- lm\n- qm2\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}