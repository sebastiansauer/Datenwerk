{
  "hash": "5d31d758b7c46ed7cd8ba39fcb370008",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: lm-Standardfehler\nextype: schoice\nexsolution: 1\nexshuffle: no\ncategories:\n- inference\n- lm\n- qm2\ndate: '2022-09-04'\ntitle: lm-standardfehler\n\n---\n\n\n\n\n\n\n\n\n\n\n# Exercise\n\nMan kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt.\nZumeist wird dazu der *Standardfehler* (engl. standard error, SE) verwendet.\n\nIn dieser Übung untersuchen wir,\nwie sich der SE als Funktion der Stichprobengröße, $n$, verhält.\n\n\nErstellen Sie dazu folgenden Datensatz:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nn <- 2^4\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n```\n:::\n\n\n\n\n\nHier ist das Ergebnis. Uns interessiert v.a. `Std. Error` für den Prädiktor `x`: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y ~ x, data = d) %>% \nsummary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8758 -0.3004 -0.1946  0.2529  1.3000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.1422     0.1561  -0.911    0.378    \nx             0.9546     0.1317   7.251 4.22e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5976 on 14 degrees of freedom\nMultiple R-squared:  0.7897,\tAdjusted R-squared:  0.7747 \nF-statistic: 52.58 on 1 and 14 DF,  p-value: 4.216e-06\n```\n\n\n:::\n:::\n\n\n\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\n\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie,\nwie sich die Schätzgenauigkeit, gemessen über den SE, verändert.\nBerechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\n\nBei welcher Stichprobengröße ist SE am kleinsten?\n\nAnswerlist\n----------\n* $2^5$\n* $2^6$\n* $2^7$\n* $2^8$\n* $2^9$\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\nProbieren wir es aus!\n\nErste Verdopplung, $n=2^5$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^5\n\nd5 <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nlm5 <- lm(y ~ x, data = d5)\n\nlm5 %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = d5)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.68722 -0.43286 -0.07974  0.38128  1.62001 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.07923    0.09254  -0.856    0.399    \nx            1.11837    0.11377   9.830 6.81e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5181 on 30 degrees of freedom\nMultiple R-squared:  0.7631,\tAdjusted R-squared:  0.7552 \nF-statistic: 96.63 on 1 and 30 DF,  p-value: 6.812e-11\n```\n\n\n:::\n:::\n\n\n\n\n\n\nMan kann sich den Standardfehler komfortabler ausgeben lassen,\nwenn man das Paket `easystats` verwendet:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easystats)\nlm5 %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|          t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|----------:|--------:|---------:|\n|(Intercept) |  -0.0792257| 0.0925390| 0.95| -0.2682155| 0.1097641| -0.8561335|       30| 0.3987108|\n|x           |   1.1183739| 0.1137728| 0.95|  0.8860189| 1.3507289|  9.8298902|       30| 0.0000000|\n\n</div>\n:::\n:::\n\n\n\n\nJetzt mit den anderen Stichprobengrößen:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^6\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|       SE|   CI|     CI_low|   CI_high|         t| df_error|         p|\n|:-----------|-----------:|--------:|----:|----------:|---------:|---------:|--------:|---------:|\n|(Intercept) |   0.0179108| 0.075495| 0.95| -0.1330015| 0.1688232|  0.237245|       62| 0.8132489|\n|x           |   1.0192013| 0.070361| 0.95|  0.8785517| 1.1598509| 14.485316|       62| 0.0000000|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^7\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|          t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|----------:|--------:|---------:|\n|(Intercept) |  -0.0283003| 0.0418013| 0.95| -0.1110239| 0.0544232| -0.6770198|      126| 0.4996344|\n|x           |   1.0038115| 0.0423511| 0.95|  0.9200000| 1.0876230| 23.7021619|      126| 0.0000000|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^8\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|     CI_low|   CI_high|         t| df_error|         p|\n|:-----------|-----------:|---------:|----:|----------:|---------:|---------:|--------:|---------:|\n|(Intercept) |   0.0431977| 0.0290556| 0.95| -0.0140228| 0.1004182|  1.486728|      254| 0.1383268|\n|x           |   1.0565355| 0.0278379| 0.95|  1.0017129| 1.1113581| 37.953072|      254| 0.0000000|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 2^9\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nmein_lm <- lm(y ~ x, data = d)\n\nmein_lm %>% \n  parameters()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Parameter   | Coefficient|        SE|   CI|    CI_low|   CI_high|        t| df_error|         p|\n|:-----------|-----------:|---------:|----:|---------:|---------:|--------:|--------:|---------:|\n|(Intercept) |   0.0508174| 0.0212192| 0.95| 0.0091296| 0.0925052|  2.39488|      510| 0.0169857|\n|x           |   0.9834259| 0.0210561| 0.95| 0.9420586| 1.0247932| 46.70508|      510| 0.0000000|\n\n</div>\n:::\n:::\n\n\n\n\nAnswerlist\n----------\n\n\n* Falsch\n* Falsch\n* Falsch\n* Falsch\n* Wahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\n\n\n\n---\n\nCategories: \n\n- inference\n- lm\n- qm2\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}