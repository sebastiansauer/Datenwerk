{
  "hash": "a878b1e7b01f1732b21d16ecb65a4d76",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- sentiment\n- string\n- xgb\n- tune\ndate: '2023-12-03'\ntitle: germeval03-sent-wordvec-xgb-plain\ndraft: false   # DRAFT TRUE\neval: true\n---\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie außerdem *deutsche Word-Vektoren* für das Feature-Engineering.\n\nAls Lernalgorithmus verwenden Sie XGB. \n\nPreppen und Backen Sie das Rezept,\naber führen Sie die Pipelien mit dem gebackenen Datensatz und einem \"Plain-Rezept\" durch.\n\n\n## Daten\n\nVerwenden Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\n## AV und UV\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\n## Hinweise\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n- Nutzen Sie das `sentiws` Lexikon.\n- ❗ Achten Sie darauf, die Variable `c2` zu entfernen bzw. nicht zu verwenden.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(lobstr)  # object size\nlibrary(visdat)  # Fingerprint/footprint of dataset (CSV)\ndata(\"sentiws\", package = \"pradadata\")\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n\n## Learner/Modell: RF\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <-\n  rand_forest(mode = \"classification\",\n           mtry = tune(), \n           min_n = tune()\n  )\n```\n:::\n\n\n\n\n\n## Gebackenen Datensatz als neue Grundlage\n\nWir importieren den schon an anderer Stelle aufbereiteten Datensatz.\nDas hat den Vorteil (hoffentlich), das die Datenvolumina viel kleiner sind.\nDie Arbeit des Feature Engineering wurde uns schon abgenommen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvis_dat(d_train) +\n  # remove axis labels:\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank() \n        )\n```\n\n::: {.cell-output-display}\n![](vis-dat-1.png){fig-pos='H' width=384}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test_baked <- read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")\n```\n:::\n\n\n\n## Plain-Rezept\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- \n  recipe(c1 ~ ., data = d_train)\n```\n:::\n\n\n\n\n\n## Neuer Workflow mit plainem Rezept\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf <-\n  workflow() |> \n  add_recipe(rec) |> \n  add_model(mod)\n```\n:::\n\n\n\n\n\n\n## Parallelisierung über mehrere Kerne\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parallel)\nall_cores <- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl <- makeCluster(3)\nplan(cluster, workers = cl)\n```\n:::\n\n\n\nAchtung: Viele Kerne brauchen auch viel Speicher.\n\n## Tune/Resample/Fit\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit_wordvec_senti_rf <-\n  tune_grid(\n    wf,\n    grid = 10,\n    resamples = vfold_cv(d_train, v = 5))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1351.392 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nbeep()\n```\n:::\n\n\n\nModerate Größe:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobj_size(fit_wordvec_senti_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5.05 MB\n```\n\n\n:::\n:::\n\n\n\n\n## Get best performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(fit_wordvec_senti_rf)\n```\n\n::: {.cell-output-display}\n![](unnamed-chunk-6-1.png){fig-pos='H' width=384}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(fit_wordvec_senti_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     9    30 roc_auc binary     0.792     5 0.00401 Preprocessor1_Model08\n2    23     4 roc_auc binary     0.784     5 0.00381 Preprocessor1_Model01\n3    27    40 roc_auc binary     0.780     5 0.00335 Preprocessor1_Model02\n4    39    15 roc_auc binary     0.775     5 0.00321 Preprocessor1_Model04\n5    56     8 roc_auc binary     0.770     5 0.00348 Preprocessor1_Model06\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_params <- select_best(fit_wordvec_senti_rf)\n```\n:::\n\n\n\n## Finalisieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_params <- select_best(fit_wordvec_senti_rf)\ntic()\nwf_finalized <- finalize_workflow(wf, best_params)\nlastfit_rf <- fit(wf_finalized, data = d_train)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n14.077 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n## Test-Set-Güte\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(lastfit_rf, new_data = d_test_baked)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.324 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.708\n2 f_meas   binary         0.304\n```\n\n\n:::\n:::\n\n\n\n## Fazit\n\nVerzichtet man auf ein Rezept mit viel Datenvolumen (Wordvektoren blähen das Rezept mächtig auf), so wird das Fitten schlanker und schneller.\nSchneller auch deshalb, weil ggf. kein Swapping zwischen Speicher und Festplatte mehr nötig ist.\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}