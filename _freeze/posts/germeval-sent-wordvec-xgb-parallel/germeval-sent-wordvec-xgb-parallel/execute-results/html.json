{
  "hash": "d9bccaac3c6cebff820049ef569b84da",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- sentiment\n- string\n- xgb\n- speed\ndate: '2023-12-01'\ntitle: germeval03-sent-wordvec-xgb-parallel\ndraft: true\nexecute: \n  eval: false\n---\n\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie außerdem *deutsche Word-Vektoren* für das Feature-Engineering.\n\nAls Lernalgorithmus verwenden Sie XGB.\n\nVerwenden Sie mehrere Rechenkerne und dokumentieren Sie die Geschwindigkeit (und die Zeitersparnis im Vergleich zu einem einzelnen Rechenkern).\n\nVerwenden Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n- Nutzen Sie das `sentiws` Lexikon.\n- ❗ Achten Sie darauf, die Variable `c2` zu entfernen bzw. nicht zu verwenden.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(lobstr)  # object size\ndata(\"sentiws\", package = \"pradadata\")\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n## Mehrere Kerne\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel(cores=3)\n```\n:::\n\n\n\n\n## Learner/Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <-\n  boost_tree(mode = \"classification\",\n             learn_rate = .01, \n             tree_depth = 5\n             )\n```\n:::\n\n\n## Rezept\n\nPfad zu den Wordvecktoren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath_wordvec <- \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/part-0.arrow\"\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_recipe_wordvec_senti.R\")\n\nrec <- def_recipe_wordvec_senti(data_train = d_train,\n                                path_wordvec = path_wordvec)\n```\n:::\n\n\n\n\n## Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_df.R\")\nwf <- def_wf()\n```\n:::\n\n\n\n## Check\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nrec_prepped <- prep(rec)\ntoc()\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobj_size(rec_prepped)\n```\n:::\n\n\nGroß!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_rec_baked <- bake(rec_prepped, new_data = NULL)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(d_rec_baked))\n```\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit_wordvec_senti_xgb <-\n  fit(wf,\n      data = d_train)\ntoc()\nbeep()\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_wordvec_senti_xgb\n```\n:::\n\n\nObjekt-Größe:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(fit_wordvec_senti_xgb)\n```\n:::\n\n\n\nGroß!\n\nWie wir gesehen haben, ist das Rezept riesig.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(butcher)\nout <- butcher(fit_wordvec_senti_xgb)\nlobstr::obj_size(out)\n```\n:::\n\n\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(fit_wordvec_senti_xgb, new_data = germeval_test)\ntoc()\n```\n:::\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}