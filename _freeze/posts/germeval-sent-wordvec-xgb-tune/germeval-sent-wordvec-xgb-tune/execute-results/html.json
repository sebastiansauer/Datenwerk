{
  "hash": "f45b00c7647fb665852df2403bb831b2",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- sentiment\n- string\n- xgb\n- tune\ndate: '2023-12-03'\ntitle: germeval03-sent-wordvec-xgb-tune\ndraft: true   # DRAFT TRUE\neval: false\n---\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Sentiments und TextFeatures im Rahmen von Feature-Engineering.\nNutzen Sie außerdem *deutsche Word-Vektoren* für das Feature-Engineering.\n\nAls Lernalgorithmus verwenden Sie XGB. Tunen Sie die Lernrate und die max. Tiefe (`max_depth`) des Modells.\n\n\n\n## Daten\n\nVerwenden Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\n## AV und UV\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\n## Hinweise\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n- Nutzen Sie das `sentiws` Lexikon.\n- ❗ Achten Sie darauf, die Variable `c2` zu entfernen bzw. nicht zu verwenden.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(lobstr)  # object size\ndata(\"sentiws\", package = \"pradadata\")\n```\n:::\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n\n## Learner/Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <-\n  boost_tree(mode = \"classification\",\n             learn_rate = tune(), \n             tree_depth = tune()\n             )\n```\n:::\n\n\n## Rezept\n\nPfad zu den Wordvektoren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath_wordvec <- \"/Users/sebastiansaueruser/datasets/word-embeddings/wikipedia2vec/part-0.arrow\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_recipe_wordvec_senti.R\")\n\nrec <- def_recipe_wordvec_senti(data_train = d_train,\n                                path_wordvec = path_wordvec)\n```\n:::\n\n\n\n\n## Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/funs/def_wf.R\")\nwf <- def_wf()\n```\n:::\n\n\n\n## Check\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nrec_prepped <- prep(rec)\ntoc()\n\nrec_prepped\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nobj_size(rec_prepped)\n```\n:::\n\n\nGroß!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_rec_baked <- bake(rec_prepped, new_data = NULL)\n\nhead(d_rec_baked)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(d_rec_baked))\n```\n:::\n\n\n\n## Parallelisierung über mehrere Kerne\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parallel)\nall_cores <- detectCores(logical = FALSE)\n\nlibrary(doFuture)\nregisterDoFuture()\ncl <- makeCluster(2)\nplan(cluster, workers = cl)\n```\n:::\n\n\n\n\n## Tune/Resample/Fit\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit_wordvec_senti_xgb <-\n  tune_grid(\n    wf,\n    grid = 10,\n    resamples = vfold_cv(d_train, v = 5),\n    data = d_train)\ntoc()\nbeep()\n```\n:::\n\n\n\n\nObjekt-Größe:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(fit_wordvec_senti_xgb)\n```\n:::\n\n\n\nGroß!\n\nWie wir gesehen haben, ist das Rezept riesig.\n\n\n\n## Get best performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(fit_wordvec_senti_xgb)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(fit_wordvec_senti_xgb)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_params <- select_best(fit_wordvec_senti_xgb)\n```\n:::\n\n\n\n## Finalisieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_params <- select_best(fit_wordvec_senti_xgb)\ntic()\nwf_finalized <- finalize_workflow(wf, best_params)\nlastfit_xgb <- fit(wf_finalized, data = d_train)\ntoc()\n```\n:::\n\n\n\n## Test-Set-Güte\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(lastfit_xgb, new_data = germeval_test)\ntoc()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}