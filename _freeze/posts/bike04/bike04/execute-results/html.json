{
  "hash": "752b111148f7c2b0365af34b40208d54",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: bike04\nextype: num\nexsolution: r fmt(sol)\nexshuffle: no\nexpoints: 1\ncategories:\n- statlearning\n- tidymodels\n- num\ndate: '2023-05-17'\nslug: bike04\ntitle: bike04\n\n---\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nKann man die Anzahl gerade verliehener Fahrräder eines entsprechenden Anbieters anhand der Temperatur vorhersagen?\n\nIn dieser Übung untersuchen wir diese Frage.\n\nSie können die Daten von der [Webseite der UCI](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#) herunterladen.\n\nWir beziehen uns auf den Datensatz `day`.\n\nBerechnen Sie einen Entscheidungsbaum  mit der Anzahl der aktuell vermieteten Räder als AV und der aktuellen Temperatur als UV!\n\nTunen Sie alle Paramter; lassen Sie sich 20 Tuningparameter vorschlagen.\n\nGeben Sie den MSE an!\n\n[Hinweise](https://datenwerk.netlify.app/Hinweise.html)\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-1_8671805010af2bce301d4efd92c6a331'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)\n```\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-2_63299d5133c708c6558e757f0d55a265'}\n\n```{.r .cell-code}\nd <- read.csv(\"/Users/sebastiansaueruser/datasets/Bike-Sharing-Dataset/day.csv\")\n```\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-3_2dc11c0064bfc14ff596837106afe10a'}\n\n```{.r .cell-code}\nglimpse(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 731\nColumns: 16\n$ instant    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ dteday     <chr> \"2011-01-01\", \"2011-01-02\", \"2011-01-03\", \"2011-01-04\", \"20…\n$ season     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ yr         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ mnth       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ holiday    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,…\n$ weekday    <int> 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4,…\n$ workingday <int> 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,…\n$ weathersit <int> 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ temp       <dbl> 0.3441670, 0.3634780, 0.1963640, 0.2000000, 0.2269570, 0.20…\n$ atemp      <dbl> 0.3636250, 0.3537390, 0.1894050, 0.2121220, 0.2292700, 0.23…\n$ hum        <dbl> 0.805833, 0.696087, 0.437273, 0.590435, 0.436957, 0.518261,…\n$ windspeed  <dbl> 0.1604460, 0.2485390, 0.2483090, 0.1602960, 0.1869000, 0.08…\n$ casual     <int> 331, 131, 120, 108, 82, 88, 148, 68, 54, 41, 43, 25, 38, 54…\n$ registered <int> 654, 670, 1229, 1454, 1518, 1518, 1362, 891, 768, 1280, 122…\n$ cnt        <int> 985, 801, 1349, 1562, 1600, 1606, 1510, 959, 822, 1321, 126…\n```\n\n\n:::\n:::\n\n\n## Data split\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-4_05fb88c14f1674bc92e715ceac67ab3f'}\n\n```{.r .cell-code}\nset.seed(42)\nd_split <- initial_split(d, strata = cnt)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n## Define recipe\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-5_47ac5ceda57b9839fe9d188e659fabab'}\n\n```{.r .cell-code}\nrec1 <- \n  recipe(cnt ~ temp, data = d)\n```\n:::\n\n\n\n\n## Define model\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-6_69714edce0a785b3f1ebd7e4fe728caa'}\n\n```{.r .cell-code}\nm1 <-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune(),\n                mode = \"regression\")\n```\n:::\n\n\n\n## Tuning grid\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-7_5e605144d6f37690d5177d1cb2db4a29'}\n\n```{.r .cell-code}\ngrid <-\n  grid_latin_hypercube(cost_complexity(), \n               tree_depth(),\n               min_n(),\n               size = 20)\ngrid\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   cost_complexity tree_depth min_n\n             <dbl>      <int> <int>\n 1        1.09e- 7          8    13\n 2        9.98e- 9         14    32\n 3        1.72e- 5          8    38\n 4        6.73e- 5         11     9\n 5        5.01e- 6         13    20\n 6        1.60e- 2          5    18\n 7        4.08e- 9         12     4\n 8        3.49e- 3          2     8\n 9        3.72e-10          9    27\n10        3.14e- 7         11    21\n11        3.92e- 2          3    30\n12        8.08e- 5          6    26\n13        1.04e- 6         14    33\n14        1.17e-10          1    36\n15        9.35e-10          4    16\n16        3.05e- 4          7    15\n17        1.80e- 6          6    23\n18        8.38e- 4          3     5\n19        8.01e- 3         13    11\n20        3.46e- 8         10    39\n```\n\n\n:::\n:::\n\n\nAlternativ:\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-8_515b9af13ccabb230455650557e067da'}\n\n```{.r .cell-code}\ngrid <-\n  grid_latin_hypercube(extract_parameter_set_dials(m1), size = 50)\ngrid\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 3\n   cost_complexity tree_depth min_n\n             <dbl>      <int> <int>\n 1   0.000390               6    21\n 2   0.0000000863           8    15\n 3   0.000576              12    37\n 4   0.0000000469           2    31\n 5   0.0000000283           5    19\n 6   0.00000000207          4     5\n 7   0.000000614            2    23\n 8   0.00000000952         14    13\n 9   0.00000413            11     7\n10   0.0000472              7    12\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n\n## Define Resamples\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-9_542e064ed3ab3fb2e77934cc0d82a3f4'}\n\n```{.r .cell-code}\nrsmpl <- vfold_cv(d_train)\n```\n:::\n\n\n\n## Workflow\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-10_77400c06760e93284a2f50f2e71d6848'}\n\n```{.r .cell-code}\nwf1 <-\n  workflow() %>% \n  add_model(m1) %>% \n  add_recipe(rec1) \n```\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-11_a1a6f29694263821081fa3a596c42c33'}\n\n```{.r .cell-code}\ntic()\nfit1 <- tune_grid(\n  object = wf1, \n  resamples = rsmpl)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.762 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nfit1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   <list>           <chr>  <list>            <list>          \n 1 <split [492/55]> Fold01 <tibble [20 × 7]> <tibble [0 × 3]>\n 2 <split [492/55]> Fold02 <tibble [20 × 7]> <tibble [0 × 3]>\n 3 <split [492/55]> Fold03 <tibble [20 × 7]> <tibble [0 × 3]>\n 4 <split [492/55]> Fold04 <tibble [20 × 7]> <tibble [0 × 3]>\n 5 <split [492/55]> Fold05 <tibble [20 × 7]> <tibble [0 × 3]>\n 6 <split [492/55]> Fold06 <tibble [20 × 7]> <tibble [0 × 3]>\n 7 <split [492/55]> Fold07 <tibble [20 × 7]> <tibble [0 × 3]>\n 8 <split [493/54]> Fold08 <tibble [20 × 7]> <tibble [0 × 3]>\n 9 <split [493/54]> Fold09 <tibble [20 × 7]> <tibble [0 × 3]>\n10 <split [493/54]> Fold10 <tibble [20 × 7]> <tibble [0 × 3]>\n```\n\n\n:::\n:::\n\n\n\n## Bester Kandidat\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-12_1a829d93b46b5d8e5b8eb003defeb6f8'}\n\n```{.r .cell-code}\nshow_best(fit1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            <dbl>      <int> <int> <chr>   <chr>      <dbl> <int>   <dbl>\n1        3.92e- 4          2    18 rmse    standard   1443.    10    29.9\n2        1.46e- 2         11    38 rmse    standard   1453.    10    33.5\n3        1.23e- 2         14    10 rmse    standard   1458.    10    32.5\n4        1.17e- 9          3    29 rmse    standard   1459.    10    29.2\n5        4.46e-10          5    36 rmse    standard   1460.    10    29.9\n# ℹ 1 more variable: .config <chr>\n```\n\n\n:::\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-13_b7f2bedc5a8fed62c9eb20148a47eb0f'}\n\n```{.r .cell-code}\nwf1_best <-\n  wf1 %>% \n  finalize_workflow(parameters = select_best(fit1))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n\n\n:::\n:::\n\n\n\n## Last Fit\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-14_1631778c9ce6f2e20cd3ae2e2396d548'}\n\n```{.r .cell-code}\nfit_testsample <- last_fit(wf1_best, d_split)\n```\n:::\n\n\n\n\n## Model performance (metrics) in test set\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-15_085786e215e16699aa41d3797e5e3855'}\n\n```{.r .cell-code}\nfit_testsample %>% collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard    1399.    Preprocessor1_Model1\n2 rsq     standard       0.497 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-16_9113b9499bfb7e3a6a9db3a4f0295452'}\n\n```{.r .cell-code}\nMSE <- fit_testsample %>% collect_metrics() %>% pluck(3, 1)\nMSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1398.675\n```\n\n\n:::\n:::\n\n\n\n\n**Solution**: 1398.6748691\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-17_589a0c1440975d41e0055461e0d62290'}\n\n:::\n\n\n\n\n\n---\n\nCategories: \n\n- statlearning\n- tidymodels\n- num\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}