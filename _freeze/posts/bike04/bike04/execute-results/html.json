{
  "hash": "752b111148f7c2b0365af34b40208d54",
  "result": {
    "markdown": "---\nexname: bike04\nextype: num\nexsolution: r fmt(sol)\nexshuffle: no\nexpoints: 1\ncategories:\n- statlearning\n- tidymodels\n- num\ndate: '2023-05-17'\nslug: bike04\ntitle: bike04\n\n---\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nKann man die Anzahl gerade verliehener Fahrräder eines entsprechenden Anbieters anhand der Temperatur vorhersagen?\n\nIn dieser Übung untersuchen wir diese Frage.\n\nSie können die Daten von der [Webseite der UCI](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#) herunterladen.\n\nWir beziehen uns auf den Datensatz `day`.\n\nBerechnen Sie einen Entscheidungsbaum  mit der Anzahl der aktuell vermieteten Räder als AV und der aktuellen Temperatur als UV!\n\nTunen Sie alle Paramter; lassen Sie sich 20 Tuningparameter vorschlagen.\n\nGeben Sie den MSE an!\n\n[Hinweise](https://datenwerk.netlify.app/Hinweise.html)\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-1_6f67f7fec452fedbfe0064885f914dd3'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)\n```\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-2_f553ea6364ae821808965b6017f7cb4d'}\n\n```{.r .cell-code}\nd <- read.csv(\"/Users/sebastiansaueruser/datasets/Bike-Sharing-Dataset/day.csv\")\n```\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-3_d4c63d9e38346e6b183f7922f5e9f7be'}\n\n```{.r .cell-code}\nglimpse(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 731\nColumns: 16\n$ instant    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ dteday     <chr> \"2011-01-01\", \"2011-01-02\", \"2011-01-03\", \"2011-01-04\", \"20…\n$ season     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ yr         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ mnth       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ holiday    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,…\n$ weekday    <int> 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4,…\n$ workingday <int> 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,…\n$ weathersit <int> 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ temp       <dbl> 0.3441670, 0.3634780, 0.1963640, 0.2000000, 0.2269570, 0.20…\n$ atemp      <dbl> 0.3636250, 0.3537390, 0.1894050, 0.2121220, 0.2292700, 0.23…\n$ hum        <dbl> 0.805833, 0.696087, 0.437273, 0.590435, 0.436957, 0.518261,…\n$ windspeed  <dbl> 0.1604460, 0.2485390, 0.2483090, 0.1602960, 0.1869000, 0.08…\n$ casual     <int> 331, 131, 120, 108, 82, 88, 148, 68, 54, 41, 43, 25, 38, 54…\n$ registered <int> 654, 670, 1229, 1454, 1518, 1518, 1362, 891, 768, 1280, 122…\n$ cnt        <int> 985, 801, 1349, 1562, 1600, 1606, 1510, 959, 822, 1321, 126…\n```\n:::\n:::\n\n\n## Data split\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-4_e9b4d19215633df2184ddabfbe2db89a'}\n\n```{.r .cell-code}\nset.seed(42)\nd_split <- initial_split(d, strata = cnt)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n## Define recipe\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-5_b92a5d2a50b7bb7f5ba1ddee741aa49f'}\n\n```{.r .cell-code}\nrec1 <- \n  recipe(cnt ~ temp, data = d)\n```\n:::\n\n\n\n\n## Define model\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-6_ddffdbd56a3168fbdb0acf7136110045'}\n\n```{.r .cell-code}\nm1 <-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune(),\n                mode = \"regression\")\n```\n:::\n\n\n\n## Tuning grid\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-7_8689ae59731921fafc2aa3d037884ff3'}\n\n```{.r .cell-code}\ngrid <-\n  grid_latin_hypercube(cost_complexity(), \n               tree_depth(),\n               min_n(),\n               size = 20)\ngrid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 3\n   cost_complexity tree_depth min_n\n             <dbl>      <int> <int>\n 1        1.09e- 7          8    13\n 2        9.98e- 9         14    32\n 3        1.72e- 5          8    38\n 4        6.73e- 5         11     9\n 5        5.01e- 6         13    20\n 6        1.60e- 2          5    18\n 7        4.08e- 9         12     4\n 8        3.49e- 3          2     8\n 9        3.72e-10          9    27\n10        3.14e- 7         11    21\n11        3.92e- 2          3    30\n12        8.08e- 5          6    26\n13        1.04e- 6         14    33\n14        1.17e-10          1    36\n15        9.35e-10          4    16\n16        3.05e- 4          7    15\n17        1.80e- 6          6    23\n18        8.38e- 4          3     5\n19        8.01e- 3         13    11\n20        3.46e- 8         10    39\n```\n:::\n:::\n\n\nAlternativ:\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-8_58dac3e7ad454a5ad3e5439de9eda797'}\n\n```{.r .cell-code}\ngrid <-\n  grid_latin_hypercube(extract_parameter_set_dials(m1), size = 50)\ngrid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 3\n   cost_complexity tree_depth min_n\n             <dbl>      <int> <int>\n 1   0.000390               6    21\n 2   0.0000000863           8    15\n 3   0.000576              12    37\n 4   0.0000000469           2    31\n 5   0.0000000283           5    19\n 6   0.00000000207          4     5\n 7   0.000000614            2    23\n 8   0.00000000952         14    13\n 9   0.00000413            11     7\n10   0.0000472              7    12\n# ℹ 40 more rows\n```\n:::\n:::\n\n\n\n## Define Resamples\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-9_97faf784c761e2020aa02dbd343f625c'}\n\n```{.r .cell-code}\nrsmpl <- vfold_cv(d_train)\n```\n:::\n\n\n\n## Workflow\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-10_7b21d5dd99086a4b1b5018f3e6b4c8d5'}\n\n```{.r .cell-code}\nwf1 <-\n  workflow() %>% \n  add_model(m1) %>% \n  add_recipe(rec1) \n```\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-11_cbc0357a176d0bb3d1db1f405e1642b4'}\n\n```{.r .cell-code}\ntic()\nfit1 <- tune_grid(\n  object = wf1, \n  resamples = rsmpl)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n12.204 sec elapsed\n```\n:::\n\n```{.r .cell-code}\nfit1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   <list>           <chr>  <list>            <list>          \n 1 <split [492/55]> Fold01 <tibble [20 × 7]> <tibble [0 × 3]>\n 2 <split [492/55]> Fold02 <tibble [20 × 7]> <tibble [0 × 3]>\n 3 <split [492/55]> Fold03 <tibble [20 × 7]> <tibble [0 × 3]>\n 4 <split [492/55]> Fold04 <tibble [20 × 7]> <tibble [0 × 3]>\n 5 <split [492/55]> Fold05 <tibble [20 × 7]> <tibble [0 × 3]>\n 6 <split [492/55]> Fold06 <tibble [20 × 7]> <tibble [0 × 3]>\n 7 <split [492/55]> Fold07 <tibble [20 × 7]> <tibble [0 × 3]>\n 8 <split [493/54]> Fold08 <tibble [20 × 7]> <tibble [0 × 3]>\n 9 <split [493/54]> Fold09 <tibble [20 × 7]> <tibble [0 × 3]>\n10 <split [493/54]> Fold10 <tibble [20 × 7]> <tibble [0 × 3]>\n```\n:::\n:::\n\n\n\n## Bester Kandidat\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-12_cb14981a0a496b6dd9cdf8bca101dfc8'}\n\n```{.r .cell-code}\nshow_best(fit1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            <dbl>      <int> <int> <chr>   <chr>      <dbl> <int>   <dbl>\n1        4.94e- 5          4    35 rmse    standard   1490.    10    42.6\n2        7.02e- 8          4    32 rmse    standard   1497.    10    45.1\n3        4.02e- 2          6    12 rmse    standard   1511.    10    39.2\n4        4.04e- 3          8    37 rmse    standard   1518.    10    45.2\n5        2.93e-10         11    23 rmse    standard   1562.    10    48.1\n# ℹ 1 more variable: .config <chr>\n```\n:::\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-13_11b0d286424b8e870b2d29603353f539'}\n\n```{.r .cell-code}\nwf1_best <-\n  wf1 %>% \n  finalize_workflow(parameters = select_best(fit1))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n:::\n:::\n\n\n\n## Last Fit\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-14_abc015c3c9b9ce06d20c62f68c7ab365'}\n\n```{.r .cell-code}\nfit_testsample <- last_fit(wf1_best, d_split)\n```\n:::\n\n\n\n\n## Model performance (metrics) in test set\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-15_8a55c9fe6cc30f7d74366bc66dff93e0'}\n\n```{.r .cell-code}\nfit_testsample %>% collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard    1416.    Preprocessor1_Model1\n2 rsq     standard       0.481 Preprocessor1_Model1\n```\n:::\n:::\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-16_d2d9bfa0e8b776938530d52c9ce84b47'}\n\n```{.r .cell-code}\nMSE <- fit_testsample %>% collect_metrics() %>% pluck(3, 1)\nMSE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1416.308\n```\n:::\n:::\n\n\n\n\n**Solution**: 1416.3081428\n\n\n\n::: {.cell hash='bike04_cache/html/unnamed-chunk-17_1016eefa5fa0ac9c1004fb098e70c90c'}\n\n:::\n\n\n\n\n\n---\n\nCategories: \n\n- statlearning\n- tidymodels\n- num\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}