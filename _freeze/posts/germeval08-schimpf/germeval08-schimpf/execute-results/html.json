{
  "hash": "63593a866aa4a76c0b3a2270ee77b2ba",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval08-schimpf\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- 2023\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- string\ndate: '2023-11-15'\nslug: germeval08-schimpf\ntitle: germeval08-schimpf\n\n---\n\n\n\n\n\n\n# Aufgabe\n\nErstellen Sie ein prädiktives Modell für Textdaten. Nutzen Sie Schimpfwörter im Rahmen von Feature-Engineering.\n\nNutzen Sie die [GermEval-2018-Daten](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/0B5VML).\n\nDie Daten sind unter CC-BY-4.0 lizensiert. Author: Wiegand, Michael (Spoken Language Systems, Saarland University (2010-2018), Leibniz Institute for the German Language (since 2019)),\n\nDie Daten sind auch über das R-Paket [PradaData](https://github.com/sebastiansauer/pradadata/tree/master/data-raw/GermEval-2018-Data-master) zu beziehen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n```\n:::\n\n\nDie AV lautet `c1`. Die (einzige) UV lautet: `text`.\n\n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n- Nutzen Sie Tidymodels.\n- Nutzen Sie das `sentiws` Lexikon.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(id, c1, text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(tidytext)\nlibrary(syuzhet)\nlibrary(beepr)\ndata(\"schimpfwoerter\", package = \"pradadata\")\n```\n:::\n\n\nUm ein Wörterbuch zu erzeugen für `syuzhet` braucht es eine Spalte `value`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschimpfwoerter$value <- 1\n```\n:::\n\n\n\n\nEine [Vorlage für ein Tidymodels-Pipeline findet sich hier](https://datenwerk.netlify.app/posts/tidymodels-vorlage2/tidymodels-vorlage2.html).\n\n\n## Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model:\nmod1 <-\n  rand_forest(mode = \"classification\")\n\n# recipe:\nrec1 <-\n  recipe(c1 ~ ., data = d_train) |> \n  update_role(id, new_role = \"id\")  |> \n  #update_role(c2, new_role = \"ignore\") |> \n  update_role(text, new_role = \"ignore\") |> \n  step_mutate(n_schimpf = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = schimpfwoerter))  |> \n  step_rm(text)  # Datensatz verschlanken\n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod1) %>% \n  add_recipe(rec1)\n```\n:::\n\n\n\n\n## Fit\n\nOhne Tuning:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit1 <-\n  fit(wf1,\n      data = d_train)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n10.428 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\n#beep()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_mutate()\n• step_rm()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      5009 \nNumber of independent variables:  1 \nMtry:                             1 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.2137514 \n```\n\n\n:::\n:::\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(fit1, new_data = germeval_test)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.198 sec elapsed\n```\n\n\n:::\n:::\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_metrics <- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.676\n2 f_meas   binary         0.336\n```\n\n\n:::\n:::\n\n\n\n\nAls Check: Das gepreppte/bebackene Rezept:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nrec1_prepped <- prep(rec1)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n10.499 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nd_train_baked <- bake(rec1_prepped, new_data = NULL)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.006 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked |> \n  arrange(-n_schimpf) |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n     id c1      n_schimpf\n  <int> <fct>       <dbl>\n1  4493 OFFENSE         4\n2   707 OFFENSE         3\n3   771 OFFENSE         3\n4  1504 OTHER           3\n5  3145 OTHER           3\n6  3354 OFFENSE         3\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train |> \n  filter(id == 707) |> \n  pull(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"@mastermikeg @machtjanix23 @AthinaMala @_macmike @Norbinator2403 @ennof_ @troll_putin @NancyPeggyMandy @petpanther0 @info2099 @lifetrend @ThomasGBauer @SchmiddieMaik @charlie_silve @NoHerrman @willjrosenblatt @feldenfrizz @nasanasal @ellibisathide @MD_Franz Der Typ hat sich mit etlichen hier angelegt, hat inhaltlich nichts zu bieten - nur Klugscheißern. Eigenes hat er auch nicht zu bieten - dafür reicht sein Intellekt nicht.\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train |> \n  filter(id == 707) |> \n  select(text) |> \n  unnest_tokens(output = word, input = text) |> \n  inner_join(schimpfwoerter)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    word value\n1    typ     1\n2 nichts     1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train |> \n  filter(id == 4493) |> \n  pull(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"@Der_Eisenhans @focusonline Soweit mir bekannt ist das Wort Muschi ein kosenahme für eine Katze die es auch Geschlechts spezifisch gibt. Als Schwanz oder Schweif bezeichnet man das End Stück eines Pferdes oder Hund. Beides nicht Ursprung der Fortpflanzung. Ich hoffe ich konnte helfen. :-)\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train |> \n  filter(id == 4493) |> \n  select(text) |> \n  unnest_tokens(output = word, input = text) |> \n  inner_join(schimpfwoerter)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     word value\n1   katze     1\n2 schwanz     1\n3 schweif     1\n4   stück     1\n5    hund     1\n```\n\n\n:::\n:::\n\n\n\n\n---\n\nCategories: \n\n- 2023\n- textmining\n- datawrangling\n- germeval\n- prediction\n- tidymodels\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}