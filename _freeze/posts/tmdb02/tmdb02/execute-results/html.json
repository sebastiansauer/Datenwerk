{
  "hash": "38f96ffa8d53c0838e439cdbdd8b1ff9",
  "result": {
    "markdown": "---\nexname: tmdb02\nextype: num\nexsolution: r sol\nextol: 0.2\nexpoints: 1\ncategories:\n- ds1\n- tidymodels\n- statlearning\n- tmdb\n- trees\n- num\ndate: '2023-05-17'\nslug: tmdb02\ntitle: tmdb02\n\n---\n\n\n\n\n\n\n\n\n<!-- ```{r read-supplement} -->\n<!-- result_obj_path <- \"tmbd_rf_fit1.rds\" -->\n<!-- #file.exists(here::here(\"objects\", result_obj_path)) -->\n<!-- exams::include_supplement(file = result_obj_path, -->\n<!--                    recursive = TRUE) -->\n\n<!-- #rf_fit <- readr::read_rds(\"/Users/sebastiansaueruser/github-repos/rexams-exercises/objects/tmbd_rf_fit1.rds\") -->\n<!-- ``` -->\n\n\n\n# Aufgabe\n\nWir bearbeiten hier die Fallstudie [TMDB Box Office Prediction - \nCan you predict a movie's worldwide box office revenue?](https://www.kaggle.com/competitions/tmdb-box-office-prediction/overview),\nein [Kaggle](https://www.kaggle.com/)-Prognosewettbewerb.\n\nZiel ist es, genaue Vorhersagen zu machen,\nin diesem Fall für Filme.\n\n\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n```\n:::\n\n\n\n##### Aufgabe\n\nReichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Kaggle-Score\n\n\nHinweise:\n\n- Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.\n- Berechnen Sie einen *Entscheidungsbaum* und einen *Random-Forest*.\n- Tunen Sie nach Bedarf; verwenden Sie aber Default-Werte.\n- Verwenden Sie Tidymodels.\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Vorbereitung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(doParallel)  # mehrere CPUs nutzen\nlibrary(finetune)  # Tune Anova\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <- read_csv(d_train_path)\nd_test <- read_csv(d_test_path)\n\nglimpse(d_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3,000\nColumns: 23\n$ id                    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection <chr> \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                <dbl> 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                <chr> \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              <chr> NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               <chr> \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     <chr> \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        <chr> \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              <chr> \"When Lou, who has become the \\\"father of the In…\n$ popularity            <dbl> 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           <chr> \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  <chr> \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  <chr> \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          <chr> \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               <dbl> 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      <chr> \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                <chr> \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               <chr> \"The Laws of Space and Time are About to be Viol…\n$ title                 <chr> \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              <chr> \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  <chr> \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  <chr> \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               <dbl> 12314651, 95149435, 13092000, 16000000, 3923970,…\n```\n:::\n\n```{.r .cell-code}\nglimpse(d_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 4,398\nColumns: 22\n$ id                    <dbl> 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection <chr> \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                <dbl> 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                <chr> \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              <chr> \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               <chr> \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     <chr> \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        <chr> \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              <chr> \"Ash and friends (this time accompanied by newco…\n$ popularity            <dbl> 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           <chr> \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  <chr> NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  <chr> \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          <chr> \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               <dbl> 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      <chr> \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                <chr> \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               <chr> \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 <chr> \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              <chr> \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  <chr> \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  <chr> \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…\n```\n:::\n:::\n\n\n## Rezept\n\n### Rezept definieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <-\n  recipe(revenue ~ ., data = d_train) %>% \n  update_role(all_predictors(), new_role = \"id\") %>% \n  update_role(popularity, runtime, revenue, budget) %>% \n  update_role(revenue, new_role = \"outcome\") %>% \n  step_mutate(budget = ifelse(budget < 10, 10, budget)) %>% \n  step_log(budget) %>% \n  step_impute_knn(all_predictors())\n\nrec1\n```\n:::\n\n\n\n### Check das Rezept \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1_prepped <-\n  prep(rec1, verbose = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\noper 1 step mutate [training] \noper 2 step log [training] \noper 3 step impute knn [training] \nThe retained training set is ~ 28.71 Mb  in memory.\n```\n:::\n\n```{.r .cell-code}\nrec1_prepped\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked <-\n  rec1_prepped %>% \n  bake(new_data = NULL) \n\nhead(d_train_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 23\n     id belongs_to_collection   budget genres homepage imdb_id original_language\n  <dbl> <fct>                    <dbl> <fct>  <fct>    <fct>   <fct>            \n1     1 [{'id': 313576, 'name'…  16.5  [{'id… <NA>     tt2637… en               \n2     2 [{'id': 107674, 'name'…  17.5  [{'id… <NA>     tt0368… en               \n3     3 <NA>                     15.0  [{'id… http://… tt2582… en               \n4     4 <NA>                     14.0  [{'id… http://… tt1821… hi               \n5     5 <NA>                      2.30 [{'id… <NA>     tt1380… ko               \n6     6 <NA>                     15.9  [{'id… <NA>     tt0093… en               \n# ℹ 16 more variables: original_title <fct>, overview <fct>, popularity <dbl>,\n#   poster_path <fct>, production_companies <fct>, production_countries <fct>,\n#   release_date <fct>, runtime <dbl>, spoken_languages <fct>, status <fct>,\n#   tagline <fct>, title <fct>, Keywords <fct>, cast <fct>, crew <fct>,\n#   revenue <dbl>\n```\n:::\n:::\n\n\n\nDie AV-Spalte sollte leer sein:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbake(rec1_prepped, new_data = head(d_test), all_outcomes())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked %>% \n  map_df(~ sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 23\n     id belongs_to_collection budget genres homepage imdb_id original_language\n  <int>                 <int>  <int>  <int>    <int>   <int>             <int>\n1     0                  2396      0      7     2054       0                 0\n# ℹ 16 more variables: original_title <int>, overview <int>, popularity <int>,\n#   poster_path <int>, production_companies <int>, production_countries <int>,\n#   release_date <int>, runtime <int>, spoken_languages <int>, status <int>,\n#   tagline <int>, title <int>, Keywords <int>, cast <int>, crew <int>,\n#   revenue <int>\n```\n:::\n:::\n\n\n\nKeine fehlenden Werte mehr *in den Prädiktoren*.\n\nNach fehlenden Werten könnte man z.B. auch so suchen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatawizard::describe_distribution(d_train_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVariable   |     Mean |       SD |      IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n---------------------------------------------------------------------------------------------------------\nid         |  1500.50 |   866.17 |  1500.50 |    [1.00, 3000.00] |     0.00 |    -1.20 | 3000 |         0\nbudget     |    12.51 |     6.44 |    14.88 |      [2.30, 19.76] |    -0.87 |    -1.09 | 3000 |         0\npopularity |     8.46 |    12.10 |     6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime    |   107.85 |    22.08 |    24.00 |     [0.00, 338.00] |     1.02 |     8.20 | 3000 |         0\nrevenue    | 6.67e+07 | 1.38e+08 | 6.66e+07 |   [1.00, 1.52e+09] |     4.54 |    27.78 | 3000 |         0\n```\n:::\n:::\n\n\n\nSo bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\n\n\nDas Test-Sample backen wir auch mal:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test_baked <-\n  bake(rec1_prepped, new_data = d_test)\n\nd_test_baked %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 22\n     id belongs_to_collection   budget genres homepage imdb_id original_language\n  <dbl> <fct>                    <dbl> <fct>  <fct>    <fct>   <fct>            \n1  3001 [{'id': 34055, 'name':…   2.30 [{'id… <NA>     <NA>    ja               \n2  3002 <NA>                     11.4  [{'id… <NA>     <NA>    en               \n3  3003 <NA>                      2.30 [{'id… <NA>     <NA>    en               \n4  3004 <NA>                     15.7  <NA>   <NA>     <NA>    fr               \n5  3005 <NA>                     14.5  [{'id… <NA>     <NA>    en               \n6  3006 <NA>                      2.30 [{'id… <NA>     <NA>    en               \n# ℹ 15 more variables: original_title <fct>, overview <fct>, popularity <dbl>,\n#   poster_path <fct>, production_companies <fct>, production_countries <fct>,\n#   release_date <fct>, runtime <dbl>, spoken_languages <fct>, status <fct>,\n#   tagline <fct>, title <fct>, Keywords <fct>, cast <fct>, crew <fct>\n```\n:::\n:::\n\n\n\n\n\n## Kreuzvalidierung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_scheme <- vfold_cv(d_train,\n                      v = 5, \n                      repeats = 1)\n```\n:::\n\n\n\n## Modelle\n\n### Baum\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_tree <-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                mode = \"regression\")\n```\n:::\n\n\n\n\n### Random Forest\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_rf <-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000,\n              mode = \"regression\") %>% \n  set_engine(\"ranger\", num.threads = 4)\n```\n:::\n\n\n\n## Workflows\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_tree <-\n  workflow() %>% \n  add_model(mod_tree) %>% \n  add_recipe(rec1)\n\nwf_rf <-\n  workflow() %>% \n  add_model(mod_rf) %>% \n  add_recipe(rec1)\n```\n:::\n\n\n\n## Fitten und tunen\n\nUm Rechenzeit zu sparen,\nkann man den Parameter `grid` bei `tune_grid()` auf einen kleinen Wert setzen.\nDer Default ist 10.\nUm gute Vorhersagen zu erzielen,\nsollte man den Wert tendenziell noch über 10 erhöhen.\n\n### Tree\n\n\nParallele Verarbeitung starten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\ntree_fit <-\n  wf_tree %>% \n  tune_race_anova(\n    resamples = cv_scheme,\n    #grid = 2\n  )\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n28.687 sec elapsed\n```\n:::\n:::\n\n\n\nHilfe zu `tune_grid()` bekommt man [hier](https://www.rdocumentation.org/packages/tune/versions/0.2.0/topics/tune_grid).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 5\n  splits             id    .order .metrics          .notes          \n  <list>             <chr>  <int> <list>            <list>          \n1 <split [2400/600]> Fold1      1 <tibble [20 × 6]> <tibble [0 × 3]>\n2 <split [2400/600]> Fold4      3 <tibble [20 × 6]> <tibble [0 × 3]>\n3 <split [2400/600]> Fold5      2 <tibble [20 × 6]> <tibble [0 × 3]>\n4 <split [2400/600]> Fold3      4 <tibble [18 × 6]> <tibble [0 × 3]>\n5 <split [2400/600]> Fold2      5 <tibble [16 × 6]> <tibble [0 × 3]>\n```\n:::\n:::\n\n\nSteht was in den `.notes`?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit[[\".notes\"]][[2]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 0 × 3\n# ℹ 3 variables: location <chr>, type <chr>, note <chr>\n```\n:::\n:::\n\n\nNein.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(tree_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 × 8\n   cost_complexity tree_depth .metric .estimator      mean     n std_err .config\n             <dbl>      <int> <chr>   <chr>          <dbl> <int>   <dbl> <chr>  \n 1   0.00000000350         12 rmse    standard     8.90e+7     5 3.90e+6 Prepro…\n 2   0.00000000350         12 rsq     standard     5.80e-1     5 1.85e-2 Prepro…\n 3   0.0112                 4 rmse    standard     9.10e+7     5 3.53e+6 Prepro…\n 4   0.0112                 4 rsq     standard     5.53e-1     5 3.09e-2 Prepro…\n 5   0.000000119            3 rmse    standard     9.00e+7     5 3.53e+6 Prepro…\n 6   0.000000119            3 rsq     standard     5.60e-1     5 2.94e-2 Prepro…\n 7   0.0000000126           9 rmse    standard     8.85e+7     5 3.81e+6 Prepro…\n 8   0.0000000126           9 rsq     standard     5.83e-1     5 1.88e-2 Prepro…\n 9   0.0000204             10 rmse    standard     8.88e+7     5 3.83e+6 Prepro…\n10   0.0000204             10 rsq     standard     5.81e-1     5 1.86e-2 Prepro…\n11   0.000162              14 rmse    standard     8.89e+7     5 3.96e+6 Prepro…\n12   0.000162              14 rsq     standard     5.81e-1     5 1.80e-2 Prepro…\n13   0.000000411            7 rmse    standard     8.80e+7     5 3.66e+6 Prepro…\n14   0.000000411            7 rsq     standard     5.86e-1     5 1.96e-2 Prepro…\n15   0.000803              13 rmse    standard     8.83e+7     5 3.51e+6 Prepro…\n16   0.000803              13 rsq     standard     5.84e-1     5 2.15e-2 Prepro…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(tree_fit)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator      mean     n  std_err .config\n            <dbl>      <int> <chr>   <chr>          <dbl> <int>    <dbl> <chr>  \n1    0.000000411           7 rmse    standard   88042857.     5 3661854. Prepro…\n2    0.000803             13 rmse    standard   88251763.     5 3514498. Prepro…\n3    0.0000000126          9 rmse    standard   88518890.     5 3808404. Prepro…\n4    0.0000204            10 rmse    standard   88832638.     5 3834097. Prepro…\n5    0.000162             14 rmse    standard   88870622.     5 3960107. Prepro…\n```\n:::\n:::\n\n\n\n## Finalisieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_tree_wf <-\n  wf_tree %>% \n  finalize_workflow(select_best(tree_fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n:::\n\n```{.r .cell-code}\nbest_tree_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (regression)\n\nMain Arguments:\n  cost_complexity = 4.11198549660991e-07\n  tree_depth = 7\n\nComputational engine: rpart \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_last_fit <-\n  fit(best_tree_wf, data = d_train)\n\ntree_last_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 3000 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n  1) root 3000 5.672651e+19   66725850  \n    2) budget< 18.32631 2845 1.958584e+19   46935270  \n      4) budget< 17.19976 2252 5.443953e+18   25901120  \n        8) popularity< 9.734966 1745 1.665118e+18   17076460  \n         16) popularity< 5.761331 1019 3.184962e+17    8793730  \n           32) budget< 15.44456 782 1.408243e+17    6074563  \n             64) popularity< 1.517383 293 1.907705e+16    3025921  \n              128) runtime>=46.5 284 6.431604e+15    2487837 *\n              129) runtime< 46.5 9 9.968486e+15   20005440 *\n             65) popularity>=1.517383 489 1.173924e+17    7901255  \n              130) runtime< 102.5 275 2.547281e+16    5299779 *\n              131) runtime>=102.5 214 8.766682e+16   11244270 *\n           33) budget>=15.44456 237 1.528117e+17   17765830  \n             66) popularity< 3.72614 121 6.186578e+16   12630020  \n              132) runtime< 133.5 98 3.493383e+16   10065970 *\n              133) runtime>=133.5 23 2.354245e+16   23555100 *\n             67) popularity>=3.72614 116 8.442526e+16   23123020  \n              134) budget< 15.84227 22 2.265705e+15   10929350 *\n              135) budget>=15.84227 94 7.812290e+16   25976860 *\n         17) popularity>=5.761331 726 1.178595e+18   28701940  \n           34) budget< 16.15249 484 6.504138e+17   21093220  \n             68) runtime< 107.5 313 3.896786e+17   17092250  \n              136) budget< 14.59463 198 1.157478e+17   12713890 *\n              137) budget>=14.59463 115 2.636000e+17   24630660 *\n             69) runtime>=107.5 171 2.465536e+17   28416630  \n              138) runtime>=117.5 97 8.067516e+16   23263720 *\n              139) runtime< 117.5 74 1.599268e+17   35171110 *\n           35) budget>=16.15249 242 4.441208e+17   43919380  \n             70) popularity< 7.596262 121 1.442289e+17   37076050  \n              140) popularity>=5.995644 102 7.485982e+16   33612470 *\n              141) popularity< 5.995644 19 6.157651e+16   55670010 *\n             71) popularity>=7.596262 121 2.885588e+17   50762700  \n              142) budget< 16.84798 88 1.993449e+17   42769810 *\n              143) budget>=16.84798 33 6.859993e+16   72077070 *\n        9) popularity>=9.734966 507 3.175231e+18   56273980  \n         18) budget< 15.36217 186 3.092335e+17   24880850  \n           36) popularity< 14.04031 151 1.743659e+17   20728170  \n             72) popularity< 11.34394 80 2.434569e+16   15019690  \n              144) popularity>=10.45217 46 5.224202e+15    9926190 *\n              145) popularity< 10.45217 34 1.631346e+16   21910890 *\n             73) popularity>=11.34394 71 1.444759e+17   27160260  \n              146) popularity>=11.49837 62 8.191069e+16   21675010 *\n              147) popularity< 11.49837 9 4.784879e+16   64947560 *\n           37) popularity>=14.04031 35 1.210294e+17   42796710  \n             74) runtime>=92.5 27 3.313350e+16   30755680  \n\n...\nand 70 more lines.\n```\n:::\n:::\n\n\n\n\n## Vorhersage Test-Sample\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(tree_last_fit, new_data = d_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,398 × 1\n        .pred\n        <dbl>\n 1   5299779.\n 2   5299779.\n 3  12713888.\n 4  23263724.\n 5   5299779.\n 6  23263724.\n 7  11244273.\n 8  65093270.\n 9  42769814.\n10 372118475.\n# ℹ 4,388 more rows\n```\n:::\n:::\n\n\n\n### RF\n\n## Fitten und Tunen\n\nUm Rechenzeit zu sparen,\nkann man das Objekt, wenn einmal berechnet,\nabspeichern unter `result_obj_path` auf der Festplatte und beim nächsten Mal importieren,\ndas geht schneller als neu berechnen.\n\n\nDas könnte dann z.B. so aussehen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (file.exists(result_obj_path)) {\n  rf_fit <- read_rds(result_obj_path)\n} else {\n  tic()\n  rf_fit <-\n    wf_rf %>% \n    tune_grid(\n      resamples = cv_scheme)\n  toc()\n}\n```\n:::\n\n\n\n*Achtung* Ein Ergebnisobjekt von der Festplatte zu laden ist *gefährlich*.\nWenn Sie Ihr Modell verändern, aber vergessen, das Objekt auf der Festplatte zu aktualisieren,\nwerden Ihre Ergebnisse falsch sein (da auf dem veralteten Objekt beruhend),\nohne dass Sie durch eine Fehlermeldung von R gewarnt würden!\n\n\n\nSo kann man das Ergebnisobjekt auf die Festplatte schreiben:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(rf_fit, file = \"objects/tmbd_rf_fit1.rds\")\n```\n:::\n\n\n\nAber wir berechnen lieber neu:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nrf_fit <-\n  wf_rf %>% \n  tune_grid(\n    resamples = cv_scheme\n    #grid = 2\n    )\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n24.613 sec elapsed\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(rf_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 8\n    mtry min_n .metric .estimator         mean     n      std_err .config       \n   <int> <int> <chr>   <chr>             <dbl> <int>        <dbl> <chr>         \n 1     3    27 rmse    standard   82999898.        5 3316009.     Preprocessor1…\n 2     3    27 rsq     standard          0.627     5       0.0222 Preprocessor1…\n 3     1    20 rmse    standard   81777078.        5 3735199.     Preprocessor1…\n 4     1    20 rsq     standard          0.639     5       0.0227 Preprocessor1…\n 5     3     6 rmse    standard   83872326.        5 2426800.     Preprocessor1…\n 6     3     6 rsq     standard          0.620     5       0.0281 Preprocessor1…\n 7     2    17 rmse    standard   82048483.        5 2922265.     Preprocessor1…\n 8     2    17 rsq     standard          0.634     5       0.0242 Preprocessor1…\n 9     2    31 rmse    standard   82635263.        5 3356051.     Preprocessor1…\n10     2    31 rsq     standard          0.630     5       0.0224 Preprocessor1…\n11     2    37 rmse    standard   82825412.        5 3452599.     Preprocessor1…\n12     2    37 rsq     standard          0.629     5       0.0225 Preprocessor1…\n13     2    22 rmse    standard   82197145.        5 3036229.     Preprocessor1…\n14     2    22 rsq     standard          0.633     5       0.0235 Preprocessor1…\n15     2    35 rmse    standard   82778207.        5 3453777.     Preprocessor1…\n16     2    35 rsq     standard          0.629     5       0.0226 Preprocessor1…\n17     1     9 rmse    standard   81326037.        5 3287307.     Preprocessor1…\n18     1     9 rsq     standard          0.641     5       0.0237 Preprocessor1…\n19     3    12 rmse    standard   83024317.        5 2579892.     Preprocessor1…\n20     3    12 rsq     standard          0.626     5       0.0264 Preprocessor1…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nselect_best(rf_fit)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1     1     9 Preprocessor1_Model09\n```\n:::\n:::\n\n\n\n\n\n## Finalisieren\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <-\n  wf_rf %>% \n  finalize_workflow(select_best(rf_fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <-\n  fit(final_wf, data = d_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_preds <- \n  final_fit %>% \n  predict(new_data = d_test) %>% \n  bind_cols(d_test)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsubmission <-\n  final_preds %>% \n  select(id, revenue = .pred)\n```\n:::\n\n\n\nAbspeichern und einreichen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(submission, file = \"submission.csv\")\n```\n:::\n\n\n\n## Kaggle Score\n\nDiese Submission erzielte einen Score von **2.7664** (RMSLE).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsol <- 2.7664\n```\n:::\n\n\n\n\n\n\n---\n\nCategories: \n\n- ds1\n- tidymodels\n- statlearning\n- tmdb\n- trees\n- num\n\n",
    "supporting": [
      "tmdb02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}