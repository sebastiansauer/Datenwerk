{
  "hash": "9ab31d7f03e46e1aa9c9c0e24de8efbd",
  "result": {
    "engine": "knitr",
    "markdown": "---\nextype: schoice\nexsolution: 1\nexname: corrplot\ndate: '2023-05-17'\nslug: tidytext\ntitle: tidytext\ncategories: schoice\n\n---\n\n\n\n\n\n\n# Aufgabe\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(tidyverse)\ntext_df %>%\n  unnest_tokens(word, text) %>% \n  filter(str_detect(word, \"[a-z]\"))\n```\n:::\n\n\n\nWelche Aussage zu dieser Syntax ist korrekt?\n\n\nAnswerlist\n----------\n* Der Text wird so \"entschachtelt\", dass in jeder Zelle nur noch ein Wort steht. Dabei werden so viele Spalten angehängt, wie Wörter in der betreffenden Zelle standen.\n* Durch `filter()` in Verbindung mit `str_detect()` werden alle Buchstaben von a bis z entfernt.\n* Ein Token bedeutet hier so viel wie eine numerische Analyseeinheit.\n* Der Text wird in das *lange* Format umwandelt, so dass nur noch ein Wort pro Zeile steht.\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\nD: Es entsteht ein *langer* Dataframe.\n\n\n\n---\n\nCategories: \n\nschoice\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}