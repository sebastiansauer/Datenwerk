{
  "hash": "df3dba90290f20443544e27718648e98",
  "result": {
    "markdown": "---\nexname: tidymodels-lasso\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- tidymodels\n- statlearning\n- lasso\n- lm\n- string\ndate: '2023-05-17'\nslug: tidymodels-lasso\ntitle: tidymodels-lasso\n\n---\n\n\n\n\n\n# Aufgabe\n\n<!-- Schreiben Sie eine Vorlage für eine prädiktive Analyse mit Tidymodels! -->\n\nSchreiben Sie eine prototypische Analyse für ein Vorhersagemodell mit dem *Lasso*.\n\nHinweise:\n\n- Tunen Sie die Penalisierung.\n- Verwenden Sie Kreuzvalidierung.\n- Verwenden Sie Standardwerte, wo nicht anders angegeben.\n- Fixieren Sie Zufallszahlen auf den Startwert 42.\n- Verwenden Sie den Datensatz `penguins`.\n- Modellformel: `body_mass_g ~ .`\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd <- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd <-\n  d %>% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split <- initial_split(d)\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n# model:\nmod_lasso <-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl <- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain <- \n  recipe(body_mass_g ~  ., data = d_train) %>% \n  update_role(\"...1\", new_role = \"id\") %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked <- \n  prep(rec1_plain) %>% bake(new_data = NULL)\n\nna_n <- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 <-\n  workflow() %>% \n  add_model(mod_lasso) %>% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit <-\n  wf1 %>% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n7.995 sec elapsed\n```\n:::\n\n```{.r .cell-code}\n# best candidate:\nshow_best(wf1_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 7\n   penalty .metric .estimator  mean     n std_err .config              \n     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 1.97e-10 rmse    standard    281.    10    12.0 Preprocessor1_Model01\n2 4.54e- 9 rmse    standard    281.    10    12.0 Preprocessor1_Model02\n3 8.93e- 8 rmse    standard    281.    10    12.0 Preprocessor1_Model03\n4 1.75e- 7 rmse    standard    281.    10    12.0 Preprocessor1_Model04\n5 1.65e- 6 rmse    standard    281.    10    12.0 Preprocessor1_Model05\n```\n:::\n\n```{.r .cell-code}\n# finalize wf:\nwf1_final <-\n  wf1 %>% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final <-\n  wf1_final %>% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard     326.    Preprocessor1_Model1\n2 rsq     standard       0.819 Preprocessor1_Model1\n```\n:::\n:::\n\n\nMan beachte: Für regulierte Modelle sind Zentrierung und Skalierung nötig.\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- statlearning\n- lasso\n- lm\n- string\n\n",
    "supporting": [
      "tidymodels-lasso_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}