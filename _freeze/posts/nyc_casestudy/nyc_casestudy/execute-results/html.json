{
  "hash": "86132768bf710214c7e5b769f15e2083",
  "result": {
    "engine": "knitr",
    "markdown": "---\nextype: string\nexsolution: r sol\nexname: nyc_casestudy\nexpoints: 25\ncategories:\n- ds1\n- tidymodels\n- statlearning\n- string\ndate: '2023-05-17'\nslug: nyc_casestudy\ntitle: nyc_casestudy\n\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\n\nFallstudie \n\n\nEine Analystin untersucht Verspätungen der New Yorker Flüge. Sie gibt folgenden Code ein und erhält unten stehendes Ergebnis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sjmisc)\nlibrary(tidyverse)\nlibrary(caret)\ndata(flights, package = \"nycflights13\")\n\nmy_crossval <- trainControl(method = \"cv\",\n                            number = 5,\n                            allowParallel = TRUE,\n                            verboseIter = FALSE)\n\ndoMC::registerDoMC(cores = 2)\n\n\nflights2 <- flights %>%\n  select_if(is.numeric) %>% \n  drop_na() %>% \n  select(-c(year, dep_delay)) %>% \n  std(suffix = \"\")  \n\nn_uebung <- round(.8 * nrow(flights2), digits = 0)\n\nuebung_index <- sample(1:nrow(flights2), size = n_uebung)\n\nuebung_df <- filter(flights2, row_number() %in% uebung_index)\ntest_df <- filter(flights2, !(row_number() %in% uebung_index))\n\nlm_fit1 <- train(arr_delay ~ .,\n                 data = uebung_df,\n                 method = \"lm\",\n                 trControl = my_crossval)\n\nsummary(lm_fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = .outcome ~ ., data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0953 -0.4702 -0.2033  0.1599 29.2400 \n\nCoefficients: (1 not defined because of singularities)\n                 Estimate Std. Error  t value Pr(>|t|)    \n(Intercept)    -0.0009503  0.0017921   -0.530   0.5959    \nmonth          -0.0017658  0.0017979   -0.982   0.3260    \nday             0.0009082  0.0017928    0.507   0.6124    \ndep_time        0.8225147  0.0062273  132.081   <2e-16 ***\nsched_dep_time -0.5863701  0.0441450  -13.283   <2e-16 ***\narr_time       -0.2787396  0.0029549  -94.332   <2e-16 ***\nsched_arr_time  0.0968838  0.0036361   26.645   <2e-16 ***\nflight          0.0385112  0.0020520   18.768   <2e-16 ***\nair_time        1.4220104  0.0132370  107.427   <2e-16 ***\ndistance       -1.4407468  0.0132872 -108.431   <2e-16 ***\nhour            0.0802044  0.0435578    1.841   0.0656 .  \nminute                 NA         NA       NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9171 on 261866 degrees of freedom\nMultiple R-squared:  0.1515,\tAdjusted R-squared:  0.1514 \nF-statistic:  4675 on 10 and 261866 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nIm Folgenden untersucht sie die prädiktive Güte am Testdatensatz.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1_pred <- predict(lm_fit1, newdata = test_df)\n\nlm1_pred_fit <- postResample(pred = lm1_pred, obs = test_df$arr_delay)\nlm1_pred_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     RMSE  Rsquared       MAE \n0.9372781 0.1516473 0.5521067 \n```\n\n\n:::\n:::\n\n\nSchließlich berechnet sie noch ein Random-Forest-Modell. Um Zeit zu sparen, verringert sie den Datensatz in dieser ersten Analyse.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_grid <- data.frame(\n  .mtry = c(4, 5, 6, 7),\n  .splitrule = \"variance\",\n  .min.node.size = 5)\n\nuebung_df_small <- sample_n(uebung_df, size = 1000)\n\nrf_fit1 <- train(arr_delay ~ .,\n                 data = uebung_df_small,\n                 method = \"ranger\",\n                 trControl = my_crossval)\n```\n:::\n\n\n\nAuch hier lässt sie sich wieder die Gütekoeffizienten ausgeben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf1_pred <- predict(rf_fit1, newdata = test_df)\nrf1_pred_fit <- postResample(pred = rf1_pred, obs = test_df$arr_delay)\nrf1_pred_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     RMSE  Rsquared       MAE \n0.6001004 0.7181543 0.3510000 \n```\n\n\n:::\n:::\n\n\n\n\n\n\na) Interpretieren Sie die Koeffizienten des Prädiktors NA des Modells `lm1` (s. Spalten `Estimate` bis `Pr(>|t|)`)!\nb) Welcher Prädiktor des Modells `lm1` ist am wichtigsten? Begründen Sie Ihre Antwort!\nc) Interpretieren Sie die Ausgabe des Objekts `lm1_pred_fit`!\nd) Welche Gefahren bzw. Probleme können damit verbunden sein, dass die Analystin die Stichprobe auf $n=1000$ verkleinert?\ne) Vergleichen Sie die Gütekoeffizienten der beiden Modelle im Test-Datensatz!\nf) Diskutieren Sie einen (möglichen) Grund für die Unterschiede in den Gütekriterien zwischen den beiden Modellen!\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n**Interpretieren Sie die Koeffizienten des Prädiktors NA des Modells `lm1`!**\n\n- Estimate: Punktschätzer des Einflussgewichts\n- Std. Err: Standardfehler, ein Koeffizient zur Beurteilung der (Un-)Genauigkeit des Punktschätzers\n- t value: Estimate geteilt durch Std. Error, Signal-Noise-Ratio, z-Wert\n- Pr: p-Wert\n\n**Welcher Prädiktor des Modells `lm1` ist am wichtigsten? Begründen Sie Ihre Antwort!**\n\n- Eine Möglichkeit zur Bestimmung der Prädiktorenrelevanz besteht darin, den Prädiktor mit höchstem Absolutwert in der Spalte `t value` heranzuziehen. \n- In diesem Fall ist das `dep_time`.\n\n**Interpretieren Sie die Ausgabe des Objekts `lm1_pred_fit`!**\n\n- Es werden drei Gütekriterien berichtet: R-Quadrat, MSE und MAE. MSE gibt den mittleren Quadratfehler der vorhersage an; MAE den mittleren Absolutfehler.\n- Je höher $R^2$ und je geringer MAE bzw. MSE sind, desto besser ist das Modell.\n\n\n**Welche Gefahren bzw. Probleme können damit verbunden sein, dass die Analystin die Stichprobe auf $n=1000$ verkleinert?**\n\n- Kleinere Stichproben schätzen die Population ungenauer.\n- Durch die Stichprobenziehung könnten sich die Verteilungen verändern, was wiederum einen Einfluss auf die Vorhersagen haben kann.\n\n**Vergleichen Sie die Gütekoeffizienten der beiden Modelle im Test-Datensatz!**\n\n- Das Random-Forest-Modell hat deutlich besser abgeschnitten als das lineare Modell.\n\n\n**Diskutieren Sie einen (möglichen) Grund für die Unterschiede in den Gütekriterien zwischen den beiden Modellen!**\n\n- Ein lineares Modell wird dort gute Vorhersagen leisten, wo seine Voraussetzungen erfüllt sind. Eine wichtige Vorausssetzung sind lineare Beziehungen der Prädiktoren zum Kriterium. \n- Hier könnte der Fall vorliegen, dass die Beziehungen nicht linear sind, so dass ein Modell - wie das Random-Forest-Modell - das nicht auf lineare Beziehungen abzielt, bessere Vorhersagen treffen kann.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsol <- \"s. text\"\n```\n:::\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- ds1\n- tidymodels\n- statlearning\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}