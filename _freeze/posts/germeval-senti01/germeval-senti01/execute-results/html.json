{
  "hash": "a567c73dfdc5dfda64dcc034b5fe47cf",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval-senti01\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- tidymodels\n- textmining\n- prediction\n- sentimentanalysis\n- germeval\n- string\ndate: '2023-11-11'\nslug: germeval-senti01\ntitle: germeval-senti01\n\n---\n\n\n\n\n\n\n# Aufgabe\n\n\nFühren Sie eine Sentiment-Analyse als Teils eines Tidymodels-Rezept durch.\nModellieren Sie dann mit einem einfachen linearen Modell die abhängige Variable. \n\nVerwenden Sie diesen Datensatz:\n\n\n\n::: {.cell}\n\n:::\n\n\n\nDie AV ist `c1`. \n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Setup\n\n\n::: {.cell}\n\n:::\n\n\n\n## Daten\n\n`c2` brauchen wir hier nicht:\n\n\n::: {.cell}\n\n:::\n\n\n\n## Rezept\n\nRezept definieren:\n\n\n::: {.cell}\n\n:::\n\n\n\n`step_mutate` ergänzt für die erzeugte (mutierte) Variable automatisch eine Rolle im Rezept, nimmt sie also als Prädiktor auf.\n\n\nMal schauen:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  number operation type   trained skip  id          \n   <int> <chr>     <chr>  <lgl>   <lgl> <chr>       \n1      1 step      mutate FALSE   FALSE mutate_dOdAD\n2      2 step      rm     FALSE   FALSE rm_Z4Hvw    \n```\n\n\n:::\n:::\n\n\n\nPreppen und backen:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n8.616 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n     id c1       n_emo\n  <int> <fct>    <dbl>\n1     1 OTHER    0.004\n2     2 OTHER   -0.347\n3     3 OTHER    0    \n4     4 OTHER    0    \n5     5 OFFENSE  0    \n6     6 OTHER   -0.346\n```\n\n\n:::\n:::\n\n\n\n## Model\n\n\n::: {.cell}\n\n:::\n\n\n\n## Workflow\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n8.491 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_mutate()\n• step_rm()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n(Intercept)        n_emo  \n     0.6819       0.4802  \n\nDegrees of Freedom: 5008 Total (i.e. Null);  5007 Residual\nNull Deviance:\t    6402 \nResidual Deviance: 6392 \tAIC: 6396\n```\n\n\n:::\n:::\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n4.654 sec elapsed\n```\n\n\n:::\n:::\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.660\n2 kap      binary         0    \n```\n\n\n:::\n:::\n\n\n\n## Baseline\n\nEin einfaches Referenzmodell ist, einfach die häufigste Kategorie vorherzusagen:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  c1          n\n  <chr>   <int>\n1 OFFENSE  1688\n2 OTHER    3321\n```\n\n\n:::\n:::\n\n\n\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- textmining\n- prediction\n- sentimentanalysis\n- germeval\n- string\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}