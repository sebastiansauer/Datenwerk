{
  "hash": "366096d103f8fa0f99d6e69d807e1ebf",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: germeval-senti01\nexpoints: 1\nextype: string\nexsolution: NA\ncategories:\n- tidymodels\n- textmining\n- prediction\n- sentiment\n- germeval\n- string\ndate: '2023-11-16'\nslug: germeval-senti01\ntitle: germeval-senti01\n\n---\n\n\n\n\n\n\n# Aufgabe\n\n\nFühren Sie eine Sentiment-Analyse als Teils eines Tidymodels-Rezept durch.\nModellieren Sie dann mit einem einfachen linearen Modell die abhängige Variable. \n\nVerwenden Sie diesen Datensatz:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analyse-Daten:\ndata(\"germeval_train\", package = \"pradadata\")\ndata(\"germeval_test\", package = \"pradadata\")\n# Sentiment-Daten\ndata(\"sentiws\", package = \"pradadata\")\n```\n:::\n\n\n\nDie AV ist `c1`. \n\nHinweise:\n\n- Orientieren Sie sich im Übrigen an den [allgemeinen Hinweisen des Datenwerks](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(syuzhet)  # get_sentiment\nlibrary(tidymodels)\nlibrary(tictoc)\n```\n:::\n\n\n\n## Daten\n\n`c2` brauchen wir hier nicht:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  germeval_train |> \n  select(-c2) |> \n  as_tibble()\n```\n:::\n\n\n\n## Rezept\n\nRezept definieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <-\n  recipe(c1 ~ ., data = d_train) |> \n  update_role(id, new_role = \"id\")  |> \n  #update_role(c2, new_role = \"ignore\") |> \n  update_role(text, new_role = \"ignore\") |> \n  step_mutate(n_emo = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = sentiws))  |> \n  step_rm(text)  # Datensatz verschlanken\n```\n:::\n\n\n\n`step_mutate` ergänzt für die erzeugte (mutierte) Variable automatisch eine Rolle im Rezept, nimmt sie also als Prädiktor auf.\n\n\nMal schauen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  number operation type   trained skip  id          \n   <int> <chr>     <chr>  <lgl>   <lgl> <chr>       \n1      1 step      mutate FALSE   FALSE mutate_XC8s1\n2      2 step      rm     FALSE   FALSE rm_g6jF6    \n```\n\n\n:::\n:::\n\n\n\nPreppen und backen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nrec_prepped <- prep(rec)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n12.92 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_prepped\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_baked <- bake(rec_prepped, new_data = NULL)\nhead(rec_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n     id c1       n_emo\n  <int> <fct>    <dbl>\n1     1 OTHER    0.004\n2     2 OTHER   -0.347\n3     3 OTHER    0    \n4     4 OTHER    0    \n5     5 OFFENSE  0    \n6     6 OTHER   -0.346\n```\n\n\n:::\n:::\n\n\n\n## Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <-\n  logistic_reg()\n```\n:::\n\n\n\n## Workflow\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf <- workflow() |> \n  add_recipe(rec) |> \n  add_model(mod)\n```\n:::\n\n\n\n\n## Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nfit1 <-\n  fit(wf,\n      data = d_train)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n12.64 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_mutate()\n• step_rm()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n(Intercept)        n_emo  \n     0.6819       0.4802  \n\nDegrees of Freedom: 5008 Total (i.e. Null);  5007 Residual\nNull Deviance:\t    6402 \nResidual Deviance: 6392 \tAIC: 6396\n```\n\n\n:::\n:::\n\n\n## Test-Set-Güte\n\n\nVorhersagen im Test-Set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\npreds <-\n  predict(fit1, new_data = germeval_test)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n7.397 sec elapsed\n```\n\n\n:::\n:::\n\n\nUnd die Vorhersagen zum Test-Set hinzufügen, damit man `TRUTH` und `ESTIMATE` vergleichen kann:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  germeval_test |> \n  bind_cols(preds) |> \n  mutate(c1 = as.factor(c1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics(d_test,\n        truth = c1,\n        estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.660\n2 kap      binary         0    \n```\n\n\n:::\n:::\n\n\n\n## Baseline\n\nEin einfaches Referenzmodell ist, einfach die häufigste Kategorie vorherzusagen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train |> \n  count(c1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  c1          n\n  <chr>   <int>\n1 OFFENSE  1688\n2 OTHER    3321\n```\n\n\n:::\n:::\n\n\n\n\n\n\n---\n\nCategories: \n\n- tidymodels\n- textmining\n- prediction\n- sentimentanalysis\n- germeval\n- string\n\n",
    "supporting": [
      "germeval-senti01_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}