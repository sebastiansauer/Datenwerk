{
  "hash": "0d945ebff735a48e93f399d2a436c880",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: tmdb04\nextype: num\nexsolution: r sol\nextol: 0.2\nexpoints: 1\ncategories:\n- ds1\n- tidymodels\n- statlearning\n- tmdb\n- random-forest\n- num\ndate: '2023-05-17'\nslug: tmdb04\ntitle: tmdb04\n\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nWir bearbeiten hier die Fallstudie [TMDB Box Office Prediction - \nCan you predict a movie's worldwide box office revenue?](https://www.kaggle.com/competitions/tmdb-box-office-prediction/overview),\nein [Kaggle](https://www.kaggle.com/)-Prognosewettbewerb.\n\nZiel ist es, genaue Vorhersagen zu machen,\nin diesem Fall für Filme.\n\n\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n```\n:::\n\n\n\n# Aufgabe\n\nReichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\n\n\nHinweise:\n\n- Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.\n- Halten Sie das Modell so *einfach* wie möglich. Verwenden Sie als Algorithmus die *lineare Regression* ohne weitere Schnörkel.\n- Logarithmieren Sie `budget` und `revenue`.\n- Minimieren Sie die Vorverarbeitung (`steps`) so weit als möglich.\n- Verwenden Sie `tidymodels`.\n- Die Zielgröße ist `revenue` in Dollars; nicht in \"Log-Dollars\". Sie müssen also rücktransformieren,\nwenn Sie `revenue` logarithmiert haben, bevor Sie Ihre Prognose einreichen.\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\n# Vorbereitung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(finetune)\nlibrary(doParallel)\nlibrary(tictoc)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_raw <- read_csv(d_train_path)\nd_test_raw <- read_csv(d_test_path)\n```\n:::\n\n\n\n\nSicher ist sicher:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_backup <- d_train_raw\n```\n:::\n\n\n\n\nMal einen Blick werfen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(d_train_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,000\nColumns: 23\n$ id                    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection <chr> \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                <dbl> 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                <chr> \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              <chr> NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               <chr> \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     <chr> \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        <chr> \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              <chr> \"When Lou, who has become the \\\"father of the In…\n$ popularity            <dbl> 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           <chr> \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  <chr> \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  <chr> \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          <chr> \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               <dbl> 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      <chr> \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                <chr> \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               <chr> \"The Laws of Space and Time are About to be Viol…\n$ title                 <chr> \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              <chr> \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  <chr> \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  <chr> \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               <dbl> 12314651, 95149435, 13092000, 16000000, 3923970,…\n```\n\n\n:::\n:::\n\n\n\n## Train-Set verschlanken\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_raw_reduced <-\n  d_train_raw %>% \n  select(id, popularity, runtime, revenue, budget) \n```\n:::\n\n\n\n## Test-Set verschlanken\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <-\n  d_test_raw %>% \n  select(id,popularity, runtime, budget) \n```\n:::\n\n\n\n\n\n## Outcome logarithmieren\n\nDer Outcome [sollte *nicht* im Rezept transformiert werden (vgl. Part 3, S. 30, in dieser Unterlage)](https://github.com/topepo/nyr-2020).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <-\n  d_train_raw_reduced %>% \n  mutate(revenue = if_else(revenue < 10, 10, revenue)) %>% \n  mutate(revenue = log(revenue)) \n```\n:::\n\n\n\nPrüfen, ob das funktioniert hat:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train$revenue %>% is.infinite() %>% any()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\nKeine unendlichen Werte mehr, auf dieser Basis können wir weitermachen.\n\n\n# Fehlende Werte prüfen\n\nWelche Spalten haben viele fehlende Werte?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easystats)\ndescribe_distribution(d_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariable   |     Mean |       SD |      IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n---------------------------------------------------------------------------------------------------------\nid         |  1500.50 |   866.17 |  1500.50 |    [1.00, 3000.00] |     0.00 |    -1.20 | 3000 |         0\npopularity |     8.46 |    12.10 |     6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime    |   107.86 |    22.09 |    24.00 |     [0.00, 338.00] |     1.02 |     8.19 | 2998 |         2\nrevenue    |    15.97 |     3.04 |     3.37 |      [2.30, 21.14] |    -1.60 |     3.82 | 3000 |         0\nbudget     | 2.25e+07 | 3.70e+07 | 2.90e+07 |   [0.00, 3.80e+08] |     3.10 |    13.23 | 3000 |         0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsum_isna <- function(x) {sum(is.na(x))}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train %>% \n  summarise(across(everything(), sum_isna))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n     id popularity runtime revenue budget\n  <int>      <int>   <int>   <int>  <int>\n1     0          0       2       0      0\n```\n\n\n:::\n:::\n\n\n\n\n# Rezept\n\n## Rezept definieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2 <-\n  recipe(revenue ~ ., data = d_train) %>% \n  step_mutate(budget = ifelse(budget == 0, NA, budget)) %>%  # log mag keine 0\n  step_log(budget) %>% \n  step_impute_knn(all_predictors()) %>% \n  step_dummy(all_nominal_predictors())  %>% \n  update_role(id, new_role = \"id\")\n\nrec2\n```\n:::\n\n\nSchauen Sie mal, der Log mag keine Nullen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1,2, NA, 0)\n\nlog(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0000000 0.6931472        NA      -Inf\n```\n\n\n:::\n:::\n\n\n\nDa $log(0) = -\\infty$. Aus dem Grund wandeln wir 0 lieber in `NA` um.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rec2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  number operation type       trained skip  id              \n   <int> <chr>     <chr>      <lgl>   <lgl> <chr>           \n1      1 step      mutate     FALSE   FALSE mutate_5IvPK    \n2      2 step      log        FALSE   FALSE log_HuvzM       \n3      3 step      impute_knn FALSE   FALSE impute_knn_bzUap\n4      4 step      dummy      FALSE   FALSE dummy_Gm3kh     \n```\n\n\n:::\n:::\n\n\n\n\n## Check das Rezept \n\nWir berechnen das Rezept:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2_prepped <-\n  prep(rec2, verbose = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\noper 1 step mutate [training] \noper 2 step log [training] \noper 3 step impute knn [training] \noper 4 step dummy [training] \nThe retained training set is ~ 0.12 Mb  in memory.\n```\n\n\n:::\n\n```{.r .cell-code}\nrec2_prepped\n```\n:::\n\n\n\nDas ist noch *nicht* auf einen Datensatz angewendet! Lediglich die `steps` wurden *vorbereitet*, \"präpariert\": z.B.\n\"Diese Dummy-Variablen impliziert das Rezept\".\n\n\nSo sieht das dann aus, wenn man das *präparierte* Rezept auf das Train-Sample anwendet:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked2 <-\n  rec2_prepped %>% \n  bake(new_data = NULL) \n\nhead(d_train_baked2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n     id popularity runtime budget revenue\n  <dbl>      <dbl>   <dbl>  <dbl>   <dbl>\n1     1      6.58       93   16.5    16.3\n2     2      8.25      113   17.5    18.4\n3     3     64.3       105   15.0    16.4\n4     4      3.17      122   14.0    16.6\n5     5      1.15      118   15.8    15.2\n6     6      0.743      83   15.9    15.0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked2 %>% \n  map_df(sum_isna)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n     id popularity runtime budget revenue\n  <int>      <int>   <int>  <int>   <int>\n1     0          0       0      0       0\n```\n\n\n:::\n:::\n\n\n\nKeine fehlenden Werte mehr *in den Prädiktoren*.\n\nNach fehlenden Werten könnte man z.B. auch so suchen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatawizard::describe_distribution(d_train_baked2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariable   |    Mean |     SD |     IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n-----------------------------------------------------------------------------------------------------\nid         | 1500.50 | 866.17 | 1500.50 |    [1.00, 3000.00] |     0.00 |    -1.20 | 3000 |         0\npopularity |    8.46 |  12.10 |    6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime    |  107.85 |  22.08 |   24.00 |     [0.00, 338.00] |     1.02 |     8.20 | 3000 |         0\nbudget     |   16.09 |   1.89 |    1.90 |      [0.00, 19.76] |    -2.93 |    18.71 | 3000 |         0\nrevenue    |   15.97 |   3.04 |    3.37 |      [2.30, 21.14] |    -1.60 |     3.82 | 3000 |         0\n```\n\n\n:::\n:::\n\n\n\nSo bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\n\n## Check Test-Sample\n\nDas Test-Sample backen wir auch mal, um zu prüfen, das alles läuft:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test_baked2 <-\n  bake(rec2_prepped, new_data = d_test)\n\nd_test_baked2 %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n     id popularity runtime budget\n  <dbl>      <dbl>   <dbl>  <dbl>\n1  3001       3.85      90   15.8\n2  3002       3.56      65   11.4\n3  3003       8.09     100   16.4\n4  3004       8.60     130   15.7\n5  3005       3.22      92   14.5\n6  3006       8.68     121   16.1\n```\n\n\n:::\n:::\n\n\n\nSieht soweit gut aus.\n\n\n# Kreuzvalidierung / Resampling\n\n\nHier ist *nur* aus Gründen der Rechenzeit auf kleine Werte von $v$ und $r$ ausgewichen worden.\nBesser wäre z.B. $v=10$ und $r=3$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_scheme <- vfold_cv(d_train,\n                      v = 3, \n                      repeats = 1)\n```\n:::\n\n\n\n# Modelle\n\n\n\n## LM\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_lm <-\n  linear_reg()\n```\n:::\n\n\n\n\n# Workflow-Set\n\nHier nur ein sehr kleiner Workflow-Set.\n\nDas ist übrigens eine gute Strategie: Erstmal mit einem kleinen Prozess anfangen,\nund dann sukzessive erweitern.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreproc2 <- list(rec1 = rec2)\nmodels2 <- list(lm1 = mod_lm)\n \n \nall_workflows2 <- workflow_set(preproc2, models2)\n```\n:::\n\n\n\n# Fitten und tunen\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmdb_model_set2 <-\n    all_workflows2 %>% \n    workflow_map(resamples = cv_scheme,\n                 control = control_grid(verbose = TRUE),\n                 fn = \"tune_race_anova\")\n```\n:::\n\n\n\n\n\n\n# Finalisieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmdb_model_set2 %>% \n  collect_metrics() %>% \n  arrange(-mean) %>% \n  head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 9\n  wflow_id .config          preproc model .metric .estimator  mean     n std_err\n  <chr>    <chr>            <chr>   <chr> <chr>   <chr>      <dbl> <int>   <dbl>\n1 rec1_lm1 Preprocessor1_M… recipe  line… rmse    standard   2.46      3  0.119 \n2 rec1_lm1 Preprocessor1_M… recipe  line… rsq     standard   0.349     3  0.0326\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model_params2 <-\nextract_workflow_set_result(tmdb_model_set2, \"rec1_lm1\") %>% \n  select_best()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n```\n\n\n:::\n\n```{.r .cell-code}\nbest_model_params2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  .config             \n  <chr>               \n1 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n## Finalisieren\n\nFinalisieren bedeutet:\n\n- Besten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell)\n- Den besten Workflow mit den optimalen Modell-Parametern ausstatten\n- Damit dann den ganzen Train-Datensatz fitten\n- Auf dieser Basis das Test-Sample vorhersagen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_wf2 <- \nall_workflows2 %>% \n  extract_workflow(\"rec1_lm1\")\n\nbest_wf2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_wf_finalized2 <- \n  best_wf2 %>% \n  finalize_workflow(best_model_params2)\n\nbest_wf_finalized2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n\n\n:::\n:::\n\n\n## Final Fit\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_final2 <-\n  best_wf_finalized2 %>% \n  fit(d_train)\n\nfit_final2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)   popularity      runtime       budget  \n    1.26186      0.03755      0.01289      0.80752  \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- \nfit_final2 %>% \n  predict(new_data = d_test)\n\nhead(preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred\n  <dbl>\n1  15.3\n2  11.4\n3  16.1\n4  16.0\n5  14.3\n6  16.1\n```\n\n\n:::\n:::\n\n\nAchtung, wenn die Outcome-Variable im Rezept verändert wurde,\ndann würde obiger Code *nicht* durchlaufen.\n\n\nGrund ist [hier](https://github.com/tidymodels/workflows/issues/63) beschrieben:\n\n\n>    When predict() is used, it only has access to the predictors (mirroring how this would work with new samples). Even if the outcome column is present, it is not exposed to the recipe. This is generally a good idea so that we can avoid information leakage.\n\n\n>    One approach is the use the skip = TRUE option in step_log() so that it will avoid that step during predict() and/or bake(). However, if you are using this recipe with the tune package, there will still be an issue because the metric function(s) would get the predictions in log units and the observed outcome in the original units.\n\n>   The better approach is, for simple transformations like yours, to log the outcome outside of the recipe (before data analysis and the initial split).\n\n## Submission df\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubmission_df <-\n  d_test %>% \n  select(id) %>% \n  bind_cols(preds) %>% \n  rename(revenue = .pred)\n\nhead(submission_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n     id revenue\n  <dbl>   <dbl>\n1  3001    15.3\n2  3002    11.4\n3  3003    16.1\n4  3004    16.0\n5  3005    14.3\n6  3006    16.1\n```\n\n\n:::\n:::\n\n\n\n\n## Zurücktransformieren\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubmission_df <-\n  submission_df %>% \n  mutate(revenue = exp(revenue)-1)\n\nhead(submission_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n     id   revenue\n  <dbl>     <dbl>\n1  3001  4435143.\n2  3002    91755.\n3  3003  9782986.\n4  3004  8573795.\n5  3005  1598106.\n6  3006 10061439.\n```\n\n\n:::\n:::\n\n\n\n[Hier](https://numpy.org/doc/stable/reference/generated/numpy.expm1.html) ein Beispiel,\nwarum $e^x-1$ genauer ist für kleine Zahlen als $e^x$.\n\nAbspeichern und einreichen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(submission_df, file = \"submission.csv\")\n```\n:::\n\n\n\n# Kaggle Score\n\nDiese Submission erzielte einen Score von **Score: 2.46249** (RMSLE).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsol <- 2.5\n```\n:::\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- ds1\n- tidymodels\n- statlearning\n- tmdb\n- random-forest\n- num\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}