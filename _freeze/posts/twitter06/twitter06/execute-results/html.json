{
  "hash": "168142cc4e6098feecab8748571f3cd5",
  "result": {
    "markdown": "---\nextype: string\nexsolution: NA\nexname: twitter06\nexpoints: 1\ncategories:\n- textmining\n- twitter\n- programming\ndate: '2022-10-28'\nslug: twitter06\ntitle: twitter06\n\n---\n\n\n\n\n\n\n\n\n\n\n# Exercise\n\n\nLaden Sie $n=10^k$ Tweets von Twitter herunter (mit $k=4$) via der Twitter API;\ndie Tweets sollen jeweils an eine prominente Person gerichtet sein.\n\nBeziehen Sie sich auf folgende Personen bzw. Twitter-Accounts:\n\n- `Markus_Soeder`\n- `karl_lauterbach`.\n\n\n\nBereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopwörter entfernen, Zahlen entfernen, ...).\n\nNutzen Sie die Daten dann,\num eine Sentimentanalyse zu erstellen.\n\n\nVergleichen Sie die Ergebnisse für alle untersuchten Personen.\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rtweet)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: SnowballC\n```\n:::\n\n```{.r .cell-code}\nlibrary(SnowballC)  # Stemming\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(sentiws, package = \"pradadata\")\n```\n:::\n\n\n\n\nZuerst muss man sich anmelden und die Tweets herunterladen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nauth <- rtweet_app(bearer_token = Bearer_Token)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets_to_kl <- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(tweets_to_kl, file = \"tweets_to_kl.rds\", compress = \"gz\")\ntweets_to_ms <- search_tweets(\"@Markus_Soeder\", n = 1e4, include_rts = FALSE)\n#write_rds(tweets_to_ms, file = \"tweets_to_ms.rds\", compress = \"gz\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nDie Vorverarbeitung pro Screenname packen wir in eine Funktion,\ndas macht es hinten raus einfacher:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprepare_tweets <- function(tweets){\n  \n  tweets %>% \n    select(full_text) %>% \n    unnest_tokens(output = word, input = full_text) %>% \n    anti_join(tibble(word = lsa::stopwords_de)) %>% \n    mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %>% \n    mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %>% \n    mutate(word = str_replace_na(word, \" +\")) %>% \n    drop_na()\n}\n```\n:::\n\n\n\nTest:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkl_prepped <- \n  prepare_tweets(tweets_to_kl_raw)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n\n```{.r .cell-code}\nhead(kl_prepped)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 1\n  word                     \n  <chr>                    \n1 tonline⁩                  \n2 spreche                  \n3 neuen                    \n4 pläne                    \n5 bundesgesundheitsminister\n6 karl_lauterbach⁩          \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nms_prepped <-\n  prepare_tweets(tweets_to_ms_raw)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n\n```{.r .cell-code}\nhead(ms_prepped)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 1\n  word         \n  <chr>        \n1 markus_soeder\n2 climate      \n3 activists    \n4 are          \n5 sometimes    \n6 depicted     \n```\n:::\n:::\n\n\n\nScheint zu passen.\n\n\n\nDie Sentimentanalyse packen wir auch in eine Funktion:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_tweets_sentiments <- function(tweets){\n  \n  tweets %>% \n    inner_join(sentiws) %>% \n    group_by(neg_pos) %>% \n    summarise(senti_avg = mean(value, na.rm = TRUE),\n              senti_sd = sd(value, na.rm = TRUE),\n              senti_n = n()) \n}\n```\n:::\n\n\n\nTest:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkl_prepped %>% \n  get_tweets_sentiments()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n```\n:::\n:::\n\n\n\n\n\nTest:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets_to_kl_raw %>% \n  prepare_tweets() %>% \n  get_tweets_sentiments()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\nJoining, by = \"word\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n```\n:::\n:::\n\n\nScheint zu passen.\n\n\nWir könnten noch die beiden Funktionen in eine wrappen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_sentiments <- function(tweets) {\n\n  tweets %>% \n    prepare_tweets() %>% \n    get_tweets_sentiments()\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets_to_kl_raw %>% \n  prep_sentiments()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\nJoining, by = \"word\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n```\n:::\n:::\n\n\n\nOkay, jetzt werden wir die Funktion auf jede Screenname bzw. die Tweets jedes Screennames an.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets_list <-\n  list(\n    kl = tweets_to_kl_raw, \n    ms = tweets_to_ms_raw)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsentis <-\n  tweets_list %>% \n  map_df(prep_sentiments, .id = \"id\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\nJoining, by = \"word\"\nJoining, by = \"word\"\nJoining, by = \"word\"\n```\n:::\n:::\n\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- textmining\n- twitter\n- programming\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}