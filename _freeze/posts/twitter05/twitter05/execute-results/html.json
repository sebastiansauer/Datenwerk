{
  "hash": "1e2c84fa4a296abeefe92098ce2831ea",
  "result": {
    "markdown": "---\nextype: string\nexsolution: NA\nexname: twitter05\nexpoints: 1\ncategories:\n- textmining\n- twitter\ndate: '2022-10-28'\nslug: twitter05\ntitle: twitter05\n\n---\n\n\n\n\n\n\n\n\n\n# Exercise\n\nLaden Sie $n=10^k$ Tweets von Twitter herunter (mit $k=2$) via der Twitter API; Suchterm soll sein \"@karl_lauterbach\".\nBereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopwörter entfernen, Zahlen entfernen, ...).\n\nNutzen Sie die Daten,\num eine Sentimentanalyse zu erstellen.\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Solution\n\n\n\nNutzen Sie die Daten der letzten Aufgabe,\num eine Sentimentanalyse zu erstellen.\n\n\n\n\nZuerst muss man sich anmelden und die Tweets herunterladen;\ndieser Teil ist hier nicht aufgeführt (s. andere Aufgaben).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rtweet)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: SnowballC\n```\n:::\n\n```{.r .cell-code}\nlibrary(SnowballC)  # Stemming\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkarl2 <- \n  karl1 %>% \n  select(full_text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkarl3 <- \n  karl2 %>% \n  unnest_tokens(output = word, input = full_text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkarl4 <- \nkarl3 %>% \n  anti_join(tibble(word = lsa::stopwords_de)) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkarl5 <- \n  karl4 %>% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %>% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %>% \n  mutate(word = str_replace_na(word, \" +\")) %>% \n  drop_na()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(sentiws, package = \"pradadata\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkarl7 <-\n  karl5 %>% \n  inner_join(sentiws)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkarl7 %>% \n  group_by(neg_pos) %>% \n  summarise(senti_avg = mean(value, na.rm = TRUE),\n            senti_sd = sd(value, na.rm = TRUE),\n            senti_n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.300    0.198      11\n2 pos         0.140    0.203      28\n```\n:::\n:::\n\n\nAchtung, Sentimentanalyse sollte *vor* dem Stemming kommen.\n\n\n\n\n\n\n\n---\n\nCategories: \n\n- textmining\n- twitter\n\n",
    "supporting": [
      "twitter05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}