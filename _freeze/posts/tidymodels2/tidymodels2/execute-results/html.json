{
  "hash": "62256f30293c43742c8f33f61f0d1500",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexname: tidymodels2\nextype: string\nexsolution: NA\ncategories:\n- ds1\n- tidymodels\n- prediction\n- yacsda\n- statlearning\n- error\n- string\n- mtcars\ndate: '2023-05-17'\nslug: tidymodels2\ntitle: tidymodels2\n\n---\n\n\n\n\n\n\n\n\n\n\n# Aufgabe\n\nEin merkwürdiger Fehler bzw. eine merkwürdige Fehlermeldung in Tidymodels -\ndas untersuchen wir hier genauer und versuchen das Phänomen zu erklären.\n\n\n\n\n*Aufgabe*\n\nErläutern Sie die Ursachen des Fehlers!\nSchalten Sie den Fehler an und ab,\num zu zeigen,\ndass Sie Ihn verstehen.\n\n\n\n\n# Startup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n:::\n\n\n\n\n\n\n# Data import\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"mtcars\")\n\nd_train <- mtcars %>% slice_head(n = 20)\nd_test <- mtcars %>% slice(21:n())\n```\n:::\n\n\n\n\n\n\n\n# Recipe\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_chosen <- c(\"hp\", \"disp\", \"am\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <- \n  recipe( ~ ., data = d_train) %>% \n  update_role(all_predictors(), new_role = \"id\") %>% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %>% \n  update_role(mpg, new_role = \"outcome\")\nrec1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train_baked <-\n  rec1 %>% \n  prep() %>% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 20\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n# Model 1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_lm <- linear_reg()\n```\n:::\n\n\n\n\n\n# Workflow 1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1 <-\n  workflow() %>% \n  add_model(model_lm) %>% \n  add_recipe(rec1)\n```\n:::\n\n\n\n\n\n\n\n#  Fit\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_fit1 <-\n  wf1 %>% \n  fit(d_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <-\n  lm_fit1 %>% \n  predict(d_test)\n\nhead(preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred\n  <dbl>\n1  22.6\n2  17.2\n3  17.4\n4  12.1\n5  14.9\n6  28.2\n```\n\n\n:::\n:::\n\n\n\n\n\nAus Gründen der Reproduzierbarkeit bietet es sich an, eine `SessionInfo` anzugeben:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] yardstick_1.3.1    workflowsets_1.1.0 workflows_1.1.4    tune_1.2.1        \n [5] rsample_1.2.1      recipes_1.1.0      parsnip_1.2.1      modeldata_1.3.0   \n [9] infer_1.0.7        dials_1.3.0        scales_1.3.0       broom_1.0.6       \n[13] tidymodels_1.2.0   lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n[17] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[21] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] foreach_1.5.2       jsonlite_1.8.8      splines_4.2.1      \n [4] prodlim_2023.03.31  GPfit_1.0-8         yaml_2.3.8         \n [7] globals_0.16.2      ipred_0.9-14        pillar_1.9.0       \n[10] backports_1.4.1     lattice_0.21-8      glue_1.6.2         \n[13] digest_0.6.33       hardhat_1.4.0       colorspace_2.1-0   \n[16] htmltools_0.5.7     Matrix_1.5-4.1      timeDate_4022.108  \n[19] pkgconfig_2.0.3     lhs_1.1.6           DiceDesign_1.9     \n[22] listenv_0.9.0       gower_1.0.1         lava_1.7.2.1       \n[25] tzdb_0.4.0          timechange_0.2.0    generics_0.1.3     \n[28] withr_3.0.0         furrr_0.3.1         nnet_7.3-19        \n[31] cli_3.6.2           survival_3.5-5      magrittr_2.0.3     \n[34] evaluate_0.23       fansi_1.0.6         future_1.33.0      \n[37] parallelly_1.36.0   MASS_7.3-60         class_7.3-22       \n[40] tools_4.2.1         data.table_1.15.4   hms_1.1.3          \n[43] lifecycle_1.0.4     munsell_0.5.0       compiler_4.2.1     \n[46] rlang_1.1.4         grid_4.2.1          iterators_1.0.14   \n[49] rstudioapi_0.16.0   htmlwidgets_1.6.4   rmarkdown_2.28     \n[52] gtable_0.3.4        codetools_0.2-19    R6_2.5.1           \n[55] knitr_1.48          fastmap_1.1.1       future.apply_1.11.0\n[58] utf8_1.2.4          stringi_1.8.3       parallel_4.2.1     \n[61] Rcpp_1.0.13         vctrs_0.6.5         rpart_4.1.21       \n[64] tidyselect_1.2.0    xfun_0.47          \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n</br>\n\n# Lösung\n\n\nDefiniert man das Rezept so:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2 <- recipe(mpg ~ hp + disp + am, data = d_train)\n```\n:::\n\n\n\n\nDann läuft `predict()` brav durch.\n\n\nAuch dieser Code funktioniert:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec3 <- \n  recipe(mpg ~ ., data = d_train) %>% \n  update_role(all_predictors(), new_role = \"id\") %>% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %>% \n  update_role(mpg, new_role = \"outcome\")\n```\n:::\n\n\n\n\n\n\nDas Problem von `rec1` scheint darin zu legen,\ndass die *Rollen* der Variablen nicht richtig gelöscht werden,\nwas `predict()` verwirrt:\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <- \n  recipe(mpg ~ ., data = d_train) %>% \n  update_role(all_predictors(), new_role = \"id\") %>% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %>% \n  update_role(mpg, new_role = \"outcome\")\nrec1\n```\n:::\n\n\n\n\n\nDaher läuft das Rezept `rec3` durch,\nwenn man zunächst alle Prädiktoren in ID-Variablen umwandelt: Damit\nsind alle Rollen wieder sauber.\n\n\n\n\n\n---\n\nCategories: \n\n- ds1\n- tidymodels\n- prediction\n- yacsda\n- statlearning\n- error\n- string\n\n",
    "supporting": [
      "tidymodels2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}