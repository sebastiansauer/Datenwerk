[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Many shiny pieces",
    "section": "",
    "text": "bertie-bott3\n\n\n\n\n\n\nprobability\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-simpson\n\n\n\n\n\n\nlm\n\n\nbayes\n\n\nregression\n\n\ncausal\n\n\n\n\n\n\n\n\n\nOct 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-lm2\n\n\n\n\n\n\nlm\n\n\nen\n\n\nregression\n\n\npenguins\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-lm\n\n\n\n\n\n\nlm\n\n\nen\n\n\nregression\n\n\npenguins\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsamples-nyc2\n\n\n\n\n\n\ninference\n\n\nstory\n\n\nyacsda\n\n\n\n\n\n\n\n\n\nSep 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsamples-nyc\n\n\n\n\n\n\ninference\n\n\nstory\n\n\nyacsda\n\n\n\n\n\n\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-easystats\n\n\n\n\n\n\ndatawrangling\n\n\ntidyverse\n\n\neda\n\n\nen\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nwikipedia\n\n\n\n\n\n\nsimulation\n\n\nprobability\n\n\nstory\n\n\nnullhypothesis\n\n\n\n\n\n\n\n\n\nAug 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nflights-delay-simplified\n\n\n\n\n\n\nlm\n\n\nregression\n\n\ninteraction\n\n\nyacsda\n\n\n\n\n\n\n\n\n\nJun 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nflights-delay\n\n\n\n\n\n\nlm\n\n\nregression\n\n\ninteraction\n\n\nyacsda\n\n\n\n\n\n\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmario-compare-models\n\n\n\n\n\n\nlm\n\n\nregression\n\n\ninteraction\n\n\n\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nflights-yacsda-eda\n\n\n\n\n\n\neda\n\n\nyacsda\n\n\nvariability\n\n\nassociation\n\n\n\n\n\n\n\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\noecd-yacsda\n\n\n\n\n\n\neda\n\n\ndatawrangling\n\n\nvis\n\n\nyacsda\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsmartphone1\n\n\n\n\n\n\nR\n\n\neda\n\n\ndatawrangling\n\n\nvis\n\n\nyacsda\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-vis-bodymass1\n\n\n\n\n\n\nvis\n\n\n\n\n\n\n\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-vis-bodymass2\n\n\n\n\n\n\nvis\n\n\n\n\n\n\n\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nmutate03\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr-mtcars1\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nimport-xls\n\n\n\n\n\n\nR\n\n\ndata\n\n\n\n\n\n\n\n\n\nApr 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nr-quiz\n\n\n\n\n\n\nR\n\n\nen\n\n\nquiz\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-df-r\n\n\n\n\n\n\nprobability\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKausal\n\n\n\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nJan 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm_parameterzahl_simple\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nparameters\n\n\n\n\n\n\n\n\n\nJan 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nchatgpt-sentiment-loop-all\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\ntransformer\n\n\nchatgpt\n\n\nsentiment\n\n\n\n\n\n\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkollision-eignung\n\n\n\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nhintertuer\n\n\n\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsaratoga-cor1\n\n\n\n\n\n\nR\n\n\nvis\n\n\ncausal\n\n\neda\n\n\n\n\n\n\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsaratoga-cor2\n\n\n\n\n\n\nR\n\n\nvis\n\n\ncausal\n\n\neda\n\n\n\n\n\n\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWskt-Schluckspecht\n\n\n\n\n\n\npost\n\n\nbayes\n\n\nregression\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nchatgpt-sentiment-simple\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\ntransformer\n\n\nchatgpt\n\n\nsentiment\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-glm\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\ntune\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-elasticnet\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\nelasticnet\n\n\ntune\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nScikit-Learn-LLM Zero Shot Learners\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\ntransformer\n\n\nchatgpt\n\n\nsentiment\n\n\nscikit\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nchatgpt-sentiment-loop\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\ntransformer\n\n\nchatgpt\n\n\nsentiment\n\n\n\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-rf-tune\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\nrandom-forest\n\n\ntune\n\n\n\n\n\n\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-xgb-tune\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\nxgb\n\n\ntune\n\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-rf-plain\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\nrandom-forest\n\n\ntune\n\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-xgb-plain\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\nxgb\n\n\ntune\n\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-wordvec-xgb\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\nxgb\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwfsets1\n\n\n\n\n\n\nR\n\n\nstatlearning\n\n\ntidymodels\n\n\nwfsets\n\n\ntemplate\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval10-wordvec-rf\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-emojis\n\n\n\n\n\n\ntextmining\n\n\ntidymodels\n\n\ncount\n\n\ngermeval\n\n\nemoji\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval04\n\n\n\n\n\n\n2023\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval03-sent-textfeatures-rand-for\n\n\n\n\n\n\n2023\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nsentiment\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval02\n\n\n\n\n\n\ntextmining\n\n\ntidymodels\n\n\ngermeval\n\n\nsentiment\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval05\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nwordvec\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nemojis1\n\n\n\n\n\n\nemoji\n\n\ntextmining\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval08-schimpf\n\n\n\n\n\n\n2023\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-words01\n\n\n\n\n\n\ntextmining\n\n\ntidymodels\n\n\ncount\n\n\ngermeval\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPupil-size\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nregression\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval09-tfidf\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval01-textfeatures\n\n\n\n\n\n\n2023\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval06\n\n\n\n\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nwordvec\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmovie-sentiment1\n\n\n\n\n\n\ntextmining\n\n\nimdb\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval-textfeatures01\n\n\n\n\n\n\ntidymodels\n\n\ntextmining\n\n\nprediction\n\n\nsentiment\n\n\ngermeval\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-emoji-emo\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\nemoji\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval-senti01\n\n\n\n\n\n\ntidymodels\n\n\ntextmining\n\n\nprediction\n\n\nsentiment\n\n\ngermeval\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval08-extract-spacy\n\n\n\n\n\n\nwordvec\n\n\ntextmining\n\n\npython\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReThink4e1\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-08-name-clash\n\n\n\n\n\n\nR\n\n\nerror\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-07\n\n\n\n\n\n\nR\n\n\nerror\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-remove-na\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nna-per-col\n\n\n\n\n\n\nR\n\n\ndatawrangling\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngermeval07\n\n\n\n\n\n\n2023\n\n\ntextmining\n\n\ndatawrangling\n\n\ngermeval\n\n\nprediction\n\n\ntidymodels\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-error1introd\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\nerror\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-vorlage3\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-remove-na2\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkekse02\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npostvert-vis-zwielicht\n\n\n\n\n\n\n2023\n\n\nvis\n\n\nbayes\n\n\npost\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m5\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nbayes-grid\n\n\nrethink-chap2\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbath42\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nnum\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m2\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\nbayes\n\n\nrethink-chap2\n\n\nstring\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m3\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nrethink-chap2\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m4\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nbayes-grid\n\n\nrethink-chap2\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntotale-Wskt1\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nbayes\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngroesse01\n\n\n\n\n\n\n2023\n\n\nbayes\n\n\nbayesbox\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGem-Wskt2\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\ncloze\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz10\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\ndistributions\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz17\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\noptions-print\n\n\n\n\n\n\n2023\n\n\nR\n\n\ntidyverse\n\n\nmarkdown\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nalphafehler-inflation3\n\n\n\n\n\n\nprobability\n\n\nR\n\n\ninference\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz19\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\ndistributions\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nalphafehler-inflation4\n\n\n\n\n\n\nprobability\n\n\nR\n\n\ninference\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKaefer2\n\n\n\n\n\n\nR\n\n\nbayes\n\n\nbayesbox\n\n\nnum\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree1\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDAG-Graph\n\n\n\n\n\n\nfopro\n\n\nresearchdesign\n\n\ncausal\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsentiws2\n\n\n\n\n\n\ntextmining\n\n\ntokenizer\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq03\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq04\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nabh-ereignisse2\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel06\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz18\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nalphafehler-inflation2\n\n\n\n\n\n\nprobability\n\n\nR\n\n\ninference\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz20\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\ninference\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz16\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGem-Wskt3\n\n\n\n\n\n\nprobability\n\n\ndyn\n\n\nbayes\n\n\nnum\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz11\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\ndistributions\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq05\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq02\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKlausuren-bestehen\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmodellguete-testset\n\n\n\n\n\n\nregression\n\n\nperformance\n\n\nrmse\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m1\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\nstring\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex02\n\n\n\n\n\n\ntextmining\n\n\nregex\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwithin-design-analysis1\n\n\n\n\n\n\nregression\n\n\nwithin-design\n\n\nresearchdesign\n\n\nfopro\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren1a\n\n\n\n\n\n\nregression\n\n\n2023\n\n\nstring\n\n\nqm2\n\n\nqm2-pruefung\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Wskt2\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nnum\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-lexicon\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\nregex\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz02\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz05\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\ndistributions\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-05\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex03\n\n\n\n\n\n\nregex\n\n\ntextmining\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq10\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nbayes\n\n\nbayes-grid\n\n\nnum\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren2a\n\n\n\n\n\n\nregression\n\n\n2023\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz04\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\ndistributions\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz03\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nausreisser1\n\n\n\n\n\n\neda\n\n\ndatawrangling\n\n\ntidyverse\n\n\nausreisser\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWeinhaendler\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\nbayes\n\n\nstring\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Wskt3\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncorona-blutgruppe\n\n\n\n\n\n\nprobability\n\n\ndependent\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nUrne2\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNerd-gelockert\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m1\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\nrethink-chap2\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsicherheit2\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m6\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nbayes-grid\n\n\nrethink-chap2\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig_var3a\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBayes-Theorem1\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbayes2\n\n\n\n\n\n\nR\n\n\nbayes\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRethink2m7\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nbayes-grid\n\n\nrethink-chap2\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nk-coins-k-hits\n\n\n\n\n\n\nprobability\n\n\ndyn\n\n\nbayes\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nabh-ereignisse\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngroesse02\n\n\n\n\n\n\n2023\n\n\nbayes\n\n\nbayes-grid\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAdditionssatz1\n\n\n\n\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree2\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nspeed\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKaefer1\n\n\n\n\n\n\nR\n\n\nbayes\n\n\nbayesbox\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq09\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree5\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nspeed\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq07\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz14\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz13\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nVar-vs-Stufe\n\n\n\n\n\n\nfopro\n\n\nresearchdesign\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq01\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nexam-22\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq06\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree4\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nspeed\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-tree3\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nspeed\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niq08\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel05\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz12\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz15\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKrebs1\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz08\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Wskt1\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz06\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz01\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex01\n\n\n\n\n\n\ntextmining\n\n\nregex\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m5\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBsp-Binomial\n\n\n\n\n\n\nprobability\n\n\nbinomial\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz07\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-quiz09\n\n\n\n\n\n\nquiz\n\n\nprobability\n\n\nbayes\n\n\ndistributions\n\n\nquiz1-qm2-ws23\n\n\nschoice\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m4\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nUrne1\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren2_var1\n\n\n\n\n\n\nlm\n\n\nregression\n\n\nbayes\n\n\nadjust\n\n\nstring\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKlausur-raten\n\n\n\n\n\n\nprobability\n\n\ndyn\n\n\nbayes\n\n\nnum\n\n\nqm2-pruefung\n\n\nqm2\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsicherheit\n\n\n\n\n\n\nR\n\n\nprobability\n\n\nnum\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrepro1-sessioninfo\n\n\n\n\n\n\nR\n\n\nrepro\n\n\nstring\n\n\n\n\n\n\n\n\n\nOct 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig_var3\n\n\n\n\n\n\ndyn\n\n\nprobability\n\n\nnum\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-gapminder\n\n\n\n\n\n\nvis\n\n\nyacsda\n\n\nggquick\n\n\ngapminder\n\n\nstring\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-penguins\n\n\n\n\n\n\nvis\n\n\nyacsda\n\n\nggquick\n\n\npenguins\n\n\nstring\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-mtcars\n\n\n\n\n\n\nvis\n\n\nyacsda\n\n\nggquick\n\n\nmtcars\n\n\nstring\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-01\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nstring\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal28\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\nschoice\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal29\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\nschoice\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nppv-dyn1\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nregression\n\n\nnum\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nppv-mtcars1\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nregression\n\n\nnum\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndurch3-durch5\n\n\n\n\n\n\nR\n\n\nchallenge\n\n\nstring\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nstep-dummy\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\names-kaggle1\n\n\n\n\n\n\nregression\n\n\ndata\n\n\nkaggle\n\n\nstring\n\n\nkaggle\n\n\n\n\n\n\n\n\n\nJun 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntargets-multiple-data-files\n\n\n\n\n\n\nprojectmgt\n\n\ntargets\n\n\nrepro\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregex-insert-char\n\n\n\n\n\n\ntextmining\n\n\nregex\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ncount-emoji\n\n\n\n\n\n\ntextmining\n\n\nnlp\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npca\n\n\n\n\n\n\neda\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-lasso2\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\nlasso\n\n\nlm\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap1\n\n\n\n\n\n\nstatlearning\n\n\nds1\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels1\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\ndyn\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike04\n\n\n\n\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike03\n\n\n\n\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTest-MSE2\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-lasso3\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\nlasso\n\n\nlm\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-finalize\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike02\n\n\n\n\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-vorlage\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntitanic_casestudy\n\n\n\n\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCluster02\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlex-vs-nichtflex-Methode3\n\n\n\n\n\n\nstatlearning\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbootstrap\n\n\n\n\n\n\nstatlearning\n\n\ninference\n\n\nschoice\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwfsets_penguins02\n\n\n\n\n\n\nR\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\nwfsets\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnyc_casestudy\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlex-vs-nichtflex-Methode2\n\n\n\n\n\n\nstatlearning\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlex-vs-nichtflex-Methode\n\n\n\n\n\n\nstatlearning\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsmape\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nShrinkage1\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm-mario2\n\n\n\n\n\n\nR\n\n\nlm\n\n\npredict\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-03\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-04\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-02\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbreiman\n\n\n\n\n\n\nds1\n\n\nprediction\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm-mario3\n\n\n\n\n\n\nR\n\n\nlm\n\n\npredict\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nds-quiz\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb06\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nrandom-forest\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels_workflowset01\n\n\n\n\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb01\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nrandom-forest\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb08\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nrandom-forest\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndiamonds-tidymodels01\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins02\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins05\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting1\n\n\n\n\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsupervisedlearning\n\n\n\n\n\n\nstatlearning\n\n\nds1\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-poly01\n\n\n\n\n\n\nR\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb07\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregr-tree01\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nn-se\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins04\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins03\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels2\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nerror\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-usemodels\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nds-quiz2\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npredictioncontest1\n\n\n\n\n\n\nR\n\n\nds1\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPCA1\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nOLS-Minimierung\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nbike01\n\n\n\n\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels3\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nlm\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTest-MSE1\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwfsets_penguins01\n\n\n\n\n\n\nR\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\nwfsets\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmse\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCluster01\n\n\n\n\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCV1\n\n\n\n\n\n\nstatlearning\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-finalize2\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-lasso\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\nlasso\n\n\nlm\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm-mario1\n\n\n\n\n\n\nR\n\n\nlm\n\n\npredict\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ngini-plot\n\n\n\n\n\n\n2023\n\n\nvis\n\n\nstatlearning\n\n\ntrees\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrf-finalize3\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-ames-01\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidytext\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins06\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins01\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nknn-ames01\n\n\n\n\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting2\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSzenario-charakterisieren1\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregr-tree03\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb02\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\ntrees\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb05\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nrandom-forest\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregr-tree02\n\n\n\n\n\n\nstatlearning\n\n\ntrees\n\n\ntidymodels\n\n\nmtcars\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTengku-Hanis01\n\n\n\n\n\n\ntidymodels\n\n\nprediction\n\n\nyacsda\n\n\nstatlearning\n\n\ntrees\n\n\nspeed\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-penguins07\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntrees\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-vorlage2\n\n\n\n\n\n\ntidymodels\n\n\nstatlearning\n\n\ntemplate\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb04\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nrandom-forest\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntmdb03\n\n\n\n\n\n\nds1\n\n\ntidymodels\n\n\nstatlearning\n\n\ntmdb\n\n\nrandom-forest\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidymodels-poly02\n\n\n\n\n\n\nR\n\n\nstatlearning\n\n\ntidymodels\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na1\n\n\n\n\n\n\n2023\n\n\neda\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na5\n\n\n\n\n\n\n2023\n\n\neda\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na2\n\n\n\n\n\n\n2023\n\n\neda\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na3\n\n\n\n\n\n\n2023\n\n\neda\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter-na4\n\n\n\n\n\n\n2023\n\n\neda\n\n\nna\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa06\n\n\n\n\n\n\ndata\n\n\neda\n\n\nlagemaße\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr2\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nassociation\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-regr01\n\n\n\n\n\n\nlm\n\n\nmtcars\n\n\nassociation\n\n\nregression\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkorr-als-regr\n\n\n\n\n\n\nlm\n\n\nregression\n\n\nstring\n\n\nassociation\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregression1a\n\n\n\n\n\n\nregression\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr4\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nassociation\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr3\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nassociation\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlm1\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nstats-nutshell\n\n\nschoice\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkorr02\n\n\n\n\n\n\ndyn\n\n\neda\n\n\nassociation\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression5\n\n\n\n\n\n\ndyn\n\n\nregression\n\n\nlm\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression3\n\n\n\n\n\n\ndyn\n\n\nregression\n\n\nlm\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLinearitaet1a\n\n\n\n\n\n\nlm\n\n\nregression\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression4\n\n\n\n\n\n\ndyn\n\n\nregression\n\n\nlm\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ninterpret-koeff-lm\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnichtlineare-regr1\n\n\n\n\n\n\nlm\n\n\nvis\n\n\nqm2\n\n\nregression\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregression1b\n\n\n\n\n\n\nregression\n\n\nR\n\n\nlm\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-korr1\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nassociation\n\n\nnum\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa03\n\n\n\n\n\n\ndata\n\n\neda\n\n\nassociation\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nregression1\n\n\n\n\n\n\nregression\n\n\ndyn\n\n\nlm\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression6\n\n\n\n\n\n\ndyn\n\n\nregression\n\n\nexam-22\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAussagen-einfache-Regr\n\n\n\n\n\n\nregression\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkorr01\n\n\n\n\n\n\ndyn\n\n\neda\n\n\nassociation\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-regr02\n\n\n\n\n\n\nlm\n\n\nbayes\n\n\nrope\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nanim01\n\n\n\n\n\n\n2023\n\n\nvis\n\n\nanimation\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nanim03\n\n\n\n\n\n\n2023\n\n\nvis\n\n\nanimation\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nanim02\n\n\n\n\n\n\n2023\n\n\nvis\n\n\nanimation\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa04\n\n\n\n\n\n\ndata\n\n\neda\n\n\nlagemaße\n\n\nvis\n\n\nanimation\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa05\n\n\n\n\n\n\ndata\n\n\neda\n\n\nlagemaße\n\n\nvis\n\n\nanimation\n\n\nstring\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKennwert-robust\n\n\n\n\n\n\neda\n\n\nlagemaße\n\n\nvariability\n\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa07\n\n\n\n\n\n\ndata\n\n\neda\n\n\nlagemaße\n\n\nvariability\n\n\nstring\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvis-mariokart-variab\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\nvis\n\n\nvariability\n\n\nstring\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsd-vergleich\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\nvis\n\n\nvariability\n\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa01\n\n\n\n\n\n\ndata\n\n\neda\n\n\nlagemaße\n\n\nvariability\n\n\nstring\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nStreuung-Histogramm\n\n\n\n\n\n\neda\n\n\nvariability\n\n\ndyn\n\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-sd1\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise06\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKennwert-robust2\n\n\n\n\n\n\neda\n\n\nvariability\n\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-desk01\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\nvis\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-sd2\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise04\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-sd3\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise05\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nvariability\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmw-berechnen\n\n\n\n\n\n\neda\n\n\ndatawrangling\n\n\ndyn\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmw-berechnen2\n\n\n\n\n\n\neda\n\n\ndatawrangling\n\n\ndyn\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-max2\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean1\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle10\n\n\n\n\n\n\neda\n\n\nlagemaße\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise01\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-max1\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSchiefe1\n\n\n\n\n\n\nschoice\n\n\neda\n\n\ndistributions\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSchiefe-erkennen\n\n\n\n\n\n\neda\n\n\ndistributions\n\n\nschoice\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nnasa02\n\n\n\n\n\n\ndata\n\n\neda\n\n\nlagemaße\n\n\nstring\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise03\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean2\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean4\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmariokart-mean3\n\n\n\n\n\n\ndatawrangling\n\n\ndplyr\n\n\neda\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nsummarise02\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmutate02\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidydata1\n\n\n\n\n\n\ndatawrangling\n\n\ntidy\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle9\n\n\n\n\n\n\neda\n\n\n2023\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle7\n\n\n\n\n\n\neda\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nfilter01\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle1\n\n\n\n\n\n\neda\n\n\ndatawrangling\n\n\ntidyverse\n\n\ndplyr\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\naffairs-dplyr\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMWberechnen\n\n\n\n\n\n\neda\n\n\ndatawrangling\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmutate01\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ntidyverse\n\n\ndplyr\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr-uebersetzen\n\n\n\n\n\n\ndatawrangling\n\n\ntidyverse\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle4\n\n\n\n\n\n\neda\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle3\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwrangle5\n\n\n\n\n\n\neda\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nhaeufigkeit01\n\n\n\n\n\n\ndatawrangling\n\n\neda\n\n\ncount\n\n\nstring\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLogikpruefung2\n\n\n\n\n\n\nR\n\n\n2023\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-01\n\n\n\n\n\n\nR\n\n\n2023\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nthere-is-no-package\n\n\n\n\n\n\nR\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertberechnen2\n\n\n\n\n\n\nR\n\n\ndyn\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertzuweisen_mc\n\n\n\n\n\n\nR\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-06a\n\n\n\n\n\n\nR\n\n\n2023\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nargumente\n\n\n\n\n\n\nR\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLogikpruefung1\n\n\n\n\n\n\nR\n\n\n2023\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nimport-mtcars\n\n\n\n\n\n\nR\n\n\ndata\n\n\nmtcars\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertzuweisen\n\n\n\n\n\n\nR\n\n\n2023\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertpruefen\n\n\n\n\n\n\nR\n\n\n2023\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-02\n\n\n\n\n\n\nR\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-04\n\n\n\n\n\n\nR\n\n\n2023\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTyp-Fehler-R-03\n\n\n\n\n\n\nstring\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPfad\n\n\n\n\n\n\nR\n\n\ndatawrangling\n\n\nqm1\n\n\nqm2\n\n\nstring\n\n\ndata\n\n\nimport\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWertberechnen\n\n\n\n\n\n\nR\n\n\ndyn\n\n\nnum\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nboxhist\n\n\n\n\n\n\nvis\n\n\neda\n\n\nen\n\n\ncloze\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmax-corr1\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDiamonds-Histogramm-Vergleich2\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nboxplots-de1a\n\n\n\n\n\n\nvis\n\n\neda\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmovies-vis2\n\n\n\n\n\n\nvis\n\n\neda\n\n\nstring\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRidges-vergleichen\n\n\n\n\n\n\nvis\n\n\ndyn\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDiamonds-Histogramm-Vergleich\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmax-corr2\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHistogramm-in-Boxplot\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmin-corr1\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwozu-balkendiagramm\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmovies-vis1\n\n\n\n\n\n\nvis\n\n\neda\n\n\nstring\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBoxplot-Aussagen\n\n\n\n\n\n\nvis\n\n\neda\n\n\ndyn\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwozu-streudiagramm\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nStreudiagramm\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndiamonds-histogram\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nn-vars-diagram\n\n\n\n\n\n\nvis\n\n\n2023\n\n\nnum\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvariability01\n\n\n\n\n\n\nvariability\n\n\nbasics\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDef-Statistik01\n\n\n\n\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nKausale-Verben\n\n\n\n\n\n\ncausal\n\n\nresearch-question\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntidy1\n\n\n\n\n\n\ntidy\n\n\ndatawrangling\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSkalenniveau1a\n\n\n\n\n\n\ndyn\n\n\nvariable-levels\n\n\nvariable-levels\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nZiele-Statistik\n\n\n\n\n\n\nbasics\n\n\n2023\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nvariability02\n\n\n\n\n\n\nvariability\n\n\nbasics\n\n\nschoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSkalenniveau1b\n\n\n\n\n\n\ndyn\n\n\nvariable-levels\n\n\nvariable-levels\n\n\nmchoice\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal02\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal03\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel01\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post2\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\npost\n\n\nexam-22\n\n\nqm2\n\n\nmtcars\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig_var2\n\n\n\n\n\n\ndyn\n\n\nprobability\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post3\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\npost\n\n\nexam-22\n\n\nqm2\n\n\nqm2-pruefung\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-04\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-03\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-02\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npenguins-stan-05\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nexam-22\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal01\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npigs2\n\n\n\n\n\n\nbayes\n\n\nqm2\n\n\nqm2-pruefung\n\n\nregression\n\n\nexam-22\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nrope2\n\n\n\n\n\n\nrope\n\n\nbayes\n\n\nregression\n\n\nexam-22\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPPV1a-mtcars\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nexam-22\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-post\n\n\n\n\n\n\nbayes\n\n\npost\n\n\nestimation\n\n\nexam-22\n\n\nqm2\n\n\nmtcars\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwskt-mtcars-1l\n\n\n\n\n\n\npost\n\n\nbayes\n\n\nregression\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nkausal05\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal04\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal-bedrooms1\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal-einfach\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal21\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal26\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal10\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal27\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal20\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal06\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal08\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal09\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal07\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrandomdag1\n\n\n\n\n\n\ncausal\n\n\ndag\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal_corona_glatze\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal25\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal22\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nMediterran-Alk\n\n\n\n\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal23\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal24\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkausal24\n\n\n\n\n\n\ndag\n\n\ncausal\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nttest-skalenniveau\n\n\n\n\n\n\nttest\n\n\nregression\n\n\nvariable-levels\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegression2\n\n\n\n\n\n\nregression\n\n\ndyn\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nNullhyp-Beispiel\n\n\n\n\n\n\nnullhypothesis\n\n\ninference\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInteraktionseffekt1\n\n\n\n\n\n\ninteraction\n\n\nregression\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret03\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nqm2\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope-regression\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nrope\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegr-Bayes-interpret02\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nposterior_interval\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\npost\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-rope1\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\npost\n\n\nexam-22\n\n\nqm2\n\n\nmtcars\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm_prioriwerte\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope4\n\n\n\n\n\n\nrope\n\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope3\n\n\n\n\n\n\nrope\n\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ndiamonds-nullhyp-mws\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nnullhypothesis\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nzwert-berechnen\n\n\n\n\n\n\nz-value\n\n\nR\n\n\nmath\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nanova-skalenniveau\n\n\n\n\n\n\nvariable-levels\n\n\nanova\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nGriech-Buchstaben-Inferenz\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\nparameters\n\n\n\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nrope1\n\n\n\n\n\n\nrope\n\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm_parameterzahl\n\n\n\n\n\n\nbayes\n\n\nregression\n\n\nparameters\n\n\n\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBayes-Ziel1\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nLikelihood2\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\nlikelihood\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBayesmod-bestimmen01\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\nprior\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPost-befragen1\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\npost\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPostvert-Regr-01\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\npost\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBed-Post-Wskt1\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\npost\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPriorwahl1\n\n\n\n\n\n\nfat-tails\n\n\ndistributions\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBayesmod-bestimmen02\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\nprior\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nLikelihood-identifizieren\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\nlikelihood\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPriorwahl2\n\n\n\n\n\n\nregression\n\n\nbayes\n\n\ndistributions\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nfattails02\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nfattails01\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nfat-tails\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3e1-7\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\npost\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-05\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-02\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nquiz\n\n\nqm2\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-03\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-04\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-17\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-10\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-11\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-16\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-18\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-01\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-06\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-08\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-09\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-07\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-13\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-14\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-15\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nVerteilungen-Quiz-12\n\n\n\n\n\n\ndistributions\n\n\nVerteilungen-Quiz\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter07\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nNov 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nAnteil-Apple\n\n\n\n\n\n\nbayes\n\n\nbayes-grid\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nIQ-Studentis\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWarum-Bayes\n\n\n\n\n\n\nqm2\n\n\nbayes\n\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSim-Prior\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPriori-Streuung\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\ndistributions\n\n\nbayes\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nReThink4e3\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nReThink4e2\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nfat-tails-Artikel\n\n\n\n\n\n\nprobability\n\n\ndistributions\n\n\nfat-tails\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nstan_glm01\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m2\n\n\n\n\n\n\nbayes\n\n\npost\n\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nKung-height\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nReThink3m3\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nZwielichter-Dozent-Bayes\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\nppv\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nsubjektiv-Bayes\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter01\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter06\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nLose-Nieten-Binomial-Grid\n\n\n\n\n\n\nprobability\n\n\nbinomial\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel04\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\nsimulation\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel03\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nwuerfel02\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter03\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter04\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter05\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ntwitter02\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\neuro-bayes\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nkekse01\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map01\n\n\n\n\n\n\nR\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map06\n\n\n\n\n\n\nprogramming\n\n\nloop\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-abhaengig\n\n\n\n\n\n\nprobability\n\n\ndependent\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nvoll-normal\n\n\n\n\n\n\nprobability\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nGem-Wskt1\n\n\n\n\n\n\nprobability\n\n\nqm2\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map05\n\n\n\n\n\n\nprogramming\n\n\nloop\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map02\n\n\n\n\n\n\nR\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map03\n\n\n\n\n\n\nR\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npurrr-map04\n\n\n\n\n\n\nR\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nungewiss-arten-regression\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\nlm\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInferenz-fuer-alle\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\nuncertainty\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-simple1\n\n\n\n\n\n\nregression\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\nmcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlog-y-regression3\n\n\n\n\n\n\nstats-nutshell\n\n\nqm2\n\n\nregression\n\n\nlog\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlog-y-regression2\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren1\n\n\n\n\n\n\nqm2\n\n\nlm\n\n\nbayes\n\n\nstats-nutshell\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\ninterpret-koeff\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nbayes\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nvorhersageintervall1\n\n\n\n\n\n\nlm\n\n\ninference\n\n\nqm2\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlm-Standardfehler\n\n\n\n\n\n\ninference\n\n\nlm\n\n\nqm2\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\npunktschaetzer-reicht-nicht\n\n\n\n\n\n\nregression\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-simple2\n\n\n\n\n\n\nregression\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nmtcars-simple3\n\n\n\n\n\n\nregression\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\nqm2\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nttest-als-regression\n\n\n\n\n\n\nregression\n\n\nttest\n\n\nvariable-levels\n\n\nmtcars\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nlog-y-regression1\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nadjustieren2\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nbayes\n\n\nadjust\n\n\nqm2-pruefung\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nStichprobenziehen1\n\n\n\n\n\n\nlm\n\n\ninference\n\n\nqm2\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nGriech-Buchstaben-Inferenz\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/adjustieren1a/adjustieren1a.html",
    "href": "posts/adjustieren1a/adjustieren1a.html",
    "title": "adjustieren1a",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\n\nlibrary(tidyverse)\nlibrary(easystats)\ndata(mtcars)\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(hp_z = hp - mean(hp))\n\n\nlm1 &lt;- lm(mpg ~ hp_z, data = mtcars)\nparameters(lm1)\n\nParameter   | Coefficient |   SE |         95% CI | t(30) |      p\n------------------------------------------------------------------\n(Intercept) |       20.09 | 0.68 | [18.70, 21.49] | 29.42 | &lt; .001\nhp z        |       -0.07 | 0.01 | [-0.09, -0.05] | -6.74 | &lt; .001\n\n\nJetzt können wir aus dem Achsenabschnitt (Intercept) herauslesen, dass ein Auto mit hp_z = 0 - also mit mittlerer PS-Zahl - vielleicht gut 20 Meilen weit mit einer Gallone Sprit kommt.\nZur Verdeutlichung ein Diagramm zum Modell:\n\nestimate_relation(lm1) |&gt; plot()\n\n\n\n\n\n\n\n\nAdjustieren Sie im Modell die PS-Zahl um die Art des Schaltgetriebes (am), so dass das neue Modell den statistischen Effekt (nicht notwendig auch kausal) der PS-Zahl bereinigt bzw. unabhängig von der Art des Schaltgetriebes widerspiegelt!\nGeben Sie den Punktschätzer für den Effekt von am in diesem Modell an!\nHinweise:\n\nam=0 ist ein Auto mit Automatikgetriebe.\nWir gehen davon aus, dass der Regressionseffekt gleich stark ist auf allen (beiden) Stufen von am. M.a.W.: Es liegt kein Interaktionseffekt vor.\nBeachten Sie die üblichen Hinweise des Datenwerks.\nNutzen Sie lm, um das Modell zu berechnen.\n\n         \n\n\nLösung\n\nlm2 &lt;- lm(mpg ~ hp_z + am, data = mtcars)\nparameters(lm2)\n\nParameter   | Coefficient |       SE |         95% CI | t(29) |      p\n----------------------------------------------------------------------\n(Intercept) |       17.95 |     0.68 | [16.56, 19.33] | 26.55 | &lt; .001\nhp z        |       -0.06 | 7.86e-03 | [-0.07, -0.04] | -7.50 | &lt; .001\nam          |        5.28 |     1.08 | [ 3.07,  7.48] |  4.89 | &lt; .001\n\n\nDie Spalte Coefficient gibt den mittleren geschätzten Wert für den jeweiligen Koeffizienten an, also den Schätzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt für Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als für Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\n\nestimate_relation(lm2) |&gt; plot()\n\n\n\n\n\n\n\n\nam wird als numerische Variable erkannt. Das ist nicht sinnvoll, da am eher eine kategoriale Variable ist.\nDas können wir so ändern:\n\nmtcars &lt;- \n  mtcars |&gt; \n  mutate(am = factor(am))\n\n\nlm3 &lt;- lm(mpg ~ hp_z + am, data = mtcars)\nparameters(lm3)\n\nParameter   | Coefficient |       SE |         95% CI | t(29) |      p\n----------------------------------------------------------------------\n(Intercept) |       17.95 |     0.68 | [16.56, 19.33] | 26.55 | &lt; .001\nhp z        |       -0.06 | 7.86e-03 | [-0.07, -0.04] | -7.50 | &lt; .001\nam [1]      |        5.28 |     1.08 | [ 3.07,  7.48] |  4.89 | &lt; .001\n\n\nDie Koeffizienten bleiben gleich.\nLösung: 5.28.\nAber im Diagramm wird am jetzt als Faktor-Variable erkannt, was Sinn macht:\n\nestimate_relation(lm3) |&gt; plot()\n\n\n\n\n\n\n\n\nMan könnte hier noch einen Interaktionseffekt ergänzen.\n\nCategories:\n\nregression\n‘2023’\nstring"
  },
  {
    "objectID": "posts/samples-nyc2/index.html",
    "href": "posts/samples-nyc2/index.html",
    "title": "samples-nyc2",
    "section": "",
    "text": "Drei Studierende arbeiten für die New Yorker Flughafenbehörde als Werkstudenten. Fragt ihre Chefin eines Tages: “Welcher der drei New Yorker Flughäfen hat im Schnitt die höchste Verspätung? Zieht mal eine kleine Stichprobe und gebt mir eine gute Antwort.”\nStudi A überlegt: “Hm, ich schaue mir mal die ersten 1000 Flüge des Jahres und diesen Mittelwert nehme ich als Schätzwert für die Verspätung des ganzen Jahres.”\nStudi B argumentiert so: “Hm, ich nehme die ersten 100 Flüge von jedem Monat, rechne davon den Mittelwert aus. Das ist dann mein Schätzwert für die Verspätung des ganzen Jahres, pro Flughafen.”\nStudi C hingegen ist folgender Meinung: “Ich ziehe mal eine Zufallsstichprobe, habe ich in der Statistik-Vorlesung gelernt. N=100 sollte genügen.”\nDie Chefin bezieht sich übrigens auf das Jahr 2023.\nAufgabe: Welcher der drei Studis macht die beste Vorhersage? Rechnen Sie nach und begründen Sie Ihre Meinung!"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#setup",
    "href": "posts/samples-nyc2/index.html#setup",
    "title": "samples-nyc2",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\nlibrary(nycflights23)  # Dataset \"flights\"\ndata(\"flights\")\nlibrary(tidyverse)\n\nWie viele Flüge gab es?\n\nnrow(flights)\n\n[1] 435352\n\n\nViele!\nWelche Variablen gibt es im Datensatz?\n\nglimpse(flights)\n\nRows: 435,352\nColumns: 19\n$ year           &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 1, 18, 31, 33, 36, 503, 520, 524, 537, 547, 549, 551, 5…\n$ sched_dep_time &lt;int&gt; 2038, 2300, 2344, 2140, 2048, 500, 510, 530, 520, 545, …\n$ dep_delay      &lt;dbl&gt; 203, 78, 47, 173, 228, 3, 10, -6, 17, 2, -10, -9, -7, -…\n$ arr_time       &lt;int&gt; 328, 228, 500, 238, 223, 808, 948, 645, 926, 845, 905, …\n$ sched_arr_time &lt;int&gt; 3, 135, 426, 2352, 2252, 815, 949, 710, 818, 852, 901, …\n$ arr_delay      &lt;dbl&gt; 205, 53, 34, 166, 211, -7, -1, -25, 68, -7, 4, -13, -14…\n$ carrier        &lt;chr&gt; \"UA\", \"DL\", \"B6\", \"B6\", \"UA\", \"AA\", \"B6\", \"AA\", \"UA\", \"…\n$ flight         &lt;int&gt; 628, 393, 371, 1053, 219, 499, 996, 981, 206, 225, 800,…\n$ tailnum        &lt;chr&gt; \"N25201\", \"N830DN\", \"N807JB\", \"N265JB\", \"N17730\", \"N925…\n$ origin         &lt;chr&gt; \"EWR\", \"JFK\", \"JFK\", \"JFK\", \"EWR\", \"EWR\", \"JFK\", \"EWR\",…\n$ dest           &lt;chr&gt; \"SMF\", \"ATL\", \"BQN\", \"CHS\", \"DTW\", \"MIA\", \"BQN\", \"ORD\",…\n$ air_time       &lt;dbl&gt; 367, 108, 190, 108, 80, 154, 192, 119, 258, 157, 164, 1…\n$ distance       &lt;dbl&gt; 2500, 760, 1576, 636, 488, 1085, 1576, 719, 1400, 1065,…\n$ hour           &lt;dbl&gt; 20, 23, 23, 21, 20, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6,…\n$ minute         &lt;dbl&gt; 38, 0, 44, 40, 48, 0, 10, 30, 20, 45, 59, 0, 59, 0, 0, …\n$ time_hour      &lt;dttm&gt; 2023-01-01 20:00:00, 2023-01-01 23:00:00, 2023-01-01 2…\n\n\nNehmen wir dep_delay als Zielvariable. Die Chefin hat nicht genau gesagt, welche Variable sie meint. Da sieht man es mal wieder: Man muss Annahmen treffen. Ist aber auch schön, denn man kann selber entscheiden, was einem besser gefällt."
  },
  {
    "objectID": "posts/samples-nyc2/index.html#los-gehts",
    "href": "posts/samples-nyc2/index.html#los-gehts",
    "title": "samples-nyc2",
    "section": "2.2 Los geht’s",
    "text": "2.2 Los geht’s\n\n2.2.1 Studentin A\n\nestimate_A &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  slice(1:1000) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_A\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n26.1\n\n\nJFK\n19.9\n\n\nLGA\n9.4\n\n\n\n\n\n\n“Klares (?) Ergebnis! EWR, also Newark, hat die größte Verspätung!”\n\n\n2.2.2 Student B\n\nestimate_B &lt;-\nflights |&gt; \n  select(dep_delay, origin, month) |&gt; \n  drop_na() |&gt; \n  group_by(month, origin) |&gt; \n  slice(1:100) |&gt; \n  summarise(dep_delay = mean(dep_delay)) |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_B\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n8.47\n\n\nJFK\n9.74\n\n\nLGA\n0.76\n\n\n\n\n\n\n“Knapp! EWR hat fast so viel Verspätung wie JFK.”\n\n\n2.2.3 Studentin C\n\nset.seed(73)\n\nestimate_C &lt;-\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nestimate_C\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n2.0\n\n\nJFK\n14.3\n\n\nLGA\n8.8\n\n\n\n\n\n\n“Glasklares (?) Ergebnis! JFK, also John-F-Kennedy, hat die größte Verspätung! Newark ist hingegen superpünktlich!”"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#moment",
    "href": "posts/samples-nyc2/index.html#moment",
    "title": "samples-nyc2",
    "section": "2.3 Moment",
    "text": "2.3 Moment\nLeider entbrennt hier ein Streit. Vermutlich einige Eifersuchtsmomente hinter den Kulissen, aber wir wissen nichts Genaues.\nStudentin A: “So ein Quatsch, C, du hast die Zufallszahl auf 73 festgelegt, warum gerade diese Zahl?! Bei einer anderen Zahl könnte ein ganz andere Stichprobe und damit ein ganz anderes Ergebnis herauskommen!”\nStudentin C: “Ich habe kürzlich gelernt, dass nicht 42, sondern 73 die beste Zahl ist. Also musste ich 73 nehmen!\nStudent B: “Aber was käme heraus, wenn du 42 als Zufallszahl nehmen würdest, nur mal theoretisch?”\nStudentin C: “Äh…”\n\nset.seed(42)\nflights |&gt; \n  select(dep_delay, origin) |&gt; \n  drop_na() |&gt; \n  sample_n(size = 100)  |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n28.3\n\n\nJFK\n7.5\n\n\nLGA\n9.9\n\n\n\n\n\n\nStudentin C: “Äh, also… Das spielt doch gar keine Rolle, was rauskommt, denn bei jeder Zahl kann ja was anderes rauskommen.”\nA: “Du müsstest also dein Vorgehen ändern… Jede Zahl ausprobieren oder so.”\nC: “Liebe A, du mit deinen Flügen vom Jahresbeginn, das ist doch totaler Quatsch, an deiner Stelle wäre ich lieber still.”\nA: “Aber es kommt was Gutes raus mit meiner Methode!”\nB: “Woher willst du überhaupt wissen, ob es was Gutes ist?”\nA: “Wirst schon sehen!”\nC: “Puh, also gut, ich rechne noch mal. Ich zieh einfach ne Menge Stichproben, mit zufälligen Seed-Nummern …”\nA: “Whatever!”\nC: “Moment.., hier kommt Newark, EWR.”\n\nn_reps &lt;- 100  # Anzahl von Stichproben\nsample_size &lt;- 100  # Umfang jeder Stichprobe\n\newr_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"EWR\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\newr_viele_schaetzwerte\n\n[1] 15\n\n\nB: “Wow, C, du bist halt schon die Statistik-Checkerin…”.\nA: “Hey B, hör gefälligst auf, dich bei A einzuschmeicheln!”\nB: “Jedenfalls ist das Ergebnis von A … anders als unsere!”\nC: “Hier noch mal mein Prinzip für die anderen Flughäfen. JFK:”\n\njfk_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"JFK\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\njfk_viele_schaetzwerte\n\n[1] 16\n\n\nC: “Und LaGuardia:”\n\nlga_viele_schaetzwerte &lt;-\n replicate(n_reps, flights |&gt; \n                      select(dep_delay, origin) |&gt; \n                      filter(origin == \"LGA\") |&gt; \n                      drop_na() |&gt; \n                      sample_n(size = sample_size) |&gt; \n                      summarise(dep_delay = mean(dep_delay))) |&gt; \n  as.numeric() |&gt; \n  mean()\n\nlga_viele_schaetzwerte\n\n[1] 11\n\n\nC: “Also, unterm Strich, LGA rules! LGA hat die geringste Verspätung im Schnitt, nach meiner Rechnung.”\n\nlga_viele_schaetzwerte\n\n[1] 11\n\newr_viele_schaetzwerte\n\n[1] 15\n\njfk_viele_schaetzwerte\n\n[1] 16"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#fazit",
    "href": "posts/samples-nyc2/index.html#fazit",
    "title": "samples-nyc2",
    "section": "2.4 Fazit?",
    "text": "2.4 Fazit?\nA: “Okay, meine Methode war ein bisschen zu einfach. Aber hat auch am wenigsten Arbeit gemacht. Das nennt man wirtschaftlich vorgehen, nur darum geht’s im Business. Also hab ich trotzdem gewonnen!”\nB: “Nope, mein Vorgehen ist in Wirklichkeit das Beste. Ich hab von jedem Monat 100 Flüge genommen, so hat sich alles super ausgeglichen, Jahreszeiten und so, glaub ich. Und es wäre nicht so viel Aufwand wie die zich Tausend Stichproben, die C gezogen hat.”\nC: “Kann ja alles sein, aber mein Vorgehen hat am meisten Spaß gemacht. Übrigens B, wir könnten uns, also unsere beiden Ideen, doch zusammenlegn, kombinieren. Das müsste ein super Ergebnis geben. Wollen wir zwei uns das mal zusammen anschauen, nur wir zwei?”"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#wahre-verspätung",
    "href": "posts/samples-nyc2/index.html#wahre-verspätung",
    "title": "samples-nyc2",
    "section": "3.1 Wahre Verspätung",
    "text": "3.1 Wahre Verspätung\nDie Chefin berechnet die wahre Verspätung über alle Flüge 2023 (in YNC) insgesamt (also in der Population der NYC-Flüge von 2023):\n\nwahre_verspaetung &lt;- \n  flights |&gt; \n  select(origin, dep_delay) |&gt; \n  drop_na() |&gt; \n  group_by(origin) |&gt; \n  summarise(dep_delay = mean(dep_delay))\n\nwahre_verspaetung\n\n\n\n\n\norigin\ndep_delay\n\n\n\n\nEWR\n15.40407\n\n\nJFK\n15.90416\n\n\nLGA\n10.82417\n\n\n\n\n\n\nChefin: “LaGuardia hat am wenigsten Verspätung. JFK am meisten, aber dicht gefolgt von EWR.”\nChefin: “Jetzt schauen wir mal, wer pro Flughafen am genauesten geschätzt hat.”\n\nmodellgueten &lt;-\n  wahre_verspaetung |&gt; \n  mutate(estimate_A = estimate_A$dep_delay,\n         estimate_B = estimate_B$dep_delay,\n         estimate_C = c(\n           ewr_viele_schaetzwerte,\n           jfk_viele_schaetzwerte,\n           lga_viele_schaetzwerte)\n  ) |&gt; \n  pivot_longer(contains(\"estimate\"), \n               names_to = \"student\", \n               values_to = \"estimate\") |&gt; \n  mutate(error_abs = abs(dep_delay - estimate)) \n\nChefin: “LaGuardia wurde ingesamt am genauesten geschätzt, von allen drei Studenten. Aber Studentin A überschätzt die Verspätung massiv bei Newark und bei JFK.”\nChefin: “Hier sind die Details.”\n\nmodellgueten |&gt; \n  ggplot(aes(y = estimate, x = origin)) +\n # geom_line() +\n  geom_col(data = wahre_verspaetung,\n    aes(x = origin, y = dep_delay)) +\n  geom_col(aes(fill = student),\n    position = \"dodge\",\n    alpha = .8) +\n  labs(caption = \"black bars show true delay\",\n       y = \"estimated delay\",\n       fill = \"students' estimates\")"
  },
  {
    "objectID": "posts/samples-nyc2/index.html#and-the-winner-is",
    "href": "posts/samples-nyc2/index.html#and-the-winner-is",
    "title": "samples-nyc2",
    "section": "3.2 And the winner is …",
    "text": "3.2 And the winner is …\nChefin: “And the winner is …”\n\nmodellgueten |&gt; \n  ggplot(aes(x = student, y = error_abs)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nmodellgueten_summ &lt;-\n  modellgueten |&gt; \n  group_by(student) |&gt; \n  summarise(error_abs = mean(error_abs)) |&gt; \n  arrange(error_abs)\n\nmodellgueten_summ\n\n\n\n\n\nstudent\nerror_abs\n\n\n\n\nestimate_C\n0.2158932\n\n\nestimate_A\n5.3439716\n\n\nestimate_B\n7.7180189\n\n\n\n\n\n\nChefin: “Sieht so aus, als hätte B knapp gewonnen, vor C. A ist leider weit abgeschlagen.”\nA: “Mensch, B, du bist hier der Datenhecht!”\nB: “Ich glaub’s ja nicht, ich meine, ich hab’s immer gewusst!”\nC: “Moment, mein Vorgehen müsste in der Theorie das Beste sein?!”"
  },
  {
    "objectID": "posts/zwert-berechnen/zwert-berechnen.html",
    "href": "posts/zwert-berechnen/zwert-berechnen.html",
    "title": "zwert-berechnen",
    "section": "",
    "text": "Exercise\nSei \\(X \\sim \\mathcal{N}(42, 7)\\) und \\(x_1 = 28\\).\nBerechnen Sie den z-Wert für \\(x_1\\)!\nHinweis:\n\nRunden Sie ggf. auf die nächste ganze Zahl.\n\n         \n\n\nSolution\n\nx1_z = (x1 - x_mw) / x_sd\n\n-2\n\nCategories:\n\nz-value\nR\nmath"
  },
  {
    "objectID": "posts/wuerfel06/wuerfel06.html",
    "href": "posts/wuerfel06/wuerfel06.html",
    "title": "wuerfel06",
    "section": "",
    "text": "Aufgabe\nWas ist die Wahrscheinlichkeit, bei 10 Wiederholungen des Werfens zweier Würfel mindestens einen Sechserpasch zu werfen?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\nSei \\(A_i\\) das Ereignis “Sechserpach” in der \\(i\\)-ten Wiederholung.\nEs gilt: \\(Pr(A_i) = 1/36\\).\nNennen wir \\(A\\) “keinen Sechserpasch in jeder Wiederholung”, wir suchen die Wahrscheinlichkeit von A.\n“Mindestens einen Sechserpasch” - Das Gegenteil davon ist “keinen Sechserpasch$.\n\\(Pr(\\neg A_i) = 35/36\\).\nNennen wir \\(X\\) eine Zufallsvariable, die die Anzahl der Sechserpasche zählt.\nDie Wiederholungen sind voneinander unabhängig, es gilt also\n\\(Pr(X=0) = Pr(\\neg A) = \\left(\\frac{35}{36} \\right)^{10}\\)\n\nPr_kein_Secherpasch &lt;- (35/36)^10\nPr_kein_Secherpasch\n\n[1] 0.7544934\n\n\nDas Gegenteil (Komplement) von \\(\\neg A\\), also \\(A\\) ist das gesuchte Ereignis.\n\nPr_A &lt;- 1 - Pr_kein_Secherpasch\nPr_A\n\n[1] 0.2455066\n\n\nDie Lösung lautet 0.2455066.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/wuerfel04/wuerfel04.html",
    "href": "posts/wuerfel04/wuerfel04.html",
    "title": "wuerfel04",
    "section": "",
    "text": "Exercise\nWas ist die Wahrscheinlichkeit, mit zwei fairen Würfeln genau 10 Augen zu werfen?\nHinweise:\n\nNutzen Sie Simulationsmnethoden der Wahrscheinlichkeitsrechnung, keine exakten Rechnung auf Basis der Wahrscheinlichkeitsrechnung.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nSetzen Sie bei Simulationsaufgaben immer die Zufallszahlen mit set.seed(). Sofern kein anderer Wert für set.seed() genannt, verwenden Sie die Zahl 42.\nDa es bei dieser Aufgabe nötig ist, zwei Mal Zufallszahlen zu berechnen (für zwei Würfel nämlich), verwenden Sie beim ersten Würfel die Zahl 42 und beim zweiten Würfel die Zahl 43.\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nEinen Würfelwurf in R kann man so simulieren:\n\nwuerfel &lt;- sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))\nwuerfel\n\n[1] 5\n\n\nBei sample gibt x den Ereignisraum, \\(\\Omega\\), an, size die Stichprobengröße und prob gibt für jedes Element von x die Wahrscheinlichkeit an.\nDas machen wir jetzt 1000 Mal. Viel Spaß beim Tippen…\n… … …\nOkay, das sollten wir einfacher hinkriegen. Man kann R sagen, dass sie eine Funktion (wie sample) oft ausführen soll. Damit können wir viele Würfelwürfe simulieren. Diese “Wiederholungsfunktion” heißt replicate(n, expr); dabei gibt n an, wie oft die Funktion wiederholt werden soll, und expr ist der Ausdruck (die Funktion), die wiederholt werden soll, das ist bei uns die Funktion sample, wie oben dargestellt.\n\nzehn_wuerfel &lt;- replicate(n = 10, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\nzehn_wuerfel\n\n [1] 2 6 3 2 6 3 6 5 3 1\n\n\nKönnen wir natürlich auch zich Mal wiederholen, nicht nur 10 Mal, sagen wir \\(10^4\\) Mal:\n\nset.seed(42)\nwuerfel1_oft &lt;- replicate(n = 10^4, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\n\nmean(wuerfel1_oft)\n\n[1] 3.4968\n\n\nAh, interessant: Der Mittelwert ist etwa 3.5…\nJetzt werfen wir noch einen zweiten Würfel genau so oft:\n\nset.seed(43)\nwuerfel2_oft &lt;- replicate(n = 10^4, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\n\nmean(wuerfel2_oft)\n\n[1] 3.4983\n\n\nDas packen wir jetzt in eine Tabelle und ergänzen die Augensumme für jede Wiederholung des Doppelwurfes:\n\nd &lt;-\n  tibble(w1 = wuerfel1_oft,\n         w2 = wuerfel2_oft,\n         w_sum = w1+w2)\n\nhead(d)\n\n# A tibble: 6 × 3\n     w1    w2 w_sum\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     4     5\n2     1     1     2\n3     3     2     5\n4     6     6    12\n5     5     3     8\n6     5     5    10\n\n\nJetzt ist es einfach:\nWir zählen einfach, wie oft das Ergebnis 10 vorkommt in der Tabelle.\n\nd %&gt;% \n  count(w_sum == 10)\n\n# A tibble: 2 × 2\n  `w_sum == 10`     n\n  &lt;lgl&gt;         &lt;int&gt;\n1 FALSE          9148\n2 TRUE            852\n\n\nErgänzen wir die Anteile dieser Anzahl:\n\nd %&gt;% \n  count(w_sum == 10) %&gt;% \n  mutate(Anteil = n/sum(n))\n\n# A tibble: 2 × 3\n  `w_sum == 10`     n Anteil\n  &lt;lgl&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 FALSE          9148 0.915 \n2 TRUE            852 0.0852\n\n\nDie Lösung lautet also: 0.08 (gerundet auf zwei Dezimalen)\nAuf einfache Weise können wir entsprechend die Wahrscheinlichkeit für mindestens \\(k\\) Augen (bei zwei Würfelwürfen) ermitteln, mit \\(k\\) ist die gesuchte Augensumme, hier 10.\n\nd %&gt;% \n  count(w_sum &gt;= 10) %&gt;% \n  mutate(Anteil = n/sum(n))\n\n# A tibble: 2 × 3\n  `w_sum &gt;= 10`     n Anteil\n  &lt;lgl&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 FALSE          8316  0.832\n2 TRUE           1684  0.168\n\n\nOder höchstens 10, ganz analog:\n\nd %&gt;% \n  count(w_sum &lt;= 10) %&gt;% \n  mutate(Anteil = n/sum(n))\n\n# A tibble: 2 × 3\n  `w_sum &lt;= 10`     n Anteil\n  &lt;lgl&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 FALSE           832 0.0832\n2 TRUE           9168 0.917 \n\n\n\nCategories:\n\nprobability\ndice\nsimulation"
  },
  {
    "objectID": "posts/wuerfel02/wuerfel02.html",
    "href": "posts/wuerfel02/wuerfel02.html",
    "title": "wuerfel02",
    "section": "",
    "text": "Exercise\nWas ist die Wahrscheinlichkeit, mit zwei fairen Würfeln mindestens 10 Augen zu werfen?\nHinweise:\n\nNutzen Sie exakte Methoden der Wahrscheinlichkeitsrechnung, keine Simulation.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\n\n         \n\n\nSolution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden Würfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), …, (1,6), …, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd &lt;- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\n\nd\n\n# A tibble: 36 × 2\n   wuerfel1 wuerfel2\n      &lt;int&gt;    &lt;int&gt;\n 1        1        1\n 2        1        2\n 3        1        3\n 4        1        4\n 5        1        5\n 6        1        6\n 7        2        1\n 8        2        2\n 9        2        3\n10        2        4\n# ℹ 26 more rows\n\n\nJetzt ergänzen wir eine Spalte für die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 &lt;-\n  d %&gt;% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n# A tibble: 6 × 3\n  wuerfel1 wuerfel2   prob\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;\n1        1        1 0.0278\n2        1        2 0.0278\n3        1        3 0.0278\n4        1        4 0.0278\n5        1        5 0.0278\n6        1        6 0.0278\n\n\nAußerdem ergänzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;      &lt;int&gt;\n1        1        1 0.0278          2\n2        1        2 0.0278          3\n3        1        3 0.0278          4\n4        1        4 0.0278          5\n5        1        5 0.0278          6\n6        1        6 0.0278          7\n\n\nFür manche Augensummen gibt es mehrere Möglichkeiten:\n\nd3 %&gt;% \n  filter(augensumme == 7)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;      &lt;int&gt;\n1        1        6 0.0278          7\n2        2        5 0.0278          7\n3        3        4 0.0278          7\n4        4        3 0.0278          7\n5        5        2 0.0278          7\n6        6        1 0.0278          7\n\n\n… für andere weniger:\n\nd3 %&gt;% \n  filter(augensumme == 12)\n\n# A tibble: 1 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;      &lt;int&gt;\n1        6        6 0.0278         12\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 &lt;- \n  d3 %&gt;% \n  group_by(augensumme) %&gt;% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n# A tibble: 11 × 2\n   augensumme totale_w_pro_augenzahl\n        &lt;int&gt;                  &lt;dbl&gt;\n 1          2                 0.0278\n 2          3                 0.0556\n 3          4                 0.0833\n 4          5                 0.111 \n 5          6                 0.139 \n 6          7                 0.167 \n 7          8                 0.139 \n 8          9                 0.111 \n 9         10                 0.0833\n10         11                 0.0556\n11         12                 0.0278\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %&gt;% \n  summarise(sum(totale_w_pro_augenzahl))\n\n# A tibble: 1 × 1\n  `sum(totale_w_pro_augenzahl)`\n                          &lt;dbl&gt;\n1                             1\n\n\nUnd:\n\nd2 %&gt;% \n  summarise(sum(prob))\n\n# A tibble: 1 × 1\n  `sum(prob)`\n        &lt;dbl&gt;\n1           1\n\n\nPasst!\nDie Wahrscheinlichkeit für die Augensumme von mind. 10 beträgt also:\n\nloesung &lt;-\n  d4 %&gt;% \n  filter(augensumme &gt;= 10) %&gt;% \n  summarise(prob_sum = sum(totale_w_pro_augenzahl)) %&gt;% \n  pull(prob_sum)\n\nloesung\n\n[1] 0.1666667\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html",
    "title": "Wskt-Schluckspecht",
    "section": "",
    "text": "Prüfen Sie folgende Hypothese:\n\nAutos mit viel PS haben einen höheren Spritverbrauch als Autos mit wenig PS.\n\nQuantifizieren Sie die Wahrscheinlichkeit dieser Hypothese!\nHinweise:\n\n“viel PS” definieren wir als “mehr als der Median”.\nVerwenden Sie den Datensatz mtcars.\nNutzen Sie die Bayes-Statistik mit Stan.\nBeachten Sie die Standardhinweise des Datenwerks."
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#setup",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#setup",
    "title": "Wskt-Schluckspecht",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell",
    "title": "Wskt-Schluckspecht",
    "section": "Modell",
    "text": "Modell\nDie Hypothese kann man wie folgt formalisieren:\n\\[\\text{mpg}_{PS=0} &gt; \\text{mpg}_{PS=1}\\],\nwobei \\(PS=0\\) die Autos mit wenig PS meint."
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#vorverarbeitung",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#vorverarbeitung",
    "title": "Wskt-Schluckspecht",
    "section": "Vorverarbeitung",
    "text": "Vorverarbeitung\n\nmtcars &lt;-\n  mtcars |&gt; \n  mutate(PS = case_when(\n    mpg &gt; median(mpg) ~ 1,\n    mpg &lt;= median(mpg) ~ 0\n  ))"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell-berechnen",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#modell-berechnen",
    "title": "Wskt-Schluckspecht",
    "section": "Modell berechnen",
    "text": "Modell berechnen\n\nm &lt;- stan_glm(mpg ~ PS,\n              data = mtcars,\n              refresh = 0,\n              seed = 42)\n\n\nparameters(m)\n\nParameter   | Median |         95% CI |   pd |  Rhat |     ESS |                   Prior\n----------------------------------------------------------------------------------------\n(Intercept) |  15.68 | [13.81, 17.54] | 100% | 1.000 | 3302.00 | Normal (20.09 +- 15.07)\nPS          |   9.42 | [ 6.79, 12.12] | 100% | 1.000 | 3549.00 |  Normal (0.00 +- 29.72)"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#post-verteilung-auslesen",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#post-verteilung-auslesen",
    "title": "Wskt-Schluckspecht",
    "section": "Post-Verteilung auslesen",
    "text": "Post-Verteilung auslesen\n\nm_post &lt;-\n  m |&gt;\n  as_tibble()\n\nprop &lt;- \nm_post |&gt; \n  count(PS &gt;= 0) |&gt; \n  mutate(prop = n/sum(n))\n\nprop\n\n# A tibble: 1 × 3\n  `PS &gt;= 0`     n  prop\n  &lt;lgl&gt;     &lt;int&gt; &lt;dbl&gt;\n1 TRUE       4000     1"
  },
  {
    "objectID": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#antwort",
    "href": "posts/Wskt-Schluckspecht/Wskt-Schluckspecht.html#antwort",
    "title": "Wskt-Schluckspecht",
    "section": "Antwort",
    "text": "Antwort\nLaut unserem Modell beträgt die Wahrscheinlichkeit für obige Hypothese 1."
  },
  {
    "objectID": "posts/wskt-quiz19/wskt-quiz19.html",
    "href": "posts/wskt-quiz19/wskt-quiz19.html",
    "title": "wskt-quiz19",
    "section": "",
    "text": "Behauptung:\nDie folgenden Variablen haben (alle) “Fat Tails”: Intelligenz (IQ) und das Einkommen von Musikern.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz19/wskt-quiz19.html#answerlist",
    "href": "posts/wskt-quiz19/wskt-quiz19.html#answerlist",
    "title": "wskt-quiz19",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz19/wskt-quiz19.html#answerlist-1",
    "href": "posts/wskt-quiz19/wskt-quiz19.html#answerlist-1",
    "title": "wskt-quiz19",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz17/wskt-quiz17.html",
    "href": "posts/wskt-quiz17/wskt-quiz17.html",
    "title": "wskt-quiz17",
    "section": "",
    "text": "Behauptung:\nHat eine Hypothese die Priori-Wahrscheinlichkeit von 0, so wird die Post-Wahrscheinlichkeit dieser Hypothese 0 sein.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz17/wskt-quiz17.html#answerlist",
    "href": "posts/wskt-quiz17/wskt-quiz17.html#answerlist",
    "title": "wskt-quiz17",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz17/wskt-quiz17.html#answerlist-1",
    "href": "posts/wskt-quiz17/wskt-quiz17.html#answerlist-1",
    "title": "wskt-quiz17",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz15/wskt-quiz15.html",
    "href": "posts/wskt-quiz15/wskt-quiz15.html",
    "title": "wskt-quiz15",
    "section": "",
    "text": "Behauptung:\n\\(Pr(BA) = Pr(B|A) \\cdot Pr(A)\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz15/wskt-quiz15.html#answerlist",
    "href": "posts/wskt-quiz15/wskt-quiz15.html#answerlist",
    "title": "wskt-quiz15",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz15/wskt-quiz15.html#answerlist-1",
    "href": "posts/wskt-quiz15/wskt-quiz15.html#answerlist-1",
    "title": "wskt-quiz15",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz13/wskt-quiz13.html",
    "href": "posts/wskt-quiz13/wskt-quiz13.html",
    "title": "wskt-quiz13",
    "section": "",
    "text": "Behauptung: Die Post-Verteilung gibt die Wahrscheinlichkeit der Daten an, gegeben der Hypothese.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz13/wskt-quiz13.html#answerlist",
    "href": "posts/wskt-quiz13/wskt-quiz13.html#answerlist",
    "title": "wskt-quiz13",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz13/wskt-quiz13.html#answerlist-1",
    "href": "posts/wskt-quiz13/wskt-quiz13.html#answerlist-1",
    "title": "wskt-quiz13",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz11/wskt-quiz11.html",
    "href": "posts/wskt-quiz11/wskt-quiz11.html",
    "title": "wskt-quiz11",
    "section": "",
    "text": "Sei \\(X \\sim N(100, 15)\\).\nBehauptung: Es gilt: \\(Pr(X \\ge 115) &lt; .2\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz11/wskt-quiz11.html#answerlist",
    "href": "posts/wskt-quiz11/wskt-quiz11.html#answerlist",
    "title": "wskt-quiz11",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz11/wskt-quiz11.html#answerlist-1",
    "href": "posts/wskt-quiz11/wskt-quiz11.html#answerlist-1",
    "title": "wskt-quiz11",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz09/wskt-quiz09.html",
    "href": "posts/wskt-quiz09/wskt-quiz09.html",
    "title": "wskt-quiz09",
    "section": "",
    "text": "Sei \\(X \\sim U(0, 1)\\).\nBehauptung: Es gilt: \\(f(X=1) = .1\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz09/wskt-quiz09.html#answerlist",
    "href": "posts/wskt-quiz09/wskt-quiz09.html#answerlist",
    "title": "wskt-quiz09",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz09/wskt-quiz09.html#answerlist-1",
    "href": "posts/wskt-quiz09/wskt-quiz09.html#answerlist-1",
    "title": "wskt-quiz09",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz07/wskt-quiz07.html",
    "href": "posts/wskt-quiz07/wskt-quiz07.html",
    "title": "wskt-quiz07",
    "section": "",
    "text": "Folgende Formel ist korrekt: \\(Pr(H|D) = Pr(D|H) \\cdot Pr(H)\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz07/wskt-quiz07.html#answerlist",
    "href": "posts/wskt-quiz07/wskt-quiz07.html#answerlist",
    "title": "wskt-quiz07",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz07/wskt-quiz07.html#answerlist-1",
    "href": "posts/wskt-quiz07/wskt-quiz07.html#answerlist-1",
    "title": "wskt-quiz07",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz05/wskt-quiz05.html",
    "href": "posts/wskt-quiz05/wskt-quiz05.html",
    "title": "wskt-quiz05",
    "section": "",
    "text": "Wasserplanet entdeckt (Er wurde auf den Namen “Bath42” getauft)! Die ganze Oberfläche besteht aus Wasser. Jemand presentiert uns die Probe von diesem Planeten: Wasser! Allerdings ohne zu sagen, ob die Probe vom Wasserplaneten oder von der Erde (E) kommt. Hm.\nGilt die folgende Gleichung: \\(Pr(W|E) = Pr(E|W)\\)?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz05/wskt-quiz05.html#answerlist",
    "href": "posts/wskt-quiz05/wskt-quiz05.html#answerlist",
    "title": "wskt-quiz05",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz05/wskt-quiz05.html#answerlist-1",
    "href": "posts/wskt-quiz05/wskt-quiz05.html#answerlist-1",
    "title": "wskt-quiz05",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\ndistributions\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz03/wskt-quiz03.html",
    "href": "posts/wskt-quiz03/wskt-quiz03.html",
    "title": "wskt-quiz03",
    "section": "",
    "text": "Wirft man eine faire Münze 10-fach, so gilt \\(Pr(\\text{10 mal Kopf}) = Pr(\\text{10 mal Zahl}) &gt; .01\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz03/wskt-quiz03.html#answerlist",
    "href": "posts/wskt-quiz03/wskt-quiz03.html#answerlist",
    "title": "wskt-quiz03",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz03/wskt-quiz03.html#answerlist-1",
    "href": "posts/wskt-quiz03/wskt-quiz03.html#answerlist-1",
    "title": "wskt-quiz03",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz01/wskt-quiz01.html",
    "href": "posts/wskt-quiz01/wskt-quiz01.html",
    "title": "wskt-quiz01",
    "section": "",
    "text": "Sind die Ereignisse \\(A\\) und \\(B\\) unabhängig, so gilt \\(Pr(A|B) = P(A)\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz01/wskt-quiz01.html#answerlist",
    "href": "posts/wskt-quiz01/wskt-quiz01.html#answerlist",
    "title": "wskt-quiz01",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz01/wskt-quiz01.html#answerlist-1",
    "href": "posts/wskt-quiz01/wskt-quiz01.html#answerlist-1",
    "title": "wskt-quiz01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Nein, die Aussage ist nicht falsch, sie ist wahr.\nWahr. Ja, die Aussage ist wahr.\n\n\nCategories:\n\nquiz\nprobability\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html",
    "href": "posts/wskt-df-r/wskt-df-r.html",
    "title": "wskt-df-r",
    "section": "",
    "text": "In dieser Aufgabe betrachten wir typische Relationen von Ereignissen, um typische Fragen der Wahrscheinlichkeitsrechnung zu beantworten.\nGegeben sei folgender Datensatz:\n\nd &lt;-\n  data.frame(\n    A = c(1, 1, 0, 0),\n    B = c(1, 0, 1, 0)\n  )\n\nd\n\n\n\n\n\nA\nB\n\n\n\n\n1\n1\n\n\n1\n0\n\n\n0\n1\n\n\n0\n0\n\n\n\n\n\n\nDer Datensatz d stellt alle vier Kombinationen der beiden Variablen A und B da (wir gehen davon aus, dass es sich um binäre Variablen, wie Ereignisse, handelt, der Einfachheit halber).\nDabei steht A == 1 für \\(A\\) (Ereignis \\(A\\) ist der Fall) und A == 0 für \\(\\neg A\\), A tritt nicht ein, ist nicht der Fall.\nGenerell wird in der Wissenschaft und Technik 0 für “nein, falsch” und 1 für “ja, wahr, richtig” verwendet.\nAufgabe: Berechnen Sie mit R \\(Pr(A\\cap B), Pr(\\neg A\\cap B), Pr(A\\cup B), Pr(A|B), Pr(B|A)\\)!"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#setup",
    "href": "posts/wskt-df-r/wskt-df-r.html#setup",
    "title": "wskt-df-r",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\n\nHier ist unserer Datentabelle:\n\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n1\n1\n\n\n1\n0\n\n\n0\n1\n\n\n0\n0"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#pracap-b",
    "href": "posts/wskt-df-r/wskt-df-r.html#pracap-b",
    "title": "wskt-df-r",
    "section": "\\(Pr(A\\cap B)\\)",
    "text": "\\(Pr(A\\cap B)\\)\n\nd |&gt; \n  filter(A == 1 & B == 1)\n\n\n\n\n\nA\nB\n\n\n\n\n1\n1\n\n\n\n\n\n\nAlso 1 von 4 Zeilen, das heißt 1/4 oder .25.\nMan kann das auch mit count ausrechnen:\n\nd |&gt; \n  count(A == 1 & B == 1)\n\n\n\n\n\nA == 1 & B == 1\nn\n\n\n\n\nFALSE\n3\n\n\nTRUE\n1\n\n\n\n\n\n\nDer Operator & steht für das logische “UND” (Schnitt, intersect).\nUnd so kann man sich noch die Anteile ausrechnen lassen:\n\nd |&gt; \n  count(A == 1 & B == 1) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\nA == 1 & B == 1\nn\nAnteil\n\n\n\n\nFALSE\n3\n0.75\n\n\nTRUE\n1\n0.25"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#prneg-acap-b",
    "href": "posts/wskt-df-r/wskt-df-r.html#prneg-acap-b",
    "title": "wskt-df-r",
    "section": "\\(Pr(\\neg A\\cap B)\\)",
    "text": "\\(Pr(\\neg A\\cap B)\\)\n\\(Pr(\\neg A\\cap B)\\) ist im Prinzip identisch zum Schnitt ohne Negation:\n\nd |&gt; \n  count(A == 0 & B == 1) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\nA == 0 & B == 1\nn\nAnteil\n\n\n\n\nFALSE\n3\n0.75\n\n\nTRUE\n1\n0.25\n\n\n\n\n\n\nOder so:\n\nd |&gt; \n  count(!(A == 1) & B == 1) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\n!(A == 1) & B == 1\nn\nAnteil\n\n\n\n\nFALSE\n3\n0.75\n\n\nTRUE\n1\n0.25\n\n\n\n\n\n\nDer Operator ! entspricht der logischen Negation."
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#pracup-b",
    "href": "posts/wskt-df-r/wskt-df-r.html#pracup-b",
    "title": "wskt-df-r",
    "section": "\\(Pr(A\\cup B)\\)",
    "text": "\\(Pr(A\\cup B)\\)\nKommen wir zu \\(Pr(A\\cup B)\\), der logischen Vereinigung, auch logisches “ODER” genannt.\n\nd |&gt; \n  count((A == 1) | (B == 1)) |&gt; \n  mutate(Anteil = n / sum(n))\n\n\n\n\n\n(A == 1) | (B == 1)\nn\nAnteil\n\n\n\n\nFALSE\n1\n0.25\n\n\nTRUE\n3\n0.75\n\n\n\n\n\n\nDer Operator | steht in R für das logische ODER.\nWie man sieht, kann man die Klammern um (A == 1) | (B == 1) verwenden für bessere Sichtbarkeit. Es ist aber nicht nötig."
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#prab",
    "href": "posts/wskt-df-r/wskt-df-r.html#prab",
    "title": "wskt-df-r",
    "section": "\\(Pr(A|B)\\)",
    "text": "\\(Pr(A|B)\\)\n\\(Pr(A|B)\\) entspricht einem Filtern, d.h. bedingen auf B entspricht einem Filtern, so dass nur noch \\(B\\) und nicht \\(\\neg B\\) übrig bleibt.\n\nd |&gt; \n  filter(B == 1) |&gt; \n  count(A)\n\n\n\n\n\nA\nn\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n\n\n\n\n1 Fall von 2 erfüllt die Bedingung A == 1, also 50%."
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#prba",
    "href": "posts/wskt-df-r/wskt-df-r.html#prba",
    "title": "wskt-df-r",
    "section": "\\(Pr(B|A)\\)",
    "text": "\\(Pr(B|A)\\)\nDiese Aufgabe ist analog zu \\(Pr(A|B)\\):\n\nd |&gt; \n  filter(A == 1) |&gt; \n  count(B)\n\n\n\n\n\nB\nn\n\n\n\n\n0\n1\n\n\n1\n1"
  },
  {
    "objectID": "posts/wskt-df-r/wskt-df-r.html#bonus-prbneg-a",
    "href": "posts/wskt-df-r/wskt-df-r.html#bonus-prbneg-a",
    "title": "wskt-df-r",
    "section": "Bonus \\(Pr(B|\\neg A)\\)",
    "text": "Bonus \\(Pr(B|\\neg A)\\)\n\\(Pr(B|\\neg A)\\) - Eigentlich nichts Neues:\n\nd |&gt; \n  filter(!(A == 1)) |&gt; \n  count(B)\n\n\n\n\n\nB\nn\n\n\n\n\n0\n1\n\n\n1\n1"
  },
  {
    "objectID": "posts/wrangle7/wrangle7.html",
    "href": "posts/wrangle7/wrangle7.html",
    "title": "wrangle7",
    "section": "",
    "text": "Welche Aussage zur Funktion filter() aus dem R-Paket dplyr ist richtig?\n\n\n\nfilter() filtert (behält) Zeilen, für die eine Prüfung TRUE ergibt\nfilter() filtert (behält)Zeilen, für die eine Prüfung FALSE ergibt\nfilter() filtert (behält) Zeilen, für die eine Prüfung TRUE oder NA ergibt\nMöchte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, x == NA).\nMöchte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, is.na(x))."
  },
  {
    "objectID": "posts/wrangle7/wrangle7.html#answerlist",
    "href": "posts/wrangle7/wrangle7.html#answerlist",
    "title": "wrangle7",
    "section": "",
    "text": "filter() filtert (behält) Zeilen, für die eine Prüfung TRUE ergibt\nfilter() filtert (behält)Zeilen, für die eine Prüfung FALSE ergibt\nfilter() filtert (behält) Zeilen, für die eine Prüfung TRUE oder NA ergibt\nMöchte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, x == NA).\nMöchte man nur nicht-fehlende Zeilen aus der Variable x aus dem Dataframe df filtern (behalten), so formuliert man filter(df, is.na(x))."
  },
  {
    "objectID": "posts/wrangle7/wrangle7.html#answerlist-1",
    "href": "posts/wrangle7/wrangle7.html#answerlist-1",
    "title": "wrangle7",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\neda\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/wrangle4/wrangle4.html",
    "href": "posts/wrangle4/wrangle4.html",
    "title": "wrangle4",
    "section": "",
    "text": "Welche Variante der folgenden Syntax-Beispiele ist richtig (formal korrekt)?\n\n\n\nfilter(flights, month = 1, day = 1)\nfilter(flights, day == 1)\nfilter(month == 1, day == 1)\nfilter(month = 1, day == 1)\nfilter(flights, month == 1, day == 1)"
  },
  {
    "objectID": "posts/wrangle4/wrangle4.html#answerlist",
    "href": "posts/wrangle4/wrangle4.html#answerlist",
    "title": "wrangle4",
    "section": "",
    "text": "filter(flights, month = 1, day = 1)\nfilter(flights, day == 1)\nfilter(month == 1, day == 1)\nfilter(month = 1, day == 1)\nfilter(flights, month == 1, day == 1)"
  },
  {
    "objectID": "posts/wrangle4/wrangle4.html#answerlist-1",
    "href": "posts/wrangle4/wrangle4.html#answerlist-1",
    "title": "wrangle4",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\neda\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/wrangle10/wrangle10.html",
    "href": "posts/wrangle10/wrangle10.html",
    "title": "wrangle10",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgende Tabelle:\n\ndf &lt;- tibble(\n  groesse = c(180, 190, 160, 170),\n  geschlecht = c(\"m\", \"m\", \"f\", \"f\")\n)\ndf\n\n\n\n\ngroesse\ngeschlecht\n\n\n\n\n180\nm\n\n\n190\nm\n\n\n160\nf\n\n\n170\nf\n\n\n\n\n\nHinweis: Der Befehl tibble erstellt einen Tibble (Dataframe).\nWas ist er erste Wert, den der folgende Ausdruck zurückliefert?\n\ndf_grouped &lt;- group_by(df, geschlecht)\n\nsummarise(df_grouped, ergebnis = mean(groesse))\n\n         \n\n\nLösung\nDie Werte werden alphabetisch (bzw. alphanumerisch) sortiert. “f” kommt vor “m” im Alphabet.\nAntwort: 165\n\ndf_grouped &lt;- group_by(df, geschlecht)\n\nsummarise(df_grouped, ergebnis = mean(groesse))\n\n\n\n\ngeschlecht\nergebnis\n\n\n\n\nf\n165\n\n\nm\n185\n\n\n\n\n\n\nCategories:\n\neda\nlagemaße\nnum"
  },
  {
    "objectID": "posts/wozu-streudiagramm/wozu-streudiagramm.html",
    "href": "posts/wozu-streudiagramm/wozu-streudiagramm.html",
    "title": "wozu-streudiagramm",
    "section": "",
    "text": "Zu welchem Zweck ist ein Streudiagramm am besten geeignet?\n\n\n\nUm Verteilungen einer nominalen Variablen darzustellen.\nUm Verteilungen einer metrischen Variablen darzustellen.\nUm Verteilungen einer stetigen, metrischen Variablen darzustellen.\nUm Zusammenhänge zwischen zwei nominalen Variablen darzustellen.\nUm Zusammenhänge zwischen zwei metrischen Variablen darzustellen."
  },
  {
    "objectID": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist",
    "href": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist",
    "title": "wozu-streudiagramm",
    "section": "",
    "text": "Um Verteilungen einer nominalen Variablen darzustellen.\nUm Verteilungen einer metrischen Variablen darzustellen.\nUm Verteilungen einer stetigen, metrischen Variablen darzustellen.\nUm Zusammenhänge zwischen zwei nominalen Variablen darzustellen.\nUm Zusammenhänge zwischen zwei metrischen Variablen darzustellen."
  },
  {
    "objectID": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist-1",
    "href": "posts/wozu-streudiagramm/wozu-streudiagramm.html#answerlist-1",
    "title": "wozu-streudiagramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvis\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html",
    "href": "posts/within-design-analysis1/within-design-analysis1.html",
    "title": "within-design-analysis1",
    "section": "",
    "text": "Analysieren Sie die Veränderung in einem längsschnittlichen Experiment (Within-Design).\nIm Zuge des Experiments durchliefen alle \\(n\\) Versuchspersonen 3 Bedingungen. Entsprechend liegen für jede Versuchsperson 3 Messungen vor (y1, y2, y3). Anders gesagt gab es drei Messzeitpunkte (t1, t2, t3), zu denen die abhängige Variable (y) jeweils gemessen wurde Die Messung bestand bei jeder Bedingung aus 10 Items, wobei die Wahrscheinlichkeit, ein Item zu lösen zwischen den Bedingungen unterschiedlich war.\nPrüfen Sie die folgende Hypothesen:\n\n\\(y_{t2} - y_{t1} &gt; 0\\)\n\\(y_{t3} - y_{t2} &gt; 0\\)\n\nGehen Sie von folgenden (hier einfach simulierten) Daten aus:\n\nn &lt;- 40  # Anzahl Versuchspersonen\nn_items &lt;- 10  # Anzahl Items pro Messung von y\nprob &lt;- c(.5, .7, .9)  # Lösungswahrscheinlichkeit pro Messzeitpunkt (t1, t2, t3)\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nset.seed(42)\nd &lt;-\n  tibble(id = 1:n,\n         y1 = rbinom(n = n, size = n_items, prob = prob[1]),\n         y2 = rbinom(n = n, size = n_items, prob = prob[2]),\n         y3 = rbinom(n = n, size = n_items, prob = prob[3]),\n         g = c(rep(times = n/2, x = \"A\"), rep(times = n/2, x = \"B\"))\n         )\nhead(d)\n\n# A tibble: 6 × 5\n     id    y1    y2    y3 g    \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1     1     7     8     9 A    \n2     2     7     7    10 A    \n3     3     4     9     9 A    \n4     4     7     4     9 A    \n5     5     6     7     8 A    \n6     6     5     4     9 A    \n\n\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#pakete-starten",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#pakete-starten",
    "title": "within-design-analysis1",
    "section": "Pakete starten",
    "text": "Pakete starten\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-aufbereiten",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-aufbereiten",
    "title": "within-design-analysis1",
    "section": "Daten aufbereiten",
    "text": "Daten aufbereiten\nUm die Daten (besser) analysieren zu können, formen wir sie ins “lange Format” um.\n\nd_long &lt;-\n  d %&gt;% \n  pivot_longer(cols = c(y1, y2, y3), names_to = \"time\", values_to = \"y\")"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen",
    "title": "within-design-analysis1",
    "section": "Daten zusammenfassen",
    "text": "Daten zusammenfassen\n\nd_long %&gt;% \n  group_by(time) %&gt;% \n  summarise(y_mean = mean(y),\n            y_sd = sd(y)) %&gt;% \n  mutate(delta = y_mean - lag(y_mean))\n\n# A tibble: 3 × 4\n  time  y_mean  y_sd delta\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 y1      5.45 1.74  NA   \n2 y2      7.05 1.55   1.6 \n3 y3      8.98 0.891  1.92"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-visualisieren",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-visualisieren",
    "title": "within-design-analysis1",
    "section": "Daten visualisieren",
    "text": "Daten visualisieren\n\nd_long %&gt;% \n  ggplot(aes(x = time, y = y)) +\n  geom_jitter(width = .1) +\n  stat_summary(fun.y = mean, geom = \"point\", color = \"red\", size = 3) +\n  stat_summary(fun.y = mean, geom = \"line\", color = \"red\", linewidth = 1, group = 1) \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n\n\nMan sieht, dass der Wert von Y steigt von t1 zu t2 und genauso von t2 zu t3."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-transformieren",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-transformieren",
    "title": "within-design-analysis1",
    "section": "Daten transformieren",
    "text": "Daten transformieren\nMan kann auch die Veränderung (das “delta”) zwischen den Messzeitpunkten berechnen, um dann zu prüfen, ob dieses delta dann positiv ist.\n\nd2 &lt;-\n  d %&gt;% \n  mutate(t2mt1 = y2 - y1,  # t2 *m*inus t1\n         t3mt2 = y3 - y2,  # t3 minus t2\n         t3mt1 = y3 - y1)  # t3 mind t1, die Gesamtveränderung von \"Anfang\" zu \"Ende\"\n\n\nd2_long &lt;- \n  d2 %&gt;% \n  pivot_longer(cols = c(t2mt1, t3mt2, t3mt1), names_to = \"time\", values_to = \"delta\")"
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen-1",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#daten-zusammenfassen-1",
    "title": "within-design-analysis1",
    "section": "Daten zusammenfassen",
    "text": "Daten zusammenfassen\n\nd2_long %&gt;% \n  group_by(time) %&gt;% \n  summarise(delta_mean = mean(delta),\n            delta_sd = sd(delta)) %&gt;% \n  mutate(delta2 = delta_mean - lag(delta_mean))\n\n# A tibble: 3 × 4\n  time  delta_mean delta_sd delta2\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 t2mt1       1.6      2.63  NA   \n2 t3mt1       3.52     1.78   1.92\n3 t3mt2       1.92     1.97  -1.6 \n\n\nWie man sieht, ist das Delta t2mt1 positiv, im Mittelwert steigt also y. Gleiches gilt für t3mt2 und t3mt1.\n\nd2_long %&gt;% \n  filter(time != \"t3mt1\") %&gt;% \n  ggplot(aes(x = time, y = delta)) +\n  geom_jitter(width = .1) +\n  stat_summary(fun.y = mean, geom = \"point\", color = \"red\", size = 3) +\n  stat_summary(fun.y = mean, geom = \"line\", color = \"red\", linewidth = 1, group = 1) \n\n\n\n\n\n\n\n\nDie Veränderungen von t1 zu t2 (t2mt1) sind ähnlich zu denen von t2 zu t3 (t3mt2)."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#modell-t2mt1",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#modell-t2mt1",
    "title": "within-design-analysis1",
    "section": "Modell t2mt1",
    "text": "Modell t2mt1\nDas entsprechende Regressionsmodell für t2mt2 liefert einfach den Mittelwert des Deltas.\n\nm1_t2mt1 &lt;- lm(t2mt1 ~ 1, data = d2)\ncoef(m1_t2mt1)\n\n(Intercept) \n        1.6 \n\n\nEin Bayes-Modell hat den Vorteil, dass es uns einfach zu interpretierende Inferenzstatistik gibt.\n\nm1_bayes &lt;- stan_glm(t2mt1 ~ 1, data = d2, refresh = 0)\ncoef(m1_bayes)\n\n(Intercept) \n   1.602565 \n\n\n\nparameters(m1_bayes)\n\nParameter   | Median |       95% CI |     pd |  Rhat |     ESS |                 Prior\n--------------------------------------------------------------------------------------\n(Intercept) |   1.60 | [0.77, 2.47] | 99.95% | 1.000 | 2449.00 | Normal (1.60 +- 6.57)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nMit einer Wahrscheinlichkeit von 100% ist das Delta positiv (laut m1_bayes). Das kann man aus dem Koeffizienten pd ablesen (probability of direction)."
  },
  {
    "objectID": "posts/within-design-analysis1/within-design-analysis1.html#m_t3mt2",
    "href": "posts/within-design-analysis1/within-design-analysis1.html#m_t3mt2",
    "title": "within-design-analysis1",
    "section": "m_t3mt2",
    "text": "m_t3mt2\n\nm_t3mt2_bayes &lt;- stan_glm(t3mt2 ~ 1, data = d2, refresh = 0)\nparameters(m_t3mt2_bayes)\n\nParameter   | Median |       95% CI |   pd |  Rhat |     ESS |                 Prior\n------------------------------------------------------------------------------------\n(Intercept) |   1.93 | [1.32, 2.53] | 100% | 1.001 | 2753.00 | Normal (1.93 +- 4.92)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nAuch hier ist das Modell sehr meinungsstark: Mit einer Wahrscheinlichkeit von 100% ist der Koeffizient (Veränderung von t2 zu t3) positiv.\n\nCategories:\n\nregression\nwithin-design\nresearchdesign\nfopro\nstring"
  },
  {
    "objectID": "posts/wikipedia/index.html",
    "href": "posts/wikipedia/index.html",
    "title": "wikipedia",
    "section": "",
    "text": "1 Aufgabe\nIn Ihrem Buch “Active Statistics” beschreiben die Autoren eine Studie der Wikipedia-Organisation (Gelman & Vehtari, 2024), vgl. S. 33f.\nIn der Studie - ein kontrolliertes Experiment, auch “A/B-Test” genannt - wurde der Effekt von abgerundeten vs. quadratischen Ecken von Textboxen auf die Spendenbereitschaft untersucht (s. Abb. 2, S. 34). (Das Buch ist kostenfrei auf der Webseite zum Buch erhältlich.)\nRunde Ecken:\n\nQuadratische Ecken:\n\nDas Wikipedia-Team gab folgende Stichprobengrößen an:\n\nn_control_group &lt;- 954630  # runde Ecken\nn_exp_group &lt;- 1082180  # quadratische Ecken\nn_total &lt;- n_control_group + n_exp_group\n\nDamit liegt der Anteil der Experimentalgruppe am Gesamtstichprobenumfang bei 53%:\n\nn_exp_group / n_total\n\n[1] 0.5313112\n\n\nWie hoch ist die Wahrscheinlichkeit, einen so großen, d.h. 53% vs. 47%, (oder noch größeren) Unterschied in den Umfängen der beiden Stichproben zu erhalten, unter der Annahme einer zufälligen Aufteilung?\nHinweise:\n\nNutzen Sie Simulationstechniken.\nDie Wahrscheinlichkeit ist auf 2 Dezimalen zu runden.\n\n\n\n2 Lösung\n\nlibrary(tidyverse)\nlibrary(ggpubr)  # Visualisierung\n\nWir führen probehalber den Versuch einmal durch. Hat jemand mal eben zwei Millionen Münzen? Anstelle von Münzen können wir auch den Computer nutzen.\nWir bezeichnen die beiden Ausgänge des Münzwurfexperiments mit 0 (Kontrollgruppe) und 1 (Experimentalgruppe). Eine 1 bedeutet also, dass eine Person der Experimentalgruppe zugeordnet wurde und eine 0, dass sie der Kontrollgruppe zugeordnet wurde.\nDen Münzwurf wiederholen wir n_total Mal:\n\nset.seed(42)  # Zufallszahlen festlegen, zur Reproduzierbarkeit\nwikipedia_experiment &lt;- sample(\n  x = c(0,1),  # Ergebnisraum\n  size = n_total,  # Anzahl der Münzen\n  replace = TRUE)  # Ziehen mit Zurücklegen\n\nMit sample können wir Stichproben ziehen, z.B. von Münzwürfen.\nDas Ergebnis ist ein lange Reihe von 0 und 1, die die jeweiligen Ergebnisse der Münzwürfe darstellt. Hier sind die ersten paar Ergebnisse:\n\nhead(wikipedia_experiment, n = 20)\n\n [1] 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1\n\n\nWenn wir jetzt den Mittelwert berechnen, haben wir damit den Anteil der Experimentalgruppe an der Gesamtstichprobe:\n\nanteil_exp_gruppe &lt;- mean(wikipedia_experiment)\nanteil_exp_gruppe\n\n[1] 0.5002185\n\n\nSehr nah dran an der exakten Hälfte! Dieser Versuchsausgang spricht dagegen, dass 53% dass Ergebnis einer Zufallsaufteilung (in Experimental- und Kontrollgruppe) ist. Aber vielleicht war es nur Pech bzw. Glück? Vielleicht würde das Experiment, wenn wir nochmal die ca. 2 Millionen Münzen werfen, zu einem ganz anderen Ergebnis kommen?\nProbieren wir es aus! Wir wiederholen das Experiment sagen wir n_reps = 100 Mal und notieren jedes Mal den Anteil der Experimentalgruppe am Stichprobenumfang.\n\nn_reps &lt;- 100\n\nDazu hilft die Funktion replicate, die die Münzwurf (Funktion sample plus (danach) mean) beliebig oft wiederholt:\n\nset.seed(42)\nviele_versuche &lt;- replicate(n_reps, \n                            sample(x = c(0,1), \n                                   size = n_total,\n                                   replace = TRUE) |&gt; \n                              mean())\n\nHier sind die Ergebnisse:\n\nviele_versuche\n\n  [1] 0.5002185 0.5001561 0.5004016 0.4997148 0.4999867 0.4998606 0.5006157\n  [8] 0.4999214 0.4997987 0.5005185 0.5001198 0.5008940 0.4995905 0.4995876\n [15] 0.5000462 0.5000658 0.5000570 0.5002308 0.5000756 0.5002509 0.4999126\n [22] 0.4995596 0.4996062 0.4993976 0.5003250 0.5002921 0.5004021 0.4996809\n [29] 0.5000844 0.4997948 0.4999995 0.5002170 0.5000025 0.5005086 0.4999362\n [36] 0.5003211 0.5008872 0.4996401 0.4998296 0.5004311 0.5002288 0.4998660\n [43] 0.4993681 0.4996784 0.5001031 0.4996779 0.5003638 0.4997722 0.4999656\n [50] 0.4993347 0.4998650 0.4998871 0.5000128 0.5000786 0.5005307 0.5001576\n [57] 0.5000417 0.4998424 0.4998449 0.4998606 0.5005715 0.5002686 0.4999651\n [64] 0.5001060 0.4996313 0.5003024 0.5000948 0.5005975 0.5002897 0.4995689\n [71] 0.5002278 0.4997894 0.5002254 0.5000304 0.4998719 0.5005464 0.4998012\n [78] 0.4998714 0.4999396 0.4999008 0.4995149 0.5001267 0.5003800 0.4999273\n [85] 0.4995100 0.5000584 0.5000172 0.5005818 0.5003000 0.4997800 0.4999887\n [92] 0.4998915 0.5001939 0.4997683 0.4999651 0.4996475 0.5001630 0.4998046\n [99] 0.5006564 0.4997820\n\n\nEin paar Statistiken dazu:\n\nmean(viele_versuche)\n\n[1] 0.5000308\n\nsd(viele_versuche)\n\n[1] 0.0003243425\n\nmedian(viele_versuche)\n\n[1] 0.5000076\n\nIQR(viele_versuche)\n\n[1] 0.0004255429\n\n\nWie man sieht, ist die Streuung sehr gering: Alle Ergebnisse streuen sehr eng um 1/2 (50%). Von 3 Prozentpunkten Abweichung ist nichts zu sehen.\nVielleicht ist es nützlich, wenn man diesen Vektor (viele_versuche) visualisiert, z.B. mit einem Histogramm aus ggpubr.\nDie Daten benötigen wir dazu als Dataframe:\n\nd &lt;- tibble(viele_versuche)\n\nglimpse(d)\n\nRows: 100\nColumns: 1\n$ viele_versuche &lt;dbl&gt; 0.5002185, 0.5001561, 0.5004016, 0.4997148, 0.4999867, …\n\n\n\ngghistogram(d, x = \"viele_versuche\",\n            add = \"mean\")\n\n\n\n\n\n\n\n\nHier noch ein Dichtediagramm, da sieht man die Verteilungsform besser:\n\nggdensity(d, x = \"viele_versuche\")\n\n\n\n\n\n\n\n\nUnter der Annahme einer Normalverteilung (was man als hinreichend gegeben betrachten kann), liegen ca. 95% der Werte zwischen MW ± 2 sd, bzw. ca. 99% nicht weiter als 3 sd vom MW entfernt.\nFazit: Unsere Simulation zeigt, dass die Wahrscheinlichkeit für einen Stichprobenanteil von 53% sehr klein ist, kleiner als 1 von 100 in unserer Simulation (1%) und vermutlich noch deutlich kleiner als 1%.\nWir können daraus schließen, dass die Zufallszuteilung (Randomisierung) nicht richtig funktioniert hat. Hätte sie funktioniert, wäre eine Aufteilung von 53% zu 47% kaum zu erwarten gewesen.\nAnders gesagt verwerfen wir die (Null-)Hypothese einer zufälligen Zuteilung zu den Gruppen.\n\n\n\n\n\n\n\nReferences\n\nGelman, A., & Vehtari, A. (2024). Active statistics: Stories, games, problems, and hands-on demonstrations for applied regression and causal inference (1st ed.). Cambridge University Press. https://doi.org/10.1017/9781009436243"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html",
    "title": "wfsets_penguins01",
    "section": "",
    "text": "Berechnen Sie die Vorhersagegüte (RMSE) für folgende Lernalgorithmen:\n\nlineares Modell\nknn (neighbors: tune)\n\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nNutzen Sie minimale Vorverarbeitung."
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#setup",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#setup",
    "title": "wfsets_penguins01",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(penguins, package = \"palmerpenguins\")"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#daten",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#daten",
    "title": "wfsets_penguins01",
    "section": "Daten",
    "text": "Daten\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()\n\n\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#modelle",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#modelle",
    "title": "wfsets_penguins01",
    "section": "Modelle",
    "text": "Modelle\nLineares Modell:\n\nmod_lin &lt;- linear_reg()\n\nmod_knn &lt;- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#rezepte",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#rezepte",
    "title": "wfsets_penguins01",
    "section": "Rezepte",
    "text": "Rezepte\n\nrec_basic &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n         step_normalize(all_predictors())\n\nrec_basic"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#resampling",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#resampling",
    "title": "wfsets_penguins01",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpls &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#workflow-set",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#workflow-set",
    "title": "wfsets_penguins01",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic),\n    models = list(mod_lm = mod_lin,\n                  mod_nn = mod_knn)\n  )\n\nwf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result    \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 rec_simple_mod_nn &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#fitten",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#fitten",
    "title": "wfsets_penguins01",
    "section": "Fitten",
    "text": "Fitten\n\nwf_fit &lt;-\n  wf_set %&gt;% \n  workflow_map(resamples = rsmpls)\n\nwf_fit\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result   \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;rsmp[+]&gt;\n2 rec_simple_mod_nn &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;tune[+]&gt;\n\n\nCheck:\n\nwf_fit %&gt;% pluck(\"result\")\n\n[[1]]\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [224/25]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [224/25]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [224/25]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [224/25]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [224/25]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [224/25]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [224/25]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [224/25]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [224/25]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [225/24]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n[[2]]\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [224/25]&gt; Fold01 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [224/25]&gt; Fold02 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [224/25]&gt; Fold03 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [224/25]&gt; Fold04 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [224/25]&gt; Fold05 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [224/25]&gt; Fold06 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [224/25]&gt; Fold07 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [224/25]&gt; Fold08 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [224/25]&gt; Fold09 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [225/24]&gt; Fold10 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#bester-kandidat",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#bester-kandidat",
    "title": "wfsets_penguins01",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(wf_fit)\n\n\n\n\n\n\n\n\n\nautoplot(wf_fit, select_best = TRUE)\n\n\n\n\n\n\n\n\n\nrank_results(wf_fit, rank_metric = \"rmse\") %&gt;% \n  filter(.metric == \"rmse\")\n\n# A tibble: 9 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 rec_simple_mod_nn Prepro… rmse     642.    31.3    10 recipe       near…     1\n2 rec_simple_mod_nn Prepro… rmse     646.    30.9    10 recipe       near…     2\n3 rec_simple_mod_lm Prepro… rmse     647.    24.0    10 recipe       line…     3\n4 rec_simple_mod_nn Prepro… rmse     648.    32.2    10 recipe       near…     4\n5 rec_simple_mod_nn Prepro… rmse     659.    31.7    10 recipe       near…     5\n6 rec_simple_mod_nn Prepro… rmse     660.    32.2    10 recipe       near…     6\n7 rec_simple_mod_nn Prepro… rmse     687.    36.4    10 recipe       near…     7\n8 rec_simple_mod_nn Prepro… rmse     729.    39.7    10 recipe       near…     8\n9 rec_simple_mod_nn Prepro… rmse     786.    47.6    10 recipe       near…     9\n\n\nAm besten war das lineare Modell, aber schauen wir uns auch mal das knn-Modell an, v.a. um zu wissen, wie man den besten Tuningparameter-Wert sieht:\n\nextract_workflow_set_result(wf_fit, \"rec_simple_mod_nn\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 1 × 2\n  neighbors .config             \n      &lt;int&gt; &lt;chr&gt;               \n1        14 Preprocessor1_Model8"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#last-fit",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#last-fit",
    "title": "wfsets_penguins01",
    "section": "Last Fit",
    "text": "Last Fit\n\nbest_wf &lt;-\n  wf_fit %&gt;% \n  extract_workflow(\"rec_simple_mod_lm\")\n\nFinalisieren müssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\nfit_final &lt;-\n  best_wf %&gt;% \n  last_fit(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins01/wfsets_penguins01.html#modellgüte-im-test-set",
    "href": "posts/wfsets_penguins01/wfsets_penguins01.html#modellgüte-im-test-set",
    "title": "wfsets_penguins01",
    "section": "Modellgüte im Test-Set",
    "text": "Modellgüte im Test-Set\n\ncollect_metrics(fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     658.    Preprocessor1_Model1\n2 rsq     standard       0.342 Preprocessor1_Model1\n\n\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html",
    "href": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html",
    "title": "Wertzuweisen_mc",
    "section": "",
    "text": "Welche der folgenden Syntax-Varianten ist/sind formal (“syntaktisch”) korrekt?\n\n\n\nloesung &lt;-42\nloesung &lt; - 42\nloesung-&gt;42\nloesung==42\nloesung&lt;-\"42\""
  },
  {
    "objectID": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist",
    "href": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist",
    "title": "Wertzuweisen_mc",
    "section": "",
    "text": "loesung &lt;-42\nloesung &lt; - 42\nloesung-&gt;42\nloesung==42\nloesung&lt;-\"42\""
  },
  {
    "objectID": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist-1",
    "href": "posts/Wertzuweisen_mc/Wertzuweisen_mc.html#answerlist-1",
    "title": "Wertzuweisen_mc",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nR\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/Wertpruefen/Wertpruefen.html",
    "href": "posts/Wertpruefen/Wertpruefen.html",
    "title": "Wertpruefen",
    "section": "",
    "text": "Aufgabe\nGeben Sie die R-Syntax ein, um zu prüfen, dass die Variable loesung den Wert 42 hat.\nHinweis: Geben Sie Ihre Lösung ohne Leerzeichen an, da sonst eine richtige Lösung nicht erkannt werden kann.\n         \n\n\nLösung\nloesung==42\n\nCategories:\n\nR\n‘2023’\nstring"
  },
  {
    "objectID": "posts/Wertberechnen/Wertberechnen.html",
    "href": "posts/Wertberechnen/Wertberechnen.html",
    "title": "Wertberechnen",
    "section": "",
    "text": "Aufgabe\nWelchen Wert bzw. welches Ergebnis liefert folgende R-Syntax für ergebnis zurück?\nx hat zu Beginn den Wert 3.\nHinweis: sqrt(x) liefert die (positive) Quadratwurzel von x zurück.\n         \n\n\nLösung\nEs wird 2 zurückgeliefert.\n\nCategories:\n\nR\ndyn\nnum"
  },
  {
    "objectID": "posts/Warum-Bayes/Warum-Bayes.html",
    "href": "posts/Warum-Bayes/Warum-Bayes.html",
    "title": "Warum-Bayes",
    "section": "",
    "text": "Exercise\nNennen Sie einen (fachlichen) Grund, warum Sie eine Bayes-Analyse machen würden (und nicht etwa ein Analyse auf Basis der frequentistischen Statistik).\n         \n\n\nSolution\nEs existieren mehrere Gründe, einige wichtige sind:\n\nBayes-Analysen erlauben es, Vorwissen in die Analyse einfließen zu lassen.\nBayes-Analysen geben die Wahrscheinlichkeit einer Hypothese bzw. eines Parameterwerts zurück.\nBayes-Analysen erlauben es, Modelle exakt und flexibel zu spezifizieren.\nBayes-Analysen sind bei kleineren Stichproben genauer.\n\n“Quantifizierung” ist keine ausreichende Begründung für die Verwendung der Bayes-Statistik, da auch z.B. eine Frequentistische Analyse Quantifizierung bietet. Hingegen ist “Quantifizierung der Wahrscheinlichkeit der Forschungshypothese” ein valider Grund, denn der Frequentismus erlaubt nicht die Wahrscheinlichkeit einer Hypothese zu quantifizieren.\n“Wahrscheinlichkeitsaussagen” ist ebenfalls keine ausreichende Begründung für Bayes, denn auch im Frequentismus gibt es Wahrscheinlichkeitsaussagen, auch wenn diese weniger stark in die Wahrscheinlichkeitstheorie geknüpft sind als die Bayes-Inferenz (vgl. Jaynes, 2003).\nEs ist als Begründung nicht ausreichend, z.B. von “Erwartungen ans die Auswertung” zu sprechen, wenn man auf die Priori-Verteilung als (valider) Vorteil der Bayes-Inferenz abzielen möchte.\nEbenso ist es nicht ausreichend, allgemein auf eine “höhere Zuverlässigkeit” o.Ä. der Bayes-Inferenz hinzuweisen.\nDas ROPE ist eine praktische, sinnvolle Methode, allerdings gibt es mittlerweile vergleichbare Verfahren im Frequentismus, sog. Äquivalenztests.\nDer Grund, warum Bayes-Analysen bei kleineren Stichproben zu genaueren Ergebnissen kommen, liegt im Priori-Wissen. Spezifiziert man z.B. eine Normalverteilung mit Sigma=1 und findet in den Daten einen Wert von zB. Sigma=6, also einen extremen Ausreißer, so wird die Priori-Verteilung dafür sorgen, den Extremwert “zurechtzustutzen” auf einen Wert näher der Mittelwert der Verteilung. Sofern dies sinnvoll/korrekt ist, wird man mit diesem Vorgehen zu genaueren Ergebnissen kommen. Die Hoffnung ist, dass einzelne Extremwerte eher Messfehler sind.\n\nCategories:\n\nqm2\nbayes\nprobability"
  },
  {
    "objectID": "posts/voll-normal/voll-normal.html",
    "href": "posts/voll-normal/voll-normal.html",
    "title": "voll-normal",
    "section": "",
    "text": "Exercise\nNehmen wir an, \\(k=10\\) voneinander unabhängige Eigenschaften \\(E_1, E_2, \\ldots, E_{10}\\) bestimmen, ob eine Person als “normal” angesehen wird. Jede dieser Eigenschaften kann entweder mit “normal” (n) oder aber “nichtnormal” (nn) ausgeprägt sein, wobei wir nicht genau vorhersagen können, wie diese Eigenschaften bei einer Person bestellt sein werden.\nAls Zufallsexperiment ausgedrückt: \\(\\Omega_E := \\{n, nn\\}\\) mit den zwei Ergebnissen \\(n\\) und \\(nn\\).\nMit der Wahrscheinlichkeit \\(Pr_{E_i} = 0.9\\) treffe das Ereignis \\(N_i := E_i = \\{n\\}\\) (für alle \\(i = 1, \\ldots, k\\)) zu.\nNehmen wir weiter an, als “voll normal” (\\(VN\\)) wird eine Person genau dann angesehen, wenn sie in allen \\(k\\) Eigenschaften “normal” ausgeprägt ist, das Ereignis \\(N\\) also für alle \\(k\\) Eigenschaften auftritt.\n\nNennen Sie Beispiele für mögliche Eigenschaften \\(E\\)!\nWie groß ist die Wahrscheinlichkeit - unter den hier geschilderten Annahmen -, dass eine Person “voll normal” ist?\nDiskutieren Sie die Plausibilität der Annahmen!\n\n         \n\n\nSolution\n\nIntelligenz, Aussehen, Gesundheit, Herkunft, Hautfarbe, sexuelle Identität oder Neigung, …\nFür unabhängige Ereignisse ist die Wahrscheinlichkeit, dass sie alle eintreten, gleich dem Produkt ihrer Einzelwahrscheinlichkeiten:\n\n\\(VN = Pr(E_i)^{10} = 0.9^{10} \\approx 0.3486784\\)\nDie Wahrscheinlichkeit, dass \\(VN\\) nicht eintritt (Nicht-Voll-Normal, NVN), ist dann die Gegenwahrscheinlichkeit: \\(NVN = 1- VN\\).\n\nMehrere der Annahmen sind diskutabel. So könnten die Eigenschaften nicht unabhängig sein, dann wäre der hier gezeigte Rechenweg nicht anwendbar. Die Wahrscheinlichkeit für “normal” könnte höher oder niedriger sein, wobei 90% nicht ganz unplausibel ist. Schließlich unterliegt das Ereignis \\(E_N\\) mit den Ergebnissen \\(n\\) bzw. \\(nn\\) sozialpsychologischen bzw. soziologischen Einflüssen und kann variieren.\n\n\nCategories:\n\nprobability\nmeta"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html",
    "href": "posts/vis-mtcars/vis-mtcars.html",
    "title": "vis-mtcars",
    "section": "",
    "text": "In dieser Fallstudie (YACSDA: Yet another Case Study on Data Analysis) untersuchen wir den Datensatz mtcars.\nSie können den Datensatz so beziehen:\n\ndata(\"mtcars\")\nd &lt;- mtcars \n\nEin Codebook finden Sie hier.\nDie Forschungsfrage lautet:\nWas ist der Einfluss der Schaltung und der PS-Zahl auf den Spritverbrauch?\n\nAbhängige Variable (metrisch), y: Spritverbrauch (mpg)\nUnabhängige Variable 1 (nominal), x1: Schaltung (am)\nUnabhängige Variable 2 (metrisch), x2: PS-Zahl (hp)\n\nVisualisieren Sie dazu folgende Aspekte der Forschungsfrage!"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#umbenennen",
    "href": "posts/vis-mtcars/vis-mtcars.html#umbenennen",
    "title": "vis-mtcars",
    "section": "Umbenennen",
    "text": "Umbenennen\nZur einfacheren Verarbeitung nenne ich die Variablen um:\n\nd &lt;-\n  d |&gt; \n  rename(y = mpg, x1 = am, x2 = hp)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.",
    "text": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.\nDas R-Paket ggpubr erstellt schöne Diagramme (basierend auf ggplot) auf einfache Art. Nehmen wir ein Dichtediagramm; die Variable y soll auf der X-Achse stehen:\n\nggdensity(d, x = \"y\")\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable in Anführungsstriche gesetzt werden muss: x = \"y\".\nOder ein Histogramm:\n\ngghistogram(d, x = \"y\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "href": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "title": "vis-mtcars",
    "section": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.",
    "text": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.\nUm Diagramme mit Statistiken anzureichen, bietet sich das Paket ggstatsplot an:\n\ngghistostats(d, x = y)\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable nicht in Anführungsstriche gesetzt werden darf: x = y."
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie die Verteilung von x1 und x2.",
    "text": "Visualisieren Sie die Verteilung von x1 und x2.\n\nx1\n\nd_counted &lt;- \n  d |&gt; \n  count(x1) \n\n\nggbarplot(data = d_counted, y = \"n\", x = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\n\n\nx2\n\ngghistostats(d, x = x2)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie die Verteilung von y bedingt auf x1",
    "text": "Visualisieren Sie die Verteilung von y bedingt auf x1\n\ngghistogram(d, x = \"y\", fill = \"x1\")\n\n\n\n\n\n\n\n\nOder so:\n\ngghistogram(d, x = \"y\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "href": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "title": "vis-mtcars",
    "section": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu",
    "text": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu\n\ngrouped_gghistostats(d, x = y, grouping.var = x1)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "href": "posts/vis-mtcars/vis-mtcars.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "title": "vis-mtcars",
    "section": "Visualisieren Sie den Zusammenhang von y und x2",
    "text": "Visualisieren Sie den Zusammenhang von y und x2\n\nggscatter(d, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#verbessern-sie-das-letzte-diagramm-so-dass-es-übersichtlicher-wird",
    "href": "posts/vis-mtcars/vis-mtcars.html#verbessern-sie-das-letzte-diagramm-so-dass-es-übersichtlicher-wird",
    "title": "vis-mtcars",
    "section": "Verbessern Sie das letzte Diagramm, so dass es übersichtlicher wird",
    "text": "Verbessern Sie das letzte Diagramm, so dass es übersichtlicher wird\nEs gibt mehrere Wege, das Diagramm übersichtlicher zu machen. Logarithmieren ist ein Weg.\n\nd |&gt; \n  mutate(x2 = log(x2)) |&gt; \n  ggscatter(x = \"x2\", y = \"y\")\n\n\n\n\n\n\n\n\nSynonym könnten wir schreiben:\n\nd_logged &lt;- \n  d |&gt; \n  mutate(x2 = log(x2))\n  \n\nggscatter(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "href": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "title": "vis-mtcars",
    "section": "Fügen Sie dem letzten Diagramm relevante Kennzahlen hinzu",
    "text": "Fügen Sie dem letzten Diagramm relevante Kennzahlen hinzu\n\nggscatterstats(d_logged, x = x2, y = y)"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "href": "posts/vis-mtcars/vis-mtcars.html#fügen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "title": "vis-mtcars",
    "section": "Fügen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu",
    "text": "Fügen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"reg.line\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "href": "posts/vis-mtcars/vis-mtcars.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "title": "vis-mtcars",
    "section": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade",
    "text": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "href": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "title": "vis-mtcars",
    "section": "Gruppieren Sie das letzte Diagramm nach x1",
    "text": "Gruppieren Sie das letzte Diagramm nach x1\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"),\n          facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#dichotomisieren-sie-y-und-zählen-sie-die-häufigkeiten",
    "href": "posts/vis-mtcars/vis-mtcars.html#dichotomisieren-sie-y-und-zählen-sie-die-häufigkeiten",
    "title": "vis-mtcars",
    "section": "Dichotomisieren Sie y und zählen Sie die Häufigkeiten",
    "text": "Dichotomisieren Sie y und zählen Sie die Häufigkeiten\nNehmen wir einen Mediansplit, um zu dichotomisieren.\n\nd &lt;-\n  d |&gt; \n  mutate(y_dicho = ifelse(y &gt; median(y), \"high\", \"low\"))\n\n\nd |&gt; \n  count(y_dicho) |&gt; \n  ggbarplot(x = \"y_dicho\", y = \"n\")\n\n\n\n\n\n\n\n\nGleich viele! Das sollte nicht verwundern."
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "href": "posts/vis-mtcars/vis-mtcars.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "title": "vis-mtcars",
    "section": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1",
    "text": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1\n\nd_count &lt;- \nd |&gt; \n  count(y_dicho, x1) \n\nd_count\n\n  y_dicho x1  n\n1    high  0  4\n2    high  1 11\n3     low  0 15\n4     low  1  2\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"n\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-mtcars/vis-mtcars.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-häufigkeiten-statt-absoluter-häufigkeiten-gezeigt-werden",
    "href": "posts/vis-mtcars/vis-mtcars.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-häufigkeiten-statt-absoluter-häufigkeiten-gezeigt-werden",
    "title": "vis-mtcars",
    "section": "Variieren Sie das letzte Diagramm so, dass Anteile (relative Häufigkeiten) statt absoluter Häufigkeiten gezeigt werden",
    "text": "Variieren Sie das letzte Diagramm so, dass Anteile (relative Häufigkeiten) statt absoluter Häufigkeiten gezeigt werden\n\nd_count &lt;-\n  d_count |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n  y_dicho x1  n prop\n1    high  0  4 0.12\n2    high  1 11 0.34\n3     low  0 15 0.47\n4     low  1  2 0.06\n\n\nCheck:\n\nd_count |&gt; \n  summarise(sum(prop))\n\n  sum(prop)\n1      0.99\n\n\nGut! Die Anteile summieren sich zu ca. 1 (100 Prozent).\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMan beachten, dass sich die Anteile auf das “Gesamt-N” beziehen.\n\nCategories:\n\nvis\nyacsda\nggquick\nmtcars\nstring"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html",
    "href": "posts/vis-gapminder/vis-gapminder.html",
    "title": "vis-gapminder",
    "section": "",
    "text": "In dieser Fallstudie (YACSDA: Yet another Case Study on Data Analysis) untersuchen wir den Datensatz gapminder.\nSie können den Datensatz so beziehen:\n\n#install.packages(\"gapminder\")\nlibrary(gapminder)\ndata(\"gapminder\")\nd &lt;- gapminder \n\nOder so:\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/gapminder/gapminder.csv\")\n\nEin Codebook finden Sie hier.\nDie Forschungsfrage lautet:\nWas ist der Einfluss des Kontinents und des Bruttosozialprodukts auf die Lebenswartung?\n\nAbhängige Variable (metrisch), y: Lebenserwartung\nUnabhängige Variable 1 (nominal), x1: Kontinent\nUnabhängige Variable 2 (metrisch), x2: Bruttosozialprodukt\n\nVisualisieren Sie dazu folgende Aspekte der Forschungsfrage!"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#umbenennen",
    "href": "posts/vis-gapminder/vis-gapminder.html#umbenennen",
    "title": "vis-gapminder",
    "section": "Umbenennen",
    "text": "Umbenennen\nZur einfacheren Verarbeitung nenne ich die Variablen um:\n\nd &lt;-\n  d |&gt; \n  rename(y = lifeExp, x1 = continent, x2 = gdpPercap)"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.",
    "text": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.\nDas R-Paket ggpubr erstellt schöne Diagramme (basierend auf ggplot) auf einfache Art. Nehmen wir ein Dichtediagramm; die Variable y soll auf der X-Achse stehen:\n\nggdensity(d, x = \"y\")\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable in Anführungsstriche gesetzt werden muss: x = \"y\".\nOder ein Histogramm:\n\ngghistogram(d, x = \"y\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`."
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "href": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu.",
    "title": "vis-gapminder",
    "section": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.",
    "text": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu.\nUm Diagramme mit Statistiken anzureichen, bietet sich das Paket ggstatsplot an:\n\ngghistostats(d, x = y)\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable nicht in Anführungsstriche gesetzt werden darf: x = y."
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie die Verteilung von x1 und x2.",
    "text": "Visualisieren Sie die Verteilung von x1 und x2.\n\nx1\n\nd_counted &lt;- \n  d |&gt; \n  count(x1) \n\n\nggbarplot(data = d_counted, y = \"n\", x = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\n\n\nx2\n\ngghistostats(d, x = x2)"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie die Verteilung von y bedingt auf x1",
    "text": "Visualisieren Sie die Verteilung von y bedingt auf x1\n\ngghistogram(d, x = \"y\", fill = \"x1\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`.\n\n\n\n\n\n\n\n\n\nOder so:\n\ngghistogram(d, x = \"y\", facet.by = \"x1\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`."
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "href": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "title": "vis-gapminder",
    "section": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu",
    "text": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu\n\ngrouped_gghistostats(d, x = y, grouping.var = x1)"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "href": "posts/vis-gapminder/vis-gapminder.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "title": "vis-gapminder",
    "section": "Visualisieren Sie den Zusammenhang von y und x2",
    "text": "Visualisieren Sie den Zusammenhang von y und x2\n\nggscatter(d, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#verbessern-sie-das-letzte-diagramm-so-dass-es-übersichtlicher-wird",
    "href": "posts/vis-gapminder/vis-gapminder.html#verbessern-sie-das-letzte-diagramm-so-dass-es-übersichtlicher-wird",
    "title": "vis-gapminder",
    "section": "Verbessern Sie das letzte Diagramm, so dass es übersichtlicher wird",
    "text": "Verbessern Sie das letzte Diagramm, so dass es übersichtlicher wird\nEs gibt mehrere Wege, das Diagramm übersichtlicher zu machen. Logarithmieren ist ein Weg.\n\nd |&gt; \n  mutate(x2 = log(x2)) |&gt; \n  ggscatter(x = \"x2\", y = \"y\")\n\n\n\n\n\n\n\n\nSynonym könnten wir schreiben:\n\nd_logged &lt;- \n  d |&gt; \n  mutate(x2 = log(x2))\n  \n\nggscatter(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "href": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "title": "vis-gapminder",
    "section": "Fügen Sie dem letzten Diagramm relevante Kennzahlen hinzu",
    "text": "Fügen Sie dem letzten Diagramm relevante Kennzahlen hinzu\n\nggscatterstats(d_logged, x = \"x2\", y = \"y\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "href": "posts/vis-gapminder/vis-gapminder.html#fügen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "title": "vis-gapminder",
    "section": "Fügen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu",
    "text": "Fügen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"reg.line\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "href": "posts/vis-gapminder/vis-gapminder.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "title": "vis-gapminder",
    "section": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade",
    "text": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"))"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "href": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "title": "vis-gapminder",
    "section": "Gruppieren Sie das letzte Diagramm nach x1",
    "text": "Gruppieren Sie das letzte Diagramm nach x1\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"),\n          facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#dichotomisieren-sie-y-und-zählen-sie-die-häufigkeiten",
    "href": "posts/vis-gapminder/vis-gapminder.html#dichotomisieren-sie-y-und-zählen-sie-die-häufigkeiten",
    "title": "vis-gapminder",
    "section": "Dichotomisieren Sie y und zählen Sie die Häufigkeiten",
    "text": "Dichotomisieren Sie y und zählen Sie die Häufigkeiten\nNehmen wir einen Mediansplit, um zu dichotomisieren.\n\nd &lt;-\n  d |&gt; \n  mutate(y_dicho = ifelse(y &gt; median(y), \"high\", \"low\"))\n\n\nd |&gt; \n  count(y_dicho) |&gt; \n  ggbarplot(x = \"y_dicho\", y = \"n\")\n\n\n\n\n\n\n\n\nGleich viele! Das sollte nicht verwundern."
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "href": "posts/vis-gapminder/vis-gapminder.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "title": "vis-gapminder",
    "section": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1",
    "text": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1\n\nd_count &lt;- \nd |&gt; \n  count(y_dicho, x1) \n\nd_count\n\n# A tibble: 9 × 3\n  y_dicho x1           n\n  &lt;chr&gt;   &lt;fct&gt;    &lt;int&gt;\n1 high    Africa      64\n2 high    Americas   211\n3 high    Asia       207\n4 high    Europe     346\n5 high    Oceania     24\n6 low     Africa     560\n7 low     Americas    89\n8 low     Asia       189\n9 low     Europe      14\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"n\", facet.by = \"x1\")"
  },
  {
    "objectID": "posts/vis-gapminder/vis-gapminder.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-häufigkeiten-statt-absoluter-häufigkeiten-gezeigt-werden",
    "href": "posts/vis-gapminder/vis-gapminder.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-häufigkeiten-statt-absoluter-häufigkeiten-gezeigt-werden",
    "title": "vis-gapminder",
    "section": "Variieren Sie das letzte Diagramm so, dass Anteile (relative Häufigkeiten) statt absoluter Häufigkeiten gezeigt werden",
    "text": "Variieren Sie das letzte Diagramm so, dass Anteile (relative Häufigkeiten) statt absoluter Häufigkeiten gezeigt werden\n\nd_count &lt;-\n  d_count |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n# A tibble: 9 × 4\n  y_dicho x1           n  prop\n  &lt;chr&gt;   &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 high    Africa      64  0.04\n2 high    Americas   211  0.12\n3 high    Asia       207  0.12\n4 high    Europe     346  0.2 \n5 high    Oceania     24  0.01\n6 low     Africa     560  0.33\n7 low     Americas    89  0.05\n8 low     Asia       189  0.11\n9 low     Europe      14  0.01\n\n\nCheck:\n\nd_count |&gt; \n  summarise(sum(prop))\n\n# A tibble: 1 × 1\n  `sum(prop)`\n        &lt;dbl&gt;\n1        0.99\n\n\nGut! Die Anteile summieren sich zu ca. 1 (100 Prozent).\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMan beachten, dass sich die Anteile auf das “Gesamt-N” beziehen.\nVielleicht möchten wir die Anteile lieber pro Stufe von x1 beziehen. Dazu gruppieren wir nach (und pro Stufe von) x1.\n\nd_count &lt;-\n  d_count |&gt; \n  group_by(x1) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n# A tibble: 9 × 4\n# Groups:   x1 [5]\n  y_dicho x1           n  prop\n  &lt;chr&gt;   &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 high    Africa      64  0.1 \n2 high    Americas   211  0.7 \n3 high    Asia       207  0.52\n4 high    Europe     346  0.96\n5 high    Oceania     24  1   \n6 low     Africa     560  0.9 \n7 low     Americas    89  0.3 \n8 low     Asia       189  0.48\n9 low     Europe      14  0.04\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\n\nCategories:\n\nvis\nyacsda\nggquick\ngapminder\nstring"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html",
    "href": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html",
    "title": "Verteilungen-Quiz-17",
    "section": "",
    "text": "Ei Forschi untersucht die mittlere Körpergröße eines bis dato unbekannten Urwaldvolks. Dabei findet sich aposteriori (also als Ergebnis der Untersuchung) \\(\\bar{x} \\sim N(160,5)\\) (in Zentimetern).\nDis Forschi resümiert: “Mit sehr hoher Wahrscheinlichkeit, also 95%, sind diese Menschen im Schnitt größer als 1 Meter 60 Zentimeter groß”.\nIst diese Aussage korrekt (gegeben der Angaben)?\nHinweise:\n\nNutzen Sie Simulationsmethoden zur Lösung\nFixieren Sie die Zufallszahlen auf die Startzahl 42.\nZiehen Sie \\(10^5\\) Zufallszahlen aus der gegebenen Verteilung.\n\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist",
    "href": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist",
    "title": "Verteilungen-Quiz-17",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-17/Verteilungen-Quiz-17.html#answerlist-1",
    "title": "Verteilungen-Quiz-17",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html",
    "href": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html",
    "title": "Verteilungen-Quiz-15",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nDas HDI schneidet auf beiden Seiten des Intervalls die gleiche Wahrscheinlichkeitsmasse ab.\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist",
    "href": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist",
    "title": "Verteilungen-Quiz-15",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-15/Verteilungen-Quiz-15.html#answerlist-1",
    "title": "Verteilungen-Quiz-15",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html",
    "href": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html",
    "title": "Verteilungen-Quiz-13",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nBei rechtsschiefen Verteilungen gilt \\(\\bar{x} \\gt Md\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist",
    "href": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist",
    "title": "Verteilungen-Quiz-13",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-13/Verteilungen-Quiz-13.html#answerlist-1",
    "title": "Verteilungen-Quiz-13",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html",
    "href": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html",
    "title": "Verteilungen-Quiz-11",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nBei einer Verteilung gilt: \\(\\bar{x} = Md = \\text{Modus}\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist",
    "href": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist",
    "title": "Verteilungen-Quiz-11",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-11/Verteilungen-Quiz-11.html#answerlist-1",
    "title": "Verteilungen-Quiz-11",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html",
    "href": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html",
    "title": "Verteilungen-Quiz-09",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\ge \\bar{x} + \\sigma) \\approx 0.84\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html#answerlist",
    "href": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html#answerlist",
    "title": "Verteilungen-Quiz-09",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-09/Verteilungen-Quiz-09.html#answerlist-1",
    "title": "Verteilungen-Quiz-09",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html",
    "href": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html",
    "title": "Verteilungen-Quiz-07",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\le 100) \\ne 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist",
    "href": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist",
    "title": "Verteilungen-Quiz-07",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-07/Verteilungen-Quiz-07.html#answerlist-1",
    "title": "Verteilungen-Quiz-07",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html",
    "href": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html",
    "title": "Verteilungen-Quiz-05",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nIst eine stetige Verteilung symmetrisch, gilt dann\n\\(Pr(X \\ge \\bar{x} + 1) = Pr(X \\le \\bar{x} - 1)\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html#answerlist",
    "href": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html#answerlist",
    "title": "Verteilungen-Quiz-05",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-05/Verteilungen-Quiz-05.html#answerlist-1",
    "title": "Verteilungen-Quiz-05",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html",
    "href": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html",
    "title": "Verteilungen-Quiz-03",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nWenn eine Verteilung einer stetigen Zufallsvariablen \\(X\\) (z.B. die Posteriori-Verteilung einer Bayes-Analyse) normalverteilt ist, gilt dann \\(Pr(X \\ge\\bar{x}) = 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist",
    "href": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist",
    "title": "Verteilungen-Quiz-03",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-03/Verteilungen-Quiz-03.html#answerlist-1",
    "title": "Verteilungen-Quiz-03",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-01/Verteilungen-Quiz-01.html",
    "href": "posts/Verteilungen-Quiz-01/Verteilungen-Quiz-01.html",
    "title": "Verteilungen-Quiz-01",
    "section": "",
    "text": "Beziehen Sie sich auf den Standard-Globusversuch mit \\(N=9\\) Würfen und \\(W=6\\) Wassertreffern (binomialverteilt), vgl. hier.\nDie Stichproben-Postverteilung sieht so aus:\n\n\n\n\n\n\n\n\n\nIst sich das Modell auf Basis dieser Post-Verteilung sicher sein, dass der Wasseranteil \\(\\pi=.7\\) beträgt?\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-01/Verteilungen-Quiz-01.html#answerlist",
    "href": "posts/Verteilungen-Quiz-01/Verteilungen-Quiz-01.html#answerlist",
    "title": "Verteilungen-Quiz-01",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-01/Verteilungen-Quiz-01.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-01/Verteilungen-Quiz-01.html#answerlist-1",
    "title": "Verteilungen-Quiz-01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/variation01/variation01.html",
    "href": "posts/variation01/variation01.html",
    "title": "variability01",
    "section": "",
    "text": "In welchem Datensatz, \\(x1, x2, x3, x4\\), gibt es am meisten Variation?\nDatensatz x1:\n\n\n\n\n\nx1\n\n\n\n\n0.14\n\n\n-0.06\n\n\n0.04\n\n\n0.06\n\n\n0.04\n\n\n-0.01\n\n\n0.15\n\n\n-9.47e-03\n\n\n0.20\n\n\n-6.27e-03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatensatz x2:\n\n\n\n\n\nx2\n\n\n\n\n1.30\n\n\n2.29\n\n\n-1.39\n\n\n-0.28\n\n\n-0.13\n\n\n0.64\n\n\n-0.28\n\n\n-2.66\n\n\n-2.44\n\n\n1.32\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatensatz x3:\n\n\n\n\n\nx3\n\n\n\n\n-3.07\n\n\n-17.81\n\n\n-1.72\n\n\n12.15\n\n\n18.95\n\n\n-4.30\n\n\n-2.57\n\n\n-17.63\n\n\n4.60\n\n\n-6.40\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatensatz x4:\n\n\n\n\n\nx4\n\n\n\n\n45.55\n\n\n70.48\n\n\n103.51\n\n\n-60.89\n\n\n50.50\n\n\n-171.70\n\n\n-78.45\n\n\n-85.09\n\n\n-241.42\n\n\n3.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/variation01/variation01.html#answerlist",
    "href": "posts/variation01/variation01.html#answerlist",
    "title": "variability01",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/variation01/variation01.html#answerlist-1",
    "href": "posts/variation01/variation01.html#answerlist-1",
    "title": "variability01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvariablity\nbasics\nschoice"
  },
  {
    "objectID": "posts/Urne2/Urne2.html",
    "href": "posts/Urne2/Urne2.html",
    "title": "Urne2",
    "section": "",
    "text": "Aufgabe\nIn einer Urne befinden sich fünf Kugeln, von denen 4 rot sind und 1 weiß.\nAufgabe: Wie groß ist die Wahrscheinlichkeit, dass bei 2 Ziehungen mit Zurücklegen (ZmZ) genau 2 rote Kugeln gezogen werden?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\nSei \\(R1\\) “rote Kugel im 1. Zug gezogen”.\nSei \\(R2\\) “rote Kugel im 2. Zug gezogen”.\nGesucht ist die gemeinsame Wahrscheinlichkeit für R1 und R2: \\(Pr(R1 \\cap R2)\\), die Wahrscheinlichkeit also, dass beide Ereignisse (R1 und R2) eintreten: \\(Pr(R1 \\cap R2)\\).\nFür R1 gilt: \\(Pr(R1) = 4/5\\).\nFür R2 gilt: \\(Pr(R2|R1) = 4/5\\).\nMan beachte, dass R1 und R2 unabhängig sind: \\(R1 \\perp \\!\\!\\! \\perp R2\\), d.h. sie sind nicht abhängig (voneinander).\n\nPr_R1 &lt;- 4/5\nPr_R2_geg_R1 &lt;- 4/5\nPr_R1_R2 &lt;- Pr_R1 * Pr_R2_geg_R1\nPr_R1_R2\n\n[1] 0.64\n\n\nDie Lösung lautet 0.64.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/ungewiss-arten-regr/ungewiss-arten-regr.html",
    "href": "posts/ungewiss-arten-regr/ungewiss-arten-regr.html",
    "title": "ungewiss-arten-regression",
    "section": "",
    "text": "Exercise\nEine statistische Analyse, wie eine Regression, ist mit mehreren Arten an Ungewissheit konfrontiert. Zum einen gibt es die Ungewissheit in den Modellparametern. Für die Regression bedeutet das: “Liegt die Regressionsgerade in”Wahrheit” (in der Population) genauso wie in der Stichprobe, sind Achsenabschnitt und Steigung in der Stichprobe also identisch zur Popuation?“. Zum anderen die Ungewissheit innerhalb des Modells. Auch wenn wir die”wahre” Regressionsgleichung kennen würden, wären (in aller Regel) die Vorhersagen trotzdem nicht perfekt. Auch wenn wir etwa wüssten, wieviel Klausurpunkte “in Wahrheit” pro Stunde Lernen herausspringen (und wenn wir den wahren Achsenabschnitt kennen würden), so würde das Modell trotzdem keine perfekten Vorhersagen zum Klausurerfolg liefern. Vermutlich fehlen dem Modell wichtige Informationen etwa zur Motivation der Studentis.\nVor diesem Hintergrund, betrachten Sie folgendes statistisches Modell, das mit den Methoden der Bayes-Statistik berechnet wurde. Dazu wurde die Funktion stan_glm() verwendet, die ähnlich zu lm() ein lineare Modell berechnet. Ein wichtiger Unterschied zu lm() ist, dass Ungewissheiten zu den Parameterschätzungen ausgegeben werden.\n\ndata(mtcars) \nlibrary(rstanarm) \nlibrary(easystats)\nlm1 &lt;- stan_glm(mpg ~ hp, data = mtcars,\n                refresh = 0)  # um nicht zu viel R-Ausgabe zu erhalten\n\nparameters(lm1)\n\nParameter   | Median |         95% CI |   pd |  Rhat |     ESS |                   Prior\n----------------------------------------------------------------------------------------\n(Intercept) |  30.08 | [26.70, 33.43] | 100% | 0.999 | 3419.00 | Normal (20.09 +- 15.07)\nhp          |  -0.07 | [-0.09, -0.05] | 100% | 0.999 | 3469.00 |   Normal (0.00 +- 0.22)\n\n\nFür den Prädiktor hp ist das Regressionsgewicht (Punktschätzer) angegeben unter der Spalte Median. Dieser Wert entspricht der Punktschätzung in der Population und ist identisch zum Regressionsgewicht (“b”) der Stichprobe.\nDie Spalte 95% CI gibt das 95%-Konfidenzintervall (CI wie confidence interval) zur Schätzung der Ungewissheit der Koeffizienten (der entsprechenden Zeile) wieder.\n\nWie breit ist das Intervall, in dem mit 95% Gewissheit der Achsenabschnitt liegt (laut diesem Model)?\nWie breit ist das Intervall, in dem mit 95% Gewissheit das Regressionsgewicht liegt (laut diesem Model)?\n\nHinweise:\n\nRunden Sie auf zwei Dezimalstellen.\nIgnorieren Sie die Spalte zu ROPE, pd, Prior und Rhat! Goldene Regel der Statistik: Wenn du eine Information nicht brauchst, dann ignoriere sie erstmal ;-)\n\n         \n\n\nSolution\n\n6.73\n0.04\n\n\nCategories:\n\nqm2\ninference\nlm"
  },
  {
    "objectID": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html",
    "href": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html",
    "title": "Typ-Fehler-R-07",
    "section": "",
    "text": "Question"
  },
  {
    "objectID": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist",
    "href": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist",
    "title": "Typ-Fehler-R-07",
    "section": "Answerlist",
    "text": "Answerlist\n\nR ist abgestürzt; am besten neu starten.\nR verträgt im Standard nur Grüße in englischer Sprache. Sprachpakete updaten.\nR wartet auf das Ende der Text-Auszeichnung, also auf das schließende Anführungszeichen. Das muss noch eingegeben werden. Alternativ kann man “Escape” drücken.\nEs gibt kein Problem; man kann einfach den nächsten Befehl eingeben.\nR hat gewartet auf das Ende der Text-Auszeichnung, also auf das schließende Anführungszeichen. Jetzt ist R abgestürzt und muss neu gestartet werden."
  },
  {
    "objectID": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist-1",
    "href": "posts/Typ-Fehler-R-07/Typ-Fehler-R-07.html#answerlist-1",
    "title": "Typ-Fehler-R-07",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nRichtig\nFalsch\nFalsch\n\n\nCategories:\n\nR\nerror\nmchoice"
  },
  {
    "objectID": "posts/Typ-Fehler-R-04/Typ-Fehler-R-04.html",
    "href": "posts/Typ-Fehler-R-04/Typ-Fehler-R-04.html",
    "title": "Typ-Fehler-R-04",
    "section": "",
    "text": "Aufgabe\nGegeben sei diese Syntax, die einen Fehlermeldung ausgibt:\n\nmean(c(1,2,3,4). na.rm = TRUE)\n\nError: &lt;text&gt;:1:16: unexpected symbol\n1: mean(c(1,2,3,4).\n                   ^\n\n\nGeben Sie die korrekte Syntax ein, die nicht zu einer Fehlermeldung führt!\nBitte verwenden Sie keine Leerzeichen bei Ihrer Eingabe.\n         \n\n\nLösung\n\nmean(c(1,2,3,4), na.rm = TRUE)\n\n[1] 2.5\n\n\n\nsol &lt;- \"mean(c(1,2,3,4),na.rm=TRUE)\"\n\nDie Antwort lautet: mean(c(1,2,3,4),na.rm=TRUE).\n\nCategories:\n\nR\n‘2023’\nstring"
  },
  {
    "objectID": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html",
    "href": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html",
    "title": "Typ-Fehler-R-02",
    "section": "",
    "text": "R gibt folgende Fehlermeldung aus:\n(Fehler in library(XXX): es gibt kein Paket namens 'XXX'),\nwobei für XXX ein Paketname wie tidyverse angeführt wird.\nWählen Sie die plausibelste Ursache aus!\n\n\n\nDas Paket XXX ist nicht installiert auf dem aktuellen Rechner.\nDas Paket XXX ist nicht verfügbar genau für dieses Betriebssystem.\nEs existiert kein Paket mit Namen XXX.\nDas Paket XXX ist nicht geladen.\nDas Paket XXX ist defekt."
  },
  {
    "objectID": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist",
    "href": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist",
    "title": "Typ-Fehler-R-02",
    "section": "",
    "text": "Das Paket XXX ist nicht installiert auf dem aktuellen Rechner.\nDas Paket XXX ist nicht verfügbar genau für dieses Betriebssystem.\nEs existiert kein Paket mit Namen XXX.\nDas Paket XXX ist nicht geladen.\nDas Paket XXX ist defekt."
  },
  {
    "objectID": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist-1",
    "href": "posts/Typ-Fehler-R-02/Typ-Fehler-R-02.html#answerlist-1",
    "title": "Typ-Fehler-R-02",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig.\nFalsch.\nFalsch.\nFalsch.\nFalsch.\n\n\nCategories:\n\nR\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/twitter07/twitter07.html",
    "href": "posts/twitter07/twitter07.html",
    "title": "twitter07",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=2\\)) und zwar pro Nutzerkonto wie unten angegeben . die Tweets sollen jeweils an eine prominente Person gerichtet sein.\nBeziehen Sie sich auf diese Politikis.\n         \n         \n\n\nSolution\nWir starten die benötigten R-Pakete:\n\nlibrary(academictwitteR)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(askpass)\nlibrary(rio)\n\nHier ist der Datensatz mit den Twitterkonten, für die wir die Daten herunterladen sollen:\n\npoliticians_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/datascience-text/main/data/twitter-german-politicians.csv\"\npoliticians &lt;- import(politicians_path)\npoliticians\n\n                                               name  party      screenname\n1                                   Karl Lauterbach    SPD Karl_Lauterbach\n2                                       Olaf Scholz    SPD      OlafScholz\n3                                 Annalena Baerback Gruene       ABaerbock\n4  Bundesministerium für Wirtschaft und Klimaschutz Gruene            BMWK\n5                                    Friedrich Merz    CDU  _FriedrichMerz\n6                                      Markus Söder    CSU   Markus_Soeder\n7                                       Cem Özdemir Gruene    cem_oezdemir\n8                                    Janine Wissler  Linke  Janine_Wissler\n9                                 Martin Schirdewan  Linke      schirdewan\n10                                Christian Lindner    FDP       c_lindner\n11                    Marie-Agnes Strack-Zimmermann    FDP      MAStrackZi\n12                                   Tino Chrupalla    AFD  Tino_Chrupalla\n13                                     Alice Weidel    AFD    Alice_Weidel\n                                  comment\n1                                    &lt;NA&gt;\n2                                    &lt;NA&gt;\n3                                    &lt;NA&gt;\n4  Robert Habeck ist der Minister im BMWK\n5                                CDU-Chef\n6                                CSU-Chef\n7                                    BMEL\n8                            Linke-Chefin\n9                              Linke-Chef\n10                               FDP-Chef\n11     Vorsitzende Verteidigungsausschuss\n12                     AFD-Bundessprecher\n13                   AFD-Bundessprecherin\n\n\nWir müssen noch das Passwort bereitstellen:\n\nbearer_token &lt;- askpass::askpass(\"bearer token\")\n\nUnd dann definieren wir eine Funktion, die das Gewichtheben für uns erledigt:\n\nget_all_tweets_politicians &lt;- function(screenname, n = 1e1) {\n  get_all_tweets(query = paste0(\"to:\", screenname, \" -is:retweet\"),\n                 start_tweets = \"2021-01-01T00:00:00Z\",\n                 end_tweets = \"2021-12-31T23:59:59Z\",\n                 bearer_token = bearer_token,\n                 file = glue::glue(\"~/datasets/Twitter/hate-speech/tweets_to_{screenname}_2021.rds\"),\n                 data_path = glue::glue(\"~/datasets/Twitter/hate-speech/{screenname}\"),\n                 n = n)\n}\n\nJetzt wenden wir die Funktion auf jedes Twitterkonto unserer Liste (alle Politikis) an:\n\nd &lt;- politicians$screenname %&gt;% \n  map(get_all_tweets_politicians)\n\n\nCategories:\n\ntextmining\ntwitter\nprogramming"
  },
  {
    "objectID": "posts/twitter05/twitter05.html",
    "href": "posts/twitter05/twitter05.html",
    "title": "twitter05",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=2\\)) via der Twitter API; Suchterm soll sein “(karl_lauterbach?)”. Bereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopwörter entfernen, Zahlen entfernen, …).\nNutzen Sie die Daten, um eine Sentimentanalyse zu erstellen.\n         \n\n\nSolution\nNutzen Sie die Daten der letzten Aufgabe, um eine Sentimentanalyse zu erstellen.\nZuerst muss man sich anmelden und die Tweets herunterladen; dieser Teil ist hier nicht aufgeführt (s. andere Aufgaben).\n\nlibrary(rtweet)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n\nLoading required package: SnowballC\n\nlibrary(SnowballC)  # Stemming\n\nBeachten Sie, dass die Spalten je nach Funktion, die Sie zum Herunterladen der Tweets verwenden, unterschiedlich heißen können.\n\nkarl2 &lt;- \n  karl1 %&gt;% \n  select(contains(\"text\"))\n\n\nkarl3 &lt;- \n  karl2 %&gt;% \n  unnest_tokens(output = word, input = text)\n\n\nkarl4 &lt;- \nkarl3 %&gt;% \n  anti_join(tibble(word = lsa::stopwords_de)) \n\nJoining with `by = join_by(word)`\n\n\n\nkarl5 &lt;- \n  karl4 %&gt;% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %&gt;% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %&gt;% \n  mutate(word = str_replace_na(word, \" +\")) %&gt;% \n  drop_na()\n\n\ndata(sentiws, package = \"pradadata\")\n\n\nkarl7 &lt;-\n  karl5 %&gt;% \n  inner_join(sentiws)\n\nJoining with `by = join_by(word)`\n\n\n\nkarl7 %&gt;% \n  group_by(neg_pos) %&gt;% \n  summarise(senti_avg = mean(value, na.rm = TRUE),\n            senti_sd = sd(value, na.rm = TRUE),\n            senti_n = n())\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;\n1 neg        -0.347    0.186       2\n2 pos         0.167    0.283       3\n\n\nAchtung, Sentimentanalyse sollte vor dem Stemming kommen.\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/twitter03/twitter03.html",
    "href": "posts/twitter03/twitter03.html",
    "title": "twitter03",
    "section": "",
    "text": "Exercise\nLaden Sie die neuesten Tweets an karl_lauterbach herunter, die mindestens 100 Likes oder 100 Retweets haben.\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rtweet)\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nDann anmelden:\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\nTweets an Karl Lauterbach suchen:\n\nkarl1 &lt;- search_tweets(\"@karl_lauterbach min_faves:100 OR min_retweets:100\", n = 10)\n\n\nkarl1 %&gt;% \n  select(retweet_count, favorite_count)\n\n# A tibble: 10 × 2\n   retweet_count favorite_count\n           &lt;int&gt;          &lt;int&gt;\n 1            56            210\n 2            56            229\n 3            44           1626\n 4            60            225\n 5            30            494\n 6             5            148\n 7            27            435\n 8            12            178\n 9            13            162\n10            46            375\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/twitter01/twitter01.html",
    "href": "posts/twitter01/twitter01.html",
    "title": "twitter01",
    "section": "",
    "text": "Exercise\nLaden Sie die neuesten Tweets an karl_lauterbach herunter!\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rtweet)\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nDann anmelden, z.B. als Bot:\n\nauth &lt;- rtweet_bot(api_key = API_Key,\n                   api_secret = API_Key_Secret,\n                   access_token = Access_Token,\n                   access_secret = Access_Token_Secret)\n\n… Oder als App, das bringt bessere Raten mit sich:\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\nTest:\n\nsesa_test &lt;- get_timeline(user = \"sauer_sebastian\", n = 3) %&gt;% \n  select(full_text)\n\nsesa_test\n\n1 RT @fuecks: By the way: Systematic destruction of life-sustaining infrastructures …\n2 RT @NoContextBrits: No shortbread for little Nazis. https://t.co/F6FUPvRz94        \n3 RT @ernst_gennat: 2 oder 3 Jahre #Tempolimit von 120 km/h. Abschließend Evaluation…\nTweets an Karl Lauterbach suchen:\n\nkarl1 &lt;- search_tweets(\"@karl_lauterbach\")\n\nIn Auszügen:\n\"@Karl_Lauterbach Ein Minister der alle paar Stunden Zeit hat einen Mist zu verbreiten....\"   \n\"@Karl_Lauterbach @focusonline Long Covid ist nichts anderes als schwere Nebenwirkungen der Gentherapie!\"  \"@Karl_Lauterbach @focusonline Wer schützt uns vor Long Lauterbach?\"\n\"@Karl_Lauterbach Also Karl, primär fordere ich und viele andere eher erstmal dein sofortigen Rücktritt.\"  \"@Karl_Lauterbach Behalt deinen Senf für dich!\"                                                            \"@Karl_Lauterbach Oh Gott 😱\"     \n\"@Karl_Lauterbach Ach nein, der Clown mit Lebensangst ….\\n\\nhttps://t.co/8cQZeHh6Ew\"                       \"@Karl_Lauterbach Ich kenne nur Leute mit Long Covid, die mehrfach geimpft sind! Das ist kein Witz! Scheinbar liegt’s wohl doch an den Spritzen???\"                                                            \"@Karl_Lauterbach @focusonline Interessiert keine Sau 😉\"                      \n\"RT @Karl_Lauterbach @focusonline „Lauterbachs Aussagen können fundamental nicht stimmen“\\nhttps://t.co/rfxnWAWiZX\"                                                                          \"@Karl_Lauterbach @focusonline 🤡😂😂😂😂😂😂\"                                         \n\"@Karl_Lauterbach Jau und sie sind kein fähiger Gesundheitsminister, sondern lediglich ein gekaufter Coronaminister\"        \nPuh, viele toxische Tweets, wie es scheint.\nUnd ohne Retweets (RT) und ohne Replies:\n\nkarl2 &lt;- search_tweets(\"@karl_lauterbach\", \n  include_rts = FALSE, `-filter` = \"replies\")\n\nTweets, die an Karl Lauterbach gerichtet sind, per API-Anweisung:\n\nkarl3 &lt;- search_tweets(\"to:karl_lauterbach\", n = 100)\n\n\"@Karl_Lauterbach Vielen Dank, dass LongCovid ein gefundenes fressen für die jenigen ist, die nicht mehr Arbeiten wollen.\"       \n \"@Karl_Lauterbach verpiss dich einfach! Immer dieser Schwachsinn\"    \n\"@Karl_Lauterbach @focusonline Das sind genau die Impfnebenwirkungen! Will man nun das wenden um die Impfnebenwirkungen zu vertuschen? \\nWofür ist die Impfung gut wenn nicht mal Long-Covid verhindert wird, die Ansteckung konnte sie noch nie verhindern!\\nWarum sind 89% Covid Patienten geimpfte in den Spitäler?\"\n\"@Karl_Lauterbach Was spielen Sie eigentlich für ein schmutziges Spiel?\\n\\nhttps://t.co/8LJIzxyF7G\"   \n \"@Karl_Lauterbach @focusonline Bessen von Covid! Ständig wird das Netz durchsucht, nach Artikeln,die instrumentalisiert werden, um für Impfung zu werben. Was hätte nur ein vernünftiger Gesundheitsminister mit so viel Zeit Vernünftiges im Gesundheitswesen auf die Beine stellen können...\"    \n\"@Karl_Lauterbach Mit Dauerschaden wegen der Impfung 💉 bin ich Arbeitslos geworden in der Pflege 🤷‍♂️ Ist das normal Herr @Karl_Lauterbach ?\"          \nOb man mit @karl_lauterbach sucht oder `to:karl_lauterbach”, scheint keinen großen Unterschied zu machen (?).\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html",
    "href": "posts/ttest-als-regr/ttest-als-regr.html",
    "title": "ttest-als-regression",
    "section": "",
    "text": "Der t-Test kann als Spezialfall der Regressionsanalyse gedeutet werden.\nHierbei ist es wichtig, sich das Skalenniveau der Variablen, die ein t-Test verarbeitet, vor Augen zu führen.\nHinweisse:\n\nDie folgende Abbildung gibt Tipps.\nInformationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenennen Sie die Skalenniveaus der UV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nBenennen Sie die Skalenniveaus der AV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nNennen Sie eine beispielhafte Forschungsfrage für einen t-Test.\nSkizzieren Sie ein Diagramm einer Regression, die analytisch identisch (oder sehr ähnlich) zu einem t-Test ist!"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html#answerlist",
    "href": "posts/ttest-als-regr/ttest-als-regr.html#answerlist",
    "title": "ttest-als-regression",
    "section": "",
    "text": "Benennen Sie die Skalenniveaus der UV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nBenennen Sie die Skalenniveaus der AV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nNennen Sie eine beispielhafte Forschungsfrage für einen t-Test.\nSkizzieren Sie ein Diagramm einer Regression, die analytisch identisch (oder sehr ähnlich) zu einem t-Test ist!"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html#answerlist-1",
    "href": "posts/ttest-als-regr/ttest-als-regr.html#answerlist-1",
    "title": "ttest-als-regression",
    "section": "Answerlist",
    "text": "Answerlist\n\nUV: binär\nAV: metrisch\nUnterscheiden sich die mittleren Einparkzeiten von Frauen und Männern?\nAus dem Datensatz mtcars:\n\n\ndata(mtcars)\nmtcars %&gt;% \n  ggplot() +\n  aes(x = am, y = mpg) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nregression\nttest\nvariable-levels"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html",
    "href": "posts/tmdb08/tmdb08.html",
    "title": "tmdb08",
    "section": "",
    "text": "Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\""
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#train-set-verschlanken",
    "href": "posts/tmdb08/tmdb08.html#train-set-verschlanken",
    "title": "tmdb08",
    "section": "Train-Set verschlanken",
    "text": "Train-Set verschlanken\n\nd_train &lt;-\n  d_train_raw %&gt;% \n  select(id, popularity, runtime, revenue, budget)"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#test-set-verschlanken",
    "href": "posts/tmdb08/tmdb08.html#test-set-verschlanken",
    "title": "tmdb08",
    "section": "Test-Set verschlanken",
    "text": "Test-Set verschlanken\n\nd_test &lt;-\n  d_test_raw %&gt;% \n  select(id,popularity, runtime, budget)"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#rezept-definieren",
    "href": "posts/tmdb08/tmdb08.html#rezept-definieren",
    "title": "tmdb08",
    "section": "Rezept definieren",
    "text": "Rezept definieren\n\nrec2 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  step_mutate(budget = ifelse(budget == 0, 1, budget)) %&gt;%  # log mag keine 0\n  step_log(budget) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())  %&gt;% \n  update_role(id, new_role = \"id\")\n\nrec2"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#lm-regularisiert",
    "href": "posts/tmdb08/tmdb08.html#lm-regularisiert",
    "title": "tmdb08",
    "section": "LM regularisiert",
    "text": "LM regularisiert\nMit mixture = 1 definieren wir ein Lasso.\n\nmod_lm &lt;-\n  linear_reg(penalty = tune(), mixture = 1) %&gt;% \n  set_engine(\"glmnet\")\n\nCheck:\n\nmod_lm\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#finalisieren-1",
    "href": "posts/tmdb08/tmdb08.html#finalisieren-1",
    "title": "tmdb08",
    "section": "Finalisieren",
    "text": "Finalisieren\nFinalisieren bedeutet:\n\nBesten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell)\nDen besten Workflow mit den optimalen Modell-Parametern ausstatten\nDamit dann den ganzen Train-Datensatz fitten\nAuf dieser Basis das Test-Sample vorhersagen\n\n\nbest_wf2 &lt;- \nall_workflows2 %&gt;% \n  extract_workflow(\"rec1_lm1\")\n\nbest_wf2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\nbest_wf_finalized2 &lt;- \n  best_wf2 %&gt;% \n  finalize_workflow(best_model_params2)\n\nbest_wf_finalized2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1.12138579835732e-10\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#final-fit",
    "href": "posts/tmdb08/tmdb08.html#final-fit",
    "title": "tmdb08",
    "section": "Final Fit",
    "text": "Final Fit\n\nfit_final2 &lt;-\n  best_wf_finalized2 %&gt;% \n  fit(d_train)\n\nfit_final2\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev   Lambda\n1   0  0.00 63460000\n2   1  3.62 57820000\n3   1  6.62 52680000\n4   1  9.11 48000000\n5   1 11.18 43740000\n6   1 12.90 39850000\n7   2 15.24 36310000\n8   2 17.19 33090000\n9   2 18.81 30150000\n10  2 20.16 27470000\n11  2 21.28 25030000\n12  2 22.21 22800000\n13  3 23.10 20780000\n14  3 23.95 18930000\n15  3 24.66 17250000\n16  3 25.25 15720000\n17  3 25.74 14320000\n18  3 26.15 13050000\n19  3 26.49 11890000\n20  3 26.77 10830000\n21  3 27.00  9872000\n22  3 27.20  8995000\n23  3 27.36  8196000\n24  3 27.49  7467000\n25  3 27.60  6804000\n26  3 27.69  6200000\n27  3 27.77  5649000\n28  3 27.83  5147000\n29  3 27.88  4690000\n30  3 27.93  4273000\n31  3 27.96  3894000\n32  3 27.99  3548000\n33  3 28.02  3232000\n34  3 28.04  2945000\n35  3 28.06  2684000\n36  3 28.07  2445000\n37  3 28.08  2228000\n38  3 28.09  2030000\n39  3 28.10  1850000\n40  3 28.11  1685000\n41  3 28.11  1536000\n42  3 28.12  1399000\n43  3 28.12  1275000\n44  3 28.13  1162000\n45  3 28.13  1058000\n46  3 28.13   964500\n\n...\nand 12 more lines.\n\n\n\npreds &lt;- \nfit_final2 %&gt;% \n  predict(new_data = d_test)\n\nhead(preds)\n\n# A tibble: 6 × 1\n       .pred\n       &lt;dbl&gt;\n1 -14840891.\n2  10804710.\n3  11698900.\n4  99190531.\n5  41798496.\n6  29974421."
  },
  {
    "objectID": "posts/tmdb08/tmdb08.html#submission-df",
    "href": "posts/tmdb08/tmdb08.html#submission-df",
    "title": "tmdb08",
    "section": "Submission df",
    "text": "Submission df\nWir brauchen die ID-Spalte und die Vorhersagen für die Einreichung:\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n# A tibble: 6 × 2\n     id    revenue\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  3001 -14840891.\n2  3002  10804710.\n3  3003  11698900.\n4  3004  99190531.\n5  3005  41798496.\n6  3006  29974421.\n\n\nAbspeichern und einreichen:\n\nwrite_csv(submission_df, file = \"submission_regul_lm.csv\")\n\nLeider ein schlechter Score: 5.77945.\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/tmdb06/tmdb06.html",
    "href": "posts/tmdb06/tmdb06.html",
    "title": "tmdb06",
    "section": "",
    "text": "Aufgabe\nMelden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Lineares Modell mit Tidymodels!\nHinweise\n\n\nVerzichten Sie auf Vorverarbeitung.\nVerzichten Sie auf Tuning.\nReichen Sie das Modell ein und berichten Sie Ihren Score.\nBegrenzen Sie sich auf folgende Prädiktoren.\nVerwenden Sie (langweiligerweise) nur ein lineares Modell.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\")\n\n         \n\n\nLösung\n\n\nPakete starten\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(finetune)  # Anova Race\nlibrary(doParallel)  # parallele Verarbeitung\n\n\n\nDaten importieren\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nWerfen wir einen Blick in die Daten:\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In…\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol…\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,…\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        &lt;chr&gt; \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco…\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 &lt;chr&gt; \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…\n\n\npreds_chosen sind alle Prädiktoren im Datensatz, oder nicht? Das prüfen wir mal kurz:\n\npreds_chosen %in% names(d_train) %&gt;% \n  all()\n\n[1] TRUE\n\n\nJa, alle Elemente von preds_chosen sind Prädiktoren im (Train-)Datensatz.\n\n\nCV\nWir brauchen keine CV, da wir keine Tuningparameter haben.\n\ncv_scheme &lt;- vfold_cv(d_train)\n\n\n\nRezept\n\nrec1 &lt;- \n  recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_naomit(all_predictors()) \nrec1\n\nMan beachte, dass noch 21 Prädiktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (“gebacken”) wurde.\n\ntidy(rec1)\n\n# A tibble: 2 × 6\n  number operation type       trained skip  id              \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;           \n1      1 step      impute_bag FALSE   FALSE impute_bag_sBkeX\n2      2 step      naomit     FALSE   TRUE  naomit_NxiQP    \n\n\nRezept checken:\n\nprep(rec1)\n\n\nd_train_baked &lt;-\n  rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n\nRows: 3,000\nColumns: 4\n$ budget     &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00, 8.00e+06,…\n$ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.148070, 0.743274…\n$ runtime    &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119, 98, 122, …\n$ revenue    &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970, 3261638, 8…\n\n\nFehlende Werte noch übrig?\n\nlibrary(easystats)\ndescribe_distribution(d_train_baked) %&gt;% \n  select(Variable, n_Missing)\n\nVariable   | n_Missing\n----------------------\nbudget     |         0\npopularity |         0\nruntime    |         0\nrevenue    |         0\n\n\n\n\nModell\n\nmodel_lm &lt;- linear_reg()\n\n\n\nWorkflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model_lm) %&gt;% \n  add_recipe(rec1)\n\n\n\nModell fitten (und tunen)\n\n#doParallel::registerDoParallel(4)\ntic()\nlm_fit1 &lt;-\n  wf1 %&gt;% \n  fit(d_train)\ntoc()\n\n0.645 sec elapsed\n\n\n\npreds &lt;-\n  lm_fit1 %&gt;% \n  predict(d_test)\n\n\n\nSubmission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n# A tibble: 6 × 2\n     id   revenue\n  &lt;dbl&gt;     &lt;dbl&gt;\n1  3001 -4147506.\n2  3002 -8808140.\n3  3003  8523980.\n4  3004 31675099.\n5  3005  -504355.\n6  3006 13531355.\n\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\n\n\nKaggle Score\nDiese Submission erzielte einen Score von Score: 6.14787 (RMSLE).\n\nsol &lt;- 6.14787\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html",
    "href": "posts/tmdb04/tmdb04.html",
    "title": "tmdb04",
    "section": "",
    "text": "Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\""
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#train-set-verschlanken",
    "href": "posts/tmdb04/tmdb04.html#train-set-verschlanken",
    "title": "tmdb04",
    "section": "Train-Set verschlanken",
    "text": "Train-Set verschlanken\n\nd_train_raw_reduced &lt;-\n  d_train_raw %&gt;% \n  select(id, popularity, runtime, revenue, budget)"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#test-set-verschlanken",
    "href": "posts/tmdb04/tmdb04.html#test-set-verschlanken",
    "title": "tmdb04",
    "section": "Test-Set verschlanken",
    "text": "Test-Set verschlanken\n\nd_test &lt;-\n  d_test_raw %&gt;% \n  select(id,popularity, runtime, budget)"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#outcome-logarithmieren",
    "href": "posts/tmdb04/tmdb04.html#outcome-logarithmieren",
    "title": "tmdb04",
    "section": "Outcome logarithmieren",
    "text": "Outcome logarithmieren\nDer Outcome sollte nicht im Rezept transformiert werden (vgl. Part 3, S. 30, in dieser Unterlage).\n\nd_train &lt;-\n  d_train_raw_reduced %&gt;% \n  mutate(revenue = if_else(revenue &lt; 10, 10, revenue)) %&gt;% \n  mutate(revenue = log(revenue)) \n\nPrüfen, ob das funktioniert hat:\n\nd_train$revenue %&gt;% is.infinite() %&gt;% any()\n\n[1] FALSE\n\n\nKeine unendlichen Werte mehr, auf dieser Basis können wir weitermachen."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#rezept-definieren",
    "href": "posts/tmdb04/tmdb04.html#rezept-definieren",
    "title": "tmdb04",
    "section": "Rezept definieren",
    "text": "Rezept definieren\n\nrec2 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  step_mutate(budget = ifelse(budget == 0, NA, budget)) %&gt;%  # log mag keine 0\n  step_log(budget) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())  %&gt;% \n  update_role(id, new_role = \"id\")\n\nrec2\n\nSchauen Sie mal, der Log mag keine Nullen:\n\nx &lt;- c(1,2, NA, 0)\n\nlog(x)\n\n[1] 0.0000000 0.6931472        NA      -Inf\n\n\nDa \\(log(0) = -\\infty\\). Aus dem Grund wandeln wir 0 lieber in NA um.\n\ntidy(rec2)\n\n# A tibble: 4 × 6\n  number operation type       trained skip  id              \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;           \n1      1 step      mutate     FALSE   FALSE mutate_5IvPK    \n2      2 step      log        FALSE   FALSE log_HuvzM       \n3      3 step      impute_knn FALSE   FALSE impute_knn_bzUap\n4      4 step      dummy      FALSE   FALSE dummy_Gm3kh"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#check-das-rezept",
    "href": "posts/tmdb04/tmdb04.html#check-das-rezept",
    "title": "tmdb04",
    "section": "Check das Rezept",
    "text": "Check das Rezept\nWir berechnen das Rezept:\n\nrec2_prepped &lt;-\n  prep(rec2, verbose = TRUE)\n\noper 1 step mutate [training] \noper 2 step log [training] \noper 3 step impute knn [training] \noper 4 step dummy [training] \nThe retained training set is ~ 0.12 Mb  in memory.\n\nrec2_prepped\n\nDas ist noch nicht auf einen Datensatz angewendet! Lediglich die steps wurden vorbereitet, “präpariert”: z.B. “Diese Dummy-Variablen impliziert das Rezept”.\nSo sieht das dann aus, wenn man das präparierte Rezept auf das Train-Sample anwendet:\n\nd_train_baked2 &lt;-\n  rec2_prepped %&gt;% \n  bake(new_data = NULL) \n\nhead(d_train_baked2)\n\n# A tibble: 6 × 5\n     id popularity runtime budget revenue\n  &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1      6.58       93   16.5    16.3\n2     2      8.25      113   17.5    18.4\n3     3     64.3       105   15.0    16.4\n4     4      3.17      122   14.0    16.6\n5     5      1.15      118   15.8    15.2\n6     6      0.743      83   15.9    15.0\n\n\n\nd_train_baked2 %&gt;% \n  map_df(sum_isna)\n\n# A tibble: 1 × 5\n     id popularity runtime budget revenue\n  &lt;int&gt;      &lt;int&gt;   &lt;int&gt;  &lt;int&gt;   &lt;int&gt;\n1     0          0       0      0       0\n\n\nKeine fehlenden Werte mehr in den Prädiktoren.\nNach fehlenden Werten könnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train_baked2)\n\nVariable   |    Mean |     SD |     IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n-----------------------------------------------------------------------------------------------------\nid         | 1500.50 | 866.17 | 1500.50 |    [1.00, 3000.00] |     0.00 |    -1.20 | 3000 |         0\npopularity |    8.46 |  12.10 |    6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime    |  107.85 |  22.08 |   24.00 |     [0.00, 338.00] |     1.02 |     8.20 | 3000 |         0\nbudget     |   16.09 |   1.89 |    1.90 |      [0.00, 19.76] |    -2.93 |    18.71 | 3000 |         0\nrevenue    |   15.97 |   3.04 |    3.37 |      [2.30, 21.14] |    -1.60 |     3.82 | 3000 |         0\n\n\nSo bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#check-test-sample",
    "href": "posts/tmdb04/tmdb04.html#check-test-sample",
    "title": "tmdb04",
    "section": "Check Test-Sample",
    "text": "Check Test-Sample\nDas Test-Sample backen wir auch mal, um zu prüfen, das alles läuft:\n\nd_test_baked2 &lt;-\n  bake(rec2_prepped, new_data = d_test)\n\nd_test_baked2 %&gt;% \n  head()\n\n# A tibble: 6 × 4\n     id popularity runtime budget\n  &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1  3001       3.85      90   15.8\n2  3002       3.56      65   11.4\n3  3003       8.09     100   16.4\n4  3004       8.60     130   15.7\n5  3005       3.22      92   14.5\n6  3006       8.68     121   16.1\n\n\nSieht soweit gut aus."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#lm",
    "href": "posts/tmdb04/tmdb04.html#lm",
    "title": "tmdb04",
    "section": "LM",
    "text": "LM\n\nmod_lm &lt;-\n  linear_reg()"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#finalisieren-1",
    "href": "posts/tmdb04/tmdb04.html#finalisieren-1",
    "title": "tmdb04",
    "section": "Finalisieren",
    "text": "Finalisieren\nFinalisieren bedeutet:\n\nBesten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell)\nDen besten Workflow mit den optimalen Modell-Parametern ausstatten\nDamit dann den ganzen Train-Datensatz fitten\nAuf dieser Basis das Test-Sample vorhersagen\n\n\nbest_wf2 &lt;- \nall_workflows2 %&gt;% \n  extract_workflow(\"rec1_lm1\")\n\nbest_wf2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\nbest_wf_finalized2 &lt;- \n  best_wf2 %&gt;% \n  finalize_workflow(best_model_params2)\n\nbest_wf_finalized2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#final-fit",
    "href": "posts/tmdb04/tmdb04.html#final-fit",
    "title": "tmdb04",
    "section": "Final Fit",
    "text": "Final Fit\n\nfit_final2 &lt;-\n  best_wf_finalized2 %&gt;% \n  fit(d_train)\n\nfit_final2\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)   popularity      runtime       budget  \n    1.26186      0.03755      0.01289      0.80752  \n\n\n\npreds &lt;- \nfit_final2 %&gt;% \n  predict(new_data = d_test)\n\nhead(preds)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  15.3\n2  11.4\n3  16.1\n4  16.0\n5  14.3\n6  16.1\n\n\nAchtung, wenn die Outcome-Variable im Rezept verändert wurde, dann würde obiger Code nicht durchlaufen.\nGrund ist hier beschrieben:\n\nWhen predict() is used, it only has access to the predictors (mirroring how this would work with new samples). Even if the outcome column is present, it is not exposed to the recipe. This is generally a good idea so that we can avoid information leakage.\n\n\nOne approach is the use the skip = TRUE option in step_log() so that it will avoid that step during predict() and/or bake(). However, if you are using this recipe with the tune package, there will still be an issue because the metric function(s) would get the predictions in log units and the observed outcome in the original units.\n\n\nThe better approach is, for simple transformations like yours, to log the outcome outside of the recipe (before data analysis and the initial split)."
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#submission-df",
    "href": "posts/tmdb04/tmdb04.html#submission-df",
    "title": "tmdb04",
    "section": "Submission df",
    "text": "Submission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n# A tibble: 6 × 2\n     id revenue\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  3001    15.3\n2  3002    11.4\n3  3003    16.1\n4  3004    16.0\n5  3005    14.3\n6  3006    16.1"
  },
  {
    "objectID": "posts/tmdb04/tmdb04.html#zurücktransformieren",
    "href": "posts/tmdb04/tmdb04.html#zurücktransformieren",
    "title": "tmdb04",
    "section": "Zurücktransformieren",
    "text": "Zurücktransformieren\n\nsubmission_df &lt;-\n  submission_df %&gt;% \n  mutate(revenue = exp(revenue)-1)\n\nhead(submission_df)\n\n# A tibble: 6 × 2\n     id   revenue\n  &lt;dbl&gt;     &lt;dbl&gt;\n1  3001  4435143.\n2  3002    91755.\n3  3003  9782986.\n4  3004  8573795.\n5  3005  1598106.\n6  3006 10061439.\n\n\nHier ein Beispiel, warum \\(e^x-1\\) genauer ist für kleine Zahlen als \\(e^x\\).\nAbspeichern und einreichen:\n\nwrite_csv(submission_df, file = \"submission.csv\")"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html",
    "href": "posts/tmdb02/tmdb02.html",
    "title": "tmdb02",
    "section": "",
    "text": "Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\n\n\nReichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Kaggle-Score\nHinweise:\n\nSie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.\nBerechnen Sie einen Entscheidungsbaum und einen Random-Forest.\nTunen Sie nach Bedarf; verwenden Sie aber Default-Werte.\nVerwenden Sie Tidymodels."
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#vorbereitung",
    "href": "posts/tmdb02/tmdb02.html#vorbereitung",
    "title": "tmdb02",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(doParallel)  # mehrere CPUs nutzen\nlibrary(finetune)  # Tune Anova\n\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In…\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol…\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,…\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        &lt;chr&gt; \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco…\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 &lt;chr&gt; \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#rezept",
    "href": "posts/tmdb02/tmdb02.html#rezept",
    "title": "tmdb02",
    "section": "Rezept",
    "text": "Rezept\n\nRezept definieren\n\nrec1 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(popularity, runtime, revenue, budget) %&gt;% \n  update_role(revenue, new_role = \"outcome\") %&gt;% \n  step_mutate(budget = ifelse(budget &lt; 10, 10, budget)) %&gt;% \n  step_log(budget) %&gt;% \n  step_impute_knn(all_predictors())\n\nrec1\n\n\n\nCheck das Rezept\n\nrec1_prepped &lt;-\n  prep(rec1, verbose = TRUE)\n\noper 1 step mutate [training] \noper 2 step log [training] \noper 3 step impute knn [training] \nThe retained training set is ~ 28.71 Mb  in memory.\n\nrec1_prepped\n\n\nd_train_baked &lt;-\n  rec1_prepped %&gt;% \n  bake(new_data = NULL) \n\nhead(d_train_baked)\n\n# A tibble: 6 × 23\n     id belongs_to_collection   budget genres homepage imdb_id original_language\n  &lt;dbl&gt; &lt;fct&gt;                    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;   &lt;fct&gt;            \n1     1 [{'id': 313576, 'name'…  16.5  [{'id… &lt;NA&gt;     tt2637… en               \n2     2 [{'id': 107674, 'name'…  17.5  [{'id… &lt;NA&gt;     tt0368… en               \n3     3 &lt;NA&gt;                     15.0  [{'id… http://… tt2582… en               \n4     4 &lt;NA&gt;                     14.0  [{'id… http://… tt1821… hi               \n5     5 &lt;NA&gt;                      2.30 [{'id… &lt;NA&gt;     tt1380… ko               \n6     6 &lt;NA&gt;                     15.9  [{'id… &lt;NA&gt;     tt0093… en               \n# ℹ 16 more variables: original_title &lt;fct&gt;, overview &lt;fct&gt;, popularity &lt;dbl&gt;,\n#   poster_path &lt;fct&gt;, production_companies &lt;fct&gt;, production_countries &lt;fct&gt;,\n#   release_date &lt;fct&gt;, runtime &lt;dbl&gt;, spoken_languages &lt;fct&gt;, status &lt;fct&gt;,\n#   tagline &lt;fct&gt;, title &lt;fct&gt;, Keywords &lt;fct&gt;, cast &lt;fct&gt;, crew &lt;fct&gt;,\n#   revenue &lt;dbl&gt;\n\n\nDie AV-Spalte sollte leer sein:\n\nbake(rec1_prepped, new_data = head(d_test), all_outcomes())\n\n# A tibble: 6 × 0\n\n\n\nd_train_baked %&gt;% \n  map_df(~ sum(is.na(.)))\n\n# A tibble: 1 × 23\n     id belongs_to_collection budget genres homepage imdb_id original_language\n  &lt;int&gt;                 &lt;int&gt;  &lt;int&gt;  &lt;int&gt;    &lt;int&gt;   &lt;int&gt;             &lt;int&gt;\n1     0                  2396      0      7     2054       0                 0\n# ℹ 16 more variables: original_title &lt;int&gt;, overview &lt;int&gt;, popularity &lt;int&gt;,\n#   poster_path &lt;int&gt;, production_companies &lt;int&gt;, production_countries &lt;int&gt;,\n#   release_date &lt;int&gt;, runtime &lt;int&gt;, spoken_languages &lt;int&gt;, status &lt;int&gt;,\n#   tagline &lt;int&gt;, title &lt;int&gt;, Keywords &lt;int&gt;, cast &lt;int&gt;, crew &lt;int&gt;,\n#   revenue &lt;int&gt;\n\n\nKeine fehlenden Werte mehr in den Prädiktoren.\nNach fehlenden Werten könnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train_baked)\n\nVariable   |     Mean |       SD |      IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n---------------------------------------------------------------------------------------------------------\nid         |  1500.50 |   866.17 |  1500.50 |    [1.00, 3000.00] |     0.00 |    -1.20 | 3000 |         0\nbudget     |    12.51 |     6.44 |    14.88 |      [2.30, 19.76] |    -0.87 |    -1.09 | 3000 |         0\npopularity |     8.46 |    12.10 |     6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime    |   107.85 |    22.08 |    24.00 |     [0.00, 338.00] |     1.02 |     8.20 | 3000 |         0\nrevenue    | 6.67e+07 | 1.38e+08 | 6.66e+07 |   [1.00, 1.52e+09] |     4.54 |    27.78 | 3000 |         0\n\n\nSo bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\nDas Test-Sample backen wir auch mal:\n\nd_test_baked &lt;-\n  bake(rec1_prepped, new_data = d_test)\n\nd_test_baked %&gt;% \n  head()\n\n# A tibble: 6 × 22\n     id belongs_to_collection   budget genres homepage imdb_id original_language\n  &lt;dbl&gt; &lt;fct&gt;                    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;   &lt;fct&gt;            \n1  3001 [{'id': 34055, 'name':…   2.30 [{'id… &lt;NA&gt;     &lt;NA&gt;    ja               \n2  3002 &lt;NA&gt;                     11.4  [{'id… &lt;NA&gt;     &lt;NA&gt;    en               \n3  3003 &lt;NA&gt;                      2.30 [{'id… &lt;NA&gt;     &lt;NA&gt;    en               \n4  3004 &lt;NA&gt;                     15.7  &lt;NA&gt;   &lt;NA&gt;     &lt;NA&gt;    fr               \n5  3005 &lt;NA&gt;                     14.5  [{'id… &lt;NA&gt;     &lt;NA&gt;    en               \n6  3006 &lt;NA&gt;                      2.30 [{'id… &lt;NA&gt;     &lt;NA&gt;    en               \n# ℹ 15 more variables: original_title &lt;fct&gt;, overview &lt;fct&gt;, popularity &lt;dbl&gt;,\n#   poster_path &lt;fct&gt;, production_companies &lt;fct&gt;, production_countries &lt;fct&gt;,\n#   release_date &lt;fct&gt;, runtime &lt;dbl&gt;, spoken_languages &lt;fct&gt;, status &lt;fct&gt;,\n#   tagline &lt;fct&gt;, title &lt;fct&gt;, Keywords &lt;fct&gt;, cast &lt;fct&gt;, crew &lt;fct&gt;"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#kreuzvalidierung",
    "href": "posts/tmdb02/tmdb02.html#kreuzvalidierung",
    "title": "tmdb02",
    "section": "Kreuzvalidierung",
    "text": "Kreuzvalidierung\n\ncv_scheme &lt;- vfold_cv(d_train,\n                      v = 5, \n                      repeats = 1)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#modelle",
    "href": "posts/tmdb02/tmdb02.html#modelle",
    "title": "tmdb02",
    "section": "Modelle",
    "text": "Modelle\n\nBaum\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                mode = \"regression\")\n\n\n\nRandom Forest\n\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000,\n              mode = \"regression\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#workflows",
    "href": "posts/tmdb02/tmdb02.html#workflows",
    "title": "tmdb02",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;% \n  add_model(mod_tree) %&gt;% \n  add_recipe(rec1)\n\nwf_rf &lt;-\n  workflow() %&gt;% \n  add_model(mod_rf) %&gt;% \n  add_recipe(rec1)"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#fitten-und-tunen",
    "href": "posts/tmdb02/tmdb02.html#fitten-und-tunen",
    "title": "tmdb02",
    "section": "Fitten und tunen",
    "text": "Fitten und tunen\nUm Rechenzeit zu sparen, kann man den Parameter grid bei tune_grid() auf einen kleinen Wert setzen. Der Default ist 10. Um gute Vorhersagen zu erzielen, sollte man den Wert tendenziell noch über 10 erhöhen.\n\nTree\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\ntree_fit &lt;-\n  wf_tree %&gt;% \n  tune_race_anova(\n    resamples = cv_scheme,\n    #grid = 2\n  )\ntoc()\n\n37.736 sec elapsed\n\n\nHilfe zu tune_grid() bekommt man hier.\n\ntree_fit\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 5\n  splits             id    .order .metrics          .notes          \n  &lt;list&gt;             &lt;chr&gt;  &lt;int&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [2400/600]&gt; Fold1      3 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [2400/600]&gt; Fold2      1 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [2400/600]&gt; Fold3      2 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [2400/600]&gt; Fold5      4 &lt;tibble [16 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [2400/600]&gt; Fold4      5 &lt;tibble [14 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n\nSteht was in den .notes?\n\ntree_fit[[\".notes\"]][[2]]\n\n# A tibble: 0 × 3\n# ℹ 3 variables: location &lt;chr&gt;, type &lt;chr&gt;, note &lt;chr&gt;\n\n\nNein.\n\ncollect_metrics(tree_fit)\n\n# A tibble: 14 × 8\n   cost_complexity tree_depth .metric .estimator      mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1.56e- 5         14 rmse    standard     8.95e+7     5 4.65e+6 Prepro…\n 2        1.56e- 5         14 rsq     standard     5.82e-1     5 3.16e-2 Prepro…\n 3        9.32e- 5         10 rmse    standard     8.91e+7     5 4.66e+6 Prepro…\n 4        9.32e- 5         10 rsq     standard     5.85e-1     5 3.11e-2 Prepro…\n 5        2.36e-10          5 rmse    standard     8.80e+7     5 4.57e+6 Prepro…\n 6        2.36e-10          5 rsq     standard     5.92e-1     5 3.20e-2 Prepro…\n 7        2.29e- 8         11 rmse    standard     8.93e+7     5 4.67e+6 Prepro…\n 8        2.29e- 8         11 rsq     standard     5.83e-1     5 3.10e-2 Prepro…\n 9        9.60e- 4          9 rmse    standard     8.84e+7     5 5.00e+6 Prepro…\n10        9.60e- 4          9 rsq     standard     5.90e-1     5 3.22e-2 Prepro…\n11        1.94e- 9         12 rmse    standard     8.95e+7     5 4.64e+6 Prepro…\n12        1.94e- 9         12 rsq     standard     5.82e-1     5 3.10e-2 Prepro…\n13        5.72e- 7          7 rmse    standard     8.83e+7     5 4.73e+6 Prepro…\n14        5.72e- 7          7 rsq     standard     5.91e-1     5 3.38e-2 Prepro…\n\n\n\nshow_best(tree_fit)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator      mean     n  std_err .config\n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n1        2.36e-10          5 rmse    standard   88038619.     5 4572618. Prepro…\n2        5.72e- 7          7 rmse    standard   88262344.     5 4734314. Prepro…\n3        9.60e- 4          9 rmse    standard   88397994.     5 5003102. Prepro…\n4        9.32e- 5         10 rmse    standard   89140111.     5 4663576. Prepro…\n5        2.29e- 8         11 rmse    standard   89330466.     5 4668641. Prepro…"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#finalisieren",
    "href": "posts/tmdb02/tmdb02.html#finalisieren",
    "title": "tmdb02",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nbest_tree_wf &lt;-\n  wf_tree %&gt;% \n  finalize_workflow(select_best(tree_fit))\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nbest_tree_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (regression)\n\nMain Arguments:\n  cost_complexity = 2.36005153743282e-10\n  tree_depth = 5\n\nComputational engine: rpart \n\n\n\ntree_last_fit &lt;-\n  fit(best_tree_wf, data = d_train)\n\ntree_last_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_impute_knn()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 3000 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 3000 5.672651e+19   66725850  \n   2) budget&lt; 18.32631 2845 1.958584e+19   46935270  \n     4) budget&lt; 17.19976 2252 5.443953e+18   25901120  \n       8) popularity&lt; 9.734966 1745 1.665118e+18   17076460  \n        16) popularity&lt; 5.761331 1019 3.184962e+17    8793730  \n          32) budget&lt; 15.44456 782 1.408243e+17    6074563 *\n          33) budget&gt;=15.44456 237 1.528117e+17   17765830 *\n        17) popularity&gt;=5.761331 726 1.178595e+18   28701940  \n          34) budget&lt; 16.15249 484 6.504138e+17   21093220 *\n          35) budget&gt;=16.15249 242 4.441208e+17   43919380 *\n       9) popularity&gt;=9.734966 507 3.175231e+18   56273980  \n        18) budget&lt; 15.36217 186 3.092335e+17   24880850  \n          36) popularity&lt; 14.04031 151 1.743659e+17   20728170 *\n          37) popularity&gt;=14.04031 35 1.210294e+17   42796710 *\n        19) budget&gt;=15.36217 321 2.576473e+18   74464390  \n          38) popularity&lt; 19.64394 300 2.025184e+18   68010500 *\n          39) popularity&gt;=19.64394 21 3.602808e+17  166662900 *\n     5) budget&gt;=17.19976 593 9.361685e+18  126815400  \n      10) popularity&lt; 19.63372 570 6.590372e+18  117422100  \n        20) budget&lt; 17.86726 374 2.692151e+18   94469490  \n          40) popularity&lt; 8.444193 149 6.363495e+17   68256660 *\n          41) popularity&gt;=8.444193 225 1.885623e+18  111828200 *\n        21) budget&gt;=17.86726 196 3.325222e+18  161219400  \n          42) popularity&lt; 11.60513 126 1.693483e+18  136587100 *\n          43) popularity&gt;=11.60513 70 1.417677e+18  205557600 *\n      11) popularity&gt;=19.63372 23 1.474624e+18  359605200  \n        22) runtime&gt;=109.5 16 9.882757e+17  299077200 *\n        23) runtime&lt; 109.5 7 2.937458e+17  497955000 *\n   3) budget&gt;=18.32631 155 1.557371e+19  429978800  \n     6) popularity&lt; 17.26579 101 4.711450e+18  299997300  \n      12) budget&lt; 18.73897 67 1.671489e+18  230290900  \n        24) popularity&lt; 12.66146 40 5.426991e+17  174328700  \n          48) budget&lt; 18.44536 18 1.099070e+17  134734600 *\n          49) budget&gt;=18.44536 22 3.814856e+17  206724000 *\n        25) popularity&gt;=12.66146 27 8.179336e+17  313197700  \n          50) budget&lt; 18.52944 13 1.273606e+17  234797100 *\n          51) budget&gt;=18.52944 14 5.364675e+17  385998300 *\n      13) budget&gt;=18.73897 34 2.072879e+18  437360100  \n        26) runtime&lt; 132.5 26 1.123840e+18  391271100  \n          52) popularity&lt; 11.34182 9 9.729505e+16  248614500 *\n          53) popularity&gt;=11.34182 17 7.464210e+17  466795200 *\n        27) runtime&gt;=132.5 8 7.143147e+17  587149400 *\n     7) popularity&gt;=17.26579 54 5.964228e+18  673092200  \n      14) budget&lt; 18.99438 33 2.082469e+18  534404700  \n        28) popularity&lt; 25.35778 19 5.425201e+17  416871200 *\n\n...\nand 4 more lines."
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#vorhersage-test-sample",
    "href": "posts/tmdb02/tmdb02.html#vorhersage-test-sample",
    "title": "tmdb02",
    "section": "Vorhersage Test-Sample",
    "text": "Vorhersage Test-Sample\n\npredict(tree_last_fit, new_data = d_test)\n\n# A tibble: 4,398 × 1\n        .pred\n        &lt;dbl&gt;\n 1   6074563.\n 2   6074563.\n 3  21093221.\n 4  21093221.\n 5   6074563.\n 6  21093221.\n 7   6074563.\n 8  68256659.\n 9  43919378.\n10 205557624.\n# ℹ 4,388 more rows\n\n\n\nRF"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#fitten-und-tunen-1",
    "href": "posts/tmdb02/tmdb02.html#fitten-und-tunen-1",
    "title": "tmdb02",
    "section": "Fitten und Tunen",
    "text": "Fitten und Tunen\nUm Rechenzeit zu sparen, kann man das Objekt, wenn einmal berechnet, abspeichern unter result_obj_path auf der Festplatte und beim nächsten Mal importieren, das geht schneller als neu berechnen.\nDas könnte dann z.B. so aussehen:\n\nif (file.exists(result_obj_path)) {\n  rf_fit &lt;- read_rds(result_obj_path)\n} else {\n  tic()\n  rf_fit &lt;-\n    wf_rf %&gt;% \n    tune_grid(\n      resamples = cv_scheme)\n  toc()\n}\n\nAchtung Ein Ergebnisobjekt von der Festplatte zu laden ist gefährlich. Wenn Sie Ihr Modell verändern, aber vergessen, das Objekt auf der Festplatte zu aktualisieren, werden Ihre Ergebnisse falsch sein (da auf dem veralteten Objekt beruhend), ohne dass Sie durch eine Fehlermeldung von R gewarnt würden!\nSo kann man das Ergebnisobjekt auf die Festplatte schreiben:\n\n#write_rds(rf_fit, file = \"objects/tmbd_rf_fit1.rds\")\n\nAber wir berechnen lieber neu:\n\ntic()\nrf_fit &lt;-\n  wf_rf %&gt;% \n  tune_grid(\n    resamples = cv_scheme\n    #grid = 2\n    )\ntoc()\n\n34.282 sec elapsed\n\n\n\ncollect_metrics(rf_fit)\n\n# A tibble: 20 × 8\n    mtry min_n .metric .estimator         mean     n      std_err .config       \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt; &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;         \n 1     3    26 rmse    standard   81496992.        5 4420334.     Preprocessor1…\n 2     3    26 rsq     standard          0.647     5       0.0319 Preprocessor1…\n 3     1     8 rmse    standard   81104914.        5 4249148.     Preprocessor1…\n 4     1     8 rsq     standard          0.651     5       0.0270 Preprocessor1…\n 5     3    13 rmse    standard   82253761.        5 4204371.     Preprocessor1…\n 6     3    13 rsq     standard          0.639     5       0.0316 Preprocessor1…\n 7     2    16 rmse    standard   81466291.        5 4103501.     Preprocessor1…\n 8     2    16 rsq     standard          0.646     5       0.0298 Preprocessor1…\n 9     2    36 rmse    standard   81355080.        5 4051776.     Preprocessor1…\n10     2    36 rsq     standard          0.649     5       0.0281 Preprocessor1…\n11     3     5 rmse    standard   84125788.        5 4113181.     Preprocessor1…\n12     3     5 rsq     standard          0.623     5       0.0347 Preprocessor1…\n13     1    32 rmse    standard   82381636.        5 4069505.     Preprocessor1…\n14     1    32 rsq     standard          0.645     5       0.0230 Preprocessor1…\n15     1    33 rmse    standard   82130106.        5 3978566.     Preprocessor1…\n16     1    33 rsq     standard          0.647     5       0.0231 Preprocessor1…\n17     2    20 rmse    standard   81547269.        5 4189669.     Preprocessor1…\n18     2    20 rsq     standard          0.647     5       0.0294 Preprocessor1…\n19     2    23 rmse    standard   81351141.        5 4073682.     Preprocessor1…\n20     2    23 rsq     standard          0.648     5       0.0285 Preprocessor1…\n\n\n\nselect_best(rf_fit)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1     8 Preprocessor1_Model02"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#finalisieren-1",
    "href": "posts/tmdb02/tmdb02.html#finalisieren-1",
    "title": "tmdb02",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nfinal_wf &lt;-\n  wf_rf %&gt;% \n  finalize_workflow(select_best(rf_fit))\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n\nfinal_fit &lt;-\n  fit(final_wf, data = d_train)\n\n\nfinal_preds &lt;- \n  final_fit %&gt;% \n  predict(new_data = d_test) %&gt;% \n  bind_cols(d_test)\n\n\nsubmission &lt;-\n  final_preds %&gt;% \n  select(id, revenue = .pred)\n\nAbspeichern und einreichen:\n\nwrite_csv(submission, file = \"submission.csv\")"
  },
  {
    "objectID": "posts/tmdb02/tmdb02.html#kaggle-score",
    "href": "posts/tmdb02/tmdb02.html#kaggle-score",
    "title": "tmdb02",
    "section": "Kaggle Score",
    "text": "Kaggle Score\nDiese Submission erzielte einen Score von 2.7664 (RMSLE).\n\nsol &lt;- 2.7664\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\ntrees\nnum"
  },
  {
    "objectID": "posts/titanic_casestudy/titanic_casestudy.html",
    "href": "posts/titanic_casestudy/titanic_casestudy.html",
    "title": "titanic_casestudy",
    "section": "",
    "text": "Aufgabe\nFallstudie\nEine Analystin untersucht die Daten zum Titanic-Unglück.\n\nlibrary(tidyverse)\nlibrary(mosaic)\ndata(titanic_train, package = \"titanic\")\n\nZunächst berechnet Sie die Gesamt-Überlebensrate:\n\ntally(Survived ~ 1, data = titanic_train, format = \"percent\")\n\n        1\nSurvived        1\n       0 61.61616\n       1 38.38384\n\n\nDanach überprüft sie, ob sich die Geschlechter hinsichtlich der Überlebensrate unterscheiden.\n\nmosaicplot(Sex ~ Survived, data = titanic_train)\n\n\n\n\n\n\n\n\nAls dritten Schritt versucht Sie, die Überlebensrate auf Basis mehrerer Variablen vorherzusagen, dazu verwendet Sie ein lineares (Logit-)Modell.\n\nlm_titanic1 &lt;- glm(Survived ~ Sex + Age + Fare, \n                   data = titanic_train, family = \"binomial\")\n\nsummary(lm_titanic1)\n\n\nCall:\nglm(formula = Survived ~ Sex + Age + Fare, family = \"binomial\", \n    data = titanic_train)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4107  -0.6376  -0.5875   0.7900   2.0342  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.934841   0.239101   3.910 9.24e-05 ***\nSexmale     -2.347599   0.189956 -12.359  &lt; 2e-16 ***\nAge         -0.010570   0.006498  -1.627    0.104    \nFare         0.012773   0.002696   4.738 2.16e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 964.52  on 713  degrees of freedom\nResidual deviance: 716.07  on 710  degrees of freedom\n  (177 observations deleted due to missingness)\nAIC: 724.07\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nInterpretieren Sie das Ergebnis des Mosaicplots!\nKann man (fundiert) auf Basis dieses Modells sagen, dass das Geschlecht eine Ursache des Überlebens ist? Begründen Sie!\nWelche Variablen eignen sich (laut diesem Modell), um Überleben vorherzusagen?\nWelche Variable ist die wichtigste (laut diesem Modell)?\n\n         \n\n\nLösung\nInterpretieren Sie das Ergebnis des Mosaicplots!\n\nFrauen haben eine deutlich höhere Überlebensrate als Männer.\nEs gibt deutlich mehr Männer als Frauen.\n\nKann man (fundiert) auf Basis dieses Modells sagen, dass das Geschlecht eine Ursache des Überlebens ist? Begründen Sie!\n\nNein.\nZwar ist Geschlecht mit Überlebens korreliert (bzw. die beiden Variablen sind abhängig), aber das heißt noch nicht (zwingend), dass es eine kausale Beziehung ist. So wie “Störche” und “Babies” nur “scheinkorreliert” sind, könnte hier ebenfalls eine Scheinkorrelation vorliegen.\n\nWelche Variablen eignen sich (laut diesem Modell), um Überleben vorherzusagen?\n\nZu diesem Zweck wird mitunter die Signifikanz der Regressiongewichte \\(\\beta\\) herangezogen.\nHier sind sex und fare signifikant.\n\nWelche Variable ist die wichtigste (laut diesem Modell)?\n\nZu diesem Zweck kann der t-Wert herangezogen werden.\nFür sexMale ist dieser Wert (im Modell) am größten.\n\n\nsol &lt;- \"s. text\"\n\n\nCategories:\nstring"
  },
  {
    "objectID": "posts/tidymodels_workflowset01/tidymodels_workflowset01.html",
    "href": "posts/tidymodels_workflowset01/tidymodels_workflowset01.html",
    "title": "tidymodels_workflowset01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie\n         \n\n\nLösung\n\nCategories:\nnum"
  },
  {
    "objectID": "posts/tidymodels2/tidymodels2.html",
    "href": "posts/tidymodels2/tidymodels2.html",
    "title": "tidymodels2",
    "section": "",
    "text": "Aufgabe\nEin merkwürdiger Fehler bzw. eine merkwürdige Fehlermeldung in Tidymodels - das untersuchen wir hier genauer und versuchen das Phänomen zu erklären.\nAufgabe\nErläutern Sie die Ursachen des Fehlers! Schalten Sie den Fehler an und ab, um zu zeigen, dass Sie Ihn verstehen.\n\n\nStartup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nData import\n\ndata(\"mtcars\")\n\nd_train &lt;- mtcars %&gt;% slice_head(n = 20)\nd_test &lt;- mtcars %&gt;% slice(21:n())\n\n\n\nRecipe\n\npreds_chosen &lt;- c(\"hp\", \"disp\", \"am\")\n\n\nrec1 &lt;- \n  recipe( ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %&gt;% \n  update_role(mpg, new_role = \"outcome\")\nrec1\n\n\nd_train_baked &lt;-\n  rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n\nRows: 20\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1\n\n\n\n\nModel 1\n\nmodel_lm &lt;- linear_reg()\n\n\n\nWorkflow 1\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model_lm) %&gt;% \n  add_recipe(rec1)\n\n\n\nFit\n\nlm_fit1 &lt;-\n  wf1 %&gt;% \n  fit(d_train)\n\n\npreds &lt;-\n  lm_fit1 %&gt;% \n  predict(d_test)\n\nhead(preds)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  22.6\n2  17.2\n3  17.4\n4  12.1\n5  14.9\n6  28.2\n\n\nAus Gründen der Reproduzierbarkeit bietet es sich an, eine SessionInfo anzugeben:\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] yardstick_1.3.1    workflowsets_1.1.0 workflows_1.1.4    tune_1.2.1        \n [5] rsample_1.2.1      recipes_1.1.0      parsnip_1.2.1      modeldata_1.3.0   \n [9] infer_1.0.7        dials_1.3.0        scales_1.3.0       broom_1.0.6       \n[13] tidymodels_1.2.0   lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n[17] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[21] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] foreach_1.5.2       jsonlite_1.8.8      splines_4.2.1      \n [4] prodlim_2023.03.31  GPfit_1.0-8         yaml_2.3.8         \n [7] globals_0.16.2      ipred_0.9-14        pillar_1.9.0       \n[10] backports_1.4.1     lattice_0.21-8      glue_1.6.2         \n[13] digest_0.6.33       hardhat_1.4.0       colorspace_2.1-0   \n[16] htmltools_0.5.7     Matrix_1.5-4.1      timeDate_4022.108  \n[19] pkgconfig_2.0.3     lhs_1.1.6           DiceDesign_1.9     \n[22] listenv_0.9.0       gower_1.0.1         lava_1.7.2.1       \n[25] tzdb_0.4.0          timechange_0.2.0    generics_0.1.3     \n[28] withr_3.0.0         furrr_0.3.1         nnet_7.3-19        \n[31] cli_3.6.2           survival_3.5-5      magrittr_2.0.3     \n[34] evaluate_0.23       fansi_1.0.6         future_1.33.0      \n[37] parallelly_1.36.0   MASS_7.3-60         class_7.3-22       \n[40] tools_4.2.1         data.table_1.15.4   hms_1.1.3          \n[43] lifecycle_1.0.4     munsell_0.5.0       compiler_4.2.1     \n[46] rlang_1.1.4         grid_4.2.1          iterators_1.0.14   \n[49] rstudioapi_0.16.0   htmlwidgets_1.6.4   rmarkdown_2.28     \n[52] gtable_0.3.4        codetools_0.2-19    R6_2.5.1           \n[55] knitr_1.48          fastmap_1.1.1       future.apply_1.11.0\n[58] utf8_1.2.4          stringi_1.8.3       parallel_4.2.1     \n[61] Rcpp_1.0.13         vctrs_0.6.5         rpart_4.1.21       \n[64] tidyselect_1.2.0    xfun_0.47          \n\n\n         \n\n\nLösung\nDefiniert man das Rezept so:\n\nrec2 &lt;- recipe(mpg ~ hp + disp + am, data = d_train)\n\nDann läuft predict() brav durch.\nAuch dieser Code funktioniert:\n\nrec3 &lt;- \n  recipe(mpg ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %&gt;% \n  update_role(mpg, new_role = \"outcome\")\n\nDas Problem von rec1 scheint darin zu legen, dass die Rollen der Variablen nicht richtig gelöscht werden, was predict() verwirrt:\n\nrec1 &lt;- \n  recipe(mpg ~ ., data = d_train) %&gt;% \n  update_role(all_predictors(), new_role = \"id\") %&gt;% \n  update_role(all_of(preds_chosen), new_role = \"predictor\") %&gt;% \n  update_role(mpg, new_role = \"outcome\")\nrec1\n\nDaher läuft das Rezept rec3 durch, wenn man zunächst alle Prädiktoren in ID-Variablen umwandelt: Damit sind alle Rollen wieder sauber.\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nerror\nstring"
  },
  {
    "objectID": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "href": "posts/tidymodels-vorlage3/tidymodels-vorlage3.html",
    "title": "tidymodels-vorlage3",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse für ein Vorhersagemodell, das sich als Vorlage für Analysen dieser Art eignet!\nVerzichten Sie auf Resampling und Tuning.\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie keinen Parameter des Modells\nVerwenden Sie keine Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\n# Setup:\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.3     ✔ stringr   1.5.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tictoc)  # Zeitmessung\nlibrary(easystats)   # NAs zählen\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (6): rownames, bill_length_mm, bill_depth_mm, flipper_length_mm, body_ma...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"regression\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d_train) |&gt; \n  step_unknown(all_nominal_predictors(), new_level = \"NA\") |&gt; \n  step_naomit(all_predictors()) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_zv(all_predictors()) |&gt; \n  step_normalize(all_predictors()) \n\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  last_fit(split = d_split)\n\n→ A | error:   Missing data in columns: bill_length_mm, bill_depth_mm, flipper_length_mm.\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\nWarning: All models failed. Run `show_notes(.Last.tune.result)` for more\ninformation.\n\ntoc()\n\n0.594 sec elapsed\n\ncollect_metrics(wf1_fit)\n\nNULL\n\n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n# A tibble: 6 × 12\n  rownames bill_length_mm bill_depth_mm flipper_length_mm    year body_mass_g\n     &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n1   -1.24          -1.53          0.386            -0.794 -1.29          3450\n2    1.45           1.32          0.386            -0.365  1.14          3675\n3   -0.212          0.401        -1.97              0.707 -1.29          4500\n4   -0.993          0.343         0.887            -0.294 -0.0757        4150\n5    0.530          0.879        -0.566             2.07  -0.0757        5800\n6   -0.281         -0.957         0.787            -1.15   1.14          3650\n# ℹ 6 more variables: species_Chinstrap &lt;dbl&gt;, species_Gentoo &lt;dbl&gt;,\n#   island_Dream &lt;dbl&gt;, island_Torgersen &lt;dbl&gt;, sex_male &lt;dbl&gt;, sex_NA. &lt;dbl&gt;\n\n\n\ndescribe_distribution(d_train_baked)\n\nVariable          |      Mean |     SD |     IQR |              Range | Skewness | Kurtosis |   n | n_Missing\n-------------------------------------------------------------------------------------------------------------\nrownames          | -5.63e-17 |   1.00 |    1.70 |      [-1.72, 1.68] |    -0.01 |    -1.21 | 257 |         0\nbill_length_mm    | -2.97e-16 |   1.00 |    1.68 |      [-2.28, 2.98] |     0.01 |    -0.79 | 257 |         0\nbill_depth_mm     |  2.71e-16 |   1.00 |    1.60 |      [-2.02, 2.19] |    -0.11 |    -0.87 | 257 |         0\nflipper_length_mm | -9.83e-16 |   1.00 |    1.64 |      [-1.94, 2.07] |     0.32 |    -1.02 | 257 |         0\nyear              | -6.89e-14 |   1.00 |    2.43 |      [-1.29, 1.14] |    -0.12 |    -1.51 | 257 |         0\nbody_mass_g       |   4200.97 | 792.54 | 1212.50 | [2700.00, 6300.00] |     0.49 |    -0.69 | 257 |         0\nspecies_Chinstrap | -2.24e-17 |   1.00 |    0.00 |      [-0.50, 1.98] |     1.49 |     0.22 | 257 |         0\nspecies_Gentoo    |  1.64e-17 |   1.00 |    2.07 |      [-0.76, 1.31] |     0.56 |    -1.70 | 257 |         0\nisland_Dream      | -5.50e-17 |   1.00 |    2.08 |      [-0.75, 1.34] |     0.60 |    -1.66 | 257 |         0\nisland_Torgersen  |  1.72e-17 |   1.00 |    0.00 |      [-0.41, 2.43] |     2.04 |     2.18 | 257 |         0\nsex_male          | -5.86e-17 |   1.00 |    2.00 |      [-0.96, 1.03] |     0.07 |    -2.01 | 257 |         0\nsex_NA.           |  1.45e-17 |   1.00 |    0.00 |      [-0.15, 6.46] |     6.35 |    38.63 | 257 |         0\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/tidymodels-vorlage/tidymodels-vorlage.html",
    "href": "posts/tidymodels-vorlage/tidymodels-vorlage.html",
    "title": "tidymodels-vorlage",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse für ein Vorhersagemodell, das sich als Vorlage für Analysen dieser Art eignet!\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie mind. einen Parameter des Modells\nVerwenden Sie Kreuzvalidierung\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\n# 2023-05-08\n\n\n# Setup:\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.3     ✔ stringr   1.5.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tictoc)  # Zeitmessung\nlibrary(baguette)  # Bagged-Trees\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (6): rownames, bill_length_mm, bill_depth_mm, flipper_length_mm, body_ma...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_bag &lt;-\n  bag_tree(mode = \"regression\",\n           cost_complexity = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- recipe(body_mass_g ~  ., data = d_train)\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_bag) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n35.202 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 7\n  cost_complexity .metric .estimator  mean     n std_err .config              \n            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1        2.10e- 3 rmse    standard    302.    10    13.1 Preprocessor1_Model09\n2        1.72e-10 rmse    standard    305.    10    18.4 Preprocessor1_Model10\n3        1.71e- 9 rmse    standard    306.    10    17.3 Preprocessor1_Model07\n4        3.34e- 5 rmse    standard    311.    10    18.1 Preprocessor1_Model04\n5        7.33e- 9 rmse    standard    316.    10    15.1 Preprocessor1_Model03\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     326.    Preprocessor1_Model1\n2 rsq     standard       0.847 Preprocessor1_Model1\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html",
    "title": "tidymodels-tree4",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nEntscheidungsbaum\n\nModellformel: body_mass_g ~ . (Datensatz palmerpenguins::penguins)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nAuslassen gering performanter Tuningparameterwerte\nVerwenden Sie ein Anova-Grid-Search!\nParallelisieren Sie auf mehrere Kerne (wenn möglich).\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nBeachten Sie die üblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#setup",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#setup",
    "title": "tidymodels-tree4",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\ndata(\"penguins\", package = \"palmerpenguins\")\nlibrary(tictoc)  # Zeitmessung\nlibrary(finetune)  # tune_race_anova\nlibrary(doParallel)  # mehrere CPUs nutzen \n\nLoading required package: foreach\n\n\n\nAttaching package: 'foreach'\n\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nset.seed(42)\n\nEntfernen wir Fälle ohne y-Wert:\n\nd &lt;-\n  penguins %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#daten-teilen",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#daten-teilen",
    "title": "tidymodels-tree4",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#modelle",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#modelle",
    "title": "tidymodels-tree4",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"regression\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#rezepte",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#rezepte",
    "title": "tidymodels-tree4",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(body_mass_g ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#resampling",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#resampling",
    "title": "tidymodels-tree4",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#workflows",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#workflows",
    "title": "tidymodels-tree4",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#tuning-grid",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#tuning-grid",
    "title": "tidymodels-tree4",
    "section": "Tuning-Grid",
    "text": "Tuning-Grid\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\n\nHinweis: Andere Arten von Tuning-Grids sind sinnvoller, hier ist nur zum Vergleich mit anderen Aufgaben diese Form des Tuning-Grids gewählt.\nDie Zeilen im Tuninggrid zeigen uns, für wie viele Modellparameter ein Modell berechnet wird. Natürlich üblicherweise jedes Modell mit Resampling. Da kommt in Summe ein mitunter sehr große Menge an Modellberechnungen zusammen."
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#ohne-speed-up",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#ohne-speed-up",
    "title": "tidymodels-tree4",
    "section": "Ohne Speed-up",
    "text": "Ohne Speed-up\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            resamples = rsmpl)\ntoc()\n\n78.464 sec elapsed\n\n\nDie angegebene Rechenzeit bezieht sich auf einen 4-Kerne-MacBook Pro (2020)."
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-1",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-1",
    "title": "tidymodels-tree4",
    "section": "Mit Speeed-up 1",
    "text": "Mit Speeed-up 1\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            control = control_race(verbose = FALSE,\n                                   pkgs = c(\"tidymodels\"),\n                                   save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n72.066 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-2",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-2",
    "title": "tidymodels-tree4",
    "section": "Mit Speeed-up 2",
    "text": "Mit Speeed-up 2\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(\n    object = wf_tree,\n    grid = tune_grid,\n    metrics = metric_set(rmse),\n    control = control_race(verbose = FALSE,\n                           pkgs = c(\"tidymodels\"),\n                           save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n27.524 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-3",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#mit-speeed-up-3",
    "title": "tidymodels-tree4",
    "section": "Mit Speeed-up 3",
    "text": "Mit Speeed-up 3\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            control = control_grid(verbose = FALSE,\n                                   save_pred = TRUE),\n            resamples = rsmpl)\ntoc()\n\n27.312 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree4/tidymodels-tree4.html#fazit",
    "href": "posts/tidymodels-tree4/tidymodels-tree4.html#fazit",
    "title": "tidymodels-tree4",
    "section": "Fazit",
    "text": "Fazit\nMit Speed-up ist schneller also ohne. Hier haben wir einen Entscheidungsbaum berechnet, der ist nicht so sehr parallelisierbar. Bei einem “Wald-Modell”, wie Random Forests, sollte der Vorteil der Parallisierung viel deutlich sein.\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html",
    "title": "tidymodels-tree2",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nEntscheidungsbaum\n\nModellformel: am ~ . (Datensatz mtcars)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nVerwenden mehrerer Prozesskerne\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nFühren Sie eine \\(v=2\\)-fache Kreuzvalidierung durch (weil die Stichprobe so klein ist).\nBeachten Sie die üblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#setup",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#setup",
    "title": "tidymodels-tree2",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\nlibrary(doParallel)  # Nutzen mehrerer Kerne\n\nLoading required package: foreach\n\n\n\nAttaching package: 'foreach'\n\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\n\nFür Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#daten-teilen",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#daten-teilen",
    "title": "tidymodels-tree2",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#modelle",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#modelle",
    "title": "tidymodels-tree2",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#rezepte",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#rezepte",
    "title": "tidymodels-tree2",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#resampling",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#resampling",
    "title": "tidymodels-tree2",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#workflows",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#workflows",
    "title": "tidymodels-tree2",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#tuningfitting",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#tuningfitting",
    "title": "tidymodels-tree2",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\ntune_grid\n\n# A tibble: 125 × 3\n   cost_complexity tree_depth min_n\n             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n 1    0.0000000001          1     2\n 2    0.0000000178          1     2\n 3    0.00000316            1     2\n 4    0.000562              1     2\n 5    0.1                   1     2\n 6    0.0000000001          4     2\n 7    0.0000000178          4     2\n 8    0.00000316            4     2\n 9    0.000562              4     2\n10    0.1                   4     2\n# ℹ 115 more rows"
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#ohne-parallelisierung",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#ohne-parallelisierung",
    "title": "tidymodels-tree2",
    "section": "Ohne Parallelisierung",
    "text": "Ohne Parallelisierung\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\n\n→ A | warning: 21 samples were requested but there were 12 rows in the data. 12 will be used.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x3\n\n\n→ B | warning: 30 samples were requested but there were 12 rows in the data. 12 will be used.\n\n\nThere were issues with some computations   A: x3\nThere were issues with some computations   A: x25   B: x7\n→ C | warning: 40 samples were requested but there were 12 rows in the data. 12 will be used.\nThere were issues with some computations   A: x25   B: x7\nThere were issues with some computations   A: x25   B: x25   C: x10\nThere were issues with some computations   A: x26   B: x25   C: x25\nThere were issues with some computations   A: x35   B: x25   C: x25\nThere were issues with some computations   A: x50   B: x38   C: x25\nThere were issues with some computations   A: x50   B: x50   C: x39\nThere were issues with some computations   A: x50   B: x50   C: x50\n\ntoc()\n\n23.317 sec elapsed\n\n\nca. 45 sec. auf meinem Rechner (4-Kerne-MacBook Pro 2020)."
  },
  {
    "objectID": "posts/tidymodels-tree2/tidymodels-tree2.html#mit-parallelisierung",
    "href": "posts/tidymodels-tree2/tidymodels-tree2.html#mit-parallelisierung",
    "title": "tidymodels-tree2",
    "section": "Mit Parallelisierung",
    "text": "Mit Parallelisierung\nWie viele CPUs hat mein Computer?\n\nparallel::detectCores(logical = FALSE)\n\n[1] 4\n\n\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\nfit_tree2 &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\n12.936 sec elapsed\n\n\nca. 17 Sekunden - deutlich schneller!\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/tidymodels-remove-na2/tidymodels-remove-na2.html",
    "href": "posts/tidymodels-remove-na2/tidymodels-remove-na2.html",
    "title": "tidymodels-remove-na2",
    "section": "",
    "text": "Aufgabe\n\nDas folgende Rezept ist gedacht, fehlende Werte aus dem Datensatz penguins zu entfernen. Allerdings erfüllt es diese Aufgabe nicht.\nFinden Sie den Fehler und korrigieren Sie das Rezept.\nHinweise:\n\nVerwenden Sie tidymodels.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\n# Setup:\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.3     ✔ stringr   1.5.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (6): rownames, bill_length_mm, bill_depth_mm, flipper_length_mm, body_ma...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d) |&gt; \n  step_naomit() \n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n# A tibble: 6 × 9\n  rownames species island   bill_length_mm bill_depth_mm flipper_length_mm sex  \n     &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt; &lt;fct&gt;\n1        1 Adelie  Torgers…           39.1          18.7               181 male \n2        2 Adelie  Torgers…           39.5          17.4               186 fema…\n3        3 Adelie  Torgers…           40.3          18                 195 fema…\n4        4 Adelie  Torgers…           NA            NA                  NA &lt;NA&gt; \n5        5 Adelie  Torgers…           36.7          19.3               193 fema…\n6        6 Adelie  Torgers…           39.3          20.6               190 male \n# ℹ 2 more variables: year &lt;dbl&gt;, body_mass_g &lt;dbl&gt;\n\n\n\ndescribe_distribution(d_train_baked)\n\nVariable          |    Mean |     SD |     IQR |              Range | Skewness | Kurtosis |   n | n_Missing\n-----------------------------------------------------------------------------------------------------------\nrownames          |  172.50 |  99.45 |  172.50 |     [1.00, 344.00] |     0.00 |    -1.20 | 344 |         0\nbill_length_mm    |   43.92 |   5.46 |    9.30 |     [32.10, 59.60] |     0.05 |    -0.88 | 342 |         2\nbill_depth_mm     |   17.15 |   1.97 |    3.12 |     [13.10, 21.50] |    -0.14 |    -0.91 | 342 |         2\nflipper_length_mm |  200.92 |  14.06 |   23.25 |   [172.00, 231.00] |     0.35 |    -0.98 | 342 |         2\nyear              | 2008.03 |   0.82 |    2.00 | [2007.00, 2009.00] |    -0.05 |    -1.50 | 344 |         0\nbody_mass_g       | 4201.75 | 801.95 | 1206.25 | [2700.00, 6300.00] |     0.47 |    -0.72 | 342 |         2\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/tidymodels-poly02/tidymodels-poly02.html",
    "href": "posts/tidymodels-poly02/tidymodels-poly02.html",
    "title": "tidymodels-poly02",
    "section": "",
    "text": "Aufgabe\nFitten Sie ein Polynomial-Modell für folgende Modellgleichung:\nbody_mass_g ~ bill_length_mm.\nGesucht ist der RMSE im Test-Set (optimal hinsichtlich minimalem Prognosefehler).\nHinweise:\n\nDatensatz penguins (palmerpenguins)\nVerwenden Sie Tidymodels\nFitten Sie Polynome des Grades 1 bis 10.\nDefinieren Sie die Polynomegrade als Tuningparameter.\nEntfernen Sie fehlende Werte in den Prädiktoren.\nWie immer gilt: Verwenden Sie die Standardeinstellungen der Funktionen, soweit nicht anders angegeben.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\ndata(penguins, package = \"palmerpenguins\")\n\nDatenaufteilung:\n\nd_split &lt;- initial_split(penguins)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nRezept:\n\nrec1 &lt;- \n  recipe(body_mass_g ~ bill_length_mm, data = penguins) %&gt;% \n  step_naomit(all_predictors()) %&gt;% \n  step_poly(all_predictors(), degree = tune()) %&gt;% \n  update_role(contains(\"_poly_\"), new_role = \"predictor\")\n\nWarning: No columns were selected in `update_role()`.\n\n\nCheck:\n\nd_baked &lt;- bake(prep(rec1), new_data = NULL)\n\nRezepte mit Tuningparametern kann man nicht preppen/backen.\nWorkflow:\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(linear_reg()) %&gt;% \n  add_recipe(rec1)\n\nTuning:\n\nset.seed(42)\ntune1 &lt;-\n  tune_grid(\n    wf1,\n    resamples = vfold_cv(data = penguins),\n    metrics = metric_set(rmse),\n    grid = grid_regular(degree(range = c(1, 10)),\n                               levels = 10),\n    control = control_grid(save_workflow = TRUE)\n  )\n\n\nautoplot(tune1)\n\n\n\n\n\n\n\n\n\nshow_best(tune1)\n\n# A tibble: 5 × 7\n  degree .metric .estimator  mean     n std_err .config              \n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1      2 rmse    standard    638.    10    22.7 Preprocessor02_Model1\n2      4 rmse    standard    641.    10    23.7 Preprocessor04_Model1\n3      1 rmse    standard    643.    10    21.8 Preprocessor01_Model1\n4      5 rmse    standard    643.    10    23.5 Preprocessor05_Model1\n5      3 rmse    standard    643.    10    24.2 Preprocessor03_Model1\n\n\nFinalisieren:\n\nbest1 &lt;- fit_best(tune1)\nbest1\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_naomit()\n• step_poly()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n          (Intercept)  bill_length_mm_poly_1  bill_length_mm_poly_2  \n                 4202                   8813                  -1708  \n\n\nPredicten:\n\nfinal1 &lt;- last_fit(best1, d_split)\ncollect_metrics(final1)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     666.    Preprocessor1_Model1\n2 rsq     standard       0.287 Preprocessor1_Model1\n\n\nOder so:\n\nsol &lt;- \npredict(best1, new_data = d_test) %&gt;% \n  bind_cols(d_test) %&gt;% \n  rmse(truth = body_mass_g, estimate = .pred) %&gt;% \n  pull(.estimate) %&gt;% \n  pluck(1)\n\nsol\n\n[1] 657.5297\n\n\nDie Antwort lautet: 657.5296534.\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html",
    "title": "tidymodels-penguins07",
    "section": "",
    "text": "Berechnen Sie ein Entscheidungsbaum-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm.\nBerichten Sie die RMSE!\nHinweise:\n\nTuning Sie \\(Cp\\) mit 20 verschiedenen den Werten.\nLöschen Sie alle Zeilen mit fehlenden Werten in den Prädiktoren.\nBeachten Sie die üblichen Hinweise.\nNatürlich gilt: Ceteris paribus. Halten Sie also die Modelle im Übrigen vergleichbar bzw. identisch."
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#setup",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#setup",
    "title": "tidymodels-penguins07",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nWir dürfen keine fehlenden Werte in der Y-Variable haben (im Train-Set), sonst meckert Tidymodels:\n\nd2 &lt;- \n  d %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#daten-aufteilen",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#daten-aufteilen",
    "title": "tidymodels-penguins07",
    "section": "Daten aufteilen:",
    "text": "Daten aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#cv-1",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#cv-1",
    "title": "tidymodels-penguins07",
    "section": "CV",
    "text": "CV\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 10)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#workflow",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#workflow",
    "title": "tidymodels-penguins07",
    "section": "Workflow",
    "text": "Workflow\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric_predictors())\n\nmod_tree &lt;- \ndecision_tree(\n  mode = \"regression\",\n  cost_complexity = tune()\n)\n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#fitten",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#fitten",
    "title": "tidymodels-penguins07",
    "section": "Fitten",
    "text": "Fitten\n\ntic()\nwflow_fit &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = 20,\n    metrics = metric_set(rmse)\n    )\ntoc()\n\n12.189 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-penguins07/tidymodels-penguins07.html#modellgüte",
    "href": "posts/tidymodels-penguins07/tidymodels-penguins07.html#modellgüte",
    "title": "tidymodels-penguins07",
    "section": "Modellgüte",
    "text": "Modellgüte\n\nbestfit1 &lt;- fit_best(x = wflow_fit)\nlastfit1 &lt;- last_fit(bestfit1, d_split)\ncollect_metrics(lastfit1)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     638.    Preprocessor1_Model1\n2 rsq     standard       0.315 Preprocessor1_Model1\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntrees\nschoice"
  },
  {
    "objectID": "posts/tidymodels-penguins05/tidymodels-penguins05.html",
    "href": "posts/tidymodels-penguins05/tidymodels-penguins05.html",
    "title": "tidymodels-penguins05",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=2 CV.\nTunen Sie \\(K\\), setzen Sie den Tuning-Wertebereich auf 1 bis 5.\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs prüfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nK-Nearest Neighbor Model Specification (regression)\n\nMain Arguments:\n  neighbors = tune()\n\nComputational engine: kknn \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n# A tibble: 6 × 2\n  bill_length_mm body_mass_g\n           &lt;dbl&gt;       &lt;dbl&gt;\n1           34.5        2900\n2           52.2        3450\n3           45.4        4800\n4           42.1        4000\n5           50          5350\n6           41.5        4000\n\n\nAuf NA prüfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5, repeats = 2)\nfolds\n\n#  5-fold cross-validation repeated 2 times \n# A tibble: 10 × 3\n   splits           id      id2  \n   &lt;list&gt;           &lt;chr&gt;   &lt;chr&gt;\n 1 &lt;split [199/50]&gt; Repeat1 Fold1\n 2 &lt;split [199/50]&gt; Repeat1 Fold2\n 3 &lt;split [199/50]&gt; Repeat1 Fold3\n 4 &lt;split [199/50]&gt; Repeat1 Fold4\n 5 &lt;split [200/49]&gt; Repeat1 Fold5\n 6 &lt;split [199/50]&gt; Repeat2 Fold1\n 7 &lt;split [199/50]&gt; Repeat2 Fold2\n 8 &lt;split [199/50]&gt; Repeat2 Fold3\n 9 &lt;split [199/50]&gt; Repeat2 Fold4\n10 &lt;split [200/49]&gt; Repeat2 Fold5\n\n\nTunen:\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = grid_regular(\n      neighbors(range = c(1, 5))\n    )\n  )\n\nd_resamples\n\n# Tuning results\n# 5-fold cross-validation repeated 2 times \n# A tibble: 10 × 5\n   splits           id      id2   .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;   &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [199/50]&gt; Repeat1 Fold1 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [199/50]&gt; Repeat1 Fold2 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [199/50]&gt; Repeat1 Fold3 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [199/50]&gt; Repeat1 Fold4 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [200/49]&gt; Repeat1 Fold5 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [199/50]&gt; Repeat2 Fold1 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [199/50]&gt; Repeat2 Fold2 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [199/50]&gt; Repeat2 Fold3 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [199/50]&gt; Repeat2 Fold4 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [200/49]&gt; Repeat2 Fold5 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nBester Kandidat:\n\nshow_best(d_resamples)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 3 × 7\n  neighbors .metric .estimator  mean     n std_err .config             \n      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1         5 rmse    standard    733.    10    19.3 Preprocessor1_Model3\n2         3 rmse    standard    777.    10    23.8 Preprocessor1_Model2\n3         1 rmse    standard    945.    10    28.0 Preprocessor1_Model1\n\n\n\nfitbest &lt;- fit_best(d_resamples)\nfitbest\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nkknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5L,     data, 5))\n\nType of response variable: continuous\nminimal mean absolute error: 497.0257\nMinimal mean squared error: 407926.4\nBest kernel: optimal\nBest k: 5\n\n\nLast Fit:\n\nfit_last &lt;- last_fit(fitbest, d_split)\nfit_last\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits           id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;           &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [249/84]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nModellgüte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     654.    Preprocessor1_Model1\n2 rsq     standard       0.294 Preprocessor1_Model1\n\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n[1] 0.2935091\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins03/tidymodels-penguins03.html",
    "href": "posts/tidymodels-penguins03/tidymodels-penguins03.html",
    "title": "tidymodels-penguins03",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=1 CV.\nTunen Sie \\(K\\) (Default-Tuning)\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs prüfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nK-Nearest Neighbor Model Specification (regression)\n\nMain Arguments:\n  neighbors = tune()\n\nComputational engine: kknn \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n# A tibble: 6 × 2\n  bill_length_mm body_mass_g\n           &lt;dbl&gt;       &lt;dbl&gt;\n1           34.5        2900\n2           52.2        3450\n3           45.4        4800\n4           42.1        4000\n5           50          5350\n6           41.5        4000\n\n\nAuf NA prüfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(43)\nfolds &lt;- vfold_cv(d_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits           id   \n  &lt;list&gt;           &lt;chr&gt;\n1 &lt;split [199/50]&gt; Fold1\n2 &lt;split [199/50]&gt; Fold2\n3 &lt;split [199/50]&gt; Fold3\n4 &lt;split [199/50]&gt; Fold4\n5 &lt;split [200/49]&gt; Fold5\n\n\nTunen:\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE)\n  )\n\nd_resamples\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics          .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [199/50]&gt; Fold1 &lt;tibble [18 × 5]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [199/50]&gt; Fold2 &lt;tibble [18 × 5]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [199/50]&gt; Fold3 &lt;tibble [18 × 5]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [199/50]&gt; Fold4 &lt;tibble [18 × 5]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [200/49]&gt; Fold5 &lt;tibble [18 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nBester Kandidat:\n\nshow_best(d_resamples)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 7\n  neighbors .metric .estimator  mean     n std_err .config             \n      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1        14 rmse    standard    664.     5    22.7 Preprocessor1_Model9\n2        12 rmse    standard    671.     5    23.2 Preprocessor1_Model8\n3        11 rmse    standard    675.     5    24.1 Preprocessor1_Model7\n4         9 rmse    standard    685.     5    22.3 Preprocessor1_Model6\n5         8 rmse    standard    688.     5    22.9 Preprocessor1_Model5\n\n\n\nfitbest &lt;- fit_best(d_resamples)\nfitbest\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nkknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(14L,     data, 5))\n\nType of response variable: continuous\nminimal mean absolute error: 526.4603\nMinimal mean squared error: 416216.1\nBest kernel: optimal\nBest k: 14\n\n\nLast Fit:\n\nfit_last &lt;- last_fit(fitbest, d_split)\nfit_last\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits           id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;           &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [249/84]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nModellgüte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     606.    Preprocessor1_Model1\n2 rsq     standard       0.382 Preprocessor1_Model1\n\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n[1] 0.38246\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins01/tidymodels-penguins01.html",
    "href": "posts/tidymodels-penguins01/tidymodels-penguins01.html",
    "title": "tidymodels-penguins01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=1 CV.\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read.csv(d_path)\n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(penguins)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nlm_mod &lt;-\n  linear_reg()\n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(lm_mod)\n\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n# A tibble: 6 × 2\n  bill_length_mm body_mass_g\n           &lt;dbl&gt;       &lt;int&gt;\n1           36          3450\n2           50.9        3675\n3           46.1        4500\n4           45.8        4150\n5           48.6        5800\n6           39          3650\n\n\nAuf NA prüfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits           id   \n  &lt;list&gt;           &lt;chr&gt;\n1 &lt;split [206/52]&gt; Fold1\n2 &lt;split [206/52]&gt; Fold2\n3 &lt;split [206/52]&gt; Fold3\n4 &lt;split [207/51]&gt; Fold4\n5 &lt;split [207/51]&gt; Fold5\n\n\nResampling:\n\npenguins_resamples &lt;-\n  fit_resamples(\n    wflow,\n    resamples = folds\n  )\npenguins_resamples\n\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics         .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [206/52]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [206/52]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [206/52]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [207/51]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [207/51]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nLast Fit:\n\npenguins_last &lt;- last_fit(wflow, d_split)\n\nModellgüte im Test-Sample:\n\npenguins_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     652.    Preprocessor1_Model1\n2 rsq     standard       0.385 Preprocessor1_Model1\n\n\nR-Quadrat:\n\nsol &lt;-  collect_metrics(penguins_last)[[\".estimate\"]][2]\nsol\n\n[1] 0.3850608\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-lasso2/tidymodels-lasso2.html",
    "href": "posts/tidymodels-lasso2/tidymodels-lasso2.html",
    "title": "tidymodels-lasso2",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine minimale Analyse für ein Vorhersagemodell mit dem Lasso.\nHinweise:\n\nVerzichten Sie auf Tuning der Penalisierung; setzen Sie den Wert auf 0.1\nVerzichten Sie auf die Unterteilung von Train- und Test-Set.\nVerzichten Sie auf Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ .\n\n         \n\n\nLösung\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\n# d_train &lt;- training(d_split)\n# d_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = 0.1,\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\n# set.seed(42)\n# rsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit(data = d)\ntoc()\n\n1.223 sec elapsed\n\n# best candidate:\nwf1_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_normalize()\n• step_dummy()\n• step_impute_bag()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00 697.60\n2   1 12.89 635.70\n3   1 23.58 579.20\n4   1 32.47 527.70\n5   1 39.84 480.90\n6   1 45.96 438.10\n7   1 51.05 399.20\n8   2 55.36 363.80\n9   2 59.11 331.40\n10  2 62.22 302.00\n11  2 64.81 275.20\n12  2 66.95 250.70\n13  3 69.54 228.40\n14  3 72.37 208.20\n15  3 74.73 189.70\n16  3 76.68 172.80\n17  3 78.30 157.50\n18  3 79.65 143.50\n19  3 80.77 130.70\n20  3 81.70 119.10\n21  3 82.47 108.50\n22  3 83.11  98.89\n23  3 83.64  90.10\n24  3 84.08  82.10\n25  3 84.45  74.81\n26  3 84.75  68.16\n27  3 85.00  62.11\n28  3 85.21  56.59\n29  3 85.39  51.56\n30  4 85.54  46.98\n31  5 85.69  42.81\n32  5 85.80  39.00\n33  5 85.90  35.54\n34  6 86.01  32.38\n35  7 86.17  29.50\n36  7 86.31  26.88\n37  7 86.43  24.50\n38  7 86.53  22.32\n39  7 86.62  20.34\n40  7 86.68  18.53\n41  7 86.74  16.88\n42  7 86.79  15.38\n43  8 86.83  14.02\n44  8 86.92  12.77\n45  8 86.99  11.64\n46  8 87.05  10.60\n\n...\nand 24 more lines.\n\n# Modellgüte:\n\npredict(wf1_fit, new_data = d) %&gt;% \n  bind_cols(d %&gt;% select(body_mass_g)) %&gt;% \n  rmse(truth = body_mass_g,\n       estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        285.\n\n\nMan beachte: Für regulierte Modelle sind Zentrierung und Skalierung nötig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nsimple\nstring\ntemplate"
  },
  {
    "objectID": "posts/tidymodels-error1/tidymodels-error1.html",
    "href": "posts/tidymodels-error1/tidymodels-error1.html",
    "title": "tidymodels-error1introd",
    "section": "",
    "text": "Aufgabe\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.0     ✔ tidyr        1.3.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.3.0     ✔ workflows    1.1.3\n✔ parsnip      1.2.0     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.3.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(tictoc)\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read.csv(d_path)\n\nDie folgende Pipeline hat einen Fehler. Welcher ist das?\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"regression\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d_train) |&gt; \n  #step_unknown(all_nominal_predictors(), new_level = \"NA\") |&gt; \n  #step_novel(all_nominal_predictors()) |&gt; \n  step_naomit(all_predictors()) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_nzv(all_predictors()) |&gt; \n  step_normalize(all_predictors()) \n\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# fitting:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  fit(data = d_train)\ntoc()\n\n0.256 sec elapsed\n\npreds &lt;- predict(wf1_fit, new_data = d_test) \n\nError: Missing data in columns: bill_length_mm, bill_depth_mm, flipper_length_mm.\n\n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n# A tibble: 6 × 12\n  rownames bill_length_mm bill_depth_mm flipper_length_mm    year body_mass_g\n     &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;   &lt;dbl&gt;       &lt;int&gt;\n1   -1.24          -1.53          0.386            -0.794 -1.29          3450\n2    1.45           1.32          0.386            -0.365  1.14          3675\n3   -0.212          0.401        -1.97              0.707 -1.29          4500\n4   -0.993          0.343         0.887            -0.294 -0.0757        4150\n5    0.530          0.879        -0.566             2.07  -0.0757        5800\n6   -0.281         -0.957         0.787            -1.15   1.14          3650\n# ℹ 6 more variables: species_Chinstrap &lt;dbl&gt;, species_Gentoo &lt;dbl&gt;,\n#   island_Dream &lt;dbl&gt;, island_Torgersen &lt;dbl&gt;, sex_female &lt;dbl&gt;,\n#   sex_male &lt;dbl&gt;\n\n\n\nd_train_baked |&gt; \n  map_int(~ sum(is.na(.)))\n\n         rownames    bill_length_mm     bill_depth_mm flipper_length_mm \n                0                 0                 0                 0 \n             year       body_mass_g species_Chinstrap    species_Gentoo \n                0                 0                 0                 0 \n     island_Dream  island_Torgersen        sex_female          sex_male \n                0                 0                 0                 0 \n\n\n         \n\n\nLösung\nDer Fehler liegt darin, dass das Rezept keine Änderungen an der AV ausführt. In der AV gibt es aber fehlende Werte (NA) im Test-Set.\n\ncolSums(is.na(d_test))\n\n         rownames           species            island    bill_length_mm \n                0                 0                 0                 1 \n    bill_depth_mm flipper_length_mm       body_mass_g               sex \n                1                 1                 1                 0 \n             year \n                0 \n\n\nEinen fehlenden Wert, um genau zu sein. Dieser eine fehlende Wert versalzt uns die Suppe:\n\nd_test_nona &lt;-\n  d_test |&gt; \n  na.omit()\n\nUnd schon geht’s.\n\npreds &lt;- predict(wf1_fit, new_data = d_test_nona) \npreds |&gt; \n  head()\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1 3952.\n2 3675.\n3 3615.\n4 3806.\n5 3490.\n6 3390.\n\n\nDieser SO-Post handelt von einem vergleichbarem Problem.\n\nCategories:\n\ntidymodels\nstatlearning\nerror\nNA\nstring"
  },
  {
    "objectID": "posts/tidymodels-ames-04/tidymodels-ames-04.html",
    "href": "posts/tidymodels-ames-04/tidymodels-ames-04.html",
    "title": "tidymodels-ames-04",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nVerwenden Sie die Funktion last_fit.\n\n         \n\n\nLösung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price)) %&gt;% \n  select(Sale_Price, Gr_Liv_Area)\n\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\n\nset.seed(42)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nRezept definieren:\n\nrec1 &lt;- \n  recipe(Sale_Price ~ Gr_Liv_Area, data = ames) \n\nVorhersagen mit last_fit:\n\nfit1_last &lt;- last_fit(object = m1, preprocessor = rec1, split = ames_split)  \nfit1_last\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits             id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [2342/588]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nWir bekommen ein Objekt, in dem Fit, Modellgüte, Vorhersagen und Hinweise enthalten sind.\nOhne Rezept lässt sich last_fit nicht anwenden.\nVorhersagen:\n\nfit1_last %&gt;% collect_predictions() %&gt;% \n  head()\n\n# A tibble: 6 × 5\n  id               .pred  .row Sale_Price .config             \n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;               \n1 train/test split  5.07     2       5.02 Preprocessor1_Model1\n2 train/test split  5.18     3       5.24 Preprocessor1_Model1\n3 train/test split  5.31    18       5.60 Preprocessor1_Model1\n4 train/test split  5.11    26       5.15 Preprocessor1_Model1\n5 train/test split  5.18    29       5.26 Preprocessor1_Model1\n6 train/test split  5.10    30       4.98 Preprocessor1_Model1\n\n\nModellgüte im Test-Sample:\n\nfit1_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.118 Preprocessor1_Model1\n2 rsq     standard       0.517 Preprocessor1_Model1\n\n\nR-Quadrat:\n\nsol &lt;- 0.517\nsol\n\n[1] 0.517\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-ames-02/tidymodels-ames-02.html",
    "href": "posts/tidymodels-ames-02/tidymodels-ames-02.html",
    "title": "tidymodels-ames-02",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price)) %&gt;% \n  select(Sale_Price, Gr_Liv_Area)\n\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\n\nset.seed(42)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nModell fitten:\n\nfit1 &lt;-\n  m1 %&gt;% \n  fit(Sale_Price ~ Gr_Liv_Area, data = ames)\n\n\nfit1 %&gt;% pluck(\"fit\") \n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nCoefficients:\n(Intercept)  Gr_Liv_Area  \n  4.8552133    0.0002437  \n\n\nModellgüte im Train-Sample:\n\nfit1_performance &lt;-\n  fit1 %&gt;% \n  extract_fit_engine()  # identisch zu pluck(\"fit\")\n\nModellgüte im Train-Sample:\n\nfit1_performance %&gt;% summary()\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.02587 -0.06577  0.01342  0.07202  0.39231 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.855e+00  7.355e-03  660.12   &lt;2e-16 ***\nGr_Liv_Area 2.437e-04  4.648e-06   52.43   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1271 on 2928 degrees of freedom\nMultiple R-squared:  0.4842,    Adjusted R-squared:  0.484 \nF-statistic:  2749 on 1 and 2928 DF,  p-value: &lt; 2.2e-16\n\n\nR-Quadrat via easystats:\n\nlibrary(easystats)\nfit1_performance %&gt;% r2()  # rmse()\n\n# R2 for Linear Regression\n       R2: 0.484\n  adj. R2: 0.484\n\n\n\ntidy(fit1_performance)  # ähnlich zu parameters()\n\n# A tibble: 2 × 5\n  term        estimate  std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 4.86     0.00736        660.        0\n2 Gr_Liv_Area 0.000244 0.00000465      52.4       0\n\n\nVorhersagen im Test-Sample:\n\npreds &lt;- predict(fit1, new_data = ames_test)  # liefert TABELLE (tibble) zurück\nhead(preds)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.18\n3  5.31\n4  5.11\n5  5.18\n6  5.10\n\n\npreds ist ein Tibble, also müssen wir noch die Spalte .pred. herausziehen, z.B. mit pluck(preds, \".pred\"):\n\npreds_vec &lt;- preds$.pred\n\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = pluck(preds, \".pred\"),  # pluck aus der Tabelle rausziehen\n         .pred = preds_vec)  # oder  mit dem Dollar-Operator\n\nhead(ames_test2)\n\n# A tibble: 6 × 4\n  Sale_Price Gr_Liv_Area preds .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       5.02         896  5.07  5.07\n2       5.24        1329  5.18  5.18\n3       5.60        1856  5.31  5.31\n4       5.15        1056  5.11  5.11\n5       5.26        1337  5.18  5.18\n6       4.98         987  5.10  5.10\n\n\nOder mit unnest:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = preds) %&gt;% \n  unnest(preds) # Listenspalte \"entschachteln\"\n\nhead(ames_test2)\n\n# A tibble: 6 × 3\n  Sale_Price Gr_Liv_Area .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt;\n1       5.02         896  5.07\n2       5.24        1329  5.18\n3       5.60        1856  5.31\n4       5.15        1056  5.11\n5       5.26        1337  5.18\n6       4.98         987  5.10\n\n\nOder wir binden einfach die Spalte an den Tibble:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  bind_cols(preds = preds)  # nimmt Tabelle und bindet die Spalten dieser Tabelle an eine Tabelle\n\nhead(ames_test2)\n\n# A tibble: 6 × 3\n  Sale_Price Gr_Liv_Area .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt;\n1       5.02         896  5.07\n2       5.24        1329  5.18\n3       5.60        1856  5.31\n4       5.15        1056  5.11\n5       5.26        1337  5.18\n6       4.98         987  5.10\n\n\nModellgüte im Test-Sample:\n\nrsq(ames_test2,\n    truth = Sale_Price,\n    estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.517\n\n\n\nsol &lt;- 0.51679\n\nZur Interpretation von Log10-Werten\n\n5e5\n\n[1] 5e+05\n\n5*10^5 - 500000\n\n[1] 0\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidydata1/tidydata1.html",
    "href": "posts/tidydata1/tidydata1.html",
    "title": "tidydata1",
    "section": "",
    "text": "Laden Sie die folgende Tabellen mit folgendem Befehl aus dem Paket tidyverse:\n\ntable1_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tidy-table1.csv\"\ntable1 &lt;- read_csv(table1_path)\n\nInsgesamt sollten Sie als folgende Tabellen in Ihrem environment verfügbar haben:\n\ntable1\ntable2\ntable3\ntable4\ntable5\n\nWelche der Tabellen ist in der Normalform?\n\n\n\ntable1\ntable2\ntable3\ntable4\ntable5"
  },
  {
    "objectID": "posts/tidydata1/tidydata1.html#answerlist",
    "href": "posts/tidydata1/tidydata1.html#answerlist",
    "title": "tidydata1",
    "section": "",
    "text": "table1\ntable2\ntable3\ntable4\ntable5"
  },
  {
    "objectID": "posts/tidydata1/tidydata1.html#answerlist-1",
    "href": "posts/tidydata1/tidydata1.html#answerlist-1",
    "title": "tidydata1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\ndatawrangling\ntidy\nschoice"
  },
  {
    "objectID": "posts/there-is-no-package/there-is-no-package.html",
    "href": "posts/there-is-no-package/there-is-no-package.html",
    "title": "there-is-no-package",
    "section": "",
    "text": "Sie führen folgende R-Syntax aus:\nlibrary(tidyverse)\nUnd bekommen als Antwort eine Fehlermeldung quittiert:\nthere is no package called 'tidyverse'.\nWas ist die Ursache bzw. zu tun?\n\n\n\nEs existiert kein Paket namens tidyverse.\nEs existiert kein Paket namens tidyverse auf Ihrem Rechner.\nDas Paket tidyverse ist nicht gestartet.\nDas Paket tidyverse ist kaputt.\nR ist in Sie verliebt und versucht auf ungelenke Weise Kontakt aufzunehmen."
  },
  {
    "objectID": "posts/there-is-no-package/there-is-no-package.html#answerlist",
    "href": "posts/there-is-no-package/there-is-no-package.html#answerlist",
    "title": "there-is-no-package",
    "section": "",
    "text": "Es existiert kein Paket namens tidyverse.\nEs existiert kein Paket namens tidyverse auf Ihrem Rechner.\nDas Paket tidyverse ist nicht gestartet.\nDas Paket tidyverse ist kaputt.\nR ist in Sie verliebt und versucht auf ungelenke Weise Kontakt aufzunehmen."
  },
  {
    "objectID": "posts/there-is-no-package/there-is-no-package.html#answerlist-1",
    "href": "posts/there-is-no-package/there-is-no-package.html#answerlist-1",
    "title": "there-is-no-package",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nR\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/Test-MSE1/Test-MSE1.html",
    "href": "posts/Test-MSE1/Test-MSE1.html",
    "title": "Test-MSE1",
    "section": "",
    "text": "Angenommen, Sie arbeiten als Analyst mit folgender Aufgabe:\nEs liegt ein Datensatz mit 600 Beschäftigten (als Beobachtungseinheit) vor. Für jede Person sind folgende Informationen bekannt: Dauer der Betriebszugehörigkeit, Alter, Ausbildung und Ergebnis der letzten Leistungsbeurteilung. Ziel ist es, die Höhe des zu erwartenden Gehalts vorherzusagen.\nWelche Aussage ist richtig?\n\n\n\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erklärung (inference). \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine unüberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Test-MSE1/Test-MSE1.html#answerlist",
    "href": "posts/Test-MSE1/Test-MSE1.html#answerlist",
    "title": "Test-MSE1",
    "section": "",
    "text": "Es handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erklärung (inference). \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine unüberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Test-MSE1/Test-MSE1.html#answerlist-1",
    "href": "posts/Test-MSE1/Test-MSE1.html#answerlist-1",
    "title": "Test-MSE1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/targets-multiple-data-files/targets-multiple-data-files.html",
    "href": "posts/targets-multiple-data-files/targets-multiple-data-files.html",
    "title": "targets-multiple-data-files",
    "section": "",
    "text": "Aufgabe\nSchreiben Sie eine targets Pipeline, die einen Ordner mit Datendateien beobachtet und sich aktualisiert, wenn neue Daten dazukommt. Die Pipeline soll die Datendateien importieren und zu einer Tabelle zusammenfügen und schließlich die Zeilen zählen.\n         \n\n\nLösung\nDie folgende Lösung ist stark inspiriert von diesem SO-Post.\nWir scheiben eine _targets.R Datei mit folgendem Inhalt.\nZuerst das Setup:\n\nlibrary(targets)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tarchetypes)  # für tar_files()\n\nDann definieren wir Konstanten; hier den Pfad:\n\npath &lt;- list()\npath$data &lt;- \"data/\"\n\nAus Gründen der Ordnungsfreude haben wir eine Liste erstellt, in der dann alle möglichen Pfade abgelegt werden können.\nSchließlich definieren wir die Pipeline. Hier spielt die Musik:\n\nlist(\n  tar_files(data_paths, path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\")),  # Liste der Daten-Dateien\n  tar_target(data_proc, data_paths %&gt;% read_csv(),  # Einlesen\n             pattern = map(data_paths)),  # Über alle Elemente von data_paths iterieren, also über alle Datendateien\n  tar_target(n_row, nrow(data_proc))  # Zeilen zählen\n)\n\n[[1]]\n[[1]]$data_paths_files\n&lt;tar_stem&gt; \n  name: data_paths_files \n  command:\n    path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\") \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: always\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[1]]$data_paths\n&lt;tar_pattern&gt; \n  name: data_paths \n  command:\n    data_paths_files \n  pattern:\n    map(data_paths_files) \n  format: file \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: main \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: thorough\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    character(0) \n  library:\n    NULL\n\n[[2]]\n&lt;tar_pattern&gt; \n  name: data_proc \n  command:\n    data_paths %&gt;% read_csv() \n  pattern:\n    map(data_paths) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: thorough\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[3]]\n&lt;tar_stem&gt; \n  name: n_row \n  command:\n    nrow(data_proc) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: thorough\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n\n\nMit pattern = map(data_paths) iterieren wir nicht nur über alle Elemente von data_path, sondern fügen die Elemente auch zu einer Tabelle zusammen.\nHier ist die ganze Syntax noch einmal:\n\n# _targets.R file\n\nlibrary(targets)\nlibrary(tidyverse)\nlibrary(tarchetypes)\n\n\npath &lt;- list()\npath$data &lt;- \"data/\"\n\n\nlist(\n  tar_files(data_paths, path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\")),\n  tar_target(data_proc, data_paths %&gt;% read_csv(),\n             pattern = map(data_paths)),\n  tar_target(n_row, nrow(data_proc))\n)\n\n[[1]]\n[[1]]$data_paths_files\n&lt;tar_stem&gt; \n  name: data_paths_files \n  command:\n    path$data %&gt;% list.files(full.names = TRUE, pattern = \"csv\") \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: always\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[1]]$data_paths\n&lt;tar_pattern&gt; \n  name: data_paths \n  command:\n    data_paths_files \n  pattern:\n    map(data_paths_files) \n  format: file \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: main \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: thorough\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    character(0) \n  library:\n    NULL\n\n[[2]]\n&lt;tar_pattern&gt; \n  name: data_proc \n  command:\n    data_paths %&gt;% read_csv() \n  pattern:\n    map(data_paths) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: thorough\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n[[3]]\n&lt;tar_stem&gt; \n  name: n_row \n  command:\n    nrow(data_proc) \n  format: rds \n  repository: local \n  iteration method: vector \n  error mode: stop \n  memory mode: persistent \n  storage mode: main \n  retrieval mode: main \n  deployment mode: worker \n  priority: 0 \n  resources:\n    list() \n  cue:\n    mode: thorough\n    command: TRUE\n    depend: TRUE\n    format: TRUE\n    repository: TRUE\n    iteration: TRUE\n    file: TRUE\n    seed: TRUE \n  packages:\n    tarchetypes\n    lubridate\n    forcats\n    stringr\n    dplyr\n    purrr\n    readr\n    tidyr\n    tibble\n    ggplot2\n    tidyverse\n    targets\n    stats\n    graphics\n    grDevices\n    utils\n    datasets\n    colorout\n    methods\n    base \n  library:\n    NULL\n\n\n\nCategories:\n\nprojectmgt\ntargets\nrepro\nstring"
  },
  {
    "objectID": "posts/supervisedlearning/supervisedlearning.html",
    "href": "posts/supervisedlearning/supervisedlearning.html",
    "title": "supervisedlearning",
    "section": "",
    "text": "Welches der folgenden Verfahren ist ein Vertreter des geleiteten Lernens (supervised learning)?\n\n\n\nClusteranalyse\nPCA\nAnalyse der Worthäufigkeit in Textmining-Analysen\nRandom Forest"
  },
  {
    "objectID": "posts/supervisedlearning/supervisedlearning.html#answerlist",
    "href": "posts/supervisedlearning/supervisedlearning.html#answerlist",
    "title": "supervisedlearning",
    "section": "",
    "text": "Clusteranalyse\nPCA\nAnalyse der Worthäufigkeit in Textmining-Analysen\nRandom Forest"
  },
  {
    "objectID": "posts/summarise05/summarise05.html",
    "href": "posts/summarise05/summarise05.html",
    "title": "summarise05",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, wie viele Lenkräder bei der Auktion dabei waren.\nFassen Sie die Spalte total_pr zusammen und zwar zur MAA und zum IQR - pro Gruppe!\n\nGeben Sie den erste Wert des IQR als Antwort zurück!\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nZusammenfassen:\n\nlibrary(DescTools)\nmariokart_gruppiert &lt;- group_by(mariokart, wheels)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, \n                             pr_iqr = IQR(total_pr),\n                             pr_maa = mean(abs(total_pr - mean(total_pr))),\n                             pr_maa2 = MeanAD(total_pr)\n                             )  # zusammenfassen\nmariokart_klein\n\n# A tibble: 5 × 4\n  wheels pr_iqr pr_maa pr_maa2\n   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1      0   7      7.05    7.05\n2      1   5.32   3.25    3.25\n3      2   7.18  11.9    11.9 \n4      3   5.25   5.25    5.25\n5      4   0      0       0   \n\n\nMöchte man den MAA nicht von Hand ausrechnen, so kann man die Funktion MeanAD aus dem Paket DescTools nutzen (Denken Sie daran, dass Sie das Paket einmalig installiert haben müssen.)\nDie Lösung lautet: 7.00\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nvariability\nnum"
  },
  {
    "objectID": "posts/summarise03/summarise03.html",
    "href": "posts/summarise03/summarise03.html",
    "title": "summarise03",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, wie viele Lenkräder bei der Auktion dabei waren.\nFassen Sie die Spalte total_pr zusammen und zwar zum Mittelwert - pro Gruppe!\nBerechnen Sie den Mittelwert dieser Zahlen!\n\nGeben Sie diese Zahl als Antwort zurück!\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nZusammenfassen:\n\nmariokart_gruppiert &lt;- group_by(mariokart, wheels)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, pr_mean = mean(total_pr))  # zusammenfassen\nmariokart_klein\n\n# A tibble: 5 × 2\n  wheels pr_mean\n   &lt;int&gt;   &lt;dbl&gt;\n1      0    41.1\n2      1    44.2\n3      2    61.0\n4      3    69.8\n5      4    65.0\n\n\n\nsummarise(mariokart_klein, pr_mean = mean(pr_mean))\n\n# A tibble: 1 × 1\n  pr_mean\n    &lt;dbl&gt;\n1    56.2\n\n\nmin analog.\nDie Lösung lautet: 56\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/summarise01/summarise01.html",
    "href": "posts/summarise01/summarise01.html",
    "title": "summarise01",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nFassen Sie die Spalte total_pr zusammen und zwar zum maximalwert!\nGeben Sie diese Zahl als Antwort zurück!\nHinweise:\n\nRunden Sie auf die nächste ganze Zahl.\nBeachten Sie die üblichen Hinweise des Datenwerks.\n\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nZusammenfassen:\n\nmariokart_klein &lt;- summarise(mariokart, max_preis = max(total_pr)) \nmariokart_klein\n\n  max_preis\n1    326.51\n\n\nmin analog.\nDie Lösung lautet: 327 Euro\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/Streuung-Histogramm/Streuung-Histogramm.html",
    "href": "posts/Streuung-Histogramm/Streuung-Histogramm.html",
    "title": "Streuung-Histogramm",
    "section": "",
    "text": "Wählen Sie das Diagramm, in dem der vertikale gestrichelte Linie am genauesten die Position des Medians (\\(Md\\)) widerspiegelt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist",
    "href": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist",
    "title": "Streuung-Histogramm",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist-1",
    "href": "posts/Streuung-Histogramm/Streuung-Histogramm.html#answerlist-1",
    "title": "Streuung-Histogramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\neda\nstreuungsmaß\nvariability\ndyn\nschoice"
  },
  {
    "objectID": "posts/Stichprobenziehen1/Stichprobenziehen1.html",
    "href": "posts/Stichprobenziehen1/Stichprobenziehen1.html",
    "title": "Stichprobenziehen1",
    "section": "",
    "text": "Exercise\nIn dieser Übung untersuchen wir den Effekt der Stichprobengröße auf die Genauigkeit der Schätzung. Und zwar auf praktische Art und Weise.\nAls praktisches Beispiel soll uns dabei die Körpergröße dienen. Wir erfragen die Körpergröße der Studis und betrachten den Mittelwert einer Stichrpobe in Abhängigkeit der Größe der Stichprobe.\n\nGeben Sie anonym Ihre Körpergröße hier ein.\nSie können die Daten hier beziehen.\nBerechnen Sie den Mittelwert der Körpergröße für eine zufällige Stichprobe der Größen \\(n=5\\) und \\(n=50\\)\nDann berechnen Sie die den “echten” Mittelwert der Studis; damit ist der Mittelwert aller Werte der Tabelle gemeint.\nDiskutieren Sie die Ergebnisse!\nWird die Schätzung genauer bei größerer Stichprobe?\nWird die Schätzung “robuster” (weniger schwankend) bei größerer Stichprobe?\n\n         \n\n\nSolution\nIndividuell\n\nCategories:\n\nlm\ninference\nqm2"
  },
  {
    "objectID": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html",
    "href": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html",
    "title": "stan_glm_prioriwerte",
    "section": "",
    "text": "Berechnet man eine Posteriori-Verteilung mit stan_glm(), so kann man entweder die schwach informativen Prioriwerte der Standardeinstellung verwenden, oder selber Prioriwerte definieren.\nBetrachten Sie dazu dieses Modell:\nstan_glm(price ~ cut, data = diamonds, \n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(10, 10, 10, 10)),\n                   prior_intercept = normal(3000, 500))\nBeziehen Sie sich auf den Datensatz diamonds.\nHinweise:\n\nGehen Sie davon aus, dass die Post-Verteilung von Intercept und Gruppeneffekte normalverteilt sind.\n\nWelche Aussage dazu passt (am besten)?\n\n\n\nEs wird für (genau) einen Parameter eine Priori-Verteilung definiert.\nFür das Regressionsgewicht \\(\\beta_1\\) sind negative Werte apriori plausibel.\nMit prior = normal() werden Gruppenmittelwerte definiert.\nAlle Parameter des Modells sind normalverteilt."
  },
  {
    "objectID": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist",
    "href": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist",
    "title": "stan_glm_prioriwerte",
    "section": "",
    "text": "Es wird für (genau) einen Parameter eine Priori-Verteilung definiert.\nFür das Regressionsgewicht \\(\\beta_1\\) sind negative Werte apriori plausibel.\nMit prior = normal() werden Gruppenmittelwerte definiert.\nAlle Parameter des Modells sind normalverteilt."
  },
  {
    "objectID": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist-1",
    "href": "posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html#answerlist-1",
    "title": "stan_glm_prioriwerte",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Es gibt mehrere Parameter im Modell (Achsenabschnitt, 4 Prädiktoren, sigma)\nWahr. Für cutGood sind negative Werte plausibel.\nFalsch. prior = normal() werden Regressionskoeffizienten in ihren Prioris definiert.\nFalsch. sigma ist in Stans Voreinstellung exponentialverteilt.\n\n\nCategories:\n\nbayes\nregression"
  },
  {
    "objectID": "posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html",
    "href": "posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html",
    "title": "stan_glm_parameterzahl",
    "section": "",
    "text": "Exercise\nBerechnet man eine Posteriori-Verteilung mit stan_glm(), so kann man entweder die schwach informativen Prioriwerte der Standardeinstellung verwenden, oder selber Prioriwerte definieren.\nBetrachten Sie dazu dieses Modell:\nstan_glm(price ~ cut, data = diamonds, \n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(100, 100, 100, 100)),\n                   prior_aux = exponential(1),\n                   prior_intercept = normal(3000, 500))\nWie viele Parameter gibt es in diesem Modell?\nHinweise:\n\nGeben Sie nur eine (ganze) Zahl ein.\n\n         \n\n\nSolution\nGrundsätzlich hat ein Regressionsmodell die folgenden Parameter:\n\neinen Parameter für den Intercept, \\(\\beta_0\\)\npro UV ein weiterer Parameter, \\(\\beta_1, \\beta_2, \\ldots\\)\nfür sigma (\\(\\sigma\\)) noch ein zusätzlicher Parameter\n\nZu beachten ist aber, dass bei einer nominalen Variablen mit zwei Stufen nur ein Regressionsgewicht (\\(\\beta_1\\)) berechnet wird. Allgemein gilt bei nominalen also, dass bei \\(k\\) Stufen nur \\(k-1\\) Regressionsgewichte berechnet werden.\nIm vorliegenden Fall hat die Variable cut 5 Stufen, also werden 4 Regressiongewiche berechnet.\nIn Summe werden also 6 Parameter berechnet.\nBerechnet man das Modell, so kann man sich auch Infos über die Prioris ausgeben lassen:\n\nm1 &lt;- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100)),\n               prior_intercept = normal(3000, 500),\n               prior_aux = exponential(1),\n               refresh = 0)\n\nprior_summary(m1)\n\nPriors for model 'm1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 3000, scale = 500)\n\nCoefficients\n ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nWie man sieht, wird für die Streuung im Standard eine Exponentialverteilung verwendet von stan_glm(). Gibt man also nicht an - wie im Beispiel m1 oben, so wird stan_glm() für die Streuung, d.h. prior_aux eine Exponentialverteilung verwenden. Zu beachten ist, dass stan_glm() ein automatische Skalierung vornimmt.\nS. hier für weitere Erläuterung.\nMöchte man den Prior für die Streuung direkt ansprechen, so kann man das so formulieren:\n\nm2 &lt;- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100)),\n               prior_intercept = normal(3000, 500),\n               prior_aux = exponential(1),\n               refresh = 0)\n\nprior_summary(m1)\n\nPriors for model 'm1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 3000, scale = 500)\n\nCoefficients\n ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nZu beachten ist beim selber definieren der Prioris, dass dann keine Auto-Skalierung von stan_glm() vorgenommen wird, es sei denn, man weist es explizit an:\n\nm3 &lt;- stan_glm(price ~ cut, data = diamonds, \n               prior = normal(location = c(100, 100, 100, 100),\n                              scale = c(100, 100, 100, 100),\n                              autoscale = TRUE),\n               prior_intercept = normal(3000, 500, autoscale = TRUE),\n               prior_aux = exponential(1, autoscale = TRUE),\n               chain = 1,  # nur 1 mal Stichproben ziehen, um Zeit zu sparen\n               refresh = 0)\n\nprior_summary(m3)\n\nPriors for model 'm3' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 3000, scale = 500)\n  Adjusted prior:\n    ~ normal(location = 3000, scale = 2e+06)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [100,100,100,...], scale = [100,100,100,...])\n  Adjusted prior:\n    ~ normal(location = [100,100,100,...], scale = [1129833.17, 868199.02, 936606.47,...])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.00025)\n------\nSee help('prior_summary.stanreg') for more details\n\n\nGrundsätzlich ist es nützlich für die numerische Stabilität, dass die Zahlen (hier die Parameterwerte) etwa die gleiche Größenordnung haben, am besten um die 0-1 herum. Daher bietet sich oft eine z-Standardisierung an.\nUnabhängig von der der Art der Parameter ist die Anzahl immer gleich.\nDie Anzahl der geschätzten Parameter werden im Modell-Summary unter Estimates gezeigt:\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      price ~ cut\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 53940\n predictors:   5\n\nEstimates:\n              mean   sd     10%    50%    90% \n(Intercept) 4027.0   22.1 3998.3 4026.8 4055.8\ncut.L       -248.8   52.7 -316.9 -249.5 -180.9\ncut.Q       -283.6   46.9 -342.3 -283.4 -223.2\ncut.C       -580.5   41.8 -633.6 -580.1 -527.2\ncut^4       -266.4   36.8 -314.6 -266.5 -218.6\nsigma       3830.6   11.1 3816.4 3830.4 3845.4\n\nFit Diagnostics:\n           mean   sd     10%    50%    90% \nmean_PPD 3931.9   23.1 3902.3 3931.8 3962.0\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.4  1.0  3025 \ncut.L         1.1  1.0  2393 \ncut.Q         1.0  1.0  2135 \ncut.C         0.8  1.0  2550 \ncut^4         0.7  1.0  3132 \nsigma         0.1  1.0  7241 \nmean_PPD      0.4  1.0  3673 \nlog-posterior 0.0  1.0  1883 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\n\nDas sind:\n\n1 Intercept (Achsenabschnitt) - prior_intercept\n4 Gruppen (zusätzlich zur Referenzgruppe, die mit dem Achsenabschnitt dargestellt ist) - prior_normal\n1 Sigma (Ungewissheit “innerhalb des Modells”) - prior_aux\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/smartphone1/index.html",
    "href": "posts/smartphone1/index.html",
    "title": "smartphone1",
    "section": "",
    "text": "In dieser Fallstudie analysieren Sie die Ergebnisse einer Umfrage zum Thema Smartphone-Nutzung. \nKernstück der Umfrage ist die Smartphone-Sucht-Skala (kwon_smartphone_2013?). Eine Studie fand, dass ca. ein Siebtel der Studierenden süchtig nach ihrem Smartphone sind (haug_smartphone_2015?); demnach könnte dem Thema eine hohe Bedeutsamkeit zukommen.\n\nImportieren Sie den Datensatz zur Handynutzung von Google-Docs.\nBenennen Sie die Spalten um und zwar nach folgendem Muster: itemXY, wobei XY die Nummer der Spalte ist. Sichern Sie die ursprünglichen Spaltennamen in einem Vektor. Tipp: Der Funktion names(meine_tabelle) können Sie einen Vektor mit neuen Spaltennamen übergeben.\nBerechnen Sie für die Items der Smartphone-Addiction-Scale den Mittelwert pro Person. Tipp: Erstellen Sie einen Dataframe mit den entsprechenden Items und nutzen Sie dann die Funktion rowMeans(mein_dataframe), um den Mittelwert über mehrere Spalten für jede Zeile zu berechnen (“Score”).\nVisualisieren Sie die Verteilung des Scores getrennt für die Geschlechter.\nNach einer Quelle (kwon_smartphone_2013?) liegt der Cutoff-Wert für Sucht bei 3.1 (Männer) bzw. 3.3 (Frauen). Bestimmen Sie den Anteil abhängiger Personen (pro Geschlecht).\nDas Item i13 ist ein Versuch, mit einem einzelnen Item zu messen, ob jemand süchtig nach seinem Smartphone ist (Item-Label: “Ich.würde.sagen..dass.ich.smartphone.süchtig.bin.”). Visualisieren Sie den Zusammenhang dieses Items mit dem Score.\nVisualsieren Sie den Anteil abhängiger Personen.\nBerechnen Sie, wie viel Geld für das zuletzt gekaufte Handy im Schnitt ausgegeben wurde. Gruppieren Sie dabei nach dem Betriebsystem.\nWer gibt mehr Geld für das Handy aus: Frauen oder Männer? Beantworten Sie die Frage anhand des Medians.\nVisualisieren Sie den Median des Geldausgebens für das Handy, getrennt nach Geschlechtern\n\n\n\n\n\n\n\nTip\n\n\n\nNutzen Sie ChatGPT oder einen anderen Bot, um sich Hilfe mit dem R-Code zu holen. \\(\\square\\)\n\n\n\n\n\n\n\n\nTip\n\n\n\nEs wird (fast) nie von Ihnen verlangt, dass Sie eine Aufgabe mit einem bestimmten R-Befehl lösen. Wenn Ihnen ein bestimmter R-Befehl nicht zusagt (oder Sie ihn nicht kennen oder verstehen) – dann nehmen Sie einfach einen anderen R-Befehl, der Ihnen mehr zusagt. \\(\\square\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeachten Sie die Hinweise des Datenwerks. \\(\\square\\)"
  },
  {
    "objectID": "posts/smartphone1/index.html#daten-importieren",
    "href": "posts/smartphone1/index.html#daten-importieren",
    "title": "smartphone1",
    "section": "2.1 Daten importieren",
    "text": "2.1 Daten importieren\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/Smartphone-Nutzung%20(Responses)%20-%20Form%20responses%201.csv\"\nsmartphone_raw &lt;- read.csv(data_path)\n\nDie Anzahl der Spalten einer Tabelle kann man sich übrigens z.B. mit ncol ausgeben lassen:\n\nanz_spalten &lt;- ncol(smartphone_raw)\nanz_spalten\n\n[1] 18\n\n\nUnsere Datentabelle hat also 18 Spalten."
  },
  {
    "objectID": "posts/smartphone1/index.html#spalten-umbenennen",
    "href": "posts/smartphone1/index.html#spalten-umbenennen",
    "title": "smartphone1",
    "section": "2.2 Spalten umbenennen",
    "text": "2.2 Spalten umbenennen\nZunächst sichern wir die alten Spaltennamen in einen Vektor:\n\nitem_labels_old &lt;- names(smartphone_raw)\nitem_labels_old\n\n [1] \"Timestamp\"                                                                                                        \n [2] \"Wann.haben.Sie.heute.zum.letzten.Mal.Ihr.Handy.benutzt..Bitte.geben.Sie.die.Uhrzeit.an.\"                          \n [3] \"Aufgrund.meiner.Smartphone.Nutzung.erledige.ich.geplante.Aufgaben.nicht.\"                                         \n [4] \"Aufgrund.meiner.Smartphone.Nutzung.fällt.es.mir.schwer..mich.in.der.Schule.oder.Arbeit.zu.konzentrieren.\"         \n [5] \"Bei.der.Nutzung.des.Smartphones.bekomme.ich.Schmerzen.in.Handgelenk.oder.Nacken.\"                                 \n [6] \"Ich.würde.es.nicht.aushalten..kein.Smartphone.zu.haben.\"                                                          \n [7] \"Wenn.ich.mein.Smartphone.nicht.in.der.Hand.habe..fühle.ich.mich.unruhig.und.gereizt.\"                             \n [8] \"Ich.denke.ständig.an.mein.Smartphone..auch.wenn.ich.es.nicht.benutze.\"                                            \n [9] \"Ich.werde.nie.aufhören..mein.Smartphone.zu.benutzen..selbst.wenn.mein.Alltag.bereits.stark.davon.beeinflusst.ist.\"\n[10] \"Ich.schaue.ständig.auf.mein.Smartphone..um.keine.Neuigkeiten.zu.verpassen.\"                                       \n[11] \"Ich.benutze.mein.Smartphone.länger.als.ich.es.vorhabe.\"                                                           \n[12] \"Die.Menschen.in.meinem.Umfeld.sagen.mir..dass.ich.mein.Smartphone.zu.häufig.nutze.\"                               \n[13] \"Ich.würde.sagen..dass.ich.smartphone.süchtig.bin.\"                                                                \n[14] \"Hier.ist.Platz.für.Ihre.Kommentare\"                                                                               \n[15] \"Bitte.geben.Sie.Ihr.Geschlecht.an.\"                                                                               \n[16] \"Bitte.geben.Sie.Ihr.Alter.an.\"                                                                                    \n[17] \"Bitte.geben.Sie.das.Betriebssystem.Ihres..am.meisten.genutzten..Handies.an.\"                                      \n[18] \"Wie.viel.Geld.haben.Sie.für.Ihr.zuletzt.gekauftes.Handy.gezahlt.\"                                                 \n\n\nVariablen aus psychologischen Fragebögen nennt man übrigens oft items.\nUnd dann nennen wir die Spaltennamen um. Das geht mit der Funktion names(smartphone_raw) &lt;-, der wir einen Vektor mit neuen Spaltennamen übergeben, z.B. so:\n\nitem_labels_new &lt;- c( \"item1\",  \"item2\", \"item3\", \"item4\",\n                      \"item5\", \"item6\",  \"item7\", \"item8\",\n                      \"item9\",  \"item10\", \"item11\", \"item12\",\n                      \"item13\", \"item14\", \"item15\", \"item16\",\n                      \"item17\", \"item18\")\n\nWichtig ist, dass ihr Vektor item_labels_new genau so viele Elemente hat, wie die Datentabelle Spalten hat.\nJetzt können Sie der Funktion names() den neuen Vektor item_labels_new zuweisen und haben damit die Spaltenanmen geändert:\n\nnames(smartphone_raw) &lt;- item_labels_new\n\nDen Vektor item_labels_new zu erstellen, war Ihnen zu viel Tipperei? Ja, mir auch. Schneller geht’s mit der Funktion paste0. Das erklärt sich am einfachsten mit einem Beispiel:\n\npaste0(\"item\", 1:3)\n\n[1] \"item1\" \"item2\" \"item3\"\n\n\nSehen Sie, was paste0 macht? Es fügt zwei Vektoreneinen Reißverschluss zusammen. Da item nur aus einem Element besteht, wird es item einfach auf die richtige Länge erhöht.\nDer Doppelpunkt in 1:3 bedeutet “von 1 bis 3”.\nAlso:\n\nnames(smartphone_raw) &lt;- paste0(\"item\",1:anz_spalten)\n\nSie möchten lieber zweistellige Nummern für die Spalten, also 01, 02, …, 09, 10, …? Gute Idee. Aber wie macht man das? Eine einfache Lösung: Fragen Sie ChatGPT!\n\n👩‍🎓: I want a string of the type “itemXY”, where XY is a number between 0 and 18. Make sure to use two digits. Use the R function paste0.\n\n\n🤖: 😸"
  },
  {
    "objectID": "posts/smartphone1/index.html#vertiefung-fingerabdruck-der-datentabelle",
    "href": "posts/smartphone1/index.html#vertiefung-fingerabdruck-der-datentabelle",
    "title": "smartphone1",
    "section": "2.3 Vertiefung: Fingerabdruck der Datentabelle",
    "text": "2.3 Vertiefung: Fingerabdruck der Datentabelle\nMit dem R-Paket visdat bekommt man einen “Fingerabdruck” der Datentabelle.\nAm einfachsten erklärt sich das an einem Beispiel. Schauen Sie sich das folgende Diagramm mal an. Es zeigt Ihnen den Datentyp pro Spalte und außerdem fehlende Werte.\n\nlibrary(visdat)\n\nvis_dat(smartphone_raw)\n\n\n\n\n\n\n\n\nDas ist deutlich übersichtlicher als eine Excel-Tabelle, wenn es darum geht, die Datenstruktur grob zu verstehen."
  },
  {
    "objectID": "posts/smartphone1/index.html#mittelwert-der-smartphone-addiction-scale",
    "href": "posts/smartphone1/index.html#mittelwert-der-smartphone-addiction-scale",
    "title": "smartphone1",
    "section": "2.4 Mittelwert der Smartphone-Addiction-Scale",
    "text": "2.4 Mittelwert der Smartphone-Addiction-Scale\n\nsmartphone_addiction_mittelwert &lt;- \nsmartphone_raw |&gt; \n  select(item3:item12) |&gt; \n  rowMeans()\n\nWir erhalten einen Vektor mit den Mittwerten (Score) pro Person für die Skala Smartphone-Abhängigkeit:\n\nhead(smartphone_addiction_mittelwert)\n\n[1] 3.0 3.8 2.7 3.2 4.2 3.3\n\n\nDiesen Vektor fügen wir dann unseren Daten hinzu. Außerdem benennen wir die Spalte item15 in sex um, damit wir uns merken können, in welcher Spalte das Geschlecht codiert ist.\n\nsmartphone &lt;-\n  smartphone_raw |&gt; \n  mutate(smartphone_addiction_mean = smartphone_addiction_mittelwert) |&gt; \n  rename(sex = item15) |&gt;   \n  filter(sex == \"Frau\" | sex == \"Mann\") \n\nMit rename(neuer_name = alter_name) können Sie die Namen von Spalten Ihrer Datentabelle ändern.\n\n🧑‍🎓 Also das mit rename hätte ich jetzt nicht gewusst.\n\n\n👩‍🏫 Dann frag mal ChatGPT.\n\n\n🤖 Ja, bitte!!\n\nAlternativ können Sie die folgende, etwas fortgeschrittenere Syntax nutzen:\n\nsmartphone2 &lt;- \nsmartphone_raw |&gt; \n  rowwise() |&gt; \n  mutate(smartphone_addiction_mean = mean(c_across(item3:item12)))"
  },
  {
    "objectID": "posts/smartphone1/index.html#score-visualisieren",
    "href": "posts/smartphone1/index.html#score-visualisieren",
    "title": "smartphone1",
    "section": "2.5 Score visualisieren",
    "text": "2.5 Score visualisieren\nLeider kann DataExplorer nicht mehrere Gruppen in einem Dichtediagramm anzeigen. Wir müssten also mit DataExplorer zwei Diagramme erstellen, eines für Frauen und eines für Männer. Eleganter geht es mit dem Paket ggpubr\n\nsmartphone |&gt; \n  ggdensity(x = \"smartphone_addiction_mean\", \n            color = \"sex\")"
  },
  {
    "objectID": "posts/smartphone1/index.html#anteil-smartphone-abhängigkeit",
    "href": "posts/smartphone1/index.html#anteil-smartphone-abhängigkeit",
    "title": "smartphone1",
    "section": "2.6 Anteil Smartphone-Abhängigkeit",
    "text": "2.6 Anteil Smartphone-Abhängigkeit\nMit case_when erstellen wir folgende Regel:\n\n“addicted”: wenn der Score &gt; 3.1 und das Geschlecht “Mann” ist bzw.\n“addicted”: wenn der Score &gt; 3.3 und das Geschlecht “Frau” ist bzw.\n“nicht addicted”: ansonsten\n\n\nsmartphone &lt;-\n  smartphone |&gt; \n  mutate(is_addicted =\n           case_when(smartphone_addiction_mean &gt; 3.1 & sex == \"Mann\" ~ \"addicted\",\n                     smartphone_addiction_mean &gt; 3.3 & sex == \"Frau\" ~ \"addicted\",\n                     TRUE ~ \"not-addicted\"))\n\nJetzt haben wir die Spalte is_addicted, die für jede Person (Zeile) angibt, ob die Person addicted ist. Nun zählen wir die Anzahl (n) aus, und zwar pro Geschlechtsgruppe. Weil es praktisch ist, rechen wir die Anzahl noch in einen Anteil (proportion) um.\n\nsmartphone_count &lt;- \nsmartphone |&gt; \n  group_by(sex) |&gt; \n  count(is_addicted) |&gt; \n  mutate(is_addicted_proportion = n / sum(n))\n\nsmartphone_count\n\n# A tibble: 4 × 4\n# Groups:   sex [2]\n  sex   is_addicted      n is_addicted_proportion\n  &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;                  &lt;dbl&gt;\n1 Frau  addicted        18                  0.462\n2 Frau  not-addicted    21                  0.538\n3 Mann  addicted         2                  0.333\n4 Mann  not-addicted     4                  0.667"
  },
  {
    "objectID": "posts/smartphone1/index.html#smartphone-sucht-mit-einzelnen-item-gemessen",
    "href": "posts/smartphone1/index.html#smartphone-sucht-mit-einzelnen-item-gemessen",
    "title": "smartphone1",
    "section": "2.7 Smartphone-Sucht, mit einzelnen Item gemessen",
    "text": "2.7 Smartphone-Sucht, mit einzelnen Item gemessen\n\nsmartphone |&gt; \n  select(smartphone_addiction_mean, item13) |&gt; \n  drop_na() |&gt; \n  plot_scatterplot(by = \"smartphone_addiction_mean\")\n\n\n\n\n\n\n\n\nEs scheint einen Zusammenhang zwischen item13 und smartphone_addiction_mean zu geben."
  },
  {
    "objectID": "posts/smartphone1/index.html#anteil-der-abhängigen-visualisieren",
    "href": "posts/smartphone1/index.html#anteil-der-abhängigen-visualisieren",
    "title": "smartphone1",
    "section": "2.8 Anteil der Abhängigen visualisieren",
    "text": "2.8 Anteil der Abhängigen visualisieren\nDer Anteil der abhängigen Personen ist in beiden Geschlechtern gleich hoch:\n\nsmartphone_count |&gt; \n  plot_bar(by = \"sex\")\n\n\n\n\n\n\n\n\nHier noch eine alternative Visualisierung mit dem Paket ggpubr:\n\nsmartphone_count |&gt; \n  ggbarplot(x = \"sex\", y = \"n\", fill = \"is_addicted\")"
  },
  {
    "objectID": "posts/smartphone1/index.html#kosten-nach-betriebssystem",
    "href": "posts/smartphone1/index.html#kosten-nach-betriebssystem",
    "title": "smartphone1",
    "section": "2.9 Kosten nach Betriebssystem",
    "text": "2.9 Kosten nach Betriebssystem\n\nsmartphone |&gt; \n  group_by(item17) |&gt; \n  summarise(price_mean = mean(item18, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  item17  price_mean\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Android       412 \n2 iOS           742."
  },
  {
    "objectID": "posts/smartphone1/index.html#kosten-nach-geschlecht",
    "href": "posts/smartphone1/index.html#kosten-nach-geschlecht",
    "title": "smartphone1",
    "section": "2.10 Kosten nach Geschlecht",
    "text": "2.10 Kosten nach Geschlecht\n\nsmartphone |&gt; \n  group_by(sex) |&gt; \n  summarise(price_median = median(item18, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  sex   price_median\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Frau           700\n2 Mann          1000\n\n\nMänner geben im Median 300 Euro mehr aus.\n\n\n\n\n\n\nTip\n\n\n\nWenn Sie nicht mehr wissen, was z.B. na.rm = TRUE bedeutet, dann einfach googeln oder einen ChatBot fragen. In der Regel ist die Frage dann in zwei Minuten beantwortet. \\(\\square\\)"
  },
  {
    "objectID": "posts/smartphone1/index.html#kosten-nach-geschlecht-visualisieren",
    "href": "posts/smartphone1/index.html#kosten-nach-geschlecht-visualisieren",
    "title": "smartphone1",
    "section": "2.11 Kosten nach Geschlecht visualisieren",
    "text": "2.11 Kosten nach Geschlecht visualisieren\n\nsmartphone |&gt; \n  select(sex, item18) |&gt; \n  plot_boxplot(by = \"sex\")\n\n\n\n\n\n\n\n\nWie man sieht ist der Median bei den Männern höher als bei den Frauen. Allerdings fällt der Median der Männer aus das dritte Quartil, was vermuten lässt, dass da irgendwas nicht stimmt. Schauen wir uns die Daten näher an:\n\nsmartphone |&gt; \n  filter(sex == \"Mann\")\n\n                item1    item2 item3 item4 item5 item6 item7 item8 item9 item10\n1 02/05/2024 16:29:51              4     4     3    NA     1    NA     1      4\n2 02/05/2024 16:30:37 16:20:00     2     5     2     4     3     3     3      3\n3 02/05/2024 16:30:42 16:20:00     1     2     2     4     1     1     6      5\n4 02/05/2024 16:30:48 16:30:00     5     5     2     6     2     2     5      4\n5 02/05/2024 16:30:58 16:00:00     4     2     3     5     2     2     3      4\n6 02/05/2024 16:31:28 16:28:00     6     6     1     6     3     2     6      3\n  item11 item12 item13 item14  sex item16  item17 item18\n1      4     NA      2        Mann     21 Android    400\n2      4      2      4        Mann     19     iOS   1000\n3      3      1      5        Mann     22     iOS   1200\n4      5      4      4        Mann     19 Android    300\n5      5      1      2        Mann     29     iOS   1000\n6      6      2      5        Mann     19     iOS   1000\n  smartphone_addiction_mean  is_addicted\n1                        NA not-addicted\n2                       3.1 not-addicted\n3                       2.6 not-addicted\n4                       4.0     addicted\n5                       3.1 not-addicted\n6                       4.1     addicted\n\n\nAh, es sind einfach sehr wenig Männer in diesem Datensatz enthalten."
  },
  {
    "objectID": "posts/Skalenniveau1b/Skalenniveau1b.html",
    "href": "posts/Skalenniveau1b/Skalenniveau1b.html",
    "title": "Skalenniveau1b",
    "section": "",
    "text": "Variable\n\n\n\n\nErgebnis bei Talent-Show (1. Platz Mr. Cool, 2. Platz Mr. Bright, 3. Platz Mr. Right)\n\n\nGewicht eines Tieres\n\n\nAugenfarbe\n\n\nAlter\n\n\n\n\n\n\n\n\nGeben Sie für jede der folgenden vier Variable an, ob sie über ein metrisches Skalenniveau verfügt!"
  },
  {
    "objectID": "posts/Skalenniveau1b/Skalenniveau1b.html#answerlist",
    "href": "posts/Skalenniveau1b/Skalenniveau1b.html#answerlist",
    "title": "Skalenniveau1b",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nRichtig\n\n\nCategories:\n\ndyn\nvariable-levels\nvariable-levels\nmchoice"
  },
  {
    "objectID": "posts/Sim-Prior/Sim-Prior.html",
    "href": "posts/Sim-Prior/Sim-Prior.html",
    "title": "Sim-Prior",
    "section": "",
    "text": "Exercise\nGegeben dem folgenden Modell, simulieren Sie Daten aus der Prior-Verteilung (Priori-Prädiktiv-Verteilung).\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior für \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(0, 1)\\)\nPrior für \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{U}(0, 10)\\)\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nn &lt;- 1e4\n\n\nsim &lt;- tibble(\n  mu = rnorm(n = n),  # Default-Werte sind mean=0, sd = 1\n  sigma = runif(n = n, 0, 10)) %&gt;%\n  mutate(\n    y = rnorm(n = n, mean = mu, sd = sigma))\n\nggplot(sim, aes(x = y)) +\n  geom_density() +\n  labs(x = \"y\", y = \"Dichte\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/sicherheit/sicherheit.html",
    "href": "posts/sicherheit/sicherheit.html",
    "title": "sicherheit",
    "section": "",
    "text": "Aufgabe\nEin Betreiber eines komplexen technischen Geräts versucht, Sie zu beruhigen. Die Wahrscheinlichkeit eines Ausfalls (Ereignis \\(A\\)) betrage nur 0.001. Allerdings pro Komponente des Geräts. Das Gerät besteht aus 10 Komponenten.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\nUnterstellen Sie Unabhängkeit der einzelnen Ereignisse.\n\n         \n\n\nLösung\nDen Ausfall der Komponente \\(i\\) bezeichnen wir als \\(A_i\\) und entsprechend \\(Pr(A_i) = 0.001\\).\n\\(Pr(\\neg A_i) = 1- Pr(A_i)\\)\n\nPr_Ai &lt;- 0.001\nPr_negAi &lt;- 1 - Pr_Ai\nPr_negAi\n\n[1] 0.999\n\n\nDie Wahrscheinlichkeit, dass keine der Komponenten ausfällt, ist dann über den Multiplikationssatzu bestimmen:\n\nPr_negA &lt;- Pr_negAi^10\nPr_negA\n\n[1] 0.9900449\n\n\nDie Lösung lautet 0.9900449.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/sentiws2/sentiws2.html",
    "href": "posts/sentiws2/sentiws2.html",
    "title": "sentiws2",
    "section": "",
    "text": "Aufgabe\nImportieren Sie das sentiws Lexikon:\nDie Spalte inflections birgt eine Reihe von Word-Varianten. Es scheint sinnvoll zu sein, diese Wörter zu nutzen. Aber um sie zu nutzen, muss man sie tokenisieren.\nAufgabe: Tokenisieren Sie die Tabelle sentiws, Spalte inflections.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\n\n\n# A tibble: 28,620 × 3\n   neg_pos word           value\n   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n 1 neg     abbaus       -0.058 \n 2 neg     abbaues      -0.058 \n 3 neg     abbauen      -0.058 \n 4 neg     abbaue       -0.058 \n 5 neg     abbruches    -0.0048\n 6 neg     abbrüche     -0.0048\n 7 neg     abbruchs     -0.0048\n 8 neg     abbrüchen    -0.0048\n 9 neg     abdankungen  -0.0048\n10 neg     abdämpfungen -0.0048\n# ℹ 28,610 more rows\n\n\nDas ging einfach!\nNur die NAs sollten wir vielleicht noch entfernen.\n\nCategories:\n\ntextmining\ntokenizer\nstring"
  },
  {
    "objectID": "posts/scikit-llm-zeroshot/scikit-llm-zeroshot.html",
    "href": "posts/scikit-llm-zeroshot/scikit-llm-zeroshot.html",
    "title": "Scikit-Learn-LLM Zero Shot Learners",
    "section": "",
    "text": "Aufgabe\nFragen Sie ChatGPT via Scikit-Learn-LLM zum Sentiment der ersten 7 Texte (=Tweets) aus dem Germeval-2018-Datensatz (Test). Nutzen Sie die gleiche Zahl an Tweets aus dem Train-Datensatz zum Finetuning Ihres Modells. Nutzen Sie den Endpoint ZeroShotGPTClassifier.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. 💸 Informieren Sie sich vorab. Um auf die API zugreifen zu können, müssen Sie sich ein Konto angelegt haben und über ein Guthaben verfügen. Werfen Sie hin und wieder einen Blick auf Ihr OpenAI-Guthaben-Konto.\n\n\n\n\n\n\n\nCaution\n\n\n\nAktuell sind scikit-llm und openai in den aktuellsten Versionen inkompatibel.\n\nERROR: pip’s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scikit-llm 0.4.2 requires openai&lt;1.0,&gt;=0.27.9, but you have openai 1.3.5 which is incompatible.\n\nDie einfachste Lösung ist, beide Pakete in verschiedenen venvs zu lagern. \\(\\square\\)\n\n\n\n\n\nsci-llm\n\n\n         \n\n\nLösung\nWir legen ggf. eine neue venv an:\n\nlibrary(reticulate)\n\n\n#virtualenv_create(\"scikit-llm\")\n\nUnd nutzen diese:\n\nuse_virtualenv(\"scikit-llm\")\n\nCheck:\n\npy_config()\n\npython:         /Users/sebastiansaueruser/.virtualenvs/scikit-llm/bin/python\nlibpython:      /Users/sebastiansaueruser/.pyenv/versions/3.11.1/lib/libpython3.11.dylib\npythonhome:     /Users/sebastiansaueruser/.virtualenvs/scikit-llm:/Users/sebastiansaueruser/.virtualenvs/scikit-llm\nversion:        3.11.1 (main, Oct  4 2023, 18:12:06) [Clang 15.0.0 (clang-1500.0.40.1)]\nnumpy:          /Users/sebastiansaueruser/.virtualenvs/scikit-llm/lib/python3.11/site-packages/numpy\nnumpy_version:  1.26.2\n\nNOTE: Python version was forced by use_python() function\n\n\n\npy_list_packages() |&gt; head()\n\n          package version            requirement\n1         absl-py   1.4.0         absl-py==1.4.0\n2         aiohttp   3.9.0         aiohttp==3.9.0\n3       aiosignal   1.3.1       aiosignal==1.3.1\n4 annotated-types   0.6.0 annotated-types==0.6.0\n5           anyio   3.7.1           anyio==3.7.1\n6    array-record   0.4.0    array-record==0.4.0\n\n\nGgf. müssen Sie zunächst die nötigen Module installieren, z.B. so: reticulate::py_install(\"scikit-llm\").\n\n#py_install(\"scikit-llm\")\n\nModule importieren:\n\nfrom skllm import ZeroShotGPTClassifier   \nfrom skllm.config import SKLLMConfig  # Anmeldung\nimport pandas as pd\nimport time \nimport os\n\nTrain-Daten importieren:\n\ncsv_file_path_train = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv'\ngermeval_train = pd.read_csv(csv_file_path_train)\n\nTest-Daten importieren:\n\ncsv_file_path_test = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv'\ngermeval_test = pd.read_csv(csv_file_path_test)\n\nDie ersten paar Texte aus dem Train-Datensatz herausziehen:\n\nn_tweets = 7\nX_train = germeval_train[\"text\"].head(n_tweets).tolist()\nX_train\n\n['@corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.', '@ahrens_theo fröhlicher gruß aus der schönsten stadt der welt theo ⚓️', '@dushanwegner Amis hätten alles und jeden gewählt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!', '@spdde kein verläßlicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgesprächen - schickt diese Stümper #SPD in die Versenkung.', '@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Geschützte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bemüht - übrigens leicht rückläufig gewesen.', '@milenahanm 33 bis 45 habe ich noch gar nicht gelebt und es geht mir am Arsch vorbei was in dieser Zeit geschehen ist. Ich lebe im heute und jetzt und nicht in der Vergangenheit.']\n\n\nUnd hier sind die Labels dazu:\n\ny_train = germeval_train[\"c1\"].head(n_tweets).tolist()\ny_train\n\n['OTHER', 'OTHER', 'OTHER', 'OTHER', 'OFFENSE', 'OTHER', 'OFFENSE']\n\n\nUnd analog für den Test-Datensatz:\n\nX_test = germeval_test[\"text\"].head(n_tweets).tolist()\n\nAnmelden bei OpenAI:\n\nOPENAI_SECRET_KEY = os.environ.get(\"OPENAI_API_KEY\")\nOPENAI_ORG_ID = os.environ.get(\"OPENAI_ORG_ID\")\n\nSKLLMConfig.set_openai_key(OPENAI_SECRET_KEY)\nSKLLMConfig.set_openai_org(OPENAI_ORG_ID)\n\nModel definieren:\n\nclf = ZeroShotGPTClassifier(openai_model=\"gpt-3.5-turbo\")\n\nModel fitten:\n\nclf.fit(X = X_train, y = y_train)  \n\nZeroShotGPTClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ZeroShotGPTClassifierZeroShotGPTClassifier()\n\n\nVorhersagen:\n\ny_pred = clf.predict(X = X_test)  \n\n  0%|          | 0/7 [00:00&lt;?, ?it/s]\n 14%|█▍        | 1/7 [00:38&lt;03:48, 38.03s/it]\n 29%|██▊       | 2/7 [00:48&lt;01:48, 21.62s/it]\n 43%|████▎     | 3/7 [01:16&lt;01:38, 24.65s/it]\n 57%|█████▋    | 4/7 [01:18&lt;00:47, 15.81s/it]\n 71%|███████▏  | 5/7 [01:28&lt;00:27, 13.69s/it]\n 86%|████████▌ | 6/7 [01:31&lt;00:09,  9.87s/it]\n100%|██████████| 7/7 [01:33&lt;00:00, 13.32s/it]\nVoilà:\n\nfor tweet, sentiment in zip(X_test, y_pred):\n    print(f\"Review: {tweet}\\nPredicted Sentiment: {sentiment}\\n\\n\")\n\nReview: Meine Mutter hat mir erzählt, dass mein Vater einen Wahlkreiskandidaten nicht gewählt hat, weil der gegen die Homo-Ehe ist ☺\nPredicted Sentiment: OFFENSE\n\n\nReview: @Tom174_ @davidbest95 Meine Reaktion; |LBR| Nicht jeder Moslem ist ein Terrorist. Aber jeder Moslem glaubt an Überlieferungen, die Gewalt und Terror begünstigen.\nPredicted Sentiment: OFFENSE\n\n\nReview: #Merkel rollt dem Emir von #Katar, der islamistischen Terror unterstützt, den roten Teppich aus.Wir brauchen einen sofortigen #Waffenstopp!\nPredicted Sentiment: OFFENSE\n\n\nReview: „Merle ist kein junges unschuldiges Mädchen“ Kch....... 😱 #tatort\nPredicted Sentiment: OFFENSE\n\n\nReview: @umweltundaktiv Asylantenflut bringt eben nur negatives für Deutschland. Drum Asylanenstop und Rückführung der Mehrzahl.\nPredicted Sentiment: OFFENSE\n\n\nReview: @_StultaMundi Die Bibel enthält ebenfalls Gesetze des Zivil- und Strafrechts.\nPredicted Sentiment: OTHER\n\n\nReview: @Thueringen_ @Miquwarchar @Pontifex_de Man munkelt, Franziskus ist großer \"Kiss\"- und \"Black Sabbath\"-Fan! #RockOn\nPredicted Sentiment: OTHER"
  },
  {
    "objectID": "posts/Schiefe-erkennen/Schiefe-erkennen.html",
    "href": "posts/Schiefe-erkennen/Schiefe-erkennen.html",
    "title": "Schiefe-erkennen",
    "section": "",
    "text": "Wählen Sie das Histogramm, welches am deutlichsten die Eigenschaft “rechtsschief” aufweist!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE"
  },
  {
    "objectID": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist",
    "href": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist",
    "title": "Schiefe-erkennen",
    "section": "",
    "text": "A\nB\nC\nD\nE"
  },
  {
    "objectID": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist-1",
    "href": "posts/Schiefe-erkennen/Schiefe-erkennen.html#answerlist-1",
    "title": "Schiefe-erkennen",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\neda\ndistributions\nschoice"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html",
    "href": "posts/saratoga-cor1/saratoga-cor1.html",
    "title": "saratoga-cor1",
    "section": "",
    "text": "Importieren Sie den Datensatz saratoga.\nGruppieren Sie den Datensatz in die Quartile für livingArea.\nBerechnen Sie dann den Zusammenhang zwischen price und bedrooms pro Quartil von livingArea.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nTipp: Die Funktion ntile aus {dplyr} teilt eine Variable var in Quartile auf, wenn Sie schreiben ntile(var, 4)."
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#setup",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#setup",
    "title": "saratoga-cor1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#gruppieren",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#gruppieren",
    "title": "saratoga-cor1",
    "section": "Gruppieren",
    "text": "Gruppieren\n\nd2 &lt;-\n  SaratogaHouses |&gt; \n  mutate(q = ntile(livingArea, 4)) |&gt; \n  group_by(q)"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#statistiken",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#statistiken",
    "title": "saratoga-cor1",
    "section": "Statistiken",
    "text": "Statistiken\n\nd2 |&gt; \n  summarise(korrelation = cor(bedrooms, price))\n\n# A tibble: 4 × 2\n      q korrelation\n  &lt;int&gt;       &lt;dbl&gt;\n1     1      0.126 \n2     2      0.0781\n3     3     -0.143 \n4     4     -0.0478"
  },
  {
    "objectID": "posts/saratoga-cor1/saratoga-cor1.html#visualisierung",
    "href": "posts/saratoga-cor1/saratoga-cor1.html#visualisierung",
    "title": "saratoga-cor1",
    "section": "Visualisierung",
    "text": "Visualisierung\n\nggscatter(d2, \n          x = \"bedrooms\",\n          y = \"price\",\n          facet.by = \"q\",\n          add = \"reg.line\")"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html",
    "href": "posts/saratoga-cor2/saratoga-cor2.html",
    "title": "saratoga-cor2",
    "section": "",
    "text": "Importieren Sie den Datensatz saratoga.\nBerechnen Sie dann den Zusammenhang zwischen price und livingArea pro Stufe von bedrooms.\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks."
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#setup",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#setup",
    "title": "saratoga-cor2",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#gruppieren",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#gruppieren",
    "title": "saratoga-cor2",
    "section": "Gruppieren",
    "text": "Gruppieren\n\nd2 &lt;-\n  SaratogaHouses |&gt; \n  group_by(bedrooms)"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#statistiken",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#statistiken",
    "title": "saratoga-cor2",
    "section": "Statistiken",
    "text": "Statistiken\n\nd2 |&gt; \n  summarise(korrelation = cor(livingArea, price))\n\n# A tibble: 7 × 2\n  bedrooms korrelation\n     &lt;int&gt;       &lt;dbl&gt;\n1        1       0.115\n2        2       0.510\n3        3       0.636\n4        4       0.687\n5        5       0.721\n6        6       0.882\n7        7       0.791"
  },
  {
    "objectID": "posts/saratoga-cor2/saratoga-cor2.html#visualisierung",
    "href": "posts/saratoga-cor2/saratoga-cor2.html#visualisierung",
    "title": "saratoga-cor2",
    "section": "Visualisierung",
    "text": "Visualisierung\n\nggscatter(d2, \n          x = \"livingArea\",\n          y = \"price\",\n          facet.by = \"bedrooms\",\n          add = \"reg.line\")"
  },
  {
    "objectID": "posts/Schiefe1/Schiefe1.html",
    "href": "posts/Schiefe1/Schiefe1.html",
    "title": "Schiefe1",
    "section": "",
    "text": "Welche der Abbildungen zeigt am deutlichsten eine rechtsschiefe Verteilung?\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/Schiefe1/Schiefe1.html#answerlist",
    "href": "posts/Schiefe1/Schiefe1.html#answerlist",
    "title": "Schiefe1",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/Schiefe1/Schiefe1.html#answerlist-1",
    "href": "posts/Schiefe1/Schiefe1.html#answerlist-1",
    "title": "Schiefe1",
    "section": "Answerlist",
    "text": "Answerlist\n\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/sd-vergleich/sd-vergleich.html",
    "href": "posts/sd-vergleich/sd-vergleich.html",
    "title": "sd-vergleich",
    "section": "",
    "text": "Welches der folgenden Diagramm hat die größte Streuung, gemessen in Standardabweichung (sd, sigma)?\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nalle gleich\nkeine Antwort möglich"
  },
  {
    "objectID": "posts/sd-vergleich/sd-vergleich.html#answerlist",
    "href": "posts/sd-vergleich/sd-vergleich.html#answerlist",
    "title": "sd-vergleich",
    "section": "",
    "text": "A\nB\nC\nalle gleich\nkeine Antwort möglich"
  },
  {
    "objectID": "posts/sd-vergleich/sd-vergleich.html#answerlist-1",
    "href": "posts/sd-vergleich/sd-vergleich.html#answerlist-1",
    "title": "sd-vergleich",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Dieses Diagramm hat die kleinste Streuung\nFalsch.\nWahr.\nFalsch. Die Streuungen sind unterschiedlich.\nFalsch.\n\n\nCategories:\n\ndatawrangling\neda\ntidyverse\nvis\nvariability\nschoice"
  },
  {
    "objectID": "posts/Shrinkage1/Shrinkage1.html",
    "href": "posts/Shrinkage1/Shrinkage1.html",
    "title": "Shrinkage1",
    "section": "",
    "text": "Shrinkage (Penalisierung) ist eine Erweiterung der klassischen Linearen Modelle. Welche Aussage dazu ist richtig?\n\n\n\nDie Modellkoeffizienten von penalisierten linearen Modelle können wie normale lineare Modelle interpretiert werden.\nDie L2-Norm der Penalisierung kann zur Auswahl von Prädiktoren herangezogen werden.\nDie L1-Norm der Penalisierung wird auch als Ridge-Regression bezeichnet.\nDie Ridge-Regression ist ein Algorithmus, der eine Größe minimiert, in der ein Strafterm zum üblichen Least-Square-Termin hinzuaddiert wird, wobei dieser Strafterm die (mit \\(\\lambda\\)) gewichtete Summe der Absolutwerte der \\(\\beta\\)-Koeffizienten beschreibt.\nDie Lasso-Regression liefert im Vergleich zur Ridge-Regression tendenziell bessere Ergebnisse, wenn das Kriterium eine Funktion von vielen Prädiktoren ist, deren Koeffizienten jeweils etwa gleich stark sind."
  },
  {
    "objectID": "posts/Shrinkage1/Shrinkage1.html#answerlist",
    "href": "posts/Shrinkage1/Shrinkage1.html#answerlist",
    "title": "Shrinkage1",
    "section": "",
    "text": "Die Modellkoeffizienten von penalisierten linearen Modelle können wie normale lineare Modelle interpretiert werden.\nDie L2-Norm der Penalisierung kann zur Auswahl von Prädiktoren herangezogen werden.\nDie L1-Norm der Penalisierung wird auch als Ridge-Regression bezeichnet.\nDie Ridge-Regression ist ein Algorithmus, der eine Größe minimiert, in der ein Strafterm zum üblichen Least-Square-Termin hinzuaddiert wird, wobei dieser Strafterm die (mit \\(\\lambda\\)) gewichtete Summe der Absolutwerte der \\(\\beta\\)-Koeffizienten beschreibt.\nDie Lasso-Regression liefert im Vergleich zur Ridge-Regression tendenziell bessere Ergebnisse, wenn das Kriterium eine Funktion von vielen Prädiktoren ist, deren Koeffizienten jeweils etwa gleich stark sind."
  },
  {
    "objectID": "posts/Shrinkage1/Shrinkage1.html#answerlist-1",
    "href": "posts/Shrinkage1/Shrinkage1.html#answerlist-1",
    "title": "Shrinkage1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/sicherheit2/sicherheit2.html",
    "href": "posts/sicherheit2/sicherheit2.html",
    "title": "sicherheit2",
    "section": "",
    "text": "Aufgabe\nEin Betreiber eines komplexen technischen Geräts versucht, Sie zu beruhigen. Die Wahrscheinlichkeit eines Ausfalls (Ereignis \\(A\\)) betrage nur 0.001. Allerdings pro Komponente des Geräts. Das Gerät besteht aus \\(k=10^3\\) Komponenten.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\nUnterstellen Sie Unabhängigkeit der Komponenten.\n\n         \n\n\nLösung\nDen Ausfall der Komponente \\(i\\) bezeichnen wir als \\(A_i\\) und entsprechend \\(Pr(A_i) = 0.001\\).\n\\(Pr(\\neg A_i) = 1- Pr(A_i)\\)\n\nPr_Ai &lt;- 0.001\nPr_negAi &lt;- 1 - Pr_Ai\nPr_negAi\n\n[1] 0.999\n\n\nDie Wahrscheinlichkeit, dass keine der Komponenten ausfällt, ist dann über den Multiplikationssatzu bestimmen:\n\nk &lt;- 10^3\nPr_negA &lt;- Pr_negAi^k\nPr_negA\n\n[1] 0.3676954\n\n\nDie Lösung lautet 0.3676954.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/Skalenniveau1a/Skalenniveau1a.html",
    "href": "posts/Skalenniveau1a/Skalenniveau1a.html",
    "title": "Skalenniveau1a",
    "section": "",
    "text": "Verfügt die Variable Alter über ein metrisches Skalenniveau?\n\n\n\nnein\nja"
  },
  {
    "objectID": "posts/Skalenniveau1a/Skalenniveau1a.html#answerlist",
    "href": "posts/Skalenniveau1a/Skalenniveau1a.html#answerlist",
    "title": "Skalenniveau1a",
    "section": "",
    "text": "nein\nja"
  },
  {
    "objectID": "posts/smape/smape.html",
    "href": "posts/smape/smape.html",
    "title": "smape",
    "section": "",
    "text": "Zur Bemessung der (prädiktiven) Güte eines Modells existieren verschiedene Kennzahlen, auch abhängig davon, ob es sich um eine Regression oder Klassifikation handelt. Eine Kennzahl heißt SMAPE (Symmetric Mean Absolute Percentage). Welche Aussage zu dieser Kennzahl ist falsch?\n\n\n\nDie SMAPE-Werte von Variablen verschiedener Skalierung sind kaum zu vergleichen.\nSMAPE hat einen Wertebereich von 0 bis 1, d.h. SMAPE \\(\\in [0,1]\\).\nGrößere Werte zeigen schlechtere Vorhersagegüte an.\nDer SMAPE kann nicht negativ werden."
  },
  {
    "objectID": "posts/smape/smape.html#answerlist",
    "href": "posts/smape/smape.html#answerlist",
    "title": "smape",
    "section": "",
    "text": "Die SMAPE-Werte von Variablen verschiedener Skalierung sind kaum zu vergleichen.\nSMAPE hat einen Wertebereich von 0 bis 1, d.h. SMAPE \\(\\in [0,1]\\).\nGrößere Werte zeigen schlechtere Vorhersagegüte an.\nDer SMAPE kann nicht negativ werden."
  },
  {
    "objectID": "posts/stan_glm01/stan_glm01.html",
    "href": "posts/stan_glm01/stan_glm01.html",
    "title": "stan_glm01",
    "section": "",
    "text": "Exercise\nGegeben dem folgenden Modell, geben Sie den Befehl mit stan_glm() an, um die Posteriori-Verteilung zu berechnen.\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior für \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(0, 1)\\) k\n         \n\n\nSolution\n\nlibrary(rstanarm)\n\n\nmodel &lt;-\n  stan_glm(h ~ 1,\n           prior_intercept = normal(0,1),\n           prior_aux = exponential(0.1),\n           daten = meine_Daten\n  )\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/stan_glm_parameterzahl_simple/stan_glm_parameterzahl_simple.html",
    "href": "posts/stan_glm_parameterzahl_simple/stan_glm_parameterzahl_simple.html",
    "title": "stan_glm_parameterzahl_simple",
    "section": "",
    "text": "Exercise\nBetrachten Sie dazu dieses Modell:\nstan_glm(price ~ cut, data = diamonds)\nWie viele Parameter gibt es in diesem Modell?\nHinweise:\n\nGeben Sie nur eine (ganze) Zahl ein.\n\n         \n\n\nSolution\nGrundsätzlich hat ein Regressionsmodell die folgenden Parameter:\n\neinen Parameter für den Intercept, \\(\\beta_0\\)\npro UV ein weiterer Parameter, \\(\\beta_1, \\beta_2, \\ldots\\)\nfür sigma (\\(\\sigma\\)) noch ein zusätzlicher Parameter\n\nZu beachten ist aber, dass bei einer nominalen Variablen mit zwei Stufen nur ein Regressionsgewicht (\\(\\beta_1\\)) berechnet wird. Allgemein gilt bei nominalen also, dass bei \\(k\\) Stufen nur \\(k-1\\) Regressionsgewichte berechnet werden.\nIm vorliegenden Fall hat die Variable cut 5 Stufen, also werden 4 Regressiongewiche berechnet.\nDie Anzahl der Parameter in diesem Modell ist also: 6"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html",
    "href": "posts/step-dummy/step-dummy.html",
    "title": "step-dummy",
    "section": "",
    "text": "Viele Lernalgorithmen können nicht mit nominalen Variablen umgehen; daher muss man sie dummifizieren, um sie einer Verarbeitung zugänglich zu machen. In Tidymodels gibt es dafür step_dummy().\nAber bezieht step_dummy() nur Variablen vom Typ factor ein oder auch Variablen vom Typ character? Oder vielleicht weder noch?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nNur Variablen vom Typ factor\nNur Variablen vom Typ character\nSowohl Variablen vom Typ factor als auch vom Typ character\nWeder Variablen vom Typ factor noch vom Typ character"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#answerlist",
    "href": "posts/step-dummy/step-dummy.html#answerlist",
    "title": "step-dummy",
    "section": "",
    "text": "Nur Variablen vom Typ factor\nNur Variablen vom Typ character\nSowohl Variablen vom Typ factor als auch vom Typ character\nWeder Variablen vom Typ factor noch vom Typ character"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#setup",
    "href": "posts/step-dummy/step-dummy.html#setup",
    "title": "step-dummy",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\nDaten:\n\nd &lt;-\n  data.frame(\n    y = c(1,2,3,4,5),\n    x = c(\"A\", \"B\", \"B\", \"C\", \"A\")\n  )\n\nstr(d)\n\n'data.frame':   5 obs. of  2 variables:\n $ y: num  1 2 3 4 5\n $ x: chr  \"A\" \"B\" \"B\" \"C\" ..."
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#rezept-1",
    "href": "posts/step-dummy/step-dummy.html#rezept-1",
    "title": "step-dummy",
    "section": "Rezept 1",
    "text": "Rezept 1\nRezept 1, mit Variable vom Typ character:\n\nrec &lt;-\n  recipe(y ~ x, data = d) %&gt;% \n  step_dummy(x)\n\nd_baked &lt;- rec %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nstr(d_baked)\n\ntibble [5 × 3] (S3: tbl_df/tbl/data.frame)\n $ y  : num [1:5] 1 2 3 4 5\n $ x_B: num [1:5] 0 1 1 0 0\n $ x_C: num [1:5] 0 0 0 1 0"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#rezept-2",
    "href": "posts/step-dummy/step-dummy.html#rezept-2",
    "title": "step-dummy",
    "section": "Rezept 2",
    "text": "Rezept 2\nRezept 2, mit Variable vom Typ factor:\nDaten:\n\nd2 &lt;-\n  data.frame(\n    y = c(1,2,3,4,5),\n    x = factor(c(\"A\", \"B\", \"B\", \"C\", \"A\"))\n  )\n\nstr(d2)\n\n'data.frame':   5 obs. of  2 variables:\n $ y: num  1 2 3 4 5\n $ x: Factor w/ 3 levels \"A\",\"B\",\"C\": 1 2 2 3 1\n\n\n\nrec2 &lt;-\n  recipe(y ~ x, data = d2) %&gt;% \n  step_dummy(x)\n\nd_baked2 &lt;- rec2 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nstr(d_baked2)\n\ntibble [5 × 3] (S3: tbl_df/tbl/data.frame)\n $ y  : num [1:5] 1 2 3 4 5\n $ x_B: num [1:5] 0 1 1 0 0\n $ x_C: num [1:5] 0 0 0 1 0"
  },
  {
    "objectID": "posts/step-dummy/step-dummy.html#answerlist-1",
    "href": "posts/step-dummy/step-dummy.html#answerlist-1",
    "title": "step-dummy",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr. step_dummy transformiert beide Arten von Variablen\nFalsch\n\n\nCategories:\n\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/Streudiagramm/Streudiagramm.html",
    "href": "posts/Streudiagramm/Streudiagramm.html",
    "title": "Streudiagramm",
    "section": "",
    "text": "-.90\n0\n+.90\n1\n-1"
  },
  {
    "objectID": "posts/Streudiagramm/Streudiagramm.html#answerlist",
    "href": "posts/Streudiagramm/Streudiagramm.html#answerlist",
    "title": "Streudiagramm",
    "section": "",
    "text": "-.90\n0\n+.90\n1\n-1"
  },
  {
    "objectID": "posts/Streudiagramm/Streudiagramm.html#answerlist-1",
    "href": "posts/Streudiagramm/Streudiagramm.html#answerlist-1",
    "title": "Streudiagramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nvis\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/subjektiv-Bayes/subjektiv-Bayes.html",
    "href": "posts/subjektiv-Bayes/subjektiv-Bayes.html",
    "title": "subjektiv-Bayes",
    "section": "",
    "text": "Exercise\nNennen Sie einen Aspekte der bayesianischen Analyse, der (in Teilen) subjektiv ist - abgesehen von der Wahl der Priori-Verteilung.\n         \n\n\nSolution\n\nLinearitätsannahme in (linearen) Modellen\nWahl des Likelihoods\nWahl der Daten\nMethoden der Modellprüfung\nGeneralisierung des Modells auf andere Situationen\nWahl der Prädiktoren\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/summarise02/summarise02.html",
    "href": "posts/summarise02/summarise02.html",
    "title": "summarise02",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, ob ein Foto bei der Auktion dabei war (stock_photo).\nFassen Sie die Spalte total_pr zusammen und zwar zum maximalwert - pro Gruppe!\nBerechnen Sie den Mittelwert dieser beiden Zahlen!\n\nGeben Sie diese Zahl als Antwort zurück!\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nZusammenfassen:\n\nmariokart_gruppiert &lt;- group_by(mariokart, stock_photo)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, max_preis = max(total_pr))  # zusammenfassen\nmariokart_klein\n\n# A tibble: 2 × 2\n  stock_photo max_preis\n  &lt;chr&gt;           &lt;dbl&gt;\n1 no               327.\n2 yes               75 \n\n\n\nsummarise(mariokart_klein, max_preis_mw = mean(max_preis))\n\n# A tibble: 1 × 1\n  max_preis_mw\n         &lt;dbl&gt;\n1         201.\n\n\nmin analog.\nDie Lösung lautet: 201\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nnum"
  },
  {
    "objectID": "posts/summarise04/summarise04.html",
    "href": "posts/summarise04/summarise04.html",
    "title": "summarise04",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\n\nGruppieren Sie danach, wie viele Lenkräder bei der Auktion dabei waren.\nFassen Sie die Spalte total_pr zusammen und zwar zur Standardabweichung (SD) - pro Gruppe!\n\nGeben Sie die erste Kennzahl als Antwort zurück!\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nZusammenfassen:\n\nmariokart_gruppiert &lt;- group_by(mariokart, wheels)  # Gruppieren\nmariokart_klein &lt;- summarise(mariokart_gruppiert, pr_sd = sd(total_pr))  # zusammenfassen\nmariokart_klein\n\n# A tibble: 5 × 2\n  wheels pr_sd\n   &lt;int&gt; &lt;dbl&gt;\n1      0 14.3 \n2      1  4.15\n3      2 38.3 \n4      3  7.42\n5      4 NA   \n\n\nDie Lösung lautet: 14.27\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nvariability\nnum"
  },
  {
    "objectID": "posts/summarise06/summarise06.html",
    "href": "posts/summarise06/summarise06.html",
    "title": "summarise06",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nFassen Sie die Spalte total_pr zusammen und zwar zu verschiedenene Maßen der Streuung (keine Gruppierung).\nWelchem Koeffizienten der Streuung schenken Sie am meisten Vertrauen in diesem Fall? Geben Sie den Wert als Antwort an.\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidyverse)  # startet das Paket tidyverse\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nZusammenfassen:\n\nlibrary(DescTools)\nmariokart_summarised &lt;- summarise(mariokart, \n                                  pr_sd = sd(total_pr),\n                                  pr_iqr = IQR(total_pr),\n                                  pr_maa = mean(abs(total_pr - mean(total_pr))),\n                                  pr_maa2 = MeanAD(total_pr)\n)  # zusammenfassen\nmariokart_summarised\n\n# A tibble: 1 × 4\n  pr_sd pr_iqr pr_maa pr_maa2\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1  25.7   12.8   10.0    10.0\n\n\nMöchte man den MAA nicht von Hand ausrechnen, so kann man die Funktion MeanAD aus dem Paket DescTools nutzen (Denken Sie daran, dass Sie das Paket einmalig installiert haben müssen.)\nDa es Extremwerte gibt in total_pr wird die SD besonders hoch sein. Der Grund ist, dass die SD eine Statistik ist, die auf einem Mittelwert beruht. Außerdem werden bei der Berechnung der SD die einzelnen Werte quadriert, was große Werte überproportional vergrößert. Aus diesem Grund könnte der IQR hier gegenüber anderen Maßen bevorzugt werden.\nLösung: 12.82\n\nCategories:\n\ndatawrangling\neda\ntidyverse\ndplyr\nvariability\nnum"
  },
  {
    "objectID": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html",
    "href": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html",
    "title": "Szenario-charakterisieren1",
    "section": "",
    "text": "Angenommen, Sie arbeiten als Analyst mit folgender Aufgabe:\nEs liegt ein Datensatz mit 600 Beschäftigten (als Beobachtungseinheit) vor. Für jede Person sind folgende Informationen bekannt: Dauer der Betriebszugehörigkeit, Alter, Ausbildung und Ergebnis der letzten Leistungsbeurteilung. Ziel ist es, die Höhe des zu erwartenden Gehalts vorherzusagen.\n\n\n\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erklärung (inference) \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine unüberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist",
    "href": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist",
    "title": "Szenario-charakterisieren1",
    "section": "",
    "text": "Es handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Erklärung (inference) \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=5\\).\nEs handelt sich um eine Klassifikation. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\).\nEs handelt sich um eine Regression. Ziel ist eine Vorhersage. \\(N=600\\), \\(p=4\\). Es handelt sich um eine unüberwachte (unsupervised) Analyse."
  },
  {
    "objectID": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist-1",
    "href": "posts/Szenario-charakterisieren1/Szenario-charakterisieren1.html#answerlist-1",
    "title": "Szenario-charakterisieren1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\nschoice"
  },
  {
    "objectID": "posts/Tengku-Hanis01/Tengku-Hanis01.html",
    "href": "posts/Tengku-Hanis01/Tengku-Hanis01.html",
    "title": "Tengku-Hanis01",
    "section": "",
    "text": "Aufgabe\nBearbeiten Sie diese Fallstudie von Tengku Hanis!\n         \n\n\nLösung\nDie folgende Lösung basiert auf der oben angegebenen Fallstudie.\nPakete laden:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.8     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(finetune)\n\nDaten importieren:\n\ndata(income, package = \"kernlab\")\n\nDatensatz vereinfachen:\n\nset.seed(2021)\nincome2 &lt;- \n  income %&gt;% \n  filter(INCOME == \"[75.000-\" | INCOME == \"[50.000-75.000)\") %&gt;% \n  slice_sample(n = 600) %&gt;% \n  mutate(INCOME = fct_drop(INCOME), \n         INCOME = fct_recode(INCOME, \n                             rich = \"[75.000-\",\n                             less_rich = \"[50.000-75.000)\"), \n         INCOME = factor(INCOME, ordered = F)) %&gt;% \n  mutate(across(-INCOME, fct_drop))\n\nCheck:\n\nDataExplorer::plot_missing(income)\n\n\n\n\n\n\n\n\n{DataExplorer} sieht nach einem nützlichen Paket aus. Check it out hier!\nDaten aufteilen (“Spending our data budget”):\n\nset.seed(2021)\ndat_index &lt;- initial_split(income2, strata = INCOME)\ndat_train &lt;- training(dat_index)\ndat_test &lt;- testing(dat_index)\n\nKreuzvalidierung:\n\nset.seed(2021)\ndat_cv &lt;- vfold_cv(dat_train, v = 10, repeats = 1, strata = INCOME)\n\nRezept:\n\ndat_rec &lt;- \n  recipe(INCOME ~ ., data = dat_train) %&gt;% \n  step_impute_mode(all_predictors()) %&gt;% \n  step_ordinalscore(AGE, EDUCATION, AREA, HOUSEHOLD.SIZE, UNDER18)\n\nAls Modell (im engeren Sinne) nutzen wir ein Random-Forest-Modell:\n\nrf_mod &lt;- \n  rand_forest(mtry = tune(),\n              trees = tune(),\n              min_n = tune()) %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"ranger\")\n\nWie man sieht, geben wir 3 Tuningparameter an.\nModell und Rezept zum Workflow zusammenfassen:\n\nrf_wf &lt;- \n  workflow() %&gt;% \n  add_recipe(dat_rec) %&gt;% \n  add_model(rf_mod)\n\nTuning Grids definieren:\nWichtig ist, dass wir genau die Parameter angeben im Grid, die wir auch zum Tunen getaggt haben. Das kann man händisch erledigen:\n\n# Regular grid:\nreg_grid &lt;- grid_regular(mtry(c(1, 13)), \n                         trees(), \n                         min_n(), \n                         levels = 3)\n\n# Random grid mit 100 Kandidaten:\nrand_grid &lt;- grid_random(mtry(c(1, 13)), \n                         trees(), \n                         min_n(), \n                         size = 100)\n\nWir speichern die Vorhersagen aller Folds im Train-Sample, um die Modellgüte im Train- bzw. Validierungssample anschauen zu können:\n\nctrl &lt;- control_grid(save_pred = T,\n                     extract = extract_model)\nmeasure &lt;- metric_set(roc_auc)\n\nAußerdem haben wir als Gütemaß roc_auc definiert.\nIn der Fallstudie wurde noch extract = extract_model bei control_grid() ergänzt. Das lassen wir der Einfachheit halber mal weg.\nParallelisieren auf mehreren Kernen, um Rechenzeit zu sparen:\n\nlibrary(doParallel)\n\nLoading required package: foreach\n\n\n\nAttaching package: 'foreach'\n\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\n# Create a cluster object and then register: \ncl &lt;- makePSOCKcluster(4)\nregisterDoParallel(cl)\n\nWie viele CPUs hat mein Computer?\n\ndetectCores(logical = FALSE)\n\n[1] 4\n\n\nJetzt geht’s ab: Tuning und Fitting!\nHier das “reguläre Gitter” an Tuningkandidaten:\n\nset.seed(2021)\ntune_regular &lt;- \n  rf_wf %&gt;% \n  tune_grid(\n    resamples = dat_cv, \n    grid = reg_grid,         \n    control = ctrl, \n    metrics = measure)\n\nstopCluster(cl)\n\nDie Modellgüte im Vergleich zwischen den Tuning-Kandidaten kann man sich schön ausgeben lassen:\n\nautoplot(tune_regular)\n\n\n\n\n\n\n\n\nGeht aber nur, wenn man oben gesagt hat, dass man die Predictions speichern möchte.\nWelche Kandidatin war am besten:\n\nshow_best(tune_regular)\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     7  2000     2 roc_auc binary     0.690    10  0.0178 Preprocessor1_Model08\n2     7  2000    40 roc_auc binary     0.689    10  0.0184 Preprocessor1_Model26\n3     7  1000     2 roc_auc binary     0.688    10  0.0162 Preprocessor1_Model05\n4    13  1000    21 roc_auc binary     0.687    10  0.0155 Preprocessor1_Model15\n5     7  2000    21 roc_auc binary     0.687    10  0.0161 Preprocessor1_Model17\n\n\nSo kann man sich die beste Kandidatin anschauen:\n\nshow_best(tune_regular) %&gt;% \n  arrange(-mean) %&gt;% \n  slice(1)\n\n# A tibble: 1 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     7  2000     2 roc_auc binary     0.690    10  0.0178 Preprocessor1_Model08\n\n\nAber man kann sich auch von Tidymodels einfach die beste Kandidatin sagen lassen:\n\nbest_rf &lt;-\n  select_best(tune_regular, \"roc_auc\")\n\nAuf dieser Basis können wir jetzt den Workflow finalisieren, also die Tuningparameter einfüllen:\n\nfinal_wf &lt;- \n  rf_wf %&gt;% \n  finalize_workflow(best_rf)\nfinal_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_mode()\n• step_ordinalscore()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 7\n  trees = 2000\n  min_n = 2\n\nComputational engine: ranger \n\n\nUnd mit diesen Werten den ganzen Train-Datensatz fitten:\n\ntest_fit &lt;- \n  final_wf %&gt;%\n  last_fit(dat_index) \n\nWie gut ist das jetzt?\n\ntest_fit %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.576 Preprocessor1_Model1\n2 roc_auc  binary         0.599 Preprocessor1_Model1\n\n\n\nCategories:\n\ntidymodels\nprediction\nyacsda\nstatlearning\ntrees\nspeed\nstring"
  },
  {
    "objectID": "posts/Test-MSE2/Test-MSE2.html",
    "href": "posts/Test-MSE2/Test-MSE2.html",
    "title": "Test-MSE2",
    "section": "",
    "text": "Anhand der folgenden Abbildung sollen Aussagen zur Test-MSE (Mean Squared Error) untersucht werden.\n\nIn der linken Teil-Abbildung zeigt die Gerade die wahre Funktion; die übrigen Kurven sind verschiedene geschätzte Funktionen. In der rechten Teil-Abbildungen sind verschiedene Fehlerarten der geschätzten Funktionen dargestellt (in Bezug zur linken Teil-Abbildung).\nWelche Aussage zur rechten Teil-Abbildung ist richtig?\n\n\n\nDie obere (konvexe, nach rechts ansteigende) Kurve zeigt den Test-Fehler.\nDie obere (konvexe, nach rechts ansteigende) Kurve zeigt den Train-Fehler.\nKurven, die den Testfehler in Abhängigkeit der Modellflexibilität zeigen, sind nicht U-förmig.\nKurven, die den Trainfehler in Abhängigkeit der Modellflexibilität zeigen, gehen nicht gegen Null.\nBei sehr hoher Modellflexibilität nähern sich die Kurven für Train- und Testfehler zunehmend an."
  },
  {
    "objectID": "posts/Test-MSE2/Test-MSE2.html#answerlist",
    "href": "posts/Test-MSE2/Test-MSE2.html#answerlist",
    "title": "Test-MSE2",
    "section": "",
    "text": "Die obere (konvexe, nach rechts ansteigende) Kurve zeigt den Test-Fehler.\nDie obere (konvexe, nach rechts ansteigende) Kurve zeigt den Train-Fehler.\nKurven, die den Testfehler in Abhängigkeit der Modellflexibilität zeigen, sind nicht U-förmig.\nKurven, die den Trainfehler in Abhängigkeit der Modellflexibilität zeigen, gehen nicht gegen Null.\nBei sehr hoher Modellflexibilität nähern sich die Kurven für Train- und Testfehler zunehmend an."
  },
  {
    "objectID": "posts/Test-MSE2/Test-MSE2.html#answerlist-1",
    "href": "posts/Test-MSE2/Test-MSE2.html#answerlist-1",
    "title": "Test-MSE2",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/tidy1/tidy1.html",
    "href": "posts/tidy1/tidy1.html",
    "title": "tidy1",
    "section": "",
    "text": "Das Konzept von “tidy” Daten (“Tidyformat”) spielt in der Datenanalyse eine wichtige Rolle.\nBetrachten Sie die Tabellen im Folgenden. Welche ist “tidy”?\nHinweise:\n\nAlle Variablen sollen nicht konstant sein, also mehr als einen uniquen Wert aufweisen.\nAlle Variablen sollen keine fehlenden Werte aufweisen, also komplett sein.\nAlle Variablen sollen numerisch sein.\n\nTabelle A:\n\n\n\n\n\n\n\n\n\nTabelle A\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1\n2\n\n\n2\n20\n2\n2\n\n\n1\n30\n3\n2\n\n\n2\n40\n4\n2\n\n\n\n\n\n\n\n\nTabelle B:\n\n\n\n\n\n\n\n\n\nTabelle B\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1\nA\n\n\n2\n20\n2\nB\n\n\n1\n30\n3\nC\n\n\n2\n40\n4\nD\n\n\n\n\n\n\n\n\nTabelle C:\n\n\n\n\n\n\n\n\n\nTabelle C\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1\nid2\n\n\n2\n20\n2\nid2\n\n\n1\n30\n3\n1,2\n\n\n2\n40\n4\nid2\n\n\n\n\n\n\n\n\nTabelle D:\n\n\n\n\n\n\n\n\n\nTabelle D\n\n\ngroup\ny\nid1\nid2\n\n\n\n\n1\n10\n1\n1\n\n\n2\n20\n2\n1\n\n\n1\n30\n3\n2\n\n\n2\n40\n4\n2\n\n\n\n\n\n\n\n\nTabelle E:\n\n\n\n\n\n\n\n\n\nTabelle E\n\n\ngroup\n\ny\nid1\nid2\n\n\n\n\n1\nNA\n10\n1\n1\n\n\n2\nNA\n20\n2\n1\n\n\n1\nNA\n30\n3\n2\n\n\n2\nNA\n40\n4\n2\n\n\n\n\n\n\n\n\n\n\n\nTabelle A\nTabelle B\nTabelle C\nTabelle D\nTabelle E"
  },
  {
    "objectID": "posts/tidy1/tidy1.html#answerlist",
    "href": "posts/tidy1/tidy1.html#answerlist",
    "title": "tidy1",
    "section": "",
    "text": "Tabelle A\nTabelle B\nTabelle C\nTabelle D\nTabelle E"
  },
  {
    "objectID": "posts/tidy1/tidy1.html#answerlist-1",
    "href": "posts/tidy1/tidy1.html#answerlist-1",
    "title": "tidy1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Eine Spalte soll nicht aus einem uniquen Wert bestehen.\nFalsch. Alle Werte sollen numerisch sein\nFalsch. Die Spalte id2weißt einen nicht erlaubten Wert auf.\nRichtig. Das ist ein ‘tidy Tibble’.\nFalsch. In einem Tidy-Tibble darf keine leere Spalte vorkommen.\n\n\nCategories:\n\ntidy\ndatawrangling\nschoice"
  },
  {
    "objectID": "posts/tidymodels-ames-01/tidymodels-ames-01.html",
    "href": "posts/tidymodels-ames-01/tidymodels-ames-01.html",
    "title": "tidymodels-ames-01",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nGesucht ist R-Quadrat als Maß für die Modellgüte im Train-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price))\n\nDatensatz aufteilen:\n\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nModell fitten:\n\nfit1 &lt;-\n  m1 %&gt;% \n  fit(Sale_Price ~ Gr_Liv_Area, data = ames)\n\n\nfit1 %&gt;% pluck(\"fit\") \n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nCoefficients:\n(Intercept)  Gr_Liv_Area  \n  4.8552133    0.0002437  \n\n\nModellgüte im Train-Sample:\n\nfit1_performance &lt;-\n  fit1 %&gt;% \n  extract_fit_engine()  # identisch zu pluck(\"fit\")\n\nModellgüte:\n\nfit1_performance %&gt;% summary()\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.02587 -0.06577  0.01342  0.07202  0.39231 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.855e+00  7.355e-03  660.12   &lt;2e-16 ***\nGr_Liv_Area 2.437e-04  4.648e-06   52.43   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1271 on 2928 degrees of freedom\nMultiple R-squared:  0.4842,    Adjusted R-squared:  0.484 \nF-statistic:  2749 on 1 and 2928 DF,  p-value: &lt; 2.2e-16\n\n\nR-Quadrat via easystats:\n\nlibrary(easystats)\nfit1_performance %&gt;% r2()  # rmse()\n\n# R2 for Linear Regression\n       R2: 0.484\n  adj. R2: 0.484\n\n\n\ntidy(fit1_performance)  # ähnlich zu parameters()\n\n# A tibble: 2 × 5\n  term        estimate  std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 4.86     0.00736        660.        0\n2 Gr_Liv_Area 0.000244 0.00000465      52.4       0\n\n\n\nsol &lt;- 0.484\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-ames-03/tidymodels-ames-03.html",
    "href": "posts/tidymodels-ames-03/tidymodels-ames-03.html",
    "title": "tidymodels-ames-03",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nRücktransformieren Sie die Log-Werte in “Roh-Dollar”.\nGeben Sie den mittleren Vorhersagewert an als Lösung.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\nlibrary(tidymodels)\ndata(ames)\n\nMultiplikatives Modell:\n\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price)) %&gt;% \n  select(Sale_Price, Gr_Liv_Area)\n\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\n\nset.seed(42)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\nModell definieren:\n\nm1 &lt;-\n  linear_reg() # engine ist \"lm\" im Default\n\nModell fitten:\n\nfit1 &lt;-\n  m1 %&gt;% \n  fit(Sale_Price ~ Gr_Liv_Area, data = ames)\n\n\nfit1 %&gt;% pluck(\"fit\") \n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nCoefficients:\n(Intercept)  Gr_Liv_Area  \n  4.8552133    0.0002437  \n\n\nModellgüte im Train-Sample:\n\nfit1_performance &lt;-\n  fit1 %&gt;% \n  extract_fit_engine()  # identisch zu pluck(\"fit\")\n\nModellgüte im Train-Sample:\n\nfit1_performance %&gt;% summary()\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.02587 -0.06577  0.01342  0.07202  0.39231 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.855e+00  7.355e-03  660.12   &lt;2e-16 ***\nGr_Liv_Area 2.437e-04  4.648e-06   52.43   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1271 on 2928 degrees of freedom\nMultiple R-squared:  0.4842,    Adjusted R-squared:  0.484 \nF-statistic:  2749 on 1 and 2928 DF,  p-value: &lt; 2.2e-16\n\n\nR-Quadrat via easystats:\n\nlibrary(easystats)\nfit1_performance %&gt;% r2()  # rmse()\n\n# R2 for Linear Regression\n       R2: 0.484\n  adj. R2: 0.484\n\n\n\ntidy(fit1_performance)  # ähnlich zu parameters()\n\n# A tibble: 2 × 5\n  term        estimate  std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 4.86     0.00736        660.        0\n2 Gr_Liv_Area 0.000244 0.00000465      52.4       0\n\n\nVorhersagen im Test-Sample:\n\npreds &lt;- predict(fit1, new_data = ames_test)  # liefert TABELLE (tibble) zurück\nhead(preds)\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.18\n3  5.31\n4  5.11\n5  5.18\n6  5.10\n\n\npreds ist ein Tibble, also müssen wir noch die Spalte .pred. herausziehen, z.B. mit pluck(preds, \".pred\"):\n\npreds_vec &lt;- preds$.pred\n\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = pluck(preds, \".pred\"),  # pluck aus der Tabelle rausziehen\n         .pred = preds_vec)  # oder  mit dem Dollar-Operator\n\nhead(ames_test2)\n\n# A tibble: 6 × 4\n  Sale_Price Gr_Liv_Area preds .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       5.02         896  5.07  5.07\n2       5.24        1329  5.18  5.18\n3       5.60        1856  5.31  5.31\n4       5.15        1056  5.11  5.11\n5       5.26        1337  5.18  5.18\n6       4.98         987  5.10  5.10\n\n\nOder mit unnest:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  mutate(preds = preds) %&gt;% \n  unnest(preds) # Listenspalte \"entschachteln\"\n\nhead(ames_test2)\n\n# A tibble: 6 × 3\n  Sale_Price Gr_Liv_Area .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt;\n1       5.02         896  5.07\n2       5.24        1329  5.18\n3       5.60        1856  5.31\n4       5.15        1056  5.11\n5       5.26        1337  5.18\n6       4.98         987  5.10\n\n\nOder wir binden einfach die Spalte an den Tibble:\n\names_test2 &lt;-\n  ames_test %&gt;% \n  bind_cols(preds = preds)  # nimmt Tabelle und bindet die Spalten dieser Tabelle an eine Tabelle\n\nhead(ames_test2)\n\n# A tibble: 6 × 3\n  Sale_Price Gr_Liv_Area .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt;\n1       5.02         896  5.07\n2       5.24        1329  5.18\n3       5.60        1856  5.31\n4       5.15        1056  5.11\n5       5.26        1337  5.18\n6       4.98         987  5.10\n\n\nModellgüte im Test-Sample:\n\nrsq(ames_test2,\n    truth = Sale_Price,\n    estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.517\n\n\n\nsol &lt;- 0.51679\n\nZur Interpretation von Log10-Werten\n\n5e5\n\n[1] 5e+05\n\n5*10^5 - 500000\n\n[1] 0\n\n\nRücktransformation (ohne Bias-Korrektur):\n\names_test2 &lt;-\n  ames_test2 %&gt;% \n  mutate(pred_raw = 10^(.pred))\n\nMittelwert der Vorhersagen:\n\nsol &lt;- mean(ames_test2$pred_raw)\nsol\n\n[1] 175973.8\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-ames-05/tidymodels-ames-05.html",
    "href": "posts/tidymodels-ames-05/tidymodels-ames-05.html",
    "title": "tidymodels-ames-05",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein knn-Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: log(Sale_Price) ~ ., data = ames_train.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nDenken Sie daran, die nominal skalierten Variablen in Dummy-Variablen umzurechnen.\nDenken Sie daran, dass kNN gleich skalierte Prädiktoren benötigt.\nNutzen Sie eine v=10,r=1 CV.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\ndata(ames)\n\nAV loggen:\n\names &lt;-\n  ames %&gt;% \n  mutate(Sale_Price = log(Sale_Price, base = 10))\n\nDatensatz aufteilen:\n\nset.seed(42)\ndata_split &lt;- initial_split(ames, strata = \"Sale_Price\")\names_train &lt;- training(data_split)\names_test &lt;- testing(data_split)\n\nWorkflow:\n\names_rec &lt;-\n  recipe(Sale_Price ~ ., data = ames_train) %&gt;%\n  # step_log(Sale_Price, base = 10) %&gt;%   No!\n  step_other(Neighborhood, threshold = .1)  %&gt;%\n  step_dummy(all_nominal()) %&gt;%\n  step_zv(all_predictors()) \n\nknn_model2 &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()  # Wir tunen \"neighbors\"\n  ) \n\names_wflow2 &lt;-\n  workflow() %&gt;%\n  add_recipe(ames_rec) %&gt;%\n  add_model(knn_model2)\n\names_wflow2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_other()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nK-Nearest Neighbor Model Specification (regression)\n\nMain Arguments:\n  neighbors = tune()\n\nComputational engine: kknn \n\n\nCV:\n\nset.seed(42)\names_folds &lt;- vfold_cv(ames_train, strata = \"Sale_Price\", v = 2)\names_folds\n\n#  2-fold cross-validation using stratification \n# A tibble: 2 × 2\n  splits              id   \n  &lt;list&gt;              &lt;chr&gt;\n1 &lt;split [1098/1099]&gt; Fold1\n2 &lt;split [1099/1098]&gt; Fold2\n\n\nTunen:\n\ntic()\names_grid_search &lt;-\n  tune_grid(\n    knn_model2,\n    ames_rec,\n    resamples = ames_folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = 2,  # 2 Tuningparameterwerte, hier nur zum Zeit sparen\n  )\ntoc()\n\n5.253 sec elapsed\n\names_grid_search\n\n# Tuning results\n# 2-fold cross-validation using stratification \n# A tibble: 2 × 4\n  splits              id    .metrics         .notes          \n  &lt;list&gt;              &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [1098/1099]&gt; Fold1 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [1099/1098]&gt; Fold2 &lt;tibble [4 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nModellgüte im Train-Samples über die Tuningparameter hinweg:\n\nautoplot(ames_grid_search)\n\n\n\n\n\n\n\n\nFitte besten Modellkandidaten (Paket tune &gt;= V1.1.0 benötigt):\n\nfit1_final &lt;- fit_best(ames_grid_search)\n\nVorhersagen:\n\npreds &lt;-\n  predict(fit1_final, ames_test)\n\nModellgüte im Test-Sample:\n\nfit1_metrics &lt;-\n  preds %&gt;% \n  bind_cols(ames_test %&gt;% select(Sale_Price)) %&gt;% \n  rsq(truth = Sale_Price, estimate = .pred)\n\nfit1_metrics\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.739\n\n\nR-Quadrat:\n\nsol &lt;- fit1_metrics %&gt;% pull(.estimate)\nsol\n\n[1] 0.739015\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-lasso/tidymodels-lasso.html",
    "href": "posts/tidymodels-lasso/tidymodels-lasso.html",
    "title": "tidymodels-lasso",
    "section": "",
    "text": "Aufgabe\n\nSchreiben Sie eine prototypische Analyse für ein Vorhersagemodell mit dem Lasso.\nHinweise:\n\nTunen Sie die Penalisierung.\nVerwenden Sie Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ .\n\n         \n\n\nLösung\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n15.016 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\n# A tibble: 5 × 7\n   penalty .metric .estimator  mean     n std_err .config              \n     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1 1.97e-10 rmse    standard    281.    10    12.0 Preprocessor1_Model01\n2 4.54e- 9 rmse    standard    281.    10    12.0 Preprocessor1_Model02\n3 8.93e- 8 rmse    standard    281.    10    12.0 Preprocessor1_Model03\n4 1.75e- 7 rmse    standard    281.    10    12.0 Preprocessor1_Model04\n5 1.65e- 6 rmse    standard    281.    10    12.0 Preprocessor1_Model05\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     326.    Preprocessor1_Model1\n2 rsq     standard       0.819 Preprocessor1_Model1\n\n\nMan beachte: Für regulierte Modelle sind Zentrierung und Skalierung nötig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nstring\ntemplate"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html",
    "title": "tidymodels-lasso3",
    "section": "",
    "text": "Schreiben Sie eine prototypische Analyse für ein Vorhersagemodell mit dem Lasso.\nBerichten Sie, welche Prädiktoren nach dem Lasso im Modell verbleiben.\nHinweise:\n\nTunen Sie die Penalisierung.\nVerwenden Sie Kreuzvalidierung.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\nVerwenden Sie den Datensatz penguins.\nModellformel: body_mass_g ~ ."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#standardvorgehen",
    "title": "tidymodels-lasso3",
    "section": "Standardvorgehen",
    "text": "Standardvorgehen\n\n# 2023-05-14\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variablenbedeutung\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\n# drop rows with NA in outcome variable:\nd &lt;-\n  d %&gt;% \n  drop_na(body_mass_g)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod_lasso &lt;-\n  linear_reg(mode = \"regression\",\n             penalty = tune(),\n             mixture = 1,\n             engine = \"glmnet\")\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1_plain &lt;- \n  recipe(body_mass_g ~  ., data = d_train) %&gt;% \n  update_role(\"rownames\", new_role = \"id\") %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_bag(all_predictors())\n\n\n# check:\nd_train_baked &lt;- \n  prep(rec1_plain) %&gt;% bake(new_data = NULL)\n\nna_n &lt;- sum(is.na(d_train_baked))\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod_lasso) %&gt;% \n  add_recipe(rec1_plain)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n11.456 sec elapsed\n\n# best candidate:\nshow_best(wf1_fit)\n\n# A tibble: 5 × 7\n   penalty .metric .estimator  mean     n std_err .config              \n     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1 1.97e-10 rmse    standard    281.    10    12.0 Preprocessor1_Model01\n2 4.54e- 9 rmse    standard    281.    10    12.0 Preprocessor1_Model02\n3 8.93e- 8 rmse    standard    281.    10    12.0 Preprocessor1_Model03\n4 1.75e- 7 rmse    standard    281.    10    12.0 Preprocessor1_Model04\n5 1.65e- 6 rmse    standard    281.    10    12.0 Preprocessor1_Model05\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     326.    Preprocessor1_Model1\n2 rsq     standard       0.819 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#inspektion-der-tuningparameter",
    "title": "tidymodels-lasso3",
    "section": "Inspektion der Tuningparameter",
    "text": "Inspektion der Tuningparameter\n\nautoplot(wf1_fit)\n\n\n\n\n\n\n\n\nDie Standard-Wahl der Tuningparameter-Werte war offenbar nicht so ideal, zumindest sieht man kaum Unterschiede zwischen der Modellgüte in Abhängigkeit von den Werten der Tuningparameter."
  },
  {
    "objectID": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "href": "posts/tidymodels-lasso3/tidymodels-lasso3.html#variablenbedeutung",
    "title": "tidymodels-lasso3",
    "section": "Variablenbedeutung",
    "text": "Variablenbedeutung\n\nlibrary(vip)\n\nvi_preds &lt;- \nwf1_fit_final %&gt;% \n  extract_fit_engine() %&gt;% \n  vi()\n\nvi_preds\n\n# A tibble: 9 × 3\n  Variable          Importance Sign \n  &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;\n1 species_Gentoo         763.  POS  \n2 sex_male               389.  POS  \n3 species_Chinstrap      284.  NEG  \n4 flipper_length_mm      268.  POS  \n5 bill_length_mm         128.  POS  \n6 bill_depth_mm           70.6 POS  \n7 island_Dream            63.8 NEG  \n8 year                    30.7 NEG  \n9 island_Torgersen         0   NEG  \n\n\n\nvi_preds %&gt;% \n  ggplot(aes(x = Importance, y = reorder(Variable, Importance), fill = Sign)) +\n  geom_col()\n\n\n\n\n\n\n\n\nMan beachte: Für regulierte Modelle sind Zentrierung und Skalierung nötig.\n\nCategories:\n\ntidymodels\nstatlearning\nlasso\nlm\nstring\ntemplate"
  },
  {
    "objectID": "posts/tidymodels-penguins02/tidymodels-penguins02.html",
    "href": "posts/tidymodels-penguins02/tidymodels-penguins02.html",
    "title": "tidymodels-penguins02",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=1 CV.\nTunen Sie nicht.\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs prüfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\"\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nK-Nearest Neighbor Model Specification (regression)\n\nComputational engine: kknn \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n# A tibble: 6 × 2\n  bill_length_mm body_mass_g\n           &lt;dbl&gt;       &lt;dbl&gt;\n1           34.5        2900\n2           52.2        3450\n3           45.4        4800\n4           42.1        4000\n5           50          5350\n6           41.5        4000\n\n\nAuf NA prüfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits           id   \n  &lt;list&gt;           &lt;chr&gt;\n1 &lt;split [199/50]&gt; Fold1\n2 &lt;split [199/50]&gt; Fold2\n3 &lt;split [199/50]&gt; Fold3\n4 &lt;split [199/50]&gt; Fold4\n5 &lt;split [200/49]&gt; Fold5\n\n\nResampling:\n\nd_resamples &lt;-\n  fit_resamples(\n    wflow,\n    resamples = folds\n  )\n\nd_resamples\n\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics         .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [199/50]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [199/50]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [199/50]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [199/50]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [200/49]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nLast Fit:\n\nfit_last &lt;- last_fit(wflow, d_split)\n\nModellgüte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     654.    Preprocessor1_Model1\n2 rsq     standard       0.294 Preprocessor1_Model1\n\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n[1] 0.2935091\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins04/tidymodels-penguins04.html",
    "href": "posts/tidymodels-penguins04/tidymodels-penguins04.html",
    "title": "tidymodels-penguins04",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nGesucht ist R-Quadrat als Maß für die Modellgüte im TEST-Sample.\nHinweise:\n\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nNutzen Sie eine v=5,r=2 CV.\nTunen Sie \\(K\\) (Default-Tuning)\nEntfernen Sie fehlende Werte in den Variablen.\nVerzichten Sie auf weitere Schritte der Vorverarbeitung.\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nDatensatz auf NAs prüfen:\n\nd2 &lt;-\n  d %&gt;% \n  drop_na() \n\nDatensatz aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nWorkflow:\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)\n\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nK-Nearest Neighbor Model Specification (regression)\n\nMain Arguments:\n  neighbors = tune()\n\nComputational engine: kknn \n\n\nBacken:\n\nd_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_baked %&gt;% head()\n\n# A tibble: 6 × 2\n  bill_length_mm body_mass_g\n           &lt;dbl&gt;       &lt;dbl&gt;\n1           34.5        2900\n2           52.2        3450\n3           45.4        4800\n4           42.1        4000\n5           50          5350\n6           41.5        4000\n\n\nAuf NA prüfen:\n\nsum(is.na(d_baked))\n\n[1] 0\n\n\nCV:\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 5, repeats = 2)\nfolds\n\n#  5-fold cross-validation repeated 2 times \n# A tibble: 10 × 3\n   splits           id      id2  \n   &lt;list&gt;           &lt;chr&gt;   &lt;chr&gt;\n 1 &lt;split [199/50]&gt; Repeat1 Fold1\n 2 &lt;split [199/50]&gt; Repeat1 Fold2\n 3 &lt;split [199/50]&gt; Repeat1 Fold3\n 4 &lt;split [199/50]&gt; Repeat1 Fold4\n 5 &lt;split [200/49]&gt; Repeat1 Fold5\n 6 &lt;split [199/50]&gt; Repeat2 Fold1\n 7 &lt;split [199/50]&gt; Repeat2 Fold2\n 8 &lt;split [199/50]&gt; Repeat2 Fold3\n 9 &lt;split [199/50]&gt; Repeat2 Fold4\n10 &lt;split [200/49]&gt; Repeat2 Fold5\n\n\nTunen:\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE)\n  )\n\nd_resamples\n\n# Tuning results\n# 5-fold cross-validation repeated 2 times \n# A tibble: 10 × 5\n   splits           id      id2   .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;   &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [199/50]&gt; Repeat1 Fold1 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [199/50]&gt; Repeat1 Fold2 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [199/50]&gt; Repeat1 Fold3 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [199/50]&gt; Repeat1 Fold4 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [200/49]&gt; Repeat1 Fold5 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [199/50]&gt; Repeat2 Fold1 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [199/50]&gt; Repeat2 Fold2 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [199/50]&gt; Repeat2 Fold3 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [199/50]&gt; Repeat2 Fold4 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [200/49]&gt; Repeat2 Fold5 &lt;tibble [20 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nBester Kandidat:\n\nshow_best(d_resamples)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 7\n  neighbors .metric .estimator  mean     n std_err .config              \n      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1        15 rmse    standard    676.    10    15.6 Preprocessor1_Model10\n2        13 rmse    standard    684.    10    15.7 Preprocessor1_Model09\n3        11 rmse    standard    692.    10    16.4 Preprocessor1_Model08\n4        10 rmse    standard    694.    10    16.5 Preprocessor1_Model07\n5         9 rmse    standard    702.    10    15.8 Preprocessor1_Model06\n\n\n\nfitbest &lt;- fit_best(d_resamples)\nfitbest\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nkknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(15L,     data, 5))\n\nType of response variable: continuous\nminimal mean absolute error: 526.1741\nMinimal mean squared error: 416047.6\nBest kernel: optimal\nBest k: 15\n\n\nLast Fit:\n\nfit_last &lt;- last_fit(fitbest, d_split)\nfit_last\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits           id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;           &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [249/84]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nModellgüte im Test-Sample:\n\nfit_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     605.    Preprocessor1_Model1\n2 rsq     standard       0.385 Preprocessor1_Model1\n\n\nR-Quadrat:\n\nsol &lt;- collect_metrics(fit_last)[[\".estimate\"]][2]\nsol\n\n[1] 0.3849557\n\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nnum"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html",
    "title": "tidymodels-penguins06",
    "section": "",
    "text": "Berechnen Sie ein kNN-Modell mit tidymodels und zwar anhand des penguins Datensatzes.\nModellgleichung: body_mass_g ~ bill_length_mm.\nVergleichen Sie die Testfehlerhöhe im Test-Sample in folgenden zwei Szenarien:\n\nTrain-Test-Aufspaltung, 10 Mal wiederholt\n10-fache Kreuzvalidierung (im Train-Sample) (\\(v=10, r= 1\\))\n\nHinweise:\n\nTuning Sie - nur im 2. Szenario - \\(k\\) mit den Werten 5, 10, 15.\nLöschen Sie alle Zeilen mit fehlenden Werten in den Prädiktoren.\nBeachten Sie die üblichen Hinweise.\nNatürlich gilt: Ceteris paribus. Halten Sie also die Modelle im Übrigen vergleichbar bzw. identisch.\n\n\n\n\nSzenario 1 hat den geringeren Vorhersagefehler.\nSzenario 2 hat den geringeren Vorhersagefehler.\nDer Vorhersagefehler ist in beiden Szenarien gleich.\nKeine Antwort möglich."
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#answerlist",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#answerlist",
    "title": "tidymodels-penguins06",
    "section": "",
    "text": "Szenario 1 hat den geringeren Vorhersagefehler.\nSzenario 2 hat den geringeren Vorhersagefehler.\nDer Vorhersagefehler ist in beiden Szenarien gleich.\nKeine Antwort möglich."
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#setup",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#setup",
    "title": "tidymodels-penguins06",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Rechenzeit messen, optional\n# data(penguins, package = \"palmerpenguins\")\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nWir dürfen keine fehlenden Werte in der Y-Variable haben (im Train-Set), sonst meckert Tidymodels:\n\nd2 &lt;- \n  d %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#daten-aufteilen",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#daten-aufteilen",
    "title": "tidymodels-penguins06",
    "section": "Daten aufteilen:",
    "text": "Daten aufteilen:\n\nset.seed(42)\nd_split &lt;- initial_split(d2)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-1",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-1",
    "title": "tidymodels-penguins06",
    "section": "CV",
    "text": "CV\n\nset.seed(42)\nfolds &lt;- vfold_cv(d_train, v = 10, repeats = 1)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#workflow",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#workflow",
    "title": "tidymodels-penguins06",
    "section": "Workflow",
    "text": "Workflow\n\nrec1 &lt;-\n  recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n  step_naomit(all_numeric_predictors())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) \n\nwflow &lt;-\n  workflow() %&gt;%\n  add_recipe(rec1) %&gt;%\n  add_model(knn_model)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten",
    "title": "tidymodels-penguins06",
    "section": "Fitten",
    "text": "Fitten\n\nd_resamples &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellgüte",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellgüte",
    "title": "tidymodels-penguins06",
    "section": "Modellgüte",
    "text": "Modellgüte\n\nbestfit1 &lt;- fit_best(x = d_resamples)\nlastfit1 &lt;- last_fit(bestfit1, d_split)\ncollect_metrics(lastfit1)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     586.    Preprocessor1_Model1\n2 rsq     standard       0.410 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-2",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#cv-2",
    "title": "tidymodels-penguins06",
    "section": "CV",
    "text": "CV\nWir resamplen nicht über das Train-Sample, sondern über die ganze Stichprobe:\n\nset.seed(42)\nfolds2 &lt;- vfold_cv(d2, v = 2, repeats = 10)"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten-1",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#fitten-1",
    "title": "tidymodels-penguins06",
    "section": "Fitten",
    "text": "Fitten\n\nd_resamples2 &lt;-\n  tune_grid(\n    wflow,\n    resamples = folds2,\n    control = control_grid(save_workflow = TRUE),\n    grid = data.frame(neighbors = c(5, 10, 15)),\n    metrics = metric_set(rmse)\n    )"
  },
  {
    "objectID": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellgüte-1",
    "href": "posts/tidymodels-penguins06/tidymodels-penguins06.html#modellgüte-1",
    "title": "tidymodels-penguins06",
    "section": "Modellgüte",
    "text": "Modellgüte\n\nbestfit2 &lt;- fit_best(x = d_resamples2)\nlastfit2 &lt;- last_fit(bestfit2, d_split)\ncollect_metrics(lastfit2)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     586.    Preprocessor1_Model1\n2 rsq     standard       0.410 Preprocessor1_Model1\n\n\n\nCategories:\n\ntidymodels\nstatlearning\nschoice"
  },
  {
    "objectID": "posts/tidymodels-poly01/tidymodels-poly01.html",
    "href": "posts/tidymodels-poly01/tidymodels-poly01.html",
    "title": "tidymodels-poly01",
    "section": "",
    "text": "Aufgabe\nFitten Sie ein Polynomial-Modell für folgende Modellgleichung:\nbody_mass_g ~ bill_length_mm.\nGesucht ist der optimale Polynomgrad im Train-Sample (optimal hinsichtlich minimalem Prognosefehler).\nHinweise:\n\nDatensatz penguins (palmerpenguins)\nVerwenden Sie Tidymodels\nFitten Sie Polynome des Grades 1 bis 10.\nDefinieren Sie die Polynomegrade als Tuningparameter.\nBeziehen Sie sich auf RMSE als Kennzahl der Modellgüte.\nEntfernen Sie fehlende Werte in den Prädiktoren\n\n         \n\n\nLösung\nSetup:\n\nlibrary(tidymodels)\ndata(penguins, package = \"palmerpenguins\")\n\nRezept:\n\nrec1 &lt;- \n  recipe(body_mass_g ~ bill_length_mm, data = penguins) %&gt;% \n  step_naomit(all_predictors()) %&gt;% \n  step_poly(all_predictors(), degree = tune()) %&gt;% \n  update_role(contains(\"_poly_\"), new_role = \"predictor\")\n\nWarning: No columns were selected in `update_role()`.\n\n\nCheck:\n\nd_baked &lt;- bake(prep(rec1), new_data = NULL)\n\nWorkflow:\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(linear_reg()) %&gt;% \n  add_recipe(rec1)\n\nRezepte mit Tuningparametern kann man nicht preppen/backen.\nTuning:\n\ntune1 &lt;-\n  tune_grid(\n    wf1,\n    resamples = vfold_cv(data = penguins),\n    metrics = metric_set(rmse),\n    grid = grid_regular(degree(range = c(1, 10)),\n                               levels = 10)\n  )\n\n\nautoplot(tune1)\n\n\n\n\n\n\n\n\n\nshow_best(tune1)\n\n# A tibble: 5 × 7\n  degree .metric .estimator  mean     n std_err .config              \n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1      2 rmse    standard    642.    10    23.5 Preprocessor02_Model1\n2      1 rmse    standard    644.    10    27.4 Preprocessor01_Model1\n3      5 rmse    standard    646.    10    23.9 Preprocessor05_Model1\n4      4 rmse    standard    648.    10    25.4 Preprocessor04_Model1\n5      3 rmse    standard    654.    10    27.8 Preprocessor03_Model1\n\n\n\nsol &lt;- show_best(tune1)$degree[1]\nsol\n\n[1] 2\n\n\nDie Antwort lautet: 2.\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/tidymodels-remove-na/tidymodels-remove-na.html",
    "href": "posts/tidymodels-remove-na/tidymodels-remove-na.html",
    "title": "tidymodels-remove-na",
    "section": "",
    "text": "Aufgabe\n\nErstellen Sie ein Rezept, dass die fehlenden Werte aus dem Datensatz penguins entfernt.\nHinweise:\n\nVerwenden Sie tidymodels.\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\n# Setup:\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.3     ✔ stringr   1.5.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tictoc)  # Zeitmessung\n\n\n\n# Data:\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\nd &lt;- read_csv(d_path)\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (6): rownames, bill_length_mm, bill_depth_mm, flipper_length_mm, body_ma...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# recipe:\nrec1 &lt;- recipe(body_mass_g ~  ., data = d) |&gt; \n  step_dummy(all_nominal_predictors()) |&gt; \n  step_normalize(all_predictors()) |&gt; \n  step_naomit(all_predictors()) \n\nAls Check: Das gepreppte/bebackene Rezept:\n\nrec1_prepped &lt;- prep(rec1)\n\nWarning: There are new levels in a factor: NA\n\nd_train_baked &lt;- bake(rec1_prepped, new_data = NULL)\n\n\nd_train_baked |&gt; \n  head()\n\n# A tibble: 6 × 11\n  rownames bill_length_mm bill_depth_mm flipper_length_mm  year body_mass_g\n     &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;\n1    -1.72         -0.883         0.784            -1.42  -1.26        3750\n2    -1.71         -0.810         0.126            -1.06  -1.26        3800\n3    -1.70         -0.663         0.430            -0.421 -1.26        3250\n4    -1.68         -1.32          1.09             -0.563 -1.26        3450\n5    -1.67         -0.847         1.75             -0.776 -1.26        3650\n6    -1.66         -0.920         0.329            -1.42  -1.26        3625\n# ℹ 5 more variables: species_Chinstrap &lt;dbl&gt;, species_Gentoo &lt;dbl&gt;,\n#   island_Dream &lt;dbl&gt;, island_Torgersen &lt;dbl&gt;, sex_male &lt;dbl&gt;\n\n\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\ndescribe_distribution(d_train_baked)\n\nVariable          |      Mean |     SD |     IQR |              Range | Skewness | Kurtosis |   n | n_Missing\n-------------------------------------------------------------------------------------------------------------\nrownames          |      0.02 |   0.99 |    1.71 |      [-1.72, 1.72] |     0.01 |    -1.19 | 333 |         0\nbill_length_mm    |      0.01 |   1.00 |    1.69 |      [-2.17, 2.87] |     0.05 |    -0.88 | 333 |         0\nbill_depth_mm     |  6.94e-03 |   1.00 |    1.57 |      [-2.05, 2.20] |    -0.15 |    -0.89 | 333 |         0\nflipper_length_mm |  3.68e-03 |   1.00 |    1.64 |      [-2.06, 2.14] |     0.36 |    -0.96 | 333 |         0\nyear              |      0.02 |   0.99 |    2.44 |      [-1.26, 1.19] |    -0.08 |    -1.48 | 333 |         0\nbody_mass_g       |   4207.06 | 805.22 | 1237.50 | [2700.00, 6300.00] |     0.47 |    -0.73 | 333 |         0\nspecies_Chinstrap |      0.02 |   1.01 |    0.00 |      [-0.50, 2.01] |     1.47 |     0.17 | 333 |         0\nspecies_Gentoo    | -6.46e-03 |   1.00 |    2.08 |      [-0.75, 1.33] |     0.60 |    -1.65 | 333 |         0\nisland_Dream      |      0.02 |   1.01 |    2.08 |      [-0.75, 1.33] |     0.54 |    -1.71 | 333 |         0\nisland_Torgersen  |     -0.03 |   0.97 |    0.00 |      [-0.42, 2.37] |     2.07 |     2.30 | 333 |         0\nsex_male          |  8.40e-17 |   1.00 |    2.00 |      [-1.01, 0.99] |    -0.02 |    -2.01 | 333 |         0\n\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html",
    "title": "tidymodels-tree1",
    "section": "",
    "text": "library(tidymodels)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#setup",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#setup",
    "title": "tidymodels-tree1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\ndata(mtcars)\nlibrary(tictoc)  # Zeitmessung\nlibrary(baguette)\n\nFür Klassifikation verlangt Tidymodels eine nominale AV, keine numerische:\n\nmtcars &lt;-\n  mtcars %&gt;% \n  mutate(am = factor(am))"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#daten-teilen",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#daten-teilen",
    "title": "tidymodels-tree1",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nd_split &lt;- initial_split(mtcars)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#modelle",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#modelle",
    "title": "tidymodels-tree1",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"classification\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())\n\nmod_bag &lt;-\n  bag_tree(mode = \"classification\",\n           cost_complexity = tune(),\n           tree_depth = tune(),\n           min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#rezepte",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#rezepte",
    "title": "tidymodels-tree1",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(am ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#resampling",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#resampling",
    "title": "tidymodels-tree1",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpl &lt;- vfold_cv(d_train, v = 2)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#workflows",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#workflows",
    "title": "tidymodels-tree1",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)\n\n\nwf_bag &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_bag)"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#tuningfitting",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#tuningfitting",
    "title": "tidymodels-tree1",
    "section": "Tuning/Fitting",
    "text": "Tuning/Fitting\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\ntune_grid\n\n# A tibble: 125 × 3\n   cost_complexity tree_depth min_n\n             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n 1    0.0000000001          1     2\n 2    0.0000000178          1     2\n 3    0.00000316            1     2\n 4    0.000562              1     2\n 5    0.1                   1     2\n 6    0.0000000001          4     2\n 7    0.0000000178          4     2\n 8    0.00000316            4     2\n 9    0.000562              4     2\n10    0.1                   4     2\n# ℹ 115 more rows\n\n\nDa beide Modelle die gleichen Tuningparameter aufweisen, brauchen wir nur ein Grid zu erstellen.\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\n18.258 sec elapsed\n\nfit_tree\n\n# Tuning results\n# 2-fold cross-validation \n# A tibble: 2 × 4\n  splits          id    .metrics           .notes           \n  &lt;list&gt;          &lt;chr&gt; &lt;list&gt;             &lt;list&gt;           \n1 &lt;split [12/12]&gt; Fold1 &lt;tibble [125 × 7]&gt; &lt;tibble [75 × 3]&gt;\n2 &lt;split [12/12]&gt; Fold2 &lt;tibble [125 × 7]&gt; &lt;tibble [75 × 3]&gt;\n\nThere were issues with some computations:\n\n  - Warning(s) x50: 21 samples were requested but there were 12 rows in the data. 12 ...\n  - Warning(s) x50: 30 samples were requested but there were 12 rows in the data. 12 ...\n  - Warning(s) x50: 40 samples were requested but there were 12 rows in the data. 12 ...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\n\ntic()\nfit_bag &lt;-\n  tune_grid(object = wf_bag,\n            grid = tune_grid,\n            metrics = metric_set(roc_auc),\n            resamples = rsmpl)\ntoc()\n\n97.331 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#bester-kandidat",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#bester-kandidat",
    "title": "tidymodels-tree1",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nshow_best(fit_tree)\n\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          1     2 roc_auc binary     0.845     2  0.0119\n2    0.0000000178          1     2 roc_auc binary     0.845     2  0.0119\n3    0.00000316            1     2 roc_auc binary     0.845     2  0.0119\n4    0.000562              1     2 roc_auc binary     0.845     2  0.0119\n5    0.1                   1     2 roc_auc binary     0.845     2  0.0119\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\n\nshow_best(fit_bag)\n\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.00000316            8     2 roc_auc binary     0.967     2 0.00423\n2    0.00000316           11     2 roc_auc binary     0.967     2 0.00423\n3    0.0000000178         15     2 roc_auc binary     0.967     2 0.00423\n4    0.0000000001          4    11 roc_auc binary     0.967     2 0.00423\n5    0.0000000178         11     2 roc_auc binary     0.965     2 0.0206 \n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\nBagging erzielte eine klar bessere Modellgüte (in den Validierungssamples) als das Entscheidungsbaum-Modell."
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#finalisieren",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#finalisieren",
    "title": "tidymodels-tree1",
    "section": "Finalisieren",
    "text": "Finalisieren\n\nwf_best_finalized &lt;-\n  wf_bag %&gt;% \n  finalize_workflow(select_best(fit_bag))"
  },
  {
    "objectID": "posts/tidymodels-tree1/tidymodels-tree1.html#last-fit",
    "href": "posts/tidymodels-tree1/tidymodels-tree1.html#last-fit",
    "title": "tidymodels-tree1",
    "section": "Last Fit",
    "text": "Last Fit\n\nfinal_fit &lt;- \n  last_fit(object = wf_best_finalized, d_split)\n\ncollect_metrics(final_fit)\n\n# A tibble: 3 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary       1       Preprocessor1_Model1\n2 roc_auc     binary       1       Preprocessor1_Model1\n3 brier_class binary       0.00103 Preprocessor1_Model1\n\n\nWie man sieht, ist die Modellgüte im Test-Sample schlechter als in den Train- bzw. Validierungssamples; ein typischer Befund.\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nstring"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html",
    "title": "tidymodels-tree3",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nEntscheidungsbaum\n\nModellformel: body_mass_g ~ . (Datensatz palmerpenguins::penguins)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nAuslassen gering performanter Tuningparameterwerte\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nBeachten Sie die üblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#setup",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#setup",
    "title": "tidymodels-tree3",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\ndata(\"penguins\", package = \"palmerpenguins\")\nlibrary(tictoc)  # Zeitmessung\nlibrary(finetune)  # tune_race_anova\nset.seed(42)\n\nEntfernen wir Fälle ohne y-Wert:\n\nd &lt;-\n  penguins %&gt;% \n  drop_na(body_mass_g)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#daten-teilen",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#daten-teilen",
    "title": "tidymodels-tree3",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#modelle",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#modelle",
    "title": "tidymodels-tree3",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_tree &lt;-\n  decision_tree(mode = \"regression\",\n                cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune())"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#rezepte",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#rezepte",
    "title": "tidymodels-tree3",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(body_mass_g ~ ., data = d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#resampling",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#resampling",
    "title": "tidymodels-tree3",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#workflows",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#workflows",
    "title": "tidymodels-tree3",
    "section": "Workflows",
    "text": "Workflows\n\nwf_tree &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_tree)"
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#tuning-grid",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#tuning-grid",
    "title": "tidymodels-tree3",
    "section": "Tuning-Grid",
    "text": "Tuning-Grid\nTuninggrid:\n\ntune_grid &lt;- grid_regular(extract_parameter_set_dials(mod_tree), levels = 5)\n\nDie Zeilen im Tuninggrid zeigen uns, für wie viele Modellparameter ein Modell berechnet wird. Natürlich üblicherweise jedes Modell mit Resampling. Da kommt in Summe ein mitunter sehr große Menge an Modellberechnungen zusammen."
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#ohne-speed-up",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#ohne-speed-up",
    "title": "tidymodels-tree3",
    "section": "Ohne Speed-up",
    "text": "Ohne Speed-up\n\ntic()\nfit_tree &lt;-\n  tune_grid(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            resamples = rsmpl)\ntoc()\n\n77.274 sec elapsed\n\n\nca. auf meinem Rechner (4-Kerne-MacBook Pro 2020)."
  },
  {
    "objectID": "posts/tidymodels-tree3/tidymodels-tree3.html#mit-geschicktem-weglassen-von-tuningparametern",
    "href": "posts/tidymodels-tree3/tidymodels-tree3.html#mit-geschicktem-weglassen-von-tuningparametern",
    "title": "tidymodels-tree3",
    "section": "Mit geschicktem Weglassen von Tuningparametern",
    "text": "Mit geschicktem Weglassen von Tuningparametern\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(object = wf_tree,\n            grid = tune_grid,\n            metrics = metric_set(rmse),\n            resamples = rsmpl)\ntoc()\n\n68.768 sec elapsed\n\n\nca. - schneller!\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html",
    "title": "tidymodels-tree5",
    "section": "",
    "text": "Berechnen Sie folgendes einfache Modell:\n\nRandom Forest mit trees=50\n\nModellformel: body_mass_g ~ . (Datensatz palmerpenguins::penguins)\nHier geht es darum, die Geschwindigkeit (und den Ressourcenverbrauch) beim Fitten zu verringern. Benutzen Sie dazu folgende Methoden\n\nAuslassen gering performanter Tuningparameterwerte\nVerwenden Sie ein Anova-Grid-Search!\nParallelisieren Sie auf mehrere Kerne (wenn möglich).\n\nHinweise:\n\nTunen Sie alle Parameter (die der Engine anbietet).\nVerwenden Sie Defaults, wo nicht anders angegeben.\nBeachten Sie die üblichen Hinweise."
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#setup",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#setup",
    "title": "tidymodels-tree5",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.8\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.3     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.0\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\ndata(\"penguins\", package = \"palmerpenguins\")\nlibrary(tictoc)  # Zeitmessung\nlibrary(finetune)  # tune_race_anova\nlibrary(doParallel)  # mehrere CPUs nutzen \n\nLoading required package: foreach\n\n\n\nAttaching package: 'foreach'\n\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nset.seed(42)\n\nEntfernen wir Fälle mit fehlenden Werten:\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#daten-teilen",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#daten-teilen",
    "title": "tidymodels-tree5",
    "section": "Daten teilen",
    "text": "Daten teilen\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#modelle",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#modelle",
    "title": "tidymodels-tree5",
    "section": "Modell(e)",
    "text": "Modell(e)\n\nmod_rf &lt;-\n  rand_forest(mode = \"regression\",\n              mtry = tune())\nmod_rf\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n\nComputational engine: ranger"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#rezepte",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#rezepte",
    "title": "tidymodels-tree5",
    "section": "Rezept(e)",
    "text": "Rezept(e)\n\nrec_plain &lt;- \n  recipe(body_mass_g ~ ., data = d_train) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_impute_knn(all_predictors())\n\n\nd_train_baked &lt;-\n  bake(prep(rec_plain, d_train), new_data = NULL)\n\nhead(d_train_baked)\n\n# A tibble: 6 × 10\n  bill_length_mm bill_depth_mm flipper_length_mm  year body_mass_g\n           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt; &lt;int&gt;       &lt;int&gt;\n1           34.5          18.1               187  2008        2900\n2           52.2          18.8               197  2009        3450\n3           45.4          14.6               211  2007        4800\n4           42.1          19.1               195  2008        4000\n5           50            15.9               224  2009        5350\n6           41.5          18.5               201  2009        4000\n# ℹ 5 more variables: species_Chinstrap &lt;dbl&gt;, species_Gentoo &lt;dbl&gt;,\n#   island_Dream &lt;dbl&gt;, island_Torgersen &lt;dbl&gt;, sex_male &lt;dbl&gt;\n\n\nKeine fehlenden Werte mehr?\n\nsum(is.na(d_train_baked))\n\n[1] 0"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#resampling",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#resampling",
    "title": "tidymodels-tree5",
    "section": "Resampling",
    "text": "Resampling\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#workflows",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#workflows",
    "title": "tidymodels-tree5",
    "section": "Workflows",
    "text": "Workflows\n\nwf_rf &lt;-\n  workflow() %&gt;%  \n  add_recipe(rec_plain) %&gt;% \n  add_model(mod_rf)\n\nwf_rf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_impute_knn()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n\nComputational engine: ranger"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#ohne-speed-up",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#ohne-speed-up",
    "title": "tidymodels-tree5",
    "section": "Ohne Speed-up",
    "text": "Ohne Speed-up\n\ntic()\nfit_rf &lt;-\n  tune_grid(\n    object = wf_rf,\n    resamples = rsmpl)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n13.061 sec elapsed\n\n\nDie angegebene Rechenzeit bezieht sich auf einen 4-Kerne-MacBook Pro (2020)."
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-1",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-1",
    "title": "tidymodels-tree5",
    "section": "Mit Speeed-up 1",
    "text": "Mit Speeed-up 1\n\ntic()\nfit_rf2 &lt;-\n  tune_race_anova(\n    object = wf_rf,\n    resamples = rsmpl)\ntoc()\n\n17.925 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-2",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-2",
    "title": "tidymodels-tree5",
    "section": "Mit Speeed-up 2",
    "text": "Mit Speeed-up 2\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_race_anova(\n    object = wf_rf,\n    metrics = metric_set(rmse),\n    control = control_race(verbose = FALSE,\n                           pkgs = c(\"tidymodels\"),\n                           save_pred = TRUE),\n            resamples = rsmpl)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n12.339 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-3",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#mit-speeed-up-3",
    "title": "tidymodels-tree5",
    "section": "Mit Speeed-up 3",
    "text": "Mit Speeed-up 3\n\ndoParallel::registerDoParallel()\n\ntic()\nfit_tree2 &lt;-\n  tune_grid(object = wf_rf,\n            metrics = metric_set(rmse),\n            control = control_grid(verbose = FALSE,\n                                   save_pred = TRUE),\n            resamples = rsmpl)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n4.53 sec elapsed"
  },
  {
    "objectID": "posts/tidymodels-tree5/tidymodels-tree5.html#fazit",
    "href": "posts/tidymodels-tree5/tidymodels-tree5.html#fazit",
    "title": "tidymodels-tree5",
    "section": "Fazit",
    "text": "Fazit\nMit Speed-up ist schneller also ohne. Ein Random-Forest ist ein Modelltyp, der von Parallelisierung gut profitiert.\n\nCategories:\n\nstatlearning\ntrees\ntidymodels\nspeed\nstring"
  },
  {
    "objectID": "posts/tidymodels-vorlage2/tidymodels-vorlage2.html",
    "href": "posts/tidymodels-vorlage2/tidymodels-vorlage2.html",
    "title": "tidymodels-vorlage2",
    "section": "",
    "text": "Aufgabe\nSchreiben Sie eine Vorlage für eine prädiktive Analyse mit Tidymodels!\n\nHinweise:\n\nBerechnen Sie ein Modell\nTunen Sie mind. einen Parameter des Modells\nVerwenden Sie Kreuzvalidierung\nVerwenden Sie Standardwerte, wo nicht anders angegeben.\nFixieren Sie Zufallszahlen auf den Startwert 42.\n\n         \n\n\nLösung\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(&lt;other_package_you_might_need_for_modelling&gt;)  # tidymodels uses existing packages for modelling so you need to make them available\n\n\n# Data:\nd_path &lt;- \"Enter data path here\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  &lt;enter_parsnip_model_name_here&gt;(mode = \"&lt;choose_regression_or_classification&gt;\",\n           cost_complexity = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(&lt;enter_output_variable&gt; ~  ., data = d_train)\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# Modellgüte im Test-Set:\ncollect_metrics(wf1_fit_final)\n\n\nCategories:\n\ntidymodels\nstatlearning\ntemplate\nstring"
  },
  {
    "objectID": "posts/tidymodels1/tidymodels1.html",
    "href": "posts/tidymodels1/tidymodels1.html",
    "title": "tidymodels1",
    "section": "",
    "text": "Prof. Salzig übt sich im statistischen Lernen. Dazu will er das Überleben im Titanic-Unglück Vorhersagen; es handelt sich um eine klassische Aufgabe im statistischen Lernen. Betrachten Sie dazu den folgenden R-Code sowie die Kommentare dazu. Wählen Sie die am besten passende Aussage.\nZuerst lädt er die nötigen R-Pakete:\n\nlibrary(tidyverse)  # data wrangling\nlibrary(tidymodels)  # modelling\nlibrary(broom)  # tidy model output\nlibrary(parallel)  # multiple cores -- *nix only, d.h. Mac und Linux\nlibrary(finetune)  # tune race anova\n\nDann initialisiert er die Anzahl der Prozessoren auf seinem Computer:\n\ncores &lt;- parallel::detectCores(logical = FALSE)\ncores\n\n[1] 4\n\n\nDaten importieren:\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre\"\ntraindata_path_url  &lt;- \"/main/data/titanic/titanic_train.csv\"\ntestdata_path_url &lt;- \"/main/data/titanic/titanic_test.csv\"\n\ntraindata_url &lt;- paste0(data_path, traindata_path_url)\ntestdata_url &lt;- paste0(data_path, testdata_path_url)\n\n\n# import the data:\ntrain_raw &lt;- read_csv(traindata_url)\ntest &lt;- read_csv(testdata_url)\n\nUnd aufbereiten:\n\n# drop unused variables:\ntrain &lt;-\n  train_raw %&gt;% \n  select(-c(Name, Cabin, Ticket))\n\n# convert string to factors:\ntrain2 &lt;- \n  train %&gt;% \n  mutate(across(where(is.character), as.factor))\n  \n# convert numeric outcome to nominal, to indicate classification:\ntrain2 &lt;- \n  train2 %&gt;% \n  mutate(Survived = as.factor(Survived))\n\nGibt es fehlende Werte in der AV?\n\nsum(is.na(train2$Survived))\n\n[1] 0\n\n\nVorverarbeitung des Datensatzes macht er via ein recipe aus tidymodels:\n\ntitanic_recipe &lt;- \n  \n  # define model formula:\n  recipe(Survived ~ ., data = train2) %&gt;%\n  \n  # Use \"ID\" etc as ID, not as predictor:\n  update_role(PassengerId, new_role = \"ID\") %&gt;% \n  \n   # impute missing values:\n  step_impute_bag(all_predictors()) %&gt;% \n  \n  # convert to dummy variables:\n  step_dummy(all_nominal_predictors())\n\nCheck no missings:\n\ntitanic_train_baked &lt;- titanic_recipe %&gt;% prep() %&gt;% bake(new_data = NULL)\n\nsum(is.na(titanic_train_baked))\n\n[1] 0\n\n\nDann definiert ein ein Modell:\n\nrf_mod2 &lt;- \n  rand_forest(mtry = tune(), # tune mtry\n              min_n = tune(), # tune minimal n per node\n              trees = 1000) %&gt;%  # set number of trees to 1000\n  set_engine(\"ranger\", \n             num.threads = cores) %&gt;% \n  set_mode(\"classification\")\n\n… und ein Kreuzvalidierungsschema:\n\ntrain_cv &lt;- vfold_cv(train2, \n                     v = 10,\n                     repeats = 1, \n                     strata = \"Survived\")\n\nAus der Hilfe zu vfold_cv:\n\nV-Fold Cross-Validation\nDescription\nV-fold cross-validation randomly splits the data into V groups of roughly equal size (called “folds”). A resample of the analysis data consisted of V-1 of the folds while the assessment set contains the final fold. In basic V-fold cross-validation (i.e. no repeats), the number of resamples is equal to V.\nUsage\nvfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, ...)\nArguments\ndata A data frame.\nv The number of partitions of the data set.\nrepeats The number of times to repeat the V-fold partitioning.\nstrata A variable that is used to conduct stratified sampling to create the folds. This could be a single character value or a variable name that corresponds to a variable that exists in the data frame.\nbreaks A single number giving the number of bins desired to stratify a numeric stratification variable.\n... Not currently used.\nDetails\nThe strata argument causes the random sampling to be conducted within the stratification variable. This can help ensure that the number of data points in the analysis data is equivalent to the proportions in the original data set. (Strata below 10% of the total are pooled together.) When more than one repeat is requested, the basic V-fold cross-validation is conducted each time. For example, if three repeats are used with v = 10, there are a total of 30 splits which as three groups of 10 that are generated separately.\n\nSo entsteht dieser Workflow:\n\ntitanic_rf_wf2 &lt;-\n  workflow() %&gt;% \n  add_model(rf_mod2) %&gt;% \n  add_recipe(titanic_recipe)\n\nJetzt: Fit the grid!\n\nset.seed(42)\n\nn_candidates &lt;- 2\n\nrf_res2 &lt;- \n  titanic_rf_wf2 %&gt;% \n  tune_race_anova(\n    resamples = train_cv,\n    grid = n_candidates,  # test 25 different tuning parameter values\n    #control = control_grid(save_pred = TRUE),\n    metrics = metric_set(roc_auc))\n\nMit dem Parameter grid kann man die Anzahl der zu berechnenden Kandidaten-Modelle festlegen.\nFür gute Vorhersagen bieten sich hohe Werte an; das kostet aber Rechenzeit.\nAus den Resampling-Kandidaten wählt er nun das beste aus:\n\nrf_best2 &lt;- \n  rf_res2 %&gt;% \n  select_best(metric = \"roc_auc\")\nrf_best2\n\n# A tibble: 1 × 3\n   mtry min_n .config             \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;               \n1     3    12 Preprocessor1_Model1\n\n\nDas beste Kandidatenmodell nutzt er nun, um den ganzen Train-Datensatz zu “fitten”:\n\n# write best parameter values to the workflow:\nrf_final_wf2 &lt;- \n  titanic_rf_wf2 %&gt;% \n  finalize_workflow(rf_best2)\n\n# fit the model:\nrf_final_model2 &lt;- \nrf_final_wf2 %&gt;% \n  fit(train2)\n\nZum Abschluss speichert er die Vorhersagen, die er dann bei Kaggle einreichen will:\n\nrf2_preds &lt;- \n  predict(rf_final_model2, new_data = test)  # compute prediction on test set\n\nEin letzter Blick auf die Verteilung der vorhergesagten Werte:\n\ncount(rf2_preds, .pred_class)\n\n# A tibble: 2 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0             284\n2 1             134\n\n\nAuf Basis dieser Analyse: Wählen Sie am besten passende Aussage!\n\n\n\nEs wurden 2 Kandidaten von Tuningparameterwerten in die Analyse einbezogen.\nEs wurde kein Parameter-Tuning durchgeführt.\nDie Metrik \\(AUC\\) sollte nicht für Klassifikationsmodelle verwendet werden.\nEs wurde eine 10-fache Kreuzvalidierung (ohne Wiederholungen) verwendet.\nDie Anzahl der Bäume im Random Forest wurde hier nicht ins Parametertuning einbezogen; allerdings wäre es sinnvoll (und üblich), dies zu tun.\nder Parameter mtry wurde hier nicht ins Parametertuning einbezogen."
  },
  {
    "objectID": "posts/tidymodels1/tidymodels1.html#answerlist",
    "href": "posts/tidymodels1/tidymodels1.html#answerlist",
    "title": "tidymodels1",
    "section": "",
    "text": "Es wurden 2 Kandidaten von Tuningparameterwerten in die Analyse einbezogen.\nEs wurde kein Parameter-Tuning durchgeführt.\nDie Metrik \\(AUC\\) sollte nicht für Klassifikationsmodelle verwendet werden.\nEs wurde eine 10-fache Kreuzvalidierung (ohne Wiederholungen) verwendet.\nDie Anzahl der Bäume im Random Forest wurde hier nicht ins Parametertuning einbezogen; allerdings wäre es sinnvoll (und üblich), dies zu tun.\nder Parameter mtry wurde hier nicht ins Parametertuning einbezogen."
  },
  {
    "objectID": "posts/tidymodels1/tidymodels1.html#answerlist-1",
    "href": "posts/tidymodels1/tidymodels1.html#answerlist-1",
    "title": "tidymodels1",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\ndyn\nschoice"
  },
  {
    "objectID": "posts/tidymodels3/tidymodels3.html",
    "href": "posts/tidymodels3/tidymodels3.html",
    "title": "tidymodels3",
    "section": "",
    "text": "Aufgabe\nBerechnen Sie ein lineares Modell mit tidymodels und zwar anhand des ames Datensatzes.\nModellgleichung: Sale_Price ~ Gr_Liv_Area, data = ames.\nBerechnen Sie ein multiplikatives (exponenzielles) Modell.\nRücktransformieren Sie die Log-Werte in “Roh-Dollar”.\n         \n\n\nLösung\nMultiplikatives Modell:\nNicht vergessen: AV-Transformation in beiden Samples!\nDatensatz aufteilen:\nModell definieren:\nModell fitten:\n\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nCoefficients:\n(Intercept)  Gr_Liv_Area  \n  4.8552133    0.0002437  \n\n\nModellgüte im Train-Sample:\nModellgüte im Train-Sample:\n\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.02587 -0.06577  0.01342  0.07202  0.39231 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.855e+00  7.355e-03  660.12   &lt;2e-16 ***\nGr_Liv_Area 2.437e-04  4.648e-06   52.43   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1271 on 2928 degrees of freedom\nMultiple R-squared:  0.4842,    Adjusted R-squared:  0.484 \nF-statistic:  2749 on 1 and 2928 DF,  p-value: &lt; 2.2e-16\n\n\nR-Quadrat via easystats:\n\n\n# R2 for Linear Regression\n       R2: 0.484\n  adj. R2: 0.484\n\n\n\n\n# A tibble: 2 × 5\n  term        estimate  std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 4.86     0.00736        660.        0\n2 Gr_Liv_Area 0.000244 0.00000465      52.4       0\n\n\nVorhersagen im Test-Sample:\n\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.18\n3  5.31\n4  5.11\n5  5.18\n6  5.10\n\n\npreds ist ein Tibble, also müssen wir noch die Spalte .pred. herausziehen, z.B. mit pluck(preds, \".pred\"):\n\n\n# A tibble: 6 × 4\n  Sale_Price Gr_Liv_Area preds .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       5.02         896  5.07  5.07\n2       5.24        1329  5.18  5.18\n3       5.60        1856  5.31  5.31\n4       5.15        1056  5.11  5.11\n5       5.26        1337  5.18  5.18\n6       4.98         987  5.10  5.10\n\n\nOder mit unnest:\n\n\n# A tibble: 6 × 3\n  Sale_Price Gr_Liv_Area .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt;\n1       5.02         896  5.07\n2       5.24        1329  5.18\n3       5.60        1856  5.31\n4       5.15        1056  5.11\n5       5.26        1337  5.18\n6       4.98         987  5.10\n\n\nOder wir binden einfach die Spalte an den Tibble:\n\n\n# A tibble: 6 × 3\n  Sale_Price Gr_Liv_Area .pred\n       &lt;dbl&gt;       &lt;int&gt; &lt;dbl&gt;\n1       5.02         896  5.07\n2       5.24        1329  5.18\n3       5.60        1856  5.31\n4       5.15        1056  5.11\n5       5.26        1337  5.18\n6       4.98         987  5.10\n\n\nModellgüte im Test-Sample:\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.517\n\n\nZur Interpretation von Log10-Werten\n\n\n[1] 5e+05\n\n\n[1] 0\n\n\nRücktransformation (ohne Bias-Korrektur):\n\nCategories:\n\nds1\ntidymodels\nprediction\nyacsda\nstatlearning\nlm\nnum"
  },
  {
    "objectID": "posts/tidytext/tidytext.html",
    "href": "posts/tidytext/tidytext.html",
    "title": "tidytext",
    "section": "",
    "text": "library(tidytext)\nlibrary(tidyverse)\ntext_df %&gt;%\n  unnest_tokens(word, text) %&gt;% \n  filter(str_detect(word, \"[a-z]\"))\n\nWelche Aussage zu dieser Syntax ist korrekt?\n\n\n\nDer Text wird so “entschachtelt”, dass in jeder Zelle nur noch ein Wort steht. Dabei werden so viele Spalten angehängt, wie Wörter in der betreffenden Zelle standen.\nDurch filter() in Verbindung mit str_detect() werden alle Buchstaben von a bis z entfernt.\nEin Token bedeutet hier so viel wie eine numerische Analyseeinheit.\nDer Text wird in das lange Format umwandelt, so dass nur noch ein Wort pro Zeile steht."
  },
  {
    "objectID": "posts/tidytext/tidytext.html#answerlist",
    "href": "posts/tidytext/tidytext.html#answerlist",
    "title": "tidytext",
    "section": "",
    "text": "Der Text wird so “entschachtelt”, dass in jeder Zelle nur noch ein Wort steht. Dabei werden so viele Spalten angehängt, wie Wörter in der betreffenden Zelle standen.\nDurch filter() in Verbindung mit str_detect() werden alle Buchstaben von a bis z entfernt.\nEin Token bedeutet hier so viel wie eine numerische Analyseeinheit.\nDer Text wird in das lange Format umwandelt, so dass nur noch ein Wort pro Zeile steht."
  },
  {
    "objectID": "posts/tmdb01/tmdb01.html",
    "href": "posts/tmdb01/tmdb01.html",
    "title": "tmdb01",
    "section": "",
    "text": "Aufgabe\nMelden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Random-Forest-Modell mit Tidymodels! Reichen Sie es bei Kaggle ein un berichten Sie den Score!\nHinweise\n\n\nVerzichten Sie auf Vorverarbeitung.\nTunen Sie die typischen Parameter.\nBegrenzen Sie sich auf folgende Prädiktoren.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\")\n\n\nAusnahme: Log-transformieren Sie budget.\nTunen Sie die typischen Parameter.\nReichen Sie das Modell ein und berichten Sie Ihren Score.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\", \"status\", \"revenue\")\n\n         \n\n\nLösung\n\nPakete starten\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)\nlibrary(doParallel)\n\n\n\nDaten importieren\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nWerfen wir einen Blick in die Daten:\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In…\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol…\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,…\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        &lt;chr&gt; \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco…\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 &lt;chr&gt; \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…\n\n\npreds_chosen sind alle Prädiktoren im Datensatz, oder nicht? Das prüfen wir mal kurz:\n\npreds_chosen %in% names(d_train) %&gt;% \n  all()\n\n[1] TRUE\n\n\nJa, alle Elemente von preds_chosen sind Prädiktoren im (Train-)Datensatz.\n\nCV\nNur um Zeit zu sparen, setzen wir die Anzahl der Folds auf \\(v=4\\). Besser wäre z.B. \\(v=10\\).\n\ncv_scheme &lt;- vfold_cv(d_train, v = 4)\n\n\n\n\nRezept 1\n\nrec1 &lt;- \n  recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_naomit(all_predictors()) \n\nMan beachte, dass noch 21 Prädiktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (“gebacken”) wurde.\n\ntidy(rec1)\n\n# A tibble: 2 × 6\n  number operation type       trained skip  id              \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;           \n1      1 step      impute_bag FALSE   FALSE impute_bag_3h7s4\n2      2 step      naomit     FALSE   TRUE  naomit_5oazu    \n\n\nRezept checken:\n\nprep(rec1)\n\n\nd_train_baked &lt;-\n  rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\n\nglimpse(d_train_baked)\n\nRows: 3,000\nColumns: 4\n$ budget     &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00, 8.00e+06,…\n$ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.148070, 0.743274…\n$ runtime    &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119, 98, 122, …\n$ revenue    &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970, 3261638, 8…\n\n\nFehlende Werte noch übrig?\n\nlibrary(easystats)\ndescribe_distribution(d_train_baked) %&gt;% \n  select(Variable, n_Missing)\n\nVariable   | n_Missing\n----------------------\nbudget     |         0\npopularity |         0\nruntime    |         0\nrevenue    |         0\n\n\n\n\nModell 1: RF\n\nmodel1 &lt;- rand_forest(mtry = tune(),\n                        trees = tune(),\n                        min_n = tune()) %&gt;% \n            set_engine('ranger') %&gt;% \n            set_mode('regression')\n\n\n\nWorkflow 1\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model1) %&gt;% \n  add_recipe(rec1)\n\n\n\nModell fitten (und tunen)\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\nrf_fit1 &lt;-\n  wf1 %&gt;% \n  tune_grid(resamples = cv_scheme)\ntoc()\n\n27.47 sec elapsed\n\n\nIrgendwelche Probleme oder Hinweise?\n\nrf_fit1[[\".notes\"]][1]\n\n[[1]]\n# A tibble: 0 × 3\n# ℹ 3 variables: location &lt;chr&gt;, type &lt;chr&gt;, note &lt;chr&gt;\n\n\nNein; bei mir nicht jedenfalls.\n\n\nBester Kandidat\n\nselect_best(rf_fit1)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 1 × 4\n   mtry trees min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1  1851    25 Preprocessor1_Model04\n\n\n\n\nWorkflow finalisieren\n\nwf_best &lt;-\n  wf1 %&gt;% \n  finalize_workflow(parameters = select_best(rf_fit1))\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n\n\nFinal Fit\n\nfit1_final &lt;-\n  wf_best %&gt;% \n  fit(d_train)\n\nfit1_final\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_bag()\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), num.trees = ~1851L, min.node.size = min_rows(~25L, x),      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  1851 \nSample size:                      3000 \nNumber of independent variables:  3 \nMtry:                             1 \nTarget node size:                 25 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       6.709961e+15 \nR squared (OOB):                  0.6452598 \n\n\n\npreds &lt;-\n  fit1_final %&gt;% \n  predict(d_test)\n\n\n\nSubmission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n# A tibble: 6 × 2\n     id   revenue\n  &lt;dbl&gt;     &lt;dbl&gt;\n1  3001  4975575.\n2  3002  6349295.\n3  3003 15825986.\n4  3004 38573272.\n5  3005  4449452.\n6  3006 26780034.\n\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\n\n\nKaggle Score\nDiese Submission erzielte einen Score von Score: 2.76961 (RMSLE).\n\nsol &lt;-  2.76961\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/tmdb03/tmdb03.html",
    "href": "posts/tmdb03/tmdb03.html",
    "title": "tmdb03",
    "section": "",
    "text": "Aufgabe\nWir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\n\n\nAufgabe\nReichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n\nSie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.\nVerwenden Sie mehrere, und zwar folgende Algorithmen: Random Forest, Boosting, lineare Regression. Tipp: Ein Workflow-Set ist hilfreich.\nLogarithmieren Sie budget.\nBetreiben Sie Feature Engineering, zumindest etwas. Insbesondere sollten Sie den Monat und das Jahr aus dem Datum extrahieren und als Features (Prädiktoren) nutzen.\nVerwenden Sie tidymodels.\nDie Zielgröße ist revenue in Dollars; nicht in “Log-Dollars”. Sie müssen also rücktransformieren, falls Sie revenue logarithmiert haben.\n\n         \n\n\nLösung\nVorbereitung\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen\n#library(Metrics)\nlibrary(lubridate)  # Datumsangaben\nlibrary(VIM)  # fehlende Werte\nlibrary(visdat)  # Datensatz visualisieren\nlibrary(lubridate)  # Datum/Uhrzeit verarbeiten\nlibrary(doParallel)  # mehrere CPUs nutzen\n\n\nd_train_raw &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nMal einen Blick werfen:\n\nglimpse(d_train_raw)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In…\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol…\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,…\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        &lt;chr&gt; \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco…\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 &lt;chr&gt; \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…\n\n\nTrain-Set verschlanken\n\nd_train &lt;-\n  d_train_raw %&gt;% \n  select(popularity, runtime, revenue, budget, release_date) \n\nDatensatz kennenlernen\n\nlibrary(visdat)\nvis_dat(d_train)\n\n\n\n\n\n\n\n\nFehlende Werte prüfen\nWelche Spalten haben viele fehlende Werte?\n\nvis_miss(d_train)\n\n\n\n\n\n\n\n\nMit {VIM} kann man einen Datensatz gut auf fehlende Werte hin untersuchen:\n\naggr(d_train)\n\n\n\n\n\n\n\n\nRezept definieren\n\nrec1 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  #update_role(all_predictors(), new_role = \"id\") %&gt;% \n  #update_role(popularity, runtime, revenue, budget, original_language) %&gt;% \n  #update_role(revenue, new_role = \"outcome\") %&gt;% \n  step_mutate(budget = if_else(budget &lt; 10, 10, budget)) %&gt;% \n  step_log(budget) %&gt;% \n  step_mutate(release_date = mdy(release_date)) %&gt;% \n  step_date(release_date, features = c(\"year\"), keep_original_cols = FALSE) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_dummy(all_nominal())\n\nrec1\n\n\ntidy(rec1)\n\n# A tibble: 6 × 6\n  number operation type       trained skip  id              \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;           \n1      1 step      mutate     FALSE   FALSE mutate_7GZRr    \n2      2 step      log        FALSE   FALSE log_9bqVu       \n3      3 step      mutate     FALSE   FALSE mutate_bGMkA    \n4      4 step      date       FALSE   FALSE date_mHs3V      \n5      5 step      impute_bag FALSE   FALSE impute_bag_57NLQ\n6      6 step      dummy      FALSE   FALSE dummy_l6So6     \n\n\nCheck das Rezept \n\nprep(rec1, verbose = TRUE)\n\noper 1 step mutate [training] \noper 2 step log [training] \noper 3 step mutate [training] \noper 4 step date [training] \noper 5 step impute bag [training] \noper 6 step dummy [training] \nThe retained training set is ~ 0.1 Mb  in memory.\n\n\n\nd_train_baked &lt;- \nprep(rec1) %&gt;% \n  bake(new_data = NULL) \n\nd_train_baked\n\n# A tibble: 3,000 × 5\n   popularity runtime budget  revenue release_date_year\n        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;             &lt;int&gt;\n 1      6.58       93  16.5  12314651              2015\n 2      8.25      113  17.5  95149435              2004\n 3     64.3       105  15.0  13092000              2014\n 4      3.17      122  14.0  16000000              2012\n 5      1.15      118   2.30  3923970              2009\n 6      0.743      83  15.9   3261638              1987\n 7      7.29       92  16.5  85446075              2012\n 8      1.95       84   2.30  2586511              2004\n 9      6.90      100   2.30 34327391              1996\n10      4.67       91  15.6  18750246              2003\n# ℹ 2,990 more rows\n\n\n\nd_train_baked %&gt;% \n  map_df(~ sum(is.na(.)))\n\n# A tibble: 1 × 5\n  popularity runtime budget revenue release_date_year\n       &lt;int&gt;   &lt;int&gt;  &lt;int&gt;   &lt;int&gt;             &lt;int&gt;\n1          0       0      0       0                 0\n\n\nKeine fehlenden Werte mehr in den Prädiktoren.\nNach fehlenden Werten könnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train_baked)\n\nVariable          |     Mean |       SD |      IQR |              Range | Skewness | Kurtosis |    n | n_Missing\n----------------------------------------------------------------------------------------------------------------\npopularity        |     8.46 |    12.10 |     6.88 | [1.00e-06, 294.34] |    14.38 |   280.10 | 3000 |         0\nruntime           |   107.85 |    22.08 |    24.00 |     [0.00, 338.00] |     1.02 |     8.20 | 3000 |         0\nbudget            |    12.51 |     6.44 |    14.88 |      [2.30, 19.76] |    -0.87 |    -1.09 | 3000 |         0\nrevenue           | 6.67e+07 | 1.38e+08 | 6.66e+07 |   [1.00, 1.52e+09] |     4.54 |    27.78 | 3000 |         0\nrelease_date_year |  2004.58 |    15.48 |    17.00 | [1969.00, 2068.00] |     1.22 |     3.94 | 3000 |         0\n\n\nSo bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\nCheck Test-Sample\nDas Test-Sample backen wir auch mal. Das hat nur den Zwecke, zu prüfen, ob unser Rezept auch richtig funktioniert. Das Preppen und Backen des Test-Samples wir automatisch von predict() bzw. last_fit() erledigt.\nWichtig: Wir preppen den Datensatz mit dem Train-Sample, auch wenn wir das Test-Sample backen wollen.\n\nrec1_prepped &lt;- prep(rec1)\n\nd_test_baked &lt;-\n  bake(rec1_prepped, new_data = d_test)\n\nd_test_baked %&gt;% \n  head()\n\n# A tibble: 6 × 4\n  popularity runtime budget release_date_year\n       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;             &lt;int&gt;\n1       3.85      90   2.30              2007\n2       3.56      65  11.4               2058\n3       8.09     100   2.30              1997\n4       8.60     130  15.7               2010\n5       3.22      92  14.5               2005\n6       8.68     121   2.30              1996\n\n\n\n\nKreuzvalidierung\nNur aus Zeitgründen ist hier \\(v=5\\) eingestellt; besser wäre z.B. \\(v=10\\) und \\(r=3\\).\n\ncv_scheme &lt;- vfold_cv(d_train,\n                      v = 5, \n                      repeats = 1)\n\n\n\nModelle\nBaum\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                mode = \"regression\")\n\nRandom Forest\n\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000,\n              mode = \"regression\") \n\nXGBoost\n\nmod_boost &lt;- boost_tree(mtry = tune(),\n                        min_n = tune(),\n                        trees = tune()) %&gt;% \n  set_mode(\"regression\")\n\nLM\n\nmod_lm &lt;-\n  linear_reg()\n\nWorkflow-Set\n\npreproc &lt;- list(rec1 = rec1)\nmodels &lt;- list(tree1 = mod_tree, \n               rf1 = mod_rf, \n               boost1 = mod_boost, \n               lm1 = mod_lm)\n \nall_workflows &lt;- workflow_set(preproc, models)\n\nFitten und tunen\n\n\nFitten/Tunen\nWenn man das Ergebnis-Objekt abgespeichert hat, dann kann man es einfach laden, spart Rechenzeit (der Tag ist kurz):\n\nresult_obj_file &lt;- \"tmdb_model_set.rds\"\n\n(Davon ausgehend, dass die Datei im Arbeitsverzeichnis liegt.)\nDann könnte man Folgendes machen:\n\nif (file.exists(result_obj_file)) {\n  tmdb_model_set &lt;- read_rds(result_obj_file)\n} else {\n  \n  &lt;computer_workflow_set_and_be_happy&gt;\n  \n}\n\nAchtung Gefährlich! Zwischenspeichern auf der Festplatte birgt die Gefahr, dass man vergisst, das Objekt auf der Festplatte zu aktualisieren und Sie noch in einem Jahr und nach 100 Updates Ihres Rezepts immer noch das uralte Objekt von der Festplatte laden …\nUm Rechenzeit zu sparen, kann man das Ergebnisobjekt abspeichern, dann muss man beim nächsten Mal nicht wieder von Neuem berechnen:\n\n#write_rds(tmdb_model_set, \"objects/tmdb_model_set.rds\")\n\nHier berechnen wir aber lieber das Modell neu:\n\ntic()\ntmdb_model_set &lt;-\n  all_workflows %&gt;% \n  workflow_map(\n    resamples = cv_scheme,\n    #grid = 10,\n    metrics = metric_set(rmse),\n    seed = 42,  # reproducibility\n    control = control_grid(verbose = FALSE))\ntoc()\n\n225.039 sec elapsed\n\n\nOhne Parallelisierung dauerte die Berechnung bei mir knapp 4 Minuten (225 Sec). Ich habe hier auf Parallelisierung verzichtet, da Tidymodels einen Fehler aufwarf mit der Begründung, dass das Paket lubridate in den parallel laufenden Instanzen nicht verfügbar sei (und der parameter pckgs = 'lubridate keine Linderung brachte).\nCheck:\n\ntmdb_model_set[[\"result\"]][[1]]\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits             id    .metrics          .notes          \n  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [2400/600]&gt; Fold1 &lt;tibble [10 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [2400/600]&gt; Fold2 &lt;tibble [10 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [2400/600]&gt; Fold3 &lt;tibble [10 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [2400/600]&gt; Fold4 &lt;tibble [10 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [2400/600]&gt; Fold5 &lt;tibble [10 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n\nFinalisieren\nWelcher Algorithmus schneidet am besten ab?\nGenauer gesagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz.\n\ntune::autoplot(tmdb_model_set)\n\n\n\n\n\n\n\n\nR-Quadrat ist nicht so entscheidend; rmse ist wichtiger.\nDie Ergebnislage ist nicht ganz klar, aber einiges spricht für das Random-Forest-Modell.\n\ntmdb_model_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(mean) %&gt;% \n  slice_head(n = 10)\n\n# A tibble: 10 × 9\n   wflow_id .config        preproc model .metric .estimator   mean     n std_err\n   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.10e7     5  3.37e6\n 2 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.12e7     5  3.37e6\n 3 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.14e7     5  3.29e6\n 4 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.14e7     5  3.56e6\n 5 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.14e7     5  3.42e6\n 6 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.15e7     5  3.43e6\n 7 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.19e7     5  3.55e6\n 8 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.23e7     5  3.67e6\n 9 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.28e7     5  3.66e6\n10 rec1_rf1 Preprocessor1… recipe  rand… rmse    standard   8.30e7     5  3.55e6\n\n\n\nbest_model_params &lt;-\nextract_workflow_set_result(tmdb_model_set, \"rec1_rf1\") %&gt;% \n  select_best()\n\nbest_model_params\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     2    24 Preprocessor1_Model06\n\n\nFinalisieren\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_rf1\")\n\nbest_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_mutate()\n• step_date()\n• step_impute_bag()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nComputational engine: ranger \n\n\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_mutate()\n• step_date()\n• step_impute_bag()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = 2\n  trees = 1000\n  min_n = 24\n\nComputational engine: ranger \n\n\nFinal Fit\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  fit(d_train)\n\nfit_final\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_mutate()\n• step_log()\n• step_mutate()\n• step_date()\n• step_impute_bag()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~2L,      x), num.trees = ~1000, min.node.size = min_rows(~24L, x),      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  1000 \nSample size:                      3000 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 24 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       6.58465e+15 \nR squared (OOB):                  0.6518847 \n\n\n\nd_test$revenue &lt;- NA\n\nfinal_preds &lt;- \n  fit_final %&gt;% \n  predict(new_data = d_test) %&gt;% \n  bind_cols(d_test)\n\nSubmission\n\nsubmission_df &lt;-\n  final_preds %&gt;% \n  select(id, revenue = .pred)\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\nKaggle Score\nDiese Submission erzielte einen Score von 4.79227 (RMSLE).\n\nsol &lt;- 4.79227\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nrandom-forest\nnum"
  },
  {
    "objectID": "posts/tmdb05/tmdb05.html",
    "href": "posts/tmdb05/tmdb05.html",
    "title": "tmdb05",
    "section": "",
    "text": "Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Boosting-Modell mit Tidymodels!\nHinweise\n\n\nFür den Start empfehle ich, etwaige Vorverarbeitung erstmal klein zu halten. Nach dem Motto: Erstmal das Modell zum Laufen kriegen, dann erst verbessern.\nTunen Sie die typischen Parameter.\nReichen Sie das Modell bei Kaggle ein und berichten Sie Ihren Score.\nIm Übrigen sind Sie frei in Ihrem Vorgehen."
  },
  {
    "objectID": "posts/tmdb05/tmdb05.html#rezept-checken",
    "href": "posts/tmdb05/tmdb05.html#rezept-checken",
    "title": "tmdb05",
    "section": "Rezept checken",
    "text": "Rezept checken\n\nd_train_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL)\nd_train_baked\n\n# A tibble: 3,000 × 4\n   budget popularity runtime  revenue\n    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.230    -0.156   -0.673 12314651\n 2  0.472    -0.0177   0.233 95149435\n 3 -0.519     4.61    -0.129 13092000\n 4 -0.576    -0.437    0.640 16000000\n 5 -0.609    -0.604    0.459  3923970\n 6 -0.392    -0.638   -1.13   3261638\n 7 -0.230    -0.0972  -0.718 85446075\n 8 -0.609    -0.538   -1.08   2586511\n 9 -0.609    -0.129   -0.356 34327391\n10 -0.446    -0.313   -0.763 18750246\n# ℹ 2,990 more rows\n\n\nViele Modelle können nicht arbeiten mit nominalen Prädiktoren oder mit fehlenden Werten. Daher sollte man im Rezept diese Fehler vorab abfangen.\nEin letzter Blick:\n\ndescribe_distribution(d_train_baked)\n\nVariable   |      Mean |       SD |      IQR |            Range | Skewness | Kurtosis |    n | n_Missing\n--------------------------------------------------------------------------------------------------------\nbudget     | -1.33e-18 |     1.00 |     0.78 |    [-0.61, 9.65] |     3.10 |    13.23 | 3000 |         0\npopularity | -6.08e-17 |     1.00 |     0.57 |   [-0.70, 23.62] |    14.38 |   280.10 | 3000 |         0\nruntime    |  3.63e-17 |     1.00 |     1.09 |   [-4.88, 10.42] |     1.02 |     8.19 | 2998 |         2\nrevenue    |  6.67e+07 | 1.38e+08 | 6.66e+07 | [1.00, 1.52e+09] |     4.54 |    27.78 | 3000 |         0\n\n\nSieht ok aus."
  },
  {
    "objectID": "posts/tmdb07/tmdb07.html",
    "href": "posts/tmdb07/tmdb07.html",
    "title": "tmdb07",
    "section": "",
    "text": "Aufgabe\nMelden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Lineares-Modell mit Regularisierung mit Tidymodels!\nHinweise\n\n\nVerzichten Sie auf Vorverarbeitung.\nTunen Sie die typischen Parameter.\nReichen Sie das Modell ein und berichten Sie Ihren Score.\nBegrenzen Sie sich auf folgende Prädiktoren.\n\n\npreds_chosen &lt;- \n  c(\"id\", \"budget\", \"popularity\", \"runtime\")\n\n         \n\n\nLösung\n\n\nPakete starten\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(finetune)\nlibrary(doParallel)\nlibrary(tictoc)\n\n\n\nDaten importieren\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nWerfen wir einen Blick in die Daten:\n\nglimpse(d_train)\n\nRows: 3,000\nColumns: 23\n$ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C…\n$ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00…\n$ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '…\n$ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht…\n$ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148…\n$ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", …\n$ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In…\n$ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807…\n$ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh…\n$ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of…\n$ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/…\n$ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol…\n$ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries …\n$ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep…\n$ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,…\n\nglimpse(d_test)\n\nRows: 4,398\nColumns: 22\n$ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, …\n$ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pokémon Collection', 'p…\n$ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06…\n$ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n…\n$ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-…\n$ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595…\n$ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", …\n$ original_title        &lt;chr&gt; \"ディアルガVSパルキアVSダークライ\", \"Attack of t…\n$ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco…\n$ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680…\n$ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1…\n$ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',…\n$ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3…\n$ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11…\n$ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,…\n$ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_…\n$ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", …\n$ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B…\n$ title                 &lt;chr&gt; \"Pokémon: The Rise of Darkrai\", \"Attack of the 5…\n$ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok√©mon'}, {'id': 1155…\n$ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i…\n$ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep…\n\n\n\n\nResampling / Cross-Validation-Scheme\n\ncv_scheme &lt;- vfold_cv(d_train)\n\nKleine Werte für \\(v\\) wie \\(v=3\\) kann man wählen, um Rechenzeit zu sparen. Das ist gerade fürs Debuggen nützlich. Für die “Wirklichkeit” ist ein höherer Wert besser, z.B. \\(v=10\\) (der Defaultwert)\n\n\nRezept\n\nrec1 &lt;- \n  recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% \n  step_impute_bag(all_predictors()) %&gt;% \n  step_naomit(all_predictors()) \nrec1\n\n\n\nModell\n\nmodel_lm &lt;- linear_reg(penalty = tune(),\n                       engine = \"glmnet\")\n\n\n\nWorkflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(model_lm) %&gt;% \n  add_recipe(rec1)\n\n\n\nModell fitten (und tunen)\nParallele Verarbeitung starten:\n\ncl &lt;- makePSOCKcluster(4)  # Create 4 clusters\nregisterDoParallel(cl)\n\n\ntic()\nlm_fit1 &lt;-\n  wf1 %&gt;% \n  tune_race_anova(resamples = cv_scheme)\ntoc()\n\n18.691 sec elapsed\n\n\n\nlm_fit1 %&gt;% show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 7\n   penalty .metric .estimator      mean     n  std_err .config              \n     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                \n1 1.62e-10 rmse    standard   84540989.    10 5365801. Preprocessor1_Model01\n2 3.06e- 9 rmse    standard   84540989.    10 5365801. Preprocessor1_Model02\n3 1.51e- 8 rmse    standard   84540989.    10 5365801. Preprocessor1_Model03\n4 9.21e- 7 rmse    standard   84540989.    10 5365801. Preprocessor1_Model04\n5 2.83e- 6 rmse    standard   84540989.    10 5365801. Preprocessor1_Model05\n\n\n\n\nFinalisieren\n\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(lm_fit1, metric = \"rmse\"))\n\n\n\nFinal Fit\n\nfit1_final &lt;-\n  wf1_final %&gt;% \n  fit(d_train)\n\nfit1_final\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_bag()\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\") \n\n   Df  %Dev    Lambda\n1   0  0.00 103500000\n2   1  9.63  94340000\n3   1 17.62  85960000\n4   1 24.25  78320000\n5   1 29.76  71370000\n6   1 34.33  65030000\n7   1 38.13  59250000\n8   1 41.28  53990000\n9   1 43.90  49190000\n10  1 46.07  44820000\n11  2 48.25  40840000\n12  2 50.48  37210000\n13  2 52.34  33900000\n14  2 53.88  30890000\n15  2 55.15  28150000\n16  2 56.21  25650000\n17  2 57.09  23370000\n18  2 57.82  21290000\n19  2 58.43  19400000\n20  2 58.93  17680000\n21  2 59.35  16110000\n22  2 59.70  14680000\n23  2 59.99  13370000\n24  2 60.23  12180000\n25  2 60.42  11100000\n26  2 60.59  10120000\n27  2 60.73   9217000\n28  2 60.84   8398000\n29  2 60.93   7652000\n30  2 61.01   6973000\n31  2 61.08   6353000\n32  2 61.13   5789000\n33  2 61.18   5274000\n34  2 61.21   4806000\n35  3 61.25   4379000\n36  3 61.29   3990000\n37  3 61.32   3635000\n38  3 61.34   3313000\n39  3 61.36   3018000\n40  3 61.38   2750000\n41  3 61.39   2506000\n42  3 61.40   2283000\n43  3 61.41   2080000\n44  3 61.42   1896000\n45  3 61.43   1727000\n46  3 61.43   1574000\n\n...\nand 12 more lines.\n\n\n\npreds &lt;-\n  fit1_final %&gt;% \n  predict(d_test)\n\n\n\nSubmission df\n\nsubmission_df &lt;-\n  d_test %&gt;% \n  select(id) %&gt;% \n  bind_cols(preds) %&gt;% \n  rename(revenue = .pred)\n\nhead(submission_df)\n\n# A tibble: 6 × 2\n     id   revenue\n  &lt;dbl&gt;     &lt;dbl&gt;\n1  3001 -3508554.\n2  3002 -7712533.\n3  3003  8857329.\n4  3004 31400199.\n5  3005   101521.\n6  3006 13470119.\n\n\nAbspeichern und einreichen:\n\n#write_csv(submission_df, file = \"submission.csv\")\n\n\n\nKaggle Score\nDiese Submission erzielte einen Score von Score: 6.14787 (RMSLE).\n\nsol &lt;- 6.14787\n\n\nCategories:\n\nds1\ntidymodels\nstatlearning\ntmdb\nnum"
  },
  {
    "objectID": "posts/totale-Wskt1/totale-Wskt1.html",
    "href": "posts/totale-Wskt1/totale-Wskt1.html",
    "title": "totale-Wskt1",
    "section": "",
    "text": "Aufgabe\nWas ist die Wahrscheinlichkeit, bei einem Krebstest ein positives Testergebnis (Ereignis \\(T\\)) zu bekommen?\nEs gibt zwei Möglichkeiten für ein positives Testergebnis: Wenn man Krebs hat (\\(K\\)) und wenn man nicht Krebs hat (\\(\\neg K\\)).\n\\(Pr(T|K) = 9/10\\), das ist die “Krebs-Erkenn-Sicherheit” des Tests.\n\\(Pr(T|\\neg K) = 99/891\\), das ist die “Fehlalarm-Quote” des Tests.\nDie Grundrate von Krebs sei \\(Pr(K) = .01\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\nDie Ereignisse \\(K\\) und K$ bilden ein vollständiges Ereignissystem. Daher ist der Satz von der totalen Wahrscheinlichkeit anzuwenden.\n\\(Pr(T) = Pr(T|K) \\cdot Pr(K) + Pr(T| \\neg K) \\cdot Pr(\\neg K)\\).\n\nPr_T_geg_K &lt;- 9/10\nPr_K &lt;- .01\nPr_NK &lt;- 1 - Pr_K  # Wskt für Nicht-Krebs\nPr_T_geg_NK &lt;- 99/891  # ca. 10 Fehlerrate\nPr_T &lt;- Pr_T_geg_K * Pr_K + Pr_T_geg_NK * Pr_NK\nPr_T\n\n[1] 0.119\n\n\nDie Lösung lautet 0.119.\n\nCategories:\n\nR\nprobability\nbayes\nnum"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html",
    "title": "ttest-skalenniveau",
    "section": "",
    "text": "Der t-Test ist ein inferenzstatistisches Verfahren des Frequentismus. Welches Skalenniveau passt zu diesem Verfahren?\nHinweisse:\n\nDie folgende Abbildung gibt Tipps.\nInformationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist",
    "title": "ttest-skalenniveau",
    "section": "",
    "text": "UV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist-1",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist-1",
    "title": "ttest-skalenniveau",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nttest\nregression\nvariable-levels"
  },
  {
    "objectID": "posts/twitter02/twitter02.html",
    "href": "posts/twitter02/twitter02.html",
    "title": "twitter02",
    "section": "",
    "text": "Exercise\nLaden Sie die neuesten Tweets an karl_lauterbach herunter - und zwar so viele wie auf einmal möglich.\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rtweet)\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\nAus der Hilfe zu search_tweets:\nDescription\nReturns Twitter statuses matching a user provided search query. ONLY RETURNS DATA FROM THE PAST 6-9 DAYS.\nTweets an Karl Lauterbach suchen:\n\nkarl_tweets &lt;- search_tweets(q = \"@karl_lauterbach\", n = 150000, retryonratelimit = TRUE)\n\nWir könnten n auch auf Inf setzen, aber, da wir auf das Refreshen des Rate Limits warten müssen, könnte sehr lange dauern. Daher nehmen wir hier nur einen kürzeren Wert.\n\ndim(karl_tweets)\n\n[1] 18000    43\n\nhead(karl_tweets)\n\n# A tibble: 6 × 43\n  created_at               id id_str      full_…¹ trunc…² displ…³ entities     metad…⁴\n  &lt;dttm&gt;                &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;list&gt;       &lt;list&gt; \n1 2022-10-23 13:30:18 1.58e18 1584145185… \"Bei ⁦@… FALSE       122 &lt;named list&gt; &lt;df&gt;   \n2 2022-10-22 18:34:37 1.58e18 1583859379… \"Es is… FALSE       263 &lt;named list&gt; &lt;df&gt;   \n3 2022-10-22 17:56:39 1.58e18 1583849826… \"Die S… FALSE       215 &lt;named list&gt; &lt;df&gt;   \n4 2022-10-24 08:10:35 1.58e18 1584427113… \"Zu we… FALSE       219 &lt;named list&gt; &lt;df&gt;   \n5 2022-10-24 08:10:35 1.58e18 1584427113… \"RT @K… FALSE       140 &lt;named list&gt; &lt;df&gt;   \n6 2022-10-24 08:10:25 1.58e18 1584427072… \"RT @U… FALSE       139 &lt;named list&gt; &lt;df&gt;   \n# … with 35 more variables: source &lt;chr&gt;, in_reply_to_status_id &lt;dbl&gt;,\n#   in_reply_to_status_id_str &lt;chr&gt;, in_reply_to_user_id &lt;dbl&gt;,\n#   in_reply_to_user_id_str &lt;chr&gt;, in_reply_to_screen_name &lt;chr&gt;, geo &lt;list&gt;,\n#   coordinates &lt;list&gt;, place &lt;list&gt;, contributors &lt;lgl&gt;, is_quote_status &lt;lgl&gt;,\n#   retweet_count &lt;int&gt;, favorite_count &lt;int&gt;, favorited &lt;lgl&gt;, retweeted &lt;lgl&gt;,\n#   possibly_sensitive &lt;lgl&gt;, lang &lt;chr&gt;, quoted_status_id &lt;dbl&gt;,\n#   quoted_status_id_str &lt;chr&gt;, quoted_status &lt;list&gt;, retweeted_status &lt;list&gt;, …\n# ℹ Use `colnames()` to see all variable names\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/twitter04/twitter04.html",
    "href": "posts/twitter04/twitter04.html",
    "title": "twitter04",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=2\\)) via der Twitter API; Suchterm soll sein “(karl_lauterbach?)”. Bereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopwörter entfernen, Zahlen entfernen, …). Berichten Sie dann die 10 häufigsten Wörter als Schätzer für die Dinge, die an Karl Lauterbach getweetet werden.\n         \n\n\nSolution\n\nlibrary(rtweet)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n\nLoading required package: SnowballC\n\nlibrary(SnowballC)  # Stemming\n\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\n\nkarl1 &lt;- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(karl1, file = \"karl1.rds\", compress = \"gz\")\n\n\nkarl2 &lt;- \n  karl1 %&gt;% \n  select(full_text)\n\n\nkarl3 &lt;- \n  karl2 %&gt;% \n  unnest_tokens(output = word, input = full_text)\n\n\nkarl4 &lt;- \nkarl3 %&gt;% \n  anti_join(tibble(word = lsa::stopwords_de)) \n\nJoining with `by = join_by(word)`\n\n\n\nkarl5 &lt;- \n  karl4 %&gt;% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %&gt;% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %&gt;% \n  mutate(word = str_replace_na(word, \" +\")) %&gt;% \n  drop_na()\n\n\nkarl6 &lt;-\n  karl5 %&gt;% \n  mutate(word = wordStem(word))\n\n\nkarl6 %&gt;% \n  count(word, sort = TRUE) %&gt;% \n  slice_head(n=10)\n\n# A tibble: 10 × 2\n   word                       n\n   &lt;chr&gt;                  &lt;int&gt;\n 1 karl_lauterbach          100\n 2 rt                        60\n 3 ultrakaerl                19\n 4 corona                    16\n 5 wirwollenmaskenpflicht    16\n 6 länder                    12\n 7 gesundheitsminist         11\n 8 polarstern64              11\n 9 schon                     11\n10 shomburg                  11\n\n\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/twitter06/twitter06.html",
    "href": "posts/twitter06/twitter06.html",
    "title": "twitter06",
    "section": "",
    "text": "Exercise\nLaden Sie \\(n=10^k\\) Tweets von Twitter herunter (mit \\(k=4\\)) via der Twitter API; die Tweets sollen jeweils an eine prominente Person gerichtet sein.\nBeziehen Sie sich auf folgende Personen bzw. Twitter-Accounts:\n\nMarkus_Soeder\nkarl_lauterbach.\n\nBereiten Sie die Textdaten mit grundlegenden Methoden des Textminings auf (Tokenisieren, Stopwörter entfernen, Zahlen entfernen, …).\nNutzen Sie die Daten dann, um eine Sentimentanalyse zu erstellen.\nVergleichen Sie die Ergebnisse für alle untersuchten Personen.\n         \n         \n\n\nSolution\n\nlibrary(rtweet)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n\nLoading required package: SnowballC\n\nlibrary(SnowballC)  # Stemming\n\n\ndata(sentiws, package = \"pradadata\")\n\nZuerst muss man sich anmelden und die Tweets herunterladen:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nauth &lt;- rtweet_app(bearer_token = Bearer_Token)\n\n\ntweets_to_kl &lt;- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(tweets_to_kl, file = \"tweets_to_kl.rds\", compress = \"gz\")\ntweets_to_ms &lt;- search_tweets(\"@Markus_Soeder\", n = 1e4, include_rts = FALSE)\n#write_rds(tweets_to_ms, file = \"tweets_to_ms.rds\", compress = \"gz\")\n\nDie Vorverarbeitung pro Screenname packen wir in eine Funktion, das macht es hinten raus einfacher:\n\nprepare_tweets &lt;- function(tweets){\n  \n  tweets %&gt;% \n    select(full_text) %&gt;% \n    unnest_tokens(output = word, input = full_text) %&gt;% \n    anti_join(tibble(word = lsa::stopwords_de)) %&gt;% \n    mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %&gt;% \n    mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %&gt;% \n    mutate(word = str_replace_na(word, \" +\")) %&gt;% \n    drop_na()\n}\n\nTest:\n\nkl_prepped &lt;- \n  prepare_tweets(tweets_to_kl_raw)\n\nJoining with `by = join_by(word)`\n\nhead(kl_prepped)\n\n# A tibble: 6 × 1\n  word                     \n  &lt;chr&gt;                    \n1 tonline⁩                  \n2 spreche                  \n3 neuen                    \n4 pläne                    \n5 bundesgesundheitsminister\n6 karl_lauterbach⁩          \n\n\n\nms_prepped &lt;-\n  prepare_tweets(tweets_to_ms_raw)\n\nJoining with `by = join_by(word)`\n\nhead(ms_prepped)\n\n# A tibble: 6 × 1\n  word         \n  &lt;chr&gt;        \n1 markus_soeder\n2 climate      \n3 activists    \n4 are          \n5 sometimes    \n6 depicted     \n\n\nScheint zu passen.\nDie Sentimentanalyse packen wir auch in eine Funktion:\n\nget_tweets_sentiments &lt;- function(tweets){\n  \n  tweets %&gt;% \n    inner_join(sentiws) %&gt;% \n    group_by(neg_pos) %&gt;% \n    summarise(senti_avg = mean(value, na.rm = TRUE),\n              senti_sd = sd(value, na.rm = TRUE),\n              senti_n = n()) \n}\n\nTest:\n\nkl_prepped %&gt;% \n  get_tweets_sentiments()\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., sentiws): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6649 of `x` matches multiple rows in `y`.\nℹ Row 3102 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n\n\nTest:\n\ntweets_to_kl_raw %&gt;% \n  prepare_tweets() %&gt;% \n  get_tweets_sentiments()\n\nJoining with `by = join_by(word)`\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., sentiws): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6649 of `x` matches multiple rows in `y`.\nℹ Row 3102 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n\n\nScheint zu passen.\nWir könnten noch die beiden Funktionen in eine wrappen:\n\nprep_sentiments &lt;- function(tweets) {\n\n  tweets %&gt;% \n    prepare_tweets() %&gt;% \n    get_tweets_sentiments()\n}\n\n\ntweets_to_kl_raw %&gt;% \n  prep_sentiments()\n\nJoining with `by = join_by(word)`\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., sentiws): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6649 of `x` matches multiple rows in `y`.\nℹ Row 3102 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n\n\nOkay, jetzt werden wir die Funktion auf jede Screenname bzw. die Tweets jedes Screennames an.\n\ntweets_list &lt;-\n  list(\n    kl = tweets_to_kl_raw, \n    ms = tweets_to_ms_raw)\n\n\nsentis &lt;-\n  tweets_list %&gt;% \n  map_df(prep_sentiments, .id = \"id\")\n\nJoining with `by = join_by(word)`\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., sentiws): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6649 of `x` matches multiple rows in `y`.\nℹ Row 3102 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nJoining with `by = join_by(word)`\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., sentiws): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 17223 of `x` matches multiple rows in `y`.\nℹ Row 2894 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nCategories:\n\ntextmining\ntwitter\nprogramming"
  },
  {
    "objectID": "posts/Typ-Fehler-R-01/Typ-Fehler-R-01.html",
    "href": "posts/Typ-Fehler-R-01/Typ-Fehler-R-01.html",
    "title": "Typ-Fehler-R-01",
    "section": "",
    "text": "Aufgabe\nKorrigieren Sie den Fehler in der Syntax:\n\nmean(x = c(1, 5, 10, 52)\n\nÄndern Sie nur diejenigen Teile der Syntax, die zwingend geändert werden müssen, damit der Fehler korrigiert wird.\nGeben Sie in der Lösung keine Leerzeichen ein.\n         \n\n\nLösung\n\nmean(x=c(1,5,10,52))\n\n[1] 17\n\n\nDie Antwort lautet: mean(x=c(1,5,10,52)).\n\nCategories:\n\nR\n‘2023’\nstring"
  },
  {
    "objectID": "posts/Typ-Fehler-R-03/Typ-Fehler-R-03.html",
    "href": "posts/Typ-Fehler-R-03/Typ-Fehler-R-03.html",
    "title": "Typ-Fehler-R-03",
    "section": "",
    "text": "Aufgabe\nGegeben sei diese Syntax:\n\nx &lt;- 42\nY &lt;- 1\n\nLässt man folgende Syntax laufen, so kommt eine Fehlermeldung:\n\nX + Y\n\nError in eval(expr, envir, enclos): object 'X' not found\n\n\nGeben Sie die korrekte Syntax ein (zur Berechnung der Summe), die nicht zu einer Fehlermeldung führt!\nBitte verwenden Sie keine Leerzeichen bei Ihrer Eingabe.\n         \n\n\nLösung\n\nx+Y\n\n[1] 43\n\n\nDie Antwort lautet: x+Y.\n\nCategories:\nstring"
  },
  {
    "objectID": "posts/Typ-Fehler-R-06a/Typ-Fehler-R-06a.html",
    "href": "posts/Typ-Fehler-R-06a/Typ-Fehler-R-06a.html",
    "title": "Typ-Fehler-R-06a",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgende R-Syntax, für die R eine Fehlermeldung ausgibt:\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x) - x)))\n\nError: &lt;text&gt;:2:22: unexpected ')'\n1: x &lt;- c(1, 2, 3)\n2: sum(abs(mean(x) - x)))\n                        ^\n\n\nGeben Sie die korrekte Syntax an! Ändern Sie nur die notwendigen Zeichen an der Syntax oben. Gehen Sie davon aus, dass die aufgerufenen Funktionen existieren.\nGeben Sie keine Leerzeichen ein.\n         \n\n\nLösung\nHinten ist eine (schließende) Klammer zu viel, die muss weg:\n\nsum(abs(mean(x)-x))  # so geht's\n\nError in mean(x): object 'x' not found\n\n\nDie Antwort lautet: sum(abs(mean(x)-x)).\n\nCategories:\n\nR\n‘2023’\nstring"
  },
  {
    "objectID": "posts/Typ-Fehler-R-08-name-clash/Typ-Fehler-R-08-name-clash.html",
    "href": "posts/Typ-Fehler-R-08-name-clash/Typ-Fehler-R-08-name-clash.html",
    "title": "Typ-Fehler-R-08-name-clash",
    "section": "",
    "text": "Aufgabe\nR spuckt eine komische Fehlermeldung aus. Was ist nur los? Hat R einen schlechten Tag?\nSchauen wir uns die Sache näher an:\n\nlibrary(dplyr)\nlibrary(MASS)\n\nmtcars_small &lt;-\n  mtcars %&gt;% \n  select(hp, am)\n\nError in select(., hp, am): unused arguments (hp, am)\n\n\nOh nein! Fehler!\nWas ist nur los?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\nDas Problem ist, dass es in beiden Paketen, {MASS} und {dplyr} (dasjenige Paket im tidyverse, in dem select() wohnt), eine Funktion namens select vorhanden ist.\nEs kommt zu einem “Name Clash”, einer Namenskollision.\nWenn mehrere Funktion gleichen Namens geladen (“attached”) sind, so “gewinnt” diejenige Funktion, die als letztes geladen wurde, in unserem Fall ist das die Funktion aus {MASS}.\nEs gibt eine Reihe von Lösungen.\n\nNur das benötigte Paket starten\n\nZuerst “entladen” wir MASS, da wir es nicht benötigen:\n\ndetach(\"package:MASS\", unload = TRUE)\n\nAlternativ (und einfacher) könnten wir R neu starten: Session &gt; Restart R.\n\nlibrary(dplyr)\n#library(MASS)\n\nmtcars %&gt;% \n  select(hp, am)\n\n                     hp am\nMazda RX4           110  1\nMazda RX4 Wag       110  1\nDatsun 710           93  1\nHornet 4 Drive      110  0\nHornet Sportabout   175  0\nValiant             105  0\nDuster 360          245  0\nMerc 240D            62  0\nMerc 230             95  0\nMerc 280            123  0\nMerc 280C           123  0\nMerc 450SE          180  0\nMerc 450SL          180  0\nMerc 450SLC         180  0\nCadillac Fleetwood  205  0\nLincoln Continental 215  0\nChrysler Imperial   230  0\nFiat 128             66  1\nHonda Civic          52  1\nToyota Corolla       65  1\nToyota Corona        97  0\nDodge Challenger    150  0\nAMC Javelin         150  0\nCamaro Z28          245  0\nPontiac Firebird    175  0\nFiat X1-9            66  1\nPorsche 914-2        91  1\nLotus Europa        113  1\nFord Pantera L      264  1\nFerrari Dino        175  1\nMaserati Bora       335  1\nVolvo 142E          109  1\n\n\nUnd schon geht’s!\n\nPaketnamen vor Funktionsnamen anfügen\n\n\n#library(dplyr)\n#library(MASS)\n\nmtcars %&gt;% \n  dplyr::select(hp, am) %&gt;% \n  dplyr::filter(hp &gt; 200)\n\n                     hp am\nDuster 360          245  0\nCadillac Fleetwood  205  0\nLincoln Continental 215  0\nChrysler Imperial   230  0\nCamaro Z28          245  0\nFord Pantera L      264  1\nMaserati Bora       335  1\n\n\n\nPaket conflicted nutzen\n\nHier gibt’s dazu nähere Infos.\n\nCategories:\n\nR\nerror\nstring"
  },
  {
    "objectID": "posts/Urne1/Urne1.html",
    "href": "posts/Urne1/Urne1.html",
    "title": "Urne1",
    "section": "",
    "text": "Aufgabe\nIn einer Urne befinden sich fünf Kugeln, von denen 4 rot sind und 1 weiß.\nAufgabe: Wie groß ist die Wahrscheinlichkeit, dass bei 2 Ziehungen ohne Zurücklegen (ZoZ) genau 2 rote Kugeln gezogen werden?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\nSei \\(R1\\) “rote Kugel im 1. Zug gezogen”.\nSei \\(R2\\) “rote Kugel im 2. Zug gezogen”.\nGesucht ist die gemeinsame Wahrscheinlichkeit für R1 und R2: \\(Pr(R1 \\cap R2)\\), die Wahrscheinlichkeit also, dass beide Ereignisse (R1 und R2) eintreten.\nFür R1 gilt: \\(Pr(R1) = 4/5\\).\nFür R2 gilt: \\(Pr(R2|R1) = 3/4\\).\nMan beachte, dass R1 und R2 nicht unabhängig sind, d.h. sie sind abhängig (voneinander).\n\nPr_R1 &lt;- 4/5\nPr_R2_geg_R1 &lt;- 3/4\nPr_R1_R2 &lt;- Pr_R1 * Pr_R2_geg_R1\nPr_R1_R2\n\n[1] 0.6\n\n\nDie Lösung lautet 0.6.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/Var-vs-Stufe/Var-vs-Stufe.html",
    "href": "posts/Var-vs-Stufe/Var-vs-Stufe.html",
    "title": "Var-vs-Stufe",
    "section": "",
    "text": "Für ein Forschungsprojekt hat ein Forschungsteam die Frage getestet, ob Personen, die einen animierten Graphen zu Auswirkungen von Stress gesehen haben danach eine höhere Motivation haben ihr Stresspensum anzugehen, als Personen, die einen statischen Graph gesehen haben. Dazu wurde jeweils in einem Fragebogen die Veränderungsbereitschaft auf das Stressniveau angepasst abgefragt, dann den jeweiligen Graphen gezeigt und danach dieselben Fragen wie davor nochmals gestellt.\nZur Auswertung wurde nun zu jeder der Fragen zur Veränderungsbereitschaft die Mittelwerte der Vor-sehen-des-Graphen-Gruppe von der Nach-sehen-des-Graphen-Gruppe abgezogen und diese Werte dann verglichen von dem animierten und dem statischen Graphen. Dabei konnte der gewünschten Effekt deutlich erkannt werden, hypothesenkonform.\nNun kommt dem Forschungsteam folgender Zweifel auf:\nOder wäre die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nJa, es wäre richtig gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nNein, es wäre falsch gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nBeide Sichtweisen sind möglich (entweder jeweils als einzelne Variable oder als ingesamt eine einzelne Variable)\nAuf Basis des dargestellten Forschungsdesigns ist diese Frage nicht zu beantworten"
  },
  {
    "objectID": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist",
    "href": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist",
    "title": "Var-vs-Stufe",
    "section": "",
    "text": "Ja, es wäre richtig gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nNein, es wäre falsch gewesen, die animierte und die statische Graphdarstellung jeweils als einzelne Variable zu betrachten.\nBeide Sichtweisen sind möglich (entweder jeweils als einzelne Variable oder als ingesamt eine einzelne Variable)\nAuf Basis des dargestellten Forschungsdesigns ist diese Frage nicht zu beantworten"
  },
  {
    "objectID": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist-1",
    "href": "posts/Var-vs-Stufe/Var-vs-Stufe.html#answerlist-1",
    "title": "Var-vs-Stufe",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nfopro\nresearchdesign\nschoice"
  },
  {
    "objectID": "posts/variation02/variation02.html",
    "href": "posts/variation02/variation02.html",
    "title": "variability02",
    "section": "",
    "text": "In welchem Datensatz (x1-x4) gibt es am meisten Variation?\nDatensatz A:\n\n\n\n\n\n\n\n\n\nDatensatz B:\n\n\n\n\n\n\n\n\n\nDatensatz C:\n\n\n\n\n\n\n\n\n\nDatensatz D:\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD"
  },
  {
    "objectID": "posts/variation02/variation02.html#answerlist",
    "href": "posts/variation02/variation02.html#answerlist",
    "title": "variability02",
    "section": "",
    "text": "A\nB\nC\nD"
  },
  {
    "objectID": "posts/variation02/variation02.html#answerlist-1",
    "href": "posts/variation02/variation02.html#answerlist-1",
    "title": "variability02",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nvariablity\nbasics\nschoice"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html",
    "href": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html",
    "title": "Verteilungen-Quiz-02",
    "section": "",
    "text": "Beziehen Sie sich auf den Standard-Globusversuch mit \\(N=9\\) Würfen und \\(W=6\\) Wassertreffern (binomialverteilt).\nAufgabe: Ist es (auf dieser Basis) plausibler von einem 50%-PI [.6,.8] auszugehen als von einem 50%-PI [.05,.95]?\n\n\n  Ja    Nein    Keine Antwort möglich \n\nAntworten"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html#answerlist",
    "href": "posts/Verteilungen-Quiz-02/Verteilungen-Quiz-02.html#answerlist",
    "title": "Verteilungen-Quiz-02",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html",
    "href": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html",
    "title": "Verteilungen-Quiz-04",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nIst eine stetige Verteilung symmetrisch, dann ist sie normalverteilt.\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist",
    "href": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist",
    "title": "Verteilungen-Quiz-04",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-04/Verteilungen-Quiz-04.html#answerlist-1",
    "title": "Verteilungen-Quiz-04",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html",
    "href": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html",
    "title": "Verteilungen-Quiz-06",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\ge 100) \\ne 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist",
    "href": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist",
    "title": "Verteilungen-Quiz-06",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-06/Verteilungen-Quiz-06.html#answerlist-1",
    "title": "Verteilungen-Quiz-06",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html",
    "href": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html",
    "title": "Verteilungen-Quiz-08",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X \\ge 115) \\approx 0.16\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist",
    "href": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist",
    "title": "Verteilungen-Quiz-08",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-08/Verteilungen-Quiz-08.html#answerlist-1",
    "title": "Verteilungen-Quiz-08",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html",
    "href": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html",
    "title": "Verteilungen-Quiz-10",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nSei \\(X \\sim N(100,15)\\), dann ist \\(Pr(X = \\bar{x}) = 1/2\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist",
    "href": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist",
    "title": "Verteilungen-Quiz-10",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-10/Verteilungen-Quiz-10.html#answerlist-1",
    "title": "Verteilungen-Quiz-10",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html",
    "href": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html",
    "title": "Verteilungen-Quiz-12",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nBei einer symmetrischen Verteilung gilt: \\(\\bar{x} = Md = \\text{Modus}\\).\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html#answerlist",
    "href": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html#answerlist",
    "title": "Verteilungen-Quiz-12",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-12/Verteilungen-Quiz-12.html#answerlist-1",
    "title": "Verteilungen-Quiz-12",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html",
    "href": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html",
    "title": "Verteilungen-Quiz-14",
    "section": "",
    "text": "Ist folgende Aussage wahr?\nBeim Perzentilintervall (PI) werden “links” und “rechts” die gleiche Wahrscheinlichkeitsmasse von einer Verteilung “abgeschnitten”.\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist",
    "href": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist",
    "title": "Verteilungen-Quiz-14",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-14/Verteilungen-Quiz-14.html#answerlist-1",
    "title": "Verteilungen-Quiz-14",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html",
    "href": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html",
    "title": "Verteilungen-Quiz-16",
    "section": "",
    "text": "Für die mittlere Körpergröße des deutschen Mannes \\(X\\) gelte \\(X \\sim N(180,06)\\) (in Zentimetern).\nQuelle Mittelwert Quelle SD geschätzt\nÄhnliche Daten finden sich bei Our World in Data.\nAufgabe: Ist folgende Aussage wahr?\nDas 50%-Quantil von \\(X\\) beträgt 180.\n\n  Ja    Nein \n\n\nAntworten"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html#answerlist",
    "href": "posts/Verteilungen-Quiz-16/Verteilungen-Quiz-16.html#answerlist",
    "title": "Verteilungen-Quiz-16",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html",
    "href": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html",
    "title": "Verteilungen-Quiz-18",
    "section": "",
    "text": "Ei Forschi untersucht den Effekt eines Intelligenztraining auf den IQ.\nDabei findet sich aposteriori (also als Ergebnis der Untersuchung) \\(\\bar{x} \\sim N(3,5)\\) (in Standard-IQ-Punkten). Wir messen dabei die Erhöhung des Intelligenzwerts.\nDis Forschi resümiert: “Mit einer Wahrscheinlichkeit von 95% profitiert man von diesem Training”.\nIst diese Aussage korrekt (gegeben der Angaben)?\nHinweise:\n\nNutzen Sie Simulationsmethoden zur Lösung\nFixieren Sie die Zufallszahlen auf die Startzahl 42.\nZiehen Sie \\(10^5\\) Zufallszahlen aus der gegebenen Verteilung.\n\n\n\n\nJa\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist",
    "href": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist",
    "title": "Verteilungen-Quiz-18",
    "section": "",
    "text": "Ja\nNein"
  },
  {
    "objectID": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist-1",
    "href": "posts/Verteilungen-Quiz-18/Verteilungen-Quiz-18.html#answerlist-1",
    "title": "Verteilungen-Quiz-18",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\ndistributions\nVerteilungen-Quiz\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/vis-mariokart-variab/vis-mariokart-variab.html",
    "href": "posts/vis-mariokart-variab/vis-mariokart-variab.html",
    "title": "vis-mariokart-variab",
    "section": "",
    "text": "Aufgabe\nIm Datensatz mariokart:\nVisualisieren Sie die Streuung der Variablen total_pr.\n         \n\n\nLösung\nPakete starten:\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✔ datawizard  0.9.0    ✔ effectsize  0.8.6 \n✔ insight     0.19.6   ✔ modelbased  0.8.6 \n✔ performance 0.10.8   ✔ parameters  0.21.3\n✔ report      0.5.7    ✖ see         0.8.0 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidyverse)  # startet das Paket tidyverse\nlibrary(DataExplorer)  # Data-Vis\nlibrary(ggpubr)  # Data-Vis\n\n\nAttaching package: 'ggpubr'\n\n\nThe following objects are masked from 'package:datawizard':\n\n    mean_sd, median_mad\n\n\nDaten importieren:\n\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nOder so:\n\ndata(mariokart, package = \"openintro\")  # aus dem Paket \"openintro\"\n\nDazu muss das Paket openintro auf Ihrem Computer installiert sein.\nVisualisieren:\nMit dataExplorer:\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  plot_density()  # oder \"plot_histogram()\"\n\n\n\n\n\n\n\n\nMit ggpubr:\n\ngghistogram(mariokart, x = \"total_pr\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`.\n\n\n\n\n\n\n\n\n\nMit ggplot:\n\nmariokart %&gt;% \n  ggplot(aes(x = total_pr)) +\n  geom_density()  # oder \"geom_histogram()\"\n\n\n\n\n\n\n\n\nFalls Sie Teile der R-Syntax nicht kennen: Im Zweifel einfach ignorieren :-)\n\nCategories:\n\ndatawrangling\neda\ntidyverse\nvis\nvariability\nstring"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html",
    "href": "posts/vis-penguins/vis-penguins.html",
    "title": "vis-penguins",
    "section": "",
    "text": "In dieser Fallstudie (YACSDA: Yet another Case Study on Data Analysis) untersuchen wir den Datensatz penguins.\nSie können den Datensatz so beziehen:\n\n#install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(\"penguins\")\nd &lt;- penguins \n\nOder so:\n\nd &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nEin Codebook finden Sie hier.\nDie Forschungsfrage lautet:\nWas ist der Einfluss der Spezies und der Schnabellänge auf das Körpergewicht?\n\nAbhängige Variable (metrisch), y: Körpergewicht\nUnabhängige Variable 1 (nominal), x1: Spezies\nUnabhängige Variable 2 (metrisch), x2: Schnabellänge\n\nVisualisieren Sie dazu folgende Aspekte der Forschungsfrage!\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#umbenennen",
    "href": "posts/vis-penguins/vis-penguins.html#umbenennen",
    "title": "vis-penguins",
    "section": "Umbenennen",
    "text": "Umbenennen\nFür weniger Tippen nenne ich die Variablen um:\n\nd &lt;-\n  d |&gt; \n  rename(y = body_mass_g, x1 = species, x2 = bill_length_mm)\n\nDas ist aber nicht unbedingt nötig und bringt auch vielleicht keinen Vorteil für Sie."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-auf-zwei-verschiedene-arten.",
    "title": "vis-penguins",
    "section": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.",
    "text": "Visualisieren Sie die Verteilung von y auf zwei verschiedene Arten.\nDas R-Paket ggpubr erstellt schöne Diagramme (basierend auf ggplot) auf einfache Art. Nehmen wir ein Dichtediagramm; die Variable y soll auf der X-Achse stehen:\n\nggdensity(d, x = \"y\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable in Anführungsstriche gesetzt werden muss: x = \"y\".\nOder ein Histogramm:\n\ngghistogram(d, x = \"y\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nAlternativ könnte man das R-Paket {DataExplorer} verwenden:\n\nd |&gt; \n  select(y) |&gt; \n  plot_density()"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#fügen-sie-relevante-kennzahlen-hinzu.",
    "href": "posts/vis-penguins/vis-penguins.html#fügen-sie-relevante-kennzahlen-hinzu.",
    "title": "vis-penguins",
    "section": "Fügen Sie relevante Kennzahlen hinzu.",
    "text": "Fügen Sie relevante Kennzahlen hinzu.\nUm Diagramme mit Statistiken anzureichen, bietet sich das Paket {ggstatsplot} an:\n\ngghistostats(d, x = y)\n\n\n\n\n\n\n\n\nBeachten Sie, dass die Variable nicht in Anführungsstriche gesetzt werden darf: x = y.\nNatürlich könnte man sich typische deskriptive Statistiken auch anderweitig ausgeben lassen, etwa mit {easystats}:\n\nd |&gt; \n  select(y) |&gt; \n  describe_distribution()\n\nVariable |    Mean |     SD |     IQR |              Range | Skewness | Kurtosis |   n | n_Missing\n--------------------------------------------------------------------------------------------------\ny        | 4201.75 | 801.95 | 1206.25 | [2700.00, 6300.00] |     0.47 |    -0.72 | 342 |         2"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-x1-und-x2.",
    "title": "vis-penguins",
    "section": "Visualisieren Sie die Verteilung von x1 und x2.",
    "text": "Visualisieren Sie die Verteilung von x1 und x2.\n\nx1\nMit ggpubr:\n\nd_counted &lt;- \n  d |&gt; \n  count(x1) \n\n\nggbarplot(data = d_counted, y = \"n\", x = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMit DataExplorer:\n\nd |&gt; \n  select(x1) |&gt; \n  plot_bar()\n\n\n\n\n\n\n\n\n\n\nx2\n\ngghistostats(d, x = x2)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-die-verteilung-von-y-bedingt-auf-x1",
    "title": "vis-penguins",
    "section": "Visualisieren Sie die Verteilung von y bedingt auf x1",
    "text": "Visualisieren Sie die Verteilung von y bedingt auf x1\n\ngghistogram(d, x = \"y\", fill = \"x1\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nOder so:\n\ngghistogram(d, x = \"y\", facet.by = \"x1\")\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`)."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "href": "posts/vis-penguins/vis-penguins.html#fügen-sie-relevante-kennzahlen-zur-letzten-visualisierung-hinzu",
    "title": "vis-penguins",
    "section": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu",
    "text": "Fügen Sie relevante Kennzahlen zur letzten Visualisierung hinzu\n\ngrouped_gghistostats(d, x = y, grouping.var = x1)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "href": "posts/vis-penguins/vis-penguins.html#visualisieren-sie-den-zusammenhang-von-y-und-x2",
    "title": "vis-penguins",
    "section": "Visualisieren Sie den Zusammenhang von y und x2",
    "text": "Visualisieren Sie den Zusammenhang von y und x2\n\nggscatter(d, x = \"x2\", y = \"y\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#verbessern-sie-das-letzte-diagramm-so-dass-es-übersichtlicher-wird",
    "href": "posts/vis-penguins/vis-penguins.html#verbessern-sie-das-letzte-diagramm-so-dass-es-übersichtlicher-wird",
    "title": "vis-penguins",
    "section": "Verbessern Sie das letzte Diagramm, so dass es übersichtlicher wird",
    "text": "Verbessern Sie das letzte Diagramm, so dass es übersichtlicher wird\nEs gibt mehrere Wege, das Diagramm übersichtlicher zu machen. Logarithmieren ist ein Weg.\n\nd |&gt; \n  mutate(x2 = log(x2)) |&gt; \n  ggscatter(x = \"x2\", y = \"y\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nSynonym könnten wir schreiben:\n\nd_logged &lt;- \n  d |&gt; \n  mutate(x2 = log(x2))\n  \n\nggscatter(d_logged, x = \"x2\", y = \"y\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#fügen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "href": "posts/vis-penguins/vis-penguins.html#fügen-sie-dem-letzten-diagramm-relevante-kennzahlen-hinzu",
    "title": "vis-penguins",
    "section": "Fügen Sie dem letzten Diagramm relevante Kennzahlen hinzu",
    "text": "Fügen Sie dem letzten Diagramm relevante Kennzahlen hinzu\n\nggscatterstats(d_logged, x = x2, y = y)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#fügen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "href": "posts/vis-penguins/vis-penguins.html#fügen-sie-dem-diagramm-zum-zusammenhang-von-y-und-x2-eine-regressionsgerade-hinzu",
    "title": "vis-penguins",
    "section": "Fügen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu",
    "text": "Fügen Sie dem Diagramm zum Zusammenhang von y und x2 eine Regressionsgerade hinzu\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"reg.line\", \n             add.params = list(color = \"blue\"))\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "href": "posts/vis-penguins/vis-penguins.html#ersetzen-sie-die-regressionsgerade-durch-eine-loess-gerade",
    "title": "vis-penguins",
    "section": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade",
    "text": "Ersetzen Sie die Regressionsgerade durch eine LOESS-Gerade\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"))\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "href": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-x1",
    "title": "vis-penguins",
    "section": "Gruppieren Sie das letzte Diagramm nach x1",
    "text": "Gruppieren Sie das letzte Diagramm nach x1\n\nggscatter(d_logged, x = \"x2\", y = \"y\", add = \"loess\", \n             add.params = list(color = \"blue\"),\n          facet.by = \"x1\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#dichotomisieren-sie-y-und-zählen-sie-die-häufigkeiten",
    "href": "posts/vis-penguins/vis-penguins.html#dichotomisieren-sie-y-und-zählen-sie-die-häufigkeiten",
    "title": "vis-penguins",
    "section": "Dichotomisieren Sie y und zählen Sie die Häufigkeiten",
    "text": "Dichotomisieren Sie y und zählen Sie die Häufigkeiten\nNehmen wir einen Mediansplit, um zu dichotomisieren.\n\nd &lt;-\n  d |&gt; \n  mutate(y_dicho = ifelse(y &gt; median(y), \"high\", \"low\"))\n\n\nd |&gt; \n  count(y_dicho) |&gt; \n  ggbarplot(x = \"y_dicho\", y = \"n\")\n\n\n\n\n\n\n\n\nGleich viele! Das sollte nicht verwundern."
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "href": "posts/vis-penguins/vis-penguins.html#gruppieren-sie-das-letzte-diagramm-nach-den-stufen-von-x1",
    "title": "vis-penguins",
    "section": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1",
    "text": "Gruppieren Sie das letzte Diagramm nach den Stufen von x1\n\nd_count &lt;- \nd |&gt; \n  count(y_dicho, x1) \n\nd_count\n\n# A tibble: 3 × 3\n  y_dicho x1            n\n  &lt;lgl&gt;   &lt;fct&gt;     &lt;int&gt;\n1 NA      Adelie      152\n2 NA      Chinstrap    68\n3 NA      Gentoo      124\n\n\n\nggbarplot(d_count, x = \"y_dicho\", y = \"n\", facet.by = \"x1\", label = TRUE)"
  },
  {
    "objectID": "posts/vis-penguins/vis-penguins.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-häufigkeiten-statt-absoluter-häufigkeiten-gezeigt-werden",
    "href": "posts/vis-penguins/vis-penguins.html#variieren-sie-das-letzte-diagramm-so-dass-anteile-relative-häufigkeiten-statt-absoluter-häufigkeiten-gezeigt-werden",
    "title": "vis-penguins",
    "section": "Variieren Sie das letzte Diagramm so, dass Anteile (relative Häufigkeiten) statt absoluter Häufigkeiten gezeigt werden",
    "text": "Variieren Sie das letzte Diagramm so, dass Anteile (relative Häufigkeiten) statt absoluter Häufigkeiten gezeigt werden\n\nd_count &lt;-\n  d_count |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(prop = round(prop, 2))\n\nd_count\n\n# A tibble: 3 × 4\n  y_dicho x1            n  prop\n  &lt;lgl&gt;   &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;\n1 NA      Adelie      152  0.44\n2 NA      Chinstrap    68  0.2 \n3 NA      Gentoo      124  0.36\n\n\nCheck:\n\nd_count |&gt; \n  summarise(sum(prop))\n\n# A tibble: 1 × 1\n  `sum(prop)`\n        &lt;dbl&gt;\n1           1\n\n\nGut! Die Anteile summieren sich zu ca. 1 (100 Prozent).\n\nggbarplot(d_count, x = \"y_dicho\", y = \"prop\", facet.by = \"x1\", label = TRUE)\n\n\n\n\n\n\n\n\nMan beachten, dass sich die Anteile auf das “Gesamt-N” beziehen.\n\nCategories:\n\nvis\nyacsda\nggquick\npenguins\nstring"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html",
    "title": "vorhersageintervall1",
    "section": "",
    "text": "Vorhersagen, etwa in einem Regressionsmodell, sind mit mehreren Arten von Unsicherheit konfrontiert.\nBerechnen Sie dazu ein Regressionsmodell, Datensatz mtcars, mit hp als Prädiktor (UV) und mpg als AV (Kriterium)!\nDann sagen Sie bitte den Wert der AV für eine Beobachtungseinheit mit mittlerer Ausprägung im Präktor vorher:\nEinmal nur unter Berücksichtigung der Unsicherheit innerhalb des Modells (“Konfidenzintervall”); einmal unter Berücksichtigung der Unsicherheit innerhalb des Modells sowie die Unsicherheit durch die Koffizienten (“Vohersageintervall”).\nHinweise:\n\npredict() ist eine Funktion, die Sie zur Vorhersage von Regressionsmodellen verwenden können.\nVerwenden Sie lm() zur Berechnung eines Regressionsmodells.\nDas Argument type von predict() erlaubt Ihnen die Wahl der Art der Vorhersage, betrachten Sie Hilfe der Funktion z.B. hier.\n\nBei welchem Intervall ist die Ungewissheit in der Vorhersage größer?\n\n\n\nKonfidenzintervall\nVohersageintervall\nGleich groß\nKommt auf weitere Faktoren an, keine pauschale Antwort möglich"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist",
    "title": "vorhersageintervall1",
    "section": "",
    "text": "Konfidenzintervall\nVohersageintervall\nGleich groß\nKommt auf weitere Faktoren an, keine pauschale Antwort möglich"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist-1",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist-1",
    "title": "vorhersageintervall1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nlm\ninference\nqm2"
  },
  {
    "objectID": "posts/Weinhaendler/Weinhaendler.html",
    "href": "posts/Weinhaendler/Weinhaendler.html",
    "title": "Weinhaendler",
    "section": "",
    "text": "Sie sind kürzlich in ein Startup-Unternehmen eingestiegen. Das Unternehmen versucht, einen Online-Weinhandel aufzubauen. Kern des Unternehmens ist eine künstliche Intelligenz, die versucht, den Kundis den best möglich passenden Wein anzudreh… zu verkaufen.\nSie haben sich bei Ihrem Bewerbungsgespräch persönlich von der Qualität der Produkte eingehend überzeugt und sind daher hoch motiviert, sich zum Wohle des Unternehmens einzusetzen.\nKürzlich hat eine Beratungsfirma, die Ihre Kunden im Rahmen einer qualitativen Studie untersucht hat, herausgefunden, dass doch ein beachtlicher Teil von einem Menschen, nicht von einem Roboter (bzw. der KI) beim Wein aussuchen beraten werden möchte. Diesen Anteil von Kunden (die nicht von der KI beraten werden möchten) möchten Sie jetzt genauer bestimmen.\nDazu haben Sie \\(N=42\\) Kundis befragt. Gut die Hälfte (\\(n=23\\)) hat sich zugunsten der KI ausgesprochen; der Rest der Kundis möchte lieber von einem Menschen beraten werden.\nGehen Sie im Folgenden davon aus, dass die Studie bzw. die erhaltenen Daten von guter Qualität ist (man also keine Probleme wie mangelnde Repräsentativität erwarten muss).\nVerwenden Sie die Gittermethode und gleichverteilte Priori-Werte.\n\nWie groß ist die Wahrscheinlichkeit, dass die KI-freundlichen Kundis bei Ihnen überwiegen?\nWie groß ist die Wahrscheinlichkeit (laut Modell), dass künftig eine Mehrheit an KI-freundlichen Kundis zu beobachten sein wird?\nWenn Sie nur eine Zahl angeben dürften: Was ist Ihr Schätzwert zum Anteil der KI-Freunde (in dieser Studie)?"
  },
  {
    "objectID": "posts/Weinhaendler/Weinhaendler.html#a",
    "href": "posts/Weinhaendler/Weinhaendler.html#a",
    "title": "Weinhaendler",
    "section": "A)",
    "text": "A)\n\nWie groß ist die Wahrscheinlichkeit (laut Modell), dass die KI-freundlichen Kundis bei Ihnen überwiegen?\n\nDas ist eine Frage nach der kumulative Verteilungsfuntion (cumulative distribution function, cdf).\n\np_grid &lt;- seq(from=0, \n              to=1, \n              length.out=1000)  # Gitterwerte\n\nprior &lt;- rep(1, 1000)  # Priori-Gewichte\n\nset.seed(42)  # Zufallszahlen festlegen\nlikelihood &lt;- dbinom(23, size = 42, prob=p_grid ) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nZiehen wir daraus Stichproben:\n\nset.seed(42)  # Zufallszahlen festlegen\nsamples &lt;- \n  tibble(\n    p = sample(p_grid , \n               prob = posterior, \n               size=1e4, \n               replace=TRUE))  \nsamples &lt;-\n  samples %&gt;% \n  mutate(id = 1:nrow(samples))\n\n\nsamples %&gt;% \n  filter(p &gt; 0.5) %&gt;% \n  summarise(wskt_mehrheit_will_ki = n()/nrow(samples))\n\n# A tibble: 1 × 1\n  wskt_mehrheit_will_ki\n                  &lt;dbl&gt;\n1                 0.731\n\n\nVisualisieren:\nMit {ggpubr}:\n\nlibrary(ggpubr)\n\ngghistogram(samples, x = \"p\") +\n  geom_vline(xintercept = 0.5, color = \"red\", linewidth=2) \n\n\n\n\n\n\n\n\nMit {ggplot2}:\n\nsamples %&gt;% \n  ggplot() +\n  aes(x = p) +\n  geom_histogram() +\n  geom_vline(xintercept = 0.5) +\n  labs(title = \"Post-Verteilung\")"
  },
  {
    "objectID": "posts/Weinhaendler/Weinhaendler.html#b",
    "href": "posts/Weinhaendler/Weinhaendler.html#b",
    "title": "Weinhaendler",
    "section": "b)",
    "text": "b)\n\nWie groß ist die Wahrscheinlichkeit (laut Modell), dass künftig eine Mehrheit an KI-freundlichen Kunfis zu beobachten sein wird?\n\n\nPPV &lt;-\n  samples %&gt;% \n  mutate(Anzahl_will_KI = rbinom(n = 1e4, size = 42, prob = p))\n\n\nPPV %&gt;% \n  ggplot() +\n  aes(x = Anzahl_will_KI) +\n  geom_histogram() +\n  labs(title = \"PPV\")\n\n\n\n\n\n\n\n\nEine Mehrheit entspricht mind. 22 von 42 Personen.\n\nPPV %&gt;% \n  filter(Anzahl_will_KI &gt;= 22) %&gt;% \n  summarise(prob_mehrheit_will_ki = n()/nrow(PPV))\n\n# A tibble: 1 × 1\n  prob_mehrheit_will_ki\n                  &lt;dbl&gt;\n1                 0.623"
  },
  {
    "objectID": "posts/Weinhaendler/Weinhaendler.html#c",
    "href": "posts/Weinhaendler/Weinhaendler.html#c",
    "title": "Weinhaendler",
    "section": "C)",
    "text": "C)\n\nWenn Sie nur eine Zahl angeben dürften: Was ist Ihr Schätzwert zum Anteil der KI-Freunde (in dieser Studie)?\n\nMan könnte den Mittelwert oder den Median angeben:\n\nlibrary(easystats)\ndescribe_distribution(samples)\n\nVariable |    Mean |      SD |     IQR |            Range | Skewness | Kurtosis |     n | n_Missing\n---------------------------------------------------------------------------------------------------\np        |    0.54 |    0.07 |    0.10 |     [0.27, 0.79] |    -0.09 |    -0.06 | 10000 |         0\nid       | 5000.50 | 2886.90 | 5000.50 | [1.00, 10000.00] |     0.00 |    -1.20 | 10000 |         0\n\n\n\nCategories:\n\nprobability\nbayes-box\nbayes\nstring"
  },
  {
    "objectID": "posts/Wertberechnen2/Wertberechnen2.html",
    "href": "posts/Wertberechnen2/Wertberechnen2.html",
    "title": "Wertberechnen2",
    "section": "",
    "text": "Aufgabe\nWelchen Wert bzw. welches Ergebnis liefert folgende R-Syntax für ergebnis zurück?\nx hat zu Beginn den Wert 15.\nHinweise:\n\nsqrt(x) liefert die (positive) Quadratwurzel von x zurück.\nx^2 liefert die zweite Potenz von x zurück.\n\n\ny &lt;- 1\n\nx &lt;- x + y - 1\n\ny = x\n\ny &lt;- y * 2\n\nx &lt;- x + 1\n\nx &lt;- sqrt(x)\n\nergebnis &lt;- x^2\n\n         \n\n\nLösung\nEs wird 16 zurückgeliefert.\n\nCategories:\n\nR\ndyn\nnum"
  },
  {
    "objectID": "posts/Wertzuweisen/Wertzuweisen.html",
    "href": "posts/Wertzuweisen/Wertzuweisen.html",
    "title": "Wertzuweisen",
    "section": "",
    "text": "Aufgabe\nWeisen Sie dem Objekt loesung den Wert 42 zu. Geben Sie den korrekten R-Code dafür ein.\nHinweis: Verzichten Sie jegliche Leerzeichen in Ihrer Eingabe, da sonst die Eingabe nicht als korrekt erkannt werden kann.\n         \n\n\nLösung\nloesung&lt;-42\n\nCategories:\n\nR\n‘2023’\nstring"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html",
    "href": "posts/wfsets1/wfsets1.html",
    "title": "wfsets1",
    "section": "",
    "text": "Berechnen Sie die Vorhersagegüte (RMSE) für folgende Lernalgorithmen mittesl tidymodels:\n\nlineares Modell\n\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nNutzen Sie minimale Vorverarbeitung im Rahmen zweier Rezepte.\nNutzen Sie ein Workflowset."
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#setup",
    "href": "posts/wfsets1/wfsets1.html#setup",
    "title": "wfsets1",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung\ndata(penguins, package = \"palmerpenguins\")"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#daten",
    "href": "posts/wfsets1/wfsets1.html#daten",
    "title": "wfsets1",
    "section": "Daten",
    "text": "Daten\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()\n\n\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#modelle",
    "href": "posts/wfsets1/wfsets1.html#modelle",
    "title": "wfsets1",
    "section": "Modelle",
    "text": "Modelle\nLineares Modell:\n\nmod_lin &lt;- linear_reg()\n\nmod_knn &lt;- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#rezepte",
    "href": "posts/wfsets1/wfsets1.html#rezepte",
    "title": "wfsets1",
    "section": "Rezepte",
    "text": "Rezepte\n\nrec_basic &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n         step_normalize(all_predictors())\n\nrec_basic\n\n\nrec_plain &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#resampling",
    "href": "posts/wfsets1/wfsets1.html#resampling",
    "title": "wfsets1",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpls &lt;- vfold_cv(d_train, v = 5)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#workflow-set",
    "href": "posts/wfsets1/wfsets1.html#workflow-set",
    "title": "wfsets1",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic,\n                   rec_plain = rec_plain),\n    models = list(mod_lm = mod_lin)\n  )\n\nwf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result    \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 rec_plain_mod_lm  &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#fitten",
    "href": "posts/wfsets1/wfsets1.html#fitten",
    "title": "wfsets1",
    "section": "Fitten",
    "text": "Fitten\n\ntic()\nwf_fit &lt;-\n  wf_set %&gt;% \n  workflow_map(resamples = rsmpls)\ntoc()\n\n1.261 sec elapsed\n\nwf_fit\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result   \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;rsmp[+]&gt;\n2 rec_plain_mod_lm  &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;rsmp[+]&gt;\n\n\nCheck:\n\nwf_fit %&gt;% pluck(\"result\")\n\n[[1]]\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics         .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [199/50]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [199/50]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [199/50]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [199/50]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [200/49]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n[[2]]\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits           id    .metrics         .notes          \n  &lt;list&gt;           &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [199/50]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [199/50]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [199/50]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [199/50]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [200/49]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#bester-kandidat",
    "href": "posts/wfsets1/wfsets1.html#bester-kandidat",
    "title": "wfsets1",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(wf_fit)\n\n\n\n\n\n\n\n\n\nautoplot(wf_fit, select_best = TRUE)\n\n\n\n\n\n\n\n\n\ncollect_metrics(wf_fit)\n\n# A tibble: 4 × 9\n  wflow_id        .config preproc model .metric .estimator    mean     n std_err\n  &lt;chr&gt;           &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1 rec_simple_mod… Prepro… recipe  line… rmse    standard   655.        5 23.0   \n2 rec_simple_mod… Prepro… recipe  line… rsq     standard     0.357     5  0.0336\n3 rec_plain_mod_… Prepro… recipe  line… rmse    standard   655.        5 23.0   \n4 rec_plain_mod_… Prepro… recipe  line… rsq     standard     0.357     5  0.0336\n\n\n\nrank_results(wf_fit, rank_metric = \"rmse\") %&gt;% \n  filter(.metric == \"rmse\")\n\n# A tibble: 2 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 rec_simple_mod_lm Prepro… rmse     655.    23.0     5 recipe       line…     1\n2 rec_plain_mod_lm  Prepro… rmse     655.    23.0     5 recipe       line…     2"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#last-fit",
    "href": "posts/wfsets1/wfsets1.html#last-fit",
    "title": "wfsets1",
    "section": "Last Fit",
    "text": "Last Fit\n\nbest_wf &lt;-\n  wf_fit %&gt;% \n  extract_workflow(\"rec_simple_mod_lm\")\n\nFinalisieren müssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\nfit_final &lt;-\n  best_wf %&gt;% \n  last_fit(d_split)"
  },
  {
    "objectID": "posts/wfsets1/wfsets1.html#modellgüte-im-test-set",
    "href": "posts/wfsets1/wfsets1.html#modellgüte-im-test-set",
    "title": "wfsets1",
    "section": "Modellgüte im Test-Set",
    "text": "Modellgüte im Test-Set\n\ncollect_metrics(fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     653.    Preprocessor1_Model1\n2 rsq     standard       0.341 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html",
    "title": "wfsets_penguins02",
    "section": "",
    "text": "Berechnen Sie die Vorhersagegüte (RMSE) für folgende Lernalgorithmen:\n\nlineares Modell\nknn (neighbors: tune)\n\nModellgleichung: body_mass_g ~ bill_length_mm, data = d_train.\nTunen Sie bei neighbors folgende Werte: 5, 10, 15, 20, 35, 30 und betrachten Sie deren Modellgüte.\nNutzen Sie minimale Vorverarbeitung.\nBerichten Sie die den RSME."
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#setup",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#setup",
    "title": "wfsets_penguins02",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidymodels)\nlibrary(tidyverse)\ndata(penguins, package = \"palmerpenguins\")"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#daten",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#daten",
    "title": "wfsets_penguins02",
    "section": "Daten",
    "text": "Daten\n\nd &lt;-\n  penguins %&gt;% \n  drop_na()\n\n\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#modelle",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#modelle",
    "title": "wfsets_penguins02",
    "section": "Modelle",
    "text": "Modelle\nLineares Modell:\n\nmod_lin &lt;- linear_reg()\n\nmod_knn &lt;- nearest_neighbor(mode = \"regression\",\n                                  neighbors = tune())"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#rezepte",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#rezepte",
    "title": "wfsets_penguins02",
    "section": "Rezepte",
    "text": "Rezepte\n\nrec_basic &lt;- recipe(body_mass_g ~ bill_length_mm, data = d_train) %&gt;% \n         step_normalize(all_predictors())\n\nrec_basic"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#resampling",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#resampling",
    "title": "wfsets_penguins02",
    "section": "Resampling",
    "text": "Resampling\n\nrsmpls &lt;- vfold_cv(d_train)"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#workflow-set",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#workflow-set",
    "title": "wfsets_penguins02",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;-\n  workflow_set(\n    preproc = list(rec_simple = rec_basic),\n    models = list(mod_lm = mod_lin,\n                  mod_nn = mod_knn)\n  )\n\nwf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result    \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 rec_simple_mod_nn &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#tuningparameter-werte-bestimmen",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#tuningparameter-werte-bestimmen",
    "title": "wfsets_penguins02",
    "section": "Tuningparameter-Werte bestimmen",
    "text": "Tuningparameter-Werte bestimmen\nWelche Tuningparameter hatten wir noch mal ausgewiesen?\n\nmod_knn %&gt;% \n  extract_parameter_set_dials()\n\nCollection of 1 parameters for tuning\n\n identifier      type    object\n  neighbors neighbors nparam[+]\n\n\nUpdaten wir die Parameter mit unseren Werten, also min. 5 Nachbarn und max. 20 Nachbarn.\n\nparams_knn &lt;- \nmod_knn %&gt;% \n  extract_parameter_set_dials() %&gt;% \n  update(neighbors = neighbors(c(5, 20)))\n\nparams_knn\n\nCollection of 1 parameters for tuning\n\n identifier      type    object\n  neighbors neighbors nparam[+]\n\n\nDiese Infos ergänzen wir jetzt in das Workflow-Set-Objekt für den Workflow mit der ID “rec_simple_mod_nn” unter der Spalte “Options”:\n\nwf_set &lt;- \nwf_set %&gt;% \n  option_add(param_info = params_knn, id = \"rec_simple_mod_nn\")  \n\nwf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result    \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 rec_simple_mod_nn &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#fitten",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#fitten",
    "title": "wfsets_penguins02",
    "section": "Fitten",
    "text": "Fitten\n\nwf_set_fit &lt;-\n  wf_set %&gt;% \n  workflow_map(resamples = rsmpls)\n\nwf_set_fit\n\n# A workflow set/tibble: 2 × 4\n  wflow_id          info             option    result   \n  &lt;chr&gt;             &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 rec_simple_mod_lm &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;rsmp[+]&gt;\n2 rec_simple_mod_nn &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;tune[+]&gt;\n\n\nCheck:\n\nwf_set_fit %&gt;% pluck(\"result\")\n\n[[1]]\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [224/25]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [224/25]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [224/25]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [224/25]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [224/25]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [224/25]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [224/25]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [224/25]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [224/25]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [225/24]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n[[2]]\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [224/25]&gt; Fold01 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [224/25]&gt; Fold02 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [224/25]&gt; Fold03 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [224/25]&gt; Fold04 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [224/25]&gt; Fold05 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [224/25]&gt; Fold06 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [224/25]&gt; Fold07 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [224/25]&gt; Fold08 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [224/25]&gt; Fold09 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [225/24]&gt; Fold10 &lt;tibble [16 × 5]&gt; &lt;tibble [0 × 3]&gt;"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#bester-kandidat",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#bester-kandidat",
    "title": "wfsets_penguins02",
    "section": "Bester Kandidat",
    "text": "Bester Kandidat\n\nautoplot(wf_set_fit)\n\n\n\n\n\n\n\n\n\nrank_results(wf_set_fit, rank_metric = \"rmse\") %&gt;% \n  filter(.metric == \"rmse\")\n\n# A tibble: 9 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 rec_simple_mod_nn Prepro… rmse     645.    23.7    10 recipe       near…     1\n2 rec_simple_mod_lm Prepro… rmse     646.    26.0    10 recipe       line…     2\n3 rec_simple_mod_nn Prepro… rmse     651.    22.4    10 recipe       near…     3\n4 rec_simple_mod_nn Prepro… rmse     653.    22.7    10 recipe       near…     4\n5 rec_simple_mod_nn Prepro… rmse     656.    22.0    10 recipe       near…     5\n6 rec_simple_mod_nn Prepro… rmse     661.    22.4    10 recipe       near…     6\n7 rec_simple_mod_nn Prepro… rmse     670.    23.3    10 recipe       near…     7\n8 rec_simple_mod_nn Prepro… rmse     680.    24.8    10 recipe       near…     8\n9 rec_simple_mod_nn Prepro… rmse     699.    30.9    10 recipe       near…     9\n\n\nAm besten war das lineare Modell, aber schauen wir uns auch mal das knn-Modell an, v.a. um zu wissen, wie man den besten Tuningparameter-Wert sieht:\n\nwf_knn &lt;- \n  extract_workflow_set_result(wf_set_fit, \"rec_simple_mod_nn\")\n\n\nwf_knn %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nwf_knn %&gt;% select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 1 × 2\n  neighbors .config             \n      &lt;int&gt; &lt;chr&gt;               \n1        19 Preprocessor1_Model8"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#last-fit",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#last-fit",
    "title": "wfsets_penguins02",
    "section": "Last Fit",
    "text": "Last Fit\n\nbest_wf &lt;-\n  wf_set_fit %&gt;% \n  extract_workflow(\"rec_simple_mod_lm\")\n\nFinalisieren müssen wir diesen Workflow nicht, da er keine Tuningparameter hatte.\n\nfit_final &lt;-\n  best_wf %&gt;% \n  last_fit(d_split)"
  },
  {
    "objectID": "posts/wfsets_penguins02/wfsets_penguins02.html#modellgüte-im-test-set",
    "href": "posts/wfsets_penguins02/wfsets_penguins02.html#modellgüte-im-test-set",
    "title": "wfsets_penguins02",
    "section": "Modellgüte im Test-Set",
    "text": "Modellgüte im Test-Set\n\ncollect_metrics(fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     670.    Preprocessor1_Model1\n2 rsq     standard       0.369 Preprocessor1_Model1\n\n\n\nCategories:\n\nR\nstatlearning\ntidymodels\nnum"
  },
  {
    "objectID": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html",
    "href": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html",
    "title": "wozu-balkendiagramm",
    "section": "",
    "text": "Zu welchem Zweck ist ein Balkendiagramm am besten geeignet?\n\n\n\nUm Mittelwerte zwischen zwei oder mehr Gruppen darzustellen.\nUm Häufigkeiten darzustellen.\nUm metrische Verteilungen darzustellen.\nUm metrische Zusammenhänge darzustellen."
  },
  {
    "objectID": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist",
    "href": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist",
    "title": "wozu-balkendiagramm",
    "section": "",
    "text": "Um Mittelwerte zwischen zwei oder mehr Gruppen darzustellen.\nUm Häufigkeiten darzustellen.\nUm metrische Verteilungen darzustellen.\nUm metrische Zusammenhänge darzustellen."
  },
  {
    "objectID": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist-1",
    "href": "posts/wozu-balkendiagramm/wozu-balkendiagramm.html#answerlist-1",
    "title": "wozu-balkendiagramm",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nvis\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/wrangle1/wrangle1.html",
    "href": "posts/wrangle1/wrangle1.html",
    "title": "wrangle1",
    "section": "",
    "text": "Welche der folgenden Spalte ist nicht Teil des Datensatzes flights aus dem R-Paket nycflights13?\nAlternativ können Sie den Datensatz hier beziehen. Hilfe zum Datensatz (Codebook) finden Sie hier.\n\n\n\nyear\nmonth\n\nday\ndep_time\nsched_dep_time\nestimated_dep_time\narr_time\nsched_arr_time"
  },
  {
    "objectID": "posts/wrangle1/wrangle1.html#answerlist",
    "href": "posts/wrangle1/wrangle1.html#answerlist",
    "title": "wrangle1",
    "section": "",
    "text": "year\nmonth\n\nday\ndep_time\nsched_dep_time\nestimated_dep_time\narr_time\nsched_arr_time"
  },
  {
    "objectID": "posts/wrangle1/wrangle1.html#answerlist-1",
    "href": "posts/wrangle1/wrangle1.html#answerlist-1",
    "title": "wrangle1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\neda\ndatawrangling\ntidyverse\ndplyr\nschoice"
  },
  {
    "objectID": "posts/wrangle3/wrangle3.html",
    "href": "posts/wrangle3/wrangle3.html",
    "title": "wrangle3",
    "section": "",
    "text": "Welche Aussage zu der Funktionsweise folgender Funktionen im R-Paket dplyr ist richtig?\n\nfilter\nselect\nsummarise\ncount\ngroup_by\n\n\n\n\nDas erste Argument darf nie ein Dataframe sein.\nDas erste Argument ist immer die zu analysierende Variable.\nSpaltennamen müssen mit Anführungsstrichen benannt werden.\nEs wird immer eine Tabelle ausgegeben.\nFunktionsnamen sind (zumeist) nicht als Verben formuliert."
  },
  {
    "objectID": "posts/wrangle3/wrangle3.html#answerlist",
    "href": "posts/wrangle3/wrangle3.html#answerlist",
    "title": "wrangle3",
    "section": "",
    "text": "Das erste Argument darf nie ein Dataframe sein.\nDas erste Argument ist immer die zu analysierende Variable.\nSpaltennamen müssen mit Anführungsstrichen benannt werden.\nEs wird immer eine Tabelle ausgegeben.\nFunktionsnamen sind (zumeist) nicht als Verben formuliert."
  },
  {
    "objectID": "posts/wrangle3/wrangle3.html#answerlist-1",
    "href": "posts/wrangle3/wrangle3.html#answerlist-1",
    "title": "wrangle3",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nWahr\nFalsch\n\n\nCategories:\n\ndatawrangling\neda\nschoice"
  },
  {
    "objectID": "posts/wrangle5/wrangle5.html",
    "href": "posts/wrangle5/wrangle5.html",
    "title": "wrangle5",
    "section": "",
    "text": "Wie prüft man in R auf Gleichheit zweier Ausdrücke?\nWählen Sie die korrekte Aussage.\n\n\n\n!= – “definiert als”\n== Prüfung auf Gleichheit\n= – Prüfung auf Gleichheit\n&lt;- – Prüfung auf Gleichheit\n!= – Prüfung auf Gleichheit"
  },
  {
    "objectID": "posts/wrangle5/wrangle5.html#answerlist",
    "href": "posts/wrangle5/wrangle5.html#answerlist",
    "title": "wrangle5",
    "section": "",
    "text": "!= – “definiert als”\n== Prüfung auf Gleichheit\n= – Prüfung auf Gleichheit\n&lt;- – Prüfung auf Gleichheit\n!= – Prüfung auf Gleichheit"
  },
  {
    "objectID": "posts/wrangle5/wrangle5.html#answerlist-1",
    "href": "posts/wrangle5/wrangle5.html#answerlist-1",
    "title": "wrangle5",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\neda\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/wrangle9/wrangle9.html",
    "href": "posts/wrangle9/wrangle9.html",
    "title": "wrangle9",
    "section": "",
    "text": "Aufgabe\nUm Variablen in einem Datensatz anzulegen oder zu verändern, nutzt man mutate() im tidyverse. mutate() ist nützlich für vektorielles Rechnen. In diesem Zusammenhang: Was ist das Ergebnis folgenden Ausdrucks?\n\nsum(1:3 + 1:3)\n\n         \n\n\nLösung\n12\n\nsum(1:3 + 1:3)\n\n[1] 12\n\n\n\nCategories:\n\neda\n‘2023’\nnum"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html",
    "title": "wskt-mtcars-1l",
    "section": "",
    "text": "Prüfen Sie folgende Hypothese:\n\nEin Auto mit manueller Schaltung hat pro Gallone Sprit mind. 5 Meilen mehr Reichweite als ein Auto mit Automatikschaltung (ceteris paribus).\n\nQuantifizieren Sie die Wahrscheinlichkeit dieser Hypothese!\nHinweise:\n\nNutzen Sie die Bayes-Statistik mit Stan.\nBeachten Sie die Standardhinweise des Datenwerks.\nVerwenden Sie den Datensatz mtcars."
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#setup",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#setup",
    "title": "wskt-mtcars-1l",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(tidyverse)\n\n\ndata(mtcars)"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell",
    "title": "wskt-mtcars-1l",
    "section": "Modell",
    "text": "Modell\nDie Hypothese kann man wie folgt formalisieren:\n\nDie Wahrscheinlichkeit, dass Manuellschalter eine höhere Reichweite haben, ist größer als die Wahrscheinlichkeit, dass Automatikschalter eine höhere Reichweite haben:\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; Pr(mpg_M &lt;= mpg_A)\\]\n\nOder anders gesagt: Die Wahrscheinlichkeit, dass Automatikschalter eine höhere Reichweite haben (pro Gallone Sprit und im Vergleich zu Automatikschalter) ist größer als 50%.\n\n\\[Pr(mpg_M &gt; mpg_A) &gt; 1/2\\] 3. Möchte man noch hinzufügen, dass sich diese Behauptung auf ein bestimmtes, nämlich unser Regressionsmodell bezieht, kann man schreiben:\n\\[Pr(mpg_M &gt; mpg_A \\quad | \\beta_0, \\beta_1, \\sigma)\\]"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell-berechnen",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#modell-berechnen",
    "title": "wskt-mtcars-1l",
    "section": "Modell berechnen",
    "text": "Modell berechnen\n\nm &lt;- stan_glm(mpg ~ am,\n              data = mtcars,\n              refresh = 0,\n              seed = 42)\n\n\nparameters(m)\n\nParameter   | Median |         95% CI |     pd |  Rhat |     ESS |                   Prior\n------------------------------------------------------------------------------------------\n(Intercept) |  17.14 | [14.85, 19.51] |   100% | 0.999 | 3739.00 | Normal (20.09 +- 15.07)\nam          |   7.21 | [ 3.72, 10.70] | 99.95% | 0.999 | 3755.00 |  Normal (0.00 +- 30.20)"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#post-verteilung-auslesen",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#post-verteilung-auslesen",
    "title": "wskt-mtcars-1l",
    "section": "Post-Verteilung auslesen",
    "text": "Post-Verteilung auslesen\n\nm_post &lt;-\n  m |&gt;\n  as_tibble()\n\nprop &lt;- \nm_post |&gt; \n  count(am &gt;= 5) |&gt; \n  mutate(prop = n/sum(n))\n\nprop\n\n# A tibble: 2 × 3\n  `am &gt;= 5`     n  prop\n  &lt;lgl&gt;     &lt;int&gt; &lt;dbl&gt;\n1 FALSE       431 0.108\n2 TRUE       3569 0.892"
  },
  {
    "objectID": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#antwort",
    "href": "posts/wskt-mtcars-1l/wskt-mtcars-1l.html#antwort",
    "title": "wskt-mtcars-1l",
    "section": "Antwort",
    "text": "Antwort\nLaut unserem Modell beträgt die Wahrscheinlichkeit für obige Hypothese 0.89."
  },
  {
    "objectID": "posts/wskt-quiz02/wskt-quiz02.html",
    "href": "posts/wskt-quiz02/wskt-quiz02.html",
    "title": "wskt-quiz02",
    "section": "",
    "text": "Gilt \\(Pr(AB) = Pr(A\\cap B) = Pr(A) \\cdot Pr(B)\\), so sind die Ereignisse \\(A\\) und \\(B\\) abhängig.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz02/wskt-quiz02.html#answerlist",
    "href": "posts/wskt-quiz02/wskt-quiz02.html#answerlist",
    "title": "wskt-quiz02",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz02/wskt-quiz02.html#answerlist-1",
    "href": "posts/wskt-quiz02/wskt-quiz02.html#answerlist-1",
    "title": "wskt-quiz02",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Ja, denn es ist die Definition für stochastische Unabhängigkeit angegeben.\nWahr. Nein, denn es war nicht nach Abhängigkeit, sondern nach Unabhängigkeit gefragt.\n\n\nCategories:\n\nquiz\nprobability\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz04/wskt-quiz04.html",
    "href": "posts/wskt-quiz04/wskt-quiz04.html",
    "title": "wskt-quiz04",
    "section": "",
    "text": "Sei \\(X \\sim Bin(10, 1/2)\\). Dann ist die zugehörige Verteilung (von \\(X\\)) symmetrisch.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz04/wskt-quiz04.html#answerlist",
    "href": "posts/wskt-quiz04/wskt-quiz04.html#answerlist",
    "title": "wskt-quiz04",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz04/wskt-quiz04.html#answerlist-1",
    "href": "posts/wskt-quiz04/wskt-quiz04.html#answerlist-1",
    "title": "wskt-quiz04",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\ndistribution\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz06/wskt-quiz06.html",
    "href": "posts/wskt-quiz06/wskt-quiz06.html",
    "title": "wskt-quiz06",
    "section": "",
    "text": "Jemand geht zum Krebstest. Der Test habe eine Sicherheit von 95%. Die Grundrate des Krebs liege bei 0.001. Leider zeigt der Test einen positiven Befund, also Krebs.\nGilt: \\(Pr(K|T) = .95\\)?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz06/wskt-quiz06.html#answerlist",
    "href": "posts/wskt-quiz06/wskt-quiz06.html#answerlist",
    "title": "wskt-quiz06",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz06/wskt-quiz06.html#answerlist-1",
    "href": "posts/wskt-quiz06/wskt-quiz06.html#answerlist-1",
    "title": "wskt-quiz06",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz08/wskt-quiz08.html",
    "href": "posts/wskt-quiz08/wskt-quiz08.html",
    "title": "wskt-quiz08",
    "section": "",
    "text": "Mehrere Proben werden zu einem unbekannten Planeten geschossen. Die Forschungsfrage lautet: Ist es die Erde (70% Wasseranteil) oder der Planet “Bath42” mit 90% Wasseranteil?\nWir sind indifferent (apriori) zu den Parameterwerten.\nDaten: 6 Treffer (Wasser) von 9 Versuchen (Proben).\nBehauptung: “Das ist fast sicher Bath42!”.\nIst die Wahrscheinlichkeit höher für Bath42 (als für die Erde)?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz08/wskt-quiz08.html#answerlist",
    "href": "posts/wskt-quiz08/wskt-quiz08.html#answerlist",
    "title": "wskt-quiz08",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz08/wskt-quiz08.html#answerlist-1",
    "href": "posts/wskt-quiz08/wskt-quiz08.html#answerlist-1",
    "title": "wskt-quiz08",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz10/wskt-quiz10.html",
    "href": "posts/wskt-quiz10/wskt-quiz10.html",
    "title": "wskt-quiz10",
    "section": "",
    "text": "Sei \\(X \\sim U(0, 2)\\).\nBehauptung: Es gilt: \\(f(X=1) = .5\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz10/wskt-quiz10.html#answerlist",
    "href": "posts/wskt-quiz10/wskt-quiz10.html#answerlist",
    "title": "wskt-quiz10",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz10/wskt-quiz10.html#answerlist-1",
    "href": "posts/wskt-quiz10/wskt-quiz10.html#answerlist-1",
    "title": "wskt-quiz10",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\ndistributions\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz12/wskt-quiz12.html",
    "href": "posts/wskt-quiz12/wskt-quiz12.html",
    "title": "wskt-quiz12",
    "section": "",
    "text": "Behauptung: Der Likelihood \\(L\\) gibt die Wahrscheinlichkeit eines Ereignisses (einer Hypothese) an, gegeben der Daten.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz12/wskt-quiz12.html#answerlist",
    "href": "posts/wskt-quiz12/wskt-quiz12.html#answerlist",
    "title": "wskt-quiz12",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz12/wskt-quiz12.html#answerlist-1",
    "href": "posts/wskt-quiz12/wskt-quiz12.html#answerlist-1",
    "title": "wskt-quiz12",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz14/wskt-quiz14.html",
    "href": "posts/wskt-quiz14/wskt-quiz14.html",
    "title": "wskt-quiz14",
    "section": "",
    "text": "Behauptung:\n\\(Pr(AB) = Pr(A|B) \\cdot Pr(B)\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz14/wskt-quiz14.html#answerlist",
    "href": "posts/wskt-quiz14/wskt-quiz14.html#answerlist",
    "title": "wskt-quiz14",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz14/wskt-quiz14.html#answerlist-1",
    "href": "posts/wskt-quiz14/wskt-quiz14.html#answerlist-1",
    "title": "wskt-quiz14",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz16/wskt-quiz16.html",
    "href": "posts/wskt-quiz16/wskt-quiz16.html",
    "title": "wskt-quiz16",
    "section": "",
    "text": "Behauptung:\n\\(Pr(A|B) = Pr(AB) / Pr(B)\\).\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz16/wskt-quiz16.html#answerlist",
    "href": "posts/wskt-quiz16/wskt-quiz16.html#answerlist",
    "title": "wskt-quiz16",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz16/wskt-quiz16.html#answerlist-1",
    "href": "posts/wskt-quiz16/wskt-quiz16.html#answerlist-1",
    "title": "wskt-quiz16",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz18/wskt-quiz18.html",
    "href": "posts/wskt-quiz18/wskt-quiz18.html",
    "title": "wskt-quiz18",
    "section": "",
    "text": "Behauptung:\nHat eine Hypothese die Priori-Wahrscheinlichkeit von 1, so wird die Post-Wahrscheinlichkeit dieser Hypothese 1 sein.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz18/wskt-quiz18.html#answerlist",
    "href": "posts/wskt-quiz18/wskt-quiz18.html#answerlist",
    "title": "wskt-quiz18",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz18/wskt-quiz18.html#answerlist-1",
    "href": "posts/wskt-quiz18/wskt-quiz18.html#answerlist-1",
    "title": "wskt-quiz18",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\nbayes\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wskt-quiz20/wskt-quiz20.html",
    "href": "posts/wskt-quiz20/wskt-quiz20.html",
    "title": "wskt-quiz20",
    "section": "",
    "text": "Behauptung:\nMann (Frau auch) kann jede Kennzahl der Deskriptivstatistik mit Methoden der Inferenzstatistik untersuchen.\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n\n\n\nFalsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz20/wskt-quiz20.html#answerlist",
    "href": "posts/wskt-quiz20/wskt-quiz20.html#answerlist",
    "title": "wskt-quiz20",
    "section": "",
    "text": "Falsch\nWahr"
  },
  {
    "objectID": "posts/wskt-quiz20/wskt-quiz20.html#answerlist-1",
    "href": "posts/wskt-quiz20/wskt-quiz20.html#answerlist-1",
    "title": "wskt-quiz20",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\n\n\nCategories:\n\nquiz\nprobability\ninference\nquiz1-qm2-ws23\nschoice"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html",
    "href": "posts/wuerfel01/wuerfel01.html",
    "title": "wuerfel01",
    "section": "",
    "text": "Wie hoch ist die Wahrscheinlichkeit, mit zwei fairen Würfeln genau 10 Augen zu werfen?\nHinweise:\n\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\nRunden Sie auf zwei Dezimalstellen.\nFixieren Sie die Zufallszahlen auf den Startwert 42.\nMit expand_grid können Sie komfortabel alle 36 Ereignisse dieses Zufallsexperiments in einen Dataframe bringen.\n\nWählen Sie die am besten passende Option:\n\n\n\n.04\n.08\n.12\n.16\n.20"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html#answerlist",
    "href": "posts/wuerfel01/wuerfel01.html#answerlist",
    "title": "wuerfel01",
    "section": "",
    "text": ".04\n.08\n.12\n.16\n.20"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html#answerlist-1",
    "href": "posts/wuerfel01/wuerfel01.html#answerlist-1",
    "title": "wuerfel01",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch.\nWahr.\nFalsch.\nFalsch.\nFalsch.\n\n\nCategories:\n\nprobability\ndice\nexam-22"
  },
  {
    "objectID": "posts/wuerfel03/wuerfel03.html",
    "href": "posts/wuerfel03/wuerfel03.html",
    "title": "wuerfel03",
    "section": "",
    "text": "Exercise\nWas ist die Wahrscheinlichkeit, mit zwei fairen Würfeln höchstens 10 Augen zu werfen?\nHinweise:\n\nNutzen Sie exakte Methoden der Wahrscheinlichkeitsrechnung, keine Simulation.\nGeben Sie Anteile oder Wahrscheinlichkeiten stets mit zwei Dezimalstellen an (sofern nicht anders verlangt).\n\n         \n\n\nSolution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden Würfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), …, (1,6), …, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd &lt;- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\n\nd\n\n# A tibble: 36 × 2\n   wuerfel1 wuerfel2\n      &lt;int&gt;    &lt;int&gt;\n 1        1        1\n 2        1        2\n 3        1        3\n 4        1        4\n 5        1        5\n 6        1        6\n 7        2        1\n 8        2        2\n 9        2        3\n10        2        4\n# ℹ 26 more rows\n\n\nJetzt ergänzen wir eine Spalte für die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 &lt;-\n  d %&gt;% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n# A tibble: 6 × 3\n  wuerfel1 wuerfel2   prob\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;\n1        1        1 0.0278\n2        1        2 0.0278\n3        1        3 0.0278\n4        1        4 0.0278\n5        1        5 0.0278\n6        1        6 0.0278\n\n\nAußerdem ergänzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;      &lt;int&gt;\n1        1        1 0.0278          2\n2        1        2 0.0278          3\n3        1        3 0.0278          4\n4        1        4 0.0278          5\n5        1        5 0.0278          6\n6        1        6 0.0278          7\n\n\nFür manche Augensummen gibt es mehrere Möglichkeiten:\n\nd3 %&gt;% \n  filter(augensumme == 7)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;      &lt;int&gt;\n1        1        6 0.0278          7\n2        2        5 0.0278          7\n3        3        4 0.0278          7\n4        4        3 0.0278          7\n5        5        2 0.0278          7\n6        6        1 0.0278          7\n\n\n… für andere weniger:\n\nd3 %&gt;% \n  filter(augensumme == 12)\n\n# A tibble: 1 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;      &lt;int&gt;\n1        6        6 0.0278         12\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 &lt;- \n  d3 %&gt;% \n  group_by(augensumme) %&gt;% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n# A tibble: 11 × 2\n   augensumme totale_w_pro_augenzahl\n        &lt;int&gt;                  &lt;dbl&gt;\n 1          2                 0.0278\n 2          3                 0.0556\n 3          4                 0.0833\n 4          5                 0.111 \n 5          6                 0.139 \n 6          7                 0.167 \n 7          8                 0.139 \n 8          9                 0.111 \n 9         10                 0.0833\n10         11                 0.0556\n11         12                 0.0278\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %&gt;% \n  summarise(sum(totale_w_pro_augenzahl))\n\n# A tibble: 1 × 1\n  `sum(totale_w_pro_augenzahl)`\n                          &lt;dbl&gt;\n1                             1\n\n\nUnd:\n\nd2 %&gt;% \n  summarise(sum(prob))\n\n# A tibble: 1 × 1\n  `sum(prob)`\n        &lt;dbl&gt;\n1           1\n\n\nPasst!\nDie Wahrscheinlichkeit für die Augensumme von höchstens 10 beträgt also:\n\nloesung &lt;-\n  d4 %&gt;% \n  filter(augensumme &lt;= 10) %&gt;% \n  summarise(prob_sum = sum(totale_w_pro_augenzahl)) %&gt;% \n  pull(prob_sum)\n\nloesung\n\n[1] 0.9166667\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/wuerfel05/wuerfel05.html",
    "href": "posts/wuerfel05/wuerfel05.html",
    "title": "wuerfel05",
    "section": "",
    "text": "Aufgabe\nWas ist die Wahrscheinlichkeit, mit zwei fairen Würfeln genau 12 Augen zu werfen?\nHinweise:\n\nOrientieren Sie sich im Übrigen an den allgemeinen Hinweisen des Datenwerks.\n\n         \n\n\nLösung\nDie Ereignisse A=“Wurf des 1. Würfels” und B=“Wurf des 2. Würfels” sind unabhängig voneinander.\nDaher gilt: \\(Pr(A\\cap B) = Pr(AB) = Pr(A) \\cdot Pr(B)\\).\n\nPr_AB &lt;- 1/6 * 1/6\nPr_AB\n\n[1] 0.02777778\n\n\nAufgrund der Unabhängigkeit gilt außerdem: \\(Pr(A|B) = Pr(A) = Pr(A|\\neg B).\\)\nDie Lösung lautet 0.0277778.\n\nCategories:\n\nR\nprobability\nnum"
  },
  {
    "objectID": "posts/Ziele-Statistik/Ziele-Statistik.html",
    "href": "posts/Ziele-Statistik/Ziele-Statistik.html",
    "title": "Ziele-Statistik",
    "section": "",
    "text": "Welche von den folgenden Optionen gehört nicht zu den Zielen von Statistik bzw. einer Forschungsfrage mit statistischem Character?\n\n\n\nverstehen\nerklären\nvorhersagen\nbeschreiben"
  },
  {
    "objectID": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist",
    "href": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist",
    "title": "Ziele-Statistik",
    "section": "",
    "text": "verstehen\nerklären\nvorhersagen\nbeschreiben"
  },
  {
    "objectID": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist-1",
    "href": "posts/Ziele-Statistik/Ziele-Statistik.html#answerlist-1",
    "title": "Ziele-Statistik",
    "section": "Answerlist",
    "text": "Answerlist\n\nWahr\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n\nbasics\n‘2023’\nschoice"
  },
  {
    "objectID": "posts/Zwielichter-Dozent-Bayes/Zwielichter-Dozent-Bayes.html",
    "href": "posts/Zwielichter-Dozent-Bayes/Zwielichter-Dozent-Bayes.html",
    "title": "Zwielichter-Dozent-Bayes",
    "section": "",
    "text": "options(digits = 2)\n\n\nExercise\nNach einem langen Unitag machen Sie sich auf den Weg nach Hause; ihr Weg führt Sie durch eine dunkle Ecke. Just dort regt sich auf einmal eine Gestalt in den Schatten. Die Person spricht Sie an: „Na, Lust auf ein Spielchen?“. Sie willigen sofort ein. Die Person stellt sich als ein Statistiker vor, dessen Namen nichts zur Sache tue; das Gesicht kommt Ihnen vage bekannt vor. „Pass auf“, erklärt der Statistiker, „wir werfen eine Münze, ich setze auf Zahl“. Dass er auf Zahl setzt, überrascht Sie nicht. „Wenn ich gewinne“, fährt der Statistiker fort, „bekomme ich 10 Euro von Dir, wenn Du gewinnst, bekommst Du 11 Euro von mir. Gutes Spiel, oder?“. Sie einigen sich auf 10 Durchgänge, in denen der Statistiker jedes Mal eine Münze wirft, fängt und dann die oben liegende Seite prüft. Erster Wurf: Zahl! Der Statistiker gewinnt. Pech für Sie. Zweiter Wurf: Zahl! Schon wieder 10 Euro für den Statistiker. Hm. Dritter Wurf: . . . Zahl! Schon wieder. Aber kann ja passieren, bei einer fairen Münze, oder? Vierter Wurf: Zahl! Langsam regen sich Zweifel bei Ihnen. Kann das noch mit rechten Dingen zugehen? Ist die Münze fair? Insgesamt gewinnt der zwielichte Statistiker 8 von 10 Durchgängen.\nUnter leisem Gelächter des Statistikers (und mit leeren Taschen) machen Sie sich von dannen. Hat er falsch gespielt? Wie plausibel ist es, bei 10 Würfen 8 Treffer zu erhalten, wenn die Münze fair ist? Ist das ein häufiges, ein typisches Ereignis oder ein seltenes, untypisches Ereignis bei einer fairen Münze? Wenn es ein einigermaßen häufiges Ereignis sein sollte, dann spricht das für die Fairness der Münze. Zumindest spricht ein Ereignis, welches von einer Hypothese als häufig vorausgesagt wird und schließlich eintritt, nicht gegen eine Hypothese. Zuhause angekommen, denken Sie sich, jetzt müssen Sie erstmal in Ruhe die Posteriori-Verteilung und die PPV ausrechnen!\n\nBerechnen Sie die Posteriori-Verteilung mit der Gittermethode! Gehen Sie von einer gleichverteilten Priori-Wahrscheinlichkeit aus. Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\nWie groß ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die Münze zugunsten des Dozenten gezinkt ist?\nGeben Sie das 50%-PI und 50%-HDPI zum Parameterwert (\\(p\\) der Münze) an!\nMit welcher Wahrscheinlichkeit liegt die Trefferchance der Münze zwischen \\(p=.45\\) und \\(p=.55\\), ist also nicht “nennenswert” gezinkt?\nWas ist der wahrscheinlichste Parameterwert (Trefferchance der Münze)?\nGeben Sie das 90%-PI und 90%-HDI zu Parameterwert (\\(p\\) der Münze) an!\nBerechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\nDiskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von \\(p\\)!\n\n         \n\n\nSolution\n\nBerechnen Sie die Posteriori-Verteilung mit der Gittermethode! Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\n\n\np_grid &lt;- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior &lt;- rep( 1 , 1000 )  # Priori-Gewichte\n\nlikelihood &lt;- dbinom(8, size = 10, prob=p_grid) \n\nunstandardisierte_posterior &lt;- likelihood * prior \n\nposterior &lt;- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples &lt;- \n  tibble(\n    gewinnchance_muenze = sample(p_grid , prob=posterior, size=1e4, replace=TRUE))\n\nVisualisierung:\n\nsamples %&gt;% \n  ggplot() +\n  aes(x = gewinnchance_muenze) +\n  geom_histogram() +\n  labs(title = \"Posterior-Verteilung\",\n       x = \"Gewinnchance der Münze (50%: faire Münze)\")\n\n\n\n\n\n\n\n\n\nWie groß ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die Münze zugunsten des Dozenten gezinkt ist?\n\n\nsamples %&gt;% \n  count(gewinnchance_muenze &gt; .5) %&gt;% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  `gewinnchance_muenze &gt; 0.5`     n   prop\n  &lt;lgl&gt;                       &lt;int&gt;  &lt;dbl&gt;\n1 FALSE                         318 0.0318\n2 TRUE                         9682 0.968 \n\n\n\nGeben Sie das 50%-PI (Perzentilintervall) und 50%-HDI zum Parameterwert (\\(p\\) der Münze) an!\n\n\nlibrary(easystats)\neti(samples, ci = .5)\n\nEqual-Tailed Interval\n\nParameter           |      50% ETI\n----------------------------------\ngewinnchance_muenze | [0.67, 0.84]\n\nhdi(samples, ci = .5)\n\nHighest Density Interval\n\nParameter           |      50% HDI\n----------------------------------\ngewinnchance_muenze | [0.71, 0.87]\n\n\nEin PI wird auch equal tail interval genannt, weil die beiden “abgeschnitten Randbereiche” links und rechts die gleichen Flächenanteil (Wahrscheinlichkeitsmasse) aufweisen.\nInteresant ist, dass das PI und das HDI zu unterschiedlichen Ergebnissen kommen. Das lässt auf eine schiefe Verteilung schließen. Außerdem eröffnet es den Raum zur Diskussion, welches Intervall man berichtet. Um diese Frage besser zu verstehen, können wir die Intervalle visualisieren.\nBonus: Visualisieren wir die Intervalle:\nPI:\n\neti(samples, ci = .5) %&gt;% plot()\n\n\n\n\n\n\n\n\nHDI:\n\nhdi(samples, ci = .5) %&gt;% plot()\n\n\n\n\n\n\n\n\nDas HDI ist schmäler und liegt näher am Modus. Vermutlich ist das HDI zu bevorzugen.\n\nMit welcher Wahrscheinlichkeit liegt die Trefferchance der Münze zwischen \\(p=.45\\) und \\(p=.55\\), ist also nicht “nennenswert” gezinkt (auf Basis unserer Modellannahmen)?\n\n\nsamples %&gt;% \n  count(gewinnchance_muenze &gt;= 0.45 & gewinnchance_muenze &lt;= .55) %&gt;% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 × 3\n  `gewinnchance_muenze &gt;= 0.45 & gewinnchance_muenze &lt;= 0.55`     n   prop\n  &lt;lgl&gt;                                                       &lt;int&gt;  &lt;dbl&gt;\n1 FALSE                                                        9531 0.953 \n2 TRUE                                                          469 0.0469\n\n\nDie Wahrscheinlichkeit, dass die Münze nicht nennenswert gezinkt ist (nach unserer Definition), ist gering. Man sollte vielleicht erwähnen, dass unsere Definition von “nicht nennenswert gezinkt” plausibel ist, und andere (vernünftige) Definitionen zu einem sehr ähnlichen Ergebnis kämen.\n\nWas ist der wahrscheinlichste Parameterwert (Trefferchance der Münze)?\n\n\nsamples %&gt;% \n   map_estimate()\n\nMAP Estimate\n\nParameter           | MAP_Estimate\n----------------------------------\ngewinnchance_muenze |         0.82\n\n\nmap_estimate steht für …\n\nFind the Highest Maximum A Posteriori probability estimate (MAP) of a posterior, i.e., the value associated with the highest probability density (the “peak” of the posterior distribution). In other words, it is an estimation of the mode for continuous parameters.\n\n(aus der Hilfeseite der Funktion)\n\nGeben Sie das 90%-PI und 90%-HDI zum Parameterwert (\\(p\\) der Münze) an!\n\n\nlibrary(easystats)\neti(samples, ci = .9)\n\nEqual-Tailed Interval\n\nParameter           |      90% ETI\n----------------------------------\ngewinnchance_muenze | [0.53, 0.92]\n\nhdi(samples, ci = .9)\n\nHighest Density Interval\n\nParameter           |      90% HDI\n----------------------------------\ngewinnchance_muenze | [0.57, 0.94]\n\n\n\nBerechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\n\n\nPPV &lt;-\n  samples %&gt;% \n  mutate(anzahl_kopf = rbinom(n = 1e4, size = 10, prob = gewinnchance_muenze))\n\nVisualisierung:\n\nPPV %&gt;% \n  ggplot() +\n  aes(x = anzahl_kopf) +\n  labs(title = \"PPV\") +\n  geom_bar()  # geom_bar() ginge auch, sieht aber bei wenig Balken nicht so gut aus.\n\n\n\n\n\n\n\n\nLaut der PPV sind 8 von 10 Treffern der Wert, der mit der höchsten Wahrscheinlichkeit zu beobachten sein wird. Allerdings sind 7 oder 9 Treffer fast genauso wahrscheinlich. Etwas genauer:\n\nPPV %&gt;% \n  count(between(anzahl_kopf, 7,9))   # \"zähle mir, wie oft ein Wert ZWISCHEN (between) 7 und 9 vorkommt\"\n\n# A tibble: 2 × 2\n  `between(anzahl_kopf, 7, 9)`     n\n  &lt;lgl&gt;                        &lt;int&gt;\n1 FALSE                         3840\n2 TRUE                          6160\n\n\nMit dieser Wahrscheinlichkeit ist ein Wert zwischen 7 und 9 zu beobachten, wenn man den Versuch wiederholt, laut dem Modell.\n\nPPV %&gt;% \n  eti(anzahl_kopf, ci = .9)\n\nEqual-Tailed Interval\n\nParameter           |       90% ETI\n-----------------------------------\ngewinnchance_muenze | [0.53,  0.92]\nanzahl_kopf         | [4.00, 10.00]\n\n\nUnser Modell sieht einen “Passungsbereich” (ein Perzentilintervall) von 4 bis 10 Treffern als mit 90% Wahrscheinlichkeit passend an.\n\nDiskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von \\(p\\)!\n\nZwar hat eine Gleichverteilung der Priori-Werte den Vorteil, dass sie “objektiv” ist in dem Sinne, dass kein Wert “bevorteilt” wird; alle gelten als gleich wahrscheinlich. Aber das ist hochgradig unplausibel: So ist z.B. der Wert \\(p=1\\) logisch unmöglich, da wir nicht nur Treffer beobachtet haben. Ein Wert von z.B. \\(p=0.999\\) erscheint uns ebenfalls sehr unwahrscheinlich. Nützlicher erscheint daher vielleicht doch eine Priori-Verteilung, die extreme Werte von \\(p\\) als unwahrscheinlich bemisst.\n\nCategories:\n\nbayes\nprobability\nppv"
  },
  {
    "objectID": "posts/penguins-simpson/index.html",
    "href": "posts/penguins-simpson/index.html",
    "title": "penguins-simpson",
    "section": "",
    "text": "Laden Sie den Datensatz penguins (Palmerpenguins). Tipp: Es gibt ein R-Paket, in dem diese Daten wohnen. Im Skript QM2 finden sich diese Daten auch. Oder im weiten Internet.\n\n\n\n\nBerechnen Sie ein Modell, um den Zusammenhang zwischen Schnabeltiefe (UV) und Körpergewicht (AV) statistisch zu schätzen.\n\n\n\nTipp 1: estimate_relation() aus dem Paket easystats, s. QM1 oder QM2. Aber es gibt auch andere Wege.\nTipp 2: Fragen Sie ChatGPT.\n\n\n\nGeben Sie die Präzision der Regressionskoeffizienten an. Interpretieren Sie das Ergebnis.\n\n\n\n\n\n\nBerechnen Sie folgendes Modell: Gewicht als Funktion von Schnabeltiefe und von Spezies\n\n\n\nwie oben\n\n\n\nVergleichen Sie die Präzision der Regressionskoeffizienten mit dem Modell 1. Interpretieren Sie das Ergebnis."
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-1",
    "href": "posts/penguins-simpson/index.html#modell-1",
    "title": "penguins-simpson",
    "section": "",
    "text": "Berechnen Sie ein Modell, um den Zusammenhang zwischen Schnabeltiefe (UV) und Körpergewicht (AV) statistisch zu schätzen.\n\n\n\nTipp 1: estimate_relation() aus dem Paket easystats, s. QM1 oder QM2. Aber es gibt auch andere Wege.\nTipp 2: Fragen Sie ChatGPT.\n\n\n\nGeben Sie die Präzision der Regressionskoeffizienten an. Interpretieren Sie das Ergebnis."
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-2-gewicht-als-funktion-von-schnabeltiefe-und-von-spezies",
    "href": "posts/penguins-simpson/index.html#modell-2-gewicht-als-funktion-von-schnabeltiefe-und-von-spezies",
    "title": "penguins-simpson",
    "section": "",
    "text": "Berechnen Sie folgendes Modell: Gewicht als Funktion von Schnabeltiefe und von Spezies\n\n\n\nwie oben\n\n\n\nVergleichen Sie die Präzision der Regressionskoeffizienten mit dem Modell 1. Interpretieren Sie das Ergebnis."
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-1-1",
    "href": "posts/penguins-simpson/index.html#modell-1-1",
    "title": "penguins-simpson",
    "section": "2.1 Modell 1",
    "text": "2.1 Modell 1\nDaten importieren:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nAchtung: Das Paket muss installiert sein.\nPakete starten:\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nModell berechnen mit lm, d.h. “frequentistisch”:\n\nm1_freq &lt;- \n  lm(body_mass_g ~ bill_depth_mm, data = penguins)\n\nMit Bayes:\n\nlibrary(rstanarm)  # Paket muss installiert sein\nm1_bayes &lt;- \n  stan_glm(body_mass_g ~ bill_depth_mm, data = penguins,\n           refresh = 0)\n\nModellparameter:\n\nparameters(m1_freq)\n\nParameter     | Coefficient |     SE |             95% CI | t(340) |      p\n---------------------------------------------------------------------------\n(Intercept)   |     7488.65 | 335.22 | [6829.29, 8148.01] |  22.34 | &lt; .001\nbill depth mm |     -191.64 |  19.42 | [-229.84, -153.45] |  -9.87 | &lt; .001\n\n\nPro Millimeter Schnabeltiefe sinkt das Gewicht um knapp 200g, im Schnitt, laut Modell.\nDie Null ist NICHT im Schätzbereich enthalten, also können wir die Hypothese, dass der Zusammenhang zwischen Schnabeltiefe und Gewicht 0 ist, verwerfen.\nWir entscheiden uns also zu glauben, dass es einen Zusammenhang gibt. Wir können nicht ganz sicher sein, aber das Modell befürwortet diese Entscheidung.\nAllerdings sind wir nicht sicher, ob das ein Scheinzusammenhang ist oder ein “echter”, d.h. kausaler Zusammenhang.\n\nparameters(m1_bayes)\n\nParameter     |  Median |             95% CI |   pd |  Rhat |     ESS |                       Prior\n---------------------------------------------------------------------------------------------------\n(Intercept)   | 7483.18 | [6853.18, 8102.24] | 100% | 1.000 | 4014.00 | Normal (4201.75 +- 2004.89)\nbill_depth_mm | -191.16 | [-227.38, -154.91] | 100% | 1.000 | 4001.00 |    Normal (0.00 +- 1015.24)\n\n\nEin typischer Befund: Frequentistische und Bayes-Ergebnisse sind - bei genügend großen Stichproben - sehr ähnlich, was die Zahlen betrifft. Sehr unterschiedlich ist aber die Interpretation.\nBayes-Interpretation:\n“Mit 95% Wahrscheinlichkeit liegt der Effekt zwischen -230g und 150g pro Millimeter Schnabeltiefe, laut dem Modell.”\nFrequentistische Interpretation:\n“Würde man sehhhr viele Stichproben aus der zugrundeliegenden Population ziehen und für jede Stichprobe ein 95%-Konfindenzintervall berechnen würde, dann würde in 95% der Fälle das wahre Populationsmittel in diesem Intervall liegen. In unserer konkreten Stichprobe lagen die Grenzen bei ca. -230 bis -150. Ob der wahre Wert in diesem bestimmten Intervall liegt, können wir aber nicht sagen.”\nModell visualisieren:\n\nestimate_relation(m1_freq) |&gt; plot()"
  },
  {
    "objectID": "posts/penguins-simpson/index.html#modell-2",
    "href": "posts/penguins-simpson/index.html#modell-2",
    "title": "penguins-simpson",
    "section": "2.2 Modell 2",
    "text": "2.2 Modell 2\nModell berechnen mit lm, d.h. “frequentistisch”:\n\nm2_freq &lt;- \n  lm(body_mass_g ~ bill_depth_mm + species, data = penguins)\n\nMit Bayes:\n\nlibrary(rstanarm)  # Paket muss installiert sein\nm2_bayes &lt;- \n  stan_glm(body_mass_g ~ bill_depth_mm + species, data = penguins, refresh = 0)\n\nModellparameter:\n\nparameters(m2_freq)\n\nParameter           | Coefficient |     SE |              95% CI | t(338) |      p\n----------------------------------------------------------------------------------\n(Intercept)         |    -1007.28 | 323.56 | [-1643.73, -370.83] |  -3.11 | 0.002 \nbill depth mm       |      256.61 |  17.56 | [  222.07,  291.16] |  14.61 | &lt; .001\nspecies [Chinstrap] |       13.38 |  52.95 | [  -90.77,  117.52] |   0.25 | 0.801 \nspecies [Gentoo]    |     2238.67 |  73.68 | [ 2093.74, 2383.60] |  30.38 | &lt; .001\n\nparameters(m2_bayes)\n\nParameter        |   Median |              95% CI |     pd |  Rhat |     ESS |                       Prior\n----------------------------------------------------------------------------------------------------------\n(Intercept)      | -1020.57 | [-1658.20, -384.09] | 99.90% | 1.000 | 2313.00 | Normal (4201.75 +- 2004.89)\nbill_depth_mm    |   257.45 | [  222.63,  291.87] |   100% | 1.000 | 2306.00 |    Normal (0.00 +- 1015.24)\nspeciesChinstrap |    12.68 | [  -90.53,  117.67] | 59.45% | 1.002 | 3678.00 |    Normal (0.00 +- 5015.92)\nspeciesGentoo    |  2239.94 | [ 2092.14, 2385.42] |   100% | 1.000 | 2669.00 |    Normal (0.00 +- 4171.63)\n\n\nÄh, Moment … Jetzt ist der Zusammenhang zwischen Schnabeltiefe und Gewicht nicht mehr negativ, sondern POSITIV?! Der Effekt geht in die entgegengesetzte Richtung? Kann das sein?!\nEin Bild zur Hilfe:\n\nm2_freq |&gt; estimate_relation() |&gt; plot()\n\n\n\n\n\n\n\n\nTatsächlich! Jetzt ist der Zusammenhang innerhalb jeder Gruppe (Spezies) POSITIV.\nDas bedeutet: Wenn wir die Spezies berücksichtigen, dann ist der Zusammenhang zwischen Schnabeltiefe und Gewicht positiv.\nDiesen Vorzeichenwechsel nennt man “Simpson-Paradox”.\n\n2.2.1 Fazit: Welches Modell ist jetzt richtig?\nDa sich die Effekte komplett widersprechen (negativ vs. positiver Zusammenhang) stellt sich die Frage: Welchem Modell - Modell 1 oder Modell 2 - glauben wir jetzt?\nDie Antwort ist ein klares: Kommt drauf an. Kommt drauf an, welcher Theorie zum kausalen Zusammenhang der betreffenden Variablen wir glauben."
  },
  {
    "objectID": "posts/bertie-bott3/index.html",
    "href": "posts/bertie-bott3/index.html",
    "title": "bertie-bott3",
    "section": "",
    "text": "1 Aufgabe\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=3\\) furchtbar scheußliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erklärt, \\(k=3\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt heißt es tapfer sein. Ziehen und runter damit!\nWie groß ist die Wahrscheinlichkeit, genau eine scheußliche Bohne zu erwischen?\nHinweis:\n\nGeben Sie das Ergebnis auf 3 Nachkommastellen gerundet an.\nBeachten Sie die Hinweise des Datenwerks\n\n           \n\n\n2 Lösung\nEs gibt drei Pfade für 1 Treffer bei 3 Wiederholungen:\n\nPfad1 &lt;- 3/20 * 17/19 * 16/18\nPfad2 &lt;- 17/20 * 3/19 * 16/18\nPfad3 &lt;- 17/20 * 16/19 * 3/18\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 + Pfad3\nGesamt_Pr\n\n[1] 0.3578947"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "chatgpt-sentiment-loop-all",
    "section": "",
    "text": "Fragen Sie ChatGPT via API zum Sentiment der Texte aus dem Germeval-2018-Datensatz (Test).\nHinweise:\n\nBeachten Sie die Standardhinweise des Datenwerks.\nNutzen Sie Python, nicht R.\nDas Verwenden der OpenAI-API kostet Geld. 💸 Informieren Sie sich vorab über die Preise von OpenAI. Um auf die API zugreifen zu können, müssen Sie sich ein Konto angelegt haben und über ein Guthaben verfügen. Sie können unter https://platform.openai.com/usage Ihre Kosten prüfen."
  },
  {
    "objectID": "posts/index.html#achtung",
    "href": "posts/index.html#achtung",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Achtung",
    "text": "Achtung\n\nOpenAI hat eine neue API (Stand: 2023-11-23), V1.3.5. Der Code der alten API bricht. 💔 \\(\\square\\)"
  },
  {
    "objectID": "posts/index.html#setup",
    "href": "posts/index.html#setup",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Setup",
    "text": "Setup\nDie richtige venv nutzen:\n\nlibrary(reticulate)\n#virtualenv_create(\"chatgpt\")\nuse_virtualenv(\"chatgpt\")\n\nCheck zu Python:\n\nreticulate::py_config()\n\nGgf. noch Module installieren:\n\n#reticulate::py_install(\"pandas\")\n#py_install(\"tiktoken\")\n#py_install(\"datar\")\n#py_install(\"scikit-learn\")"
  },
  {
    "objectID": "posts/index.html#r-pakete-und-python-module",
    "href": "posts/index.html#r-pakete-und-python-module",
    "title": "chatgpt-sentiment-loop-all",
    "section": "R-Pakete und Python-Module",
    "text": "R-Pakete und Python-Module\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(plotly)\n\nModule importieren:\n\nfrom openai import OpenAI\nimport pandas as pd\nimport numpy as np\nimport time\nfrom datetime import datetime\n#from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nVersionen der importierten Module:\n\npd.__version__\n\n\n```{zsh openai-version-zsh}\npip list | grep openai\n```\n\nWir brauchen &gt;= 1.35.\nDer Operator | ist die “Pfeife” der Kommandozeile, also sozusagen der “UND-DANN-Befehl”."
  },
  {
    "objectID": "posts/index.html#daten",
    "href": "posts/index.html#daten",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Daten",
    "text": "Daten\nDaten importieren:\n\ncsv_file_path_test = 'https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv'\n\ngermeval_test = pd.read_csv(csv_file_path_test)\n\nDie ersten paar Texte herausziehen:\n\nstart_pos = 0\nend_pos = 3531\ntweets = germeval_test[\"text\"].iloc[start_pos:(end_pos+1)].tolist()"
  },
  {
    "objectID": "posts/index.html#prompt",
    "href": "posts/index.html#prompt",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Prompt",
    "text": "Prompt\nPrompt definieren:\n\nprompt_stem  = \"Als KI mit Exertise in natürlicher Sprache und Emotionserkennung ist es Ihre Aufgabe, das Sentiment des folgenden Textes einzuschätzen. Bitte antworten Sie nur mit einem einzigen Wort, entweder 'positiv', 'neutral' oder 'negativ'. Ihre Antwort soll Ihre Insgesamt-Einschätzung zum Sentiments des Textes zusammenfassen. Nach dem Doppelpunkt folgt der Text, dessen Sentiment Sie einschätzen sollen: \"\n\nGute Prompts können helfen, gute Antworten vom Modell zu erhalten.\nMit “List Comprehension” können wir die Tweets jeweils mit dem Prompt verknüpfen:\n\nprompts = [prompt_stem + tweet for tweet in tweets]\nprompts[0]\n\nCheck: Wie viele Elemente hat die Liste prompts?\n\nlen(prompts)\n\nLaut OpenAI kostet 1k Token für das Modell gpt-3.5-turbo-1106 $0.001."
  },
  {
    "objectID": "posts/index.html#authentifizieren",
    "href": "posts/index.html#authentifizieren",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Authentifizieren",
    "text": "Authentifizieren\nAnmelden bei OpenAI:\n\nclient = OpenAI()\n\n\n\n\n\n\n\nNote\n\n\n\nDieses Anmeldeverfahren setzt voraus, dass in .Renviron die Variable OPENAI_API_KEY hinterlegt ist. \\(\\square\\)\n\n\nAnfrage an die API, in eine Funktion gepackt:\n\ndef get_completion(prompt, client_instance, model=\"gpt-3.5-turbo\"):\n  messages = [{\"role\": \"user\", \"content\": prompt}]\n  response = client_instance.chat.completions.create(\n    model=model,\n    messages=messages,\n    max_tokens=50,\n    temperature=0,\n  )\n  return response.choices[0].message.content"
  },
  {
    "objectID": "posts/index.html#api-anfragen",
    "href": "posts/index.html#api-anfragen",
    "title": "chatgpt-sentiment-loop-all",
    "section": "API anfragen",
    "text": "API anfragen\nUnd jetzt als Schleife. Ergebnisliste anlegen, am Anfang noch leer:\n\npredicted_values = []\n\n\nstart_time = time.time()\n\nfor prompt in prompts:\n  result = get_completion(prompt, client) \n  predicted_values.append(result)\n\nend_time = time.time()\nend_time - start_time\n\nVoilà:\n\nprint(predicted_values[:5])"
  },
  {
    "objectID": "posts/index.html#als-csv-speichern",
    "href": "posts/index.html#als-csv-speichern",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Als CSV speichern",
    "text": "Als CSV speichern\n\nid_seq = [i for i in range(start_pos, end_pos + 1)]\npredicted_values_df = pd.DataFrame(id_seq, columns = [\"id\"])\npredicted_values_df[\"pred\"] = predicted_values\n\nnow = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\ncsv_output_name = \"germeval_test_preds_at_\" + now\npredicted_values_df.to_csv(csv_output_name)"
  },
  {
    "objectID": "posts/index.html#oder-vorhersagen-aus-csv-importieren",
    "href": "posts/index.html#oder-vorhersagen-aus-csv-importieren",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Oder Vorhersagen aus CSV importieren",
    "text": "Oder Vorhersagen aus CSV importieren\n\npreds_path = 'https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/posts/chatgpt-sentiment-loop-all/germeval_test_preds_at_2023-12-20%2014%3A06%3A00'\n\npreds = pd.read_csv(preds_path)\n\npreds.head()\n\nMan kann eine Python-Variable an R übergeben:\n\npreds_r &lt;- py$preds"
  },
  {
    "objectID": "posts/index.html#vorhersagen-predictions-betrachten",
    "href": "posts/index.html#vorhersagen-predictions-betrachten",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Vorhersagen (Predictions) betrachten",
    "text": "Vorhersagen (Predictions) betrachten\nZählen wir mal kurz aus:\n\npreds_r |&gt; \n  count(pred) |&gt; \n  slice(3:5)  # zwei komische, kaputte Zeilen, weg damit\n\nOder in Python:\n\npreds[\"pred\"].value_counts()\n\nPuh, das ist ein bisschen was kaput gegangen."
  },
  {
    "objectID": "posts/index.html#predictions-reparieren",
    "href": "posts/index.html#predictions-reparieren",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Predictions reparieren",
    "text": "Predictions reparieren\n\nallowed_preds = [\"positiv\", \"neutral\", \"negativ\"]\npreds.loc[~preds[\"pred\"].isin(allowed_preds), \"pred\"] = np.nan\n\nCheck:\n\npreds[\"pred\"].value_counts()\n\nPasst!"
  },
  {
    "objectID": "posts/index.html#scoring-vorbereiten",
    "href": "posts/index.html#scoring-vorbereiten",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Scoring vorbereiten",
    "text": "Scoring vorbereiten\nWas waren noch mal die Variablen unser Tabelle?\n\ngermeval_test.columns\n\nDie ersten paar Werte:\n\ngermeval_test.head()\n\nRescore im Test-Set:\n\ndf = germeval_test\ndf[\"c1\"] = df[\"c1\"].replace({\"OFFENSE\": \"negativ\"})\n\ndf[\"c1\"].value_counts()\n\nRescore in den Vorhersagen\n\npreds[\"pred\"] = preds[\"pred\"].replace({\"neutral\": \"OTHER\", \"positiv\": \"OTHER\"})\n\npreds[\"pred\"].value_counts()\n\n\npreds_list = preds[\"pred\"].tolist()\n\nHier ist die Liste der wahren Werte:\n\ny = df[\"c1\"].values.tolist()"
  },
  {
    "objectID": "posts/index.html#scoring",
    "href": "posts/index.html#scoring",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Scoring",
    "text": "Scoring\n\naccuracy = accuracy_score(y, preds_list)\nprint(\"Accuracy:\", accuracy)\n\nOder mit tidymodels; zuerst aufbereiten:\n\ny_truth = as.factor(py$y)\ny_pred = py$preds_list \n\n# replace NAN with NA and convert to factor:\ny_pred = as.character(y_pred) \ny_pred[is.nan(y_pred)] &lt;- NA\ny_pred[!y_pred %in% c(\"negativ\", \"OTHER\")] &lt;- NA\ny_pred &lt;- as.factor(y_pred)\n\ntable(y_pred)\n\n\naccuracy_vec(truth = y_truth,\n             estimate = y_pred)"
  },
  {
    "objectID": "posts/index.html#fun",
    "href": "posts/index.html#fun",
    "title": "chatgpt-sentiment-loop-all",
    "section": "Fun",
    "text": "Fun\n\nfig &lt;- plot_ly(\n  domain = list(x = c(0, 1), y = c(0, 1)),\n  value = 74,\n  title = list(text = \"Accuracy\"),\n  type = \"indicator\",\n  mode = \"gauge+number\") \nfig &lt;- fig %&gt;%\n  layout(margin = list(l=20,r=30))\n\nfig"
  },
  {
    "objectID": "posts/lm-Standardfehler/lm-Standardfehler.html",
    "href": "posts/lm-Standardfehler/lm-Standardfehler.html",
    "title": "lm-Standardfehler",
    "section": "",
    "text": "Man kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser Übung untersuchen wir, wie sich der SE als Funktion der Stichprobengröße, \\(n\\), verhält.\nErstellen Sie dazu folgenden Datensatz:\n\nlibrary(tidyverse)\n\nn &lt;- 2^4\n\nd &lt;-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nHier ist das Ergebnis. Uns interessiert v.a. Std. Error für den Prädiktor x:\n\nlm(y ~ x, data = d) %&gt;% \nsummary()\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8039 -0.3986 -0.1500  0.6939  0.8013 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.1610     0.1446   1.114    0.284    \nx             1.1144     0.1660   6.711 9.92e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5777 on 14 degrees of freedom\nMultiple R-squared:  0.7629,    Adjusted R-squared:  0.746 \nF-statistic: 45.04 on 1 and 14 DF,  p-value: 9.919e-06\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie, wie sich die Schätzgenauigkeit, gemessen über den SE, verändert. Berechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\nBei welcher Stichprobengröße ist SE am kleinsten?\n\n\n\n\\(2^5\\)\n\\(2^6\\)\n\\(2^7\\)\n\\(2^8\\)\n\\(2^9\\)"
  },
  {
    "objectID": "posts/lm-Standardfehler/lm-Standardfehler.html#answerlist",
    "href": "posts/lm-Standardfehler/lm-Standardfehler.html#answerlist",
    "title": "lm-Standardfehler",
    "section": "",
    "text": "\\(2^5\\)\n\\(2^6\\)\n\\(2^7\\)\n\\(2^8\\)\n\\(2^9\\)"
  },
  {
    "objectID": "posts/lm-Standardfehler/lm-Standardfehler.html#answerlist-1",
    "href": "posts/lm-Standardfehler/lm-Standardfehler.html#answerlist-1",
    "title": "lm-Standardfehler",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\nCategories:\n\ninference\nlm\nqm2"
  },
  {
    "objectID": "posts/adjustieren2_var1/adjustieren2_var1.html",
    "href": "posts/adjustieren2_var1/adjustieren2_var1.html",
    "title": "adjustieren2_var1",
    "section": "",
    "text": "Aufgabe\nBetrachten Sie folgendes Modell, das den Zusammenhang des Preises (price) und dem Gewicht (carat) von Diamanten untersucht (Datensatz diamonds).\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\ndiamonds &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\")\n\nRows: 53940 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): cut, color, clarity\ndbl (8): rownames, carat, depth, table, price, x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAber zuerst zentrieren wir den metrischen Prädiktor carat, um den Achsenabschnitt besser interpretieren zu können.\n\ndiamonds2 &lt;-\n  diamonds %&gt;% \n  mutate(carat_z = carat - mean(carat, na.rm = TRUE))\n\nDann berechnen wir ein (bayesianisches) Regressionsmodell, wobei wir auf die Standardwerte der Prior zurückgreifen.\n\nlibrary(rstanarm)\nlm1 &lt;- stan_glm(price ~ carat_z, data = diamonds2,\n                refresh = 0)\nparameters(lm1)\n\nParameter   |  Median |             95% CI |   pd |  Rhat |     ESS |                       Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 3932.64 | [3919.83, 3945.55] | 100% | 1.004 | 1178.00 | Normal (3932.80 +- 9973.60)\ncarat_z     | 7755.90 | [7727.59, 7783.52] | 100% | 1.000 | 4716.00 |   Normal (0.00 +- 21040.85)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nZur Verdeutlichung ein Diagramm zum Modell:\n\ndiamonds2 %&gt;% \n  ggplot() +\n  aes(x = carat_z, y = price) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOder so:\n\nestimate_relation(lm1) |&gt; plot()\n\n\n\n\n\n\n\n\nAufgabe:\nGeben Sie eine Regressionsformel an, die lm1 ergänzt, so dass die Schliffart (cut) des Diamanten kontrolliert (adjustiert) wird. Anders gesagt: Das Modell soll die mittleren Preise für jede der fünf Schliffarten angeben.\nHinweis:\n\nGeben Sie nur die Regressionsformel an.\nLassen Sie zwischen Termen der Regressionsformel jeweils ein Leerzeichen Abstand.\nBeziehen Sie sich auf das Modell bzw. die Angaben oben.\nEs gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\n\n\ndiamonds %&gt;% \n  distinct(cut)\n\n# A tibble: 5 × 1\n  cut      \n  &lt;chr&gt;    \n1 Ideal    \n2 Premium  \n3 Good     \n4 Very Good\n5 Fair     \n\n\n         \n\n\nLösung\nDie richtige Antwort lautet: price ~ carat_z + cut\nDas Modell könnten wir so berechnen:\n\nlm2 &lt;- stan_glm(price ~ carat_z + cut, data = diamonds2,\n                refresh = 0)  # verhindert einen Haufen unnötigen Output\nparameters(lm2)\n\nParameter    |  Median |             95% CI |   pd |  Rhat |     ESS |                       Prior\n--------------------------------------------------------------------------------------------------\n(Intercept)  | 2401.60 | [2326.67, 2475.70] | 100% | 1.000 | 1022.00 | Normal (3932.80 +- 9973.60)\ncarat_z      | 7871.06 | [7844.55, 7898.35] | 100% | 0.999 | 3734.00 |   Normal (0.00 +- 21040.85)\ncutGood      | 1124.68 | [1040.23, 1213.25] | 100% | 1.000 | 1224.00 |   Normal (0.00 +- 34685.38)\ncutIdeal     | 1804.40 | [1726.43, 1883.62] | 100% | 1.000 | 1083.00 |   Normal (0.00 +- 20362.28)\ncutPremium   | 1443.13 | [1365.40, 1520.66] | 100% | 1.000 | 1099.00 |   Normal (0.00 +- 22862.49)\ncutVery Good | 1513.52 | [1435.77, 1594.26] | 100% | 1.000 | 1092.00 |   Normal (0.00 +- 23922.15)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nOder auch so, mit der klassischen Regression:\nlm(price ~ carat_z + cut, data = diamonds2) gi```\nDas führt zu ähnlichen Ergebnissen.\nMan könnte hier noch einen Interaktionseffekt ergänzen.\n\nCategories:\n\nlm\nregression\nbayes\nadjust\nstring"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Untitled",
    "section": "",
    "text": "Überschrift\nsjdfk\nsdjklf\n\ndfsjk\nsdfjlk\n\n\n \nThis is a form spacer\n\nA text field (1)\n  \n\n\nAnother text field (2)"
  }
]