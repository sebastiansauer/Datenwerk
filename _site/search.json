[
  {
    "objectID": "posts/kekse02/kekse02.html",
    "href": "posts/kekse02/kekse02.html",
    "title": "kekse02",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.01\n1\n0.01\n0.01\n0.00\n\n\n0.02\n1\n0.02\n0.02\n0.00\n\n\n0.03\n1\n0.03\n0.03\n0.00\n\n\n0.04\n1\n0.04\n0.04\n0.00\n\n\n0.05\n1\n0.05\n0.05\n0.00\n\n\n0.06\n1\n0.06\n0.06\n0.00\n\n\n0.07\n1\n0.07\n0.07\n0.00\n\n\n0.08\n1\n0.08\n0.08\n0.00\n\n\n0.09\n1\n0.09\n0.09\n0.00\n\n\n0.10\n1\n0.10\n0.10\n0.00\n\n\n0.11\n1\n0.11\n0.11\n0.00\n\n\n0.12\n1\n0.12\n0.12\n0.00\n\n\n0.13\n1\n0.13\n0.13\n0.00\n\n\n0.14\n1\n0.14\n0.14\n0.00\n\n\n0.15\n1\n0.15\n0.15\n0.00\n\n\n0.16\n1\n0.16\n0.16\n0.00\n\n\n0.17\n1\n0.17\n0.17\n0.00\n\n\n0.18\n1\n0.18\n0.18\n0.00\n\n\n0.19\n1\n0.19\n0.19\n0.00\n\n\n0.20\n1\n0.20\n0.20\n0.00\n\n\n0.21\n1\n0.21\n0.21\n0.00\n\n\n0.22\n1\n0.22\n0.22\n0.00\n\n\n0.23\n1\n0.23\n0.23\n0.00\n\n\n0.24\n1\n0.24\n0.24\n0.00\n\n\n0.25\n1\n0.25\n0.25\n0.00\n\n\n0.26\n1\n0.26\n0.26\n0.01\n\n\n0.27\n1\n0.27\n0.27\n0.01\n\n\n0.28\n1\n0.28\n0.28\n0.01\n\n\n0.29\n1\n0.29\n0.29\n0.01\n\n\n0.30\n1\n0.30\n0.30\n0.01\n\n\n0.31\n1\n0.31\n0.31\n0.01\n\n\n0.32\n1\n0.32\n0.32\n0.01\n\n\n0.33\n1\n0.33\n0.33\n0.01\n\n\n0.34\n1\n0.34\n0.34\n0.01\n\n\n0.35\n1\n0.35\n0.35\n0.01\n\n\n0.36\n1\n0.36\n0.36\n0.01\n\n\n0.37\n1\n0.37\n0.37\n0.01\n\n\n0.38\n1\n0.38\n0.38\n0.01\n\n\n0.39\n1\n0.39\n0.39\n0.01\n\n\n0.40\n1\n0.40\n0.40\n0.01\n\n\n0.41\n1\n0.41\n0.41\n0.01\n\n\n0.42\n1\n0.42\n0.42\n0.01\n\n\n0.43\n1\n0.43\n0.43\n0.01\n\n\n0.44\n1\n0.44\n0.44\n0.01\n\n\n0.45\n1\n0.45\n0.45\n0.01\n\n\n0.46\n1\n0.46\n0.46\n0.01\n\n\n0.47\n1\n0.47\n0.47\n0.01\n\n\n0.48\n1\n0.48\n0.48\n0.01\n\n\n0.49\n1\n0.49\n0.49\n0.01\n\n\n0.50\n1\n0.50\n0.50\n0.01\n\n\n0.50\n1\n0.50\n0.50\n0.01\n\n\n0.51\n1\n0.51\n0.51\n0.01\n\n\n0.52\n1\n0.52\n0.52\n0.01\n\n\n0.53\n1\n0.53\n0.53\n0.01\n\n\n0.54\n1\n0.54\n0.54\n0.01\n\n\n0.55\n1\n0.55\n0.55\n0.01\n\n\n0.56\n1\n0.56\n0.56\n0.01\n\n\n0.57\n1\n0.57\n0.57\n0.01\n\n\n0.58\n1\n0.58\n0.58\n0.01\n\n\n0.59\n1\n0.59\n0.59\n0.01\n\n\n0.60\n1\n0.60\n0.60\n0.01\n\n\n0.61\n1\n0.61\n0.61\n0.01\n\n\n0.62\n1\n0.62\n0.62\n0.01\n\n\n0.63\n1\n0.63\n0.63\n0.01\n\n\n0.64\n1\n0.64\n0.64\n0.01\n\n\n0.65\n1\n0.65\n0.65\n0.01\n\n\n0.66\n1\n0.66\n0.66\n0.01\n\n\n0.67\n1\n0.67\n0.67\n0.01\n\n\n0.68\n1\n0.68\n0.68\n0.01\n\n\n0.69\n1\n0.69\n0.69\n0.01\n\n\n0.70\n1\n0.70\n0.70\n0.01\n\n\n0.71\n1\n0.71\n0.71\n0.01\n\n\n0.72\n1\n0.72\n0.72\n0.01\n\n\n0.73\n1\n0.73\n0.73\n0.01\n\n\n0.74\n1\n0.74\n0.74\n0.01\n\n\n0.75\n1\n0.75\n0.75\n0.02\n\n\n0.76\n1\n0.76\n0.76\n0.02\n\n\n0.77\n1\n0.77\n0.77\n0.02\n\n\n0.78\n1\n0.78\n0.78\n0.02\n\n\n0.79\n1\n0.79\n0.79\n0.02\n\n\n0.80\n1\n0.80\n0.80\n0.02\n\n\n0.81\n1\n0.81\n0.81\n0.02\n\n\n0.82\n1\n0.82\n0.82\n0.02\n\n\n0.83\n1\n0.83\n0.83\n0.02\n\n\n0.84\n1\n0.84\n0.84\n0.02\n\n\n0.85\n1\n0.85\n0.85\n0.02\n\n\n0.86\n1\n0.86\n0.86\n0.02\n\n\n0.87\n1\n0.87\n0.87\n0.02\n\n\n0.88\n1\n0.88\n0.88\n0.02\n\n\n0.89\n1\n0.89\n0.89\n0.02\n\n\n0.90\n1\n0.90\n0.90\n0.02\n\n\n0.91\n1\n0.91\n0.91\n0.02\n\n\n0.92\n1\n0.92\n0.92\n0.02\n\n\n0.93\n1\n0.93\n0.93\n0.02\n\n\n0.94\n1\n0.94\n0.94\n0.02\n\n\n0.95\n1\n0.95\n0.95\n0.02\n\n\n0.96\n1\n0.96\n0.96\n0.02\n\n\n0.97\n1\n0.97\n0.97\n0.02\n\n\n0.98\n1\n0.98\n0.98\n0.02\n\n\n0.99\n1\n0.99\n0.99\n0.02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes-grid"
  },
  {
    "objectID": "posts/Likelihood2/Likelihood2.html",
    "href": "posts/Likelihood2/Likelihood2.html",
    "title": "Likelihood2",
    "section": "",
    "text": "Der Likelihood eines Datensatzes ist definiert als das Produkt der Likelihoods aller Beobachtungen:\n\\[\\mathcal{L} = \\prod_{i=1}^n \\mathcal{L_i}\\]\nwobei die Beobachtungen bzw. ihre Likelihood als unabhängig angenommen werden: \\(\\mathcal{L_i} \\perp \\mathcal{L_j}, \\quad i \\ne j\\).\nJe größer \\(n\\), desto …….. \\(\\mathcal{L}\\)!\nFüllen Sie die Lücke!\n\n\n\ngrößer\nkleiner\nunabhängig voneinander\nkeine Aussage möglich\nkommt auf weitere, hier nicht benannte Bedingungen an"
  },
  {
    "objectID": "posts/Likelihood2/Likelihood2.html#answerlist-1",
    "href": "posts/Likelihood2/Likelihood2.html#answerlist-1",
    "title": "Likelihood2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nRichtig\nFalsch\nFalsch\nFalsch\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/Anteil-Apple/Anteil-Apple.html",
    "href": "posts/Anteil-Apple/Anteil-Apple.html",
    "title": "Anteil-Apple",
    "section": "",
    "text": "Solution\nWir berechnen die Posteriori-Verteilung:\n\nlibrary(tidyverse)\nd <-\n  tibble(\n    p_grid = seq(0,1, by = .01),\n    prior= 1,\n    Likelihood = dbinom(x = 9,\n                        size = 12,\n                        prob = p_grid),\n    post_unstand = prior * Likelihood,\n    post_stand = post_unstand / sum(post_unstand)\n  )\n\nhead(d)\n\n# A tibble: 6 × 5\n  p_grid prior Likelihood post_unstand post_stand\n   <dbl> <dbl>      <dbl>        <dbl>      <dbl>\n1   0        1   0            0          0       \n2   0.01     1   2.13e-16     2.13e-16   2.78e-17\n3   0.02     1   1.06e-13     1.06e-13   1.38e-14\n4   0.03     1   3.95e-12     3.95e-12   5.14e-13\n5   0.04     1   5.10e-11     5.10e-11   6.63e-12\n6   0.05     1   3.68e-10     3.68e-10   4.79e-11\n\n\nVisualisieren der Posteriori-Verteilung:\n\nd %>% \n  ggplot(aes(x = p_grid, y = post_stand)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\n\nCategories:\n\nbayes\nbayes-box"
  },
  {
    "objectID": "posts/IQ-Studentis/IQ-Studentis.html",
    "href": "posts/IQ-Studentis/IQ-Studentis.html",
    "title": "IQ-Studentis",
    "section": "",
    "text": "Solution\n\nGeben Sie die Priors an.\n\n\\[\\mu \\sim \\mathcal{N}(115, 5)\\]\n\\[\\sigma \\sim \\mathcal{E}(0.1)\\]\n\nSimulieren Sie die Prior-Prädiktiv-Verteilung dazu.\n\nZiehen wir Zufallszahlen entsprechend der Priori-Werte:\n\nlibrary(tidyverse)\nn <- 1e4\n\nsim <-\n  tibble(\n    sample_mu = rnorm(n,\n      mean = 115,\n      sd   = 10\n    ),\n    sample_sigma = rexp(n,\n      rate = 0.1\n    ),\n    iq = rnorm(n,\n      mean = sample_mu,\n      sd   = sample_sigma\n    )\n  )\n\nWas ist wohl der Mittelwert und die SD dieser Priori-Prädiktiv-Verteilung?\n\nheight_sim_sd <-\n  sd(sim$iq) %>% round()\nheight_sim_sd\n\n[1] 17\n\n\n\nheight_sim_mean <-\n  mean(sim$iq) %>% round()\nheight_sim_mean\n\n[1] 115\n\n\nUnd jetzt plotten wir diese Verteilung:\n\nsim %>%\n  ggplot() +\n  aes(x = iq) +\n  geom_histogram() +\n  geom_point(\n    y = 0, x = height_sim_mean, size = 5,\n    color = \"blue\", alpha = .5\n  ) +\n  geom_vline(\n    xintercept = c(\n      height_sim_mean + height_sim_sd,\n      height_sim_mean - height_sim_sd\n    ),\n    linetype = \"dotted\"\n  ) +\n  labs(caption = \"Der blaue Punkt zeigt den Mittelwert; die gepunkteten Linien MD±SD\") +\n  scale_x_continuous(\n    limits = c(70, 145),\n    breaks = seq(70, 145, by = 5)\n  )\n\n\n\n\n\n\n\n\nOder vielleicht besser als Dichte-Diagramm, das zeigt das “Big Picture” vielleicht besser:\n\nsim %>%\n  ggplot() +\n  aes(x = iq) +\n  geom_density()\n\n\n\n\n\n\n\n\nHm, etwas randlastig die Verteilung.\nZoomen wir etwas mehr rein:\n\nsim %>%\n  ggplot() +\n  aes(x = iq) +\n  geom_density() +\n  scale_x_continuous(limits = c(65, 165))\n\n\n\n\n\n\n\n\n\nBefragen Sie die Prior-Prädiktiv-Verteilung mit geeigneten Fragen Ihrer Wahl.\n\nWas ist der Mittelwert und die SD und die üblichen deskriptiven Kennwerte?\n\nlibrary(easystats)\n\n\nsim %>%\n  select(iq) %>%\n  describe_distribution()\n\nVariable |   Mean |    SD |   IQR |            Range | Skewness | Kurtosis |     n | n_Missing\n----------------------------------------------------------------------------------------------\niq       | 115.49 | 17.26 | 18.51 | [-22.36, 275.94] |     0.21 |     5.63 | 10000 |         0\n\n\nIn welchem Bereich liegen die mittleren 95% der IQ-Werte?\n\nsim %>%\n  eti()\n\nEqual-Tailed Interval\n\nParameter    |         95% ETI\n------------------------------\nsample_mu    | [95.77, 134.90]\nsample_sigma | [ 0.23,  37.46]\niq           | [81.22, 150.08]\n\n\nAlternativ könnten wir in z-transformierten Daten denken:\n\nsim2 <-\n  tibble(\n    sample_mu =\n      rnorm(n,\n        mean = 0,\n        sd   = 1\n      ),\n    sample_sigma =\n      rexp(n,\n        rate = 1\n      )\n  ) %>%\n  mutate(\n    iq =\n      rnorm(n,\n        mean = sample_mu,\n        sd   = sample_sigma\n      )\n  )\n\n\nsim2 %>%\n  ggplot() +\n  aes(x = iq) +\n  geom_density()\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes\nsimulation"
  },
  {
    "objectID": "posts/fattails02/fattails02.html",
    "href": "posts/fattails02/fattails02.html",
    "title": "fattails02",
    "section": "",
    "text": "Answerlist\n\nkleiner als 50%\nkleiner als 5%\nkleiner als 0.5%\nkleiner als 0.05%\nkleiner als 0.005%\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nErstellen wir erstmal den ersten Teil einer Bayes-Box:\n\nd <-\n  tibble(H = c(\"Normalverteilt\", \"Randlastig verteilt\"),\n         Prior = c(1e3,1))\n\nd\n\n# A tibble: 2 × 2\n  H                   Prior\n  <chr>               <dbl>\n1 Normalverteilt       1000\n2 Randlastig verteilt     1\n\n\nDann fügen wir den Likelihood jeder Hypothese dazu:\n\nd <-\n  d %>% \n  mutate(L = c(L_norm, L_fat))\n\nd\n\n# A tibble: 2 × 3\n  H                   Prior        L\n  <chr>               <dbl>    <dbl>\n1 Normalverteilt       1000 1.31e-23\n2 Randlastig verteilt     1 4.93e- 3\n\n\nDann berechnen wir die Post-Wahrscheinlichkeit:\n\nd <-\n  d %>% \n  mutate(Post_unstand = Prior * L,\n         Post = Post_unstand / sum(Post_unstand))\nd\n\n# A tibble: 2 × 5\n  H                   Prior        L Post_unstand     Post\n  <chr>               <dbl>    <dbl>        <dbl>    <dbl>\n1 Normalverteilt       1000 1.31e-23     1.31e-20 2.66e-18\n2 Randlastig verteilt     1 4.93e- 3     4.93e- 3 1   e+ 0\n\n\nDie Wahrscheinlichkeit, dass die Variable normalverteilt ist, ist seeeeehr klein, ca. \\(10^{-18}\\).\n\n\nAnswerlist\n\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/korr-als-regr/korr-als-regr.html",
    "href": "posts/korr-als-regr/korr-als-regr.html",
    "title": "korr-als-regr",
    "section": "",
    "text": "Exercise\nDie Korrelation prüft, ob zwei Merkmale linear zusammenhängen.\nWie viele andere Verfahren kann die Korrelation als ein Spezialfall der Regression bzw. des linearen Modells \\(y = \\beta_0 + \\beta_1 + \\ldots \\beta_n + \\epsilon\\) betrachtet werden.\nAls ein spezielles Beispiel betrachten wir die Frage, ob das Gewicht eines Diamanten (carat) mit dem Preis (price) zusammenhängt (Datensatz diamonds).\nDen Datensatz können Sie so laden:\n\nlibrary(tidyverse)\ndata(diamonds)\n\n\nGeben Sie das Skalenniveau beider Variablen an!\nBetrachten Sie die Ausgabe von R:\n\n\nlm1 <- lm(price ~ carat, data = diamonds)\nsummary(lm1)\n\n\nCall:\nlm(formula = price ~ carat, data = diamonds)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-18585   -805    -19    537  12732 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -2256.4       13.1    -173   <2e-16 ***\ncarat         7756.4       14.1     551   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1550 on 53938 degrees of freedom\nMultiple R-squared:  0.849, Adjusted R-squared:  0.849 \nF-statistic: 3.04e+05 on 1 and 53938 DF,  p-value: <2e-16\n\n\nWie (bzw. wo) ist aus dieser Ausgabe die Korrelation herauszulesen?\n\nMacht es einen Unterschied, ob man Preis mit Karat bzw. Karat mit Preis korreliert?\nIn der klassischen Inferenzstatistik ist der \\(p\\)-Wert eine zentrale Größe; ist er klein (\\(p<.05\\)) so nennt man die zugehörige Statistik signifikant und verwirft die getestete Hypothese.\nIm Folgenden sehen Sie einen Korrelationstest auf statistische Signifikanz, mit R durchgeführt. Zeigt der Test ein (statistisch) signifikantes Ergebnis? Wie groß ist der “Unsicherheitskorridor”, um den Korrelationswert (zugleich Punktschätzer für den Populationswert)?\n\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.5.2\n✔ insight     0.18.2     ✔ datawizard  0.5.1   \n✔ bayestestR  0.12.1.1   ✔ performance 0.9.2   \n✔ parameters  0.18.2     ✔ effectsize  0.7.0.5 \n✔ modelbased  0.8.5      ✔ correlation 0.8.2   \n✔ see         0.7.2      ✔ report      0.5.5   \n\ndiamonds %>% \n  sample_n(30) %>% \n  select(price, carat) %>% \n  correlation()\n\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |    r |       95% CI | t(28) |         p\n-----------------------------------------------------------------\nprice      |      carat | 0.94 | [0.88, 0.97] | 14.87 | < .001***\n\np-value adjustment method: Holm (1979)\nObservations: 30\n\n\n         \n\n\nSolution\n\ncarat ist metrisch (verhältnisskaliert) und price ist metrisch (verhältnisskaliert)\n\\(R^2\\) kann bei einer einfachen (univariaten) Regression als das Quadrat von \\(r\\) berechnet werden. Daher \\(r = \\sqrt{R^2}\\).\n\n\nsqrt(0.8493)\n\n[1] 0.92\n\n\nZum Vergleich\n\ndiamonds %>% \n  summarise(r = cor(price, carat))\n\n# A tibble: 1 × 1\n      r\n  <dbl>\n1 0.922\n\n\nMan kann den Wert der Korrelation auch noch anderweitig berechnen (\\(\\beta\\) umrechnen in \\(\\rho\\)).\n\nNein. Die Korrelation ist eine symmetrische Relation.\nJa; die Zahl “3.81e-14” bezeichnet eine positive Zahl kleiner eins mit 13 Nullern vor der ersten Ziffer, die nicht Null ist (3.81 in diesem Fall). Der “Unsicherheitskorridor” reicht von etwa 0.87 bis 0.97.\n\n\nCategories:\n\ncorrelation\nlm"
  },
  {
    "objectID": "posts/Inferenz-fuer-alle/Inferenz-fuer-alle.html",
    "href": "posts/Inferenz-fuer-alle/Inferenz-fuer-alle.html",
    "title": "Inferenz-fuer-alle",
    "section": "",
    "text": "Solution\n\nFür (grundsätzlich) alle: Für jede Statistik kann man prinzipiell von der jeweiligen Stichprobe (auf Basis derer die Statistik berechnet wurde) auf eine zugehörige Grundgesamtheit schließen.\nFür (grundsätzlich) alle: Die Methoden der Inferenzstatistik sind prinzipiell unabhängig von den Spezifika bestimmter Forschungsfragen oder -bereiche. In den meisten Forschungsfragen ist man daran interessiert allgemeingültige Aussagen zu treffen. Da Statistiken sich nur auf eine Stichprobe - also einen zumeist nur kleinen Teil einer Grundgesamtheit beziehen - wird man sich kaum mit einer Statistik zufrieden geben, sondern nach Inferenzstatistik verlangen.\nIn einigen Ausnahmefällen wird man auf eine Inferenzstatistik verzichten. Etwa wenn man bereits eine Vollerhebung durchgeführt hat, z.B. alle Mitarbeitis eines Unternehmens befragt hat, dann kennt man ja bereits den wahren Populationswert. Ein anderer Fall ist, wenn man nicht an Verallgemeinerungen interessiert ist: Kennt man etwa die Überlebenschance \\(p\\) des Titanic-Unglücks, so ist es fraglich auf welche Grundgesamtheit man die Statistik \\(p\\) bzw. zu welchem Paramter \\(\\pi\\) (kleines Pi) man generalisieren möchte.\n\n\nCategories:\n\nqm2\ninference\nuncertainty"
  },
  {
    "objectID": "posts/iq03/iq03.html",
    "href": "posts/iq03/iq03.html",
    "title": "iq03",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd= 15))\n\nDa \\(\\sigma=15\\), filtern wir bis höchstens 100:\n\nsolution_d <- \n  d %>% \n  count(iq <= 100) %>% \n  mutate(prop = n / sum(n))\n\nsolution_d\n\n# A tibble: 2 × 3\n  `iq <= 100`     n  prop\n  <lgl>       <int> <dbl>\n1 FALSE         485 0.485\n2 TRUE          515 0.515\n\n\nDie Wahrscheinlichkeit für “nicht überdurchschnittlich intelligent” beträgt ca. 49%.\n\n\n\nDas Ereignis “nicht überdurchschnittlich intelligent” kann man vielleicht einfacher - und auf jeden Fall präziser benennen mit \\(iq \\le 100\\).\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/Warum-Bayes/Warum-Bayes.html",
    "href": "posts/Warum-Bayes/Warum-Bayes.html",
    "title": "Warum-Bayes",
    "section": "",
    "text": "Solution\nEs existieren mehrere Gründe, einige wichtige sind:\n\nBayes-Analysen erlauben es, Vorwissen in die Analyse einfließen zu lassen.\nBayes-Analysen geben die Wahrscheinlichkeit einer Hypothese bzw. eines Parameterwerts zurück.\nBayes-Analysen erlauben es, Modelle exakt und flexibel zu spezifizieren.\nBayes-Analysen sind bei kleineren Stichproben genauer.\n\n“Quantifizierung” ist keine ausreichende Begründung für die Verwendung der Bayes-Statistik, da auch z.B. eine Frequentistische Analyse Quantifizierung bietet. Hingegen ist “Quantifizierung der Wahrscheinlichkeit der Forschungshypothese” ein valider Grund, denn der Frequentismus erlaubt nicht die Wahrscheinlichkeit einer Hypothese zu quantifizieren.\n“Wahrscheinlichkeitsaussagen” ist ebenfalls keine ausreichende Begründung für Bayes, denn auch im Frequentismus gibt es Wahrscheinlichkeitsaussagen, auch wenn diese weniger stark in die Wahrscheinlichkeitstheorie geknüpft sind als die Bayes-Inferenz (vgl. Jaynes, 2003).\nEs ist als Begründung nicht ausreichend, z.B. von “Erwartungen ans die Auswertung” zu sprechen, wenn man auf die Priori-Verteilung als (valider) Vorteil der Bayes-Inferenz abzielen möchte.\nEbenso ist es nicht ausreichend, allgemein auf eine “höhere Zuverlässigkeit” o.Ä. der Bayes-Inferenz hinzuweisen.\nDas ROPE ist eine praktische, sinnvolle Methode, allerdings gibt es mittlerweile vergleichbare Verfahren im Frequentismus, sog. Äquivalenztests.\nDer Grund, warum Bayes-Analysen bei kleineren Stichproben zu genaueren Ergebnissen kommen, liegt im Priori-Wissen. Spezifiziert man z.B. eine Normalverteilung mit Sigma=1 und findet in den Daten einen Wert von zB. Sigma=6, also einen extremen Ausreißer, so wird die Priori-Verteilung dafür sorgen, den Extremwert “zurechtzustutzen” auf einen Wert näher der Mittelwert der Verteilung. Sofern dies sinnvoll/korrekt ist, wird man mit diesem Vorgehen zu genaueren Ergebnissen kommen. Die Hoffnung ist, dass einzelne Extremwerte eher Messfehler sind.\n\nCategories:\n\nqm2\nbayes\nprobability"
  },
  {
    "objectID": "posts/iq04/iq04.html",
    "href": "posts/iq04/iq04.html",
    "title": "iq04",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd= 15))\n\nWir filtern die schlauesten 2 Prozent:\n\nsolution_d <- \n  d %>% \n  arrange(iq) %>% \n  slice_tail(prop = 0.02) %>% \n  summarise(min(iq))\n\nsolution_d\n\n# A tibble: 1 × 1\n  `min(iq)`\n      <dbl>\n1      130.\n\n\nDie Syntax auf Deutsch übersetzt:\nDefiniere solution_d wie folgt:\nnimm die Tabelle d und dann ...\nsortiere (aufsteigend) die Spalte iq und dann ...\nschneide hinten (\"am Schwanz\") einen Anteil von 2% ab und dann ...\nfasse diese Liste an Werten zusammen zu ihrem Minimum (also dem kleinsten Wert).\nAlternativ könnte man schreiben:\n\nsolution <- \n  d %>% \n  summarise(iq_top_2komma3_prozent = quantile(iq, prob = .98))\n\nsolution\n\n# A tibble: 1 × 1\n  iq_top_2komma3_prozent\n                   <dbl>\n1                   130.\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/wuerfel01/wuerfel01.html",
    "href": "posts/wuerfel01/wuerfel01.html",
    "title": "wuerfel01",
    "section": "",
    "text": "Solution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden Würfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), …, (1,6), …, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd <- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\nd\n\n# A tibble: 36 × 2\n   wuerfel1 wuerfel2\n      <int>    <int>\n 1        1        1\n 2        1        2\n 3        1        3\n 4        1        4\n 5        1        5\n 6        1        6\n 7        2        1\n 8        2        2\n 9        2        3\n10        2        4\n# … with 26 more rows\n\n\nJetzt ergänzen wir eine Spalte für die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 <-\n  d %>% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n# A tibble: 6 × 3\n  wuerfel1 wuerfel2   prob\n     <int>    <int>  <dbl>\n1        1        1 0.0278\n2        1        2 0.0278\n3        1        3 0.0278\n4        1        4 0.0278\n5        1        5 0.0278\n6        1        6 0.0278\n\n\nAußerdem ergänzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 <-\n  d2 %>% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        1        1 0.0278          2\n2        1        2 0.0278          3\n3        1        3 0.0278          4\n4        1        4 0.0278          5\n5        1        5 0.0278          6\n6        1        6 0.0278          7\n\n\nFür manche Augensummen gibt es mehrere Möglichkeiten:\n\nd3 %>% \n  filter(augensumme == 7)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        1        6 0.0278          7\n2        2        5 0.0278          7\n3        3        4 0.0278          7\n4        4        3 0.0278          7\n5        5        2 0.0278          7\n6        6        1 0.0278          7\n\n\n… für andere weniger:\n\nd3 %>% \n  filter(augensumme == 12)\n\n# A tibble: 1 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        6        6 0.0278         12\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 <- \n  d3 %>% \n  group_by(augensumme) %>% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n# A tibble: 11 × 2\n   augensumme totale_w_pro_augenzahl\n        <int>                  <dbl>\n 1          2                 0.0278\n 2          3                 0.0556\n 3          4                 0.0833\n 4          5                 0.111 \n 5          6                 0.139 \n 6          7                 0.167 \n 7          8                 0.139 \n 8          9                 0.111 \n 9         10                 0.0833\n10         11                 0.0556\n11         12                 0.0278\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %>% \n  summarise(sum(totale_w_pro_augenzahl))\n\n# A tibble: 1 × 1\n  `sum(totale_w_pro_augenzahl)`\n                          <dbl>\n1                             1\n\n\nUnd:\n\nd2 %>% \n  summarise(sum(prob))\n\n# A tibble: 1 × 1\n  `sum(prob)`\n        <dbl>\n1           1\n\n\nPasst!\nDie Wahrscheinlichkeit für die Augensumme 10 beträgt also:\n\nloesung <-\n  d4 %>% \n  filter(augensumme == 10) %>% \n  pull(totale_w_pro_augenzahl)\n\nloesung\n\n[1] 0.08333333\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/iq05/iq05.html",
    "href": "posts/iq05/iq05.html",
    "title": "iq05",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd <- tibble(\n  id = 1:10^5,\n  iq = rnorm(n = 10^5, mean = 100, sd= 15))\n\nWir filtern die schlauesten 0,1 Prozent:\n\nd %>% \n  summarise(iq_top_0komma1_prozent = quantile(iq, prob = .999))\n\n# A tibble: 1 × 1\n  iq_top_0komma1_prozent\n                   <dbl>\n1                   146.\n\n\nMan muss mindestes über einen IQ von ca. 145 verfügen.\nAchtung: Das sind immer Zahlen als der “kleinen Welt” des Modells. Sollten unsere Annahmen nicht stimmen (normalverteilt mit MW 100 und SD 15), dann stimmt natürlich unser Ergebnis auch nicht.\nOb unsere Annahmen stimmen, kann der Computer nicht sagen. Das ist weiterhin Menschenjob.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/iq02/iq02.html",
    "href": "posts/iq02/iq02.html",
    "title": "iq02",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd= 15))\n\nDa \\(\\sigma=15\\), filtern wir ab 130:\n\nd %>% \n  count(iq >= 130)\n\n# A tibble: 2 × 2\n  `iq >= 130`     n\n  <lgl>       <int>\n1 FALSE         979\n2 TRUE           21\n\n\nDie Wahrscheinlichkeit beträgt ca. 2%.\n\n\n\nJa, diese Aufgaben ist faktisch identische zur Aufgabe iq01. Darum ging es: Sie sollen erkennen, dass ein IQ-Wert von 130 das gleiche ist wie MW+2sd.\nÜbrigens: “Wie viele SD-Einheiten liegt der Wert von Beobachtung \\(i\\) über dem Mittelwert, \\(\\bar{X}\\) ?” ist die Frage, die der z-Wert beantwortet:\n\\(z_i = \\frac{x_i - \\bar{X}}{sd(x)}\\)\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/Sim-Prior/Sim-Prior.html",
    "href": "posts/Sim-Prior/Sim-Prior.html",
    "title": "Sim-Prior",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nn <- 1e4\n\n\nsim <- tibble(\n  mu = rnorm(n = n),  # Default-Werte sind mean=0, sd = 1\n  sigma = runif(n = n, 0, 10)) %>%\n  mutate(\n    y = rnorm(n = n, mean = mu, sd = sigma))\n\nggplot(sim, aes(x = y)) +\n  geom_density() +\n  labs(x = \"y\", y = \"Dichte\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/Rethink_2m3/Rethink_2m3.html",
    "href": "posts/Rethink_2m3/Rethink_2m3.html",
    "title": "Rethink_2m3",
    "section": "",
    "text": "Solution\nZur Erinnerung:\n\\[\\begin{aligned}\nPr(A) &= Pr(A \\cap B) + Pr(A \\cap A^C)  \\qquad \\text{| totale Wskt, bei disjunkten Ereignissen}\\\\\nPr(A \\cap B) &= Pr(A|B) \\cdot Pr(B)\\\\\nPr(A \\cap B^C) &= Pr(A|B^C) \\cdot Pr(B^C)\n\\end{aligned}\\]\nWobei \\(A^C\\) das komlementäre Ereignis zu \\(A\\) meint.\nThe solution is taken from this source.\n\n# probability of land, given Earth:\np_le <- 0.3\n\n# probability of land, given Mars:\np_lm <- 1.0\n\n# probability of Earth:\np_e <- 0.5\n\n# prob. of Mars:\np_m <- 0.5\n\n# probability of land:\n# totale Wahrscheinlichkeit für Land\np_l <- (p_e * p_le) + (p_m * p_lm)\np_l\n\n[1] 0.65\n\n\nDann gilt also:\n\n# probability of Earth, given land (using Bayes' Theorem):\np_el <- (p_le * p_e) / p_l\np_el\n\n[1] 0.2307692\n\n\nEinfacher als die Rechnung ist vielleicht ein Baumdiagramm:\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/lm1/lm1.html#answerlist",
    "href": "posts/lm1/lm1.html#answerlist",
    "title": "lm1",
    "section": "Answerlist",
    "text": "Answerlist\n\nmpg und hp sind positiv korreliert laut dem Modell.\nDer Achsenabschnitt ist nahe Null.\nDie Analyse beinhaltet einen nominal skalierten Prädiktor.\nDas geschätzte Betagewicht für hp liegt bei 30.099.\nDas geschätzte Betagewicht für hp liegt bei -0.068."
  },
  {
    "objectID": "posts/lm1/lm1.html#answerlist-1",
    "href": "posts/lm1/lm1.html#answerlist-1",
    "title": "lm1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nRichtig\n\n\nCategories:\n\nregression\nlm\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/Rethink_2m4/Rethink_2m4.html",
    "href": "posts/Rethink_2m4/Rethink_2m4.html",
    "title": "Rethink_2m4",
    "section": "",
    "text": "Solution\nLet’s label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nWanted is the probability that both sides are black (bb), given one side is black (1b): \\(Pr(bb|1b)\\).\nLet’s count the ways how the data - one black side - can come up in each conjecture (hypothesis), bb, bw, ww. Let’s denote “first side white” as 1b” and “first side black” as 2b.\nbb: 2 valid paths\n\n\n\n\n\n\nbw: 1 valid path\n\n\n\n\n\n\nww: 0 valid path\n\n\n\n\n\n\n\nd <-\n  tibble::tribble(\n  ~Hyp, ~Prior,\n  \"bb\",     1, \n  \"bw\",     1,   \n  \"ww\",     1, \n  ) %>% \n  mutate(Likelihood = c(2,1,0),\n         unstand_post = Prior*Likelihood,\n         std_post = unstand_post / sum(unstand_post))\n\n\n\n\n\n\n\n  \n  \n    \n      Hyp\n      Prior\n      Likelihood\n      unstand_post\n      std_post\n    \n  \n  \n    bb\n1\n2\n2\n0.67\n    bw\n1\n1\n1\n0.33\n    ww\n1\n0\n0\n0.00\n  \n  \n  \n\n\n\n\nThe following solution is taken from this source.\n\ncard_bb_likelihood <- 2\ncard_bw_likelihood <- 1\ncard_ww_likelihood <- 0\n\nlikelihood <- c(card_bb_likelihood, card_bw_likelihood, card_ww_likelihood)\nprior <- c(1, 1, 1)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1]\n\n[1] 0.6666667\n\n\n\nCategories:\n\nprobability\n‘2022’"
  },
  {
    "objectID": "posts/ReThink3m1/ReThink3m1.html",
    "href": "posts/ReThink3m1/ReThink3m1.html",
    "title": "ReThink3m1",
    "section": "",
    "text": "Solution\n\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, 1000)\nlikelihood <- dbinom(8, size = 15, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\ntibble(p = p_grid, posterior = posterior) %>%\n  ggplot(aes(x = p, y = posterior)) +\n # geom_point() +\n  geom_line() +\n  labs(x = \"Anteil Wasser (p)\", y = \"Posterior Density\")\n\n\n\n\n\n\n\n\nQuelle\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html",
    "title": "ttest-skalenniveau",
    "section": "",
    "text": "Der t-Test ist ein inferenzstatistisches Verfahren des Frequentismus. Welches Skalenniveau passt zu diesem Verfahren?\nHinweisse:\n\nDie folgende Abbildung gibt Tipps.\nInformationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUV: nominal (mehrstufig), AV: metrisch\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (mehrstufig), AV: nominal (mehrstufig)\nUV: metrisch, AV: nominal (zweistufig)\nUV: nominal (zweistufig), AV: metrisch"
  },
  {
    "objectID": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist-1",
    "href": "posts/ttest-skalenniveau/ttest-skalenniveau.html#answerlist-1",
    "title": "ttest-skalenniveau",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr\n\n\nCategories:\n\nttest\nregr\nvariable-levels"
  },
  {
    "objectID": "posts/Bed-Wskt2/Bed-Wskt2.html",
    "href": "posts/Bed-Wskt2/Bed-Wskt2.html",
    "title": "Bed-Wskt2",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.58\n\nA_cond_B <- AandB / B_marg %>% round(2)\nAneg_cond_B <- AnegandB / B_marg %>% round(2)\nA_cond_Bneg <- AandBneg / Bneg_marg %>% round(2)\nAneg_cond_Bneg <- AnegandBneg / Bneg_marg %>% round(2)\n\n\\(Pr(A) = 0.62\\).\n\\(Pr(B) = 0.7154\\).\n\\(Pr(AB) = 0.4154\\).\n\\(Pr(A|B)= 0.5769444\\).\n\\(Pr(\\neg A|B) = 0.4222222\\).\n\\(Pr(A|\\neg B) = 0.7142857\\).\n\\(Pr(\\neg A|\\neg B) = 0.2857143\\).\n\nCategories:\n\nprobability\nconditional"
  },
  {
    "objectID": "posts/Rethink_2m5/Rethink_2m5.html",
    "href": "posts/Rethink_2m5/Rethink_2m5.html",
    "title": "Rethink_2m5",
    "section": "",
    "text": "Solution\nThe only difference to the question 2M4 is that we now have two bb cards, rendering the prior plausibility twice as high.\nLet’s label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nWanted is the probability that the second side of the card is black (2b), given one side is black (1b): \\(Pr(2b|1b)\\).\n\nd <-\n  tibble::tribble(\n  ~Hyp, ~Prior,\n  \"bb\",     2L, \n  \"bw\",     1L,   \n  \"ww\",     1L, \n  ) %>% \n  mutate(Likelihood = c(2,1,0),\n         unstand_post = Prior*Likelihood,\n         std_post = unstand_post / sum(unstand_post))\n\n\n\n\n\n\n\n  \n  \n    \n      Hyp\n      Prior\n      Likelihood\n      unstand_post\n      std_post\n    \n  \n  \n    bb\n2\n2\n4\n0.80\n    bw\n1\n1\n1\n0.20\n    ww\n1\n0\n0\n0.00\n  \n  \n  \n\n\n\n\nThe following solution is taken from this source.\n\ncard_bb_likelihood <- 2\ncard_bw_likelihood <- 1\ncard_ww_likelihood <- 0\n\nlikelihood <- c(card_bb_likelihood, card_bw_likelihood, card_ww_likelihood,\n                card_bb_likelihood)\nprior <- c(1, 1, 1, 1)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1] + posterior[4]\n\n[1] 0.8\n\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/Rethink_2m2/Rethink_2m2.html",
    "href": "posts/Rethink_2m2/Rethink_2m2.html",
    "title": "Rethink_2m2",
    "section": "",
    "text": "Solution\nThe solution is taken from this source.\n\nlibrary(tidyverse)\n\ndist <- \n  tibble(\n    # Gridwerte bestimmen:\n    p_grid = seq(from = 0, to = 1, length.out = 20),\n    # Priori-Wskt bestimmen:\n    prior  = case_when(\n      p_grid < 0.5 ~ 0,\n      p_grid >= 0.5 ~ 1)) %>%\n  mutate(\n    # Likelihood berechnen:\n    likelihood_1 = dbinom(3, size = 3, prob = p_grid),\n    likelihood_2 = dbinom(3, size = 4, prob = p_grid),\n    likelihood_3 = dbinom(5, size = 7, prob = p_grid),\n    # unstand. Posterior-Wskt:\n    unstand_post_1 = likelihood_1 * prior,\n    unstand_post_2 = likelihood_2 * prior,\n    unstand_post_3 = likelihood_3 * prior,\n    # stand. Post-Wskt:\n    std_post_1 = unstand_post_1 / sum(unstand_post_1),\n    std_post_2 = unstand_post_2 / sum(unstand_post_1),\n    std_post_3 = unstand_post_3 / sum(unstand_post_1)\n    ) \n\nJetzt können wir das Diagramm zeichnen:\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_1) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWW\")\n\n\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_2) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWWL\")\n\n\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_3) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: LWWLWWW\")\n\n\n\n\n\n\n\n\nEtwas eleganter (und deutlich komplizierter) kann man es auch so in R schreiben (Quelle):\n\ndist <- tibble(p_grid = seq(from = 0, to = 1, length.out = 20)) %>%\n  mutate(prior = case_when(\n    p_grid < 0.5 ~ 0L,\n    TRUE ~ 1L),\n    likelihood_1 = dbinom(3, size = 3, prob = p_grid),\n    likelihood_2 = dbinom(3, size = 4, prob = p_grid),\n    likelihood_3 = dbinom(5, size = 7, prob = p_grid),\n    across(starts_with(\"likelihood\"), ~ .x * prior),\n    across(starts_with(\"likelihood\"), ~ .x / sum(.x))) %>%\n  pivot_longer(cols = starts_with(\"likelihood\"), names_to = \"pattern\",\n               values_to = \"posterior\") %>%\n  separate(pattern, c(NA, \"pattern\"), sep = \"_\", convert = TRUE) %>%\n  mutate(obs = case_when(pattern == 1L ~ \"W, W, W\",\n                         pattern == 2L ~ \"W, W, W, L\",\n                         pattern == 3L ~ \"L, W, W, L, W, W, W\"))\n\nggplot(dist, aes(x = p_grid, y = posterior)) +\n  facet_wrap(vars(fct_inorder(obs)), nrow = 1) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes-grid"
  },
  {
    "objectID": "posts/iq10/iq10.html",
    "href": "posts/iq10/iq10.html",
    "title": "iq10",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nSimulieren wir uns die Stichprobe:\n\nset.seed(42)\nstipro <-\n  tibble(iq = rnorm(n = 541, mean = 92.5, sd = 7.5))\n\nJetzt basteln wir die Bayes-Box:\n\nn <- 100\n\nset.seed(42)\npostvert <-\n  tibble(p_grid = seq(from = 75, to = 130, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dnorm(x = p_grid, mean = 92.5, sd = 7.5)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nDaraus ziehen wir Stichproben:\n\nset.seed(42)\npostvert_stipros <-\n  postvert %>% \n  slice_sample(\n    n = 1e4,\n    weight_by = post,\n    replace = T) %>% \n  select(p_grid)\n\nDa slice_sample auch zufällig Stichproben zieht, müssen wir auch hier die Zufallszahlen fixieren, wenn wir die exakt gleichen Ergebnisse reproduzieren wollen.\nJetzt schauen wir (mit Spannung), wie hoch die Wahrscheinlichkeit ist für Parameterwete (p_grid) innerhalb des Intervalls wie von der Forscherin vorgegeben.\n\npostvert_stipros %>% \n  count(between(p_grid, left = 85, right = 95))\n\n# A tibble: 2 × 2\n  `between(p_grid, left = 85, right = 95)`     n\n  <lgl>                                    <int>\n1 FALSE                                     5002\n2 TRUE                                      4998\n\n\nbetween ist eine Komfortfuntion; ins Deutsche übersetzt sagt die Syntax:\nNimm die Tabelle postvert_stipros und dann ...\n  zähle den Anteil der Werte von p_grid zwischen 85 und 95.\nDie Wahrscheinlichkeit der Hypothese der Forscherin beträgt ca. 50%.\nOb das viel oder weniger ist, ist eine subjektive Frage. Das beste Vorgehen wäre jetzt, die Hypothesen anderer Forschis dagegen zu legen. Dann würde man sehen, welche Hypothese am besten zu den Daten passt.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution\nbayes\nbayes-box"
  },
  {
    "objectID": "posts/nasa01/nasa01.html",
    "href": "posts/nasa01/nasa01.html",
    "title": "nasa01",
    "section": "",
    "text": "Solution\nDekade berechnen:\n\nd <-\n  d %>% \n  mutate(decade = round(Year/10))\n\nStatistiken pro Dekade:\n\nd_summarized <- \n  d %>% \n  group_by(decade) %>% \n  summarise(temp_mean = mean(Jan),\n            temp_sd = sd(Jan))\n\nd_summarized\n\n\n\n\n\n\n\n  \n  \n    \n      decade\n      temp_mean\n      temp_sd\n    \n  \n  \n    188\n−0.20\n0.24\n    189\n−0.43\n0.22\n    190\n−0.26\n0.16\n    191\n−0.38\n0.22\n    192\n−0.28\n0.15\n    193\n−0.13\n0.22\n    194\n0.03\n0.21\n    195\n−0.05\n0.18\n    196\n0.03\n0.15\n    197\n−0.07\n0.17\n    198\n0.21\n0.19\n    199\n0.36\n0.13\n    200\n0.51\n0.20\n    201\n0.64\n0.20\n    202\n0.96\n0.15\n  \n  \n  \n\n\n\n\nZur Veranschaulichung visualisieren wir die Ergebnisse:\n\n\n\n\n\n\n\n\n\n\nCategories:\n\ndata\neda"
  },
  {
    "objectID": "posts/Weinhaendler/Weinhaendler.html",
    "href": "posts/Weinhaendler/Weinhaendler.html",
    "title": "Weinhaendler",
    "section": "",
    "text": "Solution\n\nWie groß ist die Wahrscheinlichkeit (laut Modell), dass die KI-freundlichen Kundis bei Ihnen überwiegen?\n\nDas ist eine Frage nach der kumulative Verteilungsfuntion (cumulative distribution function, cdf).\n\np_grid <- seq(from=0, \n              to=1, \n              length.out=1000)  # Gitterwerte\n\nprior <- rep(1, 1000)  # Priori-Gewichte\n\nset.seed(42)  # Zufallszahlen festlegen\nlikelihood <- dbinom(23, size = 42, prob=p_grid ) \n\nunstandardisierte_posterior <- likelihood * prior \n\nposterior <- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nZiehen wir daraus Stichproben:\n\nset.seed(42)  # Zufallszahlen festlegen\nsamples <- \n  tibble(\n    p = sample(p_grid , \n               prob = posterior, \n               size=1e4, \n               replace=TRUE))  \nsamples <-\n  samples %>% \n  mutate(id = 1:nrow(samples))\n\n\nsamples %>% \n  filter(p > 0.5) %>% \n  summarise(wskt_mehrheit_will_ki = n()/nrow(samples))\n\n# A tibble: 1 × 1\n  wskt_mehrheit_will_ki\n                  <dbl>\n1                 0.731\n\n\n\nsamples %>% \n  ggplot() +\n  aes(x = p) +\n  geom_histogram() +\n  geom_vline(xintercept = 0.5) +\n  labs(title = \"Post-Verteilung\")\n\n\n\n\n\n\n\n\n\nWie groß ist die Wahrscheinlichkeit (laut Modell), dass künftig eine Mehrheit an KI-freundlichen Kunfis zu beobachten sein wird?\n\n\nPPV <-\n  samples %>% \n  mutate(Anzahl_will_KI = rbinom(n = 1e4, size = 42, prob = p))\n\n\nPPV %>% \n  ggplot() +\n  aes(x = Anzahl_will_KI) +\n  geom_histogram() +\n  labs(title = \"PPV\")\n\n\n\n\n\n\n\n\nEine Mehrheit entspricht mind. 22 von 42 Personen.\n\nPPV %>% \n  filter(Anzahl_will_KI >= 22) %>% \n  summarise(prob_mehrheit_will_ki = n()/nrow(PPV))\n\n# A tibble: 1 × 1\n  prob_mehrheit_will_ki\n                  <dbl>\n1                 0.623\n\n\n\nWenn Sie nur eine Zahl angeben dürften: Was ist Ihr Schätzwert zum Anteil der KI-Freunde (in dieser Studie)?\n\nMan könnte den Mittelwert oder den Median angeben:\n\nlibrary(rstatix)\nget_summary_stats(samples)\n\n# A tibble: 2 × 13\n  variable     n   min       max   median      q1      q3    iqr     mad    mean\n  <chr>    <dbl> <dbl>     <dbl>    <dbl>   <dbl>   <dbl>  <dbl>   <dbl>   <dbl>\n1 id       10000 1     10000     5000.    2.50e+3 7.50e+3 5000.  3.71e+3 5.00e+3\n2 p        10000 0.274     0.789    0.546 4.95e-1 5.96e-1    0.1 7.4 e-2 5.45e-1\n# … with 3 more variables: sd <dbl>, se <dbl>, ci <dbl>\n\n\n\nCategories:\n\nprobability\nbayes-grid"
  },
  {
    "objectID": "posts/purrr-map01/purrr-map01.html",
    "href": "posts/purrr-map01/purrr-map01.html",
    "title": "purrr-map01",
    "section": "",
    "text": "Exercise\nErstellen Sie einen Tibble mit folgenden Spalten:\n\nBuchstaben A-Z, so dass in der 1. Zeile “A” steht, in der 2. Zeile “B” etc.\nBuchstaben a-z, so dass in der 1. Zeile “a” steht, in der 2. Zeile “b” etc.\nBuchstabenkombination der ersten beiden Spalten, so dass in der 1. Zeile “A-a” steht, in der 2. Zeile “B-b” etc.\n\n         \n\n\nSolution\nGeht es vielleicht so?\n\nd <-\n  tibble(\n    letter1 = LETTERS,\n    letter2 = letters,\n    letters = paste(letter1, letter2, collapse = \"-\")\n  )\n\nhead(d)\n\n# A tibble: 6 × 3\n  letter1 letter2 letters                                                       \n  <chr>   <chr>   <chr>                                                         \n1 A       a       A a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P…\n2 B       b       A a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P…\n3 C       c       A a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P…\n4 D       d       A a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P…\n5 E       e       A a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P…\n6 F       f       A a-B b-C c-D d-E e-F f-G g-H h-I i-J j-K k-L l-M m-N n-O o-P…\n\n\nNein, leider nicht.\nOK, neuer Versuch:\n\nd <-\n  tibble(\n    letter1 = LETTERS,\n    letter2 = letters) %>% \n  unite(\"letters\", c(letter1, letter2), remove = FALSE)\n\n\nhead(d)\n\n# A tibble: 6 × 3\n  letters letter1 letter2\n  <chr>   <chr>   <chr>  \n1 A_a     A       a      \n2 B_b     B       b      \n3 C_c     C       c      \n4 D_d     D       d      \n5 E_e     E       e      \n6 F_f     F       f      \n\n\nProbieren wir es mit purrr::map():\n\nd <-\n  tibble(\n    letter1 = LETTERS,\n    letter2 = letters,\n    letters = map2_chr(letter1, letter2, ~ paste(c(.x, .y), collapse =\"-\"))\n  )\n\nhead(d)\n\n# A tibble: 6 × 3\n  letter1 letter2 letters\n  <chr>   <chr>   <chr>  \n1 A       a       A-a    \n2 B       b       B-b    \n3 C       c       C-c    \n4 D       d       D-d    \n5 E       e       E-e    \n6 F       f       F-f    \n\n\nInfos zur Funktion paste() findet sich z.B. hier.\n\nCategories:\n\nr\nmap\ntidyverse"
  },
  {
    "objectID": "posts/purrr-map06/purrr-map06.html",
    "href": "posts/purrr-map06/purrr-map06.html",
    "title": "purrr-map06",
    "section": "",
    "text": "Exercise\nErstellen Sie eine Tabelle mit mit folgenden Spalten:\n\nID-Spalte: \\(1,2,..., 10\\)\nEine Spalte mit Namem ds (ds wie Plural von Datensatz), die als geschachtelt (nested) pro Element jeweils einen der folgenden Datensätze enthält: mtcars, iris, chickweight, ToothGrowth (alle in R enthalten)\n\nBerechnen Sie eine Spalte, die die Anzahl der Spalten von ds zählt!\n         \n\n\nSolution\nHier sind einige Datensätze, in einer Liste zusammengefasst:\n\nds <- list(mtcars = mtcars, iris = iris, chickweight =  ChickWeight, toothgrowth = ToothGrowth)\n\nDaraus erstellen wir eine Tabelle mit Listenspalte für die Daten:\n\nd <- \n  tibble(id = 1:length(ds),\n         ds = ds)\n\nJetzt führen wir die Funktion ncol aus, und zwar für jedes Element von ds. Wir brauchen also eine Art Schleife, das besorgt map für uns. Viele Funktionen in R sind “auomatisch verschleift” - das nennt man vektorisiert. Vektorisierte Funktionen werden für jedes Element eines Vektors ausgeführt.\nEin Beispiel für eine vektorisierte Funktion ist die Funktion +:\n\nx <- c(1,2,3)\ny <- c(10, 20, 30)\nx + y\n\n[1] 11 22 33\n\n\nMan könnte übrigens auch schreiben:\n\n`+`(x, y)\n\n[1] 11 22 33\n\n\nWas zeigt, dass + eine normale Funktion ist.\nZurück zur eigentlichen Aufgabe. Aber ncol ist eben nicht vektorisiert, darum müssen wir da noch eine Schleife dazu bauen, das macht map.\n\nd2 <- \n  d %>% \n  mutate(n_col = map(ds, ncol)) \n\nhead(d2)\n\n# A tibble: 4 × 3\n     id ds                   n_col       \n  <int> <named list>         <named list>\n1     1 <df [32 × 11]>       <int [1]>   \n2     2 <df [150 × 5]>       <int [1]>   \n3     3 <nfnGrpdD [578 × 4]> <int [1]>   \n4     4 <df [60 × 3]>        <int [1]>   \n\n\nEntnesten wir noch n_col:\n\nd2 %>% \n  unnest(n_col)\n\n# A tibble: 4 × 3\n     id ds                   n_col\n  <int> <named list>         <int>\n1     1 <df [32 × 11]>          11\n2     2 <df [150 × 5]>           5\n3     3 <nfnGrpdD [578 × 4]>     4\n4     4 <df [60 × 3]>            3\n\n\nWir können auch gleich map anweisen, keine Liste, sondern eine Zahl (double, reelle ) Zahl zurückzuliefern, dann sparen wir uns das entschachteln:\n\nd %>% \n  mutate(n_col = map_dbl(ds, ncol)) \n\n# A tibble: 4 × 3\n     id ds                   n_col\n  <int> <named list>         <dbl>\n1     1 <df [32 × 11]>          11\n2     2 <df [150 × 5]>           5\n3     3 <nfnGrpdD [578 × 4]>     4\n4     4 <df [60 × 3]>            3\n\n\n\nCategories:\n\nprogramming\nloop"
  },
  {
    "objectID": "posts/Priori-Streuung/Priori-Streuung.html",
    "href": "posts/Priori-Streuung/Priori-Streuung.html",
    "title": "Priori-Streuung",
    "section": "",
    "text": "Welche Verteilung ist (am besten) geeignet, um Streuung (\\(\\sigma\\)) zu modellieren?\n\n\n\nN(0,1)\nN(1,1)\nExp(1)\nExp(0)\nExp(-1)"
  },
  {
    "objectID": "posts/Priori-Streuung/Priori-Streuung.html#answerlist-1",
    "href": "posts/Priori-Streuung/Priori-Streuung.html#answerlist-1",
    "title": "Priori-Streuung",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\nDa Streuung \\(\\sigma\\) per Definition positiv ist, kommt eine Verteilung, die negative Werte erlaubt, nicht in Frage. Die Normalverteilung scheidet also aus.\nDie Rate der Exponentialverteilung regelt gleichzeitig Streuung und Mittelwert. Allerdings hat \\(Exp(0)\\) eine unendliche Streuung, was nicht wünschenswert ist. Eine negative Rate ist für die Exponentialverteilung nicht definiert.\nNormalverteilungen:\n\n\n\n\n\\(N(0,1)\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(N(1,1)\\):\n\n\n\n\n\n\n\n\n\nExponentialverteilungen:\n\n\n\n\\(Exp(1)\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Exp(0)\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Exp(-1)\\):\n\n\nWarning in (function (x, rate = 1, log = FALSE) : NaNs produced\n\n\nWarning: Removed 101 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nsimulation\ndistribution\nbayes"
  },
  {
    "objectID": "posts/ReThink4e3/ReThink4e3.html",
    "href": "posts/ReThink4e3/ReThink4e3.html",
    "title": "ReThink4e3",
    "section": "",
    "text": "Solution\nDie allgemeine Form des Bayes-Theorem hatten wir so kennen gelernt:\n\\[Pr(H|D) = \\frac{Pr(D|H)\\cdot Pr(H)}{Pr(D)}\\]\n\\(Pr(\\mu, \\sigma|h)\\) gibt die Posteriori-Wahrscheinlichkeit für ein bestimmte Hypothese \\(H\\) an, z.B. für die Hypothese \\(\\mu=0\\).\n\\(Pr(D|H)\\) ist der Likelihood unserer Daten \\(D\\) gegeben der gerade untersuchten Hypothese \\(H\\).\n\\(Pr(H)\\) ist die Apriori-Wahrscheinlichkeit (das “Apriori-Gewicht”) der gerade untersuchten Hypothese.\nDer Zähler gibt die unstandardisierte Posteriori-Wahrscheinlichkeit der gerade untersuchten Hypothese an.\nDer Nenner ist nur ein Normalisierungsfaktor, der dafür sorgt, dass der ganze Bruch die standardisierte Posteriori-Wahrscheinlichkeit angibt.\nIn diesem konkreten Fall untersuchen wir Hypothesen zu einem “Parameter-Pärchen”, \\(\\mu\\sigma\\). Wir fragen also, wie wahrscheinlich es ist, einen gewissen Mittelwert \\(\\mu\\) und (gleichzeitig) eine gewisse Streuung \\(\\sigma\\) aufzufinden.\nZum Beispiel könnten wir fragen: “Wie wahrscheinlich ist es, dass \\(\\mu=194\\) und \\(\\sigma=12\\)?”. Bayes’ Theorem gibt uns die Wahrscheinlichkeit für diese Hypothese.\nZur Erinnerung, Bayes’ Theorem:\n\\[Pr(\\mu \\cap \\sigma|D) = \\frac{Pr(D|\\mu \\cap \\sigma)\\cdot Pr(\\mu) \\cdot Pr(\\sigma)}{Pr(H)}\\]\nHier ist zu beachten, dass die Apriori-Wahrscheinlichkeit auf zwei Termen besteht, \\(Pr(\\mu)\\) und \\(Pr(\\sigma)\\). Sind diese unabhängig, so kann man ihre Wahrscheinlichkeiten multiplizieren, um die gemeinsame Wahrscheinlichkeit zu erhalten, also die Wahrscheinlichkeit für ein bestimmten “Mu-Sigma-Pärchen”, etwa \\(\\mu=194,\\sigma=12\\).\n\nCategories:\n\nbayes\nprobability"
  },
  {
    "objectID": "posts/corona-blutgruppe/corona-blutgruppe.html",
    "href": "posts/corona-blutgruppe/corona-blutgruppe.html",
    "title": "corona-blutgruppe",
    "section": "",
    "text": "Solution\n\n\n\nDie Lösung lautet: unabhängig.\n\\(S\\) und \\(A\\) sind unabhängig: Offenbar ist die Wahrscheinlichkeit eines schweren Verlaufs gleich groß unabhängig davon, ob die Blutgruppe A ist oder nicht. In diesem Fall spricht man von stochastischer Unabhängigkeit.\n\\(Pr(S|A) = Pr(S|A^C) = Pr(S)\\)\n\nCategories:\n\nprobabillity\ndependent"
  },
  {
    "objectID": "posts/Priorwahl1/Priorwahl1.html",
    "href": "posts/Priorwahl1/Priorwahl1.html",
    "title": "Priorwahl1",
    "section": "",
    "text": "Solution\nDie Priori-Verteilung ist nicht sinnvoll spezifiziert. Die Streuung der Normalverteilung ist so groß, dass sie fast schon uniform verteilt ist. Dieser Priori-Verteilung nimmt z.B. an, \\(Pr(|\\beta| < 250) < Pr(|\\beta| > 250)\\), was eine sehr wilde Vorstellung ist. Man könnte sagen: Die Verteilung nimmt an, dass es wahrscheinlicher ist, dass ihr bester Freund 100 Millionen Lichtjahre entfernt lebt, als dass er näher als diese Distanz bei Ihnen lebt.\nWeitere Hinweise hier\nZur Verdeutlichung: Wie wahrscheinlich ist \\(q=1,2,...,10\\) bei einer Normalverteilung zu betrachten?\nFür \\(q=1\\) beträgt die Wahrscheinlichkeit für einen Wert nicht höher als \\(q=1\\) etwa 84%:\n\npnorm(q = 1)\n\n[1] 0.8413447\n\n\nAllgemeiner:\n\noptions(digits = 20)  # Mehr Nachkommastellen\npnorm(q = 1:10)\n\n [1] 0.84134474606854292578 0.97724986805182079141 0.99865010196836989653\n [4] 0.99996832875816688002 0.99999971334842807646 0.99999999901341229958\n [7] 0.99999999999872013490 0.99999999999999933387 1.00000000000000000000\n[10] 1.00000000000000000000\n\n\nDie Wahrscheinlichkeiten für Sigma-Ereignisse bis zu ±7 finden sich z.B. hier.\n\noptions(digits = 2)\n\nVertiefung:\nNassim Taleb hat dieses Argument in seinem Buch “Statistical Consequences of Fat Tails” aufgegriffen (ein anspruchsvolles Buch). Hier finden Sie eine interessante Darstellung eines Arguments daraus.\n\nCategories:\n\nfat-tails\ndistributions"
  },
  {
    "objectID": "posts/mtcars-abhaengig/mtcars-abhaengig.html",
    "href": "posts/mtcars-abhaengig/mtcars-abhaengig.html",
    "title": "mtcars-abhaengig",
    "section": "",
    "text": "Solution\n\nSchauen wir mal in den Datensatz:\n\n\nmtcars %>% \n  select(hp, hp_high, mpg, mpg_high) %>% \n  slice_head(n = 5)\n\n                   hp hp_high  mpg mpg_high\nMazda RX4         110   FALSE 21.0     TRUE\nMazda RX4 Wag     110   FALSE 21.0     TRUE\nDatsun 710         93   FALSE 22.8     TRUE\nHornet 4 Drive    110   FALSE 21.4     TRUE\nHornet Sportabout 175    TRUE 18.7    FALSE\n\n\n\n\n\n\nmtcars %>% \n  #select(hp_high, mpg_high) %>% \n  ggplot() +\n  aes(x = hp_high, fill = mpg_high) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nHey, sowas von abhängig voneinander, die zwei Variablen, mpg_high und hp_high!\nDer rechte Balken zeigt \\(Pr(\\text{mpg_high}|\\text{ hp_high})\\) und \\(Pr(\\neg \\text{mpg_high}|\\text{hp_high})\\).Der linke Balken zeigt \\(Pr(\\text{mpg_high}|\\neg \\text{hp_high})\\) und \\(Pr(\\neg \\text{mpg_high}|\\neg \\text{hp_high})\\).\n\nBerechnen wir die relevanten Anteile:\n\n\nmtcars %>% \n  #select(hp_high, mpg_high) %>% \n  count(hp_high, mpg_high) %>%  # Anzahl pro Zelle der Kontingenztabelle\n  group_by(hp_high) %>%  # die Anteile pro \"Balken\" s. Diagramm\n  mutate(prop = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   hp_high [2]\n  hp_high mpg_high     n   prop\n  <lgl>   <lgl>    <int>  <dbl>\n1 FALSE   FALSE        3 0.176 \n2 FALSE   TRUE        14 0.824 \n3 TRUE    FALSE       14 0.933 \n4 TRUE    TRUE         1 0.0667\n\n\nAm besten, Sie führen den letzten Code Schritt für Schritt aus und schauen sich jeweils das Ergebnis an, das hilft beim Verstehen.\nAlternativ kann man sich die Häufigkeiten auch schön bequem ausgeben lassen:\n\nlibrary(mosaic)\ntally(mpg_high ~ hp_high, \n      data = mtcars, \n      format = \"proportion\")\n\n        hp_high\nmpg_high       TRUE      FALSE\n   TRUE  0.06666667 0.82352941\n   FALSE 0.93333333 0.17647059\n\n\n\nCategories:\n\nprobability\ndependent"
  },
  {
    "objectID": "posts/mtcars-simple1/mtcars-simple1.html",
    "href": "posts/mtcars-simple1/mtcars-simple1.html",
    "title": "mtcars-simple1",
    "section": "",
    "text": "Solution\nCompute Model:\n\nlm1_freq <- lm(mpg ~ hp + cyl + disp, data = mtcars)\n\nlibrary(rstanarm)\nlm1_bayes <- stan_glm(mpg ~ hp + cyl + disp, data = mtcars, refresh = 0)\n\nGet parameters:\n\nlibrary(easystats)\n\n\nparameters(lm1_freq)\n\nParameter   | Coefficient |   SE |         95% CI | t(28) |      p\n------------------------------------------------------------------\n(Intercept) |       34.18 | 2.59 | [28.88, 39.49] | 13.19 | < .001\nhp          |       -0.01 | 0.01 | [-0.04,  0.02] | -1.00 | 0.325 \ncyl         |       -1.23 | 0.80 | [-2.86,  0.41] | -1.54 | 0.135 \ndisp        |       -0.02 | 0.01 | [-0.04,  0.00] | -1.81 | 0.081 \n\n\n\nparameters(lm1_bayes)\n\nParameter   | Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS |                   Prior\n------------------------------------------------------------------------------------------------------\n(Intercept) |  34.28 | [28.87, 39.60] |   100% |        0% | 1.000 | 2600.00 | Normal (20.09 +- 15.07)\nhp          |  -0.01 | [-0.05,  0.02] | 82.93% |      100% | 1.000 | 2448.00 |   Normal (0.00 +- 0.22)\ncyl         |  -1.25 | [-2.84,  0.34] | 93.75% |     2.55% | 1.000 | 2108.00 |   Normal (0.00 +- 8.44)\ndisp        |  -0.02 | [-0.04,  0.00] | 96.05% |      100% | 1.001 | 2405.00 |   Normal (0.00 +- 0.12)\n\n\nThe coefficient is estimated as about -0.01\n\nCategories:\n\nregresssion\nen\nbayes\nfrequentist\nqm1\nstats-nutshell"
  },
  {
    "objectID": "posts/log-y-regr3/log-y-regr3.html",
    "href": "posts/log-y-regr3/log-y-regr3.html",
    "title": "log-y-regr3",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)\n\nIn dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\n\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\"\n\nd <- data_read(d_path)\n\nDokumentation und Quellenangaben zum Datensatz finden sich hier.\n\nglimpse(d)\n\nRows: 2,675\nColumns: 11\n$ V1      <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ treat   <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n$ age     <int> 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23…\n$ educ    <int> 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,…\n$ ethn    <chr> \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\",…\n$ married <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ re74    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ re75    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ re78    <dbl> 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 21…\n$ u74     <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n$ u75     <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n\n\nWelcher der Prädiktoren hat den stärkesten Einfluss auf das Einkommen?\nHinweise:\n\nVerwenden Sie lm zur Modellierung.\nOperationalisieren Sie das Einkommen mit der Variable re74.\nGehen Sie von einem kausalen Effekt der Prädiktoren aus.\nGehen Sie von einem multiplikativen Modell aus (log-y).\nLassen Sie die Variablen zur Arbeitslosigkeit außen vor.\n\n\n\n\ntreat\nage\neduc\nethn\nmarried"
  },
  {
    "objectID": "posts/log-y-regr3/log-y-regr3.html#answerlist-1",
    "href": "posts/log-y-regr3/log-y-regr3.html#answerlist-1",
    "title": "log-y-regr3",
    "section": "Answerlist",
    "text": "Answerlist\n\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nCategories:\n\nstats-nutshell\nqm2\nregression\nlog"
  },
  {
    "objectID": "posts/twitter01/twitter01.html",
    "href": "posts/twitter01/twitter01.html",
    "title": "twitter01",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rtweet)\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nDann anmelden, z.B. als Bot:\n\nauth <- rtweet_bot(api_key = API_Key,\n                   api_secret = API_Key_Secret,\n                   access_token = Access_Token,\n                   access_secret = Access_Token_Secret)\n\n… Oder als App, das bringt bessere Raten mit sich:\n\nauth <- rtweet_app(bearer_token = Bearer_Token)\n\nTest:\n\nsesa_test <- get_timeline(user = \"sauer_sebastian\", n = 3) %>% \n  select(full_text)\n\nsesa_test\n\n1 RT @fuecks: By the way: Systematic destruction of life-sustaining infrastructures …\n2 RT @NoContextBrits: No shortbread for little Nazis. https://t.co/F6FUPvRz94        \n3 RT @ernst_gennat: 2 oder 3 Jahre #Tempolimit von 120 km/h. Abschließend Evaluation…\nTweets an Karl Lauterbach suchen:\n\nkarl1 <- search_tweets(\"@karl_lauterbach\")\n\nIn Auszügen:\n\"@Karl_Lauterbach Ein Minister der alle paar Stunden Zeit hat einen Mist zu verbreiten....\"   \n\"@Karl_Lauterbach @focusonline Long Covid ist nichts anderes als schwere Nebenwirkungen der Gentherapie!\"  \"@Karl_Lauterbach @focusonline Wer schützt uns vor Long Lauterbach?\"\n\"@Karl_Lauterbach Also Karl, primär fordere ich und viele andere eher erstmal dein sofortigen Rücktritt.\"  \"@Karl_Lauterbach Behalt deinen Senf für dich!\"                                                            \"@Karl_Lauterbach Oh Gott 😱\"     \n\"@Karl_Lauterbach Ach nein, der Clown mit Lebensangst ….\\n\\nhttps://t.co/8cQZeHh6Ew\"                       \"@Karl_Lauterbach Ich kenne nur Leute mit Long Covid, die mehrfach geimpft sind! Das ist kein Witz! Scheinbar liegt’s wohl doch an den Spritzen???\"                                                            \"@Karl_Lauterbach @focusonline Interessiert keine Sau 😉\"                      \n\"RT @Karl_Lauterbach @focusonline „Lauterbachs Aussagen können fundamental nicht stimmen“\\nhttps://t.co/rfxnWAWiZX\"                                                                          \"@Karl_Lauterbach @focusonline 🤡😂😂😂😂😂😂\"                                         \n\"@Karl_Lauterbach Jau und sie sind kein fähiger Gesundheitsminister, sondern lediglich ein gekaufter Coronaminister\"        \nPuh, viele toxische Tweets, wie es scheint.\nUnd ohne Retweets (RT) und ohne Replies:\n\nkarl2 <- search_tweets(\"@karl_lauterbach\", \n  include_rts = FALSE, `-filter` = \"replies\")\n\nTweets, die an Karl Lauterbach gerichtet sind, per API-Anweisung:\n\nkarl3 <- search_tweets(\"to:karl_lauterbach\", n = 100)\n\n\"@Karl_Lauterbach Vielen Dank, dass LongCovid ein gefundenes fressen für die jenigen ist, die nicht mehr Arbeiten wollen.\"       \n \"@Karl_Lauterbach verpiss dich einfach! Immer dieser Schwachsinn\"    \n\"@Karl_Lauterbach @focusonline Das sind genau die Impfnebenwirkungen! Will man nun das wenden um die Impfnebenwirkungen zu vertuschen? \\nWofür ist die Impfung gut wenn nicht mal Long-Covid verhindert wird, die Ansteckung konnte sie noch nie verhindern!\\nWarum sind 89% Covid Patienten geimpfte in den Spitäler?\"\n\"@Karl_Lauterbach Was spielen Sie eigentlich für ein schmutziges Spiel?\\n\\nhttps://t.co/8LJIzxyF7G\"   \n \"@Karl_Lauterbach @focusonline Bessen von Covid! Ständig wird das Netz durchsucht, nach Artikeln,die instrumentalisiert werden, um für Impfung zu werben. Was hätte nur ein vernünftiger Gesundheitsminister mit so viel Zeit Vernünftiges im Gesundheitswesen auf die Beine stellen können...\"    \n\"@Karl_Lauterbach Mit Dauerschaden wegen der Impfung 💉 bin ich Arbeitslos geworden in der Pflege 🤷‍♂️ Ist das normal Herr @Karl_Lauterbach ?\"          \nOb man mit @karl_lauterbach sucht oder `to:karl_lauterbach”, scheint keinen großen Unterschied zu machen (?).\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/ReThink4e2/ReThink4e2.html",
    "href": "posts/ReThink4e2/ReThink4e2.html",
    "title": "ReThink4e2",
    "section": "",
    "text": "Wie viele Parameter sind im folgenden Modell zu schätzen?\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior für \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior für \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{U}(0, 50)\\)\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\n\n0\n1\n2\n3\nmehr"
  },
  {
    "objectID": "posts/ReThink4e2/ReThink4e2.html#answerlist-1",
    "href": "posts/ReThink4e2/ReThink4e2.html#answerlist-1",
    "title": "ReThink4e2",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/twitter06/twitter06.html",
    "href": "posts/twitter06/twitter06.html",
    "title": "twitter06",
    "section": "",
    "text": "Solution\n\nlibrary(rtweet)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\n\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n\nLoading required package: SnowballC\n\nlibrary(SnowballC)  # Stemming\n\n\ndata(sentiws, package = \"pradadata\")\n\nZuerst muss man sich anmelden und die Tweets herunterladen:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nauth <- rtweet_app(bearer_token = Bearer_Token)\n\n\ntweets_to_kl <- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(tweets_to_kl, file = \"tweets_to_kl.rds\", compress = \"gz\")\ntweets_to_ms <- search_tweets(\"@Markus_Soeder\", n = 1e4, include_rts = FALSE)\n#write_rds(tweets_to_ms, file = \"tweets_to_ms.rds\", compress = \"gz\")\n\n\n\n\nDie Vorverarbeitung pro Screenname packen wir in eine Funktion, das macht es hinten raus einfacher:\n\nprepare_tweets <- function(tweets){\n  \n  tweets %>% \n    select(full_text) %>% \n    unnest_tokens(output = word, input = full_text) %>% \n    anti_join(tibble(word = lsa::stopwords_de)) %>% \n    mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %>% \n    mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %>% \n    mutate(word = str_replace_na(word, \" +\")) %>% \n    drop_na()\n}\n\nTest:\n\nkl_prepped <- \n  prepare_tweets(tweets_to_kl_raw)\n\nJoining, by = \"word\"\n\nhead(kl_prepped)\n\n# A tibble: 6 × 1\n  word                     \n  <chr>                    \n1 tonline⁩                  \n2 spreche                  \n3 neuen                    \n4 pläne                    \n5 bundesgesundheitsminister\n6 karl_lauterbach⁩          \n\n\n\nms_prepped <-\n  prepare_tweets(tweets_to_ms_raw)\n\nJoining, by = \"word\"\n\nhead(ms_prepped)\n\n# A tibble: 6 × 1\n  word         \n  <chr>        \n1 markus_soeder\n2 climate      \n3 activists    \n4 are          \n5 sometimes    \n6 depicted     \n\n\nScheint zu passen.\nDie Sentimentanalyse packen wir auch in eine Funktion:\n\nget_tweets_sentiments <- function(tweets){\n  \n  tweets %>% \n    inner_join(sentiws) %>% \n    group_by(neg_pos) %>% \n    summarise(senti_avg = mean(value, na.rm = TRUE),\n              senti_sd = sd(value, na.rm = TRUE),\n              senti_n = n()) \n}\n\nTest:\n\nkl_prepped %>% \n  get_tweets_sentiments()\n\nJoining, by = \"word\"\n\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n\n\nTest:\n\ntweets_to_kl_raw %>% \n  prepare_tweets() %>% \n  get_tweets_sentiments()\n\nJoining, by = \"word\"\nJoining, by = \"word\"\n\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n\n\nScheint zu passen.\nWir könnten noch die beiden Funktionen in eine wrappen:\n\nprep_sentiments <- function(tweets) {\n\n  tweets %>% \n    prepare_tweets() %>% \n    get_tweets_sentiments()\n}\n\n\ntweets_to_kl_raw %>% \n  prep_sentiments()\n\nJoining, by = \"word\"\nJoining, by = \"word\"\n\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.313    0.237    3576\n2 pos         0.112    0.145    5800\n\n\nOkay, jetzt werden wir die Funktion auf jede Screenname bzw. die Tweets jedes Screennames an.\n\ntweets_list <-\n  list(\n    kl = tweets_to_kl_raw, \n    ms = tweets_to_ms_raw)\n\n\nsentis <-\n  tweets_list %>% \n  map_df(prep_sentiments, .id = \"id\")\n\nJoining, by = \"word\"\nJoining, by = \"word\"\nJoining, by = \"word\"\nJoining, by = \"word\"\n\n\n\nCategories:\n\ntextmining\ntwitter\nprogramming"
  },
  {
    "objectID": "posts/log-y-regr2/log-y-regr2.html",
    "href": "posts/log-y-regr2/log-y-regr2.html",
    "title": "log-y-regr2",
    "section": "",
    "text": "Solution\n\nd2 <-\n  d %>% \n  filter(re74 > 0) %>% \n  mutate(re74_log = log(re74))\n\n\nm <- lm(re74_log ~ educ, data = d2)\n\n\nggplot(d2) +\n  aes(x = re74) +\n  geom_density() +\n  labs(title = \"Income raw\")\n\n\nggplot(d2) +\n  aes(x = re74_log) +\n  geom_density() +\n  labs(title = \"Income log transformed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBetrachten wir die deskriptiven Statistiken:\n\nd2 %>% \n  select(re74, re74_log) %>% \n  describe_distribution()\n\nVariable |     Mean |       SD |      IQR |             Range | Skewness | Kurtosis |    n | n_Missing\n------------------------------------------------------------------------------------------------------\nre74     | 20938.28 | 12631.52 | 15086.30 | [17.63, 1.37e+05] |     1.62 |     6.81 | 2329 |         0\nre74_log |     9.73 |     0.76 |     0.80 |     [2.87, 11.83] |    -1.67 |     6.01 | 2329 |         0\n\n\nDie Log-Transformation hat in diesem Fall nicht wirklich zu einer Normalisierung der Variablen beigetragen. Aber das war auch nicht unser Ziel.\n\nCategories:\n\nregression\nlm\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/fat-tails-Artikel/fat-tails-Artikel.html",
    "href": "posts/fat-tails-Artikel/fat-tails-Artikel.html",
    "title": "fat-tails-Artikel",
    "section": "",
    "text": "Solution\n\nKriege\nPandemien\nErfolg auf der Singlebörse Tinder\nKapitelmarkt\n\n\nCategories:\n\nprobability\ndistribution\nfat-tails"
  },
  {
    "objectID": "posts/adjustieren1/adjustieren1.html",
    "href": "posts/adjustieren1/adjustieren1.html",
    "title": "adjustieren1",
    "section": "",
    "text": "Solution\n\nlibrary(rstanarm)\nlm2 <- stan_glm(mpg ~ hp_z + am, data = mtcars,\n                refresh = 0)\nsummary(lm2)\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 26.6    1.5 24.7  26.6  28.5 \nhp          -0.1    0.0 -0.1  -0.1   0.0 \nam           5.3    1.1  3.8   5.3   6.6 \nsigma        3.0    0.4  2.5   3.0   3.5 \nDie Spalte mean gibt den mittleren geschätzten Wert für den jeweiligen Koeffizienten an, also den Schätzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt für Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als für Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\n\nmtcars %>% \n  mutate(am = factor(am)) %>% \n  ggplot() +\n  aes(x = hp_z, y = mpg, color = am) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\n\n\n\nMan könnte hier noch einen Interaktionseffekt ergänzen.\n\nCategories:\n\nqm2\nlm\nbayes\nstats-nutshell"
  },
  {
    "objectID": "posts/euro-bayes/euro-bayes.html",
    "href": "posts/euro-bayes/euro-bayes.html",
    "title": "euro-bayes",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.00\n0.00\n0.00\n\n\n0.4\n1\n0.00\n0.00\n0.00\n\n\n0.5\n1\n0.01\n0.01\n0.27\n\n\n0.6\n1\n0.02\n0.02\n0.73\n\n\n0.7\n1\n0.00\n0.00\n0.00\n\n\n0.8\n1\n0.00\n0.00\n0.00\n\n\n0.9\n1\n0.00\n0.00\n0.00\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit \\(Pr(\\pi = 1/2 \\, | \\, X=140)\\) wenn \\(X \\sim Bin(250, 1/2)\\) beträgt ca. 27% oder .27.\nAllerdings würden viele Statistiker:innen nicht (nur) fragen, wie wahrscheinlich 140 Treffer sind. Stattdessen könnte man von folgender Überlegung ausgehen.\nZuerst: Welcher Wert wäre am wahrscheinlichsten, wenn die Münze fair wäre?\n\ndbinom(x = 0:250, size = 250, prob = 1/2) %>% which.max()\n\n[1] 126\n\n\nDer 126. Wert in der Liste 0:250 ist der wahrscheinlichste (also 125 Treffer).\nWenn die Münze fair ist, dann wären doch 15 Treffer mehr als 125 genauso so unwahrscheinlich wie 15 Treffer weniger als 125 Treffer. Beide Ereignisse - 110 und 140 Treffer - sind ja gleich weit entfernt von denjenigen Wert, der am wahrscheinlichsten ist, wenn die Münze fair ist.\nEi typischi Statistiki würde also eher fragen: “Wie wahrscheinlich ist es, dass man ein Ergebnis erhält, dass mind. 15 Treffer entfernt ist von der Trefferzahl, die bei einer fairen Münze zu erwarten ist?”. Aber genug davon für diese Aufgabe :-)\n\nCategories:\n\nprobability\nbayes-grid"
  },
  {
    "objectID": "posts/Pupil-size/Pupil-size.html",
    "href": "posts/Pupil-size/Pupil-size.html",
    "title": "Pupil-size",
    "section": "",
    "text": "Solution\n\nModelldefinition\n\n\\[\\begin{aligned}\ns_i &\\sim \\mathcal{N}(\\mu, \\sigma)\\qquad \\text{| s wie size }\\\\\n\\mu &\\sim \\mathcal{N}(10, 5)\\\\\n\\sigma &\\sim \\mathcal{U}(0, 20)\n\\end{aligned}\\]\n\nBegründung der Modellspezifikation\n\n\\(s_i\\): Pupillengrößen sind normalverteilt, da viele Gene additiv auf die Größe hin zusammenwirken\n\\(\\mu\\): Da wir nicht viel wissen über die mittlere Pupillengröße, entscheiden wir uns für Normalverteilung für diesen Parameter, da dies keine weiteren Annahmen (außer dass Mittelwert und Streuung endlich sind) hinzufügt. Ein Modell mit wenig Annahmen nennt man “sparsam” oder konservativ. Es ist wünschenswert, dass Modelle mit so wenig wie möglich Annahmen auskommt (aber so vielen wie nötig).\n\\(\\sigma\\): Die Streuung muss positiv sein, daher kommt keine Normalverteilung in Frage. Da wir (noch) keine passenden Verteilungen kennen außer der Gleichverteilung, entscheiden wir uns für eine vage Gleichverteilung. Die große Stichprobe wird den Priori-Wert vermutlich überstimmen.\n\nPriori-Prädiktiv-Verteilung\n\n\nn <- 1e4\nsim_prior_pred <-\n  tibble(\n    mu = rnorm(n, mean = 10, sd = 5),\n    sigma = runif(n, min = 0, max = 20),\n    size = rnorm(n, mu, sigma)\n  )\n\nsim_prior_pred %>% \n  ggplot(aes(x = size)) +\n  geom_density()\n\n\n\n\n\n\n\n\nDa es viele negative Pupillengröße-Werte gibt, sieht man deutlich, dass das Modell nicht gut spezifiziert ist. So könnte kleinere Streuungswerte zu einem realistischeren Modell führen. Oder man verwendet Verteilungen, die rein positiv sind (hier nicht weiter ausgeführt).\n\nBerechnen Sie die Posteriori-Verteilung.\n\nDie Modelle wie stan_glm() tun sich leichter, wenn man nur die relevanten Daten, ohne fehlende Werte und schon schön fertig vorverarbeitet, zur Analyse in die Modellberechnung gibt:\n\nd3 <-\n  d %>% \n  select(size) %>% \n  drop_na()\n\nDie Posteriori-Verteilung kann man mit dem Paket {rstanarm} d.h. mit der Funktion stan_glm() berechnen:\n\nlibrary(rstanarm)\nm_pupil <- stan_glm(size ~ 1,\n                    data = d3,\n                    refresh = 0)\n\nDie Daten sind groß, es kann ein paar Sekunden brauchen…\nHier ist eine nützliche Zusammenfassung der Post-Verteilung.\n\nparameters(m_pupil)\n\nParameter   | Median |        95% CI |   pd |  Rhat |     ESS |                   Prior\n---------------------------------------------------------------------------------------\n(Intercept) |  10.01 | [9.96, 10.05] | 100% | 1.001 | 2010.00 | Normal (10.01 +- 12.77)\n\n\nHier eine Visualisierung der Parameter:\n\nplot(parameters(m_pupil), show_intercept = TRUE)\n\n\n\n\n\n\n\n\nNatürlich kann man auch die Post-Verteilung plotten:\n\nm_hdi <- hdi(m_pupil, ci = c(0.5, 0.95))\n\nplot(m_hdi, show_intercept = TRUE)\n\n\n\n\n\n\n\n\nHier zur Info die ersten paar Zeilen des Post-Verteilung:\n\n\n\n\n\n\n  \n  \n    \n      (Intercept)\n      sigma\n    \n  \n  \n    10.00\n5.10\n    9.96\n5.10\n    9.97\n5.11\n    9.97\n5.11\n    9.99\n5.12\n  \n  \n  \n\n\n\n\n\nGeben Sie ein 95%-Intervall für die mittlere Pupillengröße an auf Basis der Posteriori-Verteilung.\n\n\neti(m_pupil)\n\nEqual-Tailed Interval\n\nParameter   |       95% ETI | Effects |   Component\n---------------------------------------------------\n(Intercept) | [9.96, 10.05] |   fixed | conditional\n\n\nUnd dann erstellen wir ein 89%-PI:\n\neti(m_pupil, ci = .89)\n\nEqual-Tailed Interval\n\nParameter   |       89% ETI | Effects |   Component\n---------------------------------------------------\n(Intercept) | [9.97, 10.04] |   fixed | conditional\n\n\n\nCategories:\n\nprobability\nbayes\nregression"
  },
  {
    "objectID": "posts/kekse01/kekse01.html",
    "href": "posts/kekse01/kekse01.html",
    "title": "kekse01",
    "section": "",
    "text": "Solution\n\n\n\n\n\n\n\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n1\n1\n0.75\n0.75\n0.6\n\n\n2\n1\n0.50\n0.50\n0.4\n\n\n\n\n\nDie Antwort lautet: .6\n\nCategories:\n\nprobability\nbayes-grid"
  },
  {
    "objectID": "posts/interpret-koeff/interpret-koeff.html",
    "href": "posts/interpret-koeff/interpret-koeff.html",
    "title": "interpret-koeff",
    "section": "",
    "text": "Solution\n\nIntercept (\\(\\beta_0\\)): Der Achsenabschnitt gibt den geschätzten mittleren Y-Wert (Spritverbrauch) an, wenn \\(x=0\\), also für ein Auto mit 0 PS (was nicht wirklich Sinn macht). hp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und damit die Steigung der Regressionsgeraden.\nhp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und gibt den statistischen “Effekt” der PS-Zahl auf den Spritverbrauch an. Vorsicht: Dieser “Effekt” darf nicht vorschnell als kausaler Effekt verstanden werden. Daher muss man vorsichtig sein, wenn man von einem “Effekt” spricht. Vorsichtiger wäre zu sagen: “Ein Auto mit einem PS mehr, kommt im Mittel 0,1 Meilen weniger weit mit einer Gallone Sprit, laut diesem Modell”.\n\n\nCategories:\n\nregression\nlm\nbayes\nstats-nutshell"
  },
  {
    "objectID": "posts/stan_glm01/stan_glm01.html",
    "href": "posts/stan_glm01/stan_glm01.html",
    "title": "stan_glm01",
    "section": "",
    "text": "Solution\n\nlibrary(rstanarm)\n\n\nmodel <-\n  stan_glm(h ~ 1,\n           prior_intercept = normal(0,1),\n           prior_aux = exponential(0.1),\n           daten = meine_Daten\n  )\n\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/ungewiss-arten-regr/ungewiss-arten-regr.html",
    "href": "posts/ungewiss-arten-regr/ungewiss-arten-regr.html",
    "title": "ungewiss-arten-regr",
    "section": "",
    "text": "Solution\n\n\n\n\n7.04\n0.04\n\n\nCategories:\n\nqm2\ninference\nlm"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html",
    "title": "vorhersageintervall1",
    "section": "",
    "text": "Vorhersagen, etwa in einem Regressionsmodell, sind mit mehreren Arten von Unsicherheit konfrontiert.\nBerechnen Sie dazu ein Regressionsmodell, Datensatz mtcars, mit hp als Prädiktor (UV) und mpg als AV (Kriterium)!\nDann sagen Sie bitte den Wert der AV für eine Beobachtungseinheit mit mittlerer Ausprägung im Präktor vorher:\nEinmal nur unter Berücksichtigung der Unsicherheit innerhalb des Modells (“Konfidenzintervall”); einmal unter Berücksichtigung der Unsicherheit innerhalb des Modells sowie die Unsicherheit durch die Koffizienten (“Vohersageintervall”).\nHinweise:\n\npredict() ist eine Funktion, die Sie zur Vorhersage von Regressionsmodellen verwenden können.\nVerwenden Sie lm() zur Berechnung eines Regressionsmodells.\nDas Argument type von predict() erlaubt Ihnen die Wahl der Art der Vorhersage, betrachten Sie Hilfe der Funktion z.B. hier.\n\nBei welchem Intervall ist die Ungewissheit in der Vorhersage größer?\n\n\n\nKonfidenzintervall\nVohersageintervall\nGleich groß\nKommt auf weitere Faktoren an, keine pauschale Antwort möglich"
  },
  {
    "objectID": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist-1",
    "href": "posts/vorhersageintervall1/vorhersageintervall1.html#answerlist-1",
    "title": "vorhersageintervall1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nWahr\nFalsch\nFalsch\n\n\nCategories:\n\nlm\ninference\nqm2"
  },
  {
    "objectID": "posts/voll-normal/voll-normal.html",
    "href": "posts/voll-normal/voll-normal.html",
    "title": "voll-normal",
    "section": "",
    "text": "Solution\n\nIntelligenz, Aussehen, Gesundheit, Herkunft, Hautfarbe, sexuelle Identität oder Neigung, …\nFür unabhängige Ereignisse ist die Wahrscheinlichkeit, dass sie alle eintreten, gleich dem Produkt ihrer Einzelwahrscheinlichkeiten:\n\n\\(VN = Pr(E_i)^{10} = 0.9^{10} \\approx 0.3486784\\)\nDie Wahrscheinlichkeit, dass \\(VN\\) nicht eintritt (Nicht-Voll-Normal, NVN), ist dann die Gegenwahrscheinlichkeit: \\(NVN = 1- VN\\).\n\nMehrere der Annahmen sind diskutabel. So könnten die Eigenschaften nicht unabhängig sein, dann wäre der hier gezeigte Rechenweg nicht anwendbar. Die Wahrscheinlichkeit für “normal” könnte höher oder niedriger sein, wobei 90% nicht ganz unplausibel ist. Schließlich unterliegt das Ereignis \\(E_N\\) mit den Ergebnissen \\(n\\) bzw. \\(nn\\) sozialpsychologischen bzw. soziologischen Einflüssen und kann variieren.\n\n\nCategories:\n\nprobability\nmeta"
  },
  {
    "objectID": "posts/iq07/iq07.html",
    "href": "posts/iq07/iq07.html",
    "title": "iq07",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten; Subpopulation 1:\n\nset.seed(42)\n\nd1 <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 85, sd = 15))\n\nSubpopulation 2:\n\nset.seed(42)\n\nd2 <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 115, sd = 15))\n\nDann kombinieren wir die Daten zu einer Tabelle:\n\nd <-\n  d1 %>% \n  bind_rows(d2)\n\nDann filtern wir wie in der Angabe gefragt:\n\nsolution_d <-\n  d %>% \n  count(iq > 115) %>% \n  mutate(prop = n / sum(n))\n\nsolution_d\n\n# A tibble: 2 × 3\n  `iq > 115`     n  prop\n  <lgl>      <int> <dbl>\n1 FALSE       1494 0.747\n2 TRUE         506 0.253\n\n\n\n\n\nDie Lösung lautet also 0.253.\nWenn Sie die Zufallszahlen mit set.seed fixiert haben, sollten Sie den exakt gleichen Wert gefunden haben.\nInteressant ist es vielleicht, die Gesamtpopulation zu visualisieren:\n\nggplot(d) +\n  aes(x = iq) +\n  geom_density()\n\n\n\n\n\n\n\n\nIm Vergleich dazu eine Normalverteilung mit MW=100 und SD=15:\n\n\n\n\n\n\n\n\n\nWir sehen, dass unsere Population über eine (deutlich) höhere Streuung verfügt:\n\nd %>% \n  summarise(sd(iq))\n\n# A tibble: 1 × 1\n  `sd(iq)`\n     <dbl>\n1     21.2\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/lm-Standardfehler/lm-Standardfehler.html",
    "href": "posts/lm-Standardfehler/lm-Standardfehler.html",
    "title": "lm-Standardfehler",
    "section": "",
    "text": "Man kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser Übung untersuchen wir, wie sich der SE als Funktion der Stichprobengröße, \\(n\\), verhält.\nErstellen Sie dazu folgenden Datensatz:\n\nlibrary(tidyverse)\n\nn <- 2^4\n\nd <-\n  tibble(x = rnorm(n = n),  # im Default: mean = 0, sd = 1\n         y = x + rnorm(n, mean = 0, sd = .5))\n\nHier ist das Ergebnis. Uns interessiert v.a. Std. Error für den Prädiktor x:\n\nlm(y ~ x, data = d) %>% \nsummary()\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.60191 -0.42922  0.09198  0.32313  0.59878 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.1226     0.1061  -1.156    0.267    \nx             1.0385     0.0888  11.694  1.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4223 on 14 degrees of freedom\nMultiple R-squared:  0.9071,    Adjusted R-squared:  0.9005 \nF-statistic: 136.8 on 1 and 14 DF,  p-value: 1.302e-08\n\n\nHier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie, wie sich die Schätzgenauigkeit, gemessen über den SE, verändert. Berechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\nBei welcher Stichprobengröße ist SE am kleinsten?\n\n\n\n\\(2^5\\)\n\\(2^6\\)\n\\(2^7\\)\n\\(2^8\\)\n\\(2^9\\)"
  },
  {
    "objectID": "posts/lm-Standardfehler/lm-Standardfehler.html#answerlist-1",
    "href": "posts/lm-Standardfehler/lm-Standardfehler.html#answerlist-1",
    "title": "lm-Standardfehler",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nWahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.\n\n\nCategories:\n\ninference\nlm\nqm2"
  },
  {
    "objectID": "posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html",
    "href": "posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html",
    "title": "punktschaetzer-reicht-nicht",
    "section": "",
    "text": "Solution\nModell m1 hat eine kleinere Ungewissheit im Hinblick auf die Modellkoeffizienten \\(\\beta_0, \\beta_1\\) und ist daher gegenüber m2 zu bevorzugen.\n\nCategories:\n\nregresssion\nen\nbayes\nfrequentist\nqm1\nstats-nutshell\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/Lose-Nieten-Binomial-Grid/Lose-Nieten-Binomial-Grid.html",
    "href": "posts/Lose-Nieten-Binomial-Grid/Lose-Nieten-Binomial-Grid.html",
    "title": "Lose-Nieten-Binomial-Grid",
    "section": "",
    "text": "Solution\n\nWie groß ist die Wahrscheinlichkeit für genau \\(k=0,1,...,10\\) Treffer?\n\n\nd_a <- \n  tibble(\n    k = 0:10,\n    wskt = dbinom(k, size = 10, prob = .01))\n\nd_a %>% \n  ggplot() +\n  aes(x = k, y = wskt) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      k\n      wskt\n    \n  \n  \n    0\n9.04 × 10−1\n    1\n9.14 × 10−2\n    2\n4.15 × 10−3\n    3\n1.12 × 10−4\n    4\n1.98 × 10−6\n    5\n2.40 × 10−8\n    6\n2.02 × 10−10\n    7\n1.16 × 10−12\n    8\n4.41 × 10−15\n    9\n9.90 × 10−18\n    10\n1.00 × 10−20\n  \n  \n  \n\n\n\n\n\nSagen wir, Sie haben 3 Treffer in den 10 Losen. Yeah! Jetzt sei \\(p\\) unbekannt und Sie sind indifferent zu den einzelnen Werten von \\(p\\). Visualisieren Sie die Posteriori-Wahrscheinlichkeitsverteilung mit ca. 100 Gridwerten. Was beobachten Sie?\n\n\nd2 <-\n  tibble(\n    p_grid = seq(0, 1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 3, size = 10, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd2 %>% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\nDer Modus liegt bei ca 1/3. Der Bereich plausibler Werte für \\(p\\) liegt ca. zwischen 0.1 und und 0.7, grob visuell geschätzt. Mehr dazu später.\n\nVariieren Sie \\(n\\), aber halten Sie die Trefferquote bei 1/3. Was beobachten Sie?\n\n\n# n = 2\nd3 <-\n  tibble(\n    p_grid = seq(0,1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 2, size = 6, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd3 %>% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"n=20\")\n\n\n# n = 20\nd4 <-\n  tibble(\n    p_grid = seq(0,1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 20, size = 60, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd4 %>% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"n = 20\")\n\n# n = 200\nd5 <-\n  tibble(\n    p_grid = seq(0,1, by = 0.01),\n    prior = 1,\n    Likelihood = dbinom(x = 200, size = 600, prob = p_grid),\n    unstand_post = prior * Likelihood,\n    std_post = unstand_post / sum(unstand_post)\n  )\n\nd5 %>% \n  ggplot() +\n  aes(x = p_grid, y = std_post) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"n = 20\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Modus und andere Maße der zentralen Tendenz bleiben gleich; die Streuung wird geringer.\n\nCategories:\n\nprobability\nbinomial"
  },
  {
    "objectID": "posts/fattails01/fattails01.html",
    "href": "posts/fattails01/fattails01.html",
    "title": "fattails01",
    "section": "",
    "text": "Answerlist\n\nkleiner als 50%\nkleiner als 5%\nkleiner als 0.5%\nkleiner als 0.05%\nkleiner als 0.005%\n\n         \n\n\nSolution\n\nlibrary(tidyverse)\n\nErstellen wir erstmal den ersten Teil einer Bayes-Box:\n\nd <-\n  tibble(H = c(\"Normalverteilt\", \"Randlastig verteilt\"),\n         Prior = c(1,1))\n\nd\n\n# A tibble: 2 × 2\n  H                   Prior\n  <chr>               <dbl>\n1 Normalverteilt          1\n2 Randlastig verteilt     1\n\n\nDann fügen wir den Likelihood jeder Hypothese dazu:\n\nd <-\n  d %>% \n  mutate(L = c(L_norm, L_fat))\n\nd\n\n# A tibble: 2 × 3\n  H                   Prior        L\n  <chr>               <dbl>    <dbl>\n1 Normalverteilt          1 1.31e-23\n2 Randlastig verteilt     1 4.93e- 3\n\n\nDann berechnen wir die Post-Wahrscheinlichkeit:\n\nd <-\n  d %>% \n  mutate(Post_unstand = Prior * L,\n         Post = Post_unstand / sum(Post_unstand))\nd\n\n# A tibble: 2 × 5\n  H                   Prior        L Post_unstand     Post\n  <chr>               <dbl>    <dbl>        <dbl>    <dbl>\n1 Normalverteilt          1 1.31e-23     1.31e-23 2.66e-21\n2 Randlastig verteilt     1 4.93e- 3     4.93e- 3 1   e+ 0\n\n\nDie Wahrscheinlichkeit, dass die Variable normalverteilt ist, ist seeeeehr klein, ca. \\(10^{-21}\\).\n\n\nAnswerlist\n\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/Gem-Wskt1/Gem-Wskt1.html",
    "href": "posts/Gem-Wskt1/Gem-Wskt1.html",
    "title": "Gem-Wskt1",
    "section": "",
    "text": "Solution\nDie gemeinsame Wahrscheinlichkeit beträgt 0.07.\n\n\n\n\n\n\n  \n  \n    \n      Lerntyp\n      Klausurergebnis\n      n\n      n_group\n      prop_conditional_group\n      joint_prob\n    \n  \n  \n    Viellerner\nDurchfallen\n5\n42\n0.1190476\n0.07142857\n  \n  \n  \n\n\n\n\nDie gemeinsame Wahrscheinlichkeit berechnet sich hier als der Quotient der Zellenhäufigkeit und der Gesamthäufigkeit.\nMan kann auch die Formel für gemeinsame Wahrscheinlichkeiten anwenden: \\(Pr(A) \\cdot \\Pr(B)\\).\nDazu berechnet man die Anteile für jedes der beiden Ereignisse und multipliziert diese beiden Anteile:\n`Klausurergebnis_selected * Lerntyp_selected*\n\nCategories:\n\nprobability\n‘2022’"
  },
  {
    "objectID": "posts/wuerfel04/wuerfel04.html",
    "href": "posts/wuerfel04/wuerfel04.html",
    "title": "wuerfel04",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nEinen Würfelwurf in R kann man so simulieren:\n\nwuerfel <- sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))\nwuerfel\n\n[1] 5\n\n\nBei sample gibt x den Ereignisraum, \\(\\Omega\\), an, size die Stichprobengröße und prob gibt für jedes Element von x die Wahrscheinlichkeit an.\nDas machen wir jetzt 1000 Mal. Viel Spaß beim Tippen…\n… … …\nOkay, das sollten wir einfacher hinkriegen. Man kann R sagen, dass sie eine Funktion (wie sample) oft ausführen soll. Damit können wir viele Würfelwürfe simulieren. Diese “Wiederholungsfunktion” heißt replicate(n, expr); dabei gibt n an, wie oft die Funktion wiederholt werden soll, und expr ist der Ausdruck (die Funktion), die wiederholt werden soll, das ist bei uns die Funktion sample, wie oben dargestellt.\n\nzehn_wuerfel <- replicate(n = 10, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\nzehn_wuerfel\n\n [1] 5 3 2 1 3 1 4 6 3 3\n\n\nKönnen wir natürlich auch zich Mal wiederholen, nicht nur 10 Mal, sagen wir \\(10^4\\) Mal:\n\nset.seed(42)\nwuerfel1_oft <- replicate(n = 10^4, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\n\nmean(wuerfel1_oft)\n\n[1] 3.4968\n\n\nAh, interessant: Der Mittelwert ist etwa 3.5…\nJetzt werfen wir noch einen zweiten Würfel genau so oft:\n\nset.seed(43)\nwuerfel2_oft <- replicate(n = 10^4, expr = sample(x = c(1,2,3,4,5,6), size = 1, prob = c(1/6, 1/6,1/6,1/6,1/6,1/6)))\n\nmean(wuerfel2_oft)\n\n[1] 3.4983\n\n\nDas packen wir jetzt in eine Tabelle und ergänzen die Augensumme für jede Wiederholung des Doppelwurfes:\n\nd <-\n  tibble(w1 = wuerfel1_oft,\n         w2 = wuerfel2_oft,\n         w_sum = w1+w2)\n\nhead(d)\n\n# A tibble: 6 × 3\n     w1    w2 w_sum\n  <dbl> <dbl> <dbl>\n1     1     4     5\n2     1     1     2\n3     3     2     5\n4     6     6    12\n5     5     3     8\n6     5     5    10\n\n\nJetzt ist es einfach:\nWir zählen einfach, wie oft das Ergebnis 10 vorkommt in der Tabelle.\n\nd %>% \n  count(w_sum == 10)\n\n# A tibble: 2 × 2\n  `w_sum == 10`     n\n  <lgl>         <int>\n1 FALSE          9148\n2 TRUE            852\n\n\nErgänzen wir die Anteile dieser Anzahl:\n\nd %>% \n  count(w_sum == 10) %>% \n  mutate(Anteil = n/sum(n))\n\n# A tibble: 2 × 3\n  `w_sum == 10`     n Anteil\n  <lgl>         <int>  <dbl>\n1 FALSE          9148 0.915 \n2 TRUE            852 0.0852\n\n\nDie Lösung lautet also: 0.08 (gerundet auf zwei Dezimalen)\nAuf einfache Weise können wir entsprechend die Wahrscheinlichkeit für mindestens \\(k\\) Augen (bei zwei Würfelwürfen) ermitteln, mit \\(k\\) ist die gesuchte Augensumme, hier 10.\n\nd %>% \n  count(w_sum >= 10) %>% \n  mutate(Anteil = n/sum(n))\n\n# A tibble: 2 × 3\n  `w_sum >= 10`     n Anteil\n  <lgl>         <int>  <dbl>\n1 FALSE          8316  0.832\n2 TRUE           1684  0.168\n\n\nOder höchstens 10, ganz analog:\n\nd %>% \n  count(w_sum <= 10) %>% \n  mutate(Anteil = n/sum(n))\n\n# A tibble: 2 × 3\n  `w_sum <= 10`     n Anteil\n  <lgl>         <int>  <dbl>\n1 FALSE           832 0.0832\n2 TRUE           9168 0.917 \n\n\n\nCategories:\n\nprobability\ndice\nsimulation"
  },
  {
    "objectID": "posts/wuerfel03/wuerfel03.html",
    "href": "posts/wuerfel03/wuerfel03.html",
    "title": "wuerfel03",
    "section": "",
    "text": "Solution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden Würfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), …, (1,6), …, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd <- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\n\nd\n\n# A tibble: 36 × 2\n   wuerfel1 wuerfel2\n      <int>    <int>\n 1        1        1\n 2        1        2\n 3        1        3\n 4        1        4\n 5        1        5\n 6        1        6\n 7        2        1\n 8        2        2\n 9        2        3\n10        2        4\n# … with 26 more rows\n\n\nJetzt ergänzen wir eine Spalte für die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 <-\n  d %>% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n# A tibble: 6 × 3\n  wuerfel1 wuerfel2   prob\n     <int>    <int>  <dbl>\n1        1        1 0.0278\n2        1        2 0.0278\n3        1        3 0.0278\n4        1        4 0.0278\n5        1        5 0.0278\n6        1        6 0.0278\n\n\nAußerdem ergänzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 <-\n  d2 %>% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        1        1 0.0278          2\n2        1        2 0.0278          3\n3        1        3 0.0278          4\n4        1        4 0.0278          5\n5        1        5 0.0278          6\n6        1        6 0.0278          7\n\n\nFür manche Augensummen gibt es mehrere Möglichkeiten:\n\nd3 %>% \n  filter(augensumme == 7)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        1        6 0.0278          7\n2        2        5 0.0278          7\n3        3        4 0.0278          7\n4        4        3 0.0278          7\n5        5        2 0.0278          7\n6        6        1 0.0278          7\n\n\n… für andere weniger:\n\nd3 %>% \n  filter(augensumme == 12)\n\n# A tibble: 1 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        6        6 0.0278         12\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 <- \n  d3 %>% \n  group_by(augensumme) %>% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n# A tibble: 11 × 2\n   augensumme totale_w_pro_augenzahl\n        <int>                  <dbl>\n 1          2                 0.0278\n 2          3                 0.0556\n 3          4                 0.0833\n 4          5                 0.111 \n 5          6                 0.139 \n 6          7                 0.167 \n 7          8                 0.139 \n 8          9                 0.111 \n 9         10                 0.0833\n10         11                 0.0556\n11         12                 0.0278\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %>% \n  summarise(sum(totale_w_pro_augenzahl))\n\n# A tibble: 1 × 1\n  `sum(totale_w_pro_augenzahl)`\n                          <dbl>\n1                             1\n\n\nUnd:\n\nd2 %>% \n  summarise(sum(prob))\n\n# A tibble: 1 × 1\n  `sum(prob)`\n        <dbl>\n1           1\n\n\nPasst!\nDie Wahrscheinlichkeit für die Augensumme von höchstens 10 beträgt also:\n\nloesung <-\n  d4 %>% \n  filter(augensumme <= 10) %>% \n  summarise(prob_sum = sum(totale_w_pro_augenzahl)) %>% \n  pull(prob_sum)\n\nloesung\n\n[1] 0.9166667\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/Rethink_2E4/Rethink_2E4.html",
    "href": "posts/Rethink_2E4/Rethink_2E4.html",
    "title": "Rethink_2E4",
    "section": "",
    "text": "Solution\nThe solution is taken from this source.\nThe idea is that probability is only a subjective perception of the likelihood that something will happen. In the globe tossing example, the result will always be either “land” or “water” (i.e., 0 or 1). When we toss the globe, we don’t know what the result will be, but we know it will always be “land” or “water.” To express our uncertainty in the outcome, we use probability. Because we know that water is more likely than land, we may say that the probability of “water” is 0.7; however, we’ll never actually observe a result of 0.7 waters, or observe any probability. We will only ever observe the two results of “land” and “water.”\n\nCategories:\n\nprobability\nphilosophy"
  },
  {
    "objectID": "posts/iq01/iq01.html",
    "href": "posts/iq01/iq01.html",
    "title": "iq01",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nd <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd= 15))\n\nWir filtern wie in der Angabe gewünscht:\n\nd %>% \n  count(iq >= 130)\n\n# A tibble: 2 × 2\n  `iq >= 130`     n\n  <lgl>       <int>\n1 FALSE         979\n2 TRUE           21\n\n\nCa. 20 von 1000 Personen erfüllen diese Bedingung (IQ >= 130).\nAlso: Die gesuchte Wahrscheinlichkeit beträgt ca. 2%.\n\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/iq06/iq06.html",
    "href": "posts/iq06/iq06.html",
    "title": "iq06",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\nWir simulieren die Daten:\n\nset.seed(42)\nk <- 3\nd <- tibble(\n  id = 1:10^3,\n  iq = rnorm(n = 10^3, mean = 100, sd = 15))\n\nWir filtern die schlauesten 0,1 Prozent:\n\nd %>% \n  count(iq > 85 & iq < 115) \n\n# A tibble: 2 × 2\n  `iq > 85 & iq < 115`     n\n  <lgl>                <int>\n1 FALSE                  327\n2 TRUE                   673\n\n\n\n\n\nDie Lösung lautet also 0.673.\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/iq08/iq08.html",
    "href": "posts/iq08/iq08.html",
    "title": "iq08",
    "section": "",
    "text": "Solution\nDie Wahrscheinlichkeit für “schön”, \\(S1\\) ist gleich der Wahrscheinlichkeit für “Schlau”, \\(S2\\).\n\nlibrary(tidyverse)\n\nWir simulieren die Daten; Subpopulation 1:\n\nset.seed(42)\n\nd <- tibble(\n  id = 1:10^4,\n  schoenheit = rnorm(n = 10^4, mean = 0, sd = 1),\n  schlauheit = rnorm(n = 10^4, mean = 0, sd = 1))\n\nDann filtern wir wie in der Angabe gefragt:\n\nd2 <-\n  d %>% \n  count(schoenheit > 1, schlauheit > 1) %>% \n  mutate(prop = n / sum(n))\n\nd2\n\n# A tibble: 4 × 4\n  `schoenheit > 1` `schlauheit > 1`     n  prop\n  <lgl>            <lgl>            <int> <dbl>\n1 FALSE            FALSE             7082 0.708\n2 FALSE            TRUE              1364 0.136\n3 TRUE             FALSE             1314 0.131\n4 TRUE             TRUE               240 0.024\n\n\nWieder nehmen wir den Anteil her und bezeichnen ihn als Wahrscheinlichkeit. Das ist eine schöne Sache dieser Simulationsmethoden: Es vereinfacht die Angelegenheit, denn mit Häufigkeiten lässt sich einfacher hantieren als mit Wahrscheinlichkeiten. Und die Anteile erfüllen die Kolmogorov-Axiome, wir können also beruhigt rechnen. Falls Sie also vor Sorge um die Reinheit der Mathematik nicht schlafen konnten, kann ich Sie beruhigen :-)\n\n\n\nDie Lösung lautet also 0.024.\nInteressant ist es vielleicht, die Gesamtpopulation zu visualisieren:\n\nd %>% \n  mutate(ist_schoen = if_else(schoenheit > 1, TRUE, FALSE),\n         ist_schlau = if_else(schlauheit > 1, TRUE, FALSE),\n         ist_schoen_schlau = if_else(ist_schoen & ist_schlau, TRUE, FALSE)) %>% \n  ggplot() +\n  aes(x = schoenheit, y = schlauheit, color = ist_schoen_schlau, alpha = .1) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nsimulation\nnormal-distribution"
  },
  {
    "objectID": "posts/wuerfel02/wuerfel02.html",
    "href": "posts/wuerfel02/wuerfel02.html",
    "title": "wuerfel02",
    "section": "",
    "text": "Solution\nErstellen wir uns eine Tabelle, die alle Permutationen der beiden Würfelergebnisse fasst, das sind 36 Paare: (1,1), (1,2), …, (1,6), …, (6,6).\nDas kann man von Hand erstellen, halbautomatisch in Excel oder z.B. so:\n\nlibrary(tidyverse)\nd <- expand_grid(wuerfel1 = 1:6,\n         wuerfel2 = 1:6)\n\nd\n\n# A tibble: 36 × 2\n   wuerfel1 wuerfel2\n      <int>    <int>\n 1        1        1\n 2        1        2\n 3        1        3\n 4        1        4\n 5        1        5\n 6        1        6\n 7        2        1\n 8        2        2\n 9        2        3\n10        2        4\n# … with 26 more rows\n\n\nJetzt ergänzen wir eine Spalte für die Wahrscheinlichkeit jeder Kombination, das ist einfach, denn \\(p(A \\cap B) = p(A) \\cdot p(B) = 1/36\\) gilt.\n\nd2 <-\n  d %>% \n  mutate(prob = 1/36)\n\nhead(d2)\n\n# A tibble: 6 × 3\n  wuerfel1 wuerfel2   prob\n     <int>    <int>  <dbl>\n1        1        1 0.0278\n2        1        2 0.0278\n3        1        3 0.0278\n4        1        4 0.0278\n5        1        5 0.0278\n6        1        6 0.0278\n\n\nAußerdem ergänzen wir die Summe der Augenzahlen, weil die Frage ja nach einer bestimmten Summe an Augenzahlen abzielt.\n\nd3 <-\n  d2 %>% \n  mutate(augensumme = wuerfel1 + wuerfel2)\n\nhead(d3)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        1        1 0.0278          2\n2        1        2 0.0278          3\n3        1        3 0.0278          4\n4        1        4 0.0278          5\n5        1        5 0.0278          6\n6        1        6 0.0278          7\n\n\nFür manche Augensummen gibt es mehrere Möglichkeiten:\n\nd3 %>% \n  filter(augensumme == 7)\n\n# A tibble: 6 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        1        6 0.0278          7\n2        2        5 0.0278          7\n3        3        4 0.0278          7\n4        4        3 0.0278          7\n5        5        2 0.0278          7\n6        6        1 0.0278          7\n\n\n… für andere weniger:\n\nd3 %>% \n  filter(augensumme == 12)\n\n# A tibble: 1 × 4\n  wuerfel1 wuerfel2   prob augensumme\n     <int>    <int>  <dbl>      <int>\n1        6        6 0.0278         12\n\n\nJetzt summieren wir (nach dem Additionssatz der Wahrscheinlichkeit) die Wahrscheinlichkeiten pro Augenzahl:\n\nd4 <- \n  d3 %>% \n  group_by(augensumme) %>% \n  summarise(totale_w_pro_augenzahl = sum(prob))\n\nd4\n\n# A tibble: 11 × 2\n   augensumme totale_w_pro_augenzahl\n        <int>                  <dbl>\n 1          2                 0.0278\n 2          3                 0.0556\n 3          4                 0.0833\n 4          5                 0.111 \n 5          6                 0.139 \n 6          7                 0.167 \n 7          8                 0.139 \n 8          9                 0.111 \n 9         10                 0.0833\n10         11                 0.0556\n11         12                 0.0278\n\n\nTest: Die Summe der Wahrscheinlichkeit muss insgesamt 1 sein.\n\nd4 %>% \n  summarise(sum(totale_w_pro_augenzahl))\n\n# A tibble: 1 × 1\n  `sum(totale_w_pro_augenzahl)`\n                          <dbl>\n1                             1\n\n\nUnd:\n\nd2 %>% \n  summarise(sum(prob))\n\n# A tibble: 1 × 1\n  `sum(prob)`\n        <dbl>\n1           1\n\n\nPasst!\nDie Wahrscheinlichkeit für die Augensumme von mind. 10 beträgt also:\n\nloesung <-\n  d4 %>% \n  filter(augensumme >= 10) %>% \n  summarise(prob_sum = sum(totale_w_pro_augenzahl)) %>% \n  pull(prob_sum)\n\nloesung\n\n[1] 0.1666667\n\n\n\nCategories:\n\nprobability\ndice"
  },
  {
    "objectID": "posts/nasa03/nasa03.html",
    "href": "posts/nasa03/nasa03.html",
    "title": "nasa03",
    "section": "",
    "text": "Solution\ntemp_is_above erstellen:\n\nd <-\n  d %>% \n  mutate(temp_is_above = case_when(\n    Jan > 0 ~ \"yes\",\n    Jan <= 0 ~ \"no\"\n  ))\n\nJahrhundert berechnen:\n\nd <-\n  d %>% \n  mutate(century = case_when(\n    Year < 1900 ~ \"19th\",\n    Year >= 1900 ~ \"20th\"\n  ))\n\nErhöhte Werte der Januar-Temperatur pro Jahrhundert berechnen:\n\nd_summarized <- \nd %>% \n  group_by(century) %>% \n  count(temp_is_above)\n\nd_summarized\n\n# A tibble: 4 × 3\n# Groups:   century [2]\n  century temp_is_above     n\n  <chr>   <chr>         <int>\n1 19th    no               19\n2 19th    yes               1\n3 20th    no               56\n4 20th    yes              67\n\n\nDer Befehl count() zählt aus, wie häufig die Ausprägungen der angegebenen Variablen X sind, m.a.W. er gibt die Verteilung von X wieder.\nEs macht vermutlich Sinn, noch die Anteile (relative Häufigkeiten) zu den absoluten Häufigkeiten zu ergänzen:\n\nd_summarized %>% \n  mutate(prop = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   century [2]\n  century temp_is_above     n  prop\n  <chr>   <chr>         <int> <dbl>\n1 19th    no               19 0.95 \n2 19th    yes               1 0.05 \n3 20th    no               56 0.455\n4 20th    yes              67 0.545\n\n\nOdds Ratio berechnen:\nWir bezeichnen mit c19 (für “Chance 1”) das Verhältnis von erhöhter Temperatur zu nicht erhöhter Temperatur im 19. Jahrhundert.\n\nc19 <- 1 / 19\n\nMit c20 bezeichnen wir die analoge Chance für das 20. Jahrhundert:\n\nc20 <- 56 / 67\n\nDas Verhältnis der beiden Chancen gibt das Chancenverhältnis (Odds Ratio, OR):\n\nc19 / c20\n\n[1] 0.06296992\n\n\nGenauso gut kann man das OR von c20 zu c19 ausrechnen, der Effekt bleibt identisch:\n\nc20 / c19\n\n[1] 15.8806\n\n\nIn beiden Fällen ist es ein Faktor von knapp 16.\n\nCategories:\n\ndata\neda"
  },
  {
    "objectID": "posts/Rethink_2m7/Rethink_2m7.html",
    "href": "posts/Rethink_2m7/Rethink_2m7.html",
    "title": "Rethink_2m7",
    "section": "",
    "text": "Solution\nLet’s label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nTo keep things straigt, here’s visualization of our data.\n\n\n\n\n\n\n\n\n\nWanted is the probability \\(Pr(c1=bb|1b,2w)\\), the probability of drawing (as card 1) a bb card, given that we observerd b in the first draw, denoted as 1b, and a white card in the second draw, denoted as 2w.\nLet’s draw a tree diagram for easier comprehension.\n\n\n\n\n\n\nIn the diagram, the symbol “_b_w” means that black face of a the bw-card (one black, one white face) was drawn. Similarly, “_b_b” means that one (of the two) black faces of the bb-card (two black faces) was drawn.\nHere, we have to consider two cards. Let’s use this notation ww-bb for the sequence “first card is white on both sides, second card is black on both sides”.\nThe data observed is: first card has one black side, the second card has one white side, i.,e b-w.\nLooking at the tree, we realize that out of all 8 paths, 6 feature the bb card as first card:\n\\(Pr(1bb|b,w) = 6/8 = 3/4 = 0.75\\)\nwhere 1bb means “card 1 is black on both sides”, and b,w means “first draw showed a black face, and second card showed a white face”.\nIn other words, there are 8 valid paths in the tree diagram, out of which 6 belong the the hypothesis that the first card is all black.\nAs a Bayes-Grid (or “Bayes-Box”) we can depict the situation like this:\n\n\n\n\n\nHyp\nPrior\nL\nunstand_Post\nPost\n\n\n\n\nbb\n1\n6\n6\n3/4\n\n\nbw\n1\n2\n2\n1/4\n\n\n\n\n\nOr, equally valid, realizihg that there are the events of the card “bb”:\n\n\n\n\n\nHyp\nPrior\nL\nunstand_Post\nPost\n\n\n\n\nbb\n2\n3\n6\n3/4\n\n\nbw\n1\n2\n2\n1/4\n\n\n\n\n\nOr, using probability, and not counts:\n\n\n\n\n\nHyp\nPrior\nL\nunstand_Post\nPost\n\n\n\n\nbb\n2\n3/4\n6/4\n3/4\n\n\nbw\n1\n2/4\n2/4\n1/4\n\n\n\n\n\nWhenever the probability of all paths (in a tree diagram) is the same, as it is the case in the present example, we do not need to write down the probability of the path for the likelihood. It is enough to write the number of paths (of course we can if we want).\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/ReThink3m2/ReThink3m2.html",
    "href": "posts/ReThink3m2/ReThink3m2.html",
    "title": "ReThink3m2",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\n\n\n\nPost-Verteilung berechnen:\n\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, 1000)\nlikelihood <- dbinom(8, size = 15, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nStichproben-Postverteilung erstellen:\n\nsamples <- \n  tibble(anteil_wasser = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE))\n\nhead(samples)\n\n# A tibble: 6 × 1\n  anteil_wasser\n          <dbl>\n1         0.458\n2         0.290\n3         0.427\n4         0.610\n5         0.687\n6         0.484\n\n\n\n\n\n\nsamples %>% \n  ggplot() +\n  aes(x = anteil_wasser) +\n  geom_histogram() + \n  labs(title = \"Stichproben aus der Posteriori-Verteilung\")\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(easystats)\nhdi(samples, prob = 0.9)\n\nHighest Density Interval\n\nParameter     |      95% HDI\n----------------------------\nanteil_wasser | [0.31, 0.76]\n\n\n\nCategories:\n\nbayes\npost\nprobability"
  },
  {
    "objectID": "posts/ReThink3m5/ReThink3m5.html",
    "href": "posts/ReThink3m5/ReThink3m5.html",
    "title": "ReThink3m5",
    "section": "",
    "text": "Solution\n\nBerechnen Sie die Posteriori-Verteilung und visualisieren Sie sie. Nutzen Sie die Gittermethode.\n\n\nset.seed(42)\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- case_when(\n  p_grid <  0.5 ~ 0,\n  p_grid >= 0.5 ~ 1)\nlikelihood <- dbinom(8, size = 15, prob = p_grid)\nunstand_posterior <- likelihood * prior\nposterior <- unstand_posterior / sum(unstand_posterior)\n\n\ntibble(p = p_grid, \n       posterior = posterior) %>%\n  ggplot(aes(x = p, y = posterior)) +\n # geom_point() +\n  geom_line() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\n\n\n\n\n\n\n\n\n\nZiehen Sie \\(10^4\\) Stichproben aus der Posteriori-Verteilung, die Sie mit der Gittermethode erhalten haben. Berechnen Sie auf dieser Grundlage das 90%-HDI.\n\n\nlibrary(easystats)\n# Stichproben (samples) aus der Posteriori-Verteilung:\nsamples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\nhdi(samples, prob = 0.9)\n\n95% HDI: [0.50, 0.75]\n\n\n\nBerechnen Sie die PPV für dieses Modell. Was ist die Wahrscheinlichkeit 8 von 15 Treffer zu erzielen laut dieser PPV?\n\n\nPPV <-\n  tibble(w = rbinom(1e4, size = 15, prob = samples))  # w wie Wasser\n\nPPV %>% \n  count(w == 8) %>% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 × 3\n  `w == 8`     n  prop\n  <lgl>    <int> <dbl>\n1 FALSE     8508 0.851\n2 TRUE      1492 0.149\n\n\n\nAuf Basis der aktuellen Posteriori-Wahrscheinlichkeit: Was ist die Wahrscheinlichkeit für 6 Wasser bei 9 Würfen?\n\n\nPPV <-\n  PPV %>% \n  mutate(w2 = rbinom(1e4, size = 9, prob = samples))\n\nPPV %>% \n  count(w2 == 6) %>% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 × 3\n  `w2 == 6`     n  prop\n  <lgl>     <int> <dbl>\n1 FALSE      7738 0.774\n2 TRUE       2262 0.226\n\n\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/Bsp-Binomial/Bsp-Binomial.html",
    "href": "posts/Bsp-Binomial/Bsp-Binomial.html",
    "title": "Bsp-Binomial",
    "section": "",
    "text": "Solution\nZur Erinnerung: Die Inferenzstatistik macht Aussagen bzgl. einer Population, nicht einer Stichprobe. Solche Aussagen sind ungewiss, also mit einer Unsicherheit behaftet, da wir nicht die ganze Population kennen. Aber die Daten der Stichprobe werden als Grundlage der Schätzung herangezogen.\n\nAuswahl geeigneter Kandidatis in einem Assessment-Verfahren. Man hat \\(n=40\\) Bewerbis, und die Wahrscheinlichkeit geeigneter Kandidatis liege bei \\(p=10%\\). Welche Spannweite an geeigneten Bewerbis kann man erwarten?\nSocial Influencing. Sie posten 100 Videoclips; davon werden 9 viral. Welche Spannweite plausibler Werte für eine Erfolgsquote kann man zugrunde legen?\nApp-Wartung. Sie prüfen eine Anzahl (\\(n=42\\)) alter Apps, aus einer früheren Kampagne. Sie finden, dass \\(k=19\\) noch funktionieren. Welche Quote an “technisch veraltet” muss man in der Population erwarten, und in welchem Bereich könnte sich diese Quote bewegen?\nSchulungsprogramm. Sie entwickeln ein Schulungsprogramm, das im großen Stil in einer Firma eingesetzt werden soll; mehrere Tausend Personen sollen das Programm durchlaufen. In einer Pilotstudie mit \\(n=90\\) Personen erreichen \\(k=42\\) nicht das Lernziel. Welche Parameterwerte für \\(p\\) (Lernziel erreicht) sind plausibel?\n\n\nCategories:\n\nprobability\nbinomial\nexample"
  },
  {
    "objectID": "posts/randomdag1/randomdag1.html",
    "href": "posts/randomdag1/randomdag1.html",
    "title": "randomdag1",
    "section": "",
    "text": "Gegeben sei der DAG g (s. u.). Der DAG verfügt über \\(n = 6\\) Variablen, die als Knoten im Graph dargestellt sind und mit \\(x_1, x_2, \\ldots x_n\\) bezeichnet sind.\nWelche minimale Variablenmenge muss kontrolliert werden, um den kausalen Effekt von der UV zur AV zu identifizieren?\nUV: x2.\nAV: x6.\nHinweise:\n\nMengen sind mittels geschweifter Klammern gekennzeichnet, z.B. {x1, x2} meint die Menge mit den zwei Elementen x1 und x2.\nDie leere Menge { } bedeutet, dass keine Variable kontrolliert werden muss, um den kausalen Effekt zu identifizieren.\nAlle Variablen werden als gemessen vorausgesetzt.\nEs ist möglich, dass es keine Lösung gibt, dass es also keine Adjustierungsmenge gibt, um den kausalen Effekt zu identifizieren. Wenn dies der Fall sein sollte, wählen Sie “/”.\nEs ist möglich, dass einzelne Variablen keine Kanten besitzen, also keine Verbindung zu anderen Variablen (Knoten) haben. Diese Variablen sind dann kausal unabhängig von den übrigen Variablen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ x1, x2 }\n{ x3, x6 }\n{ x1, x6 }\n{ x2, x3 }\n{ }"
  },
  {
    "objectID": "posts/randomdag1/randomdag1.html#answerlist-1",
    "href": "posts/randomdag1/randomdag1.html#answerlist-1",
    "title": "randomdag1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch\nFalsch\nFalsch\nFalsch\nRichtig\n\n\nCategories:\n\ncausal\ndag"
  },
  {
    "objectID": "posts/ReThink3e1-7/ReThink3e1-7.html",
    "href": "posts/ReThink3e1-7/ReThink3e1-7.html",
    "title": "ReThink3e1-7",
    "section": "",
    "text": "Solution\nEs finden sich auch Lösungsvorschläge online, z.B. hier\n\nWie viel Wahrscheinlichkeitsmasse liegt unter \\(p=0.2\\)?\n\n\nsamples %>% \n  count(p < 0.2)\n\n# A tibble: 2 × 2\n  `p < 0.2`     n\n  <lgl>     <int>\n1 FALSE      9993\n2 TRUE          7\n\n\nFast nix!\n\nWie viel Wahrscheinlichkeitsmasse liegt über \\(p=0.8\\)?\n\n\nsamples %>% \n  count(p > 0.8)\n\n# A tibble: 2 × 2\n  `p > 0.8`     n\n  <lgl>     <int>\n1 FALSE      8842\n2 TRUE       1158\n\n\nNaja, so gut 10%!\n\nWelcher Anteil der Posteriori-Verteilung liegt zwischen \\(p=0.2\\) und \\(p=0.8\\)?\n\n\nsamples %>% \n  count(p > 0.2 & p < 0.8) \n\n# A tibble: 2 × 2\n  `p > 0.2 & p < 0.8`     n\n  <lgl>               <int>\n1 FALSE                1165\n2 TRUE                 8835\n\n\nKnapp 90%!\n\nUnter welchem Wasseranteil \\(p\\) liegen 20% der Posteriori-Verteilung?\n\nEine Möglichkeit: Wir sortieren \\(p\\) der Größe nach (aufsteigend), filtern dann so, dass wir nur die ersten 20% der Zeilen behalten und schauen dann, was der größte Wert ist.\n\nsamples %>% \n  arrange(p) %>% \n  slice_head(prop = 0.2) %>% \n  summarise(quantil_20 = max(p))\n\n# A tibble: 1 × 1\n  quantil_20\n       <dbl>\n1      0.517\n\n\nAndererseits: Das, was wir gerade gemacht haben, nennt man auch ein Quantil berechnen, s. auch hier. Dafür gibt’s fertige Funktionen in R, wie quantile():\n\nsamples %>% \n  summarise(q_20 = quantile(p, 0.2))\n\n# A tibble: 1 × 1\n   q_20\n  <dbl>\n1 0.517\n\n\n\nÜber welchem Wasseranteil \\(p\\) liegen 10% der Posteriori-Verteilung?\n\n\nsamples %>% \n  summarise(quantile(p, 0.9))\n\n# A tibble: 1 × 1\n  `quantile(p, 0.9)`\n               <dbl>\n1              0.810\n\n\nMit 90% Wahrscheinlichkeit ist der Wasseranteil höchstns bei 81%.\n\nWelches schmälstes Intervall von \\(p\\) enthält 66% der Posteriori-Wahrscheinlichkeit?\n\n\nlibrary(easystats)\nhdi(samples, ci = 0.66)\n\nHighest Density Interval\n\nParameter |      66% HDI\n------------------------\np         | [0.52, 0.79]\n\n\n\nWelcher Wertebereich von \\(p\\) enthält 66% der Posteriori-Wahrscheinlichkeit (hier wird Posteriori-Wahrscheinlichkeit syonyom gebraucht zu Posteriori-Verteilung)?\n\nWir nutzen hier die Equal-Tail-Intervall (oder Perzentilintervall genannt), da die Aufgabe keine genauen Angaben macht.\n\neti(samples, ci = 0.66)\n\nEqual-Tailed Interval\n\nParameter |      66% ETI\n------------------------\np         | [0.50, 0.77]\n\n\nEin “mittleres” 2/3-Intervall lässt 1/3 der Wahrscheinlichkeitsmasse außen vor, und zwar gleichmäßig in zwei Hälften links und rechts, also jeweils 1/6 (17%). So ein Intervall heißt Perzentilintervall. Daher synonym:\n\nsamples %>% \n  summarise(PI_66 = quantile(p, prob = c(0.17, .84)))\n\n# A tibble: 2 × 1\n  PI_66\n  <dbl>\n1 0.501\n2 0.779\n\n\n\nCategories:\n\nbayes\nprobability\npost"
  },
  {
    "objectID": "posts/nasa02/nasa02.html",
    "href": "posts/nasa02/nasa02.html",
    "title": "nasa02",
    "section": "",
    "text": "Solution\nDekade berechnen:\n\nd <-\n  d %>% \n  mutate(decade = round(Year/10))\n\nKorrelation:\n\nd %>% \n  summarise(temp_cor = cor(Jan, Feb))\n\n# A tibble: 1 × 1\n  temp_cor\n     <dbl>\n1    0.939\n\n\nKorrelation pro Dekade:\n\nd_summarized <- \n  d %>% \n  group_by(decade) %>% \n  summarise(temp_cor = cor(Jan, Feb))\n\n\n\n\n\n\n\n  \n  \n    \n      decade\n      temp_cor\n    \n  \n  \n    188\n0.87\n    189\n0.79\n    190\n0.51\n    191\n0.84\n    192\n0.82\n    193\n0.72\n    194\n0.51\n    195\n0.78\n    196\n0.56\n    197\n0.79\n    198\n0.80\n    199\n0.53\n    200\n0.57\n    201\n0.66\n    202\n0.95\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Korrelation der Temperaturen und damit die Ähnlichkeit der Muster hat im Laufe der Dekaden immer mal wieder geschwankt.\n\nCategories:\n\ndata\neda"
  },
  {
    "objectID": "posts/Kung-height/Kung-height.html",
    "href": "posts/Kung-height/Kung-height.html",
    "title": "Kung-height",
    "section": "",
    "text": "Solution\n\nVisuelle Prüfung der Normalverteilung\n\n\nd2 <- d %>% \n  filter(age >= 18)\n\nd3 <- d2 %>% \n  select(-male)\n\nggplot(d2, aes(x = height)) +\n  geom_density()\n\nggplot(d2, aes(x = height )) +\n  facet_wrap(~ male) +\n    geom_density()\n\nggplot(d2, aes(x = height)) +\n  facet_wrap(~ male) +\n  geom_histogram(data = d3, fill = \"grey60\", alpha = .6) +\n    geom_histogram() +\n  labs(caption = \"Grau hinterlegt ist das Histogramm für die Daten über beide Geschlechter\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSchiefe und Kurtosis\n\n\nlibrary(easystats)\nd2 %>%  skewness()\n\nParameter | Skewness |    SE\n----------------------------\nheight    |    0.151 | 0.129\nweight    |    0.132 | 0.129\nage       |    0.665 | 0.129\nmale      |    0.126 | 0.129\n\nd2 %>% kurtosis()\n\nParameter | Kurtosis |    SE\n----------------------------\nheight    |   -0.483 | 0.256\nweight    |   -0.506 | 0.256\nage       |   -0.213 | 0.256\nmale      |   -1.996 | 0.256\n\n\n\nNormalverteilung, Begründung\n\nEs ist plausibel anzunehmen, dass der Phänotyp Körpergröße das Resultat des (kausalen) Einflusses vieler Gene ist, vieler Gene, die über einen vergleichbar starken Einfluss verfügen.\nEine besondere Situation stellt das X- bzw. Y-Chromosom dar, das Gene zum Geschlecht bereitstellt. Das Geschlecht ist ein einzelner Faktor, der (erfahrungsgemäß) einen relativ großen Einfluss auf die Körpergröße hat (in Anbetracht, dass vielleicht Tausende Gene additiv die Größe bestimmen). Insofern ist eine klarere Annäherung an die Normalverteilung zu erwarten, wenn man die Geschlechter einzeln betrachtet.\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/ReThink3m4/ReThink3m4.html",
    "href": "posts/ReThink3m4/ReThink3m4.html",
    "title": "ReThink3m4",
    "section": "",
    "text": "Solution\nErstellen wir zuerst wieder die Posteriori-Verteilung für den Globusversuch.\n\np_grid <- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior <- rep( 1 , 1000 )  # Priori-Gewichte\n\nset.seed(42)\nlikelihood <- dbinom( 6 , size=9 , prob=p_grid ) \n\nunstandardisierte_posterior <- likelihood * prior \n\nposterior <- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nDann ziehen wir unsere Stichproben daraus:\n\n# um die Zufallszahlen festzulegen, damit alle die gleichen Zufallswerte bekommen: \nset.seed(100) \n\n# Stichproben ziehen aus der Posteriori-Verteilung\nsamples <- \n  tibble(\n    p = sample( p_grid , prob=posterior, size=1e4, replace=TRUE)) \n\nJetzt erstellen wir die PPV für einen anderen Versuch, nämlich mit 9 Zügen:\n\nPPV <-\n  samples %>% \n  mutate(anzahl_wasser2 = rbinom(1e4, size = 9, prob = p))\n\nSchließlich zählen wir, wie oft 6 Treffer beobachtet werden:\n\nPPV %>% \n  count(anzahl_wasser2 == 6) \n\n# A tibble: 2 × 2\n  `anzahl_wasser2 == 6`     n\n  <lgl>                 <int>\n1 FALSE                  8059\n2 TRUE                   1941\n\n\nQuelle\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/Rethink_2m1/Rethink_2m1.html",
    "href": "posts/Rethink_2m1/Rethink_2m1.html",
    "title": "Rethink_2m1",
    "section": "",
    "text": "Solution\nThe solution is taken from this source.\n\nlibrary(tidyverse)\n\ndist <- \n  tibble(\n    # Gridwerte bestimmen:\n    p_grid = seq(from = 0, to = 1, length.out = 20),\n    # Priori-Wskt bestimmen:\n    prior = rep(1, times = 20)) %>%\n  mutate(\n    # Likelihood berechnen:\n    likelihood_1 = dbinom(3, size = 3, prob = p_grid),  # WWW\n    likelihood_2 = dbinom(3, size = 4, prob = p_grid),  # WWWL\n    likelihood_3 = dbinom(5, size = 7, prob = p_grid),  # LWWLWWW\n    # unstand. Posterior-Wskt:\n    unstand_post_1 = likelihood_1 * prior,\n    unstand_post_2 = likelihood_2 * prior,\n    unstand_post_3 = likelihood_3 * prior,\n    # stand. Post-Wskt:\n    std_post_1 = unstand_post_1 / sum(unstand_post_1),\n    std_post_2 = unstand_post_2 / sum(unstand_post_2),\n    std_post_3 = unstand_post_3 / sum(unstand_post_3)\n    ) \n\nJetzt können wir das Diagramm zeichnen:\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_1) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWW\")\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_2) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: WWWL\")\n\n\n\n\n\n\n\nggplot(dist) +\n  aes(x = p_grid, y= std_post_3) +\n  geom_line()+\n  geom_point() +\n  labs(x = \"p(W)\",\n       y = \"Posteriori-Wahrscheinlichkeit\",\n       title = \"Daten: LWWLWWW\")\n\n\n\n\n\n\n\n\nEtwas eleganter (und komplizierter) kann man es auch so in R schreiben (Quelle):\n\nlibrary(tidyverse)\n\ndist <- tibble(p_grid = seq(from = 0, to = 1, length.out = 20),\n               prior = rep(1, times = 20)) %>%\n  mutate(likelihood_1 = dbinom(3, size = 3, prob = p_grid),\n         likelihood_2 = dbinom(3, size = 4, prob = p_grid),\n         likelihood_3 = dbinom(5, size = 7, prob = p_grid),\n         across(starts_with(\"likelihood\"), ~ .x * prior),\n         across(starts_with(\"likelihood\"), ~ .x / sum(.x))) %>%\n  pivot_longer(cols = starts_with(\"likelihood\"), names_to = \"pattern\",\n               values_to = \"posterior\") %>%\n  separate(pattern, c(NA, \"pattern\"), sep = \"_\", convert = TRUE) %>%\n  mutate(obs = case_when(pattern == 1L ~ \"W, W, W\",\n                         pattern == 2L ~ \"W, W, W, L\",\n                         pattern == 3L ~ \"L, W, W, L, W, W, W\"))\n\nggplot(dist, aes(x = p_grid, y = posterior)) +\n  facet_wrap(vars(fct_inorder(obs)), nrow = 1) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\n\n\n\n\n\n\n\n\n\nCategories:\n\nprobability\nbayes-grid"
  },
  {
    "objectID": "posts/Rethink_2m6/Rethink_2m6.html",
    "href": "posts/Rethink_2m6/Rethink_2m6.html",
    "title": "Rethink_2m6",
    "section": "",
    "text": "Solution\nLet’s label the cards bb (black on both sides), bw (black on one, white on the other), and ww (both sides are white), respectively.\nWanted is the probability that the second side of the card is black (2b), given one side is black (1b): \\(Pr(2b|1b)\\).\n\nd <-\n  tibble::tribble(\n  ~Hyp, ~Prior,\n  \"bb\",     1L, \n  \"bw\",     2L,   \n  \"ww\",     3L, \n  ) %>% \n  mutate(Likelihood = c(2,1,0),\n         unstand_post = Prior*Likelihood,\n         std_post = unstand_post / sum(unstand_post))\n\nd %>% \n  gt() %>% \n  fmt_number(columns = 5)\n\n\n\n\n\n  \n  \n    \n      Hyp\n      Prior\n      Likelihood\n      unstand_post\n      std_post\n    \n  \n  \n    bb\n1\n2\n2\n0.50\n    bw\n2\n1\n2\n0.50\n    ww\n3\n0\n0\n0.00\n  \n  \n  \n\n\n\n\nWhenever the probability of all paths (in a tree diagram) is the same, we do not need to write down the probability of the path for the likelihood. It is enough to write the number of paths.\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/ReThink3m3/ReThink3m3.html",
    "href": "posts/ReThink3m3/ReThink3m3.html",
    "title": "ReThink3m3",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\n\n\n\nErstellen wir zuerst wieder die Posteriori-Verteilung für den Globusversuch.\n\np_grid <- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior <- rep(1, 1000 )  # Priori-Gewichte\n\nlikelihood <- dbinom(8 , size= 15, prob=p_grid ) \n\nunstandardisierte_posterior <- likelihood * prior \n\nposterior <- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\nDann ziehen wir unsere Stichproben daraus:\n\n# um die Zufallszahlen festzulegen, damit alle die gleichen Zufallswerte bekommen: \nset.seed(42) \n\n# Stichproben ziehen aus der Posteriori-Verteilung\nsamples <- \n  tibble(\n    p = sample(p_grid , prob=posterior, size=1e4, replace=TRUE))\n\n\nPPV <- \n  samples %>% \n  mutate( anzahl_wasser = rbinom(1e4, size = 15, prob = p))\n\nDurch prob = p gewichten wir die Wahrscheinlichkeit an den Werten der Posteriori-Verteilung.\nSo sehen die ersten paar Zeilen von PPV aus:\n\n\n\n\n\n\n  \n  \n    \n      p\n      anzahl_wasser\n    \n  \n  \n    0.4304304\n4\n    0.5575576\n11\n    0.6516517\n4\n    0.6156156\n9\n    0.6716717\n6\n  \n  \n  \n\n\n\n\n\n\n\n\nPPV %>% \n  ggplot() +\n  aes(x = anzahl_wasser) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nPPV %>% \n  count(anzahl_wasser == 8)\n\n# A tibble: 2 × 2\n  `anzahl_wasser == 8`     n\n  <lgl>                <int>\n1 FALSE                 8536\n2 TRUE                  1464\n\n\nAlternativer R-Code:\n\nw <- rbinom(1e4, size = 15, prob = samples$p)\nmean(w == 8)\n\n[1] 0.1504\n\n\nQuelle\n\nCategories:\n\nbayes\nppv\nprobability"
  },
  {
    "objectID": "posts/griech-buchstaben/griech-buchstaben.html",
    "href": "posts/griech-buchstaben/griech-buchstaben.html",
    "title": "Griech-Buchstaben-Inferenz",
    "section": "",
    "text": "Solution\n\n\n\n\n\nKennwert\nStatistik\nParameter\n\n\n\n\nMittelwert\n\\[\\bar{X}\\]\n\\[\\mu\\]\n\n\nMittelwertsdifferenz\n\\[d=\\bar{X}_1-\\bar{X}_2\\]\n\\[\\mu_1\\]- \\[\\mu_2\\]\n\n\nStreuung\nsd\n\\[\\sigma\\]\n\n\nAnteil\np\n\\[\\pi\\]\n\n\nKorrelation\nr\n\\[\\rho\\]\n\n\nRegressionsgewicht\nb\n\\[\\beta\\]\n\n\n\n\n\n\nCategories:\n\nqm2\nqm2-thema01"
  },
  {
    "objectID": "posts/mtcars-simple2/mtcars-simple2.html",
    "href": "posts/mtcars-simple2/mtcars-simple2.html",
    "title": "mtcars-simple2",
    "section": "",
    "text": "Solution\nCompute Model:\n\nlm1_freq <- lm(mpg ~ hp + cyl + disp, data = mtcars)\n\nlibrary(rstanarm)\nlm1_bayes <- stan_glm(mpg ~ hp + cyl + disp, data = mtcars, refresh = 0)\n\nGet R2:\n\nlibrary(easystats)\n\n\nr2(lm1_freq)\n\n# R2 for Linear Regression\n       R2: 0.768\n  adj. R2: 0.743\n\n\n\nr2(lm1_bayes)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.746 (95% CI [0.601, 0.859])\n\n\nThe coefficient is estimated as about 0.77.\n\nCategories:\n\nregresssion\nen\nbayes\nfrequentist\nqm1\nstats-nutshell"
  },
  {
    "objectID": "posts/Zwielichter-Dozent-Bayes/Zwielichter-Dozent-Bayes.html",
    "href": "posts/Zwielichter-Dozent-Bayes/Zwielichter-Dozent-Bayes.html",
    "title": "Zwielichter-Dozent-Bayes",
    "section": "",
    "text": "Exercise\nNach einem langen Unitag machen Sie sich auf den Weg nach Hause; ihr Weg führt Sie durch eine dunkle Ecke. Just dort regt sich auf einmal eine Gestalt in den Schatten. Die Person spricht Sie an: „Na, Lust auf ein Spielchen?“. Sie willigen sofort ein. Die Person stellt sich als ein Statistiker vor, dessen Namen nichts zur Sache tue; das Gesicht kommt Ihnen vage bekannt vor. „Pass auf“, erklärt der Statistiker, „wir werfen eine Münze, ich setze auf Zahl“. Dass er auf Zahl setzt, überrascht Sie nicht. „Wenn ich gewinne“, fährt der Statistiker fort, „bekomme ich 10 Euro von Dir, wenn Du gewinnst, bekommst Du 11 Euro von mir. Gutes Spiel, oder?“. Sie einigen sich auf 10 Durchgänge, in denen der Statistiker jedes Mal eine Münze wirft, fängt und dann die oben liegende Seite prüft. Erster Wurf: Zahl! Der Statistiker gewinnt. Pech für Sie. Zweiter Wurf: Zahl! Schon wieder 10 Euro für den Statistiker. Hm. Dritter Wurf: . . . Zahl! Schon wieder. Aber kann ja passieren, bei einer fairen Münze, oder? Vierter Wurf: Zahl! Langsam regen sich Zweifel bei Ihnen. Kann das noch mit rechten Dingen zugehen? Ist die Münze fair? Insgesamt gewinnt der zwielichte Statistiker 8 von 10 Durchgängen.\nUnter leisem Gelächter des Statistikers (und mit leeren Taschen) machen Sie sich von dannen. Hat er falsch gespielt? Wie plausibel ist es, bei 10 Würfen 8 Treffer zu erhalten, wenn die Münze fair ist? Ist das ein häufiges, ein typisches Ereignis oder ein seltenes, untypisches Ereignis bei einer fairen Münze? Wenn es ein einigermaßen häufiges Ereignis sein sollte, dann spricht das für die Fairness der Münze. Zumindest spricht ein Ereignis, welches von einer Hypothese als häufig vorausgesagt wird und schließlich eintritt, nicht gegen eine Hypothese. Zuhause angekommen, denken Sie sich, jetzt müssen Sie erstmal in Ruhe die Posteriori-Verteilung und die PPV ausrechnen!\n\nBerechnen Sie die Posteriori-Verteilung mit der Gittermethode! Gehen Sie von einer gleichverteilten Priori-Wahrscheinlichkeit aus. Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\nWie groß ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die Münze zugunsten des Dozenten gezinkt ist?\nGeben Sie das 50%-PI und 50%-HDPI zum Parameterwert (\\(p\\) der Münze) an!\nMit welcher Wahrscheinlichkeit liegt die Trefferchance der Münze zwischen \\(p=.45\\) und \\(p=.55\\), ist also nicht “nennenswert” gezinkt?\nWas ist der wahrscheinlichste Parameterwert (Trefferchance der Münze)?\nGeben Sie das 90%-PI und 90%-HDI zu Parameterwert (\\(p\\) der Münze) an!\nBerechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\nDiskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von \\(p\\)!\n\n         \n\n\nSolution\n\nBerechnen Sie die Posteriori-Verteilung mit der Gittermethode! Visualisieren Sie sie. Alle folgenden Teil-Fragen bauen auf der Post-Verteilung auf.\n\n\np_grid <- seq( from=0 , to=1 , length.out=1000 )  # Gitterwerte\n\nprior <- rep( 1 , 1000 )  # Priori-Gewichte\n\nlikelihood <- dbinom(8, size = 10, prob=p_grid) \n\nunstandardisierte_posterior <- likelihood * prior \n\nposterior <- unstandardisierte_posterior / sum(unstandardisierte_posterior)\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples <- \n  tibble(\n    gewinnchance_muenze = sample(p_grid , prob=posterior, size=1e4, replace=TRUE))\n\nVisualisierung:\n\nsamples %>% \n  ggplot() +\n  aes(x = gewinnchance_muenze) +\n  geom_histogram() +\n  labs(title = \"Posterior-Verteilung\",\n       x = \"Gewinnchance der Münze (50%: faire Münze)\")\n\n\n\n\n\n\n\n\n\nWie groß ist die Wahrscheinlichkeit, auf Basis der Post-Verteilung, dass die Münze zugunsten des Dozenten gezinkt ist?\n\n\nsamples %>% \n  count(gewinnchance_muenze > .5) %>% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  `gewinnchance_muenze > 0.5`     n   prop\n  <lgl>                       <int>  <dbl>\n1 FALSE                         322 0.0322\n2 TRUE                         9678 0.968 \n\n\n\nGeben Sie das 50%-PI (Perzentilintervall) und 50%-HDI zum Parameterwert (\\(p\\) der Münze) an!\n\n\nlibrary(easystats)\neti(samples, ci = .5)\n\nEqual-Tailed Interval\n\nParameter           |      50% ETI\n----------------------------------\ngewinnchance_muenze | [0.67, 0.84]\n\nhdi(samples, ci = .5)\n\nHighest Density Interval\n\nParameter           |      50% HDI\n----------------------------------\ngewinnchance_muenze | [0.72, 0.88]\n\n\nEin PI wird auch equal tail interval genannt, weil die beiden “abgeschnitten Randbereiche” links und rechts die gleichen Flächenanteil (Wahrscheinlichkeitsmasse) aufweisen.\nInteresant ist, dass das PI und das HDI zu unterschiedlichen Ergebnissen kommen. Das lässt auf eine schiefe Verteilung schließen. Außerdem eröffnet es den Raum zur Diskussion, welches Intervall man berichtet. Um diese Frage besser zu verstehen, können wir die Intervalle visualisieren.\nBonus: Visualisieren wir die Intervalle:\nPI:\n\neti(samples, ci = .5) %>% plot()\n\n\n\n\n\n\n\n\nHDI:\n\nhdi(samples, ci = .5) %>% plot()\n\n\n\n\n\n\n\n\nDas HDI ist schmäler und liegt näher am Modus. Vermutlich ist das HDI zu bevorzugen.\n\nMit welcher Wahrscheinlichkeit liegt die Trefferchance der Münze zwischen \\(p=.45\\) und \\(p=.55\\), ist also nicht “nennenswert” gezinkt (auf Basis unserer Modellannahmen)?\n\n\nsamples %>% \n  count(gewinnchance_muenze >= 0.45 & gewinnchance_muenze <= .55) %>% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 × 3\n  `gewinnchance_muenze >= 0.45 & gewinnchance_muenze <= 0.55`     n   prop\n  <lgl>                                                       <int>  <dbl>\n1 FALSE                                                        9534 0.953 \n2 TRUE                                                          466 0.0466\n\n\nDie Wahrscheinlichkeit, dass die Münze nicht nennenswert gezinkt ist (nach unserer Definition), ist gering. Man sollte vielleicht erwähnen, dass unsere Definition von “nicht nennenswert gezinkt” plausibel ist, und andere (vernünftige) Definitionen zu einem sehr ähnlichen Ergebnis kämen.\n\nWas ist der wahrscheinlichste Parameterwert (Trefferchance der Münze)?\n\n\nsamples %>% \n   map_estimate()\n\nMAP Estimate\n\nParameter           | MAP_Estimate\n----------------------------------\ngewinnchance_muenze |         0.78\n\n\nmap_estimate steht für …\n\nFind the Highest Maximum A Posteriori probability estimate (MAP) of a posterior, i.e., the value associated with the highest probability density (the “peak” of the posterior distribution). In other words, it is an estimation of the mode for continuous parameters.\n\n(aus der Hilfeseite der Funktion)\n\nGeben Sie das 90%-PI und 90%-HDI zum Parameterwert (\\(p\\) der Münze) an!\n\n\nlibrary(easystats)\neti(samples, ci = .9)\n\nEqual-Tailed Interval\n\nParameter           |      90% ETI\n----------------------------------\ngewinnchance_muenze | [0.53, 0.92]\n\nhdi(samples, ci = .9)\n\nHighest Density Interval\n\nParameter           |      90% HDI\n----------------------------------\ngewinnchance_muenze | [0.56, 0.94]\n\n\n\nBerechnen Sie die PPV! Visualisieren Sie sie. Interpretieren Sie die PPV.\n\n\nPPV <-\n  samples %>% \n  mutate(anzahl_kopf = rbinom(n = 1e4, size = 10, prob = gewinnchance_muenze))\n\nVisualisierung:\n\nPPV %>% \n  ggplot() +\n  aes(x = anzahl_kopf) +\n  labs(title = \"PPV\") +\n  geom_bar()  # geom_bar() ginge auch, sieht aber bei wenig Balken nicht so gut aus.\n\n\n\n\n\n\n\n\nLaut der PPV sind 8 von 10 Treffern der Wert, der mit der höchsten Wahrscheinlichkeit zu beobachten sein wird. Allerdings sind 7 oder 9 Treffer fast genauso wahrscheinlich. Etwas genauer:\n\nPPV %>% \n  count(between(anzahl_kopf, 7,9))   # \"zähle mir, wie oft ein Wert ZWISCHEN (between) 7 und 9 vorkommt\"\n\n# A tibble: 2 × 2\n  `between(anzahl_kopf, 7, 9)`     n\n  <lgl>                        <int>\n1 FALSE                         3815\n2 TRUE                          6185\n\n\nMit dieser Wahrscheinlichkeit ist ein Wert zwischen 7 und 9 zu beobachten, wenn man den Versuch wiederholt, laut dem Modell.\n\nPPV %>% \n  eti(anzahl_kopf, ci = .9)\n\nEqual-Tailed Interval\n\nParameter           |       90% ETI\n-----------------------------------\ngewinnchance_muenze | [0.53,  0.92]\nanzahl_kopf         | [4.00, 10.00]\n\n\nUnser Modell sieht einen “Passungsbereich” (ein Perzentilintervall) von 4 bis 10 Treffern als mit 90% Wahrscheinlichkeit passend an.\n\nDiskutieren Sie die Annahme einer Gleichverteilung des Priori-Wertes von \\(p\\)!\n\nZwar hat eine Gleichverteilung der Priori-Werte den Vorteil, dass sie “objektiv” ist in dem Sinne, dass kein Wert “bevorteilt” wird; alle gelten als gleich wahrscheinlich. Aber das ist hochgradig unplausibel: So ist z.B. der Wert \\(p=1\\) logisch unmöglich, da wir nicht nur Treffer beobachtet haben. Ein Wert von z.B. \\(p=0.999\\) erscheint uns ebenfalls sehr unwahrscheinlich. Nützlicher erscheint daher vielleicht doch eine Priori-Verteilung, die extreme Werte von \\(p\\) als unwahrscheinlich bemisst.\n\nCategories:\n\nbayes\nprobability\nppv"
  },
  {
    "objectID": "posts/purrr-map05/purrr-map05.html",
    "href": "posts/purrr-map05/purrr-map05.html",
    "title": "purrr-map05",
    "section": "",
    "text": "Exercise\nErstellen Sie eine Tabelle mit mit folgenden Spalten:\n\nID-Spalte: \\(1,2,..., 10\\)\nEine Spalte, in der jede Zelle eine Tabelle mit einem Vektor \\(x\\), einer standardnormalverteilten Zufallszahlen (n=1000), enthält\n\nBerechnen Sie den Mittelwert von jedem \\(x\\)! Diese Ergebnisse sollen als weitere Spalte der Tabelle hinzugefügt werden.\n         \n\n\nSolution\n\nd <- tibble(\n  id = 1:10) %>% \n  mutate(x = map(id, ~ rnorm(n = 1e3))\n) \n\nstr(d)\n\ntibble [10 × 2] (S3: tbl_df/tbl/data.frame)\n $ id: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ x :List of 10\n  ..$ : num [1:1000] 0.454 -0.379 0.838 0.576 -0.452 ...\n  ..$ : num [1:1000] 0.0403 0.0899 -1.9857 -1.6792 -0.3218 ...\n  ..$ : num [1:1000] 0.5553 0.1963 -0.4612 -0.0934 1.2162 ...\n  ..$ : num [1:1000] -0.5209 -0.2741 -0.4908 -0.1389 -0.0498 ...\n  ..$ : num [1:1000] -0.0841 0.5579 1.8881 -0.0544 1.0364 ...\n  ..$ : num [1:1000] -0.85 -1.036 -0.307 0.109 -1.692 ...\n  ..$ : num [1:1000] 0.349 -0.724 2.254 -1.578 -1.254 ...\n  ..$ : num [1:1000] -0.335 -0.351 0.173 0.47 0.954 ...\n  ..$ : num [1:1000] -1.42 0.981 -0.541 -1.375 0.274 ...\n  ..$ : num [1:1000] -0.411 0.388 -1.259 -1.037 1.545 ...\n\n\nSo kann man sich die Mittelwerte ausgeben lassen:\n\nd$x %>% \n  map(mean)\n\n[[1]]\n[1] -0.03530719\n\n[[2]]\n[1] -0.010507\n\n[[3]]\n[1] 0.02497519\n\n[[4]]\n[1] 0.04412629\n\n[[5]]\n[1] -0.04437515\n\n[[6]]\n[1] -0.01892384\n\n[[7]]\n[1] 0.006194343\n\n[[8]]\n[1] 0.007741509\n\n[[9]]\n[1] 0.0105266\n\n[[10]]\n[1] 0.0165064\n\n\nJetzt fügen wir den letzten Schritt als Spalte hinzu:\n\nd2 <-\n  d %>% \n  mutate(x_mean = map_dbl(x, ~ mean(.x))) \n\nhead(d2)\n\n# A tibble: 6 × 3\n     id x              x_mean\n  <int> <list>          <dbl>\n1     1 <dbl [1,000]> -0.0353\n2     2 <dbl [1,000]> -0.0105\n3     3 <dbl [1,000]>  0.0250\n4     4 <dbl [1,000]>  0.0441\n5     5 <dbl [1,000]> -0.0444\n6     6 <dbl [1,000]> -0.0189\n\n\nHier hätten wir auch schreiben können:\n\nd %>% \n  mutate(x_mean = map(x, mean)) %>% \n  unnest(x_mean) %>% \n  head()\n\n# A tibble: 6 × 3\n     id x              x_mean\n  <int> <list>          <dbl>\n1     1 <dbl [1,000]> -0.0353\n2     2 <dbl [1,000]> -0.0105\n3     3 <dbl [1,000]>  0.0250\n4     4 <dbl [1,000]>  0.0441\n5     5 <dbl [1,000]> -0.0444\n6     6 <dbl [1,000]> -0.0189\n\n\n\nCategories:\n\nprogramming\nloop"
  },
  {
    "objectID": "posts/purrr-map02/purrr-map02.html",
    "href": "posts/purrr-map02/purrr-map02.html",
    "title": "purrr-map02",
    "section": "",
    "text": "Exercise\nBestimmen Sie die häufigsten Worte im Grundatzprogramm der Partei AfD (in der aktuellsten Version).\n         \n\n\nSolution\nText aus PDF-Dateien kann man mit dem Paket pdftools einlesen:\n\nlibrary(pdftools)\n\nUsing poppler version 22.02.0\n\nd_path <- \"/Users/sebastiansaueruser/Google Drive/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf\"\n\nd <- tibble(text = pdf_text(d_path))\n\nDann erstellen wir eine Tidy-Version und tokenisieren nach Wörtern:\n\nlibrary(tidytext)\nd2 <-\n  d %>% \n  unnest_tokens(output = word, input = text)\n\nhead(d2)\n\n# A tibble: 6 × 1\n  word             \n  <chr>            \n1 programm         \n2 für              \n3 deutschland      \n4 das              \n5 grundsatzprogramm\n6 der              \n\n\nDann zählen wir die Wörter:\n\nd2 %>% \n  count(word, sort = TRUE) %>% \n  head(20)\n\n# A tibble: 20 × 2\n   word            n\n   <chr>       <int>\n 1 die          1151\n 2 und          1147\n 3 der           870\n 4 zu            435\n 5 für           392\n 6 in            392\n 7 den           271\n 8 von           257\n 9 ist           251\n10 das           225\n11 werden        214\n12 eine          211\n13 nicht         196\n14 ein           191\n15 deutschland   190\n16 sind          187\n17 wir           176\n18 afd           171\n19 des           169\n20 sich          158\n\n\n\nCategories:\n\nr\nmap\ntidyverse"
  },
  {
    "objectID": "posts/twitter03/twitter03.html",
    "href": "posts/twitter03/twitter03.html",
    "title": "twitter03",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rtweet)\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nDann anmelden:\n\nauth <- rtweet_app(bearer_token = Bearer_Token)\n\nTweets an Karl Lauterbach suchen:\n\nkarl1 <- search_tweets(\"@karl_lauterbach min_faves:100 OR min_retweets:100\", n = 10)\n\n\nkarl1 %>% \n  select(retweet_count, favorite_count)\n\n# A tibble: 10 × 2\n   retweet_count favorite_count\n           <int>          <int>\n 1            56            210\n 2            56            229\n 3            44           1626\n 4            60            225\n 5            30            494\n 6             5            148\n 7            27            435\n 8            12            178\n 9            13            162\n10            46            375\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/twitter04/twitter04.html",
    "href": "posts/twitter04/twitter04.html",
    "title": "twitter04",
    "section": "",
    "text": "Solution\n\nlibrary(rtweet)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\n\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n\nLoading required package: SnowballC\n\nlibrary(SnowballC)  # Stemming\n\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\n\nauth <- rtweet_app(bearer_token = Bearer_Token)\n\n\nkarl1 <- search_tweets(\"@karl_lauterbach\", n = 1e2, include_rts = FALSE)\n#write_rds(karl1, file = \"karl1.rds\", compress = \"gz\")\n\n\n\n\n\nkarl2 <- \n  karl1 %>% \n  select(full_text)\n\n\nkarl3 <- \n  karl2 %>% \n  unnest_tokens(output = word, input = full_text)\n\n\nkarl4 <- \nkarl3 %>% \n  anti_join(tibble(word = lsa::stopwords_de)) \n\nJoining, by = \"word\"\n\n\n\nkarl5 <- \n  karl4 %>% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %>% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %>% \n  mutate(word = str_replace_na(word, \" +\")) %>% \n  drop_na()\n\n\nkarl6 <-\n  karl5 %>% \n  mutate(word = wordStem(word))\n\n\nkarl6 %>% \n  count(word, sort = TRUE) %>% \n  slice_head(n=10)\n\n# A tibble: 10 × 2\n   word                       n\n   <chr>                  <int>\n 1 karl_lauterbach          100\n 2 rt                        60\n 3 ultrakaerl                19\n 4 corona                    16\n 5 wirwollenmaskenpflicht    16\n 6 länder                    12\n 7 gesundheitsminist         11\n 8 polarstern64              11\n 9 schon                     11\n10 shomburg                  11\n\n\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/mtcars-simple3/mtcars-simple3.html",
    "href": "posts/mtcars-simple3/mtcars-simple3.html",
    "title": "mtcars-simple3",
    "section": "",
    "text": "We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nWhich of the predictors in the above model has the weakest causal impact on the output variable?\nNotes:\n\nUse can either use frequentist or bayesian modeling.\nUse R for all computations.\nThere are multiple ways to find a solution.\n\n\n\n\ncyl\nhp\ndisp\nAll are equally strong\nnone of the above"
  },
  {
    "objectID": "posts/mtcars-simple3/mtcars-simple3.html#answerlist-1",
    "href": "posts/mtcars-simple3/mtcars-simple3.html#answerlist-1",
    "title": "mtcars-simple3",
    "section": "Answerlist",
    "text": "Answerlist\n\nwrong\ncorrect\nwrong\nwrong\nwrong\n\n\nCategories:\n\nregresssion\nen\nbayes\nfrequentist\nqm1\nstats-nutshell"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html",
    "href": "posts/ttest-als-regr/ttest-als-regr.html",
    "title": "ttest-als-regr",
    "section": "",
    "text": "Der t-Test kann als Spezialfall der Regressionsanalyse gedeutet werden.\nHierbei ist es wichtig, sich das Skalenniveau der Variablen, die ein t-Test verarbeitet, vor Augen zu führen.\nHinweisse:\n\nDie folgende Abbildung gibt Tipps.\nInformationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenennen Sie die Skalenniveaus der UV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nBenennen Sie die Skalenniveaus der AV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression).\nNennen Sie eine beispielhafte Forschungsfrage für einen t-Test.\nSkizzieren Sie ein Diagramm einer Regression, die analytisch identisch (oder sehr ähnlich) zu einem t-Test ist!"
  },
  {
    "objectID": "posts/ttest-als-regr/ttest-als-regr.html#answerlist-1",
    "href": "posts/ttest-als-regr/ttest-als-regr.html#answerlist-1",
    "title": "ttest-als-regr",
    "section": "Answerlist",
    "text": "Answerlist\n\nUV: binär\nAV: metrisch\nUnterscheiden sich die mittleren Einparkzeiten von Frauen und Männern?\nAus dem Datensatz mtcars:\n\n\ndata(mtcars)\nmtcars %>% \n  ggplot() +\n  aes(x = am, y = mpg) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nCategories:\n\nregr\nttest\nvariable-levels"
  },
  {
    "objectID": "posts/log-y-regr1/log-y-regr1.html",
    "href": "posts/log-y-regr1/log-y-regr1.html",
    "title": "log-y-regr1",
    "section": "",
    "text": "Solution\n\nd2 <-\n  d %>% \n  filter(re74 > 0) %>% \n  mutate(re74_log = log(re74))\n\n\nm <- lm(re74_log ~ educ, data = d2)\n\nHier sind die parameters des Modells.\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(2327)\np\n\n\n\n\n(Intercept)\n8.83\n0.06\n(8.70, 8.95)\n142.91\n< .001\n\n\neduc\n0.07\n4.94e-03\n(0.07, 0.08)\n15.16\n< .001\n\n\n\n\nFür jedes Jahr Bildung steigt das Einkommen also ca. um den Faktor 1.07.\nEtwas genauer:\n\\(\\hat{\\beta_1} = 0.07\\) bedeutet, dass ein Jahr Bildung zu einen erwarteten Unterschied im Einkommen in Höhe von 0.07 in Log-Einkommen führt. Anders gesagt wird das Einkommen um exp(0.07) erhöht. Dabei gilt \\(e^{0.07} \\approx 1.07\\):\n\nexp(0.07)\n\n[1] 1.072508\n\n\nDie Lösung lautet also: “Pro Jahr Bildung steigt das Einkommen - laut Modell um den Faktor ca. 1.07”.\nMan darf dabei nicht vergessen, dass wir wir uns hier auf die Schnelle ein Modell ausgedacht haben. Ob es in Wirklichkeit so ist, wie unser Modell meint, ist eine andere Sache!\n\nCategories:\n\nregression\nlm\nqm2\nstats-nutshell"
  },
  {
    "objectID": "posts/subjektiv-Bayes/subjektiv-Bayes.html",
    "href": "posts/subjektiv-Bayes/subjektiv-Bayes.html",
    "title": "subjektiv-Bayes",
    "section": "",
    "text": "Solution\n\nLinearitätsannahme in (linearen) Modellen\nWahl des Likelihoods\nWahl der Daten\nMethoden der Modellprüfung\nGeneralisierung des Modells auf andere Situationen\nWahl der Prädiktoren\n\n\nCategories:\n~"
  },
  {
    "objectID": "posts/adjustieren2/adjustieren2.html",
    "href": "posts/adjustieren2/adjustieren2.html",
    "title": "adjustieren2",
    "section": "",
    "text": "Solution\n\n\n\n\nUnser Modell lm1 schätzt den Preis eines Diamanten mittlerer Größe auf etwa 3932.5 (was immer auch die Einheiten sind, Dollar vermutlich).\nprice ~ carat_z + cut\n\nDieses zweite Modell könnten wir so berechnen:\n\nlm2 <- stan_glm(price ~ carat_z + cut, data = diamonds,\n                chains = 1,\n                refresh = 0)\nparameters(lm2)\n\nParameter    |  Median |             95% CI |   pd |  Rhat |     ESS |                       Prior\n--------------------------------------------------------------------------------------------------\n(Intercept)  | 2406.07 | [2334.35, 2488.89] | 100% | 1.000 |  321.00 | Normal (3932.80 +- 9973.60)\ncarat_z      | 7870.55 | [7843.93, 7897.58] | 100% | 1.005 | 1047.00 |   Normal (0.00 +- 21040.85)\ncutGood      | 1118.79 | [1027.17, 1203.09] | 100% | 0.999 |  434.00 |   Normal (0.00 +- 34685.38)\ncutIdeal     | 1799.71 | [1714.31, 1869.75] | 100% | 0.999 |  338.00 |   Normal (0.00 +- 20362.28)\ncutPremium   | 1437.68 | [1353.65, 1512.30] | 100% | 0.999 |  351.00 |   Normal (0.00 +- 22862.49)\ncutVery Good | 1508.84 | [1422.69, 1582.24] | 100% | 1.000 |  344.00 |   Normal (0.00 +- 23922.15)\n\n\nEin “normales” (frequentistisches) lm käme zu ähnlichen Ergebnissen:\n\nlm(price ~ carat_z + cut, data = diamonds)\n\n\nCall:\nlm(formula = price ~ carat_z + cut, data = diamonds)\n\nCoefficients:\n (Intercept)       carat_z       cutGood      cutIdeal    cutPremium  \n        2405          7871          1120          1801          1439  \ncutVery Good  \n        1510  \n\n\nMan könnte hier noch einen Interaktionseffekt ergänzen, wenn man Grund zur Annahme hat, dass es einen gibt.\n\nCategories:\n\nregression\nlm\nqm2\nbayes\nadjust"
  },
  {
    "objectID": "posts/Griech-Buchstaben-Inferenz/Griech-Buchstaben-Inferenz.html",
    "href": "posts/Griech-Buchstaben-Inferenz/Griech-Buchstaben-Inferenz.html",
    "title": "Griech-Buchstaben-Inferenz",
    "section": "",
    "text": "Solution\n\n\n\n\n\nKennwert\nStatistik\nParameter\n\n\n\n\nMittelwert\n\\[\\bar{X}\\]\n\\[\\mu\\]\n\n\nMittelwertsdifferenz\n\\[d=\\bar{X}_1-\\bar{X}_2\\]\n\\[\\mu_1\\]- \\[\\mu_2\\]\n\n\nStreuung\nsd\n\\[\\sigma\\]\n\n\nAnteil\np\n\\[\\pi\\]\n\n\nKorrelation\nr\n\\[\\rho\\]\n\n\nRegressionsgewicht\nb\n\\[\\beta\\]\n\n\n\n\n\n\nCategories:\n\nqm2\ninference\nparameters"
  },
  {
    "objectID": "posts/twitter05/twitter05.html",
    "href": "posts/twitter05/twitter05.html",
    "title": "twitter05",
    "section": "",
    "text": "Solution\nNutzen Sie die Daten der letzten Aufgabe, um eine Sentimentanalyse zu erstellen.\nZuerst muss man sich anmelden und die Tweets herunterladen; dieser Teil ist hier nicht aufgeführt (s. andere Aufgaben).\n\nlibrary(rtweet)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\n\nlibrary(tidytext)\nlibrary(lsa)  # Stopwörter\n\nLoading required package: SnowballC\n\nlibrary(SnowballC)  # Stemming\n\n\n\n\nBeachten Sie, dass die Spalten je nach Funktion, die Sie zum Herunterladen der Tweets verwenden, unterschiedlich heißen können.\n\nkarl2 <- \n  karl1 %>% \n  select(contains(\"text\"))\n\n\nkarl3 <- \n  karl2 %>% \n  unnest_tokens(output = word, input = text)\n\n\nkarl4 <- \nkarl3 %>% \n  anti_join(tibble(word = lsa::stopwords_de)) \n\nJoining, by = \"word\"\n\n\n\nkarl5 <- \n  karl4 %>% \n  mutate(word = str_replace_na(word, \"^[:digit:]+$\")) %>% \n  mutate(word = str_replace_na(word, \"hptts?://\\\\w+\")) %>% \n  mutate(word = str_replace_na(word, \" +\")) %>% \n  drop_na()\n\n\ndata(sentiws, package = \"pradadata\")\n\n\nkarl7 <-\n  karl5 %>% \n  inner_join(sentiws)\n\nJoining, by = \"word\"\n\n\n\nkarl7 %>% \n  group_by(neg_pos) %>% \n  summarise(senti_avg = mean(value, na.rm = TRUE),\n            senti_sd = sd(value, na.rm = TRUE),\n            senti_n = n())\n\n# A tibble: 2 × 4\n  neg_pos senti_avg senti_sd senti_n\n  <chr>       <dbl>    <dbl>   <int>\n1 neg        -0.347    0.186       2\n2 pos         0.167    0.283       3\n\n\nAchtung, Sentimentanalyse sollte vor dem Stemming kommen.\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/twitter02/twitter02.html",
    "href": "posts/twitter02/twitter02.html",
    "title": "twitter02",
    "section": "",
    "text": "Solution\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rtweet)\n\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\nEinloggen bei Twitter; zuerst die Credentials bereithalten:\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\n\nauth <- rtweet_app(bearer_token = Bearer_Token)\n\nAus der Hilfe zu search_tweets:\nDescription\nReturns Twitter statuses matching a user provided search query. ONLY RETURNS DATA FROM THE PAST 6-9 DAYS.\nTweets an Karl Lauterbach suchen:\n\nkarl_tweets <- search_tweets(q = \"@karl_lauterbach\", n = 150000, retryonratelimit = TRUE)\n\nWir könnten n auch auf Inf setzen, aber, da wir auf das Refreshen des Rate Limits warten müssen, könnte sehr lange dauern. Daher nehmen wir hier nur einen kürzeren Wert.\n\ndim(karl_tweets)\n\n[1] 18000    43\n\nhead(karl_tweets)\n\n# A tibble: 6 × 43\n  created_at               id id_str      full_…¹ trunc…² displ…³ entities     metad…⁴\n  <dttm>                <dbl> <chr>       <chr>   <lgl>     <dbl> <list>       <list> \n1 2022-10-23 13:30:18 1.58e18 1584145185… \"Bei ⁦@… FALSE       122 <named list> <df>   \n2 2022-10-22 18:34:37 1.58e18 1583859379… \"Es is… FALSE       263 <named list> <df>   \n3 2022-10-22 17:56:39 1.58e18 1583849826… \"Die S… FALSE       215 <named list> <df>   \n4 2022-10-24 08:10:35 1.58e18 1584427113… \"Zu we… FALSE       219 <named list> <df>   \n5 2022-10-24 08:10:35 1.58e18 1584427113… \"RT @K… FALSE       140 <named list> <df>   \n6 2022-10-24 08:10:25 1.58e18 1584427072… \"RT @U… FALSE       139 <named list> <df>   \n# … with 35 more variables: source <chr>, in_reply_to_status_id <dbl>,\n#   in_reply_to_status_id_str <chr>, in_reply_to_user_id <dbl>,\n#   in_reply_to_user_id_str <chr>, in_reply_to_screen_name <chr>, geo <list>,\n#   coordinates <list>, place <list>, contributors <lgl>, is_quote_status <lgl>,\n#   retweet_count <int>, favorite_count <int>, favorited <lgl>, retweeted <lgl>,\n#   possibly_sensitive <lgl>, lang <chr>, quoted_status_id <dbl>,\n#   quoted_status_id_str <chr>, quoted_status <list>, retweeted_status <list>, …\n# ℹ Use `colnames()` to see all variable names\n\nCategories:\n\ntextmining\ntwitter"
  },
  {
    "objectID": "posts/ReThink4e1/ReThink4e1.html",
    "href": "posts/ReThink4e1/ReThink4e1.html",
    "title": "ReThink4e1",
    "section": "",
    "text": "Welche der folgenden Zeilen zeigt den Likelihood?\n\n\n\n\\(\\mu \\sim \\mathcal{N}(0, 10)\\)\n\\(\\sigma \\sim \\mathcal{U}(0, 1)\\)\n\\(y_i = \\beta_0 + \\beta_1\\cdot x\\)\n\\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\n\nQuelle: McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press."
  },
  {
    "objectID": "posts/ReThink4e1/ReThink4e1.html#answerlist-1",
    "href": "posts/ReThink4e1/ReThink4e1.html#answerlist-1",
    "title": "ReThink4e1",
    "section": "Answerlist",
    "text": "Answerlist\n\nFalsch. Priori-Verteilung.\nFalsch. Priori-Verteilung.\nFalsch. Regressionsformel.\nWahr. Likelihood.\n\nMan könnte den Likelihood auch so schreiben:\n$y_i| , (, ) $,\nwas noch deutlicher macht, dass die Likelihood die Wahrscheinlichkeit der Daten (y) ausdrückt, gegeben der Modellparameter (\\(\\mu, \\sigma)\\).\n\nCategories:\n\nprobability\nbayes"
  },
  {
    "objectID": "posts/purrr-map03/purrr-map03.html",
    "href": "posts/purrr-map03/purrr-map03.html",
    "title": "purrr-map03",
    "section": "",
    "text": "Exercise\nImportieren Sie das Grundatzprogramm der Partei AfD (in der aktuellsten Version). Tokenisieren Sie nach Sätzen. Dann entfernen Sie alle Zahlen. Dann zählen Sie die Anzahl der Wörter pro Satz und berichten gängige deskriptive Statistiken dazu.\n         \n\n\nSolution\nText aus PDF-Dateien kann man mit dem Paket pdftools einlesen:\n\nlibrary(pdftools)\n\nUsing poppler version 22.02.0\n\nd_path <- \"/Users/sebastiansaueruser/Google Drive/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf\"\n\nd <- tibble(text = pdf_text(d_path))\n\nDann erstellen wir eine Tidy-Version und tokenisieren nach Sätzen:\n\nlibrary(tidytext)\nd2 <-\n  d %>% \n  unnest_sentences(output = word, input = text)\n\nhead(d2)\n\n# A tibble: 6 × 1\n  word                                                                          \n  <chr>                                                                         \n1 programm für deutschland.                                                     \n2 das grundsatzprogramm der alternative für deutschland.                        \n3 2   programm für deutschland | inhalt         präambel                       …\n4 familien stärken        43             und parteiferne rechnungshöfe         …\n5 3   programm für deutschland | inhalt         7 | kultur, sprache und identit…\n6 förder- und                         10.10.3 deutsche literatur im inland digi…\n\n\nDann entfernen wir die Zahlen:\n\nd3 <- \n  d2 %>% \n  mutate(word = str_remove_all(word, pattern = \"[:digit:]+\"))\n\nPrüfen wir, ob es geklappt hat:\n\nd2$word[10]\n\n[1] \"weniger subventionen    88      13.7 fischerei, forst und jagd: im einklang mit der natur     88      13.8 flächenkonkurrenz:           nicht zu lasten der land- und forstwirtschaft            88\"\n\nd3$word[10]\n\n[1] \"weniger subventionen          . fischerei, forst und jagd: im einklang mit der natur           . flächenkonkurrenz:           nicht zu lasten der land- und forstwirtschaft            \"\n\n\nOk.\nDann zählen wir die Wörter pro Satz:\n\nd4 <- \n  d3 %>% \n  summarise(word_count_per_sentence = str_count(word, \"\\\\w+\"))\n\nhead(d4)\n\n# A tibble: 6 × 1\n  word_count_per_sentence\n                    <int>\n1                       3\n2                       6\n3                     196\n4                      40\n5                     254\n6                      15\n\n\nVisualisierung:\n\nd4 %>% \n  ggplot(aes(x = word_count_per_sentence)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.5.2 (red = needs update)\n✖ insight     0.18.5   ✖ datawizard  0.6.2 \n✔ bayestestR  0.13.0   ✔ performance 0.10.0\n✔ parameters  0.19.0   ✖ effectsize  0.8.1 \n✔ modelbased  0.8.5    ✔ correlation 0.8.3 \n✔ see         0.7.3    ✔ report      0.5.5 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\ndescribe_distribution(d4)\n\nVariable                |  Mean |    SD | IQR |          Range | Skewness | Kurtosis |    n | n_Missing\n-------------------------------------------------------------------------------------------------------\nword_count_per_sentence | 21.86 | 17.24 |  19 | [0.00, 254.00] |     3.84 |    37.52 | 1208 |         0\n\n\n\nCategories:\n\nr\nmap\ntidyverse"
  },
  {
    "objectID": "posts/purrr-map04/purrr-map04.html",
    "href": "posts/purrr-map04/purrr-map04.html",
    "title": "purrr-map04",
    "section": "",
    "text": "Exercise\nImportieren Sie das Grundatzprogramm der Partei AfD (in der aktuellsten Version). Tokenisieren Sie nach Seiten. Dann verschachteln Sie die Spalte, in denen der Text der Seite steht, zu einer Listenspalte. Schließlich zählen Sie die Anzahl der Wörter pro Seite und berichten gängige deskriptive Statistiken dazu.\n         \n\n\nSolution\nText aus PDF-Dateien kann man mit dem Paket pdftools einlesen:\n\nlibrary(pdftools)\n\nUsing poppler version 22.02.0\n\nd_path <- \"/Users/sebastiansaueruser/Google Drive/Literatur/_Div/Politik/afd-grundsatzprogramm-2022.pdf\"\n\nd <- tibble(text = pdf_text(d_path),\n            page = 1:length(text))\n\nZu Seiten tokenisieren brauchen wir nicht; das Datenmaterial ist bereits nach Seiten organisiert.\nJetzt “verschachteln” (to nest) wir die Spalte mit dem Text:\n\nd2 <-\n  d %>% \n  nest(data = text)\n\nhead(d2)\n\n# A tibble: 6 × 2\n   page data            \n  <int> <list>          \n1     1 <tibble [1 × 1]>\n2     2 <tibble [1 × 1]>\n3     3 <tibble [1 × 1]>\n4     4 <tibble [1 × 1]>\n5     5 <tibble [1 × 1]>\n6     6 <tibble [1 × 1]>\n\n\nDann zählen wir die Wörter pro Seite:\n\nd3 <-\n  d2 %>% \n  mutate(word_count_per_page = map(data, ~ str_count(.x$text, \"\\\\w+\")))\n\nhead(d3)\n\n# A tibble: 6 × 3\n   page data             word_count_per_page\n  <int> <list>           <list>             \n1     1 <tibble [1 × 1]> <int [1]>          \n2     2 <tibble [1 × 1]> <int [1]>          \n3     3 <tibble [1 × 1]> <int [1]>          \n4     4 <tibble [1 × 1]> <int [1]>          \n5     5 <tibble [1 × 1]> <int [1]>          \n6     6 <tibble [1 × 1]> <int [1]>          \n\n\nWie sieht eine Zelle aus data aus?\n\nd3$data[[1]]\n\n# A tibble: 1 × 1\n  text                                                                          \n  <chr>                                                                         \n1 \"PROGRAMM FÜR\\nDEUTSCHLAND.\\nDas Grundsatzprogramm der Alternative für Deutsc…\n\n\nWie sieht eine Zelle aus word_count_per_page aus?\n\nd3$data[[1]]\n\n# A tibble: 1 × 1\n  text                                                                          \n  <chr>                                                                         \n1 \"PROGRAMM FÜR\\nDEUTSCHLAND.\\nDas Grundsatzprogramm der Alternative für Deutsc…\n\n\nAh! Darin steckt nur eine einzelne Zahl!\n\nd3$data[[1]] %>% str()\n\ntibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n $ text: chr \"PROGRAMM FÜR\\nDEUTSCHLAND.\\nDas Grundsatzprogramm der Alternative für Deutschland.\\n\"\n\n\nDas heißt, wir können vereinfachen, entschacheln:\n\nd4 <-\n  d3 %>% \n  unnest(word_count_per_page)\n\nhead(d4)\n\n# A tibble: 6 × 3\n   page data             word_count_per_page\n  <int> <list>                         <int>\n1     1 <tibble [1 × 1]>                   9\n2     2 <tibble [1 × 1]>                 410\n3     3 <tibble [1 × 1]>                 516\n4     4 <tibble [1 × 1]>                 297\n5     5 <tibble [1 × 1]>                   1\n6     6 <tibble [1 × 1]>                 414\n\n\nVisualisierung:\n\nd4 %>% \n  ggplot(aes(x = word_count_per_page)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.5.2 (red = needs update)\n✖ insight     0.18.5   ✖ datawizard  0.6.2 \n✔ bayestestR  0.13.0   ✔ performance 0.10.0\n✔ parameters  0.19.0   ✖ effectsize  0.8.1 \n✔ modelbased  0.8.5    ✔ correlation 0.8.3 \n✔ see         0.7.3    ✔ report      0.5.5 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\ndescribe_distribution(d4$word_count_per_page)\n\n  Mean |     SD |    IQR |          Range | Skewness | Kurtosis |  n | n_Missing\n--------------------------------------------------------------------------------\n285.84 | 172.27 | 322.75 | [1.00, 516.00] |    -0.64 |    -1.24 | 96 |         0\n\n\n\nCategories:\n\nr\nmap\ntidyverse"
  },
  {
    "objectID": "posts/Stichprobenziehen1/Stichprobenziehen1.html",
    "href": "posts/Stichprobenziehen1/Stichprobenziehen1.html",
    "title": "Stichprobenziehen1",
    "section": "",
    "text": "Solution\nIndividuell\n\nCategories:\n\nlm\ninference\nqm2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "datenwerk",
    "section": "",
    "text": "textmining\n\n\ntwitter\n\n\nprogramming\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\nbayes\n\n\nbayes-box\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\nnormal-distribution\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\npost\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nbayes-box\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nsimulation\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqm2\n\n\nbayes\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nsimulation\n\n\ndistribution\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfat-tails\n\n\ndistributions\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\ndistribution\n\n\nfat-tails\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\nregression\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\npost\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nppv\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbayes\n\n\nprobability\n\n\nppv\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\nprogramming\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbinomial\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\nsimulation\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\ndice\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbinomial\n\n\nexample\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntextmining\n\n\ntwitter\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\n2022\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nphilosophy\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes-grid\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nbayes\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nconditional\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprogramming\n\n\nloop\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobabillity\n\n\ndependent\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\ndependent\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\nmeta\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprobability\n\n\n2022\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprogramming\n\n\nloop\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\nmap\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\nlm\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata\n\n\neda\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata\n\n\neda\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata\n\n\neda\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncausal\n\n\ndag\n\n\n\n\n\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncorrelation\n\n\nlm\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\nuncertainty\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nttest\n\n\nregr\n\n\nvariable-levels\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregresssion\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstats-nutshell\n\n\nqm2\n\n\nregression\n\n\nlog\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqm2\n\n\nlm\n\n\nbayes\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nbayes\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlm\n\n\ninference\n\n\nqm2\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninference\n\n\nlm\n\n\nqm2\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregresssion\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregresssion\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregresssion\n\n\nen\n\n\nbayes\n\n\nfrequentist\n\n\nqm1\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregr\n\n\nttest\n\n\nvariable-levels\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nstats-nutshell\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregression\n\n\nlm\n\n\nqm2\n\n\nbayes\n\n\nadjust\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqm2\n\n\ninference\n\n\nparameters\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlm\n\n\ninference\n\n\nqm2\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqm2\n\n\nqm2-thema01\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ans Werk, Daten!",
    "section": "",
    "text": "Autor: Sebastian Sauer\nDer Quellcode findet sich hier.\nDie Lizenz ist permissiv, s. Hinweise hier."
  },
  {
    "objectID": "posts/twitter07/twitter07.html",
    "href": "posts/twitter07/twitter07.html",
    "title": "twitter07",
    "section": "",
    "text": "Solution\nWir starten die benötigten R-Pakete:\n\nlibrary(academictwitteR)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(askpass)\nlibrary(rio)\n\nHier ist der Datensatz mit den Twitterkonten, für die wir die Daten herunterladen sollen:\n\npoliticians_path <- \"https://raw.githubusercontent.com/sebastiansauer/datascience-text/main/data/twitter-german-politicians.csv\"\npoliticians <- import(politicians_path)\npoliticians\n\n                                               name  party      screenname\n1                                   Karl Lauterbach    SPD Karl_Lauterbach\n2                                       Olaf Scholz    SPD      OlafScholz\n3                                 Annalena Baerback Gruene       ABaerbock\n4  Bundesministerium für Wirtschaft und Klimaschutz Gruene            BMWK\n5                                    Friedrich Merz    CDU  _FriedrichMerz\n6                                      Markus Söder    CSU   Markus_Soeder\n7                                       Cem Özdemir Gruene    cem_oezdemir\n8                                    Janine Wissler  Linke  Janine_Wissler\n9                                 Martin Schirdewan  Linke      schirdewan\n10                                Christian Lindner    FDP       c_lindner\n11                    Marie-Agnes Strack-Zimmermann    FDP      MAStrackZi\n12                                   Tino Chrupalla    AFD  Tino_Chrupalla\n13                                     Alice Weidel    AFD    Alice_Weidel\n                                  comment\n1                                    <NA>\n2                                    <NA>\n3                                    <NA>\n4  Robert Habeck ist der Minister im BMWK\n5                                CDU-Chef\n6                                CSU-Chef\n7                                    BMEL\n8                            Linke-Chefin\n9                              Linke-Chef\n10                               FDP-Chef\n11     Vorsitzende Verteidigungsausschuss\n12                     AFD-Bundessprecher\n13                   AFD-Bundessprecherin\n\n\nWir müssen noch das Passwort bereitstellen:\n\nbearer_token <- askpass::askpass(\"bearer token\")\n\nUnd dann definieren wir eine Funktion, die das Gewichtheben für uns erledigt:\n\nget_all_tweets_politicians <- function(screenname, n = 1e1) {\n  get_all_tweets(query = paste0(\"to:\", screenname, \" -is:retweet\"),\n                 start_tweets = \"2021-01-01T00:00:00Z\",\n                 end_tweets = \"2021-12-31T23:59:59Z\",\n                 bearer_token = bearer_token,\n                 file = glue::glue(\"~/datasets/Twitter/hate-speech/tweets_to_{screenname}_2021.rds\"),\n                 data_path = glue::glue(\"~/datasets/Twitter/hate-speech/{screenname}\"),\n                 n = n)\n}\n\nJetzt wenden wir die Funktion auf jedes Twitterkonto unserer Liste (alle Politikis) an:\n\nd <- politicians$screenname %>% \n  map(get_all_tweets_politicians)\n\n\nCategories:\n\ntextmining\ntwitter\nprogramming"
  }
]